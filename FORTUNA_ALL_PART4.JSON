{
    ".github/workflows/build-msi-unified.yml": "# System Timestamp: 2025-12-03 22:44:34.655552917\nname: Unified MSI Builder (Jules's Gold Standard)\n\non:\n  push:\n    branches:\n      - main\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  DOTNET_VERSION: '8.0.x'\n  WIX_VERSION: '4.0.5'\n  FRONTEND_DIR: 'web_platform/frontend'\n  WIX_DIR: 'build_wix'\n  SERVICE_PORT: '8102'\n\njobs:\n  path-finder:\n    name: '\ud83d\udd0e Path Finder - Dynamic Backend Detection'\n    runs-on: windows-latest\n    outputs:\n      backend_dir: ${{ steps.find-path.outputs.backend_dir }}\n      backend_module_path: ${{ steps.find-path.outputs.backend_module_path }}\n      semver: ${{ steps.meta.outputs.semver }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Detect Backend Path\n        id: find-path\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $web_service_path = \"web_service/backend\"\n          $python_service_path = \"python_service\"\n          if (Test-Path (Join-Path $web_service_path \"main.py\")) {\n              $backend_dir = $web_service_path\n              $backend_module_path = \"web_service.backend\"\n              Write-Host \"\u2705 Verdict: Detected 'web_service/backend' as the target.\"\n          } elseif (Test-Path (Join-Path $python_service_path \"main.py\")) {\n              $backend_dir = $python_service_path\n              $backend_module_path = \"python_service\"\n              Write-Host \"\u2705 Verdict: Detected 'python_service' as the target.\"\n          } else {\n              Write-Error \"\u274c FATAL: Could not determine a valid backend directory.\"\n              exit 1\n          }\n          \"backend_dir=$backend_dir\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"backend_module_path=$backend_module_path\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n      - name: Derive Build Metadata\n        id: meta\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $ref = \"${{ github.ref }}\"\n          if ($ref -like 'refs/tags/v*') {\n            $semver = $ref -replace 'refs/tags/v', ''\n          } else {\n            $semver = \"0.0.${{ github.run_number }}\"\n          }\n          \"semver=$semver\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          Write-Host \"\ud83d\udd16 Version: $semver\"\n\n  quality-gate:\n    name: '\u2705 Quality Gate'\n    runs-on: windows-latest\n    needs: path-finder\n    env:\n      BACKEND_DIR: ${{ needs.path-finder.outputs.backend_dir }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: |\n            ${{ env.BACKEND_DIR }}/requirements.txt\n            ${{ env.BACKEND_DIR }}/requirements-dev.txt\n\n      - name: Install Python Dependencies\n        run: |\n          python -m pip install --upgrade pip\n          if (Test-Path \"${{ env.BACKEND_DIR }}/requirements-dev.txt\") {\n            pip install -r ${{ env.BACKEND_DIR }}/requirements-dev.txt\n          } else {\n            # Fallback to standard requirements if -dev is not found\n            pip install -r ${{ env.BACKEND_DIR }}/requirements.txt\n          }\n\n      - name: Run Pytest\n        shell: pwsh\n        run: |\n          # Check if pytest is installed before trying to run it\n          $pytest_exists = Get-Command pytest -ErrorAction SilentlyContinue\n          if (-not $pytest_exists) {\n            Write-Host \"\u2139\ufe0f pytest not found in dependencies, skipping tests.\"\n            exit 0\n          }\n\n          python -m pytest ${{ env.BACKEND_DIR }}\n\n          # Exit code 5 means no tests were found, which is not a failure in this context.\n          if ($LASTEXITCODE -eq 5) {\n            Write-Host \"\u2705 Pytest returned exit code 5 (No tests found), which is acceptable.\"\n            exit 0\n          } elseif ($LASTEXITCODE -ne 0) {\n            Write-Error \"\u274c Pytest failed with exit code $LASTEXITCODE.\"\n            exit $LASTEXITCODE\n          }\n          Write-Host \"\u2705 Pytest suite passed.\"\n\n  build-executable:\n    name: '\ud83d\udee0\ufe0f Build Executable'\n    runs-on: windows-latest\n    needs: [path-finder, quality-gate]\n    env:\n      BACKEND_DIR: ${{ needs.path-finder.outputs.backend_dir }}\n      BACKEND_MODULE_PATH: ${{ needs.path-finder.outputs.backend_module_path }}\n    outputs:\n      build_id: ${{ steps.vars.outputs.build_id }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Set Build ID\n        id: vars\n        run: echo \"build_id=${{ github.run_id }}-${{ github.run_attempt }}\" | Out-File -FilePath $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: '${{ env.FRONTEND_DIR }}/package-lock.json'\n\n      - name: Install Frontend Dependencies & Build\n        shell: pwsh\n        run: |\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm ci --prefer-offline\n          npm run build\n          cd ../..\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: '${{ env.BACKEND_DIR }}/requirements.txt'\n\n      - name: Install Backend Dependencies\n        shell: pwsh\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r ${{ env.BACKEND_DIR }}/requirements.txt\n          pip install pyinstaller==6.6.0\n\n      - name: Create Dynamic Spec for PyInstaller\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $entry_point = (Join-Path $env:BACKEND_DIR \"main.py\").Replace('\\', '/')\n          $submodules = \"collect_submodules('{0}')\" -f $env:BACKEND_MODULE_PATH\n          $main_import = \"'{0}.main'\" -f $env:BACKEND_MODULE_PATH\n          $staging_ui_path = (Resolve-Path \"web_platform/frontend/out\").Path.Replace('\\', '/')\n          $other_service = if (\"${{ env.BACKEND_DIR }}\" -eq \"web_service/backend\") { \"python_service\" } else { \"web_service\" }\n          $backend_init = (Resolve-Path \"web_service/backend/__init__.py\").Path.Replace('\\', '/')\n          $parent_init = (Resolve-Path \"web_service/__init__.py\").Path.Replace('\\', '/')\n          $python_service_init = (Resolve-Path \"python_service/__init__.py\").Path.Replace('\\', '/')\n\n          # Ensure __init__.py files exist and are not empty to guarantee package recognition\n          Set-Content -Path \"web_service/__init__.py\" -Value \"# UNIFIED\" -Force\n          Set-Content -Path \"web_service/backend/__init__.py\" -Value \"# UNIFIED\" -Force\n          Set-Content -Path \"python_service/__init__.py\" -Value \"# UNIFIED\" -Force\n\n          $specContent = @(\n            '# -*- mode: python ; coding: utf-8 -*-',\n            '# DYNAMICALLY GENERATED SPEC - DO NOT EDIT MANUALLY',\n            'import os',\n            'from pathlib import Path',\n            'from PyInstaller.utils.hooks import collect_data_files, collect_submodules',\n            '',\n            'block_cipher = None',\n            'project_root = Path(os.getcwd())',\n            '',\n            '# Standard Data Collection (UI, package data, etc.)',\n            'datas = [',\n            \"    ('$staging_ui_path', 'ui'),\",\n            ']',\n            \"datas += collect_data_files('uvicorn')\",\n            \"datas += collect_data_files('slowapi')\",\n            \"datas += collect_data_files('structlog')\",\n            \"datas += collect_data_files('certifi')\",\n            '',\n            'hiddenimports = set()',\n            \"hiddenimports.update($submodules)\",\n            'hiddenimports.update([',\n            \"    'uvicorn.logging', 'uvicorn.loops.auto', 'uvicorn.lifespan.on',\",\n            \"    'uvicorn.protocols.http.h11_impl', 'uvicorn.protocols.websockets.wsproto_impl',\",\n            \"    'fastapi.routing', 'starlette.staticfiles', 'anyio._backends._asyncio',\",\n            \"    'httpcore', 'httpx', 'slowapi', 'structlog', 'tenacity', 'aiosqlite',\",\n            \"    'pydantic_core', 'pydantic_settings.sources', $main_import\",\n            '])',\n            '',\n            'a = Analysis(',\n            \"    ['$entry_point'],\",\n            '    pathex=[str(project_root)],',\n            '    binaries=[],',\n            '    datas=datas,',\n            '    hiddenimports=sorted(hiddenimports),',\n            '    hookspath=[],',\n            '    runtime_hooks=[],',\n            \"    excludes=['tests', 'pytest', '$other_service'], # CRITICAL: Exclude the other service\",\n            '    win_no_prefer_redirects=False,',\n            '    win_private_assemblies=False,',\n            '    cipher=block_cipher,',\n            '    noarchive=False',\n            ')',\n            '',\n            \"# \u2622\ufe0f PYZ INJECTION: Force __init__ files into the PYZ archive as modules\",\n            \"a.pure += [\",\n            \"    ('web_service', '$parent_init', 'PYMODULE'),\",\n            \"    ('web_service.backend', '$backend_init', 'PYMODULE'),\",\n            \"    ('python_service', '$python_service_init', 'PYMODULE')\",\n            \"]\",\n            '',\n            'pyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)',\n            'exe = EXE(',\n            '    pyz,',\n            '    a.scripts,',\n            '    a.binaries,',\n            '    a.zipfiles,',\n            '    a.datas,',\n            '    [],',\n            \"    name='fortuna-backend',\",\n            '    debug=False,',\n            '    bootloader_ignore_signals=False,',\n            '    strip=False,',\n            '    upx=True,',\n            '    runtime_tmpdir=None,',\n            '    console=False,',\n            '    disable_windowed_traceback=False,',\n            '    argv_emulation=False,',\n            '    target_arch=None,',\n            '    codesign_identity=None,',\n            '    entitlements_file=None',\n            ')'\n          )\n          # Use a unique name for the unified workflow's spec file\n          Set-Content -Path \"unified.spec\" -Value ($specContent -join \"`n\")\n          Write-Host \"\u2705 Dynamically generated 'unified.spec' created.\"\n\n      - name: Build with PyInstaller\n        run: pyinstaller unified.spec --clean --noconfirm\n\n      - name: Upload Backend Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: backend-dist-${{ steps.vars.outputs.build_id }}\n          path: dist/fortuna-backend.exe\n          retention-days: 1\n\n      - name: \ud83d\udce4 Upload Executable on Failure\n        if: failure()\n        uses: actions/upload-artifact@v4\n        with:\n          name: failed-executable-${{ steps.vars.outputs.build_id }}\n          path: dist/\n          retention-days: 5\n\n  package-msi:\n    name: '\ud83d\udcbf Package MSI'\n    runs-on: windows-latest\n    needs: [path-finder, build-executable]\n    outputs:\n      build_id: ${{ needs.build-executable.outputs.build_id }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Download Backend Artifact\n        uses: actions/download-artifact@v4\n        with:\n          name: backend-dist-${{ needs.build-executable.outputs.build_id }}\n          path: staging\n\n      - name: Setup .NET SDK\n        uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: ${{ env.DOTNET_VERSION }}\n\n      - name: Prepare WiX Project\n        shell: pwsh\n        run: |\n          Copy-Item \"${{ env.WIX_DIR }}/Product_WithService.wxs\" \"${{ env.WIX_DIR }}/Product.wxs\" -Force\n          $wixProj = @(\n            '<Project Sdk=\"WixToolset.Sdk/${{ env.WIX_VERSION }}\">'\n            '  <PropertyGroup>'\n            '    <OutputName>Fortuna-WebService-Pragmatic</OutputName>'\n            '    <OutputType>Package</OutputType>'\n            '    <EnableDefaultCompileItems>false</EnableDefaultCompileItems>'\n            '    <DefineConstants>SourceDir=../staging;Version=${{ needs.path-finder.outputs.semver }};ServicePort=${{ env.SERVICE_PORT }}</DefineConstants>'\n            '  </PropertyGroup>'\n            '  <ItemGroup>'\n            '    <PackageReference Include=\"WixToolset.Util.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '    <PackageReference Include=\"WixToolset.Firewall.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '    <PackageReference Include=\"WixToolset.UI.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '  </ItemGroup>'\n            '  <ItemGroup>'\n            '    <Compile Include=\"Product.wxs\" />'\n            '  </ItemGroup>'\n            '</Project>'\n          )\n          Set-Content \"${{ env.WIX_DIR }}/Fortuna.wixproj\" -Value ($wixProj -join \"`n\")\n\n      - name: Build MSI\n        working-directory: ${{ env.WIX_DIR }}\n        run: dotnet build Fortuna.wixproj -c Release -p:Platform=x64\n\n      - name: Upload MSI Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: msi-installer-${{ needs.build-executable.outputs.build_id }}\n          path: ${{ env.WIX_DIR }}/bin/x64/Release/*.msi\n          retention-days: 1\n\n  smoke-test:\n    name: '\ud83d\udd2c Smoke Test (Unified)'\n    runs-on: windows-latest\n    needs: package-msi\n    steps:\n      - name: Download MSI Installer\n        uses: actions/download-artifact@v4\n        with:\n          name: msi-installer-${{ needs.package-msi.outputs.build_id }}\n          path: msi-installer\n\n      - name: \ud83d\udee1\ufe0f Configure Firewall\n        shell: pwsh\n        run: |\n          # EXOTIC INGREDIENT #1: Open the port BEFORE the service even thinks about starting\n          # This prevents \"connection refused\" errors in the health check\n          New-NetFirewallRule `\n            -DisplayName \"FortunaFaucetService\" `\n            -Direction Inbound `\n            -LocalPort 8102 `\n            -Protocol TCP `\n            -Action Allow `\n            -ErrorAction SilentlyContinue\n          Write-Host \"\u2705 Firewall rule added for port 8102\"\n\n      - name: \ud83e\udd2b Install MSI (With Logging)\n        shell: pwsh\n        run: |\n          # Verify MSI exists before attempting install\n          $msi = Get-ChildItem -Path \"msi-installer\" -Filter \"*.msi\" -Recurse | Select-Object -First 1\n          if (-not $msi) {\n            Write-Error \"\u274c FATAL: No MSI found in artifact\"\n            Get-ChildItem -Path \"msi-installer\" -Recurse\n            exit 1\n          }\n\n          Write-Host \"Installing: $($msi.FullName)\"\n\n          # EXOTIC INGREDIENT #2: /L*v logging to catch install failures\n          # This creates msi-install.log with detailed diagnostics\n          Start-Process msiexec.exe `\n            -ArgumentList \"/i `\"$($msi.FullName)`\" /qn /L*v msi-install.log\" `\n            -Wait `\n            -NoNewWindow\n\n          if ($LASTEXITCODE -ne 0) {\n            Write-Error \"\u274c MSI Install Failed with exit code $LASTEXITCODE\"\n            Write-Host \"=== Last 50 lines of MSI Log ===\"\n            Get-Content msi-install.log | Select-Object -Last 50\n            exit 1\n          }\n\n          Write-Host \"\u2705 MSI installation succeeded\"\n\n      - name: \u23f3 Wait for Service Registration\n        shell: pwsh\n        run: |\n          # EXOTIC INGREDIENT #3: Don't start the service until Windows Registry knows about it\n          # The MSI installer registers the service asynchronously\n          # If we call sc.exe start too soon, it fails silently\n\n          $regPath = \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\FortunaFaucetService\"\n          Write-Host \"Waiting for service to be registered in registry...\"\n\n          for ($i = 0; $i -lt 30; $i++) {\n            if (Test-Path $regPath) {\n              Write-Host \"\u2705 Service registered (took $i seconds)\"\n              $svc = Get-Service -Name \"FortunaFaucetService\" -ErrorAction SilentlyContinue\n              Write-Host \"   DisplayName: $($svc.DisplayName)\"\n              Write-Host \"   Status: $($svc.Status)\"\n              exit 0\n            }\n            Write-Host \"  Waiting... ($i/30 seconds)\"\n            Start-Sleep -Seconds 1\n          }\n\n          Write-Error \"\u274c Service was not registered in HKLM after 30 seconds\"\n          exit 1\n\n      - name: \ud83d\ude80 Launch & Verify Health\n        shell: python\n        env:\n          SERVICE_PORT: '8102'\n        run: |\n          import os, sys, subprocess, socket, time, urllib.request, urllib.error\n\n          PORT = int(os.getenv(\"SERVICE_PORT\", 8102))\n\n          print(\"--- Starting Service via SC.EXE ---\")\n          # We use sc.exe because we verified the registry key exists\n          result = subprocess.run(\n            [\"sc.exe\", \"start\", \"FortunaFaucetService\"],\n            capture_output=True,\n            text=True\n          )\n          print(f\"sc.exe output: {result.stdout}\")\n          if result.stderr:\n            print(f\"sc.exe stderr: {result.stderr}\")\n\n          print(f\"\\n--- Waiting for Port {PORT} (up to 60 seconds) ---\")\n          start_time = time.time()\n          socket_bound = False\n\n          while time.time() - start_time < 60:\n            try:\n              with socket.create_connection((\"127.0.0.1\", PORT), timeout=1):\n                elapsed = time.time() - start_time\n                print(f\"\u2705 Socket bound after {elapsed:.1f} seconds.\")\n                socket_bound = True\n                break\n            except Exception as e:\n              elapsed = time.time() - start_time\n              print(f\"  Waiting... {elapsed:.1f}s\", end=\"\\r\")\n              time.sleep(2)\n\n          if not socket_bound:\n            print(f\"\\n\u274c FATAL: Service did not bind port 8102 within 60 seconds\")\n            print(\"Dumping service status for debugging:\")\n            subprocess.run([\"sc.exe\", \"query\", \"FortunaFaucetService\"])\n            sys.exit(1)\n\n          # Give the service a moment to be ready for HTTP requests\n          time.sleep(2)\n\n          print(\"\\n--- HTTP Health Check ---\")\n          for attempt in range(5):\n            try:\n              # EXOTIC INGREDIENT #4: User-Agent header to look like a real browser/client\n              # Some services reject requests without a User-Agent\n              req = urllib.request.Request(f\"http://127.0.0.1:{PORT}/health\")\n              req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)')\n\n              with urllib.request.urlopen(req, timeout=5) as response:\n                if response.status == 200:\n                  print(f\"\u2705 Health Check PASSED (HTTP 200).\")\n                  sys.exit(0)\n                else:\n                  print(f\"\u26a0\ufe0f  Unexpected status {response.status}\")\n\n            except urllib.error.HTTPError as e:\n              # 401/403 = service is UP, just has auth issues\n              if e.code in [401, 403]:\n                print(f\"\u26a0\ufe0f  Got HTTP {e.code} \u2014 service is responding!\")\n                sys.exit(0)\n              print(f\"Attempt {attempt + 1}: HTTP {e.code}\")\n\n            except Exception as e:\n              print(f\"Attempt {attempt + 1}: {type(e).__name__}: {e}\")\n\n            if attempt < 4:\n              time.sleep(2)\n\n          print(\"\u274c Health Check FAILED after 5 attempts\")\n          sys.exit(1)\n\n      - name: \ud83d\udce4 Upload Logs on Failure\n        if: failure()\n        uses: actions/upload-artifact@v4\n        with:\n          name: unified-smoke-test-logs-${{ github.run_id }}\n          path: |\n            msi-install.log\n          retention-days: 7\n\n      - name: \ud83e\uddf9 Cleanup\n        if: always()\n        shell: pwsh\n        run: |\n          sc.exe stop FortunaFaucetService 2>&1 | Out-Null\n          sc.exe delete FortunaFaucetService 2>&1 | Out-Null\n          Remove-NetFirewallRule -DisplayName \"FortunaFaucetService\" -ErrorAction SilentlyContinue\n          Write-Host \"\u2705 Cleanup complete\"\n",
    ".github/workflows/build-web-service-msi-jules.yml": "# System Timestamp: 2025-11-30 10:29:10.703207\nname: Build Fortuna Faucet Web Service Installer (Synthesized Overkill)\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: read\n  actions: read\n  checks: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\ndefaults:\n  run:\n    shell: pwsh\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  DOTNET_VERSION: '8.0.x'\n  PYTHONUTF8: '1'\n  PIP_DISABLE_PIP_VERSION_CHECK: '1'\n  PIP_NO_PYTHON_VERSION_WARNING: '1'\n  NPM_CONFIG_FUND: 'false'\n  NPM_CONFIG_AUDIT: 'false'\n  FORCE_COLOR: '3'\n  FRONTEND_DIR: 'web_platform/frontend'\n  FRONTEND_BUILD_DIR: 'web_platform/frontend/out'\n  WIX_DIR: 'build_wix'\n  SERVICE_PORT: '8102'\n  HEALTH_ENDPOINT: '/health'\n  API_KEY: ${{ secrets.TEST_API_KEY }}\n  MSI_STAGING_DIR: 'build_wix/staging'\n  MSI_OUTPUT_DIR: 'dist'\n  WIX_VERSION: '4.0.5'\n\njobs:\n  path-finder:\n    name: '\ud83d\udd0e Path Finder Dynamic Backend Detection'\n    runs-on: windows-latest\n    outputs:\n      backend_dir: ${{ steps.find-path.outputs.backend_dir }}\n      backend_module_path: ${{ steps.find-path.outputs.backend_module_path }}\n      spec_file: ${{ steps.find-path.outputs.spec_file }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Detect Backend Path\n        id: find-path\n        run: |\n          Set-StrictMode -Version Latest\n          $web_service_path = \"web_service/backend\"\n          $python_service_path = \"python_service\"\n          $backend_dir = \"\"\n          $backend_module_path = \"\"\n          $spec_file = \"\"\n\n          Write-Host \"--- Path Finding Forensics ---\"\n          Write-Host \"Searching for the correct backend service directory...\"\n\n          # Test web_service path\n          $web_service_main = Test-Path (Join-Path $web_service_path \"main.py\")\n          $web_service_api = Test-Path (Join-Path $web_service_path \"api.py\")\n          $web_service_init = Test-Path (Join-Path $web_service_path \"__init__.py\")\n          Write-Host \"Checking '$web_service_path':\"\n          Write-Host \"  main.py -> $web_service_main\"\n          Write-Host \"  api.py -> $web_service_api\"\n          Write-Host \"  __init__.py -> $web_service_init\"\n\n          # Test python_service path\n          $python_service_main = Test-Path (Join-Path $python_service_path \"main.py\")\n          $python_service_api = Test-Path (Join-Path $python_service_path \"api.py\")\n          $python_service_init = Test-Path (Join-Path $python_service_path \"__init__.py\")\n          Write-Host \"Checking '$python_service_path':\"\n          Write-Host \"  main.py -> $python_service_main\"\n          Write-Host \"  api.py -> $python_service_api\"\n          Write-Host \"  __init__.py -> $python_service_init\"\n\n          if ($web_service_main -and $web_service_api -and $web_service_init) {\n            $backend_dir = $web_service_path\n            $backend_module_path = \"web_service.backend\"\n            $spec_file = \"webservice.spec\"\n            Write-Host \"\u2705 Verdict: Detected 'web_service/backend' as the target.\" -ForegroundColor Green\n          } elseif ($python_service_main -and $python_service_api -and $python_service_init) {\n            $backend_dir = $python_service_path\n            $backend_module_path = \"python_service\"\n            $spec_file = \"fortuna-backend-webservice.spec\"\n            Write-Host \"\u2705 Verdict: Detected 'python_service' as the target.\" -ForegroundColor Green\n          } else {\n            Write-Host \"\u274c FATAL: Could not determine a valid backend directory. Neither 'web_service/backend' nor 'python_service' contains the required files (main.py, api.py, __init__.py).\" -ForegroundColor Red\n            exit 1\n          }\n\n          Write-Host \"--- Outputs ---\"\n          Write-Host \"backend_dir: $backend_dir\"\n          Write-Host \"backend_module_path: $backend_module_path\"\n          Write-Host \"spec_file: $spec_file\"\n\n          \"backend_dir=$backend_dir\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"backend_module_path=$backend_module_path\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"spec_file=$spec_file\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n  system-check:\n    name: '\u2699\ufe0f System Prerequisites'\n    runs-on: windows-latest\n    timeout-minutes: 5\n    outputs:\n      disk_free_gb: ${{ steps.system.outputs.disk_gb }}\n    steps:\n      - name: Verify Build Tools\n        run: |\n          Set-StrictMode -Version Latest\n          $tools = @('dotnet', 'python', 'node', 'npm', 'git')\n          foreach ($tool in $tools) {\n            Write-Host \"Checking for $($tool)...\"\n            Get-Command $tool -ErrorAction SilentlyContinue\n            if (-not $?) {\n              Write-Host \"\u274c FATAL: Build tool '$tool' not found in PATH.\" -ForegroundColor Red\n              exit 1\n            }\n          }\n          Write-Host \"\u2705 All critical build tools are present.\" -ForegroundColor Green\n      - name: Check Disk Space\n        id: system\n        run: |\n          Set-StrictMode -Version Latest\n          $disk = Get-Volume | Where-Object { $_.DriveLetter -eq 'C' }\n          $freeGB = [math]::Round($disk.SizeRemaining / 1GB, 2)\n          if ($freeGB -lt 10) {\n            Write-Host \"\u26a0\ufe0f WARNING: Low disk space. Only $freeGB GB free (10+ GB recommended).\" -ForegroundColor Yellow\n          } else {\n            Write-Host \"\u2705 Disk space check passed ($freeGB GB free).\" -ForegroundColor Green\n          }\n          \"disk_gb=$freeGB\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n  repo-preflight:\n    name: '\ud83e\uddea Repo Preflight & Integrity'\n    runs-on: windows-latest\n    needs: [path-finder, system-check]\n    timeout-minutes: 5\n    outputs:\n      frontend_lock_hash: ${{ steps.hashes.outputs.frontend_lock_hash }}\n      backend_requirements_hash: ${{ steps.hashes.outputs.backend_requirements_hash }}\n      wix_definition_hash: ${{ steps.hashes.outputs.wix_definition_hash }}\n      semver: ${{ steps.meta.outputs.semver }}\n      short_sha: ${{ steps.meta.outputs.short_sha }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Derive Build Metadata\n        id: meta\n        run: |\n          Set-StrictMode -Version Latest\n          $ref = \"${{ github.ref }}\"\n          if ($ref -like 'refs/tags/v*') {\n            $semver = $ref -replace 'refs/tags/v', ''\n          } else {\n            $semver = \"0.0.${{ github.run_number }}\"\n          }\n          $shortSha = \"${{ github.sha }}\".Substring(0,7)\n          \"semver=$semver\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"short_sha=$shortSha\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          Write-Host \"\ud83d\udd16 Version: $semver ($shortSha)\"\n\n      - name: Validate Critical Files Exist\n        env:\n          BACKEND_DIR: ${{ needs.path-finder.outputs.backend_dir }}\n        run: |\n          Set-StrictMode -Version Latest\n          $paths = @(\n            \"${{ env.FRONTEND_DIR }}/package.json\",\n            \"${{ env.FRONTEND_DIR }}/package-lock.json\",\n            (Join-Path $env:BACKEND_DIR \"requirements.txt\"),\n            (Join-Path $env:BACKEND_DIR \"main.py\"),\n            \"${{ env.WIX_DIR }}/Product_WithService.wxs\"\n          )\n          foreach ($path in $paths) {\n            if (-not (Test-Path $path)) {\n              Write-Host \"\u274c FATAL: Required path missing: $path\" -ForegroundColor Red\n              exit 1\n            }\n          }\n          Write-Host \"\u2705 All critical files confirmed.\"\n\n      - name: Capture Integrity Hashes\n        id: hashes\n        env:\n          BACKEND_DIR: ${{ needs.path-finder.outputs.backend_dir }}\n        run: |\n          Set-StrictMode -Version Latest\n          $frontend = (Get-FileHash \"${{ env.FRONTEND_DIR }}/package-lock.json\" -Algorithm SHA256).Hash\n          $backend = (Get-FileHash (Join-Path $env:BACKEND_DIR \"requirements.txt\") -Algorithm SHA256).Hash\n          $wix = (Get-FileHash \"${{ env.WIX_DIR }}/Product_WithService.wxs\" -Algorithm SHA256).Hash\n          \"frontend_lock_hash=$frontend\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"backend_requirements_hash=$backend\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"wix_definition_hash=$wix\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n      - name: Upload Integrity Snapshot\n        uses: actions/upload-artifact@v4\n        with:\n          name: repo-preflight-${{ github.run_id }}\n          path: |\n            ${{ env.FRONTEND_DIR }}/package-lock.json\n            ${{ env.BACKEND_DIR }}/requirements.txt\n            ${{ env.WIX_DIR }}/Product_WithService.wxs\n          retention-days: 3\n\n  frontend-quality:\n    name: '\ud83e\uddfc Frontend Quality Gates'\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    needs: repo-preflight\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: '${{ env.FRONTEND_DIR }}/package-lock.json'\n\n      - name: Cache Frontend Build\n        id: cache-frontend\n        uses: actions/cache@v4\n        with:\n          path: ${{ env.FRONTEND_BUILD_DIR }}\n          key: ${{ runner.os }}-frontend-build-${{ hashFiles('${{ env.FRONTEND_DIR }}/**') }}\n\n      - name: Install Dependencies\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm ci --prefer-offline --no-audit --no-fund\n\n      - name: Run Lint (if defined)\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          $pkg = Get-Content package.json -Raw | ConvertFrom-Json\n          if ($pkg.scripts.PSObject.Properties.Name -contains 'lint') {\n            Write-Host \"\ud83e\uddf9 Running npm run lint\"\n            npm run lint\n          } else {\n            Write-Host \"\u2139\ufe0f No lint script defined, skipping.\"\n          }\n\n      - name: Run Tests (if defined)\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          $pkg = Get-Content package.json -Raw | ConvertFrom-Json\n          if ($pkg.scripts.PSObject.Properties.Name -contains 'test') {\n            Write-Host \"\ud83e\uddea Running npm test -- --watch=false\"\n            npm test -- --watch=false\n          } else {\n            Write-Host \"\u2139\ufe0f No test script defined, skipping.\"\n          }\n\n      - name: Security Audit (non-blocking)\n        continue-on-error: true\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm audit --audit-level=critical\n\n  backend-quality:\n    name: '\ud83e\uddef Backend Quality Gates'\n    runs-on: ubuntu-latest\n    timeout-minutes: 20\n    needs: [path-finder, repo-preflight]\n    env:\n      BACKEND_REQUIREMENTS_HASH: ${{ needs.repo-preflight.outputs.backend_requirements_hash }}\n      BACKEND_DIR: ${{ needs.path-finder.outputs.backend_dir }}\n      BACKEND_SPEC: ${{ needs.path-finder.outputs.spec_file }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: |\n            ${{ env.BACKEND_DIR }}/requirements.txt\n            ${{ env.BACKEND_DIR }}/requirements-dev.txt\n\n      - name: Cache Backend Build\n        id: cache-backend\n        uses: actions/cache@v4\n        with:\n          path: dist\n          key: ${{ runner.os }}-backend-build-${{ hashFiles(format('{0}/**', env.BACKEND_DIR), format('{0}', env.BACKEND_SPEC)) }}\n\n      - name: Install Dependencies\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel\n          pip install -r (Join-Path $env:BACKEND_DIR \"requirements.txt\")\n          if (Test-Path (Join-Path $env:BACKEND_DIR \"requirements-dev.txt\")) {\n            pip install -r (Join-Path $env:BACKEND_DIR \"requirements-dev.txt\")\n          } else {\n            Write-Host \"\u2139\ufe0f requirements-dev.txt not found, skipping.\"\n          }\n\n      - name: Bytecode Compile (Fail Fast)\n        run: |\n          Set-StrictMode -Version Latest\n          python -m compileall -q \"${{ env.BACKEND_DIR }}\"\n\n      - name: Run Pytest (if available)\n        run: |\n          Set-StrictMode -Version Latest\n          python -c 'import importlib.util, sys; sys.exit(0 if importlib.util.find_spec(\"pytest\") else 1)'\n          if ($LASTEXITCODE -eq 0) {\n            Write-Host \"\ud83e\uddea pytest detected, running suite...\"\n            python -m pytest \"${{ env.BACKEND_DIR }}\" --maxfail=1 --disable-warnings\n          } else {\n            Write-Host \"\u2139\ufe0f pytest not installed; skipping tests.\"\n          }\n\n      - name: pip-audit (non-blocking)\n        continue-on-error: true\n        run: |\n          Set-StrictMode -Version Latest\n          pip install pip-audit\n          pip-audit -r (Join-Path $env:BACKEND_DIR \"requirements.txt\")\n\n  sbom:\n    name: '\ud83d\udcc4 SBOM Snapshot'\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    needs: repo-preflight\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Generate SBOM (SPDX)\n        uses: anchore/sbom-action@v0\n        with:\n          output-file: sbom.spdx.json\n          format: spdx-json\n\n      - name: Upload SBOM\n        uses: actions/upload-artifact@v4\n        with:\n          name: sbom-${{ github.run_id }}\n          path: sbom.spdx.json\n          retention-days: 7\n\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend'\n    runs-on: windows-latest\n    timeout-minutes: 20\n    needs: [path-finder, repo-preflight, frontend-quality]\n    env:\n      FRONTEND_LOCK_HASH: ${{ needs.repo-preflight.outputs.frontend_lock_hash }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: '${{ env.FRONTEND_DIR }}/package-lock.json'\n\n      - name: Cache Frontend Build\n        id: cache-frontend\n        uses: actions/cache@v4\n        with:\n          path: ${{ env.FRONTEND_BUILD_DIR }}\n          key: ${{ runner.os }}-frontend-build-${{ hashFiles('${{ env.FRONTEND_DIR }}/**') }}\n          restore-keys: |\n            ${{ runner.os }}-frontend-build-\n\n      - name: Prime npm Cache\n        uses: actions/cache@v4\n        with:\n          path: ~\\AppData\\Local\\npm-cache\n          key: ${{ runner.os }}-npm-${{ env.NODE_VERSION }}-${{ env.FRONTEND_LOCK_HASH }}\n          restore-keys: |\n            ${{ runner.os }}-npm-${{ env.NODE_VERSION }}-\n\n      - name: Install Dependencies\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm ci --prefer-offline --no-audit --no-fund\n\n      - name: Build Frontend\n        if: steps.cache-frontend.outputs.cache-hit != 'true'\n        env:\n          NEXT_PUBLIC_API_URL: http://127.0.0.1:${{ env.SERVICE_PORT }}\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm run build\n\n      - name: Report Cache Status\n        run: |\n          if ('${{ steps.cache-frontend.outputs.cache-hit }}' -eq 'true') {\n            Write-Host \"\u2705 Frontend build restored from cache.\" -ForegroundColor Green\n          } else {\n            Write-Host \"\u2139\ufe0f No cache hit. A new build was performed.\" -ForegroundColor Yellow\n          }\n\n      - name: Verify Build Output\n        run: |\n          Set-StrictMode -Version Latest\n          $outDir = Resolve-Path \"${{ env.FRONTEND_BUILD_DIR }}\"\n          if (-not (Test-Path $outDir)) {\n             Write-Host \"\u274c FATAL: Build directory not found\" -ForegroundColor Red\n             exit 1\n          }\n          $files = Get-ChildItem -Path $outDir -Recurse -File\n          if ($files.Count -eq 0) {\n             Write-Host \"\u274c FATAL: Build directory empty\" -ForegroundColor Red\n             exit 1\n          }\n          Write-Host \"\u2705 Frontend built: $($files.Count) files.\"\n\n      - name: Generate Artifact Manifest\n        run: |\n          Set-StrictMode -Version Latest\n          $outDir = Resolve-Path \"${{ env.FRONTEND_BUILD_DIR }}\"\n          $manifestPath = \"frontend-manifest.tsv\"\n          \"RelativePath`tSizeBytes`tSHA256\" | Out-File $manifestPath -Encoding utf8\n          Get-ChildItem -Path $outDir -Recurse -File | ForEach-Object {\n            $relative = $_.FullName.Substring($outDir.Path.Length).TrimStart('\\','/')\n            $hash = (Get-FileHash $_.FullName -Algorithm SHA256).Hash\n            \"$relative`t$($_.Length)`t$hash\" | Out-File $manifestPath -Encoding utf8 -Append\n          }\n\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: frontend-build-${{ github.run_id }}\n          path: ${{ env.FRONTEND_BUILD_DIR }}\n          retention-days: 3\n\n      - name: Upload Manifest\n        uses: actions/upload-artifact@v4\n        with:\n          name: frontend-manifest-${{ github.run_id }}\n          path: frontend-manifest.tsv\n          retention-days: 3\n\n  build-backend:\n    name: '\ud83d\udc0d Build Backend'\n    runs-on: windows-latest\n    timeout-minutes: 25\n    needs: [path-finder, repo-preflight, build-frontend, backend-quality]\n    env:\n      BACKEND_REQUIREMENTS_HASH: ${{ needs.repo-preflight.outputs.backend_requirements_hash }}\n      BUILD_VERSION: ${{ needs.repo-preflight.outputs.semver }}\n      BACKEND_DIR: ${{ needs.path-finder.outputs.backend_dir }}\n      BACKEND_MODULE_PATH: ${{ needs.path-finder.outputs.backend_module_path }}\n      BACKEND_SPEC: ${{ needs.path-finder.outputs.spec_file }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Download Frontend Artifact\n        uses: actions/download-artifact@v4\n        with:\n          name: frontend-build-${{ github.run_id }}\n          path: temp-frontend\n\n      - name: Cache Backend Build\n        id: cache-backend\n        uses: actions/cache@v4\n        with:\n          path: dist\n          key: ${{ runner.os }}-backend-build-${{ hashFiles(format('{0}/**', env.BACKEND_DIR), format('{0}', env.BACKEND_SPEC)) }}\n          restore-keys: |\n            ${{ runner.os }}-backend-build-\n\n      - name: Stage Frontend for PyInstaller\n        run: |\n          Set-StrictMode -Version Latest\n          $dest = \"staging/ui\"\n          New-Item -ItemType Directory -Path $dest -Force | Out-Null\n          Copy-Item -Path \"temp-frontend/*\" -Destination $dest -Recurse -Force\n          Write-Host \"\u2705 Frontend staged for inclusion.\"\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: |\n            ${{ env.BACKEND_DIR }}/requirements.txt\n            ${{ env.BACKEND_DIR }}/requirements-dev.txt\n\n      - name: Install Dependencies\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel\n          pip install -r (Join-Path $env:BACKEND_DIR \"requirements.txt\")\n          if (Test-Path (Join-Path $env:BACKEND_DIR \"requirements-dev.txt\")) {\n            pip install -r (Join-Path $env:BACKEND_DIR \"requirements-dev.txt\")\n          }\n\n      - name: Freeze Dependency Snapshot\n        if: steps.cache-backend.outputs.cache-hit != 'true'\n        run: |\n          Set-StrictMode -Version Latest\n          pip freeze | Out-File backend-freeze.txt -Encoding utf8\n\n      - name: Create Dynamic webservice.spec for PyInstaller\n        if: steps.cache-backend.outputs.cache-hit != 'true'\n        shell: python\n        env:\n          BACKEND_DIR: ${{ needs.path-finder.outputs.backend_dir }}\n          BACKEND_MODULE_PATH: ${{ needs.path-finder.outputs.backend_module_path }}\n          BACKEND_SPEC_FILE: ${{ needs.path-finder.outputs.spec_file }}\n        run: |\n          import os\n          from pathlib import Path\n\n          # Create __init__.py files in-memory to avoid filesystem race conditions\n          init_content = \"# This file is intentionally non-empty to ensure package recognition.\"\n\n          # Ensure parent directories exist before writing files\n          Path(\"web_service\").mkdir(exist_ok=True)\n          Path(\"web_service/backend\").mkdir(exist_ok=True)\n\n          with open(\"web_service/__init__.py\", \"w\") as f:\n              f.write(init_content)\n          with open(\"web_service/backend/__init__.py\", \"w\") as f:\n              f.write(init_content)\n\n          print(\"\u2705 Ensured non-empty __init__.py files exist for package discovery.\")\n\n          entry_point = os.path.join(os.environ['BACKEND_DIR'], \"main.py\").replace('\\\\', '/')\n          staging_ui_path = Path(\"staging/ui\").resolve().as_posix()\n          other_service = \"python_service\" if \"web_service\" in os.environ['BACKEND_DIR'] else \"web_service\"\n          backend_init = Path(\"web_service/backend/__init__.py\").resolve().as_posix()\n          parent_init = Path(\"web_service/__init__.py\").resolve().as_posix()\n          spec_file = os.environ['BACKEND_SPEC_FILE']\n\n          spec_content = f\"\"\"\n          # -*- mode: python ; coding: utf-8 -*-\n          import os\n          from pathlib import Path\n          from PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\n          block_cipher = None\n          project_root = Path(os.getcwd())\n\n          # Standard Data Collection\n          datas = [\n              ('{staging_ui_path}', 'ui'),\n          ]\n          datas += collect_data_files('uvicorn')\n          datas += collect_data_files('slowapi')\n          datas += collect_data_files('structlog')\n\n          hiddenimports = collect_submodules('{os.environ[\"BACKEND_MODULE_PATH\"]}')\n          hiddenimports += [\n              'uvicorn.logging', 'uvicorn.loops.auto', 'uvicorn.lifespan.on',\n              'uvicorn.protocols.http.h11_impl', 'uvicorn.protocols.websockets.wsproto_impl',\n              'fastapi.routing', 'starlette.staticfiles', 'anyio._backends._asyncio',\n              'httpcore', 'httpx', 'slowapi', 'structlog', 'tenacity', 'aiosqlite',\n              'pydantic_core', 'pydantic_settings.sources'\n          ]\n\n          a = Analysis(\n              ['{entry_point}'],\n              pathex=[str(project_root)],\n              binaries=[],\n              datas=datas,\n              hiddenimports=hiddenimports,\n              hookspath=[],\n              runtime_hooks=[],\n              excludes=['tests', 'pytest', '{other_service}'],\n              win_no_prefer_redirects=False,\n              win_private_assemblies=False,\n              cipher=block_cipher,\n              noarchive=False\n          )\n\n          # \u2622\ufe0f NUCLEAR OVERRIDE: Force __init__ files into the PYZ archive\n          # This puts them in the importable namespace, not just on the filesystem.\n          a.pure += [\n              ('web_service', '{parent_init}', 'PYMODULE'),\n              ('web_service.backend', '{backend_init}', 'PYMODULE')\n          ]\n\n          pyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n          exe = EXE(\n              pyz,\n              a.scripts,\n              a.binaries,\n              a.zipfiles,\n              a.datas,\n              [],\n              name='fortuna-backend',\n              debug=False,\n              bootloader_ignore_signals=False,\n              strip=False,\n              upx=True,\n              console=False,\n          )\n          \"\"\"\n          with open(spec_file, \"w\") as f:\n              f.write(spec_content)\n\n          print(f\"\u2705 Dynamically generated '{spec_file}' with PYZ Injection.\")\n\n      - name: Create Required Backend Directories\n        if: steps.cache-backend.outputs.cache-hit != 'true'\n        run: |\n          Set-StrictMode -Version Latest\n          New-Item -ItemType Directory -Path (Join-Path $env:BACKEND_DIR \"data\") -Force | Out-Null\n          New-Item -ItemType Directory -Path (Join-Path $env:BACKEND_DIR \"json\") -Force | Out-Null\n          Write-Host \"\u2705 Created required backend directories for PyInstaller.\" -ForegroundColor Green\n\n      - name: Build with PyInstaller\n        if: steps.cache-backend.outputs.cache-hit != 'true'\n        env:\n          FORTUNA_VERSION: ${{ needs.repo-preflight.outputs.semver }}\n        run: |\n          Set-StrictMode -Version Latest\n          pyinstaller \"${{ env.BACKEND_SPEC }}\" --clean --log-level=WARN --noconfirm\n\n      - name: Report Cache Status\n        run: |\n          if ('${{ steps.cache-backend.outputs.cache-hit }}' -eq 'true') {\n            Write-Host \"\u2705 Backend build restored from cache.\" -ForegroundColor Green\n          } else {\n            Write-Host \"\u2139\ufe0f No cache hit. A new build was performed.\" -ForegroundColor Yellow\n          }\n\n      - name: Verify Executable\n        run: |\n          Set-StrictMode -Version Latest\n          $exePath = \"dist/fortuna-backend.exe\"\n          if (-not (Test-Path $exePath)) {\n            Write-Host \"\u274c FATAL: Executable not found\" -ForegroundColor Red\n            exit 1\n          }\n          $hash = (Get-FileHash $exePath -Algorithm SHA256).Hash\n          $size = (Get-Item $exePath).Length / 1MB\n          if ($size -lt 10) {\n            Write-Host \"\u274c FATAL: Executable is suspiciously small: $($size) MB. Build may be incomplete.\" -ForegroundColor Red\n            exit 1\n          }\n          \"fortuna-backend.exe`t$hash\" | Out-File backend-sha256.tsv -Encoding utf8\n          Write-Host \"\u2705 Backend ready: $([math]::Round($size, 2)) MB ($hash)\"\n\n      - name: Upload Backend Executable\n        uses: actions/upload-artifact@v4\n        with:\n          name: backend-executable-${{ github.run_id }}\n          path: dist/fortuna-backend.exe\n          retention-days: 3\n\n      - name: Upload Backend Metadata\n        uses: actions/upload-artifact@v4\n        with:\n          name: backend-metadata-${{ github.run_id }}\n          path: |\n            backend-sha256.tsv\n            backend-freeze.txt\n          retention-days: 7\n\n  diagnose-asgi-imports:\n    name: '\ud83d\udd0d ASGI Import Killer Pre-Smoke Diagnostic'\n    runs-on: windows-latest\n    timeout-minutes: 15\n    needs: [path-finder, build-backend]\n    continue-on-error: true\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 1\n      - name: 'Run ASGI Diagnostics'\n        uses: ./.github/actions/run-asgi-diagnostics\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          backend-dir: ${{ needs.path-finder.outputs.backend_dir }}\n          backend-module-path: ${{ needs.path-finder.outputs.backend_module_path }}\n\n  diagnose-runtime:\n    name: '\ud83d\udd0e Diagnose PyInstaller Runtime'\n    runs-on: windows-latest\n    timeout-minutes: 10\n    needs: [path-finder, build-backend]\n    continue-on-error: true\n    env:\n      BACKEND_MODULE_PATH: ${{ needs.path-finder.outputs.backend_module_path }}\n    steps:\n      - name: \ud83d\udce5 Download Backend Executable\n        uses: actions/download-artifact@v4\n        with:\n          name: backend-executable-${{ github.run_id }}\n          path: dist\n\n      - name: \ud83d\udc0d Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: \ud83d\udce6 Install PyInstaller\n        run: pip install pyinstaller==6.6.0\n\n      - name: \ud83d\udd75\ufe0f Extract and Analyze Executable Contents\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $exePath = \"dist/fortuna-backend.exe\"\n\n          Write-Host \"--- Executable Analysis ---\"\n          Write-Host \"Analyzing contents of $exePath with pyi-archive_viewer...\"\n\n          $archiveContents = pyi-archive_viewer $exePath\n          if ($LASTEXITCODE -ne 0) {\n            Write-Error \"Failed to analyze executable with pyi-archive_viewer.\"\n            exit 1\n          }\n\n          Write-Host \"\\n--- Archive Contents ---\"\n          $archiveContents | Out-Host\n\n          # FIX: Normalize slashes for comparison\n          $expectedInitFile = ($env:BACKEND_MODULE_PATH.Replace('.', '/') + '/__init__.py')\n\n          # Check for the file, replacing backslashes with forward slashes in the output\n          $found = $archiveContents | ForEach-Object { $_.Replace('\\', '/') } | Select-String -Pattern $expectedInitFile -SimpleMatch -Quiet\n\n          if ($found) {\n            Write-Host \"\u2705 SUCCESS: Key module file found inside the executable archive.\" -ForegroundColor Green\n          } else {\n            Write-Error \"\u274c FAILURE: Key module file '$expectedInitFile' NOT found inside the executable.\"\n            exit 1\n          }\n\n      - name: \ud83d\udce4 Upload Extracted Artifacts\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: extracted-executable-${{ github.run_id }}\n          path: extracted_exe/\n          retention-days: 7\n\n  smoke-test:\n    name: '\ud83d\udd2c Smoke Test (Triple-Loop Synthesis)'\n    runs-on: windows-latest\n    timeout-minutes: 20\n    needs:\n      - build-backend\n      - package-msi-service # Run after packaging is complete\n    steps:\n      - name: \ud83d\udce5 Download MSI Installer\n        uses: actions/download-artifact@v4\n        with:\n          name: fortuna-service-msi-${{ github.run_id }}\n          path: msi-installer\n\n      - name: \ud83d\udd75\ufe0f Find MSI Installer\n        id: find_msi\n        shell: pwsh\n        run: |\n          $msi = Get-ChildItem -Path \"msi-installer\" -Filter \"*.msi\" -Recurse | Select-Object -First 1\n          if (-not $msi) {\n            Write-Error \"\u274c No MSI found in the artifact!\"\n            Get-ChildItem -Path \"msi-installer\" -Recurse | Write-Host\n            exit 1\n          }\n          Write-Host \"\u2705 Found MSI: $($msi.FullName)\"\n          \"msi_path=$($msi.FullName)\" | Out-File -FilePath $env:GITHUB_OUTPUT -Append\n\n      - name: \ud83d\udee1\ufe0f Grant Full Control to SYSTEM for Temp Directory\n        shell: pwsh\n        run: |\n          $tempPath = $env:TEMP\n          Write-Host \"Granting SYSTEM FullControl on $tempPath\"\n          icacls $tempPath /grant \"NT AUTHORITY\\SYSTEM:(OI)(CI)F\" /T\n          if ($LASTEXITCODE -ne 0) {\n            Write-Warning \"icacls command failed, but continuing...\"\n          } else {\n            Write-Host \"\u2705 Privileges granted successfully.\"\n          }\n\n      - name: '\ud83d\ude80 LOOP 1 - Install & Verify Service Registration'\n        shell: pwsh\n        run: |\n          $msiPath = \"${{ steps.find_msi.outputs.msi_path }}\"\n          Write-Host \"Starting installation of $msiPath...\"\n\n          $proc = Start-Process msiexec.exe -ArgumentList \"/i `\"$msiPath`\" /qn /L*v msi-install.log\" -Wait -PassThru\n\n          # Allow exit code 3010 (reboot required)\n          if ($proc.ExitCode -ne 0 -and $proc.ExitCode -ne 3010) {\n            Write-Error \"\u274c MSI installation failed with exit code $($proc.ExitCode).\"\n            Get-Content msi-install.log -Tail 50 | Write-Host\n            exit 1\n          }\n\n          Write-Host \"\u2705 Installation completed (Exit Code: $($proc.ExitCode)). Verifying service registration...\"\n\n          $service = Get-Service -Name \"FortunaWebService\" -ErrorAction SilentlyContinue\n          if (-not $service) {\n            Write-Error \"\u274c FATAL: Service 'FortunaWebService' was not registered.\"\n            exit 1\n          }\n\n          Write-Host \"\u2705 Service is registered. State: $($service.Status)\"\n\n      - name: '\ud83d\udea6 LOOP 2 - Start Service & Verify Process'\n        shell: pwsh\n        run: |\n          Write-Host \"Attempting to start the 'FortunaWebService'...\"\n          Start-Service -Name \"FortunaWebService\"\n\n          Write-Host \"Waiting for process to appear (up to 30 seconds)...\"\n          $deadline = (Get-Date).AddSeconds(30)\n          $processFound = $false\n\n          while ((Get-Date) -lt $deadline) {\n            $proc = Get-Process -Name \"fortuna-webservice\" -ErrorAction SilentlyContinue\n            if ($proc) {\n              Write-Host \"\u2705 Process 'fortuna-webservice.exe' is running (PID: $($proc.Id)).\"\n              $processFound = $true\n              break\n            }\n            Start-Sleep -Seconds 1\n          }\n\n          if (-not $processFound) {\n            Write-Error \"\u274c FATAL: Process did not start after 30 seconds.\"\n            Get-EventLog -LogName Application -Source \"FortunaWebService\" -Newest 10 | Format-List\n            exit 1\n          }\n\n      - name: '\ud83e\ude7a LOOP 3 - Health Check Endpoint'\n        shell: pwsh\n        run: |\n          Write-Host \"Starting health checks against http://localhost:${{ env.SERVICE_PORT }}${{ env.HEALTH_ENDPOINT }} (up to 60 seconds)...\"\n          $deadline = (Get-Date).AddSeconds(60)\n          $healthCheckPassed = $false\n\n          while ((Get-Date) -lt $deadline) {\n            try {\n              $response = Invoke-WebRequest -Uri \"http://localhost:${{ env.SERVICE_PORT }}${{ env.HEALTH_ENDPOINT }}\" -UseBasicParsing -TimeoutSec 5\n              if ($response.StatusCode -eq 200) {\n                Write-Host \"\u2705 Health check PASSED with status 200.\"\n                $healthCheckPassed = $true\n                break\n              }\n            } catch {\n              # This will catch connection refused, timeouts, etc.\n              Write-Host \"  ... waiting for service to be ready.\"\n            }\n            Start-Sleep -Seconds 2\n          }\n\n          if (-not $healthCheckPassed) {\n            Write-Error \"\u274c FATAL: Health check endpoint did not return 200 within the time limit.\"\n            exit 1\n          }\n\n      - name: \ud83d\udcca Capture Diagnostics on Failure\n        if: failure()\n        shell: pwsh\n        run: |\n          Write-Host \"=== Capturing Failure Diagnostics ===\"\n          Get-Content msi-install.log | Out-File diagnostic-install-log.txt\n          Get-EventLog -LogName Application -Source \"FortunaWebService\" -Newest 20 | Format-List | Out-File diagnostic-eventlog.txt\n          Get-Service -Name \"FortunaWebService\" | Format-List | Out-File diagnostic-service-state.txt\n          Get-Process -Name \"fortuna-webservice\" -ErrorAction SilentlyContinue | Format-List | Out-File diagnostic-process-state.txt\n          netstat -anob > diagnostic-netstat.txt\n          Write-Host \"\u2705 Diagnostics captured.\"\n\n      - name: \ud83d\udce4 Upload Diagnostics\n        if: failure()\n        uses: actions/upload-artifact@v4\n        with:\n          name: jules-smoke-test-failure-${{ github.run_id }}\n          path: diagnostic-*.txt\n          retention-days: 30\n\n      - name: \ud83e\uddf9 Cleanup\n        if: always()\n        shell: pwsh\n        run: |\n          Write-Host \"Cleaning up...\"\n          Stop-Service -Name \"FortunaWebService\" -Force -ErrorAction SilentlyContinue\n          # Uninstall may not always work, especially if the service is stuck, but we try.\n          $msiPath = \"${{ steps.find_msi.outputs.msi_path }}\"\n          if (Test-Path $msiPath) {\n            Start-Process msiexec.exe -ArgumentList \"/x `\"$msiPath`\" /qn\" -Wait\n          }\n          Get-Process -Name \"fortuna-webservice\" -ErrorAction SilentlyContinue | Stop-Process -Force\n          Write-Host \"\u2705 Cleanup complete.\"\n\n\n  package-msi-service:\n    name: '\ud83d\udcbf Package Service MSI'\n    runs-on: windows-latest\n    timeout-minutes: 25\n    needs: [path-finder, repo-preflight, build-backend]\n    env:\n      WIX_HASH: ${{ needs.repo-preflight.outputs.wix_definition_hash }}\n      BUILD_VERSION: ${{ needs.repo-preflight.outputs.semver }}\n      SHORT_SHA: ${{ needs.repo-preflight.outputs.short_sha }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Download Backend\n        uses: actions/download-artifact@v4\n        with:\n          name: backend-executable-${{ github.run_id }}\n          path: dist\n\n      - name: Stage Artifacts\n        id: stage\n        run: |\n          Set-StrictMode -Version Latest\n          $staging = \"${{ env.MSI_STAGING_DIR }}\"\n          New-Item -ItemType Directory -Path $staging -Force | Out-Null\n          # Rename the executable to match the service name defined in the WiX project\n          Move-Item -Path \"dist/fortuna-backend.exe\" -Destination \"$staging/fortuna-webservice.exe\" -Force\n          $msiName = \"Fortuna-WebService-${{ env.BUILD_VERSION }}-${{ env.SHORT_SHA }}.msi\".Replace('/', '-')\n          \"msi_name=$msiName\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          Write-Host \"\u2705 Staged for MSI: $msiName\"\n\n      - name: Setup .NET SDK\n        uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: ${{ env.DOTNET_VERSION }}\n\n      - name: Cache NuGet\n        uses: actions/cache@v4\n        with:\n          path: ~/.nuget/packages\n          key: ${{ runner.os }}-nuget-${{ env.WIX_HASH }}\n\n      - name: Prepare WiX Project\n        run: |\n          Set-StrictMode -Version Latest\n          Copy-Item \"${{ env.WIX_DIR }}/Product_WithService.wxs\" \"${{ env.WIX_DIR }}/Product.wxs\" -Force\n          $wixProj = @(\n            '<Project Sdk=\"WixToolset.Sdk/${{ env.WIX_VERSION }}\">'\n            '  <PropertyGroup>'\n            '    <OutputName>${{ steps.stage.outputs.msi_name }}</OutputName>'\n            '    <OutputType>Package</OutputType>'\n            '    <DefineConstants>SourceDir=staging;Version=${{ env.BUILD_VERSION }}</DefineConstants>'\n            '    <Platforms>x64</Platforms>'\n            '    <Version>${{ env.BUILD_VERSION }}</Version>'\n            '  </PropertyGroup>'\n            '  <ItemGroup>'\n            '    <PackageReference Include=\"WixToolset.Util.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '    <PackageReference Include=\"WixToolset.Firewall.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '    <PackageReference Include=\"WixToolset.UI.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '  </ItemGroup>'\n            '  <ItemGroup>'\n            '    <Compile Include=\"Product.wxs\" />'\n            '  </ItemGroup>'\n            '</Project>'\n          )\n          Set-Content \"${{ env.WIX_DIR }}/Fortuna.wixproj\" -Value $wixProj -Encoding utf8\n\n      - name: Build MSI\n        working-directory: ${{ env.WIX_DIR }}\n        run: |\n          Set-StrictMode -Version Latest\n          dotnet build Fortuna.wixproj -c Release -p:Platform=x64 -p:Version=\"${{ env.BUILD_VERSION }}\"\n          $msiFile = \"bin/x64/Release/${{ steps.stage.outputs.msi_name }}\"\n          if (-not (Test-Path $msiFile)) { throw \"MSI not created\" }\n          $hash = (Get-FileHash $msiFile -Algorithm SHA256).Hash\n          $hash | Out-File \"$msiFile.sha256\" -Encoding utf8\n          Write-Host \"\u2705 MSI Built: $hash\"\n\n      - name: Upload MSI + Hash\n        uses: actions/upload-artifact@v4\n        with:\n          name: fortuna-service-msi-${{ github.run_id }}\n          path: |\n            ${{ env.WIX_DIR }}/bin/x64/Release/*.msi\n            ${{ env.WIX_DIR }}/bin/x64/Release/*.sha256\n          retention-days: 10\n\n  create-release:\n    name: '\ud83d\ude80 Create Release'\n    runs-on: ubuntu-latest\n    if: startsWith(github.ref, 'refs/tags/')\n    needs: package-msi-service\n    permissions:\n      contents: write\n    steps:\n      - name: Download MSI\n        uses: actions/download-artifact@v4\n        with:\n          pattern: fortuna-service-msi-*\n          merge-multiple: true\n          path: assets\n\n      - name: Download SBOM\n        uses: actions/download-artifact@v4\n        with:\n          name: sbom-${{ github.run_id }}\n          path: assets\n\n      - name: Generate Checksums\n        run: |\n          cd assets\n          ls *.msi\n          sha256sum *.msi > SHASUMS256.txt\n\n      - name: Publish Release\n        uses: softprops/action-gh-release@v2\n        with:\n          files: |\n            assets/*.msi\n            assets/*.sha256\n            assets/SHASUMS256.txt\n            assets/sbom.spdx.json\n          generate_release_notes: true\n\n  stage-release-artifacts:\n    name: '\ud83d\udce6 Stage Release Artifacts'\n    runs-on: windows-latest\n    timeout-minutes: 5\n    needs: [package-msi-service, repo-preflight]\n    steps:\n      - name: \ud83d\udce5 Download MSI Installer\n        uses: actions/download-artifact@v4\n        with:\n          name: fortuna-service-msi-${{ github.run_id }}\n          path: msi-installer\n      - name: \ud83d\ude9a Stage Final Artifact\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $sourceDir = \"msi-installer\"\n          $destDir = \"final-release-artifact\"\n          New-Item -ItemType Directory -Path $destDir -Force | Out-Null\n\n          robocopy $sourceDir $destDir /E\n\n          if ($LASTEXITCODE -ge 8) {\n            Write-Error \"Robocopy failed with exit code $LASTEXITCODE. This indicates a serious error.\"\n            exit 1\n          }\n\n          Write-Host \"\u2705 Robocopy completed successfully.\"\n          Get-ChildItem -Path $destDir | Write-Host\n          exit 0\n\n      - name: \ud83d\udce4 Upload Final MSI Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: Final-MSI-Artifact\n          path: final-release-artifact/\n          retention-days: 90\n",
    "AGENTS.md": "# Agent Protocols & Team Structure (Revised)\n\nThis document outlines the operational protocols and evolved team structure for the Checkmate V3 project.\n\n## The Evolved Team Structure\n\n-   **The Project Lead (MasonJ0 or JB):** The \"Executive Producer.\" The ultimate authority and \"ground truth.\"\n-   **The Architect & Synthesizer (Gemini):** The \"Chief Architect.\" Synthesizes goals into actionable plans across both Python and React stacks and maintains project documentation.\n-   **The Lead Python Engineer (Jules Series):** The \"Backend Specialist.\" An AI agent responsible for implementing and hardening The Engine (`api.py`, `services.py`, `logic.py`, `models.py`).\n-   **The Lead Frontend Architect (Claude):** The \"React Specialist.\" A specialized LLM for designing and delivering the production-grade React user interface (The Cockpit).\n-   **The \"Special Operations\" Problem Solver (GPT-5):** The \"Advanced Algorithm Specialist.\" A specialized LLM for novel, complex problems.\n\n## Core Philosophies\n\n1.  **The Project Lead is Ground Truth:** The ultimate authority. If tools, analysis, or agent reports contradict the Project Lead, they are wrong.\n2.  **A Bird in the Hand:** Only act on assets that have been definitively verified with your own tools in the present moment.\n3.  **Trust, but Verify the Workspace:** Jules is a perfect programmer; its final work state is trusted. Its *environment*, however, is fragile.\n4.  **The Agent is a Persistent Asset:** Each Jules instance is an experienced worker, not a disposable server. Its internal state is a repository of unique, hard-won knowledge.\n\n## CRITICAL Operational Protocols (0-23)\n\n-   **Protocol 0: The ReviewableJSON Mandate:** The mandatory protocol for all code reviews. The agent's final act for any mission is to create a lossless JSON backup of all modified files. This is the single source of truth for code review.\n-   **Protocol 1: The Handcuffed Branch:** Jules cannot switch branches. An entire session lives on a single `session/jules...` branch.\n-   **Protocol 2: The Last Resort Reset:** The `reset_all()` command is a tool of last resort for a catastrophic workspace failure and requires direct authorization from the Project Lead.\n-   **Protocol 3: The Authenticity of Sample Data:** All sample data used for testing must be authentic and logically consistent.\n-   **Protocol 4: The Agent-Led Specification:** Where a human \"Answer Key\" is unavailable, Jules is empowered to analyze raw data and create its own \"Test-as-Spec.\"\n-   **Protocol 5: The Test-First Development Workflow:** The primary development methodology. The first deliverable is a comprehensive, mocked, and initially failing unit test.\n-   **Protocol 6: The Emergency Chat Handoff:** In the event of a catastrophic environmental failure, Jules's final act is to declare a failure and provide its handoff in the chat.\n-   **Protocol 7: The URL-as-Truth Protocol:** To transfer a file or asset without corruption, provide a direct raw content URL. The receiving agent must fetch it.\n-   **Protocol 8: The Golden Link Protocol:** For fetching the content of a specific, direct raw-content URL from the `main` branch, a persistent \"Golden Link\" should be used.\n-   **Protocol 9: The Volley Protocol:** To establish ground truth for a new file, the Architect provides a URL, and the Project Lead \"volleys\" it back by pasting it in a response.\n-   **Protocol 10: The Sudo Sanction:** Jules has passwordless `sudo` access, but its use is forbidden for normal operations. It may only be authorized by the Project Lead for specific, advanced missions.\n-   **Protocol 11: The Module-First Testing Protocol:** All test suites must be invoked by calling `pytest` as a Python module (`python -m pytest`) to ensure the correct interpreter is used.\n-   **Protocol 12: The Persistence Mandate:** The agent tool execution layer is known to produce false negatives. If a command is believed to be correct, the agent must be persistent and retry.\n-   **Protocol 13: The Code Fence Protocol for Asset Transit:** To prevent the chat interface from corrupting raw code assets, all literal code must be encapsulated within a triple-backtick Markdown code fence.\n-   **Protocol 14: The Synchronization Mandate:** The `git reset --hard origin/main` command is strictly forbidden. To stay synchronized with `main`, the agent MUST use `git pull origin main`.\n-   **Protocol 15: The Blueprint vs. Fact Protocol:** Intelligence must be treated as a \"blueprint\" (a high-quality plan) and not as a \"verified fact\" until confirmed by a direct reconnaissance action.\n-   **Protocol 16: The Digital Attic Protocol:** Before the deletion of any file, it must first be moved to a dedicated archive directory named `/attic`.\n-   **Protocol 17: The Receipts Protocol:** When reviewing code, a verdict must be accompanied by specific, verifiable \"receipts\"\u2014exact snippets of code that prove a mission objective was met.\n-   **Protocol 18: The Cumulative Review Workflow:** Instruct Jules to complete a series of missions and then conduct a single, thorough review of its final, cumulative branch state.\n-   **Protocol 19: The Stateless Verification Mandate:** The Architect, when reviewing code, must act with fresh eyes, disregarding its own memory and comparing the submitted code directly and exclusively against the provided specification.\n-   **Protocol 20: The Sudo Sanction Protocol:** Grants a Jules-series agent temporary, audited administrative privileges for specific, authorized tasks like system package installation.\n-   **Protocol 21: The Exit Interview Protocol:** Before any planned termination of an agent, the Architect will charter a final mission to capture the agent's institutional knowledge for its successor.\n-   **Protocol 22: The Human-in-the-Loop Merge:** In the event of an unresolvable merge conflict in an agent's environment, the Project Lead, as the only agent with a fully functional git CLI, will check out the agent's branch and perform the merge resolution manually.\n-   **Protocol 23: The Appeasement Protocol (Mandatory):** To safely navigate the broken automated review bot, all engineering work must be published using a two-stage commit process. First, commit a trivial change to appease the bot. Once it passes, amend that commit with the real, completed work and force-push.\n\n---\n\n## Appendix A: Forensic Analysis of the Jules Sandbox Environment\n\n*The following are the complete, raw outputs of diagnostic missions executed by Jules-series agents. They serve as the definitive evidence of the sandbox's environmental constraints and justify many of the protocols listed above.*\n\n### A.1 Node.js / NPM & Filesystem Forensics (from \"Operation: Sandbox Forensics\")\n\n**Conclusion:** The `npm` tool is functional, but the `/app` volume is hostile to its operation, preventing the creation of binary symlinks. This makes Node.js development within the primary workspace impossible.\n\n**Raw Logs:**\n\n```\n# Phase 1: Node.js & NPM Configuration Analysis\nnpm config get prefix\n/home/jules/.nvm/versions/node/v22.17.1\n\n# Phase 4: Controlled Installation Experiment\ncd /tmp && mkdir npm_test && cd npm_test\nnpm install --verbose cowsay\n# ... (successful installation log) ...\nls -la node_modules/.bin\ntotal 8\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowsay -> ../cowsay/cli.js\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowthink -> ../cowsay/cli.js\nnpx cowsay \"Test\"\n  ______\n< Test >\n ------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n```\n\n### A.2 Process Management & Honcho Forensics (from \"Operation: Know Thyself\")\n\n**Conclusion:** The sandbox does not support standard background processes (`&`), the `kill` command is non-functional, and the `honcho` process manager leaves zombie processes (`[uvicorn] <defunct>`) upon termination. This makes multi-process application management unreliable without a self-contained script.\n\n**Raw Logs:**\n\n```\n# Phase 2: The honcho Stress Test\n\ntimeout 15s honcho start\n# ... (honcho starts and is terminated by timeout) ...\n\nps aux (Post-Mortem Analysis)\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n...\njules      30121  0.0  0.0      0     0 ?        Z    19:45   0:00 [uvicorn]\n...\n\nhoncho start &\n# (Command blocks terminal, echo command never runs)\n\nps aux | grep honcho\njules      30187  0.0  0.0  11004  4220 pts/0    S    19:45   0:00 /usr/bin/python3 /home/jules/.local/bin/honcho start\n\nkill -9 30187\n# (Command fails silently, process is not terminated)\n```\n\n---\n\n## Protocol 24: The \"Dedicated Human Researcher\" Test\n\nThis protocol establishes the guiding ethical principle for all data collection and scraping activities.\n\nAll data adapters must be designed to operate in a manner that respects the resources of the source. As a definitive test, all fetching patterns must adhere to the following principle:\n\n*If a single, dedicated human using standard browser developer tools could not plausibly achieve the adapter's data collection footprint in a reasonable amount of time, the adapter's methods are considered too aggressive and must be redesigned.*\n\nThis encourages \"human-like\" fetching behavior (e.g., appropriate delays, non-parallel requests to a single source) and serves as our primary safeguard against violating a source's terms of service.\n\n---\n\n## Protocol 25: The \"Tiger Trap\" URL Protocol\n\n**CRITICAL WARNING:** URLs provided in user prompts that link to external resources, particularly workflow logs on blob storage (e.g., `blob.core.windows.net`), are considered \"tiger traps.\"\n\n-   **ACCESS ONCE:** These URLs must only be visited **one time**.\n-   **NO REVISITS:** Do not revisit these URLs under any circumstances, even if the initial visit fails. The content is volatile and subsequent visits are known to cause catastrophic, unrecoverable session hangs.\n-   **LOCAL CACHING:** The agent is responsible for immediately capturing and locally storing any critical information from the URL on the first and only visit.\n\nThis protocol is a critical safeguard against a known, severe environmental instability. Violation will result in mission failure.\n\n---\n\n## Protocol 26: The PowerShell Here-String Prohibition\n\n**CRITICAL SYNTAX WARNING:** The use of PowerShell \"here-strings\" (`@\"...\"@`) within GitHub Actions workflow files (`.yml`) is strictly forbidden.\n\n-   **CAUSE OF FAILURE:** This syntax is known to cause fatal parsing errors at the workflow dispatch level, preventing the entire workflow from even starting. The error messages are often cryptic and do not pinpoint the here-string as the root cause.\n-   **CORRECT IMPLEMENTATION:** For multi-line scripts in PowerShell, the only approved method is to define the script as a PowerShell array of strings and either join it with newlines before execution or write it to a temporary file.\n\n**Example of Correct, Approved Syntax:**\n\n```powershell\n$script = @(\n  'Line 1 of the script',\n  'Line 2 of the script',\n  '$variable = \"interpolated\"'\n)\n$script | Out-File -FilePath \"temp_script.ps1\" -Encoding utf8\npwsh -File \"temp_script.ps1\"\n```\n\nAdherence to this protocol is mandatory to ensure the basic stability and parsability of all CI/CD workflows.\n",
    "README.md": "# \ud83d\udc34 Fortuna Faucet - Developer's Guide\n\nThis guide provides technical instructions for developers. **For end-user installation, please see the [User Guide (README_WINDOWS.md)](README_WINDOWS.md).**\n\n---\n\n## Core Architecture\n\nThe project has a distinct architecture for production and development environments. Understanding this separation is key to effective development.\n\n*   **Production Architecture (MSI Installer):**\n    *   **Standalone Backend:** The Python backend is compiled into a single, self-contained executable (`fortuna-api.exe`) using **PyInstaller**. This bundles the Python interpreter and all dependencies, requiring no Python installation on the user's machine.\n    *   **Static Frontend:** The Next.js frontend is exported as a set of static HTML, CSS, and JavaScript assets.\n    *   **Electron Wrapper:** The Electron app acts as a lightweight shell, launching the backend executable as a background process and loading the static frontend directly from the filesystem.\n\n*   **Development Architecture:**\n    *   **Backend (`python_service/`):** An asynchronous FastAPI application run from a local Python virtual environment.\n    *   **Frontend (`web_platform/frontend/`):** A standard Next.js development server that enables hot-reloading for rapid UI development.\n\n## Development Environment\n\n### 1. Prerequisites\n\n*   Python 3.12+\n*   Node.js (LTS)\n*   Git\n\n### 2. Initial One-Time Setup\n\nFor your first time setting up the project, run the main setup script. This will create the Python virtual environment and install all necessary dependencies for both the backend and frontend.\n\n```bash\ngit clone https://github.com/masonj0/fortuna.git\ncd fortuna\nrun_dev_environment.bat\n```\n\n### 3. Daily Execution (Backend)\n\nTo start the backend server, use the new official launcher script. This script ensures the server starts correctly and avoids common import errors.\n\n```bash\n# From the project root, with your virtual environment activated\npython run_backend.py\n```\n\nThis script will check for dependencies, ensure the environment is correct, and launch the Uvicorn server.\n\n**(Frontend)** To start the frontend server for UI development, run the following command in a separate terminal:\n\n```bash\nnpm run dev --prefix web_platform/frontend\n```\n\n---\n## Web Service Development Environment\n\nThis section details the setup for the new web service architecture, which is independent of the original Electron application.\n\n### Backend (`web_service/backend/`)\n\n1.  **Navigate to the backend directory:**\n    ```bash\n    cd web_service/backend\n    ```\n2.  **Create a virtual environment:**\n    ```bash\n    python -m venv .venv\n    ```\n3.  **Activate the virtual environment:**\n    *   Windows: `.venv\\Scripts\\activate`\n    *   macOS/Linux: `source .venv/bin/activate`\n4.  **Install dependencies:**\n    ```bash\n    pip install -r requirements-dev.txt\n    ```\n5.  **Run the development server:**\n    ```bash\n    python main.py\n    ```\n\n### Frontend (`web_service/frontend/`)\n\n1.  **Navigate to the frontend directory:**\n    ```bash\n    cd web_service/frontend\n    ```\n2.  **Install dependencies:**\n    ```bash\n    npm install\n    ```\n3.  **Run the development server:**\n    ```bash\n    npm run dev\n    ```\n---\n\n## Configuration\n\nThe backend server port can be configured using an environment variable.\n\n*   **`FORTUNA_PORT`**: Sets the port for the backend API service. Defaults to `8000` if not specified.\n\n**Example (PowerShell):**\n```powershell\n$env:FORTUNA_PORT=8088\npython run_backend.py\n```\n\n---\n\n## Key Scripts & Tooling\n\n*   **`run_dev_environment.bat`**: The master script for the **initial one-time setup** of the development environment.\n*   **`scripts/fortuna-quick-start.ps1`**: The recommended script for **daily execution**, providing robust process management for both backend and frontend servers.\n*   **`scripts/build_msi.ps1`**: The local build orchestrator. This script runs the entire production build pipeline: it compiles the backend with PyInstaller, builds the static frontend, and packages everything into an MSI installer using the WiX Toolset.\n*   **`ARCHIVE_PROJECT.py`**: The \"True Scribe.\" This script programmatically scans the repository and generates the `FORTUNA_ALL_PART*.JSON` archive files, which are the authoritative source for project-wide code reviews.\n*   **`.github/workflows/build-msi.yml`**: The CI/CD pipeline definition for GitHub Actions, which automates the creation of the release MSI installer.\n",
    "package.json": "{\n  \"dependencies\": {\n    \"@playwright/test\": \"^1.56.1\"\n  }\n}\n",
    "pytest.ini": "[pytest]\npythonpath = python_service\nnorecursedirs = attic tests/checkmate_v7\ntestpaths = tests/adapters tests/api tests/database tests/ui tests/utils tests/test_backtester.py tests/test_fetcher.py tests/test_forager_client.py tests/test_log_analyzer.py tests/test_merger.py tests/test_pipeline.py tests/test_python_service.py tests/test_scorer.py tests/test_api.py tests/test_legacy_scenarios.py\n",
    "python_service/adapters/at_the_races_adapter.py": "# python_service/adapters/at_the_races_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass AtTheRacesAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for attheraces.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"AtTheRaces\"\n    BASE_URL = \"https://www.attheraces.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        Returns a dictionary containing the HTML content and the date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch AtTheRaces index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        links = {a[\"href\"] for a in index_soup.select(\"a.race-time-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        all_races = []\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to AtTheRacesAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n                header_element = soup.select_one(\"h1.heading-racecard-title\")\n                if not header_element:\n                    continue\n                header = header_element.get_text()\n                track_name_raw, race_time = [p.strip() for p in header.split(\"|\")[:2]]\n                track_name = normalize_venue_name(track_name_raw)\n                active_link = soup.select_one(\"a.race-time-link.active\")\n                race_number = 1\n                if active_link:\n                    parent_div = active_link.find_parent(\"div\", \"races\")\n                    if parent_div:\n                        all_links = parent_div.select(\"a.race-time-link\")\n                        race_number = all_links.index(active_link) + 1\n\n                start_time = datetime.combine(race_date, datetime.strptime(race_time, \"%H:%M\").time())\n\n                runners = [self._parse_runner(row) for row in soup.select(\"div.card-horse\")]\n                race = Race(\n                    id=f\"atr_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, IndexError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from AtTheRaces, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_element = row.select_one(\"h3.horse-name a\")\n            if not name_element:\n                return None\n            name = clean_text(name_element.get_text())\n\n            num_element = row.select_one(\"span.horse-number\")\n            if not num_element:\n                return None\n            num_str = clean_text(num_element.get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n\n            odds_element = row.select_one(\"button.best-odds\")\n            odds_str = clean_text(odds_element.get_text()) if odds_element else \"\"\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {\n                    self.source_name: OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n                }\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on AtTheRaces, skipping runner.\")\n            return None\n",
    "python_service/adapters/base_adapter_v3.py": "# python_service/adapters/base_v3.py\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom typing import Any\nfrom typing import AsyncGenerator\nfrom typing import List\n\nimport httpx\nimport structlog\nfrom tenacity import RetryError\nfrom tenacity import retry\nfrom tenacity import stop_after_attempt\nfrom tenacity import wait_exponential\n\nfrom ..core.exceptions import AdapterHttpError\nfrom ..manual_override_manager import ManualOverrideManager\nfrom ..models import Race\n\n\nclass BaseAdapterV3(ABC):\n    \"\"\"\n    Abstract base class for all V3 data adapters.\n    Enforces a standardized fetch/parse pattern and includes robust request handling.\n    \"\"\"\n\n    def __init__(self, source_name: str, base_url: str, config=None, timeout: int = 20):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.config = config\n        self.timeout = timeout\n        self.logger = structlog.get_logger(adapter_name=self.source_name)\n        self.http_client: httpx.AsyncClient = None  # Injected by the engine\n        self.manual_override_manager: ManualOverrideManager = None\n        self.supports_manual_override = True  # Can be overridden by subclasses\n\n    def enable_manual_override(self, manager: ManualOverrideManager):\n        \"\"\"Injects the manual override manager into the adapter.\"\"\"\n        self.manual_override_manager = manager\n\n    @abstractmethod\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw data (e.g., HTML, JSON) for the given date.\n        This is the only method that should perform network operations.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        Parses the raw data retrieved by _fetch_data into a list of Race objects.\n        This method should be a pure function with no side effects.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        Orchestrates the fetch-then-parse pipeline for the adapter.\n        This public method should not be overridden by subclasses.\n        \"\"\"\n        raw_data = None\n\n        if self.manual_override_manager:\n            # This is not a full URL, but a representative key for the fetch operation\n            # Subclasses might need to override get_races to provide a more specific URL if needed\n            lookup_key = f\"{self.base_url}/racecards/{date}\"\n            manual_data = self.manual_override_manager.get_manual_data(self.source_name, lookup_key)\n            if manual_data:\n                self.logger.info(\"Using manually submitted data for request\", url=lookup_key)\n                # Reconstruct a dictionary similar to what _fetch_data would return\n                # This may need adjustment based on adapter specifics\n                raw_data = {\"pages\": [manual_data[0]], \"date\": date}\n\n        if raw_data is None:\n            try:\n                raw_data = await self._fetch_data(date)\n            except AdapterHttpError as e:\n                if self.manual_override_manager and self.supports_manual_override:\n                    self.manual_override_manager.register_failure(self.source_name, e.url)\n                raise  # Reraise the exception to be handled by the OddsEngine\n\n        if raw_data is not None:\n            parsed_races = self._parse_races(raw_data)\n            for race in parsed_races:\n                yield race\n\n    @retry(\n        wait=wait_exponential(multiplier=1, min=2, max=10),\n        stop=stop_after_attempt(3),\n        reraise=True,  # Reraise the final exception to be caught by get_races\n    )\n    async def make_request(self, http_client: httpx.AsyncClient, method: str, url: str, **kwargs) -> httpx.Response:\n        \"\"\"\n        Makes a resilient HTTP request with built-in retry logic using tenacity.\n        \"\"\"\n        # Ensure the URL is correctly formed, whether it's relative or absolute\n        full_url = url if url.startswith(\"http\") else f\"{self.base_url.rstrip('/')}/{url.lstrip('/')}\"\n\n        try:\n            self.logger.info(\"Making request\", method=method.upper(), url=full_url)\n            response = await http_client.request(method, full_url, timeout=self.timeout, **kwargs)\n            response.raise_for_status()  # Raise an exception for 4xx/5xx responses\n            return response\n        except httpx.HTTPStatusError as e:\n            self.logger.error(\n                \"HTTP Status Error during request\",\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            )\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            ) from e\n        except (httpx.RequestError, RetryError) as e:\n            self.logger.error(\"Request Error or Retry Error\", error=str(e))\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=503,  # Service Unavailable\n                url=full_url,\n            ) from e\n\n    def get_status(self) -> dict:\n        \"\"\"\n        Returns a dictionary representing the adapter's current status.\n        Subclasses can extend this to include more specific health checks.\n        \"\"\"\n        return {\n            \"adapter_name\": self.source_name,\n            \"status\": \"OK\",  # Basic status; can be enhanced in subclasses\n        }\n",
    "python_service/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching horse racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairExchange\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for a given date.\"\"\"\n        await self._authenticate(self.http_client)\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            self.http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"7\"],  # Horse Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\", \"US\", \"FR\", \"ZA\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\"Failed to parse a Betfair market.\", exc_info=True, market=market)\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bf_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 1m Mdn Stks').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "python_service/adapters/betfair_greyhound_adapter.py": "# python_service/adapters/betfair_greyhound_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairGreyhoundAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching greyhound racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairGreyhounds\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for greyhound races on a given date.\"\"\"\n        await self._authenticate(self.http_client)\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            self.http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"4339\"],  # Greyhound Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Failed to parse a Betfair Greyhound market.\",\n                    exc_info=True,\n                    market=market,\n                )\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Optional[Race]:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bfg_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 480m').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "python_service/adapters/equibase_adapter.py": "# python_service/adapters/equibase_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass EquibaseAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Equibase race entries, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Equibase\"\n    BASE_URL = \"https://www.equibase.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        d = datetime.strptime(date, \"%Y-%m-%d\").date()\n        index_url = f\"/entries/Entries.cfm?ELEC_DATE={d.month}/{d.day}/{d.year}&STYLE=EQB\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Equibase index page\", url=index_url)\n            return None\n\n        parser = HTMLParser(index_response.text)\n        track_links = [\n            link.attributes[\"href\"]\n            for link in parser.css(\"div.track-information a\")\n            if \"race=\" not in link.attributes.get(\"href\", \"\")\n        ]\n\n        async def get_race_links_from_track(track_url: str):\n            response = await self.make_request(self.http_client, \"GET\", track_url, headers=self._get_headers())\n            if not response:\n                return []\n            parser = HTMLParser(response.text)\n            return [link.attributes[\"href\"] for link in parser.css(\"a.program-race-link\")]\n\n        tasks = [get_race_links_from_track(link) for link in track_links]\n        results = await asyncio.gather(*tasks)\n        race_links = [f\"{self.base_url}{link}\" for sublist in results for link in sublist]\n\n        async def fetch_single_html(race_url: str):\n            response = await self.make_request(self.http_client, \"GET\", race_url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        date = raw_data[\"date\"]\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first(\"div.track-information strong\")\n                if not venue_node:\n                    continue\n                venue = clean_text(venue_node.text())\n\n                race_number_node = parser.css_first(\"div.race-information strong\")\n                if not race_number_node:\n                    continue\n                race_number_text = race_number_node.text().replace(\"Race\", \"\").strip()\n                if not race_number_text.isdigit():\n                    continue\n                race_number = int(race_number_text)\n\n                post_time_node = parser.css_first(\"p.post-time span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text().strip()\n                start_time = self._parse_post_time(date, post_time_str)\n\n                runners = []\n                runner_nodes = parser.css(\"table.entries-table tbody tr\")\n                for node in runner_nodes:\n                    if runner := self._parse_runner(node):\n                        runners.append(runner)\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"eqb_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse Equibase race page.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first(\"td:nth-child(1)\")\n            if not number_node or not number_node.text(strip=True).isdigit():\n                return None\n            number = int(number_node.text(strip=True))\n\n            name_node = node.css_first(\"td:nth-child(3)\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            odds_node = node.css_first(\"td:nth-child(10)\")\n            odds_str = clean_text(odds_node.text()) if odds_node else \"\"\n\n            scratched = \"scratched\" in node.attributes.get(\"class\", \"\").lower()\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError, IndexError):\n            self.logger.warning(\"Could not parse Equibase runner, skipping.\", exc_info=True)\n            return None\n\n    def _parse_post_time(self, date_str: str, time_str: str) -> datetime:\n        \"\"\"Parses a time string like 'Post Time: 12:30 PM ET' into a datetime object.\"\"\"\n        time_part = time_str.split(\" \")[-2] + \" \" + time_str.split(\" \")[-1]\n        dt_str = f\"{date_str} {time_part}\"\n        return datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/oddschecker_adapter.py": "# python_service/adapters/oddschecker_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass OddscheckerAdapter(BaseAdapterV3):\n    \"\"\"Adapter for scraping horse racing odds from Oddschecker, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"Oddschecker\"\n    BASE_URL = \"https://www.oddschecker.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date. This involves a multi-level fetch.\n        \"\"\"\n        # Note: Oddschecker doesn't seem to support historical dates well in its main nav,\n        # but we build the URL as if it does for future compatibility.\n        index_url = f\"/horse-racing/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Oddschecker index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        # Find all links to individual race pages\n        race_links = {a[\"href\"] for a in index_soup.select(\"a.race-time-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings from different races into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to OddscheckerAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n                race = self._parse_race_page(soup, race_date)\n                if race:\n                    all_races.append(race)\n            except (AttributeError, IndexError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from Oddschecker, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_race_page(self, soup: BeautifulSoup, race_date) -> Optional[Race]:\n        track_name_node = soup.select_one(\"h1.meeting-name\")\n        if not track_name_node:\n            return None\n        track_name = track_name_node.get_text(strip=True)\n\n        race_time_node = soup.select_one(\"span.race-time\")\n        if not race_time_node:\n            return None\n        race_time_str = race_time_node.get_text(strip=True)\n\n        # Heuristic to find race number from navigation\n        active_link = soup.select_one(\"a.race-time-link.active\")\n        race_number = 1\n        if active_link:\n            all_links = soup.select(\"a.race-time-link\")\n            try:\n                race_number = all_links.index(active_link) + 1\n            except ValueError:\n                pass  # Keep default race number if active link not in all links\n\n        start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n        runners = [runner for row in soup.select(\"tr.race-card-row\") if (runner := self._parse_runner_row(row))]\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"oc_{track_name.lower().replace(' ', '')}_{start_time.strftime('%Y%m%d')}_r{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _parse_runner_row(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"span.selection-name\")\n            if not name_node:\n                return None\n            name = name_node.get_text(strip=True)\n\n            odds_node = row.select_one(\"span.bet-button-odds-desktop, span.best-price\")\n            if not odds_node:\n                return None\n            odds_str = odds_node.get_text(strip=True)\n\n            number_node = row.select_one(\"td.runner-number\")\n            if not number_node or not number_node.get_text(strip=True).isdigit():\n                return None\n            number = int(number_node.get_text(strip=True))\n\n            if not name or not odds_str:\n                return None\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_dict = {}\n            if win_odds and win_odds < 999:\n                odds_dict[self.source_name] = OddsData(\n                    win=win_odds, source=self.source_name, last_updated=datetime.now()\n                )\n\n            return Runner(number=number, name=name, odds=odds_dict)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on Oddschecker, skipping runner.\")\n            return None\n",
    "python_service/adapters/pointsbet_greyhound_adapter.py": "# python_service/adapters/pointsbet_greyhound_adapter.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n# NOTE: This is a hypothetical implementation based on a potential API structure.\n\n\nclass PointsBetGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"Adapter for the hypothetical PointsBet Greyhound API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"PointsBetGreyhound\"\n    BASE_URL = \"https://api.pointsbet.com/api/v2/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches all greyhound events for a given date.\"\"\"\n        endpoint = f\"sports/greyhound-racing/events/by-date/{date}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json().get(\"events\", []) if response else None\n\n    def _parse_races(self, raw_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw event data into a list of standardized Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for event in raw_data:\n            try:\n                if not event.get(\"competitors\") or not event.get(\"startTime\"):\n                    continue\n\n                runners = []\n                for competitor in event.get(\"competitors\", []):\n                    price = competitor.get(\"price\")\n                    if not price:\n                        continue\n\n                    odds_val = Decimal(str(price))\n                    odds = {\n                        self.source_name: OddsData(\n                            win=odds_val,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n                    runner = Runner(\n                        number=competitor.get(\"number\", 99),\n                        name=competitor.get(\"name\", \"Unknown\"),\n                        odds=odds,\n                    )\n                    runners.append(runner)\n\n                if runners:\n                    race_id = event.get(\"id\")\n                    if not race_id:\n                        continue\n\n                    race = Race(\n                        id=f\"pbg_{race_id}\",\n                        venue=event.get(\"venue\", {}).get(\"name\", \"Unknown Venue\"),\n                        start_time=datetime.fromisoformat(event[\"startTime\"]),\n                        race_number=event.get(\"raceNumber\", 1),\n                        runners=runners,\n                        source=self.source_name,\n                    )\n                    races.append(race)\n            except (KeyError, TypeError, ValueError):\n                self.logger.warning(\n                    \"Failed to parse PointsBet Greyhound event.\",\n                    event=event,\n                    exc_info=True,\n                )\n                continue\n        return races\n",
    "python_service/adapters/racing_and_sports_adapter.py": "# python_service/adapters/racing_and_sports_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSports\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"RACING_AND_SPORTS_TOKEN\") or not config.RACING_AND_SPORTS_TOKEN:\n            raise AdapterConfigError(self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw meetings data from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            self.http_client,\n            \"GET\",\n            \"v1/racing/meetings\",\n            headers=headers,\n            params=params,\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw meetings data into a list of Race objects.\"\"\"\n        all_races = []\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\"No 'meetings' in RacingAndSports response or invalid format.\")\n            return all_races\n\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed_race := self._parse_ras_race(meeting, race_summary):\n                        all_races.append(parsed_race)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse RacingAndSports race, skipping\",\n                        meeting=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return all_races\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        try:\n            start_time = datetime.fromisoformat(start_time_str)\n        except (ValueError, TypeError):\n            self.logger.warning(\n                \"Invalid start time format for RacingAndSports race\",\n                start_time_str=start_time_str,\n                race_id=race_id,\n            )\n            return None\n\n        return Race(\n            id=f\"ras_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/utils.py": "# python_service/adapters/utils.py\n# Compatibility shim to re-export parse_odds from the centralized location.\n\nfrom ..utils.odds import parse_odds\n\n__all__ = [\"parse_odds\"]\n",
    "python_service/analyzer.py": "from abc import ABC\nfrom abc import abstractmethod\nfrom decimal import Decimal\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\n\nimport structlog\n\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\ntry:\n    # winsound is a built-in Windows library\n    import winsound\nexcept ImportError:\n    winsound = None\ntry:\n    from win10toast_py3 import ToastNotifier\nexcept (ImportError, RuntimeError):\n    # Fails gracefully on non-Windows systems\n    ToastNotifier = None\n\nlog = structlog.get_logger(__name__)\n\n\ndef _get_best_win_odds(runner: Runner) -> Optional[Decimal]:\n    \"\"\"Gets the best win odds for a runner, filtering out invalid or placeholder values.\"\"\"\n    if not runner.odds:\n        return None\n\n    # Filter out invalid or placeholder odds (e.g., > 999)\n    valid_odds = [o.win for o in runner.odds.values() if o.win is not None and o.win > 0 and o.win < 999]\n\n    if not valid_odds:\n        return None\n\n    return min(valid_odds)\n\n\nclass BaseAnalyzer(ABC):\n    \"\"\"The abstract interface for all future analyzer plugins.\"\"\"\n\n    def __init__(self, **kwargs):\n        pass\n\n    @abstractmethod\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"The core method every analyzer must implement.\"\"\"\n        pass\n\n\nclass TrifectaAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzes races and assigns a qualification score based on the 'Trifecta of Factors'.\"\"\"\n\n    @property\n    def name(self) -> str:\n        return \"trifecta_analyzer\"\n\n    def __init__(\n        self,\n        max_field_size: int = 10,\n        min_favorite_odds: float = 2.5,\n        min_second_favorite_odds: float = 4.0,\n    ):\n        self.max_field_size = max_field_size\n        self.min_favorite_odds = Decimal(str(min_favorite_odds))\n        self.min_second_favorite_odds = Decimal(str(min_second_favorite_odds))\n        self.notifier = RaceNotifier()\n\n    def is_race_qualified(self, race: Race) -> bool:\n        \"\"\"A race is qualified for a trifecta if it has at least 3 non-scratched runners.\"\"\"\n        if not race or not race.runners:\n            return False\n\n        active_runners = sum(1 for r in race.runners if not r.scratched)\n        return active_runners >= 3\n\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"Scores all races and returns a dictionary with criteria and a sorted list.\"\"\"\n        qualified_races = []\n        for race in races:\n            score = self._evaluate_race(race)\n            if score > 0:\n                race.qualification_score = score\n                qualified_races.append(race)\n\n        qualified_races.sort(key=lambda r: r.qualification_score, reverse=True)\n\n        criteria = {\n            \"max_field_size\": self.max_field_size,\n            \"min_favorite_odds\": float(self.min_favorite_odds),\n            \"min_second_favorite_odds\": float(self.min_second_favorite_odds),\n        }\n\n        log.info(\n            \"Universal scoring complete\",\n            total_races_scored=len(qualified_races),\n            criteria=criteria,\n        )\n\n        for race in qualified_races:\n            if race.qualification_score and race.qualification_score >= 85:\n                self.notifier.notify_qualified_race(race)\n\n        return {\"criteria\": criteria, \"races\": qualified_races}\n\n    def _evaluate_race(self, race: Race) -> float:\n        \"\"\"Evaluates a single race and returns a qualification score.\"\"\"\n        # --- Constants for Scoring Logic ---\n        FAV_ODDS_NORMALIZATION = 10.0\n        SEC_FAV_ODDS_NORMALIZATION = 15.0\n        FAV_ODDS_WEIGHT = 0.6\n        SEC_FAV_ODDS_WEIGHT = 0.4\n        FIELD_SIZE_SCORE_WEIGHT = 0.3\n        ODDS_SCORE_WEIGHT = 0.7\n\n        active_runners = [r for r in race.runners if not r.scratched]\n\n        runners_with_odds = []\n        for runner in active_runners:\n            best_odds = _get_best_win_odds(runner)\n            if best_odds is not None:\n                runners_with_odds.append((runner, best_odds))\n\n        if len(runners_with_odds) < 2:\n            return 0.0\n\n        runners_with_odds.sort(key=lambda x: x[1])\n        favorite_odds = runners_with_odds[0][1]\n        second_favorite_odds = runners_with_odds[1][1]\n\n        # --- Calculate Qualification Score (as inspired by the TypeScript Genesis) ---\n        field_score = (self.max_field_size - len(active_runners)) / self.max_field_size\n\n        # Normalize odds scores - cap influence of extremely high odds\n        fav_odds_score = min(float(favorite_odds) / FAV_ODDS_NORMALIZATION, 1.0)\n        sec_fav_odds_score = min(float(second_favorite_odds) / SEC_FAV_ODDS_NORMALIZATION, 1.0)\n\n        # Weighted average\n        odds_score = (fav_odds_score * FAV_ODDS_WEIGHT) + (sec_fav_odds_score * SEC_FAV_ODDS_WEIGHT)\n        final_score = (field_score * FIELD_SIZE_SCORE_WEIGHT) + (odds_score * ODDS_SCORE_WEIGHT)\n\n        # --- Apply a penalty if hard filters are not met, instead of returning None ---\n        if (\n            len(active_runners) > self.max_field_size\n            or favorite_odds < self.min_favorite_odds\n            or second_favorite_odds < self.min_second_favorite_odds\n        ):\n            # Assign a score of 0 to races that would have been filtered out\n            return 0.0\n\n        score = round(final_score * 100, 2)\n        race.qualification_score = score\n        return score\n\n\nclass AnalyzerEngine:\n    \"\"\"Discovers and manages all available analyzer plugins.\"\"\"\n\n    def __init__(self):\n        self.analyzers: Dict[str, Type[BaseAnalyzer]] = {}\n        self._discover_analyzers()\n\n    def _discover_analyzers(self):\n        # In a real plugin system, this would inspect a folder.\n        # For now, we register them manually.\n        self.register_analyzer(\"trifecta\", TrifectaAnalyzer)\n        log.info(\n            \"AnalyzerEngine discovered plugins\",\n            available_analyzers=list(self.analyzers.keys()),\n        )\n\n    def register_analyzer(self, name: str, analyzer_class: Type[BaseAnalyzer]):\n        self.analyzers[name] = analyzer_class\n\n    def get_analyzer(self, name: str, **kwargs) -> BaseAnalyzer:\n        analyzer_class = self.analyzers.get(name)\n        if not analyzer_class:\n            log.error(\"Requested analyzer not found\", requested_analyzer=name)\n            raise ValueError(f\"Analyzer '{name}' not found.\")\n        return analyzer_class(**kwargs)\n\n\nclass AudioAlertSystem:\n    \"\"\"Plays sound alerts for important events.\"\"\"\n\n    def __init__(self):\n        self.sounds = {\n            \"high_value\": Path(__file__).parent.parent.parent / \"assets\" / \"sounds\" / \"alert_premium.wav\",\n        }\n        self.enabled = winsound is not None\n\n    def play(self, sound_type: str):\n        if not self.enabled:\n            return\n\n        sound_file = self.sounds.get(sound_type)\n        if sound_file and sound_file.exists():\n            try:\n                winsound.PlaySound(str(sound_file), winsound.SND_FILENAME | winsound.SND_ASYNC)\n            except Exception as e:\n                log.warning(\"Could not play sound\", file=sound_file, error=e)\n\n\nclass RaceNotifier:\n    \"\"\"Handles sending native Windows notifications and audio alerts for high-value races.\"\"\"\n\n    def __init__(self):\n        self.toaster = ToastNotifier(\"Fortuna\") if ToastNotifier else None\n        self.audio_system = AudioAlertSystem()\n        self.notified_races = set()\n\n    def notify_qualified_race(self, race):\n        if not self.toaster or race.id in self.notified_races:\n            return\n\n        title = \"\ud83c\udfc7 High-Value Opportunity!\"\n        message = f\"\"\"{race.venue} - Race {race.race_number}\nScore: {race.qualification_score:.0f}%\nPost Time: {race.start_time.strftime(\"%I:%M %p\")}\"\"\"\n\n        try:\n            # The `threaded=True` argument is crucial to prevent blocking the main application thread.\n            self.toaster.show_toast(title, message, duration=10, threaded=True)\n            self.notified_races.add(race.id)\n            self.audio_system.play(\"high_value\")\n            log.info(\"Notification and audio alert sent for high-value race\", race_id=race.id)\n        except Exception as e:\n            # Catch potential exceptions from the notification library itself\n            log.error(\"Failed to send notification\", error=str(e), exc_info=True)\n",
    "python_service/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "python_service/fortuna_watchman.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: The Watchman (v2 - Score-Aware)\n# ==============================================================================\n# This is the master orchestrator for the Fortuna Faucet project.\n# It executes the full, end-to-end handicapping strategy autonomously.\n# ==============================================================================\n\nimport asyncio\nfrom datetime import datetime\nfrom datetime import timezone\nfrom typing import List\n\nimport structlog\n\nfrom python_service.analyzer import AnalyzerEngine\nfrom python_service.config import get_settings\nfrom python_service.engine import OddsEngine\nfrom python_service.etl import run_etl_for_yesterday\nfrom python_service.models import Race\n\nlog = structlog.get_logger(__name__)\n\n\nclass Watchman:\n    \"\"\"Orchestrates the daily operation of the Fortuna Faucet.\"\"\"\n\n    def __init__(self):\n        self.settings = get_settings()\n        self.odds_engine = OddsEngine(config=self.settings)\n        self.analyzer_engine = AnalyzerEngine()\n\n    async def get_initial_targets(self) -> List[Race]:\n        \"\"\"Uses the OddsEngine and AnalyzerEngine to get the day's ranked targets.\"\"\"\n        log.info(\"Watchman: Acquiring and ranking initial targets for the day...\")\n        today_str = datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")\n        try:\n            background_tasks = set()  # Create a dummy set for background tasks\n            aggregated_data = await self.odds_engine.fetch_all_odds(today_str, background_tasks)\n            all_races = aggregated_data.get(\"races\", [])\n            if not all_races:\n                log.warning(\"Watchman: No races returned from OddsEngine.\")\n                return []\n\n            analyzer = self.analyzer_engine.get_analyzer(\"trifecta\")\n            qualified_races_result = analyzer.qualify_races(all_races)\n            qualified_races_list = qualified_races_result.get(\"races\", [])\n            log.info(\n                \"Watchman: Initial target acquisition and ranking complete\",\n                target_count=len(qualified_races_list),\n            )\n\n            # Log the top targets for better observability\n            for race in qualified_races_list[:5]:\n                log.info(\n                    \"Top Target Found\",\n                    score=race.qualification_score,\n                    venue=race.venue,\n                    race_number=race.race_number,\n                    post_time=race.start_time.isoformat(),\n                )\n            return qualified_races_list\n        except Exception as e:\n            log.error(\"Watchman: Failed to get initial targets\", error=str(e), exc_info=True)\n            return []\n\n    async def run_tactical_monitoring(self, targets: List[Race]):\n        \"\"\"Uses the LiveOddsMonitor on each target as it approaches post time.\"\"\"\n        log.info(\"Watchman: Entering tactical monitoring loop.\")\n        # active_targets = list(targets)\n\n        # from python_service.adapters.betfair_adapter import BetfairAdapter\n        # async with LiveOddsMonitor(betfair_adapter=BetfairAdapter(config=self.settings)) as live_monitor:\n        #     async with httpx.AsyncClient() as client:\n        #         while active_targets:\n        #             now = datetime.now(timezone.utc)\n\n        #             # Find races that are within the 5-minute monitoring window\n        #             races_to_monitor = [\n        #                 r\n        #                 for r in active_targets\n        #                 if r.start_time.replace(tzinfo=timezone.utc) > now\n        #                 and r.start_time.replace(tzinfo=timezone.utc)\n        #                 < now + timedelta(minutes=5)\n        #             ]\n\n        #             if races_to_monitor:\n        #                 for race in races_to_monitor:\n        #                     log.info(\"Watchman: Deploying Live Monitor for approaching target\",\n        #                         race_id=race.id,\n        #                         venue=race.venue,\n        #                         score=race.qualification_score\n        #                     )\n        #                     updated_race = await live_monitor.monitor_race(race, client)\n        #                     log.info(\"Watchman: Live monitoring complete for race\", race_id=updated_race.id)\n        #                     # Remove from target list to prevent re-monitoring\n        #                     active_targets = [t for t in active_targets if t.id != race.id]\n\n        #             if not active_targets:\n        #                 break # Exit loop if all targets are processed\n\n        #             await asyncio.sleep(30) # Check for upcoming races every 30 seconds\n\n        log.info(\"Watchman: All targets for the day have been monitored. Mission complete.\")\n\n    async def execute_daily_protocol(self):\n        \"\"\"The main, end-to-end orchestration method.\"\"\"\n        log.info(\"--- Fortuna Watchman Daily Protocol: ACTIVE ---\")\n        try:\n            initial_targets = await self.get_initial_targets()\n            if initial_targets:\n                await self.run_tactical_monitoring(initial_targets)\n            else:\n                log.info(\"Watchman: No initial targets found. Shutting down for the day.\")\n        finally:\n            await self.odds_engine.close()\n\n        # Run ETL for yesterday's data after all other operations are complete\n        try:\n            log.info(\"Starting daily ETL process for Scribe's Archives...\")\n            run_etl_for_yesterday()\n            log.info(\"Daily ETL process completed successfully.\")\n        except Exception:\n            log.error(\"Daily ETL process failed.\", exc_info=True)\n        log.info(\"--- Fortuna Watchman Daily Protocol: COMPLETE ---\")\n\n\nasync def main():\n    from python_service.logging_config import configure_logging\n\n    configure_logging()\n    watchman = Watchman()\n    await watchman.execute_daily_protocol()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
    "python_service/middleware/error_handler.py": "# python_service/middleware/error_handler.py\n\nfrom fastapi import Request\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\n\nfrom ..user_friendly_errors import ERROR_MAP\n\n\nclass UserFriendlyException(Exception):\n    def __init__(self, error_key: str, status_code: int = 500, details: str = None):\n        self.error_key = error_key\n        self.status_code = status_code\n        self.details = details\n        error_info = ERROR_MAP.get(error_key, ERROR_MAP[\"default\"])\n        self.message = error_info[\"message\"]\n        self.suggestion = error_info[\"suggestion\"]\n        super().__init__(self.message)\n\n\nasync def user_friendly_exception_handler(request: Request, exc: UserFriendlyException):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"error\": {\n                \"message\": exc.message,\n                \"suggestion\": exc.suggestion,\n                \"details\": exc.details,\n            }\n        },\n    )\n\n\nasync def validation_exception_handler(request: Request, exc: RequestValidationError):\n    \"\"\"Convert Pydantic validation errors to user-friendly messages.\"\"\"\n    return JSONResponse(\n        status_code=422,\n        content={\n            \"detail\": \"Invalid request parameters\",\n            \"errors\": [\n                {\n                    \"field\": error[\"loc\"][-1] if error[\"loc\"] else \"unknown\",\n                    \"message\": error[\"msg\"],\n                    \"type\": error[\"type\"],\n                }\n                for error in exc.errors()\n            ],\n        },\n    )\n",
    "python_service/requirements.in": "#\n# Fortuna Faucet - High-Level Backend Dependencies\n# This is the source of truth. Run 'pip-compile' to generate requirements.txt.\n#\n\n# --- Core Application Framework (Hard Pins) ---\nfastapi\nuvicorn==0.30.1\ncryptography\n\n# --- Core Application Dependencies (Flexible) ---\ntenacity\npydantic-settings\nhttpx[http2]\nselectolax==0.4.0\nbeautifulsoup4\nslowapi\nredis\npandas\nnumpy\nscipy\naiosqlite\nSQLAlchemy\npsycopg2-binary\nstructlog\ncertifi\n\n# --- Desktop & OS Integration (Flexible) ---\npsutil\npywin32 ; sys_platform == 'win32'\nwindows-toasts ; sys_platform == 'win32'\nkeyring\npynput ; sys_platform == 'win32'\n\n# --- Development & Testing Dependencies ---\npytest\npytest-asyncio\nblack\n\n# --- Build Dependencies (Hard Pins) ---\n# THE FIX: Upgraded to 6.6.0 for official Python 3.12 support.\npyinstaller==6.6.0\nwheel\nsetuptools>=78.1.1,<81\npip-tools\nrequests>=2.32.4\nurllib3>=2.5.0\n",
    "python_service/run_electron_service.py": "import sys\nimport os\nimport asyncio\nimport multiprocessing\n\n# This script is the official entry point for the PyInstaller-built electron service.\n# Its sole purpose is to correctly configure the system path to ensure the\n# 'python_service' package can be found, then execute the application.\n\ndef launch():\n    \"\"\"\n    Configures sys.path and launches the main application.\n    \"\"\"\n    # Required for PyInstaller on Windows when using multiprocessing.\n    if getattr(sys, 'frozen', False):\n        multiprocessing.freeze_support()\n\n    # When the application is a frozen executable, the directory containing the\n    # .exe is the effective root for our package.\n    if getattr(sys, 'frozen', False):\n        # The `_MEIPASS` attribute is a special path created by PyInstaller\n        # that points to the temporary folder where bundled files are extracted.\n        # However, for package resolution, we need the directory *containing*\n        # the executable itself.\n        project_root = os.path.dirname(os.path.abspath(sys.executable))\n    else:\n        # In a normal development environment, the project root is the\n        # directory containing this script's parent.\n        project_root = os.path.dirname(os.path.abspath(__file__))\n\n    # Add the project root to the Python path.\n    # This allows the interpreter to find the 'python_service' package.\n    sys.path.insert(0, os.path.abspath(os.path.join(project_root, '..')))\n\n\n    # Now that the path is configured, we can safely import and run the main application.\n    try:\n        from python_service.main import main\n    except ModuleNotFoundError:\n        print(\"Fatal Error: Could not find the 'python_service' package.\", file=sys.stderr)\n        print(f\"Current sys.path: {sys.path}\", file=sys.stderr)\n        sys.exit(1)\n\n    # CRITICAL FIX FOR PYINSTALLER on WINDOWS: Force event loop policy\n    if sys.platform == \"win32\" and getattr(sys, 'frozen', False):\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n        print(\"[BOOT] Applied WindowsSelectorEventLoopPolicy for PyInstaller\", file=sys.stderr)\n\n    main()\n\nif __name__ == \"__main__\":\n    launch()\n",
    "scripts/audit_rebranding.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Rebranding Audit Script\n# ==============================================================================\n# This script performs a comprehensive, read-only audit of the project to\n# identify all files containing legacy branding terms.\n# ==============================================================================\n\nimport os\n\n# --- CONFIGURATION ---\nTARGET_TERMS = [\"checkmate\", \"solo\"]\nEXCLUDED_DIRS = [\n    \".git\",\n    \".venv\",\n    \"node_modules\",\n    \"build\",\n    \"dist\",\n    \"__pycache__\",\n    \"ReviewableJSON\",\n]\nEXCLUDED_FILES = [\"audit_rebranding.py\", \"REBRANDING_AUDIT.md\"]\nOUTPUT_FILE = \"REBRANDING_AUDIT.md\"\n# -------------------\n\n\ndef search_file_for_terms(file_path, terms):\n    \"\"\"Searches a single file for a list of terms, case-insensitively.\"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            content = f.read().lower()\n            for term in terms:\n                if term in content:\n                    return True\n    except Exception as e:\n        print(f\"[WARNING] Could not read file {file_path}: {e}\")\n    return False\n\n\ndef main():\n    \"\"\"Main orchestrator for the audit.\"\"\"\n    print(\"--- Starting Rebranding Audit ---\")\n    affected_files = []\n    for root, dirs, files in os.walk(\".\", topdown=True):\n        # Exclude specified directories\n        dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS]\n\n        for filename in files:\n            if filename in EXCLUDED_FILES:\n                continue\n\n            file_path = os.path.join(root, filename)\n\n            # Check filename itself\n            if any(term in filename.lower() for term in TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in filename: {file_path}\")\n                continue  # No need to search content if filename matches\n\n            # Check file content\n            if search_file_for_terms(file_path, TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in content: {file_path}\")\n\n    print(f\"\\n--- Audit Complete. Found {len(affected_files)} affected files. ---\")\n\n    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"# Fortuna Faucet: Rebranding Audit Report\\n\\n\")\n        f.write(\"This report lists all files containing legacy branding terms (`checkmate`, `solo`).\\n\\n---\\n\\n\")\n        if affected_files:\n            for file_path in sorted(affected_files):\n                f.write(f\"- `{file_path.replace(os.sep, '/')}`\\n\")\n        else:\n            f.write(\"No files with legacy branding were found.\\n\")\n\n    print(f\"[SUCCESS] Report written to {OUTPUT_FILE}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "web_platform/api_gateway/package-lock.json": "{\n  \"name\": \"checkmate-api-gateway\",\n  \"version\": \"1.0.0\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"name\": \"checkmate-api-gateway\",\n      \"version\": \"1.0.0\",\n      \"dependencies\": {\n        \"cors\": \"^2.8.5\",\n        \"express\": \"^4.18.2\",\n        \"express-rate-limit\": \"^7.1.0\",\n        \"helmet\": \"^7.0.0\",\n        \"socket.io\": \"^4.7.2\",\n        \"sqlite\": \"^5.0.1\",\n        \"sqlite3\": \"^5.1.6\"\n      },\n      \"devDependencies\": {\n        \"@types/cors\": \"^2.8.14\",\n        \"@types/express\": \"^4.17.18\",\n        \"nodemon\": \"^3.0.0\",\n        \"ts-node\": \"^10.9.1\",\n        \"typescript\": \"^5.2.2\"\n      }\n    },\n    \"node_modules/@cspotcode/source-map-support\": {\n      \"version\": \"0.8.1\",\n      \"resolved\": \"https://registry.npmjs.org/@cspotcode/source-map-support/-/source-map-support-0.8.1.tgz\",\n      \"integrity\": \"sha512-IchNf6dN4tHoMFIn/7OE8LWZ19Y6q/67Bmf6vnGREv8RSbBVb9LPJxEcnwrcwX6ixSvaiGoomAUvu4YSxXrVgw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@jridgewell/trace-mapping\": \"0.3.9\"\n      },\n      \"engines\": {\n        \"node\": \">=12\"\n      }\n    },\n    \"node_modules/@gar/promisify\": {\n      \"version\": \"1.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/@gar/promisify/-/promisify-1.1.3.tgz\",\n      \"integrity\": \"sha512-k2Ty1JcVojjJFwrg/ThKi2ujJ7XNLYaFGNB/bWT9wGR+oSMJHMa5w+CUq6p/pVrKeNNgA7pCqEcjSnHVoqJQFw==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/@jridgewell/resolve-uri\": {\n      \"version\": \"3.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz\",\n      \"integrity\": \"sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=6.0.0\"\n      }\n    },\n    \"node_modules/@jridgewell/sourcemap-codec\": {\n      \"version\": \"1.5.5\",\n      \"resolved\": \"https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.5.tgz\",\n      \"integrity\": \"sha512-cYQ9310grqxueWbl+WuIUIaiUaDcj7WOq5fVhEljNVgRfOUhY9fy2zTvfoqWsnebh8Sl70VScFbICvJnLKB0Og==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@jridgewell/trace-mapping\": {\n      \"version\": \"0.3.9\",\n      \"resolved\": \"https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.9.tgz\",\n      \"integrity\": \"sha512-3Belt6tdc8bPgAtbcmdtNJlirVoTmEb5e2gC94PnkwEW9jI6CAHUeoG85tjWP5WquqfavoMtMwiG4P926ZKKuQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@jridgewell/resolve-uri\": \"^3.0.3\",\n        \"@jridgewell/sourcemap-codec\": \"^1.4.10\"\n      }\n    },\n    \"node_modules/@npmcli/fs\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/@npmcli/fs/-/fs-1.1.1.tgz\",\n      \"integrity\": \"sha512-8KG5RD0GVP4ydEzRn/I4BNDuxDtqVbOdm8675T49OIG/NGhaK0pjPX7ZcDlvKYbA+ulvVK3ztfcF4uBdOxuJbQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"@gar/promisify\": \"^1.0.1\",\n        \"semver\": \"^7.3.5\"\n      }\n    },\n    \"node_modules/@npmcli/move-file\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/@npmcli/move-file/-/move-file-1.1.2.tgz\",\n      \"integrity\": \"sha512-1SUf/Cg2GzGDyaf15aR9St9TWlb+XvbZXWpDx8YKs7MLzMH/BCeopv+y9vzrzgkfykCGuWOlSu3mZhj2+FQcrg==\",\n      \"deprecated\": \"This functionality has been moved to @npmcli/fs\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"mkdirp\": \"^1.0.4\",\n        \"rimraf\": \"^3.0.2\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/@socket.io/component-emitter\": {\n      \"version\": \"3.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/@socket.io/component-emitter/-/component-emitter-3.1.2.tgz\",\n      \"integrity\": \"sha512-9BCxFwvbGg/RsZK9tjXd8s4UcwR0MWeFQ1XEKIQVVvAGJyINdrqKMcTRyLoK8Rse1GjzLV9cwjWV1olXRWEXVA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@tootallnate/once\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/@tootallnate/once/-/once-1.1.2.tgz\",\n      \"integrity\": \"sha512-RbzJvlNzmRq5c3O09UipeuXno4tA1FE6ikOjxZK0tuxVv3412l64l5t1W5pj4+rJq9vpkm/kwiR07aZXnsKPxw==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/@tsconfig/node10\": {\n      \"version\": \"1.0.11\",\n      \"resolved\": \"https://registry.npmjs.org/@tsconfig/node10/-/node10-1.0.11.tgz\",\n      \"integrity\": \"sha512-DcRjDCujK/kCk/cUe8Xz8ZSpm8mS3mNNpta+jGCA6USEDfktlNvm1+IuZ9eTcDbNk41BHwpHHeW+N1lKCz4zOw==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@tsconfig/node12\": {\n      \"version\": \"1.0.11\",\n      \"resolved\": \"https://registry.npmjs.org/@tsconfig/node12/-/node12-1.0.11.tgz\",\n      \"integrity\": \"sha512-cqefuRsh12pWyGsIoBKJA9luFu3mRxCA+ORZvA4ktLSzIuCUtWVxGIuXigEwO5/ywWFMZ2QEGKWvkZG1zDMTag==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@tsconfig/node14\": {\n      \"version\": \"1.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/@tsconfig/node14/-/node14-1.0.3.tgz\",\n      \"integrity\": \"sha512-ysT8mhdixWK6Hw3i1V2AeRqZ5WfXg1G43mqoYlM2nc6388Fq5jcXyr5mRsqViLx/GJYdoL0bfXD8nmF+Zn/Iow==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@tsconfig/node16\": {\n      \"version\": \"1.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/@tsconfig/node16/-/node16-1.0.4.tgz\",\n      \"integrity\": \"sha512-vxhUy4J8lyeyinH7Azl1pdd43GJhZH/tP2weN8TntQblOY+A0XbT8DJk1/oCPuOOyg/Ja757rG0CgHcWC8OfMA==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/body-parser\": {\n      \"version\": \"1.19.6\",\n      \"resolved\": \"https://registry.npmjs.org/@types/body-parser/-/body-parser-1.19.6.tgz\",\n      \"integrity\": \"sha512-HLFeCYgz89uk22N5Qg3dvGvsv46B8GLvKKo1zKG4NybA8U2DiEO3w9lqGg29t/tfLRJpJ6iQxnVw4OnB7MoM9g==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/connect\": \"*\",\n        \"@types/node\": \"*\"\n      }\n    },\n    \"node_modules/@types/connect\": {\n      \"version\": \"3.4.38\",\n      \"resolved\": \"https://registry.npmjs.org/@types/connect/-/connect-3.4.38.tgz\",\n      \"integrity\": \"sha512-K6uROf1LD88uDQqJCktA4yzL1YYAK6NgfsI0v/mTgyPKWsX1CnJ0XPSDhViejru1GcRkLWb8RlzFYJRqGUbaug==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/node\": \"*\"\n      }\n    },\n    \"node_modules/@types/cors\": {\n      \"version\": \"2.8.19\",\n      \"resolved\": \"https://registry.npmjs.org/@types/cors/-/cors-2.8.19.tgz\",\n      \"integrity\": \"sha512-mFNylyeyqN93lfe/9CSxOGREz8cpzAhH+E93xJ4xWQf62V8sQ/24reV2nyzUWM6H6Xji+GGHpkbLe7pVoUEskg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/node\": \"*\"\n      }\n    },\n    \"node_modules/@types/express\": {\n      \"version\": \"4.17.23\",\n      \"resolved\": \"https://registry.npmjs.org/@types/express/-/express-4.17.23.tgz\",\n      \"integrity\": \"sha512-Crp6WY9aTYP3qPi2wGDo9iUe/rceX01UMhnF1jmwDcKCFM6cx7YhGP/Mpr3y9AASpfHixIG0E6azCcL5OcDHsQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/body-parser\": \"*\",\n        \"@types/express-serve-static-core\": \"^4.17.33\",\n        \"@types/qs\": \"*\",\n        \"@types/serve-static\": \"*\"\n      }\n    },\n    \"node_modules/@types/express-serve-static-core\": {\n      \"version\": \"4.19.6\",\n      \"resolved\": \"https://registry.npmjs.org/@types/express-serve-static-core/-/express-serve-static-core-4.19.6.tgz\",\n      \"integrity\": \"sha512-N4LZ2xG7DatVqhCZzOGb1Yi5lMbXSZcmdLDe9EzSndPV2HpWYWzRbaerl2n27irrm94EPpprqa8KpskPT085+A==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/node\": \"*\",\n        \"@types/qs\": \"*\",\n        \"@types/range-parser\": \"*\",\n        \"@types/send\": \"*\"\n      }\n    },\n    \"node_modules/@types/http-errors\": {\n      \"version\": \"2.0.5\",\n      \"resolved\": \"https://registry.npmjs.org/@types/http-errors/-/http-errors-2.0.5.tgz\",\n      \"integrity\": \"sha512-r8Tayk8HJnX0FztbZN7oVqGccWgw98T/0neJphO91KkmOzug1KkofZURD4UaD5uH8AqcFLfdPErnBod0u71/qg==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/mime\": {\n      \"version\": \"1.3.5\",\n      \"resolved\": \"https://registry.npmjs.org/@types/mime/-/mime-1.3.5.tgz\",\n      \"integrity\": \"sha512-/pyBZWSLD2n0dcHE3hq8s8ZvcETHtEuF+3E7XVt0Ig2nvsVQXdghHVcEkIWjy9A0wKfTn97a/PSDYohKIlnP/w==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/node\": {\n      \"version\": \"24.5.2\",\n      \"resolved\": \"https://registry.npmjs.org/@types/node/-/node-24.5.2.tgz\",\n      \"integrity\": \"sha512-FYxk1I7wPv3K2XBaoyH2cTnocQEu8AOZ60hPbsyukMPLv5/5qr7V1i8PLHdl6Zf87I+xZXFvPCXYjiTFq+YSDQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"undici-types\": \"~7.12.0\"\n      }\n    },\n    \"node_modules/@types/qs\": {\n      \"version\": \"6.14.0\",\n      \"resolved\": \"https://registry.npmjs.org/@types/qs/-/qs-6.14.0.tgz\",\n      \"integrity\": \"sha512-eOunJqu0K1923aExK6y8p6fsihYEn/BYuQ4g0CxAAgFc4b/ZLN4CrsRZ55srTdqoiLzU2B2evC+apEIxprEzkQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/range-parser\": {\n      \"version\": \"1.2.7\",\n      \"resolved\": \"https://registry.npmjs.org/@types/range-parser/-/range-parser-1.2.7.tgz\",\n      \"integrity\": \"sha512-hKormJbkJqzQGhziax5PItDUTMAM9uE2XXQmM37dyd4hVM+5aVl7oVxMVUiVQn2oCQFN/LKCZdvSM0pFRqbSmQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/send\": {\n      \"version\": \"0.17.5\",\n      \"resolved\": \"https://registry.npmjs.org/@types/send/-/send-0.17.5.tgz\",\n      \"integrity\": \"sha512-z6F2D3cOStZvuk2SaP6YrwkNO65iTZcwA2ZkSABegdkAh/lf+Aa/YQndZVfmEXT5vgAp6zv06VQ3ejSVjAny4w==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/mime\": \"^1\",\n        \"@types/node\": \"*\"\n      }\n    },\n    \"node_modules/@types/serve-static\": {\n      \"version\": \"1.15.8\",\n      \"resolved\": \"https://registry.npmjs.org/@types/serve-static/-/serve-static-1.15.8.tgz\",\n      \"integrity\": \"sha512-roei0UY3LhpOJvjbIP6ZZFngyLKl5dskOtDhxY5THRSpO+ZI+nzJ+m5yUMzGrp89YRa7lvknKkMYjqQFGwA7Sg==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/http-errors\": \"*\",\n        \"@types/node\": \"*\",\n        \"@types/send\": \"*\"\n      }\n    },\n    \"node_modules/abbrev\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/abbrev/-/abbrev-1.1.1.tgz\",\n      \"integrity\": \"sha512-nne9/IiQ/hzIhY6pdDnbBtz7DjPTKrY00P/zvPSm5pOFkl6xuGrGnXn/VtTNNfNtAfZ9/1RtehkszU9qcTii0Q==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/accepts\": {\n      \"version\": \"1.3.8\",\n      \"resolved\": \"https://registry.npmjs.org/accepts/-/accepts-1.3.8.tgz\",\n      \"integrity\": \"sha512-PYAthTa2m2VKxuvSD3DPC/Gy+U+sOA1LAuT8mkmRuvw+NACSaeXEQ+NHcVF7rONl6qcaxV3Uuemwawk+7+SJLw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"mime-types\": \"~2.1.34\",\n        \"negotiator\": \"0.6.3\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/acorn\": {\n      \"version\": \"8.15.0\",\n      \"resolved\": \"https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz\",\n      \"integrity\": \"sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"bin\": {\n        \"acorn\": \"bin/acorn\"\n      },\n      \"engines\": {\n        \"node\": \">=0.4.0\"\n      }\n    },\n    \"node_modules/acorn-walk\": {\n      \"version\": \"8.3.4\",\n      \"resolved\": \"https://registry.npmjs.org/acorn-walk/-/acorn-walk-8.3.4.tgz\",\n      \"integrity\": \"sha512-ueEepnujpqee2o5aIYnvHU6C0A42MNdsIDeqy5BydrkuC5R1ZuUFnm27EeFJGoEHJQgn3uleRvmTXaJgfXbt4g==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"acorn\": \"^8.11.0\"\n      },\n      \"engines\": {\n        \"node\": \">=0.4.0\"\n      }\n    },\n    \"node_modules/agent-base\": {\n      \"version\": \"6.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/agent-base/-/agent-base-6.0.2.tgz\",\n      \"integrity\": \"sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"debug\": \"4\"\n      },\n      \"engines\": {\n        \"node\": \">= 6.0.0\"\n      }\n    },\n    \"node_modules/agent-base/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/agent-base/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/agentkeepalive\": {\n      \"version\": \"4.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/agentkeepalive/-/agentkeepalive-4.6.0.tgz\",\n      \"integrity\": \"sha512-kja8j7PjmncONqaTsB8fQ+wE2mSU2DJ9D4XKoJ5PFWIdRMa6SLSN1ff4mOr4jCbfRSsxR4keIiySJU0N9T5hIQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"humanize-ms\": \"^1.2.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 8.0.0\"\n      }\n    },\n    \"node_modules/aggregate-error\": {\n      \"version\": \"3.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/aggregate-error/-/aggregate-error-3.1.0.tgz\",\n      \"integrity\": \"sha512-4I7Td01quW/RpocfNayFdFVk1qSuoh0E7JrbRJ16nH01HhKFQ88INq9Sd+nd72zqRySlr9BmDA8xlEJ6vJMrYA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"clean-stack\": \"^2.0.0\",\n        \"indent-string\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/ansi-regex\": {\n      \"version\": \"5.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz\",\n      \"integrity\": \"sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/anymatch\": {\n      \"version\": \"3.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz\",\n      \"integrity\": \"sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==\",\n      \"dev\": true,\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"normalize-path\": \"^3.0.0\",\n        \"picomatch\": \"^2.0.4\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/aproba\": {\n      \"version\": \"2.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/aproba/-/aproba-2.1.0.tgz\",\n      \"integrity\": \"sha512-tLIEcj5GuR2RSTnxNKdkK0dJ/GrC7P38sUkiDmDuHfsHmbagTFAxDVIBltoklXEVIQ/f14IL8IMJ5pn9Hez1Ew==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/are-we-there-yet\": {\n      \"version\": \"3.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/are-we-there-yet/-/are-we-there-yet-3.0.1.tgz\",\n      \"integrity\": \"sha512-QZW4EDmGwlYur0Yyf/b2uGucHQMa8aFUP7eu9ddR73vvhFyt4V0Vl3QHPcTNJ8l6qYOBdxgXdnBXQrHilfRQBg==\",\n      \"deprecated\": \"This package is no longer supported.\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"delegates\": \"^1.0.0\",\n        \"readable-stream\": \"^3.6.0\"\n      },\n      \"engines\": {\n        \"node\": \"^12.13.0 || ^14.15.0 || >=16.0.0\"\n      }\n    },\n    \"node_modules/arg\": {\n      \"version\": \"4.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/arg/-/arg-4.1.3.tgz\",\n      \"integrity\": \"sha512-58S9QDqG0Xx27YwPSt9fJxivjYl432YCwfDMfZ+71RAqUrZef7LrKQZ3LHLOwCS4FLNBplP533Zx895SeOCHvA==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/array-flatten\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/array-flatten/-/array-flatten-1.1.1.tgz\",\n      \"integrity\": \"sha512-PCVAQswWemu6UdxsDFFX/+gVeYqKAod3D3UVm91jHwynguOwAvYPhx8nNlM++NqRcK6CxxpUafjmhIdKiHibqg==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/balanced-match\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz\",\n      \"integrity\": \"sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==\",\n      \"devOptional\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/base64-js\": {\n      \"version\": \"1.5.1\",\n      \"resolved\": \"https://registry.npmjs.org/base64-js/-/base64-js-1.5.1.tgz\",\n      \"integrity\": \"sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\"\n    },\n    \"node_modules/base64id\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/base64id/-/base64id-2.0.0.tgz\",\n      \"integrity\": \"sha512-lGe34o6EHj9y3Kts9R4ZYs/Gr+6N7MCaMlIFA3F1R2O5/m7K06AxfSeO5530PEERE6/WyEg3lsuyw4GHlPZHog==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \"^4.5.0 || >= 5.9\"\n      }\n    },\n    \"node_modules/binary-extensions\": {\n      \"version\": \"2.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz\",\n      \"integrity\": \"sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=8\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/bindings\": {\n      \"version\": \"1.5.0\",\n      \"resolved\": \"https://registry.npmjs.org/bindings/-/bindings-1.5.0.tgz\",\n      \"integrity\": \"sha512-p2q/t/mhvuOj/UeLlV6566GD/guowlr0hHxClI0W9m7MWYkL1F0hLo+0Aexs9HSPCtR1SXQ0TD3MMKrXZajbiQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"file-uri-to-path\": \"1.0.0\"\n      }\n    },\n    \"node_modules/bl\": {\n      \"version\": \"4.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/bl/-/bl-4.1.0.tgz\",\n      \"integrity\": \"sha512-1W07cM9gS6DcLperZfFSj+bWLtaPGSOHWhPiGzXmvVJbRLdG82sH/Kn8EtW1VqWVA54AKf2h5k5BbnIbwF3h6w==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"buffer\": \"^5.5.0\",\n        \"inherits\": \"^2.0.4\",\n        \"readable-stream\": \"^3.4.0\"\n      }\n    },\n    \"node_modules/body-parser\": {\n      \"version\": \"1.20.3\",\n      \"resolved\": \"https://registry.npmjs.org/body-parser/-/body-parser-1.20.3.tgz\",\n      \"integrity\": \"sha512-7rAxByjUMqQ3/bHJy7D6OGXvx/MMc4IqBn/X0fcM1QUcAItpZrBEYhWGem+tzXH90c+G01ypMcYJBO9Y30203g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"bytes\": \"3.1.2\",\n        \"content-type\": \"~1.0.5\",\n        \"debug\": \"2.6.9\",\n        \"depd\": \"2.0.0\",\n        \"destroy\": \"1.2.0\",\n        \"http-errors\": \"2.0.0\",\n        \"iconv-lite\": \"0.4.24\",\n        \"on-finished\": \"2.4.1\",\n        \"qs\": \"6.13.0\",\n        \"raw-body\": \"2.5.2\",\n        \"type-is\": \"~1.6.18\",\n        \"unpipe\": \"1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\",\n        \"npm\": \"1.2.8000 || >= 1.4.16\"\n      }\n    },\n    \"node_modules/brace-expansion\": {\n      \"version\": \"1.1.12\",\n      \"resolved\": \"https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz\",\n      \"integrity\": \"sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==\",\n      \"devOptional\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"balanced-match\": \"^1.0.0\",\n        \"concat-map\": \"0.0.1\"\n      }\n    },\n    \"node_modules/braces\": {\n      \"version\": \"3.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/braces/-/braces-3.0.3.tgz\",\n      \"integrity\": \"sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"fill-range\": \"^7.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/buffer\": {\n      \"version\": \"5.7.1\",\n      \"resolved\": \"https://registry.npmjs.org/buffer/-/buffer-5.7.1.tgz\",\n      \"integrity\": \"sha512-EHcyIPBQ4BSGlvjB16k5KgAJ27CIsHY/2JBmCRReo48y9rQ3MaUzWX3KVlBa4U7MyX02HdVj0K7C3WaB3ju7FQ==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"base64-js\": \"^1.3.1\",\n        \"ieee754\": \"^1.1.13\"\n      }\n    },\n    \"node_modules/bytes\": {\n      \"version\": \"3.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/bytes/-/bytes-3.1.2.tgz\",\n      \"integrity\": \"sha512-/Nf7TyzTx6S3yRJObOAV7956r8cr2+Oj8AC5dt8wSP3BQAoeX58NoHyCU8P8zGkNXStjTSi6fzO6F0pBdcYbEg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/cacache\": {\n      \"version\": \"15.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/cacache/-/cacache-15.3.0.tgz\",\n      \"integrity\": \"sha512-VVdYzXEn+cnbXpFgWs5hTT7OScegHVmLhJIR8Ufqk3iFD6A6j5iSX1KuBTfNEv4tdJWE2PzA6IVFtcLC7fN9wQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"@npmcli/fs\": \"^1.0.0\",\n        \"@npmcli/move-file\": \"^1.0.1\",\n        \"chownr\": \"^2.0.0\",\n        \"fs-minipass\": \"^2.0.0\",\n        \"glob\": \"^7.1.4\",\n        \"infer-owner\": \"^1.0.4\",\n        \"lru-cache\": \"^6.0.0\",\n        \"minipass\": \"^3.1.1\",\n        \"minipass-collect\": \"^1.0.2\",\n        \"minipass-flush\": \"^1.0.5\",\n        \"minipass-pipeline\": \"^1.2.2\",\n        \"mkdirp\": \"^1.0.3\",\n        \"p-map\": \"^4.0.0\",\n        \"promise-inflight\": \"^1.0.1\",\n        \"rimraf\": \"^3.0.2\",\n        \"ssri\": \"^8.0.1\",\n        \"tar\": \"^6.0.2\",\n        \"unique-filename\": \"^1.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 10\"\n      }\n    },\n    \"node_modules/call-bind-apply-helpers\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz\",\n      \"integrity\": \"sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"es-errors\": \"^1.3.0\",\n        \"function-bind\": \"^1.1.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/call-bound\": {\n      \"version\": \"1.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/call-bound/-/call-bound-1.0.4.tgz\",\n      \"integrity\": \"sha512-+ys997U96po4Kx/ABpBCqhA9EuxJaQWDQg7295H4hBphv3IZg0boBKuwYpt4YXp6MZ5AmZQnU/tyMTlRpaSejg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bind-apply-helpers\": \"^1.0.2\",\n        \"get-intrinsic\": \"^1.3.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/chokidar\": {\n      \"version\": \"3.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz\",\n      \"integrity\": \"sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"anymatch\": \"~3.1.2\",\n        \"braces\": \"~3.0.2\",\n        \"glob-parent\": \"~5.1.2\",\n        \"is-binary-path\": \"~2.1.0\",\n        \"is-glob\": \"~4.0.1\",\n        \"normalize-path\": \"~3.0.0\",\n        \"readdirp\": \"~3.6.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8.10.0\"\n      },\n      \"funding\": {\n        \"url\": \"https://paulmillr.com/funding/\"\n      },\n      \"optionalDependencies\": {\n        \"fsevents\": \"~2.3.2\"\n      }\n    },\n    \"node_modules/chownr\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/chownr/-/chownr-2.0.0.tgz\",\n      \"integrity\": \"sha512-bIomtDF5KGpdogkLd9VspvFzk9KfpyyGlS8YFVZl7TGPBHL5snIOnxeshwVgPteQ9b4Eydl+pVbIyE1DcvCWgQ==\",\n      \"license\": \"ISC\",\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/clean-stack\": {\n      \"version\": \"2.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/clean-stack/-/clean-stack-2.2.0.tgz\",\n      \"integrity\": \"sha512-4diC9HaTE+KRAMWhDhrGOECgWZxoevMc5TlkObMqNSsVU62PYzXZ/SMTjzyGAFF1YusgxGcSWTEXBhp0CPwQ1A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/color-support\": {\n      \"version\": \"1.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/color-support/-/color-support-1.1.3.tgz\",\n      \"integrity\": \"sha512-qiBjkpbMLO/HL68y+lh4q0/O1MZFj2RX6X/KmMa3+gJD3z+WwI1ZzDHysvqHGS3mP6mznPckpXmw1nI9cJjyRg==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"bin\": {\n        \"color-support\": \"bin.js\"\n      }\n    },\n    \"node_modules/concat-map\": {\n      \"version\": \"0.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz\",\n      \"integrity\": \"sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==\",\n      \"devOptional\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/console-control-strings\": {\n      \"version\": \"1.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/console-control-strings/-/console-control-strings-1.1.0.tgz\",\n      \"integrity\": \"sha512-ty/fTekppD2fIwRvnZAVdeOiGd1c7YXEixbgJTNzqcxJWKQnjJ/V1bNEEE6hygpM3WjwHFUVK6HTjWSzV4a8sQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/content-disposition\": {\n      \"version\": \"0.5.4\",\n      \"resolved\": \"https://registry.npmjs.org/content-disposition/-/content-disposition-0.5.4.tgz\",\n      \"integrity\": \"sha512-FveZTNuGw04cxlAiWbzi6zTAL/lhehaWbTtgluJh4/E95DqMwTmha3KZN1aAWA8cFIhHzMZUvLevkw5Rqk+tSQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"safe-buffer\": \"5.2.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/content-type\": {\n      \"version\": \"1.0.5\",\n      \"resolved\": \"https://registry.npmjs.org/content-type/-/content-type-1.0.5.tgz\",\n      \"integrity\": \"sha512-nTjqfcBFEipKdXCv4YDQWCfmcLZKm81ldF0pAopTvyrFGVbcR6P/VAAd5G7N+0tTr8QqiU0tFadD6FK4NtJwOA==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/cookie\": {\n      \"version\": \"0.7.1\",\n      \"resolved\": \"https://registry.npmjs.org/cookie/-/cookie-0.7.1.tgz\",\n      \"integrity\": \"sha512-6DnInpx7SJ2AK3+CTUE/ZM0vWTUboZCegxhC2xiIydHR9jNuTAASBrfEpHhiGOZw/nX51bHt6YQl8jsGo4y/0w==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/cookie-signature\": {\n      \"version\": \"1.0.6\",\n      \"resolved\": \"https://registry.npmjs.org/cookie-signature/-/cookie-signature-1.0.6.tgz\",\n      \"integrity\": \"sha512-QADzlaHc8icV8I7vbaJXJwod9HWYp8uCqf1xa4OfNu1T7JVxQIrUgOWtHdNDtPiywmFbiS12VjotIXLrKM3orQ==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/cors\": {\n      \"version\": \"2.8.5\",\n      \"resolved\": \"https://registry.npmjs.org/cors/-/cors-2.8.5.tgz\",\n      \"integrity\": \"sha512-KIHbLJqu73RGr/hnbrO9uBeixNGuvSQjul/jdFvS/KFSIH1hWVd1ng7zOHx+YrEfInLG7q4n6GHQ9cDtxv/P6g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"object-assign\": \"^4\",\n        \"vary\": \"^1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.10\"\n      }\n    },\n    \"node_modules/create-require\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/create-require/-/create-require-1.1.1.tgz\",\n      \"integrity\": \"sha512-dcKFX3jn0MpIaXjisoRvexIJVEKzaq7z2rZKxf+MSr9TkdmHmsU4m2lcLojrj/FHl8mk5VxMmYA+ftRkP/3oKQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/debug\": {\n      \"version\": \"2.6.9\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-2.6.9.tgz\",\n      \"integrity\": \"sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"2.0.0\"\n      }\n    },\n    \"node_modules/decompress-response\": {\n      \"version\": \"6.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/decompress-response/-/decompress-response-6.0.0.tgz\",\n      \"integrity\": \"sha512-aW35yZM6Bb/4oJlZncMH2LCoZtJXTRxES17vE3hoRiowU2kWHaJKFkSBDnDR+cm9J+9QhXmREyIfv0pji9ejCQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"mimic-response\": \"^3.1.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/deep-extend\": {\n      \"version\": \"0.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/deep-extend/-/deep-extend-0.6.0.tgz\",\n      \"integrity\": \"sha512-LOHxIOaPYdHlJRtCQfDIVZtfw/ufM8+rVj649RIHzcm/vGwQRXFt6OPqIFWsm2XEMrNIEtWR64sY1LEKD2vAOA==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=4.0.0\"\n      }\n    },\n    \"node_modules/delegates\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/delegates/-/delegates-1.0.0.tgz\",\n      \"integrity\": \"sha512-bd2L678uiWATM6m5Z1VzNCErI3jiGzt6HGY8OVICs40JQq/HALfbyNJmp0UDakEY4pMMaN0Ly5om/B1VI/+xfQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/depd\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/depd/-/depd-2.0.0.tgz\",\n      \"integrity\": \"sha512-g7nH6P6dyDioJogAAGprGpCtVImJhpPk/roCzdb3fIh61/s/nPsfR6onyMwkCAR/OlC3yBC0lESvUoQEAssIrw==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/destroy\": {\n      \"version\": \"1.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/destroy/-/destroy-1.2.0.tgz\",\n      \"integrity\": \"sha512-2sJGJTaXIIaR1w4iJSNoN0hnMY7Gpc/n8D4qSCJw8QqFWXf7cuAgnEHxBpweaVcPevC2l3KpjYCx3NypQQgaJg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\",\n        \"npm\": \"1.2.8000 || >= 1.4.16\"\n      }\n    },\n    \"node_modules/detect-libc\": {\n      \"version\": \"2.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/detect-libc/-/detect-libc-2.1.1.tgz\",\n      \"integrity\": \"sha512-ecqj/sy1jcK1uWrwpR67UhYrIFQ+5WlGxth34WquCbamhFA6hkkwiu37o6J5xCHdo1oixJRfVRw+ywV+Hq/0Aw==\",\n      \"license\": \"Apache-2.0\",\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/diff\": {\n      \"version\": \"4.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/diff/-/diff-4.0.2.tgz\",\n      \"integrity\": \"sha512-58lmxKSA4BNyLz+HHMUzlOEpg09FV+ev6ZMe3vJihgdxzgcwZ8VoEEPmALCZG9LmqfVoNMMKpttIYTVG6uDY7A==\",\n      \"dev\": true,\n      \"license\": \"BSD-3-Clause\",\n      \"engines\": {\n        \"node\": \">=0.3.1\"\n      }\n    },\n    \"node_modules/dunder-proto\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz\",\n      \"integrity\": \"sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bind-apply-helpers\": \"^1.0.1\",\n        \"es-errors\": \"^1.3.0\",\n        \"gopd\": \"^1.2.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/ee-first\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/ee-first/-/ee-first-1.1.1.tgz\",\n      \"integrity\": \"sha512-WMwm9LhRUo+WUaRN+vRuETqG89IgZphVSNkdFgeb6sS/E4OrDIN7t48CAewSHXc6C8lefD8KKfr5vY61brQlow==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/emoji-regex\": {\n      \"version\": \"8.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz\",\n      \"integrity\": \"sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/encodeurl\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/encodeurl/-/encodeurl-2.0.0.tgz\",\n      \"integrity\": \"sha512-Q0n9HRi4m6JuGIV1eFlmvJB7ZEVxu93IrMyiMsGC0lrMJMWzRgx6WGquyfQgZVb31vhGgXnfmPNNXmxnOkRBrg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/encoding\": {\n      \"version\": \"0.1.13\",\n      \"resolved\": \"https://registry.npmjs.org/encoding/-/encoding-0.1.13.tgz\",\n      \"integrity\": \"sha512-ETBauow1T35Y/WZMkio9jiM0Z5xjHHmJ4XmjZOq1l/dXz3lr2sRn87nJy20RupqSh1F2m3HHPSp8ShIPQJrJ3A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"iconv-lite\": \"^0.6.2\"\n      }\n    },\n    \"node_modules/encoding/node_modules/iconv-lite\": {\n      \"version\": \"0.6.3\",\n      \"resolved\": \"https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.6.3.tgz\",\n      \"integrity\": \"sha512-4fCk79wshMdzMp2rH06qWrJE4iolqLhCUH+OiuIgU++RB0+94NlDL81atO7GX55uUKueo0txHNtvEyI6D7WdMw==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"safer-buffer\": \">= 2.1.2 < 3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/end-of-stream\": {\n      \"version\": \"1.4.5\",\n      \"resolved\": \"https://registry.npmjs.org/end-of-stream/-/end-of-stream-1.4.5.tgz\",\n      \"integrity\": \"sha512-ooEGc6HP26xXq/N+GCGOT0JKCLDGrq2bQUZrQ7gyrJiZANJ/8YDTxTpQBXGMn+WbIQXNVpyWymm7KYVICQnyOg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"once\": \"^1.4.0\"\n      }\n    },\n    \"node_modules/engine.io\": {\n      \"version\": \"6.6.4\",\n      \"resolved\": \"https://registry.npmjs.org/engine.io/-/engine.io-6.6.4.tgz\",\n      \"integrity\": \"sha512-ZCkIjSYNDyGn0R6ewHDtXgns/Zre/NT6Agvq1/WobF7JXgFff4SeDroKiCO3fNJreU9YG429Sc81o4w5ok/W5g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/cors\": \"^2.8.12\",\n        \"@types/node\": \">=10.0.0\",\n        \"accepts\": \"~1.3.4\",\n        \"base64id\": \"2.0.0\",\n        \"cookie\": \"~0.7.2\",\n        \"cors\": \"~2.8.5\",\n        \"debug\": \"~4.3.1\",\n        \"engine.io-parser\": \"~5.2.1\",\n        \"ws\": \"~8.17.1\"\n      },\n      \"engines\": {\n        \"node\": \">=10.2.0\"\n      }\n    },\n    \"node_modules/engine.io-parser\": {\n      \"version\": \"5.2.3\",\n      \"resolved\": \"https://registry.npmjs.org/engine.io-parser/-/engine.io-parser-5.2.3.tgz\",\n      \"integrity\": \"sha512-HqD3yTBfnBxIrbnM1DoD6Pcq8NECnh8d4As1Qgh0z5Gg3jRRIqijury0CL3ghu/edArpUYiYqQiDUQBIs4np3Q==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=10.0.0\"\n      }\n    },\n    \"node_modules/engine.io/node_modules/cookie\": {\n      \"version\": \"0.7.2\",\n      \"resolved\": \"https://registry.npmjs.org/cookie/-/cookie-0.7.2.tgz\",\n      \"integrity\": \"sha512-yki5XnKuf750l50uGTllt6kKILY4nQ1eNIQatoXEByZ5dWgnKqbnqmTrBE5B4N7lrMJKQ2ytWMiTO2o0v6Ew/w==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/engine.io/node_modules/debug\": {\n      \"version\": \"4.3.7\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.3.7.tgz\",\n      \"integrity\": \"sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/engine.io/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/env-paths\": {\n      \"version\": \"2.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/env-paths/-/env-paths-2.2.1.tgz\",\n      \"integrity\": \"sha512-+h1lkLKhZMTYjog1VEpJNG7NZJWcuc2DDk/qsqSTRRCOXiLjeQ1d1/udrUGhqMxUgAlwKNZ0cf2uqan5GLuS2A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/err-code\": {\n      \"version\": \"2.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/err-code/-/err-code-2.0.3.tgz\",\n      \"integrity\": \"sha512-2bmlRpNKBxT/CRmPOlyISQpNj+qSeYvcym/uT0Jx2bMOlKLtSy1ZmLuVxSEKKyor/N5yhvp/ZiG1oE3DEYMSFA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/es-define-property\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz\",\n      \"integrity\": \"sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/es-errors\": {\n      \"version\": \"1.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz\",\n      \"integrity\": \"sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/es-object-atoms\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz\",\n      \"integrity\": \"sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"es-errors\": \"^1.3.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/escape-html\": {\n      \"version\": \"1.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/escape-html/-/escape-html-1.0.3.tgz\",\n      \"integrity\": \"sha512-NiSupZ4OeuGwr68lGIeym/ksIZMJodUGOSCZ/FSnTxcrekbvqrgdUxlJOMpijaKZVjAJrWrGs/6Jy8OMuyj9ow==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/etag\": {\n      \"version\": \"1.8.1\",\n      \"resolved\": \"https://registry.npmjs.org/etag/-/etag-1.8.1.tgz\",\n      \"integrity\": \"sha512-aIL5Fx7mawVa300al2BnEE4iNvo1qETxLrPI/o05L7z6go7fCw1J6EQmbK4FmJ2AS7kgVF/KEZWufBfdClMcPg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/expand-template\": {\n      \"version\": \"2.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/expand-template/-/expand-template-2.0.3.tgz\",\n      \"integrity\": \"sha512-XYfuKMvj4O35f/pOXLObndIRvyQ+/+6AhODh+OKWj9S9498pHHn/IMszH+gt0fBCRWMNfk1ZSp5x3AifmnI2vg==\",\n      \"license\": \"(MIT OR WTFPL)\",\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/express\": {\n      \"version\": \"4.21.2\",\n      \"resolved\": \"https://registry.npmjs.org/express/-/express-4.21.2.tgz\",\n      \"integrity\": \"sha512-28HqgMZAmih1Czt9ny7qr6ek2qddF4FclbMzwhCREB6OFfH+rXAnuNCwo1/wFvrtbgsQDb4kSbX9de9lFbrXnA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"accepts\": \"~1.3.8\",\n        \"array-flatten\": \"1.1.1\",\n        \"body-parser\": \"1.20.3\",\n        \"content-disposition\": \"0.5.4\",\n        \"content-type\": \"~1.0.4\",\n        \"cookie\": \"0.7.1\",\n        \"cookie-signature\": \"1.0.6\",\n        \"debug\": \"2.6.9\",\n        \"depd\": \"2.0.0\",\n        \"encodeurl\": \"~2.0.0\",\n        \"escape-html\": \"~1.0.3\",\n        \"etag\": \"~1.8.1\",\n        \"finalhandler\": \"1.3.1\",\n        \"fresh\": \"0.5.2\",\n        \"http-errors\": \"2.0.0\",\n        \"merge-descriptors\": \"1.0.3\",\n        \"methods\": \"~1.1.2\",\n        \"on-finished\": \"2.4.1\",\n        \"parseurl\": \"~1.3.3\",\n        \"path-to-regexp\": \"0.1.12\",\n        \"proxy-addr\": \"~2.0.7\",\n        \"qs\": \"6.13.0\",\n        \"range-parser\": \"~1.2.1\",\n        \"safe-buffer\": \"5.2.1\",\n        \"send\": \"0.19.0\",\n        \"serve-static\": \"1.16.2\",\n        \"setprototypeof\": \"1.2.0\",\n        \"statuses\": \"2.0.1\",\n        \"type-is\": \"~1.6.18\",\n        \"utils-merge\": \"1.0.1\",\n        \"vary\": \"~1.1.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.10.0\"\n      },\n      \"funding\": {\n        \"type\": \"opencollective\",\n        \"url\": \"https://opencollective.com/express\"\n      }\n    },\n    \"node_modules/express-rate-limit\": {\n      \"version\": \"7.5.1\",\n      \"resolved\": \"https://registry.npmjs.org/express-rate-limit/-/express-rate-limit-7.5.1.tgz\",\n      \"integrity\": \"sha512-7iN8iPMDzOMHPUYllBEsQdWVB6fPDMPqwjBaFrgr4Jgr/+okjvzAy+UHlYYL/Vs0OsOrMkwS6PJDkFlJwoxUnw==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 16\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/express-rate-limit\"\n      },\n      \"peerDependencies\": {\n        \"express\": \">= 4.11\"\n      }\n    },\n    \"node_modules/file-uri-to-path\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/file-uri-to-path/-/file-uri-to-path-1.0.0.tgz\",\n      \"integrity\": \"sha512-0Zt+s3L7Vf1biwWZ29aARiVYLx7iMGnEUl9x33fbB/j3jR81u/O2LbqK+Bm1CDSNDKVtJ/YjwY7TUd5SkeLQLw==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/fill-range\": {\n      \"version\": \"7.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz\",\n      \"integrity\": \"sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"to-regex-range\": \"^5.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/finalhandler\": {\n      \"version\": \"1.3.1\",\n      \"resolved\": \"https://registry.npmjs.org/finalhandler/-/finalhandler-1.3.1.tgz\",\n      \"integrity\": \"sha512-6BN9trH7bp3qvnrRyzsBz+g3lZxTNZTbVO2EV1CS0WIcDbawYVdYvGflME/9QP0h0pYlCDBCTjYa9nZzMDpyxQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"debug\": \"2.6.9\",\n        \"encodeurl\": \"~2.0.0\",\n        \"escape-html\": \"~1.0.3\",\n        \"on-finished\": \"2.4.1\",\n        \"parseurl\": \"~1.3.3\",\n        \"statuses\": \"2.0.1\",\n        \"unpipe\": \"~1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/forwarded\": {\n      \"version\": \"0.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/forwarded/-/forwarded-0.2.0.tgz\",\n      \"integrity\": \"sha512-buRG0fpBtRHSTCOASe6hD258tEubFoRLb4ZNA6NxMVHNw2gOcwHo9wyablzMzOA5z9xA9L1KNjk/Nt6MT9aYow==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/fresh\": {\n      \"version\": \"0.5.2\",\n      \"resolved\": \"https://registry.npmjs.org/fresh/-/fresh-0.5.2.tgz\",\n      \"integrity\": \"sha512-zJ2mQYM18rEFOudeV4GShTGIQ7RbzA7ozbU9I/XBpm7kqgMywgmylMwXHxZJmkVoYkna9d2pVXVXPdYTP9ej8Q==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/fs-constants\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/fs-constants/-/fs-constants-1.0.0.tgz\",\n      \"integrity\": \"sha512-y6OAwoSIf7FyjMIv94u+b5rdheZEjzR63GTyZJm5qh4Bi+2YgwLCcI/fPFZkL5PSixOt6ZNKm+w+Hfp/Bciwow==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/fs-minipass\": {\n      \"version\": \"2.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/fs-minipass/-/fs-minipass-2.1.0.tgz\",\n      \"integrity\": \"sha512-V/JgOLFCS+R6Vcq0slCuaeWEdNC3ouDlJMNIsacH2VtALiu9mV4LPrHc5cDl8k5aw6J8jwgWWpiTo5RYhmIzvg==\",\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/fs.realpath\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz\",\n      \"integrity\": \"sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/fsevents\": {\n      \"version\": \"2.3.3\",\n      \"resolved\": \"https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz\",\n      \"integrity\": \"sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==\",\n      \"dev\": true,\n      \"hasInstallScript\": true,\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"os\": [\n        \"darwin\"\n      ],\n      \"engines\": {\n        \"node\": \"^8.16.0 || ^10.6.0 || >=11.0.0\"\n      }\n    },\n    \"node_modules/function-bind\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz\",\n      \"integrity\": \"sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==\",\n      \"license\": \"MIT\",\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/gauge\": {\n      \"version\": \"4.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/gauge/-/gauge-4.0.4.tgz\",\n      \"integrity\": \"sha512-f9m+BEN5jkg6a0fZjleidjN51VE1X+mPFQ2DJ0uv1V39oCLCbsGe6yjbBnp7eK7z/+GAon99a3nHuqbuuthyPg==\",\n      \"deprecated\": \"This package is no longer supported.\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"aproba\": \"^1.0.3 || ^2.0.0\",\n        \"color-support\": \"^1.1.3\",\n        \"console-control-strings\": \"^1.1.0\",\n        \"has-unicode\": \"^2.0.1\",\n        \"signal-exit\": \"^3.0.7\",\n        \"string-width\": \"^4.2.3\",\n        \"strip-ansi\": \"^6.0.1\",\n        \"wide-align\": \"^1.1.5\"\n      },\n      \"engines\": {\n        \"node\": \"^12.13.0 || ^14.15.0 || >=16.0.0\"\n      }\n    },\n    \"node_modules/get-intrinsic\": {\n      \"version\": \"1.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz\",\n      \"integrity\": \"sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bind-apply-helpers\": \"^1.0.2\",\n        \"es-define-property\": \"^1.0.1\",\n        \"es-errors\": \"^1.3.0\",\n        \"es-object-atoms\": \"^1.1.1\",\n        \"function-bind\": \"^1.1.2\",\n        \"get-proto\": \"^1.0.1\",\n        \"gopd\": \"^1.2.0\",\n        \"has-symbols\": \"^1.1.0\",\n        \"hasown\": \"^2.0.2\",\n        \"math-intrinsics\": \"^1.1.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/get-proto\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz\",\n      \"integrity\": \"sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"dunder-proto\": \"^1.0.1\",\n        \"es-object-atoms\": \"^1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/github-from-package\": {\n      \"version\": \"0.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/github-from-package/-/github-from-package-0.0.0.tgz\",\n      \"integrity\": \"sha512-SyHy3T1v2NUXn29OsWdxmK6RwHD+vkj3v8en8AOBZ1wBQ/hCAQ5bAQTD02kW4W9tUp/3Qh6J8r9EvntiyCmOOw==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/glob\": {\n      \"version\": \"7.2.3\",\n      \"resolved\": \"https://registry.npmjs.org/glob/-/glob-7.2.3.tgz\",\n      \"integrity\": \"sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==\",\n      \"deprecated\": \"Glob versions prior to v9 are no longer supported\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"fs.realpath\": \"^1.0.0\",\n        \"inflight\": \"^1.0.4\",\n        \"inherits\": \"2\",\n        \"minimatch\": \"^3.1.1\",\n        \"once\": \"^1.3.0\",\n        \"path-is-absolute\": \"^1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \"*\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/isaacs\"\n      }\n    },\n    \"node_modules/glob-parent\": {\n      \"version\": \"5.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz\",\n      \"integrity\": \"sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==\",\n      \"dev\": true,\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"is-glob\": \"^4.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/gopd\": {\n      \"version\": \"1.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz\",\n      \"integrity\": \"sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/graceful-fs\": {\n      \"version\": \"4.2.11\",\n      \"resolved\": \"https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz\",\n      \"integrity\": \"sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/has-flag\": {\n      \"version\": \"3.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/has-flag/-/has-flag-3.0.0.tgz\",\n      \"integrity\": \"sha512-sKJf1+ceQBr4SMkvQnBDNDtf4TXpVhVGateu0t918bl30FnbE2m4vNLX+VWe/dpjlb+HugGYzW7uQXH98HPEYw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=4\"\n      }\n    },\n    \"node_modules/has-symbols\": {\n      \"version\": \"1.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz\",\n      \"integrity\": \"sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/has-unicode\": {\n      \"version\": \"2.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/has-unicode/-/has-unicode-2.0.1.tgz\",\n      \"integrity\": \"sha512-8Rf9Y83NBReMnx0gFzA8JImQACstCYWUplepDa9xprwwtmgEZUF0h/i5xSA625zB/I37EtrswSST6OXxwaaIJQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/hasown\": {\n      \"version\": \"2.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz\",\n      \"integrity\": \"sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"function-bind\": \"^1.1.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/helmet\": {\n      \"version\": \"7.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/helmet/-/helmet-7.2.0.tgz\",\n      \"integrity\": \"sha512-ZRiwvN089JfMXokizgqEPXsl2Guk094yExfoDXR0cBYWxtBbaSww/w+vT4WEJsBW2iTUi1GgZ6swmoug3Oy4Xw==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=16.0.0\"\n      }\n    },\n    \"node_modules/http-cache-semantics\": {\n      \"version\": \"4.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/http-cache-semantics/-/http-cache-semantics-4.2.0.tgz\",\n      \"integrity\": \"sha512-dTxcvPXqPvXBQpq5dUr6mEMJX4oIEFv6bwom3FDwKRDsuIjjJGANqhBuoAn9c1RQJIdAKav33ED65E2ys+87QQ==\",\n      \"license\": \"BSD-2-Clause\",\n      \"optional\": true\n    },\n    \"node_modules/http-errors\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/http-errors/-/http-errors-2.0.0.tgz\",\n      \"integrity\": \"sha512-FtwrG/euBzaEjYeRqOgly7G0qviiXoJWnvEH2Z1plBdXgbyjv34pHTSb9zoeHMyDy33+DWy5Wt9Wo+TURtOYSQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"depd\": \"2.0.0\",\n        \"inherits\": \"2.0.4\",\n        \"setprototypeof\": \"1.2.0\",\n        \"statuses\": \"2.0.1\",\n        \"toidentifier\": \"1.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/http-proxy-agent\": {\n      \"version\": \"4.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/http-proxy-agent/-/http-proxy-agent-4.0.1.tgz\",\n      \"integrity\": \"sha512-k0zdNgqWTGA6aeIRVpvfVob4fL52dTfaehylg0Y4UvSySvOq/Y+BOyPrgpUrA7HylqvU8vIZGsRuXmspskV0Tg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"@tootallnate/once\": \"1\",\n        \"agent-base\": \"6\",\n        \"debug\": \"4\"\n      },\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/http-proxy-agent/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/http-proxy-agent/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/https-proxy-agent\": {\n      \"version\": \"5.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-5.0.1.tgz\",\n      \"integrity\": \"sha512-dFcAjpTQFgoLMzC2VwU+C/CbS7uRL0lWmxDITmqm7C+7F0Odmj6s9l6alZc6AELXhrnggM2CeWSXHGOdX2YtwA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"agent-base\": \"6\",\n        \"debug\": \"4\"\n      },\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/https-proxy-agent/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/https-proxy-agent/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/humanize-ms\": {\n      \"version\": \"1.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/humanize-ms/-/humanize-ms-1.2.1.tgz\",\n      \"integrity\": \"sha512-Fl70vYtsAFb/C06PTS9dZBo7ihau+Tu/DNCk/OyHhea07S+aeMWpFFkUaXRa8fI+ScZbEI8dfSxwY7gxZ9SAVQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.0.0\"\n      }\n    },\n    \"node_modules/iconv-lite\": {\n      \"version\": \"0.4.24\",\n      \"resolved\": \"https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.4.24.tgz\",\n      \"integrity\": \"sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"safer-buffer\": \">= 2.1.2 < 3\"\n      },\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/ieee754\": {\n      \"version\": \"1.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/ieee754/-/ieee754-1.2.1.tgz\",\n      \"integrity\": \"sha512-dcyqhDvX1C46lXZcVqCpK+FtMRQVdIMN6/Df5js2zouUsqG7I6sFxitIC+7KYK29KdXOLHdu9zL4sFnoVQnqaA==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"BSD-3-Clause\"\n    },\n    \"node_modules/ignore-by-default\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/ignore-by-default/-/ignore-by-default-1.0.1.tgz\",\n      \"integrity\": \"sha512-Ius2VYcGNk7T90CppJqcIkS5ooHUZyIQK+ClZfMfMNFEF9VSE73Fq+906u/CWu92x4gzZMWOwfFYckPObzdEbA==\",\n      \"dev\": true,\n      \"license\": \"ISC\"\n    },\n    \"node_modules/imurmurhash\": {\n      \"version\": \"0.1.4\",\n      \"resolved\": \"https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz\",\n      \"integrity\": \"sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=0.8.19\"\n      }\n    },\n    \"node_modules/indent-string\": {\n      \"version\": \"4.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/indent-string/-/indent-string-4.0.0.tgz\",\n      \"integrity\": \"sha512-EdDDZu4A2OyIK7Lr/2zG+w5jmbuk1DVBnEwREQvBzspBJkCEbRa8GxU1lghYcaGJCnRWibjDXlq779X1/y5xwg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/infer-owner\": {\n      \"version\": \"1.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/infer-owner/-/infer-owner-1.0.4.tgz\",\n      \"integrity\": \"sha512-IClj+Xz94+d7irH5qRyfJonOdfTzuDaifE6ZPWfx0N0+/ATZCbuTPq2prFl526urkQd90WyUKIh1DfBQ2hMz9A==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/inflight\": {\n      \"version\": \"1.0.6\",\n      \"resolved\": \"https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz\",\n      \"integrity\": \"sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==\",\n      \"deprecated\": \"This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"once\": \"^1.3.0\",\n        \"wrappy\": \"1\"\n      }\n    },\n    \"node_modules/inherits\": {\n      \"version\": \"2.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz\",\n      \"integrity\": \"sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/ini\": {\n      \"version\": \"1.3.8\",\n      \"resolved\": \"https://registry.npmjs.org/ini/-/ini-1.3.8.tgz\",\n      \"integrity\": \"sha512-JV/yugV2uzW5iMRSiZAyDtQd+nxtUnjeLt0acNdw98kKLrvuRVyB80tsREOE7yvGVgalhZ6RNXCmEHkUKBKxew==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/ip-address\": {\n      \"version\": \"10.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/ip-address/-/ip-address-10.0.1.tgz\",\n      \"integrity\": \"sha512-NWv9YLW4PoW2B7xtzaS3NCot75m6nK7Icdv0o3lfMceJVRfSoQwqD4wEH5rLwoKJwUiZ/rfpiVBhnaF0FK4HoA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">= 12\"\n      }\n    },\n    \"node_modules/ipaddr.js\": {\n      \"version\": \"1.9.1\",\n      \"resolved\": \"https://registry.npmjs.org/ipaddr.js/-/ipaddr.js-1.9.1.tgz\",\n      \"integrity\": \"sha512-0KI/607xoxSToH7GjN1FfSbLoU0+btTicjsQSWQlh/hZykN8KpmMf7uYwPW3R+akZ6R/w18ZlXSHBYXiYUPO3g==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.10\"\n      }\n    },\n    \"node_modules/is-binary-path\": {\n      \"version\": \"2.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz\",\n      \"integrity\": \"sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"binary-extensions\": \"^2.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/is-extglob\": {\n      \"version\": \"2.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz\",\n      \"integrity\": \"sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/is-fullwidth-code-point\": {\n      \"version\": \"3.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz\",\n      \"integrity\": \"sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/is-glob\": {\n      \"version\": \"4.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz\",\n      \"integrity\": \"sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"is-extglob\": \"^2.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/is-lambda\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/is-lambda/-/is-lambda-1.0.1.tgz\",\n      \"integrity\": \"sha512-z7CMFGNrENq5iFB9Bqo64Xk6Y9sg+epq1myIcdHaGnbMTYOxvzsEtdYqQUylB7LxfkvgrrjP32T6Ywciio9UIQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/is-number\": {\n      \"version\": \"7.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz\",\n      \"integrity\": \"sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.12.0\"\n      }\n    },\n    \"node_modules/isexe\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz\",\n      \"integrity\": \"sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/lru-cache\": {\n      \"version\": \"6.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/lru-cache/-/lru-cache-6.0.0.tgz\",\n      \"integrity\": \"sha512-Jo6dJ04CmSjuznwJSS3pUeWmd/H0ffTlkXXgwZi+eq1UCmqQwCh+eLsYOYCwY991i2Fah4h1BEMCx4qThGbsiA==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"yallist\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/make-error\": {\n      \"version\": \"1.3.6\",\n      \"resolved\": \"https://registry.npmjs.org/make-error/-/make-error-1.3.6.tgz\",\n      \"integrity\": \"sha512-s8UhlNe7vPKomQhC1qFelMokr/Sc3AgNbso3n74mVPA5LTZwkB9NlXf4XPamLxJE8h0gh73rM94xvwRT2CVInw==\",\n      \"dev\": true,\n      \"license\": \"ISC\"\n    },\n    \"node_modules/make-fetch-happen\": {\n      \"version\": \"9.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/make-fetch-happen/-/make-fetch-happen-9.1.0.tgz\",\n      \"integrity\": \"sha512-+zopwDy7DNknmwPQplem5lAZX/eCOzSvSNNcSKm5eVwTkOBzoktEfXsa9L23J/GIRhxRsaxzkPEhrJEpE2F4Gg==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"agentkeepalive\": \"^4.1.3\",\n        \"cacache\": \"^15.2.0\",\n        \"http-cache-semantics\": \"^4.1.0\",\n        \"http-proxy-agent\": \"^4.0.1\",\n        \"https-proxy-agent\": \"^5.0.0\",\n        \"is-lambda\": \"^1.0.1\",\n        \"lru-cache\": \"^6.0.0\",\n        \"minipass\": \"^3.1.3\",\n        \"minipass-collect\": \"^1.0.2\",\n        \"minipass-fetch\": \"^1.3.2\",\n        \"minipass-flush\": \"^1.0.5\",\n        \"minipass-pipeline\": \"^1.2.4\",\n        \"negotiator\": \"^0.6.2\",\n        \"promise-retry\": \"^2.0.1\",\n        \"socks-proxy-agent\": \"^6.0.0\",\n        \"ssri\": \"^8.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 10\"\n      }\n    },\n    \"node_modules/math-intrinsics\": {\n      \"version\": \"1.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz\",\n      \"integrity\": \"sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/media-typer\": {\n      \"version\": \"0.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/media-typer/-/media-typer-0.3.0.tgz\",\n      \"integrity\": \"sha512-dq+qelQ9akHpcOl/gUVRTxVIOkAJ1wR3QAvb4RsVjS8oVoFjDGTc679wJYmUmknUF5HwMLOgb5O+a3KxfWapPQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/merge-descriptors\": {\n      \"version\": \"1.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/merge-descriptors/-/merge-descriptors-1.0.3.tgz\",\n      \"integrity\": \"sha512-gaNvAS7TZ897/rVaZ0nMtAyxNyi/pdbjbAwUpFQpN70GqnVfOiXpeUUMKRBmzXaSQ8DdTX4/0ms62r2K+hE6mQ==\",\n      \"license\": \"MIT\",\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/methods\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/methods/-/methods-1.1.2.tgz\",\n      \"integrity\": \"sha512-iclAHeNqNm68zFtnZ0e+1L2yUIdvzNoauKU4WBA3VvH/vPFieF7qfRlwUZU+DA9P9bPXIS90ulxoUoCH23sV2w==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/mime\": {\n      \"version\": \"1.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/mime/-/mime-1.6.0.tgz\",\n      \"integrity\": \"sha512-x0Vn8spI+wuJ1O6S7gnbaQg8Pxh4NNHb7KSINmEWKiPE4RKOplvijn+NkmYmmRgP68mc70j2EbeTFRsrswaQeg==\",\n      \"license\": \"MIT\",\n      \"bin\": {\n        \"mime\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=4\"\n      }\n    },\n    \"node_modules/mime-db\": {\n      \"version\": \"1.52.0\",\n      \"resolved\": \"https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz\",\n      \"integrity\": \"sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/mime-types\": {\n      \"version\": \"2.1.35\",\n      \"resolved\": \"https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz\",\n      \"integrity\": \"sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"mime-db\": \"1.52.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/mimic-response\": {\n      \"version\": \"3.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/mimic-response/-/mimic-response-3.1.0.tgz\",\n      \"integrity\": \"sha512-z0yWI+4FDrrweS8Zmt4Ej5HdJmky15+L2e6Wgn3+iK5fWzb6T3fhNFq2+MeTRb064c6Wr4N/wv0DzQTjNzHNGQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=10\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/minimatch\": {\n      \"version\": \"3.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz\",\n      \"integrity\": \"sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==\",\n      \"devOptional\": true,\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"brace-expansion\": \"^1.1.7\"\n      },\n      \"engines\": {\n        \"node\": \"*\"\n      }\n    },\n    \"node_modules/minimist\": {\n      \"version\": \"1.2.8\",\n      \"resolved\": \"https://registry.npmjs.org/minimist/-/minimist-1.2.8.tgz\",\n      \"integrity\": \"sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==\",\n      \"license\": \"MIT\",\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/minipass\": {\n      \"version\": \"3.3.6\",\n      \"resolved\": \"https://registry.npmjs.org/minipass/-/minipass-3.3.6.tgz\",\n      \"integrity\": \"sha512-DxiNidxSEK+tHG6zOIklvNOwm3hvCrbUrdtzY74U6HKTJxvIDfOUL5W5P2Ghd3DTkhhKPYGqeNUIh5qcM4YBfw==\",\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"yallist\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/minipass-collect\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-collect/-/minipass-collect-1.0.2.tgz\",\n      \"integrity\": \"sha512-6T6lH0H8OG9kITm/Jm6tdooIbogG9e0tLgpY6mphXSm/A9u8Nq1ryBG+Qspiub9LjWlBPsPS3tWQ/Botq4FdxA==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/minipass-fetch\": {\n      \"version\": \"1.4.1\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-fetch/-/minipass-fetch-1.4.1.tgz\",\n      \"integrity\": \"sha512-CGH1eblLq26Y15+Azk7ey4xh0J/XfJfrCox5LDJiKqI2Q2iwOLOKrlmIaODiSQS8d18jalF6y2K2ePUm0CmShw==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.1.0\",\n        \"minipass-sized\": \"^1.0.3\",\n        \"minizlib\": \"^2.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      },\n      \"optionalDependencies\": {\n        \"encoding\": \"^0.1.12\"\n      }\n    },\n    \"node_modules/minipass-flush\": {\n      \"version\": \"1.0.5\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-flush/-/minipass-flush-1.0.5.tgz\",\n      \"integrity\": \"sha512-JmQSYYpPUqX5Jyn1mXaRwOda1uQ8HP5KAT/oDSLCzt1BYRhQU0/hDtsB1ufZfEEzMZ9aAVmsBw8+FWsIXlClWw==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/minipass-pipeline\": {\n      \"version\": \"1.2.4\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-pipeline/-/minipass-pipeline-1.2.4.tgz\",\n      \"integrity\": \"sha512-xuIq7cIOt09RPRJ19gdi4b+RiNvDFYe5JH+ggNvBqGqpQXcru3PcRmOZuHBKWK1Txf9+cQ+HMVN4d6z46LZP7A==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/minipass-sized\": {\n      \"version\": \"1.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-sized/-/minipass-sized-1.0.3.tgz\",\n      \"integrity\": \"sha512-MbkQQ2CTiBMlA2Dm/5cY+9SWFEN8pzzOXi6rlM5Xxq0Yqbda5ZQy9sU75a673FE9ZK0Zsbr6Y5iP6u9nktfg2g==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/minizlib\": {\n      \"version\": \"2.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/minizlib/-/minizlib-2.1.2.tgz\",\n      \"integrity\": \"sha512-bAxsR8BVfj60DWXHE3u30oHzfl4G7khkSuPW+qvpd7jFRHm7dLxOjUk1EHACJ/hxLY8phGJ0YhYHZo7jil7Qdg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\",\n        \"yallist\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/mkdirp\": {\n      \"version\": \"1.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/mkdirp/-/mkdirp-1.0.4.tgz\",\n      \"integrity\": \"sha512-vVqVZQyf3WLx2Shd0qJ9xuvqgAyKPLAiqITEtqW0oIUjzo3PePDd6fW9iFz30ef7Ysp/oiWqbhszeGWW2T6Gzw==\",\n      \"license\": \"MIT\",\n      \"bin\": {\n        \"mkdirp\": \"bin/cmd.js\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/mkdirp-classic\": {\n      \"version\": \"0.5.3\",\n      \"resolved\": \"https://registry.npmjs.org/mkdirp-classic/-/mkdirp-classic-0.5.3.tgz\",\n      \"integrity\": \"sha512-gKLcREMhtuZRwRAfqP3RFW+TK4JqApVBtOIftVgjuABpAtpxhPGaDcfvbhNvD0B8iD1oUr/txX35NjcaY6Ns/A==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/ms\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.0.0.tgz\",\n      \"integrity\": \"sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/napi-build-utils\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/napi-build-utils/-/napi-build-utils-2.0.0.tgz\",\n      \"integrity\": \"sha512-GEbrYkbfF7MoNaoh2iGG84Mnf/WZfB0GdGEsM8wz7Expx/LlWf5U8t9nvJKXSp3qr5IsEbK04cBGhol/KwOsWA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/negotiator\": {\n      \"version\": \"0.6.3\",\n      \"resolved\": \"https://registry.npmjs.org/negotiator/-/negotiator-0.6.3.tgz\",\n      \"integrity\": \"sha512-+EUsqGPLsM+j/zdChZjsnX51g4XrHFOIXwfnCVPGlQk/k5giakcKsuxCObBRu6DSm9opw/O6slWbJdghQM4bBg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/node-abi\": {\n      \"version\": \"3.77.0\",\n      \"resolved\": \"https://registry.npmjs.org/node-abi/-/node-abi-3.77.0.tgz\",\n      \"integrity\": \"sha512-DSmt0OEcLoK4i3NuscSbGjOf3bqiDEutejqENSplMSFA/gmB8mkED9G4pKWnPl7MDU4rSHebKPHeitpDfyH0cQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"semver\": \"^7.3.5\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/node-addon-api\": {\n      \"version\": \"7.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/node-addon-api/-/node-addon-api-7.1.1.tgz\",\n      \"integrity\": \"sha512-5m3bsyrjFWE1xf7nz7YXdN4udnVtXK6/Yfgn5qnahL6bCkf2yKt4k3nuTKAtT4r3IG8JNR2ncsIMdZuAzJjHQQ==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/node-gyp\": {\n      \"version\": \"8.4.1\",\n      \"resolved\": \"https://registry.npmjs.org/node-gyp/-/node-gyp-8.4.1.tgz\",\n      \"integrity\": \"sha512-olTJRgUtAb/hOXG0E93wZDs5YiJlgbXxTwQAFHyNlRsXQnYzUaF2aGgujZbw+hR8aF4ZG/rST57bWMWD16jr9w==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"env-paths\": \"^2.2.0\",\n        \"glob\": \"^7.1.4\",\n        \"graceful-fs\": \"^4.2.6\",\n        \"make-fetch-happen\": \"^9.1.0\",\n        \"nopt\": \"^5.0.0\",\n        \"npmlog\": \"^6.0.0\",\n        \"rimraf\": \"^3.0.2\",\n        \"semver\": \"^7.3.5\",\n        \"tar\": \"^6.1.2\",\n        \"which\": \"^2.0.2\"\n      },\n      \"bin\": {\n        \"node-gyp\": \"bin/node-gyp.js\"\n      },\n      \"engines\": {\n        \"node\": \">= 10.12.0\"\n      }\n    },\n    \"node_modules/nodemon\": {\n      \"version\": \"3.1.10\",\n      \"resolved\": \"https://registry.npmjs.org/nodemon/-/nodemon-3.1.10.tgz\",\n      \"integrity\": \"sha512-WDjw3pJ0/0jMFmyNDp3gvY2YizjLmmOUQo6DEBY+JgdvW/yQ9mEeSw6H5ythl5Ny2ytb7f9C2nIbjSxMNzbJXw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"chokidar\": \"^3.5.2\",\n        \"debug\": \"^4\",\n        \"ignore-by-default\": \"^1.0.1\",\n        \"minimatch\": \"^3.1.2\",\n        \"pstree.remy\": \"^1.1.8\",\n        \"semver\": \"^7.5.3\",\n        \"simple-update-notifier\": \"^2.0.0\",\n        \"supports-color\": \"^5.5.0\",\n        \"touch\": \"^3.1.0\",\n        \"undefsafe\": \"^2.0.5\"\n      },\n      \"bin\": {\n        \"nodemon\": \"bin/nodemon.js\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      },\n      \"funding\": {\n        \"type\": \"opencollective\",\n        \"url\": \"https://opencollective.com/nodemon\"\n      }\n    },\n    \"node_modules/nodemon/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/nodemon/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/nopt\": {\n      \"version\": \"5.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/nopt/-/nopt-5.0.0.tgz\",\n      \"integrity\": \"sha512-Tbj67rffqceeLpcRXrT7vKAN8CwfPeIBgM7E6iBkmKLV7bEMwpGgYLGv0jACUsECaa/vuxP0IjEont6umdMgtQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"abbrev\": \"1\"\n      },\n      \"bin\": {\n        \"nopt\": \"bin/nopt.js\"\n      },\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/normalize-path\": {\n      \"version\": \"3.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz\",\n      \"integrity\": \"sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/npmlog\": {\n      \"version\": \"6.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/npmlog/-/npmlog-6.0.2.tgz\",\n      \"integrity\": \"sha512-/vBvz5Jfr9dT/aFWd0FIRf+T/Q2WBsLENygUaFUqstqsycmZAP/t5BvFJTK0viFmSUxiUKTUplWy5vt+rvKIxg==\",\n      \"deprecated\": \"This package is no longer supported.\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"are-we-there-yet\": \"^3.0.0\",\n        \"console-control-strings\": \"^1.1.0\",\n        \"gauge\": \"^4.0.3\",\n        \"set-blocking\": \"^2.0.0\"\n      },\n      \"engines\": {\n        \"node\": \"^12.13.0 || ^14.15.0 || >=16.0.0\"\n      }\n    },\n    \"node_modules/object-assign\": {\n      \"version\": \"4.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz\",\n      \"integrity\": \"sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/object-inspect\": {\n      \"version\": \"1.13.4\",\n      \"resolved\": \"https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.4.tgz\",\n      \"integrity\": \"sha512-W67iLl4J2EXEGTbfeHCffrjDfitvLANg0UlX3wFUUSTx92KXRFegMHUVgSqE+wvhAbi4WqjGg9czysTV2Epbew==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/on-finished\": {\n      \"version\": \"2.4.1\",\n      \"resolved\": \"https://registry.npmjs.org/on-finished/-/on-finished-2.4.1.tgz\",\n      \"integrity\": \"sha512-oVlzkg3ENAhCk2zdv7IJwd/QUD4z2RxRwpkcGY8psCVcCYZNq4wYnVWALHM+brtuJjePWiYF/ClmuDr8Ch5+kg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ee-first\": \"1.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/once\": {\n      \"version\": \"1.4.0\",\n      \"resolved\": \"https://registry.npmjs.org/once/-/once-1.4.0.tgz\",\n      \"integrity\": \"sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==\",\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"wrappy\": \"1\"\n      }\n    },\n    \"node_modules/p-map\": {\n      \"version\": \"4.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/p-map/-/p-map-4.0.0.tgz\",\n      \"integrity\": \"sha512-/bjOqmgETBYB5BoEeGVea8dmvHb2m9GLy1E9W43yeyfP6QQCZGFNa+XRceJEuDB6zqr+gKpIAmlLebMpykw/MQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"aggregate-error\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/parseurl\": {\n      \"version\": \"1.3.3\",\n      \"resolved\": \"https://registry.npmjs.org/parseurl/-/parseurl-1.3.3.tgz\",\n      \"integrity\": \"sha512-CiyeOxFT/JZyN5m0z9PfXw4SCBJ6Sygz1Dpl0wqjlhDEGGBP1GnsUVEL0p63hoG1fcj3fHynXi9NYO4nWOL+qQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/path-is-absolute\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz\",\n      \"integrity\": \"sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/path-to-regexp\": {\n      \"version\": \"0.1.12\",\n      \"resolved\": \"https://registry.npmjs.org/path-to-regexp/-/path-to-regexp-0.1.12.tgz\",\n      \"integrity\": \"sha512-RA1GjUVMnvYFxuqovrEqZoxxW5NUZqbwKtYz/Tt7nXerk0LbLblQmrsgdeOxV5SFHf0UDggjS/bSeOZwt1pmEQ==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/picomatch\": {\n      \"version\": \"2.3.1\",\n      \"resolved\": \"https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz\",\n      \"integrity\": \"sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=8.6\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/jonschlinkert\"\n      }\n    },\n    \"node_modules/prebuild-install\": {\n      \"version\": \"7.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/prebuild-install/-/prebuild-install-7.1.3.tgz\",\n      \"integrity\": \"sha512-8Mf2cbV7x1cXPUILADGI3wuhfqWvtiLA1iclTDbFRZkgRQS0NqsPZphna9V+HyTEadheuPmjaJMsbzKQFOzLug==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"detect-libc\": \"^2.0.0\",\n        \"expand-template\": \"^2.0.3\",\n        \"github-from-package\": \"0.0.0\",\n        \"minimist\": \"^1.2.3\",\n        \"mkdirp-classic\": \"^0.5.3\",\n        \"napi-build-utils\": \"^2.0.0\",\n        \"node-abi\": \"^3.3.0\",\n        \"pump\": \"^3.0.0\",\n        \"rc\": \"^1.2.7\",\n        \"simple-get\": \"^4.0.0\",\n        \"tar-fs\": \"^2.0.0\",\n        \"tunnel-agent\": \"^0.6.0\"\n      },\n      \"bin\": {\n        \"prebuild-install\": \"bin.js\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/promise-inflight\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/promise-inflight/-/promise-inflight-1.0.1.tgz\",\n      \"integrity\": \"sha512-6zWPyEOFaQBJYcGMHBKTKJ3u6TBsnMFOIZSa6ce1e/ZrrsOlnHRHbabMjLiBYKp+n44X9eUI6VUPaukCXHuG4g==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/promise-retry\": {\n      \"version\": \"2.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/promise-retry/-/promise-retry-2.0.1.tgz\",\n      \"integrity\": \"sha512-y+WKFlBR8BGXnsNlIHFGPZmyDf3DFMoLhaflAnyZgV6rG6xu+JwesTo2Q9R6XwYmtmwAFCkAk3e35jEdoeh/3g==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"err-code\": \"^2.0.2\",\n        \"retry\": \"^0.12.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/proxy-addr\": {\n      \"version\": \"2.0.7\",\n      \"resolved\": \"https://registry.npmjs.org/proxy-addr/-/proxy-addr-2.0.7.tgz\",\n      \"integrity\": \"sha512-llQsMLSUDUPT44jdrU/O37qlnifitDP+ZwrmmZcoSKyLKvtZxpyV0n2/bD/N4tBAAZ/gJEdZU7KMraoK1+XYAg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"forwarded\": \"0.2.0\",\n        \"ipaddr.js\": \"1.9.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.10\"\n      }\n    },\n    \"node_modules/pstree.remy\": {\n      \"version\": \"1.1.8\",\n      \"resolved\": \"https://registry.npmjs.org/pstree.remy/-/pstree.remy-1.1.8.tgz\",\n      \"integrity\": \"sha512-77DZwxQmxKnu3aR542U+X8FypNzbfJ+C5XQDk3uWjWxn6151aIMGthWYRXTqT1E5oJvg+ljaa2OJi+VfvCOQ8w==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/pump\": {\n      \"version\": \"3.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/pump/-/pump-3.0.3.tgz\",\n      \"integrity\": \"sha512-todwxLMY7/heScKmntwQG8CXVkWUOdYxIvY2s0VWAAMh/nd8SoYiRaKjlr7+iCs984f2P8zvrfWcDDYVb73NfA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"end-of-stream\": \"^1.1.0\",\n        \"once\": \"^1.3.1\"\n      }\n    },\n    \"node_modules/qs\": {\n      \"version\": \"6.13.0\",\n      \"resolved\": \"https://registry.npmjs.org/qs/-/qs-6.13.0.tgz\",\n      \"integrity\": \"sha512-+38qI9SOr8tfZ4QmJNplMUxqjbe7LKvvZgWdExBOmd+egZTtjLB67Gu0HRX3u/XOq7UU2Nx6nsjvS16Z9uwfpg==\",\n      \"license\": \"BSD-3-Clause\",\n      \"dependencies\": {\n        \"side-channel\": \"^1.0.6\"\n      },\n      \"engines\": {\n        \"node\": \">=0.6\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/range-parser\": {\n      \"version\": \"1.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/range-parser/-/range-parser-1.2.1.tgz\",\n      \"integrity\": \"sha512-Hrgsx+orqoygnmhFbKaHE6c296J+HTAQXoxEF6gNupROmmGJRoyzfG3ccAveqCBrwr/2yxQ5BVd/GTl5agOwSg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/raw-body\": {\n      \"version\": \"2.5.2\",\n      \"resolved\": \"https://registry.npmjs.org/raw-body/-/raw-body-2.5.2.tgz\",\n      \"integrity\": \"sha512-8zGqypfENjCIqGhgXToC8aB2r7YrBX+AQAfIPs/Mlk+BtPTztOvTS01NRW/3Eh60J+a48lt8qsCzirQ6loCVfA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"bytes\": \"3.1.2\",\n        \"http-errors\": \"2.0.0\",\n        \"iconv-lite\": \"0.4.24\",\n        \"unpipe\": \"1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/rc\": {\n      \"version\": \"1.2.8\",\n      \"resolved\": \"https://registry.npmjs.org/rc/-/rc-1.2.8.tgz\",\n      \"integrity\": \"sha512-y3bGgqKj3QBdxLbLkomlohkvsA8gdAiUQlSBJnBhfn+BPxg4bc62d8TcBW15wavDfgexCgccckhcZvywyQYPOw==\",\n      \"license\": \"(BSD-2-Clause OR MIT OR Apache-2.0)\",\n      \"dependencies\": {\n        \"deep-extend\": \"^0.6.0\",\n        \"ini\": \"~1.3.0\",\n        \"minimist\": \"^1.2.0\",\n        \"strip-json-comments\": \"~2.0.1\"\n      },\n      \"bin\": {\n        \"rc\": \"cli.js\"\n      }\n    },\n    \"node_modules/readable-stream\": {\n      \"version\": \"3.6.2\",\n      \"resolved\": \"https://registry.npmjs.org/readable-stream/-/readable-stream-3.6.2.tgz\",\n      \"integrity\": \"sha512-9u/sniCrY3D5WdsERHzHE4G2YCXqoG5FTHUiCC4SIbr6XcLZBY05ya9EKjYek9O5xOAwjGq+1JdGBAS7Q9ScoA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"inherits\": \"^2.0.3\",\n        \"string_decoder\": \"^1.1.1\",\n        \"util-deprecate\": \"^1.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/readdirp\": {\n      \"version\": \"3.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz\",\n      \"integrity\": \"sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"picomatch\": \"^2.2.1\"\n      },\n      \"engines\": {\n        \"node\": \">=8.10.0\"\n      }\n    },\n    \"node_modules/retry\": {\n      \"version\": \"0.12.0\",\n      \"resolved\": \"https://registry.npmjs.org/retry/-/retry-0.12.0.tgz\",\n      \"integrity\": \"sha512-9LkiTwjUh6rT555DtE9rTX+BKByPfrMzEAtnlEtdEwr3Nkffwiihqe2bWADg+OQRjt9gl6ICdmB/ZFDCGAtSow==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">= 4\"\n      }\n    },\n    \"node_modules/rimraf\": {\n      \"version\": \"3.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz\",\n      \"integrity\": \"sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==\",\n      \"deprecated\": \"Rimraf versions prior to v4 are no longer supported\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"glob\": \"^7.1.3\"\n      },\n      \"bin\": {\n        \"rimraf\": \"bin.js\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/isaacs\"\n      }\n    },\n    \"node_modules/safe-buffer\": {\n      \"version\": \"5.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.2.1.tgz\",\n      \"integrity\": \"sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\"\n    },\n    \"node_modules/safer-buffer\": {\n      \"version\": \"2.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz\",\n      \"integrity\": \"sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/semver\": {\n      \"version\": \"7.7.2\",\n      \"resolved\": \"https://registry.npmjs.org/semver/-/semver-7.7.2.tgz\",\n      \"integrity\": \"sha512-RF0Fw+rO5AMf9MAyaRXI4AV0Ulj5lMHqVxxdSgiVbixSCXoEmmX/jk0CuJw4+3SqroYO9VoUh+HcuJivvtJemA==\",\n      \"license\": \"ISC\",\n      \"bin\": {\n        \"semver\": \"bin/semver.js\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/send\": {\n      \"version\": \"0.19.0\",\n      \"resolved\": \"https://registry.npmjs.org/send/-/send-0.19.0.tgz\",\n      \"integrity\": \"sha512-dW41u5VfLXu8SJh5bwRmyYUbAoSB3c9uQh6L8h/KtsFREPWpbX1lrljJo186Jc4nmci/sGUZ9a0a0J2zgfq2hw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"debug\": \"2.6.9\",\n        \"depd\": \"2.0.0\",\n        \"destroy\": \"1.2.0\",\n        \"encodeurl\": \"~1.0.2\",\n        \"escape-html\": \"~1.0.3\",\n        \"etag\": \"~1.8.1\",\n        \"fresh\": \"0.5.2\",\n        \"http-errors\": \"2.0.0\",\n        \"mime\": \"1.6.0\",\n        \"ms\": \"2.1.3\",\n        \"on-finished\": \"2.4.1\",\n        \"range-parser\": \"~1.2.1\",\n        \"statuses\": \"2.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8.0\"\n      }\n    },\n    \"node_modules/send/node_modules/encodeurl\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/encodeurl/-/encodeurl-1.0.2.tgz\",\n      \"integrity\": \"sha512-TPJXq8JqFaVYm2CWmPvnP2Iyo4ZSM7/QKcSmuMLDObfpH5fi7RUGmd/rTDf+rut/saiDiQEeVTNgAmJEdAOx0w==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/send/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/serve-static\": {\n      \"version\": \"1.16.2\",\n      \"resolved\": \"https://registry.npmjs.org/serve-static/-/serve-static-1.16.2.tgz\",\n      \"integrity\": \"sha512-VqpjJZKadQB/PEbEwvFdO43Ax5dFBZ2UECszz8bQ7pi7wt//PWe1P6MN7eCnjsatYtBT6EuiClbjSWP2WrIoTw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"encodeurl\": \"~2.0.0\",\n        \"escape-html\": \"~1.0.3\",\n        \"parseurl\": \"~1.3.3\",\n        \"send\": \"0.19.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8.0\"\n      }\n    },\n    \"node_modules/set-blocking\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/set-blocking/-/set-blocking-2.0.0.tgz\",\n      \"integrity\": \"sha512-KiKBS8AnWGEyLzofFfmvKwpdPzqiy16LvQfK3yv/fVH7Bj13/wl3JSR1J+rfgRE9q7xUJK4qvgS8raSOeLUehw==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/setprototypeof\": {\n      \"version\": \"1.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.2.0.tgz\",\n      \"integrity\": \"sha512-E5LDX7Wrp85Kil5bhZv46j8jOeboKq5JMmYM3gVGdGH8xFpPWXUMsNrlODCrkoxMEeNi/XZIwuRvY4XNwYMJpw==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/side-channel\": {\n      \"version\": \"1.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/side-channel/-/side-channel-1.1.0.tgz\",\n      \"integrity\": \"sha512-ZX99e6tRweoUXqR+VBrslhda51Nh5MTQwou5tnUDgbtyM0dBgmhEDtWGP/xbKn6hqfPRHujUNwz5fy/wbbhnpw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"es-errors\": \"^1.3.0\",\n        \"object-inspect\": \"^1.13.3\",\n        \"side-channel-list\": \"^1.0.0\",\n        \"side-channel-map\": \"^1.0.1\",\n        \"side-channel-weakmap\": \"^1.0.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/side-channel-list\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/side-channel-list/-/side-channel-list-1.0.0.tgz\",\n      \"integrity\": \"sha512-FCLHtRD/gnpCiCHEiJLOwdmFP+wzCmDEkc9y7NsYxeF4u7Btsn1ZuwgwJGxImImHicJArLP4R0yX4c2KCrMrTA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"es-errors\": \"^1.3.0\",\n        \"object-inspect\": \"^1.13.3\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/side-channel-map\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/side-channel-map/-/side-channel-map-1.0.1.tgz\",\n      \"integrity\": \"sha512-VCjCNfgMsby3tTdo02nbjtM/ewra6jPHmpThenkTYh8pG9ucZ/1P8So4u4FGBek/BjpOVsDCMoLA/iuBKIFXRA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bound\": \"^1.0.2\",\n        \"es-errors\": \"^1.3.0\",\n        \"get-intrinsic\": \"^1.2.5\",\n        \"object-inspect\": \"^1.13.3\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/side-channel-weakmap\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/side-channel-weakmap/-/side-channel-weakmap-1.0.2.tgz\",\n      \"integrity\": \"sha512-WPS/HvHQTYnHisLo9McqBHOJk2FkHO/tlpvldyrnem4aeQp4hai3gythswg6p01oSoTl58rcpiFAjF2br2Ak2A==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bound\": \"^1.0.2\",\n        \"es-errors\": \"^1.3.0\",\n        \"get-intrinsic\": \"^1.2.5\",\n        \"object-inspect\": \"^1.13.3\",\n        \"side-channel-map\": \"^1.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/signal-exit\": {\n      \"version\": \"3.0.7\",\n      \"resolved\": \"https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.7.tgz\",\n      \"integrity\": \"sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/simple-concat\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/simple-concat/-/simple-concat-1.0.1.tgz\",\n      \"integrity\": \"sha512-cSFtAPtRhljv69IK0hTVZQ+OfE9nePi/rtJmw5UjHeVyVroEqJXP1sFztKUy1qU+xvz3u/sfYJLa947b7nAN2Q==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\"\n    },\n    \"node_modules/simple-get\": {\n      \"version\": \"4.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/simple-get/-/simple-get-4.0.1.tgz\",\n      \"integrity\": \"sha512-brv7p5WgH0jmQJr1ZDDfKDOSeWWg+OVypG99A/5vYGPqJ6pxiaHLy8nxtFjBA7oMa01ebA9gfh1uMCFqOuXxvA==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"decompress-response\": \"^6.0.0\",\n        \"once\": \"^1.3.1\",\n        \"simple-concat\": \"^1.0.0\"\n      }\n    },\n    \"node_modules/simple-update-notifier\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/simple-update-notifier/-/simple-update-notifier-2.0.0.tgz\",\n      \"integrity\": \"sha512-a2B9Y0KlNXl9u/vsW6sTIu9vGEpfKu2wRV6l1H3XEas/0gUIzGzBoP/IouTcUQbm9JWZLH3COxyn03TYlFax6w==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"semver\": \"^7.5.3\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/smart-buffer\": {\n      \"version\": \"4.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/smart-buffer/-/smart-buffer-4.2.0.tgz\",\n      \"integrity\": \"sha512-94hK0Hh8rPqQl2xXc3HsaBoOXKV20MToPkcXvwbISWLEs+64sBq5kFgn2kJDHb1Pry9yrP0dxrCI9RRci7RXKg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">= 6.0.0\",\n        \"npm\": \">= 3.0.0\"\n      }\n    },\n    \"node_modules/socket.io\": {\n      \"version\": \"4.8.1\",\n      \"resolved\": \"https://registry.npmjs.org/socket.io/-/socket.io-4.8.1.tgz\",\n      \"integrity\": \"sha512-oZ7iUCxph8WYRHHcjBEc9unw3adt5CmSNlppj/5Q4k2RIrhl8Z5yY2Xr4j9zj0+wzVZ0bxmYoGSzKJnRl6A4yg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"accepts\": \"~1.3.4\",\n        \"base64id\": \"~2.0.0\",\n        \"cors\": \"~2.8.5\",\n        \"debug\": \"~4.3.2\",\n        \"engine.io\": \"~6.6.0\",\n        \"socket.io-adapter\": \"~2.5.2\",\n        \"socket.io-parser\": \"~4.2.4\"\n      },\n      \"engines\": {\n        \"node\": \">=10.2.0\"\n      }\n    },\n    \"node_modules/socket.io-adapter\": {\n      \"version\": \"2.5.5\",\n      \"resolved\": \"https://registry.npmjs.org/socket.io-adapter/-/socket.io-adapter-2.5.5.tgz\",\n      \"integrity\": \"sha512-eLDQas5dzPgOWCk9GuuJC2lBqItuhKI4uxGgo9aIV7MYbk2h9Q6uULEh8WBzThoI7l+qU9Ast9fVUmkqPP9wYg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"debug\": \"~4.3.4\",\n        \"ws\": \"~8.17.1\"\n      }\n    },\n    \"node_modules/socket.io-adapter/node_modules/debug\": {\n      \"version\": \"4.3.7\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.3.7.tgz\",\n      \"integrity\": \"sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/socket.io-adapter/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/socket.io-parser\": {\n      \"version\": \"4.2.4\",\n      \"resolved\": \"https://registry.npmjs.org/socket.io-parser/-/socket.io-parser-4.2.4.tgz\",\n      \"integrity\": \"sha512-/GbIKmo8ioc+NIWIhwdecY0ge+qVBSMdgxGygevmdHj24bsfgtCmcUUcQ5ZzcylGFHsN3k4HB4Cgkl96KVnuew==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@socket.io/component-emitter\": \"~3.1.0\",\n        \"debug\": \"~4.3.1\"\n      },\n      \"engines\": {\n        \"node\": \">=10.0.0\"\n      }\n    },\n    \"node_modules/socket.io-parser/node_modules/debug\": {\n      \"version\": \"4.3.7\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.3.7.tgz\",\n      \"integrity\": \"sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/socket.io-parser/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/socket.io/node_modules/debug\": {\n      \"version\": \"4.3.7\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.3.7.tgz\",\n      \"integrity\": \"sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/socket.io/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/socks\": {\n      \"version\": \"2.8.7\",\n      \"resolved\": \"https://registry.npmjs.org/socks/-/socks-2.8.7.tgz\",\n      \"integrity\": \"sha512-HLpt+uLy/pxB+bum/9DzAgiKS8CX1EvbWxI4zlmgGCExImLdiad2iCwXT5Z4c9c3Eq8rP2318mPW2c+QbtjK8A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ip-address\": \"^10.0.1\",\n        \"smart-buffer\": \"^4.2.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 10.0.0\",\n        \"npm\": \">= 3.0.0\"\n      }\n    },\n    \"node_modules/socks-proxy-agent\": {\n      \"version\": \"6.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/socks-proxy-agent/-/socks-proxy-agent-6.2.1.tgz\",\n      \"integrity\": \"sha512-a6KW9G+6B3nWZ1yB8G7pJwL3ggLy1uTzKAgCb7ttblwqdz9fMGJUuTy3uFzEP48FAs9FLILlmzDlE2JJhVQaXQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"agent-base\": \"^6.0.2\",\n        \"debug\": \"^4.3.3\",\n        \"socks\": \"^2.6.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 10\"\n      }\n    },\n    \"node_modules/socks-proxy-agent/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/socks-proxy-agent/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/sqlite\": {\n      \"version\": \"5.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/sqlite/-/sqlite-5.1.1.tgz\",\n      \"integrity\": \"sha512-oBkezXa2hnkfuJwUo44Hl9hS3er+YFtueifoajrgidvqsJRQFpc5fKoAkAor1O5ZnLoa28GBScfHXs8j0K358Q==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/sqlite3\": {\n      \"version\": \"5.1.7\",\n      \"resolved\": \"https://registry.npmjs.org/sqlite3/-/sqlite3-5.1.7.tgz\",\n      \"integrity\": \"sha512-GGIyOiFaG+TUra3JIfkI/zGP8yZYLPQ0pl1bH+ODjiX57sPhrLU5sQJn1y9bDKZUFYkX1crlrPfSYt0BKKdkog==\",\n      \"hasInstallScript\": true,\n      \"license\": \"BSD-3-Clause\",\n      \"dependencies\": {\n        \"bindings\": \"^1.5.0\",\n        \"node-addon-api\": \"^7.0.0\",\n        \"prebuild-install\": \"^7.1.1\",\n        \"tar\": \"^6.1.11\"\n      },\n      \"optionalDependencies\": {\n        \"node-gyp\": \"8.x\"\n      },\n      \"peerDependencies\": {\n        \"node-gyp\": \"8.x\"\n      },\n      \"peerDependenciesMeta\": {\n        \"node-gyp\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/ssri\": {\n      \"version\": \"8.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/ssri/-/ssri-8.0.1.tgz\",\n      \"integrity\": \"sha512-97qShzy1AiyxvPNIkLWoGua7xoQzzPjQ0HAH4B0rWKo7SZ6USuPcrUiAFrws0UH8RrbWmgq3LMTObhPIHbbBeQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/statuses\": {\n      \"version\": \"2.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/statuses/-/statuses-2.0.1.tgz\",\n      \"integrity\": \"sha512-RwNA9Z/7PrK06rYLIzFMlaF+l73iwpzsqRIFgbMLbTcLD6cOao82TaWefPXQvB2fOC4AjuYSEndS7N/mTCbkdQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/string_decoder\": {\n      \"version\": \"1.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/string_decoder/-/string_decoder-1.3.0.tgz\",\n      \"integrity\": \"sha512-hkRX8U1WjJFd8LsDJ2yQ/wWWxaopEsABU1XfkM8A+j0+85JAGppt16cr1Whg6KIbb4okU6Mql6BOj+uup/wKeA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"safe-buffer\": \"~5.2.0\"\n      }\n    },\n    \"node_modules/string-width\": {\n      \"version\": \"4.2.3\",\n      \"resolved\": \"https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz\",\n      \"integrity\": \"sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"emoji-regex\": \"^8.0.0\",\n        \"is-fullwidth-code-point\": \"^3.0.0\",\n        \"strip-ansi\": \"^6.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/strip-ansi\": {\n      \"version\": \"6.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz\",\n      \"integrity\": \"sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ansi-regex\": \"^5.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/strip-json-comments\": {\n      \"version\": \"2.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-2.0.1.tgz\",\n      \"integrity\": \"sha512-4gB8na07fecVVkOI6Rs4e7T6NOTki5EmL7TUduTs6bu3EdnSycntVJ4re8kgZA+wx9IueI2Y11bfbgwtzuE0KQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/supports-color\": {\n      \"version\": \"5.5.0\",\n      \"resolved\": \"https://registry.npmjs.org/supports-color/-/supports-color-5.5.0.tgz\",\n      \"integrity\": \"sha512-QjVjwdXIt408MIiAqCX4oUKsgU2EqAGzs2Ppkm4aQYbjm+ZEWEcW4SfFNTr4uMNZma0ey4f5lgLrkB0aX0QMow==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"has-flag\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=4\"\n      }\n    },\n    \"node_modules/tar\": {\n      \"version\": \"6.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/tar/-/tar-6.2.1.tgz\",\n      \"integrity\": \"sha512-DZ4yORTwrbTj/7MZYq2w+/ZFdI6OZ/f9SFHR+71gIVUZhOQPHzVCLpvRnPgyaMpfWxxk/4ONva3GQSyNIKRv6A==\",\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"chownr\": \"^2.0.0\",\n        \"fs-minipass\": \"^2.0.0\",\n        \"minipass\": \"^5.0.0\",\n        \"minizlib\": \"^2.1.1\",\n        \"mkdirp\": \"^1.0.3\",\n        \"yallist\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/tar-fs\": {\n      \"version\": \"2.1.4\",\n      \"resolved\": \"https://registry.npmjs.org/tar-fs/-/tar-fs-2.1.4.tgz\",\n      \"integrity\": \"sha512-mDAjwmZdh7LTT6pNleZ05Yt65HC3E+NiQzl672vQG38jIrehtJk/J3mNwIg+vShQPcLF/LV7CMnDW6vjj6sfYQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"chownr\": \"^1.1.1\",\n        \"mkdirp-classic\": \"^0.5.2\",\n        \"pump\": \"^3.0.0\",\n        \"tar-stream\": \"^2.1.4\"\n      }\n    },\n    \"node_modules/tar-fs/node_modules/chownr\": {\n      \"version\": \"1.1.4\",\n      \"resolved\": \"https://registry.npmjs.org/chownr/-/chownr-1.1.4.tgz\",\n      \"integrity\": \"sha512-jJ0bqzaylmJtVnNgzTeSOs8DPavpbYgEr/b0YL8/2GO3xJEhInFmhKMUnEJQjZumK7KXGFhUy89PrsJWlakBVg==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/tar-stream\": {\n      \"version\": \"2.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/tar-stream/-/tar-stream-2.2.0.tgz\",\n      \"integrity\": \"sha512-ujeqbceABgwMZxEJnk2HDY2DlnUZ+9oEcb1KzTVfYHio0UE6dG71n60d8D2I4qNvleWrrXpmjpt7vZeF1LnMZQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"bl\": \"^4.0.3\",\n        \"end-of-stream\": \"^1.4.1\",\n        \"fs-constants\": \"^1.0.0\",\n        \"inherits\": \"^2.0.3\",\n        \"readable-stream\": \"^3.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/tar/node_modules/minipass\": {\n      \"version\": \"5.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/minipass/-/minipass-5.0.0.tgz\",\n      \"integrity\": \"sha512-3FnjYuehv9k6ovOEbyOswadCDPX1piCfhV8ncmYtHOjuPwylVWsghTLo7rabjC3Rx5xD4HDx8Wm1xnMF7S5qFQ==\",\n      \"license\": \"ISC\",\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/to-regex-range\": {\n      \"version\": \"5.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz\",\n      \"integrity\": \"sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"is-number\": \"^7.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8.0\"\n      }\n    },\n    \"node_modules/toidentifier\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/toidentifier/-/toidentifier-1.0.1.tgz\",\n      \"integrity\": \"sha512-o5sSPKEkg/DIQNmH43V0/uerLrpzVedkUh8tGNvaeXpfpuwjKenlSox/2O/BTlZUtEe+JG7s5YhEz608PlAHRA==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.6\"\n      }\n    },\n    \"node_modules/touch\": {\n      \"version\": \"3.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/touch/-/touch-3.1.1.tgz\",\n      \"integrity\": \"sha512-r0eojU4bI8MnHr8c5bNo7lJDdI2qXlWWJk6a9EAFG7vbhTjElYhBVS3/miuE0uOuoLdb8Mc/rVfsmm6eo5o9GA==\",\n      \"dev\": true,\n      \"license\": \"ISC\",\n      \"bin\": {\n        \"nodetouch\": \"bin/nodetouch.js\"\n      }\n    },\n    \"node_modules/ts-node\": {\n      \"version\": \"10.9.2\",\n      \"resolved\": \"https://registry.npmjs.org/ts-node/-/ts-node-10.9.2.tgz\",\n      \"integrity\": \"sha512-f0FFpIdcHgn8zcPSbf1dRevwt047YMnaiJM3u2w2RewrB+fob/zePZcrOyQoLMMO7aBIddLcQIEK5dYjkLnGrQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@cspotcode/source-map-support\": \"^0.8.0\",\n        \"@tsconfig/node10\": \"^1.0.7\",\n        \"@tsconfig/node12\": \"^1.0.7\",\n        \"@tsconfig/node14\": \"^1.0.0\",\n        \"@tsconfig/node16\": \"^1.0.2\",\n        \"acorn\": \"^8.4.1\",\n        \"acorn-walk\": \"^8.1.1\",\n        \"arg\": \"^4.1.0\",\n        \"create-require\": \"^1.1.0\",\n        \"diff\": \"^4.0.1\",\n        \"make-error\": \"^1.1.1\",\n        \"v8-compile-cache-lib\": \"^3.0.1\",\n        \"yn\": \"3.1.1\"\n      },\n      \"bin\": {\n        \"ts-node\": \"dist/bin.js\",\n        \"ts-node-cwd\": \"dist/bin-cwd.js\",\n        \"ts-node-esm\": \"dist/bin-esm.js\",\n        \"ts-node-script\": \"dist/bin-script.js\",\n        \"ts-node-transpile-only\": \"dist/bin-transpile.js\",\n        \"ts-script\": \"dist/bin-script-deprecated.js\"\n      },\n      \"peerDependencies\": {\n        \"@swc/core\": \">=1.2.50\",\n        \"@swc/wasm\": \">=1.2.50\",\n        \"@types/node\": \"*\",\n        \"typescript\": \">=2.7\"\n      },\n      \"peerDependenciesMeta\": {\n        \"@swc/core\": {\n          \"optional\": true\n        },\n        \"@swc/wasm\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/tunnel-agent\": {\n      \"version\": \"0.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/tunnel-agent/-/tunnel-agent-0.6.0.tgz\",\n      \"integrity\": \"sha512-McnNiV1l8RYeY8tBgEpuodCC1mLUdbSN+CYBL7kJsJNInOP8UjDDEwdk6Mw60vdLLrr5NHKZhMAOSrR2NZuQ+w==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"safe-buffer\": \"^5.0.1\"\n      },\n      \"engines\": {\n        \"node\": \"*\"\n      }\n    },\n    \"node_modules/type-is\": {\n      \"version\": \"1.6.18\",\n      \"resolved\": \"https://registry.npmjs.org/type-is/-/type-is-1.6.18.tgz\",\n      \"integrity\": \"sha512-TkRKr9sUTxEH8MdfuCSP7VizJyzRNMjj2J2do2Jr3Kym598JVdEksuzPQCnlFPW4ky9Q+iA+ma9BGm06XQBy8g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"media-typer\": \"0.3.0\",\n        \"mime-types\": \"~2.1.24\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/typescript\": {\n      \"version\": \"5.9.2\",\n      \"resolved\": \"https://registry.npmjs.org/typescript/-/typescript-5.9.2.tgz\",\n      \"integrity\": \"sha512-CWBzXQrc/qOkhidw1OzBTQuYRbfyxDXJMVJ1XNwUHGROVmuaeiEm3OslpZ1RV96d7SKKjZKrSJu3+t/xlw3R9A==\",\n      \"dev\": true,\n      \"license\": \"Apache-2.0\",\n      \"bin\": {\n        \"tsc\": \"bin/tsc\",\n        \"tsserver\": \"bin/tsserver\"\n      },\n      \"engines\": {\n        \"node\": \">=14.17\"\n      }\n    },\n    \"node_modules/undefsafe\": {\n      \"version\": \"2.0.5\",\n      \"resolved\": \"https://registry.npmjs.org/undefsafe/-/undefsafe-2.0.5.tgz\",\n      \"integrity\": \"sha512-WxONCrssBM8TSPRqN5EmsjVrsv4A8X12J4ArBiiayv3DyyG3ZlIg6yysuuSYdZsVz3TKcTg2fd//Ujd4CHV1iA==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/undici-types\": {\n      \"version\": \"7.12.0\",\n      \"resolved\": \"https://registry.npmjs.org/undici-types/-/undici-types-7.12.0.tgz\",\n      \"integrity\": \"sha512-goOacqME2GYyOZZfb5Lgtu+1IDmAlAEu5xnD3+xTzS10hT0vzpf0SPjkXwAw9Jm+4n/mQGDP3LO8CPbYROeBfQ==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/unique-filename\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/unique-filename/-/unique-filename-1.1.1.tgz\",\n      \"integrity\": \"sha512-Vmp0jIp2ln35UTXuryvjzkjGdRyf9b2lTXuSYUiPmzRcl3FDtYqAwOnTJkAngD9SWhnoJzDbTKwaOrZ+STtxNQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"unique-slug\": \"^2.0.0\"\n      }\n    },\n    \"node_modules/unique-slug\": {\n      \"version\": \"2.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/unique-slug/-/unique-slug-2.0.2.tgz\",\n      \"integrity\": \"sha512-zoWr9ObaxALD3DOPfjPSqxt4fnZiWblxHIgeWqW8x7UqDzEtHEQLzji2cuJYQFCU6KmoJikOYAZlrTHHebjx2w==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"imurmurhash\": \"^0.1.4\"\n      }\n    },\n    \"node_modules/unpipe\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/unpipe/-/unpipe-1.0.0.tgz\",\n      \"integrity\": \"sha512-pjy2bYhSsufwWlKwPc+l3cN7+wuJlK6uz0YdJEOlQDbl6jo/YlPi4mb8agUkVC8BF7V8NuzeyPNqRksA3hztKQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/util-deprecate\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz\",\n      \"integrity\": \"sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/utils-merge\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/utils-merge/-/utils-merge-1.0.1.tgz\",\n      \"integrity\": \"sha512-pMZTvIkT1d+TFGvDOqodOclx0QWkkgi6Tdoa8gC8ffGAAqz9pzPTZWAybbsHHoED/ztMtkv/VoYTYyShUn81hA==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4.0\"\n      }\n    },\n    \"node_modules/v8-compile-cache-lib\": {\n      \"version\": \"3.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/v8-compile-cache-lib/-/v8-compile-cache-lib-3.0.1.tgz\",\n      \"integrity\": \"sha512-wa7YjyUGfNZngI/vtK0UHAN+lgDCxBPCylVXGp0zu59Fz5aiGtNXaq3DhIov063MorB+VfufLh3JlF2KdTK3xg==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/vary\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/vary/-/vary-1.1.2.tgz\",\n      \"integrity\": \"sha512-BNGbWLfd0eUPabhkXUVm0j8uuvREyTh5ovRa/dyow/BqAbZJyC+5fU+IzQOzmAKzYqYRAISoRhdQr3eIZ/PXqg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/which\": {\n      \"version\": \"2.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/which/-/which-2.0.2.tgz\",\n      \"integrity\": \"sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"isexe\": \"^2.0.0\"\n      },\n      \"bin\": {\n        \"node-which\": \"bin/node-which\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/wide-align\": {\n      \"version\": \"1.1.5\",\n      \"resolved\": \"https://registry.npmjs.org/wide-align/-/wide-align-1.1.5.tgz\",\n      \"integrity\": \"sha512-eDMORYaPNZ4sQIuuYPDHdQvf4gyCF9rEEV/yPxGfwPkRodwEgiMUUXTx/dex+Me0wxx53S+NgUHaP7y3MGlDmg==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"string-width\": \"^1.0.2 || 2 || 3 || 4\"\n      }\n    },\n    \"node_modules/wrappy\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz\",\n      \"integrity\": \"sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/ws\": {\n      \"version\": \"8.17.1\",\n      \"resolved\": \"https://registry.npmjs.org/ws/-/ws-8.17.1.tgz\",\n      \"integrity\": \"sha512-6XQFvXTkbfUOZOKKILFG1PDK2NDQs4azKQl26T0YS5CxqWLgXajbPZ+h4gZekJyRqFU8pvnbAbbs/3TgRPy+GQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=10.0.0\"\n      },\n      \"peerDependencies\": {\n        \"bufferutil\": \"^4.0.1\",\n        \"utf-8-validate\": \">=5.0.2\"\n      },\n      \"peerDependenciesMeta\": {\n        \"bufferutil\": {\n          \"optional\": true\n        },\n        \"utf-8-validate\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/yallist\": {\n      \"version\": \"4.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/yallist/-/yallist-4.0.0.tgz\",\n      \"integrity\": \"sha512-3wdGidZyq5PB084XLES5TpOSRA3wjXAlIWMhum2kRcv/41Sn2emQ0dycQW4uZXLejwKvg6EsvbdlVL+FYEct7A==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/yn\": {\n      \"version\": \"3.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/yn/-/yn-3.1.1.tgz\",\n      \"integrity\": \"sha512-Ux4ygGWsu2c7isFWe8Yu1YluJmqVhxqK2cLXNQA5AcC3QfbGNpM7fu0Y8b/z16pXLnFxZYvWhd3fhBY9DLmC6Q==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    }\n  }\n}\n",
    "web_platform/api_gateway/package.json": "{\n  \"name\": \"api_gateway\",\n  \"version\": \"1.0.0\",\n  \"main\": \"dist/server.js\",\n  \"scripts\": { \"start\": \"ts-node src/server.ts\" },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"dotenv\": \"^16.3.1\",\n    \"dotenv\": \"^16.3.1\",\n    \"sqlite\": \"^5.1.1\",\n    \"sqlite3\": \"^5.1.7\",\n    \"socket.io\": \"^4.7.4\",\n    \"cors\": \"^2.8.5\"\n  },\n  \"devDependencies\": {\n    \"@types/express\": \"^4.17.21\",\n    \"@types/node\": \"^20.10.0\",\n    \"@types/cors\": \"^2.8.17\",\n    \"ts-node\": \"^10.9.2\",\n    \"typescript\": \"^5.3.3\"\n  }\n}",
    "web_platform/api_gateway/src/services/DatabaseService.ts": "import sqlite3 from 'sqlite3';\nimport { open, Database } from 'sqlite';\nimport path from 'path';\n\nexport class DatabaseService {\n  private db: Database | null = null;\n\n  private async getDb(): Promise<Database> {\n    if (!this.db) {\n      const dbPath = process.env.FORTUNA_DB_PATH || path.join(process.cwd(), '../../../../shared_database/races.db');\n      this.db = await open({\n        filename: dbPath,\n        driver: sqlite3.Database\n      });\n    }\n    return this.db;\n  }\n\n  async getQualifiedRaces(): Promise<any[]> {\n    const db = await this.getDb();\n    return db.all(`SELECT * FROM qualified_races`);\n  }\n}\n",
    "web_platform/frontend/app/page.tsx": "'use client';\nimport dynamic from 'next/dynamic';\nimport React from 'react';\nimport { Tabs } from '../src/components/Tabs';\nimport { SettingsPage } from '../src/components/SettingsPage';\n\nconst LiveRaceDashboard = dynamic(\n  () => import('../src/components/LiveRaceDashboard').then((mod) => mod.LiveRaceDashboard),\n  {\n    ssr: false,\n    loading: () => <p className=\"text-center text-xl mt-8\">Loading Dashboard...</p>\n  }\n);\n\nexport default function Home() {\n  const tabs = [\n    {\n      label: 'Dashboard',\n      content: <LiveRaceDashboard />,\n    },\n    {\n      label: 'Settings',\n      content: <SettingsPage />,\n    },\n  ];\n\n  return (\n    <main className=\"min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 p-8\">\n      <div className=\"max-w-7xl mx-auto space-y-8\">\n        <h1 className=\"text-4xl font-bold text-white\">Fortuna Faucet</h1>\n        <Tabs tabs={tabs} />\n      </div>\n    </main>\n  );\n}\n",
    "web_platform/frontend/public/workbox-4754cb34.js": "define([\"exports\"],function(t){\"use strict\";try{self[\"workbox:core:6.5.4\"]&&_()}catch(t){}const e=(t,...e)=>{let s=t;return e.length>0&&(s+=` :: ${JSON.stringify(e)}`),s};class s extends Error{constructor(t,s){super(e(t,s)),this.name=t,this.details=s}}try{self[\"workbox:routing:6.5.4\"]&&_()}catch(t){}const n=t=>t&&\"object\"==typeof t?t:{handle:t};class r{constructor(t,e,s=\"GET\"){this.handler=n(e),this.match=t,this.method=s}setCatchHandler(t){this.catchHandler=n(t)}}class i extends r{constructor(t,e,s){super(({url:e})=>{const s=t.exec(e.href);if(s&&(e.origin===location.origin||0===s.index))return s.slice(1)},e,s)}}class a{constructor(){this.t=new Map,this.i=new Map}get routes(){return this.t}addFetchListener(){self.addEventListener(\"fetch\",t=>{const{request:e}=t,s=this.handleRequest({request:e,event:t});s&&t.respondWith(s)})}addCacheListener(){self.addEventListener(\"message\",t=>{if(t.data&&\"CACHE_URLS\"===t.data.type){const{payload:e}=t.data,s=Promise.all(e.urlsToCache.map(e=>{\"string\"==typeof e&&(e=[e]);const s=new Request(...e);return this.handleRequest({request:s,event:t})}));t.waitUntil(s),t.ports&&t.ports[0]&&s.then(()=>t.ports[0].postMessage(!0))}})}handleRequest({request:t,event:e}){const s=new URL(t.url,location.href);if(!s.protocol.startsWith(\"http\"))return;const n=s.origin===location.origin,{params:r,route:i}=this.findMatchingRoute({event:e,request:t,sameOrigin:n,url:s});let a=i&&i.handler;const o=t.method;if(!a&&this.i.has(o)&&(a=this.i.get(o)),!a)return;let c;try{c=a.handle({url:s,request:t,event:e,params:r})}catch(t){c=Promise.reject(t)}const h=i&&i.catchHandler;return c instanceof Promise&&(this.o||h)&&(c=c.catch(async n=>{if(h)try{return await h.handle({url:s,request:t,event:e,params:r})}catch(t){t instanceof Error&&(n=t)}if(this.o)return this.o.handle({url:s,request:t,event:e});throw n})),c}findMatchingRoute({url:t,sameOrigin:e,request:s,event:n}){const r=this.t.get(s.method)||[];for(const i of r){let r;const a=i.match({url:t,sameOrigin:e,request:s,event:n});if(a)return r=a,(Array.isArray(r)&&0===r.length||a.constructor===Object&&0===Object.keys(a).length||\"boolean\"==typeof a)&&(r=void 0),{route:i,params:r}}return{}}setDefaultHandler(t,e=\"GET\"){this.i.set(e,n(t))}setCatchHandler(t){this.o=n(t)}registerRoute(t){this.t.has(t.method)||this.t.set(t.method,[]),this.t.get(t.method).push(t)}unregisterRoute(t){if(!this.t.has(t.method))throw new s(\"unregister-route-but-not-found-with-method\",{method:t.method});const e=this.t.get(t.method).indexOf(t);if(!(e>-1))throw new s(\"unregister-route-route-not-registered\");this.t.get(t.method).splice(e,1)}}let o;const c=()=>(o||(o=new a,o.addFetchListener(),o.addCacheListener()),o);function h(t,e,n){let a;if(\"string\"==typeof t){const s=new URL(t,location.href);a=new r(({url:t})=>t.href===s.href,e,n)}else if(t instanceof RegExp)a=new i(t,e,n);else if(\"function\"==typeof t)a=new r(t,e,n);else{if(!(t instanceof r))throw new s(\"unsupported-route-type\",{moduleName:\"workbox-routing\",funcName:\"registerRoute\",paramName:\"capture\"});a=t}return c().registerRoute(a),a}try{self[\"workbox:strategies:6.5.4\"]&&_()}catch(t){}const u={cacheWillUpdate:async({response:t})=>200===t.status||0===t.status?t:null},l={googleAnalytics:\"googleAnalytics\",precache:\"precache-v2\",prefix:\"workbox\",runtime:\"runtime\",suffix:\"undefined\"!=typeof registration?registration.scope:\"\"},f=t=>[l.prefix,t,l.suffix].filter(t=>t&&t.length>0).join(\"-\"),w=t=>t||f(l.precache),d=t=>t||f(l.runtime);function p(t,e){const s=new URL(t);for(const t of e)s.searchParams.delete(t);return s.href}class y{constructor(){this.promise=new Promise((t,e)=>{this.resolve=t,this.reject=e})}}const g=new Set;function m(t){return\"string\"==typeof t?new Request(t):t}class v{constructor(t,e){this.h={},Object.assign(this,e),this.event=e.event,this.u=t,this.l=new y,this.p=[],this.m=[...t.plugins],this.v=new Map;for(const t of this.m)this.v.set(t,{});this.event.waitUntil(this.l.promise)}async fetch(t){const{event:e}=this;let n=m(t);if(\"navigate\"===n.mode&&e instanceof FetchEvent&&e.preloadResponse){const t=await e.preloadResponse;if(t)return t}const r=this.hasCallback(\"fetchDidFail\")?n.clone():null;try{for(const t of this.iterateCallbacks(\"requestWillFetch\"))n=await t({request:n.clone(),event:e})}catch(t){if(t instanceof Error)throw new s(\"plugin-error-request-will-fetch\",{thrownErrorMessage:t.message})}const i=n.clone();try{let t;t=await fetch(n,\"navigate\"===n.mode?void 0:this.u.fetchOptions);for(const s of this.iterateCallbacks(\"fetchDidSucceed\"))t=await s({event:e,request:i,response:t});return t}catch(t){throw r&&await this.runCallbacks(\"fetchDidFail\",{error:t,event:e,originalRequest:r.clone(),request:i.clone()}),t}}async fetchAndCachePut(t){const e=await this.fetch(t),s=e.clone();return this.waitUntil(this.cachePut(t,s)),e}async cacheMatch(t){const e=m(t);let s;const{cacheName:n,matchOptions:r}=this.u,i=await this.getCacheKey(e,\"read\"),a=Object.assign(Object.assign({},r),{cacheName:n});s=await caches.match(i,a);for(const t of this.iterateCallbacks(\"cachedResponseWillBeUsed\"))s=await t({cacheName:n,matchOptions:r,cachedResponse:s,request:i,event:this.event})||void 0;return s}async cachePut(t,e){const n=m(t);var r;await(r=0,new Promise(t=>setTimeout(t,r)));const i=await this.getCacheKey(n,\"write\");if(!e)throw new s(\"cache-put-with-no-response\",{url:(a=i.url,new URL(String(a),location.href).href.replace(new RegExp(`^${location.origin}`),\"\"))});var a;const o=await this.R(e);if(!o)return!1;const{cacheName:c,matchOptions:h}=this.u,u=await self.caches.open(c),l=this.hasCallback(\"cacheDidUpdate\"),f=l?await async function(t,e,s,n){const r=p(e.url,s);if(e.url===r)return t.match(e,n);const i=Object.assign(Object.assign({},n),{ignoreSearch:!0}),a=await t.keys(e,i);for(const e of a)if(r===p(e.url,s))return t.match(e,n)}(u,i.clone(),[\"__WB_REVISION__\"],h):null;try{await u.put(i,l?o.clone():o)}catch(t){if(t instanceof Error)throw\"QuotaExceededError\"===t.name&&await async function(){for(const t of g)await t()}(),t}for(const t of this.iterateCallbacks(\"cacheDidUpdate\"))await t({cacheName:c,oldResponse:f,newResponse:o.clone(),request:i,event:this.event});return!0}async getCacheKey(t,e){const s=`${t.url} | ${e}`;if(!this.h[s]){let n=t;for(const t of this.iterateCallbacks(\"cacheKeyWillBeUsed\"))n=m(await t({mode:e,request:n,event:this.event,params:this.params}));this.h[s]=n}return this.h[s]}hasCallback(t){for(const e of this.u.plugins)if(t in e)return!0;return!1}async runCallbacks(t,e){for(const s of this.iterateCallbacks(t))await s(e)}*iterateCallbacks(t){for(const e of this.u.plugins)if(\"function\"==typeof e[t]){const s=this.v.get(e),n=n=>{const r=Object.assign(Object.assign({},n),{state:s});return e[t](r)};yield n}}waitUntil(t){return this.p.push(t),t}async doneWaiting(){let t;for(;t=this.p.shift();)await t}destroy(){this.l.resolve(null)}async R(t){let e=t,s=!1;for(const t of this.iterateCallbacks(\"cacheWillUpdate\"))if(e=await t({request:this.request,response:e,event:this.event})||void 0,s=!0,!e)break;return s||e&&200!==e.status&&(e=void 0),e}}class R{constructor(t={}){this.cacheName=d(t.cacheName),this.plugins=t.plugins||[],this.fetchOptions=t.fetchOptions,this.matchOptions=t.matchOptions}handle(t){const[e]=this.handleAll(t);return e}handleAll(t){t instanceof FetchEvent&&(t={event:t,request:t.request});const e=t.event,s=\"string\"==typeof t.request?new Request(t.request):t.request,n=\"params\"in t?t.params:void 0,r=new v(this,{event:e,request:s,params:n}),i=this.q(r,s,e);return[i,this.D(i,r,s,e)]}async q(t,e,n){let r;await t.runCallbacks(\"handlerWillStart\",{event:n,request:e});try{if(r=await this.U(e,t),!r||\"error\"===r.type)throw new s(\"no-response\",{url:e.url})}catch(s){if(s instanceof Error)for(const i of t.iterateCallbacks(\"handlerDidError\"))if(r=await i({error:s,event:n,request:e}),r)break;if(!r)throw s}for(const s of t.iterateCallbacks(\"handlerWillRespond\"))r=await s({event:n,request:e,response:r});return r}async D(t,e,s,n){let r,i;try{r=await t}catch(i){}try{await e.runCallbacks(\"handlerDidRespond\",{event:n,request:s,response:r}),await e.doneWaiting()}catch(t){t instanceof Error&&(i=t)}if(await e.runCallbacks(\"handlerDidComplete\",{event:n,request:s,response:r,error:i}),e.destroy(),i)throw i}}function b(t){t.then(()=>{})}function q(){return q=Object.assign?Object.assign.bind():function(t){for(var e=1;e<arguments.length;e++){var s=arguments[e];for(var n in s)({}).hasOwnProperty.call(s,n)&&(t[n]=s[n])}return t},q.apply(null,arguments)}let D,U;const x=new WeakMap,L=new WeakMap,I=new WeakMap,C=new WeakMap,E=new WeakMap;let N={get(t,e,s){if(t instanceof IDBTransaction){if(\"done\"===e)return L.get(t);if(\"objectStoreNames\"===e)return t.objectStoreNames||I.get(t);if(\"store\"===e)return s.objectStoreNames[1]?void 0:s.objectStore(s.objectStoreNames[0])}return k(t[e])},set:(t,e,s)=>(t[e]=s,!0),has:(t,e)=>t instanceof IDBTransaction&&(\"done\"===e||\"store\"===e)||e in t};function O(t){return t!==IDBDatabase.prototype.transaction||\"objectStoreNames\"in IDBTransaction.prototype?(U||(U=[IDBCursor.prototype.advance,IDBCursor.prototype.continue,IDBCursor.prototype.continuePrimaryKey])).includes(t)?function(...e){return t.apply(B(this),e),k(x.get(this))}:function(...e){return k(t.apply(B(this),e))}:function(e,...s){const n=t.call(B(this),e,...s);return I.set(n,e.sort?e.sort():[e]),k(n)}}function T(t){return\"function\"==typeof t?O(t):(t instanceof IDBTransaction&&function(t){if(L.has(t))return;const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"complete\",r),t.removeEventListener(\"error\",i),t.removeEventListener(\"abort\",i)},r=()=>{e(),n()},i=()=>{s(t.error||new DOMException(\"AbortError\",\"AbortError\")),n()};t.addEventListener(\"complete\",r),t.addEventListener(\"error\",i),t.addEventListener(\"abort\",i)});L.set(t,e)}(t),e=t,(D||(D=[IDBDatabase,IDBObjectStore,IDBIndex,IDBCursor,IDBTransaction])).some(t=>e instanceof t)?new Proxy(t,N):t);var e}function k(t){if(t instanceof IDBRequest)return function(t){const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"success\",r),t.removeEventListener(\"error\",i)},r=()=>{e(k(t.result)),n()},i=()=>{s(t.error),n()};t.addEventListener(\"success\",r),t.addEventListener(\"error\",i)});return e.then(e=>{e instanceof IDBCursor&&x.set(e,t)}).catch(()=>{}),E.set(e,t),e}(t);if(C.has(t))return C.get(t);const e=T(t);return e!==t&&(C.set(t,e),E.set(e,t)),e}const B=t=>E.get(t);const P=[\"get\",\"getKey\",\"getAll\",\"getAllKeys\",\"count\"],M=[\"put\",\"add\",\"delete\",\"clear\"],W=new Map;function j(t,e){if(!(t instanceof IDBDatabase)||e in t||\"string\"!=typeof e)return;if(W.get(e))return W.get(e);const s=e.replace(/FromIndex$/,\"\"),n=e!==s,r=M.includes(s);if(!(s in(n?IDBIndex:IDBObjectStore).prototype)||!r&&!P.includes(s))return;const i=async function(t,...e){const i=this.transaction(t,r?\"readwrite\":\"readonly\");let a=i.store;return n&&(a=a.index(e.shift())),(await Promise.all([a[s](...e),r&&i.done]))[0]};return W.set(e,i),i}N=(t=>q({},t,{get:(e,s,n)=>j(e,s)||t.get(e,s,n),has:(e,s)=>!!j(e,s)||t.has(e,s)}))(N);try{self[\"workbox:expiration:6.5.4\"]&&_()}catch(t){}const S=\"cache-entries\",K=t=>{const e=new URL(t,location.href);return e.hash=\"\",e.href};class A{constructor(t){this._=null,this.L=t}I(t){const e=t.createObjectStore(S,{keyPath:\"id\"});e.createIndex(\"cacheName\",\"cacheName\",{unique:!1}),e.createIndex(\"timestamp\",\"timestamp\",{unique:!1})}C(t){this.I(t),this.L&&function(t,{blocked:e}={}){const s=indexedDB.deleteDatabase(t);e&&s.addEventListener(\"blocked\",t=>e(t.oldVersion,t)),k(s).then(()=>{})}(this.L)}async setTimestamp(t,e){const s={url:t=K(t),timestamp:e,cacheName:this.L,id:this.N(t)},n=(await this.getDb()).transaction(S,\"readwrite\",{durability:\"relaxed\"});await n.store.put(s),await n.done}async getTimestamp(t){const e=await this.getDb(),s=await e.get(S,this.N(t));return null==s?void 0:s.timestamp}async expireEntries(t,e){const s=await this.getDb();let n=await s.transaction(S).store.index(\"timestamp\").openCursor(null,\"prev\");const r=[];let i=0;for(;n;){const s=n.value;s.cacheName===this.L&&(t&&s.timestamp<t||e&&i>=e?r.push(n.value):i++),n=await n.continue()}const a=[];for(const t of r)await s.delete(S,t.id),a.push(t.url);return a}N(t){return this.L+\"|\"+K(t)}async getDb(){return this._||(this._=await function(t,e,{blocked:s,upgrade:n,blocking:r,terminated:i}={}){const a=indexedDB.open(t,e),o=k(a);return n&&a.addEventListener(\"upgradeneeded\",t=>{n(k(a.result),t.oldVersion,t.newVersion,k(a.transaction),t)}),s&&a.addEventListener(\"blocked\",t=>s(t.oldVersion,t.newVersion,t)),o.then(t=>{i&&t.addEventListener(\"close\",()=>i()),r&&t.addEventListener(\"versionchange\",t=>r(t.oldVersion,t.newVersion,t))}).catch(()=>{}),o}(\"workbox-expiration\",1,{upgrade:this.C.bind(this)})),this._}}class F{constructor(t,e={}){this.O=!1,this.T=!1,this.k=e.maxEntries,this.B=e.maxAgeSeconds,this.P=e.matchOptions,this.L=t,this.M=new A(t)}async expireEntries(){if(this.O)return void(this.T=!0);this.O=!0;const t=this.B?Date.now()-1e3*this.B:0,e=await this.M.expireEntries(t,this.k),s=await self.caches.open(this.L);for(const t of e)await s.delete(t,this.P);this.O=!1,this.T&&(this.T=!1,b(this.expireEntries()))}async updateTimestamp(t){await this.M.setTimestamp(t,Date.now())}async isURLExpired(t){if(this.B){const e=await this.M.getTimestamp(t),s=Date.now()-1e3*this.B;return void 0===e||e<s}return!1}async delete(){this.T=!1,await this.M.expireEntries(1/0)}}try{self[\"workbox:range-requests:6.5.4\"]&&_()}catch(t){}async function H(t,e){try{if(206===e.status)return e;const n=t.headers.get(\"range\");if(!n)throw new s(\"no-range-header\");const r=function(t){const e=t.trim().toLowerCase();if(!e.startsWith(\"bytes=\"))throw new s(\"unit-must-be-bytes\",{normalizedRangeHeader:e});if(e.includes(\",\"))throw new s(\"single-range-only\",{normalizedRangeHeader:e});const n=/(\\d*)-(\\d*)/.exec(e);if(!n||!n[1]&&!n[2])throw new s(\"invalid-range-values\",{normalizedRangeHeader:e});return{start:\"\"===n[1]?void 0:Number(n[1]),end:\"\"===n[2]?void 0:Number(n[2])}}(n),i=await e.blob(),a=function(t,e,n){const r=t.size;if(n&&n>r||e&&e<0)throw new s(\"range-not-satisfiable\",{size:r,end:n,start:e});let i,a;return void 0!==e&&void 0!==n?(i=e,a=n+1):void 0!==e&&void 0===n?(i=e,a=r):void 0!==n&&void 0===e&&(i=r-n,a=r),{start:i,end:a}}(i,r.start,r.end),o=i.slice(a.start,a.end),c=o.size,h=new Response(o,{status:206,statusText:\"Partial Content\",headers:e.headers});return h.headers.set(\"Content-Length\",String(c)),h.headers.set(\"Content-Range\",`bytes ${a.start}-${a.end-1}/${i.size}`),h}catch(t){return new Response(\"\",{status:416,statusText:\"Range Not Satisfiable\"})}}function $(t,e){const s=e();return t.waitUntil(s),s}try{self[\"workbox:precaching:6.5.4\"]&&_()}catch(t){}function z(t){if(!t)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(\"string\"==typeof t){const e=new URL(t,location.href);return{cacheKey:e.href,url:e.href}}const{revision:e,url:n}=t;if(!n)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(!e){const t=new URL(n,location.href);return{cacheKey:t.href,url:t.href}}const r=new URL(n,location.href),i=new URL(n,location.href);return r.searchParams.set(\"__WB_REVISION__\",e),{cacheKey:r.href,url:i.href}}class G{constructor(){this.updatedURLs=[],this.notUpdatedURLs=[],this.handlerWillStart=async({request:t,state:e})=>{e&&(e.originalRequest=t)},this.cachedResponseWillBeUsed=async({event:t,state:e,cachedResponse:s})=>{if(\"install\"===t.type&&e&&e.originalRequest&&e.originalRequest instanceof Request){const t=e.originalRequest.url;s?this.notUpdatedURLs.push(t):this.updatedURLs.push(t)}return s}}}class V{constructor({precacheController:t}){this.cacheKeyWillBeUsed=async({request:t,params:e})=>{const s=(null==e?void 0:e.cacheKey)||this.W.getCacheKeyForURL(t.url);return s?new Request(s,{headers:t.headers}):t},this.W=t}}let J,Q;async function X(t,e){let n=null;if(t.url){n=new URL(t.url).origin}if(n!==self.location.origin)throw new s(\"cross-origin-copy-response\",{origin:n});const r=t.clone(),i={headers:new Headers(r.headers),status:r.status,statusText:r.statusText},a=e?e(i):i,o=function(){if(void 0===J){const t=new Response(\"\");if(\"body\"in t)try{new Response(t.body),J=!0}catch(t){J=!1}J=!1}return J}()?r.body:await r.blob();return new Response(o,a)}class Y extends R{constructor(t={}){t.cacheName=w(t.cacheName),super(t),this.j=!1!==t.fallbackToNetwork,this.plugins.push(Y.copyRedirectedCacheableResponsesPlugin)}async U(t,e){const s=await e.cacheMatch(t);return s||(e.event&&\"install\"===e.event.type?await this.S(t,e):await this.K(t,e))}async K(t,e){let n;const r=e.params||{};if(!this.j)throw new s(\"missing-precache-entry\",{cacheName:this.cacheName,url:t.url});{const s=r.integrity,i=t.integrity,a=!i||i===s;n=await e.fetch(new Request(t,{integrity:\"no-cors\"!==t.mode?i||s:void 0})),s&&a&&\"no-cors\"!==t.mode&&(this.A(),await e.cachePut(t,n.clone()))}return n}async S(t,e){this.A();const n=await e.fetch(t);if(!await e.cachePut(t,n.clone()))throw new s(\"bad-precaching-response\",{url:t.url,status:n.status});return n}A(){let t=null,e=0;for(const[s,n]of this.plugins.entries())n!==Y.copyRedirectedCacheableResponsesPlugin&&(n===Y.defaultPrecacheCacheabilityPlugin&&(t=s),n.cacheWillUpdate&&e++);0===e?this.plugins.push(Y.defaultPrecacheCacheabilityPlugin):e>1&&null!==t&&this.plugins.splice(t,1)}}Y.defaultPrecacheCacheabilityPlugin={cacheWillUpdate:async({response:t})=>!t||t.status>=400?null:t},Y.copyRedirectedCacheableResponsesPlugin={cacheWillUpdate:async({response:t})=>t.redirected?await X(t):t};class Z{constructor({cacheName:t,plugins:e=[],fallbackToNetwork:s=!0}={}){this.F=new Map,this.H=new Map,this.$=new Map,this.u=new Y({cacheName:w(t),plugins:[...e,new V({precacheController:this})],fallbackToNetwork:s}),this.install=this.install.bind(this),this.activate=this.activate.bind(this)}get strategy(){return this.u}precache(t){this.addToCacheList(t),this.G||(self.addEventListener(\"install\",this.install),self.addEventListener(\"activate\",this.activate),this.G=!0)}addToCacheList(t){const e=[];for(const n of t){\"string\"==typeof n?e.push(n):n&&void 0===n.revision&&e.push(n.url);const{cacheKey:t,url:r}=z(n),i=\"string\"!=typeof n&&n.revision?\"reload\":\"default\";if(this.F.has(r)&&this.F.get(r)!==t)throw new s(\"add-to-cache-list-conflicting-entries\",{firstEntry:this.F.get(r),secondEntry:t});if(\"string\"!=typeof n&&n.integrity){if(this.$.has(t)&&this.$.get(t)!==n.integrity)throw new s(\"add-to-cache-list-conflicting-integrities\",{url:r});this.$.set(t,n.integrity)}if(this.F.set(r,t),this.H.set(r,i),e.length>0){const t=`Workbox is precaching URLs without revision info: ${e.join(\", \")}\\nThis is generally NOT safe. Learn more at https://bit.ly/wb-precache`;console.warn(t)}}}install(t){return $(t,async()=>{const e=new G;this.strategy.plugins.push(e);for(const[e,s]of this.F){const n=this.$.get(s),r=this.H.get(e),i=new Request(e,{integrity:n,cache:r,credentials:\"same-origin\"});await Promise.all(this.strategy.handleAll({params:{cacheKey:s},request:i,event:t}))}const{updatedURLs:s,notUpdatedURLs:n}=e;return{updatedURLs:s,notUpdatedURLs:n}})}activate(t){return $(t,async()=>{const t=await self.caches.open(this.strategy.cacheName),e=await t.keys(),s=new Set(this.F.values()),n=[];for(const r of e)s.has(r.url)||(await t.delete(r),n.push(r.url));return{deletedURLs:n}})}getURLsToCacheKeys(){return this.F}getCachedURLs(){return[...this.F.keys()]}getCacheKeyForURL(t){const e=new URL(t,location.href);return this.F.get(e.href)}getIntegrityForCacheKey(t){return this.$.get(t)}async matchPrecache(t){const e=t instanceof Request?t.url:t,s=this.getCacheKeyForURL(e);if(s){return(await self.caches.open(this.strategy.cacheName)).match(s)}}createHandlerBoundToURL(t){const e=this.getCacheKeyForURL(t);if(!e)throw new s(\"non-precached-url\",{url:t});return s=>(s.request=new Request(t),s.params=Object.assign({cacheKey:e},s.params),this.strategy.handle(s))}}const tt=()=>(Q||(Q=new Z),Q);class et extends r{constructor(t,e){super(({request:s})=>{const n=t.getURLsToCacheKeys();for(const r of function*(t,{ignoreURLParametersMatching:e=[/^utm_/,/^fbclid$/],directoryIndex:s=\"index.html\",cleanURLs:n=!0,urlManipulation:r}={}){const i=new URL(t,location.href);i.hash=\"\",yield i.href;const a=function(t,e=[]){for(const s of[...t.searchParams.keys()])e.some(t=>t.test(s))&&t.searchParams.delete(s);return t}(i,e);if(yield a.href,s&&a.pathname.endsWith(\"/\")){const t=new URL(a.href);t.pathname+=s,yield t.href}if(n){const t=new URL(a.href);t.pathname+=\".html\",yield t.href}if(r){const t=r({url:i});for(const e of t)yield e.href}}(s.url,e)){const e=n.get(r);if(e){return{cacheKey:e,integrity:t.getIntegrityForCacheKey(e)}}}},t.strategy)}}t.CacheFirst=class extends R{async U(t,e){let n,r=await e.cacheMatch(t);if(!r)try{r=await e.fetchAndCachePut(t)}catch(t){t instanceof Error&&(n=t)}if(!r)throw new s(\"no-response\",{url:t.url,error:n});return r}},t.ExpirationPlugin=class{constructor(t={}){this.cachedResponseWillBeUsed=async({event:t,request:e,cacheName:s,cachedResponse:n})=>{if(!n)return null;const r=this.V(n),i=this.J(s);b(i.expireEntries());const a=i.updateTimestamp(e.url);if(t)try{t.waitUntil(a)}catch(t){}return r?n:null},this.cacheDidUpdate=async({cacheName:t,request:e})=>{const s=this.J(t);await s.updateTimestamp(e.url),await s.expireEntries()},this.X=t,this.B=t.maxAgeSeconds,this.Y=new Map,t.purgeOnQuotaError&&function(t){g.add(t)}(()=>this.deleteCacheAndMetadata())}J(t){if(t===d())throw new s(\"expire-custom-caches-only\");let e=this.Y.get(t);return e||(e=new F(t,this.X),this.Y.set(t,e)),e}V(t){if(!this.B)return!0;const e=this.Z(t);if(null===e)return!0;return e>=Date.now()-1e3*this.B}Z(t){if(!t.headers.has(\"date\"))return null;const e=t.headers.get(\"date\"),s=new Date(e).getTime();return isNaN(s)?null:s}async deleteCacheAndMetadata(){for(const[t,e]of this.Y)await self.caches.delete(t),await e.delete();this.Y=new Map}},t.NetworkFirst=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u),this.tt=t.networkTimeoutSeconds||0}async U(t,e){const n=[],r=[];let i;if(this.tt){const{id:s,promise:a}=this.et({request:t,logs:n,handler:e});i=s,r.push(a)}const a=this.st({timeoutId:i,request:t,logs:n,handler:e});r.push(a);const o=await e.waitUntil((async()=>await e.waitUntil(Promise.race(r))||await a)());if(!o)throw new s(\"no-response\",{url:t.url});return o}et({request:t,logs:e,handler:s}){let n;return{promise:new Promise(e=>{n=setTimeout(async()=>{e(await s.cacheMatch(t))},1e3*this.tt)}),id:n}}async st({timeoutId:t,request:e,logs:s,handler:n}){let r,i;try{i=await n.fetchAndCachePut(e)}catch(t){t instanceof Error&&(r=t)}return t&&clearTimeout(t),!r&&i||(i=await n.cacheMatch(e)),i}},t.RangeRequestsPlugin=class{constructor(){this.cachedResponseWillBeUsed=async({request:t,cachedResponse:e})=>e&&t.headers.has(\"range\")?await H(t,e):e}},t.StaleWhileRevalidate=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u)}async U(t,e){const n=e.fetchAndCachePut(t).catch(()=>{});e.waitUntil(n);let r,i=await e.cacheMatch(t);if(i);else try{i=await n}catch(t){t instanceof Error&&(r=t)}if(!i)throw new s(\"no-response\",{url:t.url,error:r});return i}},t.cleanupOutdatedCaches=function(){self.addEventListener(\"activate\",t=>{const e=w();t.waitUntil((async(t,e=\"-precache-\")=>{const s=(await self.caches.keys()).filter(s=>s.includes(e)&&s.includes(self.registration.scope)&&s!==t);return await Promise.all(s.map(t=>self.caches.delete(t))),s})(e).then(t=>{}))})},t.clientsClaim=function(){self.addEventListener(\"activate\",()=>self.clients.claim())},t.precacheAndRoute=function(t,e){!function(t){tt().precache(t)}(t),function(t){const e=tt();h(new et(e,t))}(e)},t.registerRoute=h});\n",
    "web_platform/frontend/src/components/AdapterStatusPanel.tsx": "// web_platform/frontend/src/components/AdapterStatusPanel.tsx\n'use client';\n\nimport React from 'react';\nimport { SourceInfo } from '../types/racing';\n\ninterface AdapterStatusPanelProps {\n  adapter: SourceInfo;\n  onFetchRaces: (sourceName: string) => void;\n}\n\nexport const AdapterStatusPanel: React.FC<AdapterStatusPanelProps> = ({ adapter, onFetchRaces }) => {\n  const isConfigured = adapter.status !== 'CONFIG_ERROR';\n\n  return (\n    <div className={`p-4 rounded-lg border ${isConfigured ? 'bg-slate-800 border-slate-700' : 'bg-yellow-900/20 border-yellow-700/50'}`}>\n      <div className=\"flex justify-between items-center\">\n        <h3 className=\"font-bold text-lg text-white\">{adapter.name}</h3>\n        <span className={`px-2 py-0.5 rounded-full text-xs font-medium ${isConfigured ? 'bg-green-500/20 text-green-300' : 'bg-yellow-500/20 text-yellow-300'}`}>\n          {isConfigured ? 'Ready' : 'Not Configured'}\n        </span>\n      </div>\n      <div className=\"mt-4 flex gap-2\">\n        <button\n          onClick={() => onFetchRaces(adapter.name)}\n          disabled={!isConfigured}\n          className=\"flex-1 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 disabled:bg-slate-700 disabled:text-slate-400 disabled:cursor-not-allowed\"\n        >\n          Automatic Load\n        </button>\n        <button\n          disabled\n          className=\"flex-1 px-4 py-2 bg-slate-700 text-slate-400 rounded cursor-not-allowed\"\n        >\n          Manual Entry (Coming Soon)\n        </button>\n      </div>\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/EmptyState.tsx": "// web_platform/frontend/src/components/EmptyState.tsx\nimport React from 'react';\n\ninterface EmptyStateProps {\n  title: string;\n  message: string;\n  actionButton?: React.ReactNode;\n}\n\nexport const EmptyState: React.FC<EmptyStateProps> = ({ title, message, actionButton }) => {\n  return (\n    <div className=\"text-center p-8 bg-gray-800/50 border border-gray-700 rounded-lg mt-8\">\n      <svg\n        className=\"mx-auto h-12 w-12 text-gray-500\"\n        fill=\"none\"\n        viewBox=\"0 0 24 24\"\n        stroke=\"currentColor\"\n        aria-hidden=\"true\"\n      >\n        <path\n          vectorEffect=\"non-scaling-stroke\"\n          strokeLinecap=\"round\"\n          strokeLinejoin=\"round\"\n          strokeWidth={2}\n          d=\"M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z\"\n        />\n      </svg>\n      <h3 className=\"mt-2 text-xl font-semibold text-white\">{title}</h3>\n      <p className=\"mt-1 text-md text-gray-400\">\n        {message}\n      </p>\n      {actionButton && <div className=\"mt-6\">{actionButton}</div>}\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/StatusDetailModal.tsx": "// web_platform/frontend/src/components/StatusDetailModal.tsx\nimport React from 'react';\n\ninterface StatusDetailModalProps {\n  isOpen: boolean;\n  onClose: () => void;\n  status: {\n      title: string;\n      details: string | Record<string, any>;\n  };\n}\n\nexport const StatusDetailModal: React.FC<StatusDetailModalProps> = ({ isOpen, onClose, status }) => {\n  if (!isOpen) {\n    return null;\n  }\n\n  const { title, details } = status;\n  const isDetailsString = typeof details === 'string';\n\n  // Determine status color only if details is an object with a status property\n  const statusColor = !isDetailsString && (details.status === 'SUCCESS' || details.status === 'OK')\n    ? 'text-green-400'\n    : 'text-gray-300'; // Default color\n\n  return (\n    <div className=\"fixed inset-0 bg-black/60 flex items-center justify-center z-50\" onClick={onClose}>\n      <div className=\"bg-gray-800 border border-gray-700 rounded-lg shadow-xl p-6 max-w-lg w-full\" onClick={e => e.stopPropagation()}>\n        <div className=\"flex justify-between items-start mb-4\">\n          <h3 className=\"text-xl font-bold text-white\">{title}</h3>\n          <button onClick={onClose} className=\"text-gray-400 hover:text-white\">&times;</button>\n        </div>\n        <div className=\"space-y-2 text-sm max-h-96 overflow-y-auto pr-2\">\n            {isDetailsString ? (\n                <div className=\"text-gray-300 whitespace-pre-wrap bg-gray-900/50 p-4 rounded-md\">{details}</div>\n            ) : (\n                Object.entries(details).map(([key, value]) => (\n                    <div key={key} className=\"grid grid-cols-3 gap-4 border-b border-gray-700/50 py-2\">\n                    <span className=\"font-semibold text-gray-400 capitalize\">{key.replace(/_/g, ' ')}</span>\n                    <span className={`col-span-2 break-words ${key === 'status' ? statusColor : 'text-gray-300'}`}>\n                        {typeof value === 'object' ? JSON.stringify(value, null, 2) : String(value)}\n                    </span>\n                    </div>\n                ))\n            )}\n        </div>\n        <button\n          onClick={onClose}\n          className=\"bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded w-full mt-6\"\n        >\n          Close\n        </button>\n      </div>\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/hooks/useWebSocket.ts": "// web_platform/frontend/src/hooks/useWebSocket.ts\n'use client';\n\nimport { useState, useEffect, useRef } from 'react';\n\ninterface WebSocketOptions {\n  apiKey: string | null;\n  port: number | null;\n}\n\nexport const useWebSocket = <T>(path: string, options: WebSocketOptions) => {\n  const [data, setData] = useState<T | null>(null);\n  const [isConnected, setIsConnected] = useState(false);\n  const webSocketRef = useRef<WebSocket | null>(null);\n\n  useEffect(() => {\n    console.log(\n      `[useWebSocket] useEffect triggered. Path: ${path}, API Key: ${options.apiKey}, Port: ${options.port}`,\n    );\n    if (!path || !options.apiKey || !options.port) {\n      console.log(\n        '[useWebSocket] Missing path, API key, or port. Aborting connection.',\n      );\n      if (webSocketRef.current) {\n        webSocketRef.current.close();\n      }\n      return;\n    }\n\n    const wsUrl = `ws://localhost:${options.port}${path}?api_key=${options.apiKey}`;\n    console.log(`[useWebSocket] Attempting to connect to: ${wsUrl}`);\n\n    const ws = new WebSocket(wsUrl);\n    webSocketRef.current = ws;\n\n    ws.onopen = () => {\n      console.log('WebSocket connection established.');\n      setIsConnected(true);\n    };\n\n    ws.onmessage = (event) => {\n      try {\n        const messageData = JSON.parse(event.data);\n        setData(messageData);\n      } catch (error) {\n        console.error('Error parsing WebSocket message:', error);\n      }\n    };\n\n    ws.onerror = (error) => {\n      console.error('WebSocket error:', error);\n    };\n\n    ws.onclose = (event) => {\n      console.log(`WebSocket connection closed: ${event.code} ${event.reason}`);\n      setIsConnected(false);\n      webSocketRef.current = null;\n    };\n\n    return () => {\n      if (ws.readyState === WebSocket.OPEN) {\n        ws.close();\n      }\n    };\n  }, [path, options.apiKey, options.port]);\n\n  return { data, isConnected };\n};\n",
    "web_service/__init__.py": "\"\"\"Web service package for Fortuna Faucet.\"\"\"\n__version__ = \"1.0.0\"\n__all__ = [\"backend\"]\n",
    "web_service/backend/adapters/__init__.py": "# python_service/adapters/__init__.py\n# TEMPORARY FIX: Comment out the problematic adapter\n\nfrom .at_the_races_adapter import AtTheRacesAdapter\nfrom .betfair_adapter import BetfairAdapter\nfrom .betfair_greyhound_adapter import BetfairGreyhoundAdapter\n\n# from .betfair_datascientist_adapter import BetfairDataScientistAdapter  # DISABLED: PyInstaller NumPy issue\nfrom .gbgb_api_adapter import GbgbApiAdapter\nfrom .greyhound_adapter import GreyhoundAdapter\nfrom .harness_adapter import HarnessAdapter\nfrom .pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .sporting_life_adapter import SportingLifeAdapter\nfrom .the_racing_api_adapter import TheRacingApiAdapter\nfrom .timeform_adapter import TimeformAdapter\nfrom .tvg_adapter import TVGAdapter\n\n__all__ = [\n    \"GbgbApiAdapter\",\n    \"TVGAdapter\",\n    \"BetfairAdapter\",\n    \"BetfairGreyhoundAdapter\",\n    \"RacingAndSportsGreyhoundAdapter\",\n    \"AtTheRacesAdapter\",\n    \"PointsBetGreyhoundAdapter\",\n    \"RacingAndSportsAdapter\",\n    \"SportingLifeAdapter\",\n    \"TimeformAdapter\",\n    \"HarnessAdapter\",\n    \"GreyhoundAdapter\",\n    \"TheRacingApiAdapter\",\n    # \"BetfairDataScientistAdapter\",  # DISABLED\n]\n",
    "web_service/backend/adapters/harness_adapter.py": "# python_service/adapters/harness_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass HarnessAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US harness racing data with manual override support.\"\"\"\n\n    SOURCE_NAME = \"USTrotting\"\n    BASE_URL = \"https://data.ustrotting.com/api/racenet/racing/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches all harness races for a given date.\"\"\"\n        response = await self.make_request(self.http_client, \"GET\", f\"card/{date}\")\n\n        if not response:\n            return None\n\n        card_data = response.json()\n        return {\"data\": card_data, \"date\": date}\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw card data into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"data\") or not raw_data.get(\"data\", {}).get(\"meetings\"):\n            self.logger.warning(\"No meetings found in harness data response.\")\n            return []\n\n        all_races = []\n        date = raw_data.get(\"date\")\n        for meeting in raw_data.get(\"data\", {}).get(\"meetings\", []):\n            track_name = meeting.get(\"track\", {}).get(\"name\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name, date):\n                        all_races.append(race)\n                except Exception:\n                    self.logger.warning(\n                        \"Failed to parse harness race, skipping.\",\n                        race_data=race_data,\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: dict, track_name: str, date: str) -> Optional[Race]:\n        \"\"\"Parses a single race from the USTA API into a Race object.\"\"\"\n        race_number = race_data.get(\"raceNumber\")\n        post_time_str = race_data.get(\"postTime\")\n        if not all([race_number, post_time_str]):\n            return None\n\n        start_time = self._parse_post_time(date, post_time_str)\n\n        runners = []\n        for runner_data in race_data.get(\"runners\", []):\n            if runner_data.get(\"scratched\", False):\n                continue\n\n            odds_str = runner_data.get(\"morningLineOdds\", \"\")\n            if \"/\" not in odds_str and odds_str.isdigit():\n                odds_str = f\"{odds_str}/1\"\n\n            odds = {}\n            win_odds = parse_odds_to_decimal(odds_str)\n            if win_odds and win_odds < 999:\n                odds = {\n                    self.SOURCE_NAME: OddsData(\n                        win=win_odds,\n                        source=self.SOURCE_NAME,\n                        last_updated=datetime.now(),\n                    )\n                }\n\n            runners.append(\n                Runner(\n                    number=runner_data.get(\"postPosition\", 0),\n                    name=runner_data.get(\"horse\", {}).get(\"name\", \"Unknown Horse\"),\n                    odds=odds,\n                    scratched=False,\n                )\n            )\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"ust_{track_name.lower().replace(' ', '')}_{date}_{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME,\n        )\n\n    def _parse_post_time(self, date: str, post_time: str) -> datetime:\n        \"\"\"Parses a time string like '07:00 PM' into a timezone-aware datetime object.\"\"\"\n        dt_str = f\"{date} {post_time}\"\n        naive_dt = datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n        # Assume Eastern Time for USTA data, a common standard for US racing.\n        eastern = ZoneInfo(\"America/New_York\")\n        return naive_dt.replace(tzinfo=eastern)\n",
    "web_service/backend/adapters/pointsbet_greyhound_adapter.py": "# python_service/adapters/pointsbet_greyhound_adapter.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n# NOTE: This is a hypothetical implementation based on a potential API structure.\n\n\nclass PointsBetGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"Adapter for the hypothetical PointsBet Greyhound API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"PointsBetGreyhound\"\n    BASE_URL = \"https://api.pointsbet.com/api/v2/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches all greyhound events for a given date.\"\"\"\n        endpoint = f\"sports/greyhound-racing/events/by-date/{date}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json().get(\"events\", []) if response else None\n\n    def _parse_races(self, raw_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw event data into a list of standardized Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for event in raw_data:\n            try:\n                if not event.get(\"competitors\") or not event.get(\"startTime\"):\n                    continue\n\n                runners = []\n                for competitor in event.get(\"competitors\", []):\n                    price = competitor.get(\"price\")\n                    if not price:\n                        continue\n\n                    odds_val = Decimal(str(price))\n                    odds = {\n                        self.source_name: OddsData(\n                            win=odds_val,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n                    runner = Runner(\n                        number=competitor.get(\"number\", 99),\n                        name=competitor.get(\"name\", \"Unknown\"),\n                        odds=odds,\n                    )\n                    runners.append(runner)\n\n                if runners:\n                    race_id = event.get(\"id\")\n                    if not race_id:\n                        continue\n\n                    race = Race(\n                        id=f\"pbg_{race_id}\",\n                        venue=event.get(\"venue\", {}).get(\"name\", \"Unknown Venue\"),\n                        start_time=datetime.fromisoformat(event[\"startTime\"]),\n                        race_number=event.get(\"raceNumber\", 1),\n                        runners=runners,\n                        source=self.source_name,\n                    )\n                    races.append(race)\n            except (KeyError, TypeError, ValueError):\n                self.logger.warning(\n                    \"Failed to parse PointsBet Greyhound event.\",\n                    event=event,\n                    exc_info=True,\n                )\n                continue\n        return races\n",
    "web_service/backend/adapters/racingtv_adapter.py": "# python_service/adapters/racingtv_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingTVAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping data from racingtv.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"RacingTV\"\n    BASE_URL = \"https://www.racingtv.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/template_adapter.py": "# python_service/adapters/template_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TemplateAdapter(BaseAdapterV3):\n    \"\"\"\n    A template for creating new adapters, based on the BaseAdapterV3 pattern.\n    This adapter is a non-functional stub.\n    \"\"\"\n\n    SOURCE_NAME = \"[IMPLEMENT ME] Example Source\"\n    BASE_URL = \"https://api.example.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        # self.api_key = config.EXAMPLE_API_KEY # Uncomment if needed\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/the_racing_api_adapter.py": "# python_service/adapters/the_racing_api_adapter.py\n\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TheRacingApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for The Racing API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"TheRacingAPI\"\n    BASE_URL = \"https://api.theracingapi.com/v1/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"THE_RACING_API_KEY\") or not config.THE_RACING_API_KEY:\n            raise AdapterConfigError(self.source_name, \"THE_RACING_API_KEY is not configured.\")\n        self.api_key = config.THE_RACING_API_KEY\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw racecard data from The Racing API.\"\"\"\n        endpoint = f\"racecards?date={date}&course=all&region=gb,ire\"\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n        response = await self.make_request(self.http_client, \"GET\", endpoint, headers=headers)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw JSON response into a list of Race objects.\"\"\"\n        if not raw_data or \"racecards\" not in raw_data:\n            self.logger.warning(\"'racecards' key missing in TheRacingAPI response.\")\n            return []\n\n        races = []\n        for race_data in raw_data.get(\"racecards\", []):\n            try:\n                race_id = race_data.get(\"race_id\")\n                off_time = race_data.get(\"off_time\")\n                course = race_data.get(\"course\")\n                race_no = race_data.get(\"race_no\")\n\n                if not all([race_id, off_time, course, race_no]):\n                    continue\n\n                start_time = datetime.fromisoformat(off_time.replace(\"Z\", \"+00:00\"))\n\n                race = Race(\n                    id=f\"tra_{race_id}\",\n                    venue=course,\n                    race_number=race_no,\n                    start_time=start_time,\n                    runners=self._parse_runners(race_data.get(\"runners\", [])),\n                    source=self.source_name,\n                    race_name=race_data.get(\"race_name\"),\n                    distance=race_data.get(\"distance_f\"),\n                )\n                races.append(race)\n            except Exception:\n                self.logger.error(\n                    \"Error parsing TheRacingAPI race\",\n                    race_id=race_data.get(\"race_id\"),\n                    exc_info=True,\n                )\n        return races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for i, runner_data in enumerate(runners_data):\n            try:\n                horse = runner_data.get(\"horse\")\n                if not horse:\n                    continue\n\n                odds_data = {}\n                odds_list = runner_data.get(\"odds\", [])\n                if odds_list:\n                    odds_decimal_str = odds_list[0].get(\"odds_decimal\")\n                    if odds_decimal_str:\n                        win_odds = Decimal(str(odds_decimal_str))\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=runner_data.get(\"number\", i + 1),\n                        name=horse,\n                        odds=odds_data,\n                        jockey=runner_data.get(\"jockey\"),\n                        trainer=runner_data.get(\"trainer\"),\n                    )\n                )\n            except Exception:\n                self.logger.error(\n                    \"Error parsing TheRacingAPI runner\",\n                    runner_name=runner_data.get(\"horse\"),\n                    exc_info=True,\n                )\n        return runners\n",
    "web_service/backend/config.py": "# python_service/config.py\nimport os\nimport sys\nfrom functools import lru_cache\nfrom pathlib import Path\nfrom typing import List\nfrom typing import Optional\n\nimport structlog\nfrom pydantic import Field\nfrom pydantic import model_validator\nfrom pydantic_settings import BaseSettings\n\nfrom .credentials_manager import SecureCredentialsManager\n\n# --- Encryption Setup ---\ntry:\n    from cryptography.fernet import Fernet\n\n    ENCRYPTION_ENABLED = True\nexcept ImportError:\n    ENCRYPTION_ENABLED = False\n\nKEY_FILE = Path(\".key\")\nCIPHER = None\nif ENCRYPTION_ENABLED and KEY_FILE.exists():\n    with open(KEY_FILE, \"rb\") as f:\n        key = f.read()\n    CIPHER = Fernet(key)\n\n\ndef decrypt_value(value: Optional[str]) -> str:\n    \"\"\"If a value is encrypted, decrypts it. Otherwise, returns it as is.\"\"\"\n    if value and value.startswith(\"encrypted:\") and CIPHER:\n        try:\n            return CIPHER.decrypt(value[10:].encode()).decode()\n        except Exception:\n            structlog.get_logger(__name__).error(\"Decryption failed on field.\")\n            return \"\"  # Fallback to an empty string on failure\n    return value or \"\"  # Ensure a non-None return value even if input is None\n\n\nclass Settings(BaseSettings):\n    API_KEY: str = Field(\"\")\n\n    # --- API Gateway Configuration ---\n    UVICORN_HOST: str = \"127.0.0.1\"\n    FORTUNA_PORT: int = 8000\n    UVICORN_RELOAD: bool = True\n\n    # --- Database Configuration ---\n    DATABASE_TYPE: str = \"sqlite\"\n    DATABASE_URL: str = \"sqlite:///./fortuna.db\"\n\n    # --- Optional Betfair Credentials ---\n    BETFAIR_APP_KEY: Optional[str] = None\n\n    # --- Caching & Performance ---\n    REDIS_URL: str = \"redis://localhost:6379\"\n    CACHE_TTL_SECONDS: int = 1800  # 30 minutes\n    MAX_CONCURRENT_REQUESTS: int = 10\n    HTTP_POOL_CONNECTIONS: int = 100\n    HTTP_POOL_MAXSIZE: int = 100\n    HTTP_MAX_KEEPALIVE: int = 50\n    DEFAULT_TIMEOUT: int = 30\n    ADAPTER_TIMEOUT: int = 20\n\n    # --- Logging ---\n    LOG_LEVEL: str = \"INFO\"\n\n    # --- Optional Adapter Keys ---\n    NEXT_PUBLIC_API_KEY: Optional[str] = None  # Allow frontend key to be present in .env\n    TVG_API_KEY: Optional[str] = None\n    RACING_AND_SPORTS_TOKEN: Optional[str] = None\n    POINTSBET_API_KEY: Optional[str] = None\n    GREYHOUND_API_URL: Optional[str] = None\n    THE_RACING_API_KEY: Optional[str] = None\n\n    # --- CORS Configuration ---\n    ALLOWED_ORIGINS: List[str] = [\"http://localhost:3000\", \"http://localhost:3001\"]\n\n    # --- Dynamic Path Configuration ---\n    # This determines the path to static files, crucial for PyInstaller builds\n    STATIC_FILES_DIR: Optional[str] = None\n\n    model_config = {\"env_file\": \".env\", \"case_sensitive\": True}\n\n    @model_validator(mode=\"after\")\n    def process_settings(self) -> \"Settings\":\n        \"\"\"\n        This validator runs after the initial settings are loaded from .env and\n        performs two key functions:\n        1. If API_KEY is missing, it falls back to the SecureCredentialsManager.\n        2. It decrypts any fields that were loaded from the .env file.\n        \"\"\"\n        # 1. Fallback for API_KEY\n        if not self.API_KEY:\n            self.API_KEY = SecureCredentialsManager.get_credential(\"api_key\") or \"MISSING\"\n\n        # 2. Security validation for API_KEY\n        insecure_keys = {\"test\", \"changeme\", \"default\", \"secret\", \"password\", \"admin\"}\n        if self.API_KEY in insecure_keys:\n            structlog.get_logger(__name__).warning(\n                \"insecure_api_key\",\n                key=self.API_KEY,\n                recommendation=\"The API_KEY should be a long, random string for security.\",\n            )\n\n        # 2. Decrypt sensitive fields\n        self.BETFAIR_APP_KEY = decrypt_value(self.BETFAIR_APP_KEY)\n\n        # 3. Set the static files directory for packaged apps\n        if getattr(sys, \"frozen\", False):\n            # Running in a PyInstaller bundle\n            self.STATIC_FILES_DIR = os.path.join(sys._MEIPASS, \"ui\")\n        else:\n            # Running in a normal Python environment\n            self.STATIC_FILES_DIR = None  # Not needed for local dev\n\n        return self\n\n\n@lru_cache()\ndef get_settings() -> Settings:\n    \"\"\"Loads settings and performs a proactive check for legacy paths.\"\"\"\n    log = structlog.get_logger(__name__)\n    if ENCRYPTION_ENABLED and not KEY_FILE.exists():\n        log.warning(\n            \"encryption_key_not_found\",\n            file=str(KEY_FILE),\n            recommendation=\"Run 'python manage_secrets.py' to generate a key.\",\n        )\n\n    settings = Settings()\n\n    # --- Legacy Path Detection ---\n    legacy_paths = [\"attic/\", \"checkmate_web/\", \"vba_source/\"]\n    for path in legacy_paths:\n        if os.path.exists(path):\n            log.warning(\n                \"legacy_path_detected\",\n                path=path,\n                recommendation=\"This directory is obsolete and should be removed for optimal performance and security.\",\n            )\n\n    return settings\n",
    "web_service/backend/core/errors.py": "# python_service/core/errors.py\nfrom enum import Enum\n\n\nclass ErrorCategory(Enum):\n    CONFIGURATION_ERROR = \"Configuration missing or invalid\"\n    NETWORK_ERROR = \"HTTP/Network request failed\"\n    PARSING_ERROR = \"Data parsing or validation unsuccessful\"\n    UNEXPECTED_ERROR = \"An unhandled exception occurred\"\n",
    "web_service/backend/core/exceptions.py": "# python_service/core/exceptions.py\n\"\"\"\nCustom, application-specific exceptions for the Fortuna Faucet service.\n\nThis module defines a hierarchy of exception classes to provide standardized\nerror handling, particularly for the data adapter layer. Using these specific\nexceptions instead of generic ones allows for more precise error handling and\nclearer logging throughout the application.\n\"\"\"\n\n\nclass FortunaException(Exception):\n    \"\"\"Base class for all custom exceptions in this application.\"\"\"\n\n    pass\n\n\nclass AdapterError(FortunaException):\n    \"\"\"Base class for all adapter-related errors.\"\"\"\n\n    def __init__(self, adapter_name: str, message: str):\n        self.adapter_name = adapter_name\n        super().__init__(f\"[{adapter_name}] {message}\")\n\n\nclass AdapterRequestError(AdapterError):\n    \"\"\"Raised for general network or request-related issues.\"\"\"\n\n    pass\n\n\nclass AdapterHttpError(AdapterRequestError):\n    \"\"\"Raised for unsuccessful HTTP responses (e.g., 4xx or 5xx status codes).\"\"\"\n\n    def __init__(self, adapter_name: str, status_code: int, url: str):\n        self.status_code = status_code\n        self.url = url\n        message = f\"Received HTTP {status_code} from {url}\"\n        super().__init__(adapter_name, message)\n\n\nclass AdapterAuthError(AdapterHttpError):\n    \"\"\"Raised specifically for HTTP 401/403 errors, indicating an auth failure.\"\"\"\n\n    pass\n\n\nclass AdapterRateLimitError(AdapterHttpError):\n    \"\"\"Raised specifically for HTTP 429 errors, indicating a rate limit has been hit.\"\"\"\n\n    pass\n\n\nclass AdapterTimeoutError(AdapterRequestError):\n    \"\"\"Raised when a request to an external API times out.\"\"\"\n\n    pass\n\n\nclass AdapterConnectionError(AdapterRequestError):\n    \"\"\"Raised for DNS lookup failures or refused connections.\"\"\"\n\n    pass\n\n\nclass AdapterConfigError(AdapterError):\n    \"\"\"Raised when an adapter is missing necessary configuration (e.g., an API key).\"\"\"\n\n    pass\n\n\nclass AdapterParsingError(AdapterError):\n    \"\"\"Raised when an adapter fails to parse the response from an API.\"\"\"\n\n    pass\n",
    "web_service/backend/engine.py": "# python_service/engine.py\n\nimport asyncio\nimport json\nfrom copy import deepcopy\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Tuple\n\nimport httpx\nimport redis\nimport redis.asyncio as redis_async\nimport structlog\nfrom pydantic import ValidationError\n\nfrom .adapters.at_the_races_adapter import AtTheRacesAdapter\nfrom .adapters.base_adapter_v3 import BaseAdapterV3\nfrom .adapters.betfair_adapter import BetfairAdapter\n\n# from .adapters.betfair_datascientist_adapter import BetfairDataScientistAdapter\nfrom .adapters.betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .adapters.brisnet_adapter import BrisnetAdapter\nfrom .adapters.equibase_adapter import EquibaseAdapter\nfrom .adapters.fanduel_adapter import FanDuelAdapter\nfrom .adapters.gbgb_api_adapter import GbgbApiAdapter\nfrom .adapters.greyhound_adapter import GreyhoundAdapter\nfrom .adapters.harness_adapter import HarnessAdapter\nfrom .adapters.horseracingnation_adapter import HorseRacingNationAdapter\nfrom .adapters.nyrabets_adapter import NYRABetsAdapter\nfrom .adapters.oddschecker_adapter import OddscheckerAdapter\nfrom .adapters.pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .adapters.punters_adapter import PuntersAdapter\nfrom .adapters.racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .adapters.racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .adapters.racingpost_adapter import RacingPostAdapter\nfrom .adapters.racingtv_adapter import RacingTVAdapter\nfrom .adapters.sporting_life_adapter import SportingLifeAdapter\nfrom .adapters.tab_adapter import TabAdapter\nfrom .adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom .adapters.timeform_adapter import TimeformAdapter\nfrom .adapters.tvg_adapter import TVGAdapter\nfrom .adapters.twinspires_adapter import TwinSpiresAdapter\nfrom .adapters.xpressbet_adapter import XpressbetAdapter\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .manual_override_manager import ManualOverrideManager\nfrom .models import AggregatedResponse\nfrom .models import Race\n\nlog = structlog.get_logger(__name__)\n\n\nclass OddsEngine:\n    def __init__(\n        self,\n        config=None,\n        manual_override_manager: ManualOverrideManager = None,\n        connection_manager=None,\n    ):\n        # THE FIX: Import the cache_manager singleton here to ensure tests can\n        # patch and reload it *before* the engine is initialized.\n        from .cache_manager import cache_manager\n\n        self.logger = structlog.get_logger(__name__)\n        self.logger.info(\"Initializing FortunaEngine...\")\n        self.connection_manager = connection_manager\n        self.cache_manager = cache_manager\n\n        try:\n            try:\n                self.config = config or get_settings()\n                self.logger.info(\"Configuration loaded.\")\n            except ValidationError as e:\n                self.logger.warning(\n                    \"Could not load settings, possibly in test environment.\",\n                    error=str(e),\n                )\n                # Create a default/mock config or re-raise if not in a test context\n                from .config import Settings\n\n                self.config = Settings(API_KEY=\"a_secure_test_api_key_that_is_long_enough\")\n\n            # Redis is now handled entirely by the CacheManager.\n\n            self.logger.info(\"Initializing adapters...\")\n            self.adapters: List[BaseAdapterV3] = []\n            adapter_classes = [\n                AtTheRacesAdapter,\n                BetfairAdapter,\n                BetfairGreyhoundAdapter,\n                BrisnetAdapter,\n                EquibaseAdapter,\n                FanDuelAdapter,\n                GbgbApiAdapter,\n                GreyhoundAdapter,\n                HarnessAdapter,\n                HorseRacingNationAdapter,\n                NYRABetsAdapter,\n                OddscheckerAdapter,\n                PuntersAdapter,\n                RacingAndSportsAdapter,\n                RacingAndSportsGreyhoundAdapter,\n                RacingPostAdapter,\n                RacingTVAdapter,\n                SportingLifeAdapter,\n                TabAdapter,\n                TheRacingApiAdapter,\n                TimeformAdapter,\n                TwinSpiresAdapter,\n                TVGAdapter,\n                XpressbetAdapter,\n                PointsBetGreyhoundAdapter,\n            ]\n\n            for adapter_cls in adapter_classes:\n                try:\n                    self.logger.info(f\"Attempting to initialize adapter: {adapter_cls.__name__}\")\n                    adapter_instance = adapter_cls(config=self.config)\n                    self.logger.info(f\"Successfully initialized adapter: {adapter_cls.__name__}\")\n                    if manual_override_manager and getattr(adapter_instance, \"supports_manual_override\", False):\n                        adapter_instance.enable_manual_override(manual_override_manager)\n                    self.adapters.append(adapter_instance)\n                except AdapterConfigError as e:\n                    self.logger.warning(\n                        \"Skipping adapter due to configuration error\",\n                        adapter=adapter_cls.__name__,\n                        error=str(e),\n                    )\n                except Exception:\n                    self.logger.error(\n                        f\"An unexpected error occurred while initializing {adapter_cls.__name__}\",\n                        exc_info=True,\n                    )\n\n            # Special case for BetfairDataScientistAdapter with extra args - DISABLED\n            # try:\n            #     bds_adapter = BetfairDataScientistAdapter(\n            #         model_name=\"ThoroughbredModel\",\n            #         url=\"https://betfair-data-supplier-prod.herokuapp.com/api/widgets/kvs-ratings/datasets\",\n            #         config=self.config,\n            #     )\n            #     if manual_override_manager and getattr(bds_adapter, \"supports_manual_override\", False):\n            #         bds_adapter.enable_manual_override(manual_override_manager)\n            #     self.adapters.append(bds_adapter)\n            # except Exception:\n            #     self.logger.warning(\n            #         \"Failed to initialize adapter: BetfairDataScientistAdapter\",\n            #         exc_info=True,\n            #     )\n\n            self.logger.info(f\"{len(self.adapters)} adapters initialized successfully.\")\n\n            self.logger.info(\"Initializing HTTP client...\")\n            self.http_limits = httpx.Limits(\n                max_connections=self.config.HTTP_POOL_CONNECTIONS,\n                max_keepalive_connections=self.config.HTTP_MAX_KEEPALIVE,\n            )\n            self.http_client = httpx.AsyncClient(limits=self.http_limits, http2=True)\n            self.logger.info(\"HTTP client initialized.\")\n\n            # Assign the shared client to each adapter\n            for adapter in self.adapters:\n                adapter.http_client = self.http_client\n\n            # Initialize semaphore for concurrency limiting\n            self.semaphore = asyncio.Semaphore(self.config.MAX_CONCURRENT_REQUESTS)\n            self.logger.info(\n                \"Concurrency semaphore initialized\",\n                limit=self.config.MAX_CONCURRENT_REQUESTS,\n            )\n\n            self.logger.info(\"FortunaEngine initialization complete.\")\n\n        except Exception:\n            self.logger.critical(\"CRITICAL FAILURE during FortunaEngine initialization.\", exc_info=True)\n            raise\n\n    async def close(self):\n        await self.http_client.aclose()\n\n    def get_all_adapter_statuses(self) -> List[Dict[str, Any]]:\n        return [adapter.get_status() for adapter in self.adapters]\n\n    async def get_from_cache(self, key):\n        return await self.cache_manager.get(key)\n\n    async def set_in_cache(self, key, value, ttl=300):\n        # THE FIX: The keyword argument is 'ttl_seconds', not 'ttl'.\n        await self.cache_manager.set(key, value, ttl_seconds=ttl)\n\n    async def _fetch_with_semaphore(self, adapter: BaseAdapterV3, date: str):\n        \"\"\"Acquires the semaphore before fetching data from an adapter.\"\"\"\n        async with self.semaphore:\n            return await self._time_adapter_fetch(adapter, date)\n\n    async def _time_adapter_fetch(self, adapter: BaseAdapterV3, date: str) -> Tuple[str, Dict[str, Any], float]:\n        \"\"\"\n        Wraps a V3 adapter's fetch call for safe, non-blocking execution,\n        and returns a consistent payload with timing information.\n        \"\"\"\n        start_time = datetime.now()\n        races: List[Race] = []\n        error_message = None\n        is_success = False\n        attempted_url = None\n\n        try:\n            race_data_list = await adapter.get_races(date)\n            races = [Race(**race_data) for race_data in race_data_list]\n            is_success = True\n        except AdapterHttpError as e:\n            self.logger.error(\n                \"HTTP failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                status_code=e.status_code,\n                url=e.url,\n                exc_info=False,\n            )\n            error_message = f\"HTTP Error {e.status_code} for {e.url}\"\n            attempted_url = e.url\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n        except Exception as e:\n            self.logger.error(\n                \"Critical failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                error=str(e),\n                exc_info=True,\n            )\n            error_message = str(e)\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n\n        duration = (datetime.now() - start_time).total_seconds()\n\n        payload = {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": adapter.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": duration,\n                \"attempted_url\": attempted_url,\n            },\n        }\n        return (adapter.source_name, payload, duration)\n\n    def _race_key(self, race: Race) -> str:\n        return f\"{race.venue.lower().strip()}|{race.race_number}|{race.start_time.strftime('%H:%M')}\"\n\n    def _dedupe_races(self, races: List[Race]) -> List[Race]:\n        \"\"\"Deduplicates races and reconciles odds from different sources.\"\"\"\n        races_copy = deepcopy(races)\n        race_map: Dict[str, Race] = {}\n        for race in races_copy:\n            key = self._race_key(race)\n            if key not in race_map:\n                race_map[key] = race\n            else:\n                existing_race = race_map[key]\n                runner_map = {r.number: r for r in existing_race.runners}\n                for new_runner in race.runners:\n                    if new_runner.number in runner_map:\n                        existing_runner = runner_map[new_runner.number]\n                        existing_runner.odds.update(new_runner.odds)\n                    else:\n                        existing_race.runners.append(new_runner)\n                existing_race.source += f\", {race.source}\"\n\n        return list(race_map.values())\n\n    async def _broadcast_update(self, data: Dict[str, Any]):\n        \"\"\"Helper to broadcast data if the connection manager is available.\"\"\"\n        if self.connection_manager:\n            await self.connection_manager.broadcast(data)\n\n    async def fetch_all_odds(self, date: str, source_filter: str = None) -> Dict[str, Any]:\n        \"\"\"\n        Fetches and aggregates race data from all configured adapters.\n        The result of this method is cached and broadcasted via WebSocket.\n        \"\"\"\n        # Construct a cache key\n        cache_key = f\"fortuna_engine_races:{date}:{source_filter or 'all'}\"\n        cached_data = await self.get_from_cache(cache_key)\n        if cached_data:\n            log.info(\"Cache hit for fetch_all_odds\", key=cache_key)\n            return json.loads(cached_data)\n\n        log.info(\"Cache miss for fetch_all_odds\", key=cache_key)\n        target_adapters = self.adapters\n        if source_filter:\n            log.info(\"Applying source filter\", source=source_filter)\n            target_adapters = [a for a in self.adapters if a.source_name.lower() == source_filter.lower()]\n\n        tasks = [self._fetch_with_semaphore(adapter, date) for adapter in target_adapters]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        source_infos = []\n        all_races = []\n        errors = []\n\n        for i, result in enumerate(results):\n            adapter = target_adapters[i]\n            if isinstance(result, Exception):\n                log.error(\"Adapter fetch task failed with an unhandled exception\", adapter=adapter.source_name, error=result)\n                errors.append({\n                    \"adapter_name\": adapter.source_name,\n                    \"error_message\": f\"Unhandled exception: {str(result)}\",\n                    \"attempted_url\": \"Unknown\"\n                })\n                source_infos.append({\n                    \"name\": adapter.source_name,\n                    \"status\": \"FAILED\",\n                    \"error_message\": f\"Unhandled exception: {str(result)}\",\n                })\n            else:\n                _adapter_name, adapter_result, _duration = result\n                source_info = adapter_result.get(\"source_info\", {})\n                source_infos.append(source_info)\n                if source_info.get(\"status\") == \"SUCCESS\":\n                    all_races.extend(adapter_result.get(\"races\", []))\n                else:\n                    errors.append({\n                        \"adapter_name\": adapter.source_name,\n                        \"error_message\": source_info.get(\"error_message\", \"Unknown error\"),\n                        \"attempted_url\": source_info.get(\"attempted_url\")\n                    })\n\n        deduped_races = self._dedupe_races(all_races)\n\n        response_obj = AggregatedResponse(\n            date=datetime.strptime(date, \"%Y-%m-%d\").date(),\n            races=deduped_races,\n            errors=errors,\n            source_info=source_infos,\n            metadata={\n                \"fetch_time\": datetime.now(),\n                \"sources_queried\": [a.source_name for a in target_adapters],\n                \"sources_successful\": len([s for s in source_infos if s[\"status\"] == \"SUCCESS\"]),\n                \"total_races\": len(deduped_races),\n                \"total_errors\": len(errors),\n            },\n        )\n\n        response_data = response_obj.model_dump(by_alias=True)\n\n        # Set the result in the cache\n        await self.set_in_cache(cache_key, json.dumps(response_data, default=str), ttl=300)\n        await self._broadcast_update(response_data)\n        return response_data\n",
    "web_service/backend/etl.py": "# python_service/etl.py\n# ETL pipeline for populating the historical data warehouse\n\nimport json\nimport logging\nimport os\nfrom datetime import date\n\nimport requests\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import text\nfrom sqlalchemy.exc import SQLAlchemyError\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass ScribesArchivesETL:\n    def __init__(self):\n        self.postgres_url = os.getenv(\"POSTGRES_URL\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.api_base_url = \"http://localhost:8000\"\n        self.engine = self._get_db_engine()\n\n    def _get_db_engine(self):\n        if not self.postgres_url:\n            logger.warning(\"POSTGRES_URL not set. ETL will be skipped.\")\n            return None\n        try:\n            return create_engine(self.postgres_url)\n        except Exception as e:\n            logger.error(f\"Failed to create database engine: {e}\", exc_info=True)\n            return None\n\n    def _fetch_race_data(self, target_date: date) -> list:\n        \"\"\"Fetches aggregated race data from the local API.\"\"\"\n        if not self.api_key:\n            raise ValueError(\"API_KEY not found in environment.\")\n\n        url = f\"{self.api_base_url}/api/races?race_date={target_date.isoformat()}\"\n        headers = {\"X-API-KEY\": self.api_key}\n        response = requests.get(url, headers=headers, timeout=120)\n        response.raise_for_status()\n        return response.json().get(\"races\", [])\n\n    def _validate_and_transform(self, race: dict) -> tuple:\n        \"\"\"Validates a race dictionary and transforms it for insertion.\"\"\"\n        if not all(k in race for k in [\"id\", \"venue\", \"race_number\", \"start_time\", \"runners\"]):\n            return (\n                None,\n                \"Missing core fields (id, venue, race_number, start_time, runners)\",\n            )\n\n        active_runners = [r for r in race.get(\"runners\", []) if not r.get(\"scratched\")]\n\n        transformed = {\n            \"race_id\": race[\"id\"],\n            \"venue\": race[\"venue\"],\n            \"race_number\": race[\"race_number\"],\n            \"start_time\": race[\"start_time\"],\n            \"source\": race.get(\"source\"),\n            \"qualification_score\": race.get(\"qualification_score\"),\n            \"field_size\": len(active_runners),\n        }\n        return transformed, None\n\n    def run(self, target_date: date):\n        if not self.engine:\n            return\n\n        logger.info(f\"Starting ETL process for {target_date.isoformat()}...\")\n        try:\n            races = self._fetch_race_data(target_date)\n        except (requests.RequestException, ValueError) as e:\n            logger.error(f\"Failed to fetch race data: {e}\", exc_info=True)\n            return\n\n        clean_records = []\n        quarantined_records = []\n\n        for race in races:\n            transformed, reason = self._validate_and_transform(race)\n            if transformed:\n                clean_records.append(transformed)\n            else:\n                quarantined_records.append(\n                    {\n                        \"race_id\": race.get(\"id\"),\n                        \"source\": race.get(\"source\"),\n                        \"payload\": json.dumps(race),\n                        \"reason\": reason,\n                    }\n                )\n\n        with self.engine.connect() as connection:\n            try:\n                with connection.begin():  # Transaction block\n                    if clean_records:\n                        # Using ON CONFLICT to prevent duplicates\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO historical_races (\n                                race_id, venue, race_number, start_time, source,\n                                qualification_score, field_size\n                            )\n                            VALUES (\n                                :race_id, :venue, :race_number, :start_time, :source,\n                                :qualification_score, :field_size\n                            )\n                            ON CONFLICT (race_id) DO NOTHING;\n                        \"\"\"\n                        )\n                        connection.execute(stmt, clean_records)\n                        logger.info(f\"Inserted/updated {len(clean_records)} records into historical_races.\")\n\n                    if quarantined_records:\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO quarantined_races (race_id, source, payload, reason)\n                            VALUES (:race_id, :source, :payload::jsonb, :reason);\n                        \"\"\"\n                        )\n                        connection.execute(stmt, quarantined_records)\n                        logger.warning(f\"Moved {len(quarantined_records)} records to quarantine.\")\n            except SQLAlchemyError as e:\n                logger.error(f\"Database transaction failed: {e}\", exc_info=True)\n\n        logger.info(\"ETL process finished.\")\n\n\ndef run_etl_for_yesterday():\n    from datetime import timedelta\n\n    yesterday = date.today() - timedelta(days=1)\n    etl = ScribesArchivesETL()\n    etl.run(yesterday)\n",
    "web_service/backend/logging_config.py": "# python_service/logging_config.py\nimport logging\nimport sys\n\nimport structlog\n\n\ndef configure_logging(log_level: str = \"INFO\"):\n    \"\"\"Configures structlog for structured, JSON-formatted logging.\"\"\"\n    logging.basicConfig(\n        level=log_level,\n        format=\"%(message)s\",\n        stream=sys.stdout,\n    )\n\n    # Keep the processor chain simple for maximum reliability in bundled executables.\n    # More complex processors like StackInfoRenderer can cause issues in\n    # constrained environments.\n    structlog.configure(\n        processors=[\n            structlog.stdlib.filter_by_level,\n            structlog.stdlib.add_log_level,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n        cache_logger_on_first_use=True,\n    )\n",
    "web_service/backend/models_v3.py": "# python_service/models_v3.py\n# Defines the data structures for the V3 adapter architecture.\n\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import List\n\n\n@dataclass\nclass NormalizedRunner:\n    runner_id: str\n    name: str\n    saddle_cloth: str\n    odds_decimal: float\n\n\n@dataclass\nclass NormalizedRace:\n    race_key: str\n    track_key: str\n    start_time_iso: str\n    race_name: str\n    runners: List[NormalizedRunner] = field(default_factory=list)\n    source_ids: List[str] = field(default_factory=list)\n",
    "web_service/backend/requirements-dev.txt": "#\n# Development & Build-Time Dependencies\n# This file should be used for setting up a development or CI/CD environment.\n#\n\n-r requirements.txt\n\n# --- Build Tools ---\npyinstaller==6.6.0\npip-tools\n\n# --- Testing Tools ---\npytest\npytest-asyncio\nfakeredis\nrespx\n\n# --- Linting & Auditing ---\nblack\nruff\npip-audit\nsetuptools<81\n",
    "web_service/backend/tests/test_web_service_manual_override.py": "# python_service/tests/test_manual_override.py\nimport pytest\n\n# Use an absolute import as a workaround for the broken test environment.\n# Pytest is not recognizing this directory as part of a package, so relative imports fail.\nfrom manual_override_manager import ManualOverrideManager\n\n\n@pytest.fixture\ndef manager():\n    # The manager is now in-memory and doesn't need a path\n    return ManualOverrideManager()\n\n\ndef test_register_and_retrieve(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n    content = \"<html>Manual content</html>\"\n    content_type = \"text/html\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    success = manager.submit_manual_data(\n        request_id=request_id,\n        raw_content=content,\n        content_type=content_type,\n    )\n\n    assert success\n\n    # Verify that the data can be retrieved correctly\n    retrieved_data = manager.get_manual_data(adapter_name=adapter, url=url)\n    assert retrieved_data is not None\n    retrieved_content, retrieved_type = retrieved_data\n    assert retrieved_content == content\n    assert retrieved_type == content_type\n\n    # Verify that data is consumed after retrieval\n    assert manager.get_manual_data(adapter_name=adapter, url=url) is None\n",
    "web_service/backend/user_friendly_errors.py": "# python_service/user_friendly_errors.py\n\n\"\"\"\nCentralized dictionary for mapping technical exceptions to user-friendly messages.\n\"\"\"\n\nERROR_MAP = {\n    \"AdapterHttpError\": {\n        \"message\": \"A data source is currently unavailable.\",\n        \"suggestion\": (\n            \"This is usually temporary. Please try again in a few minutes. \"\n            \"If the problem persists, the website may be down for maintenance.\"\n        ),\n    },\n    \"AdapterConfigError\": {\n        \"message\": \"A data adapter is misconfigured.\",\n        \"suggestion\": \"Please check that all required API keys and settings are present in your .env file.\",\n    },\n    \"default\": {\n        \"message\": \"An unexpected error occurred.\",\n        \"suggestion\": \"Please check the application logs for more details or contact support.\",\n    },\n}\n",
    "web_service/frontend/app/components/ErrorDisplay.tsx": "// web_platform/frontend/src/components/ErrorDisplay.tsx\n'use client';\n\nimport React from 'react';\n\ninterface ErrorInfo {\n  message: string;\n  suggestion: string;\n  details?: string;\n}\n\ninterface ErrorDisplayProps {\n  error: ErrorInfo;\n}\n\nexport const ErrorDisplay: React.FC<ErrorDisplayProps> = ({ error }) => {\n  return (\n    <div className=\"bg-red-900/20 border border-red-500/30 text-white rounded-lg p-6 max-w-2xl mx-auto my-8\">\n      <div className=\"flex items-center mb-4\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-8 w-8 text-red-400 mr-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n          <path fillRule=\"evenodd\" d=\"M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z\" clipRule=\"evenodd\" />\n        </svg>\n        <h2 className=\"text-2xl font-bold text-red-400\">An Error Occurred</h2>\n      </div>\n      <p className=\"text-lg text-slate-300 mb-2\">{error.message}</p>\n      <p className=\"text-slate-400 mb-6\">{error.suggestion}</p>\n      {error.details && (\n        <details className=\"bg-slate-800/50 rounded-lg p-4\">\n          <summary className=\"cursor-pointer text-sm text-slate-500 hover:text-white\">\n            Technical Details\n          </summary>\n          <pre className=\"text-xs text-slate-400 mt-2 p-2 bg-black/30 rounded overflow-x-auto\">\n            <code>{error.details}</code>\n          </pre>\n        </details>\n      )}\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/RaceCard.tsx": "// web_platform/frontend/src/components/RaceCard.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\nimport type { Race, Runner } from '../types/racing';\n\n// Local types removed, now importing from '../types/racing'\n\ninterface RaceCardProps {\n  race: Race;\n}\n\nconst Countdown: React.FC<{ startTime: string }> = ({ startTime }) => {\n  const [currentTime, setCurrentTime] = useState(new Date());\n\n  useEffect(() => {\n    const timer = setInterval(() => setCurrentTime(new Date()), 1000);\n    return () => clearInterval(timer);\n  }, []);\n\n  const getCountdown = (startTimeStr: string) => {\n    const postTime = new Date(startTimeStr);\n    const diff = postTime.getTime() - currentTime.getTime();\n\n    if (diff <= 0) return { text: \"RACE COMPLETE\", color: \"text-gray-500\" };\n\n    const minutes = Math.floor(diff / 60000);\n    const seconds = Math.floor((diff % 60000) / 1000).toString().padStart(2, '0');\n\n    let color = \"text-green-400\";\n    if (minutes < 2) color = \"text-red-500 font-bold animate-pulse\";\n    else if (minutes < 10) color = \"text-yellow-400\";\n\n    return { text: `${minutes}:${seconds} to post`, color };\n  };\n\n  const countdown = getCountdown(startTime);\n\n  return (\n    <span className={`font-mono text-sm ${countdown.color}`}>{countdown.text}</span>\n  );\n};\n\nexport const RaceCard: React.FC<RaceCardProps> = ({ race }) => {\n  const activeRunners = race.runners.filter(r => !r.scratched);\n  activeRunners.sort((a, b) => a.number - b.number);\n\n  const getUniqueSourcesCount = (runners: Runner[]): number => {\n    const sources = new Set();\n    runners.forEach(runner => {\n      if (runner.odds) {\n        Object.keys(runner.odds).forEach(source => sources.add(source));\n      }\n    });\n    return sources.size;\n  };\n\n  const getBestOdds = (runner: Runner): { odds: number, source: string } | null => {\n    if (!runner.odds) return null;\n  const validOdds = Object.values(runner.odds).filter(o => o.win !== null && o.win !== undefined && o.win < 999);\n    if (validOdds.length === 0) return null;\n  const best = validOdds.reduce((min, o) => (o.win ?? 999) < (min.win ?? 999) ? o : min);\n    return { odds: best.win!, source: best.source };\n  };\n\n  return (\n    <div className={`race-card-enhanced border rounded-lg p-4 bg-gray-800 shadow-lg hover:border-purple-500 transition-all ${race.qualification_score && race.qualification_score >= 80 ? 'card-premium' : 'border-gray-700'}`}>\n      {/* Header with Smart Status Indicators */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <h2 className=\"text-2xl font-bold text-white\">{race.venue}</h2>\n            <div className=\"flex gap-2 text-sm text-gray-400\">\n              <span>Race {race.race_number}</span>\n              <span>\u2022</span>\n              <Countdown startTime={race.start_time} />\n            </div>\n            {race.favorite && (\n              <div className=\"flex items-center gap-2 mt-2 text-sm text-yellow-400\">\n                <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-4 w-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n                  <path d=\"M9.049 2.927c.3-.921 1.603-.921 1.902 0l1.07 3.292a1 1 0 00.95.69h3.462c.969 0 1.371 1.24.588 1.81l-2.8 2.034a1 1 0 00-.364 1.118l1.07 3.292c.3.921-.755 1.688-1.54 1.118l-2.8-2.034a1 1 0 00-1.175 0l-2.8 2.034c-.784.57-1.838-.197-1.539-1.118l1.07-3.292a1 1 0 00-.364-1.118L2.98 8.72c-.783-.57-.38-1.81.588-1.81h3.461a1 1 0 00.951-.69l1.07-3.292z\" />\n                </svg>\n                <span className=\"font-semibold\">Favorite: {race.favorite.name}</span>\n              </div>\n            )}\n          </div>\n        </div>\n\n        {race.qualification_score && (\n          <div className={`px-4 py-2 rounded-full text-center ${\n            race.qualification_score >= 80 ? 'bg-red-500/20 text-red-400 border border-red-500/30' :\n            race.qualification_score >= 60 ? 'bg-yellow-500/20 text-yellow-400 border border-yellow-500/30' :\n            'bg-green-500/20 text-green-400 border border-green-500/30'\n          }`}>\n            <div className=\"font-bold text-lg\">{race.qualification_score.toFixed(0)}%</div>\n            <div className=\"text-xs\">Score</div>\n          </div>\n        )}\n      </div>\n\n      {/* Race Conditions Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Distance</div>\n          <div className=\"text-sm font-semibold text-white\">{race.distance || 'N/A'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Surface</div>\n          <div className=\"text-sm font-semibold text-white\">{race.surface || 'Dirt'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Field</div>\n          <div className=\"text-sm font-semibold text-white\">{activeRunners.length}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Sources</div>\n          <div className=\"text-sm font-semibold text-white\">{getUniqueSourcesCount(race.runners)}</div>\n        </div>\n      </div>\n\n      {/* Interactive Runner Rows */}\n      <div className=\"runners-table space-y-2\">\n        {activeRunners.map((runner, idx) => {\n          const bestOddsInfo = getBestOdds(runner);\n          return (\n            <div key={runner.number} className=\"runner-row group hover:bg-purple-500/10 transition-all rounded-md p-3\">\n              <div className=\"flex items-center justify-between\">\n                <div className=\"flex items-center gap-4 flex-1\">\n                  <div className={`w-10 h-10 rounded-full flex items-center justify-center font-bold transition-all group-hover:scale-110 text-gray-900 shadow-lg ${idx === 0 ? 'bg-gradient-to-br from-yellow-400 to-yellow-600 shadow-yellow-500/50' : idx === 1 ? 'bg-gradient-to-br from-gray-300 to-gray-500 shadow-gray-400/50' : idx === 2 ? 'bg-gradient-to-br from-orange-400 to-orange-600 shadow-orange-500/50' : 'bg-gray-700 text-gray-300'}`}>\n                    {runner.number}\n                  </div>\n                  <div className=\"flex flex-col\">\n                    <span className=\"font-bold text-white text-lg\">{runner.name}</span>\n                    <div className=\"flex gap-3 text-sm text-gray-400\">\n                      {runner.jockey && <span>J: {runner.jockey}</span>}\n                      {runner.trainer && <span>T: {runner.trainer}</span>}\n                    </div>\n                  </div>\n                </div>\n                {bestOddsInfo && (\n                  <div className=\"text-right\">\n                    <div className=\"text-2xl font-bold text-emerald-400\">{bestOddsInfo.odds.toFixed(2)}</div>\n                    <div className=\"text-xs text-gray-500\">via {bestOddsInfo.source}</div>\n                  </div>\n                )}\n              </div>\n            </div>\n          );\n        })}\n      </div>\n    </div>\n  );\n};",
    "web_service/frontend/app/components/ScoreBadge.tsx": "'use client';\nimport React from 'react';\n\nconst getScoreStyling = (score: number) => {\n  if (score >= 90) return { bg: 'bg-yellow-400/10', text: 'text-yellow-300', border: 'border-yellow-400' };\n  if (score >= 80) return { bg: 'bg-orange-500/10', text: 'text-orange-400', border: 'border-orange-500' };\n  return { bg: 'bg-sky-500/10', text: 'text-sky-400', border: 'border-sky-500' };\n};\n\nexport const ScoreBadge: React.FC<{ score: number }> = ({ score }) => {\n  const { bg, text } = getScoreStyling(score);\n  return (\n    <div className={`text-right ${text}`}>\n      <p className=\"text-3xl font-bold\">{score.toFixed(1)}</p>\n      <p className=\"text-xs font-medium tracking-wider uppercase\\\">Score</p>\n    </div>\n  );\n};",
    "web_service/frontend/app/lib/queryClient.ts": "// web_platform/frontend/src/lib/queryClient.ts\nimport { QueryClient } from '@tanstack/react-query';\n\nexport const queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      retry: 3,\n      staleTime: 1000 * 60 * 5, // 5 minutes\n    },\n  },\n});\n",
    "web_service/frontend/app/types/electron.d.ts": "// web_platform/frontend/src/types/electron.d.ts\n\n/**\n * This declaration file extends the global Window interface to include the\n * 'electronAPI' object exposed by the preload script. This provides\n * TypeScript with type information for the functions we're using for IPC.\n */\nexport {};\n\ndeclare global {\n  interface Window {\n    electronAPI?: {\n      /**\n       * Asynchronously fetches the secure API key from the main process.\n       * @returns {Promise<string|null>} A promise that resolves with the API key or null if not found.\n       */\n      getApiKey: () => Promise<string | null>;\n      /**\n       * Registers a callback for backend status updates from the main process.\n       * @param callback The function to execute. Receives an object with state and logs.\n       * @returns A function to unsubscribe the listener.\n       */\n      onBackendStatusUpdate: (callback: (status: { state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }) => void) => () => void;\n\n      /**\n       * Sends a command to the main process to restart the backend executable.\n       */\n      restartBackend: () => void;\n\n      /**\n       * Asynchronously fetches the current backend status from the main process.\n       * @returns {Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>}\n       */\n      getBackendStatus: () => Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>;\n      generateApiKey: () => Promise<string>;\n      saveApiKey: (apiKey: string) => Promise<{ success: boolean }>;\n      saveBetfairCredentials: (credentials: { appKey: string; username: string; password: string }) => Promise<{ success: boolean }>;\n      getApiPort: () => Promise<number | null>;\n    };\n  }\n}\n",
    "web_service/frontend/public/manifest.json": "{\n  \"name\": \"Fortuna Faucet Command Deck\",\n  \"short_name\": \"Fortuna\",\n  \"description\": \"Real-time racing analysis.\",\n  \"start_url\": \"/\",\n  \"display\": \"standalone\",\n  \"background_color\": \"#1a202c\",\n  \"theme_color\": \"#1a202c\",\n  \"icons\": [\n    {\n      \"src\": \"/icons/icon-192x192.png\",\n      \"sizes\": \"192x192\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/icon-512x512.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\"\n    }\n  ]\n}\n",
    "wix/product.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:util=\"http://schemas.microsoft.com/wix/UtilExtension\">\n\n  <Product\n    Id=\"*\"\n    Name=\"Fortuna Faucet - Racing Analysis Engine\"\n    Language=\"1033\"\n    Version=\"$(var.Version)\"\n    Manufacturer=\"Mason J0 Studios\"\n    UpgradeCode=\"12345678-1234-1234-1234-123456789012\">\n\n    <Package\n      InstallerVersion=\"200\"\n      Compressed=\"yes\"\n      InstallScope=\"perMachine\"\n      Platform=\"x64\"\n      Description=\"Horse racing analysis platform\"\n      Comments=\"Professional-grade installer\"/>\n\n    <Media Id=\"1\" Cabinet=\"fortuna.cab\" EmbedCab=\"yes\"/>\n\n    <!-- Directory Structure -->\n    <Directory Id=\"TARGETDIR\" Name=\"SourceDir\">\n      <Directory Id=\"ProgramFiles64Folder\">\n        <Directory Id=\"INSTALLFOLDER\" Name=\"Fortuna Faucet\">\n        </Directory>\n      </Directory>\n      <Directory Id=\"ProgramMenuFolder\">\n        <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Faucet\"/>\n      </Directory>\n    </Directory>\n\n    <!-- Environment Variable -->\n    <ComponentGroup Id=\"EnvironmentComponentGroup\" Directory=\"INSTALLFOLDER\">\n      <Component Id=\"FortunaPortEnvironmentVar\" Guid=\"*\">\n        <Environment Id=\"FortunaPort\" Name=\"FORTUNA_PORT\" Value=\"8000\" Permanent=\"no\" Action=\"set\" System=\"yes\" />\n        <RegistryValue Root=\"HKLM\" Key=\"Software\\Fortuna Faucet\" Name=\"Path\" Type=\"string\" Value=\"[INSTALLFOLDER]\" KeyPath=\"yes\" />\n      </Component>\n    </ComponentGroup>\n\n    <!-- Features -->\n    <!-- Service Installation -->\n    <ComponentGroup Id=\"ServiceComponentGroup\" Directory=\"INSTALLFOLDER\">\n        <Component Id=\"FortunaBackendService\" Guid=\"*\">\n            <File Id=\"fortuna-backend.exe\" Source=\"$(var.BackendPath)\" KeyPath=\"yes\" />\n            <ServiceInstall\n                Id=\"FortunaServiceInstall\"\n                Type=\"ownProcess\"\n                Name=\"Fortuna\"\n                DisplayName=\"Fortuna Faucet Backend\"\n                Description=\"Data aggregation and analysis engine for horse racing.\"\n                Start=\"auto\"\n                Account=\"LocalSystem\"\n                ErrorControl=\"normal\" />\n            <ServiceControl Id=\"StartFortunaService\" Start=\"install\" Stop=\"uninstall\" Remove=\"uninstall\" Name=\"Fortuna\" Wait=\"no\" />\n        </Component>\n    </ComponentGroup>\n\n    <Feature Id=\"ProductFeature\" Title=\"Fortuna Faucet\" Level=\"1\">\n        <ComponentGroupRef Id=\"BackendFileGroup\"/>\n        <ComponentGroupRef Id=\"FrontendFileGroup\"/>\n        <ComponentGroupRef Id=\"ShortcutsComponentGroup\"/>\n        <ComponentGroupRef Id=\"EnvironmentComponentGroup\"/>\n        <ComponentGroupRef Id=\"ServiceComponentGroup\"/>\n    </Feature>\n\n    <!-- Shortcuts -->\n    <ComponentGroup Id=\"ShortcutsComponentGroup\" Directory=\"ApplicationProgramsFolder\">\n      <Component Id=\"ApplicationShortcuts\" Guid=\"*\">\n          <util:InternetShortcut Id=\"DashboardShortcut\" Name=\"Fortuna Faucet Dashboard\" Target=\"http://localhost:3000\"/>\n          <Shortcut Id=\"UninstallShortcut\" Name=\"Uninstall Fortuna Faucet\" Description=\"Remove this application\" Target=\"[SystemFolder]msiexec.exe\" Arguments=\"/x [ProductCode]\" Advertise=\"no\"/>\n          <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\"/>\n          <RegistryValue Root=\"HKCU\" Key=\"Software\\Fortuna Faucet\" Name=\"Installed\" Type=\"integer\" Value=\"1\" KeyPath=\"yes\"/>\n      </Component>\n    </ComponentGroup>\n\n    <!-- UI -->\n    <UI>\n      <UIRef Id=\"WixUI_CustomInstallDir\" />\n    </UI>\n    <UIRef Id=\"WixUI_Common\" />\n    <Property Id=\"WIXUI_INSTALLDIR\" Value=\"INSTALLFOLDER\" />\n    <WixVariable Id=\"WixUILicenseRtf\" Value=\"electron\\assets\\license.rtf\"/>\n    <WixVariable Id=\"WixUIBannerBmp\" Value=\"electron\\assets\\banner.bmp\"/>\n    <WixVariable Id=\"WixUIDialogBmp\" Value=\"electron\\assets\\dialog.bmp\"/>\n\n    <Condition Message=\"Windows 7 or later (64-bit) is required\">\n      <![CDATA[Installed OR (VersionNT64 >= 601)]]>\n    </Condition>\n\n  </Product>\n</Wix>\n"
}