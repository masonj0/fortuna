{
    ".github/workflows/build-msi.yml": "name: Build Fortuna Faucet MSI Installer\n\non:\n  push:\n    branches: [main]\n    tags:\n      - 'v*'\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  build-installer:\n    name: Build MSI Installer\n    runs-on: windows-latest\n\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n          cache: 'npm'\n          cache-dependency-path: |\n            electron/package-lock.json\n            web_platform/frontend/package-lock.json\n\n      - name: Install Frontend Dependencies & Build\n        run: |\n          cd web_platform/frontend\n          npm ci\n          npm run build\n\n      - name: Install Electron Dependencies\n        run: |\n          cd electron\n          npm ci\n\n      - name: Setup Python 3.12\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n\n      - name: Build Backend Executable with PyInstaller\n        run: |\n          pip install -r requirements-dev.txt\n          cd python_service\n          pyinstaller --onefile --hidden-import=uvicorn --add-data \"adapters;adapters\" api.py\n        shell: bash\n\n      - name: Build MSI Installer using electron-builder\n        run: |\n          cd electron\n          npm run dist\n        env:\n          FORTUNA_BUILD_TYPE: 'full' # For now, we only build the full version\n\n      - name: Generate sanitized artifact name\n        id: sanitize\n        shell: bash\n        run: echo \"name=fortuna-faucet-installer-$(echo ${{ github.ref_name }} | sed 's/\\//-/g')\" >> $GITHUB_OUTPUT\n\n      - name: Upload MSI Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: ${{ steps.sanitize.outputs.name }}\n          path: \"electron/dist/JBMason's 1st App*.msi\"\n          retention-days: 30\n\n      - name: Create Release (on tag)\n        if: startsWith(github.ref, 'refs/tags/')\n        uses: softprops/action-gh-release@v1\n        with:\n          files: \"electron/dist/JBMason's 1st App*.msi\"\n          name: \"JBMason's 1st App ${{ github.ref_name }}\"\n          draft: false\n          prerelease: false\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    ".gitignore": "# Byte-compiled / optimized files\n__pycache__/\n*.pyc\n\n# Distribution / packaging\nbuild/\ndist/\n*.egg-info/\n\n# Unit test / coverage reports\n.pytest_cache/\n.coverage\n\n# Environments\n.venv/\nvenv/\nenv/\n\n# IDE settings\n.vscode/\n.idea/\n\n# Database files\n*.db\n*.sqlite\n*.sqlite3\n\n# Node.js\nnode_modules/\n/ui/node_modules/\n/ui/build/\nweb_platform/frontend/.next/\n\n# Environment files\n.env\n.env.*\n!/web_platform/frontend/.env.local\n\n# Log files\n*.log\n*.log*\n\n\n# Security\n.key\n",
    "AGENTS.md": "# Agent Protocols & Team Structure (Revised)\n\nThis document outlines the operational protocols and evolved team structure for the Checkmate\nV3 project.\n\n## The Evolved Team Structure\n\n-   **The Project Lead (MasonJ0 or JB):** The \"Executive Producer.\" The ultimate authority and \"ground truth.\"\n-   **The Architect & Synthesizer (Gemini):** The \"Chief Architect.\" Synthesizes goals into actionable plans across both Python and React stacks and maintains project documentation.\n-   **The Lead Python Engineer (Jules Series):** The \"Backend Specialist.\" An AI agent responsible for implementing and hardening The Engine (`api.py`, `services.py`, `logic.py`, `models.py`).\n-   **The Lead Frontend Architect (Claude):** The \"React Specialist.\" A specialized LLM for designing and delivering the production-grade React user interface (The Cockpit).\n-   **The \"Special Operations\" Problem Solver (GPT-5):** The \"Advanced Algorithm Specialist.\" A specialized LLM for novel, complex problems.\n\n## Core Philosophies\n\n1.  **The Project Lead is Ground Truth:** The ultimate authority. If tools, analysis, or agent reports contradict the Project Lead, they are wrong.\n2.  **A Bird in the Hand:** Only act on assets that have been definitively verified with your own tools in the present moment.\n3.  **Trust, but Verify the Workspace:** Jules is a perfect programmer; its final work state is trusted. Its *environment*, however, is fragile.\n4.  **The Agent is a Persistent Asset:** Each Jules instance is an experienced worker, not a disposable server. Its internal state is a repository of unique, hard-won knowledge.\n\n## CRITICAL Operational Protocols (0-23)\n\n-   **Protocol 0: The ReviewableJSON Mandate:** The mandatory protocol for all code reviews. The agent's final act for any mission is to create a lossless JSON backup of all modified files. This is the single source of truth for code review.\n-   **Protocol 1: The Handcuffed Branch:** Jules cannot switch branches. An entire session lives on a single `session/jules...` branch.\n-   **Protocol 2: The Last Resort Reset:** The `reset_all()` command is a tool of last resort for a catastrophic workspace failure and requires direct authorization from the Project Lead.\n-   **Protocol 3: The Authenticity of Sample Data:** All sample data used for testing must be authentic and logically consistent.\n-   **Protocol 4: The Agent-Led Specification:** Where a human \"Answer Key\" is unavailable, Jules is empowered to analyze raw data and create its own \"Test-as-Spec.\"\n-   **Protocol 5: The Test-First Development Workflow:** The primary development methodology. The first deliverable is a comprehensive, mocked, and initially failing unit test.\n-   **Protocol 6: The Emergency Chat Handoff:** In the event of a catastrophic environmental failure, Jules's final act is to declare a failure and provide its handoff in the chat.\n-   **Protocol 7: The URL-as-Truth Protocol:** To transfer a file or asset without corruption, provide a direct raw content URL. The receiving agent must fetch it.\n-   **Protocol 8: The Golden Link Protocol:** For fetching the content of a specific, direct raw-content URL from the `main` branch, a persistent \"Golden Link\" should be used.\n-   **Protocol 9: The Volley Protocol:** To establish ground truth for a new file, the Architect provides a URL, and the Project Lead \"volleys\" it back by pasting it in a response.\n-   **Protocol 10: The Sudo Sanction:** Jules has passwordless `sudo` access, but its use is forbidden for normal operations. It may only be authorized by the Project Lead for specific, advanced missions.\n-   **Protocol 11: The Module-First Testing Protocol:** All test suites must be invoked by calling `pytest` as a Python module (`python -m pytest`) to ensure the correct interpreter is used.\n-   **Protocol 12: The Persistence Mandate:** The agent tool execution layer is known to produce false negatives. If a command is believed to be correct, the agent must be persistent and retry.\n-   **Protocol 13: The Code Fence Protocol for Asset Transit:** To prevent the chat interface from corrupting raw code assets, all literal code must be encapsulated within a triple-backtick Markdown code fence.\n-   **Protocol 14: The Synchronization Mandate:** The `git reset --hard origin/main` command is strictly forbidden. To stay synchronized with `main`, the agent MUST use `git pull origin main`.\n-   **Protocol 15: The Blueprint vs. Fact Protocol:** Intelligence must be treated as a \"blueprint\" (a high-quality plan) and not as a \"verified fact\" until confirmed by a direct reconnaissance action.\n-   **Protocol 16: The Digital Attic Protocol:** Before the deletion of any file, it must first be moved to a dedicated archive directory named `/attic`.\n-   **Protocol 17: The Receipts Protocol:** When reviewing code, a verdict must be accompanied by specific, verifiable \"receipts\"\u2014exact snippets of code that prove a mission objective was met.\n-   **Protocol 18: The Cumulative Review Workflow:** Instruct Jules to complete a series of missions and then conduct a single, thorough review of its final, cumulative branch state.\n-   **Protocol 19: The Stateless Verification Mandate:** The Architect, when reviewing code, must act with fresh eyes, disregarding its own memory and comparing the submitted code directly and exclusively against the provided specification.\n-   **Protocol 20: The Sudo Sanction Protocol:** Grants a Jules-series agent temporary, audited administrative privileges for specific, authorized tasks like system package installation.\n-   **Protocol 21: The Exit Interview Protocol:** Before any planned termination of an agent, the Architect will charter a final mission to capture the agent's institutional knowledge for its successor.\n-   **Protocol 22: The Human-in-the-Loop Merge:** In the event of an unresolvable merge conflict in an agent's environment, the Project Lead, as the only agent with a fully functional git CLI, will check out the agent's branch and perform the merge resolution manually.\n-   **Protocol 23: The Appeasement Protocol (Mandatory):** To safely navigate the broken automated review bot, all engineering work must be published using a two-stage commit process. First, commit a trivial change to appease the bot. Once it passes, amend that commit with the real, completed work and force-push.\n\n---\n\n## Appendix A: Forensic Analysis of the Jules Sandbox Environment\n\n*The following are the complete, raw outputs of diagnostic missions executed by Jules-series agents. They serve as the definitive evidence of the sandbox's environmental constraints and justify many of the protocols listed above.*\n\n### A.1 Node.js / NPM & Filesystem Forensics (from \"Operation: Sandbox Forensics\")\n\n**Conclusion:** The `npm` tool is functional, but the `/app` volume is hostile to its operation, preventing the creation of binary symlinks. This makes Node.js development within the primary workspace impossible.\n\n**Raw Logs:**\n\n```\n# Phase 1: Node.js & NPM Configuration Analysis\nnpm config get prefix\n/home/jules/.nvm/versions/node/v22.17.1\n\n# Phase 4: Controlled Installation Experiment\ncd /tmp && mkdir npm_test && cd npm_test\nnpm install --verbose cowsay\n# ... (successful installation log) ...\nls -la node_modules/.bin\ntotal 8\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowsay -> ../cowsay/cli.js\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowthink -> ../cowsay/cli.js\nnpx cowsay \"Test\"\n  ______\n< Test >\n ------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n```\n\n### A.2 Process Management & Honcho Forensics (from \"Operation: Know Thyself\")\n\n**Conclusion:** The sandbox does not support standard background processes (`&`), the `kill` command is non-functional, and the `honcho` process manager leaves zombie processes (`[uvicorn] <defunct>`) upon termination. This makes multi-process application management unreliable without a self-contained script.\n\n**Raw Logs:**\n\n```\n# Phase 2: The honcho Stress Test\n\ntimeout 15s honcho start\n# ... (honcho starts and is terminated by timeout) ...\n\nps aux (Post-Mortem Analysis)\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n...\njules      30121  0.0  0.0      0     0 ?        Z    19:45   0:00 [uvicorn]\n...\n\nhoncho start &\n# (Command blocks terminal, echo command never runs)\n\nps aux | grep honcho\njules      30187  0.0  0.0  11004  4220 pts/0    S    19:45   0:00 /usr/bin/python3 /home/jules/.local/bin/honcho start\n\nkill -9 30187\n# (Command fails silently, process is not terminated)\n```\n\n---\n\n## Protocol 24: The \"Dedicated Human Researcher\" Test\n\nThis protocol establishes the guiding ethical principle for all data collection and scraping activities.\n\nAll data adapters must be designed to operate in a manner that respects the resources of the source. As a definitive test, all fetching patterns must adhere to the following principle:\n\n*If a single, dedicated human using standard browser developer tools could not plausibly achieve the adapter's data collection footprint in a reasonable amount of time, the adapter's methods are considered too aggressive and must be redesigned.*\n\nThis encourages \"human-like\" fetching behavior (e.g., appropriate delays, non-parallel requests to a single source) and serves as our primary safeguard against violating a source's terms of service.\n",
    "ARCHITECTURAL_MANDATE.md": "# Fortuna Faucet - Architectural Mandate (v3.0)\n\nThis document codifies the architectural laws and philosophical principles that govern the Fortuna Faucet kingdom. Adherence to this mandate is non-negotiable for all development.\n\n---\n\n## The Prime Directive: A Professional, Resilient System\n\nThe ultimate goal of this project is to be a professional-grade, A+ intelligence engine. This is achieved through three core pillars:\n\n1.  **Rigid Standardization:** Code should be consistent and predictable. Shared logic must be centralized. Common patterns must be enforced, not merely suggested.\n2.  **Resilience Engineering:** The system must be self-healing and gracefully handle the failure of its individual components. We do not simply handle errors; we build a system that anticipates and survives them.\n3.  **Developer Clarity:** The codebase must be easy to understand, maintain, and extend. Code should be self-documenting, and its intent should be obvious.\n\n---\n\n## The Law of the Adapters: The `BaseAdapterV3` Pattern\n\nAll new data adapters **MUST** inherit from the `BaseAdapterV3` abstract base class. This is the cornerstone of our standardization and resilience strategy.\n\nThe `BaseAdapterV3` enforces a strict separation of concerns:\n\n1.  **`_fetch_data(self, date)` -> `Any`:** This method's **only** responsibility is to perform network operations and retrieve raw data (e.g., HTML, JSON). It should contain no parsing logic.\n2.  **`_parse_races(self, raw_data)` -> `list[Race]`:** This method's **only** responsibility is to parse the raw data provided by `_fetch_data` into a list of `Race` objects. It must be a pure function with no side effects or network calls.\n\nThe public-facing `get_races()` method is provided by the base class and **MUST NOT** be overridden. It orchestrates the fetch-then-parse pipeline, ensuring that all adapters behave identically from the engine's perspective.\n\nThis pattern guarantees that every adapter in our fleet is consistent, predictable, and easy to test.\n\n---\n\n## The Law of the Engine: Orchestrate, Don't Participate\n\nThe `OddsEngine` is the central orchestrator. Its responsibilities are:\n\n-   To manage the fleet of active adapters.\n-   To execute all adapter fetches in parallel.\n-   To gracefully handle the failure of any individual adapter without halting the entire process.\n-   To perform the deduplication and merging of race data from multiple sources.\n-   To manage the caching layer (Redis).\n\nThe engine should remain agnostic to the internal workings of any specific adapter. It interacts only with the standardized interface provided by `BaseAdapterV3`.\n\n---\n\n## The Law of the Core Texts: Maintain the Truth\n\nThe project's core documentation is not optional. It is the living memory and strategic guide of the kingdom.\n\n-   **`ROADMAP_APPENDICES.MD`:** The Grand Strategy must be kept current. Completed objectives must be marked as such.\n-   **`HISTORY.MD`:** Significant architectural shifts and completed campaigns must be chronicled.\n-   **`PSEUDOCODE.MD`:** The architectural blueprint must be updated to reflect major changes to the system's design.\n-   **Manifests (`MANIFEST*.md`):** All new files must be added to the appropriate manifest to ensure the integrity of the archival system.\n\n\n---\n\n## The Final Law: The Law of the True Scribe\n\n**Effective Date:** 2025-10-15\n\n**Verdict:** The system of manually maintained manifest files (`MANIFEST.md`, `MANIFEST2.md`, `MANIFEST3.md`) is hereby declared a catastrophic failure and is **permanently deprecated**.\n\n**The New Law:** The one and only method for generating the project's `FORTUNA_ALL` archives is the `ARCHIVE_PROJECT.py` script. This 'True Scribe' is the single, automated source of truth. It programmatically scans and categorizes the entire kingdom, ensuring a perfect, complete, and uncorrupted archive is generated every time.\n\nAll previous archival scripts (`create_fortuna_json.py`, `MANAGE_MANIFESTS.py`) are not to be used under any circumstances.",
    "ARCHIVE_PROJECT.py": "# ARCHIVE_PROJECT.py - The Manifest-Driven Scribe\n# This script generates the FORTUNA_ALL JSON archives based on the new JSON manifests.\n\nimport os\nimport json\nfrom pathlib import Path\n\n# --- Configuration ---\nPROJECT_ROOT = Path(__file__).parent\nOUTPUT_FILENAME_TEMPLATE = \"FORTUNA_ALL_PART{}.JSON\"\n\n# Map manifest files to their corresponding archive part number\nMANIFEST_MAP = {\n    \"MANIFEST_PART1_BACKEND.json\": 1,\n    \"MANIFEST_PART2_FRONTEND.json\": 2,\n    \"MANIFEST_PART3_SUPPORT.json\": 3,\n    \"MANIFEST_PART4_ROOT.json\": 4\n}\n\ndef run_archiver():\n    print(\"--- Fortuna Faucet Manifest-Driven Scribe ---\")\n    print(\"Generating archives from JSON manifests...\")\n\n    archives = {1: {}, 2: {}, 3: {}, 4: {}}\n    total_files_archived = 0\n\n    for manifest_file, part_num in MANIFEST_MAP.items():\n        manifest_path = PROJECT_ROOT / manifest_file\n\n        try:\n            with open(manifest_path, 'r', encoding='utf-8') as f:\n                file_list = json.load(f)\n        except FileNotFoundError:\n            print(f\"[ERROR] Manifest file not found: {manifest_file}. Skipping.\")\n            continue\n        except json.JSONDecodeError:\n            print(f\"[ERROR] Could not decode JSON from {manifest_file}. Skipping.\")\n            continue\n\n        print(f\"Processing {manifest_file} for PART {part_num}...\")\n        for relative_path in file_list:\n            file_path = PROJECT_ROOT / relative_path\n            try:\n                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                    content = f.read()\n                archives[part_num][relative_path] = content\n                total_files_archived += 1\n            except FileNotFoundError:\n                print(f\"[WARNING] File listed in manifest not found: {relative_path}\")\n            except Exception as e:\n                print(f\"[ERROR] Could not read file {relative_path}: {e}\")\n\n    print(f\"\\nProcessed {total_files_archived} files across {len(MANIFEST_MAP)} manifests.\")\n\n    # Write the four JSON archive files\n    for part_num, content_dict in archives.items():\n        if not content_dict:\n            print(f\"Skipping empty PART {part_num}.\")\n            continue\n\n        output_path = PROJECT_ROOT / OUTPUT_FILENAME_TEMPLATE.format(part_num)\n        try:\n            with open(output_path, 'w', encoding='utf-8') as f:\n                json.dump(content_dict, f, indent=4)\n            print(f\"\u2705 Successfully wrote {len(content_dict)} files to {output_path.name}\")\n        except Exception as e:\n            print(f\"[FATAL] Failed to write {output_path.name}: {e}\")\n\n    print(\"\\n[SUCCESS] All manifest-driven archives are complete!\")\n\nif __name__ == \"__main__\":\n    run_archiver()\n",
    "BUILD_INSTALLER.bat": "@ECHO OFF\nTITLE Fortuna Faucet - Master MSI Builder\n\nREM --- Phase 1: Administrator Check ---\n>nul 2>&1 \"%SYSTEMROOT%\\system32\\cacls.exe\" \"%SYSTEMROOT%\\system32\\config\\system\"\nIF '%errorlevel%' NEQ '0' ( ECHO [ERROR] Administrator privileges are required. && PAUSE && EXIT /B 1 )\n\nECHO.\nECHO =================================================\nECHO  Fortuna Faucet - Master MSI Installer Builder\nECHO =================================================\nECHO.\n\nREM --- Phase 2: Pre-Flight Checks ---\nECHO [1/4] Running pre-flight environment checks...\nnpm -v >nul 2>&1\nIF %ERRORLEVEL% NEQ 0 ( ECHO [FAIL] Node.js (npm) is not found. && PAUSE && EXIT /B 1 )\nIF NOT EXIST .venv\\Scripts\\activate.bat ( ECHO [FAIL] Python environment not found. Please run run_dev_environment.bat once. && PAUSE && EXIT /B 1 )\nECHO [OK] Environment is ready for build.\nECHO.\n\nECHO [2/4] Installing/Verifying Node.js dependencies...\nECHO  - Frontend...\ncd web_platform\\frontend && npm install && cd ..\\..\nECHO  - Electron...\ncd electron && npm install && cd ..\nECHO [OK] Node.js dependencies are up to date.\nECHO.\n\nECHO Press any key to begin the build process...\nPAUSE > NUL\n\nECHO.\nECHO [3/4] Building the MSI installer via electron-builder...\nECHO This may take several minutes. Please be patient.\nECHO.\ncd electron\nnpm run dist\nIF %ERRORLEVEL% NEQ 0 ( ECHO [X] FAILED to build the MSI installer. && cd .. && PAUSE && EXIT /B 1 )\ncd ..\n\nECHO.\nECHO [4/4] Moving final MSI to project root...\nFOR /F \"delims=\" %%i IN ('dir /b electron\\dist\\*.msi') DO (\n    MOVE /Y \"electron\\dist\\%%i\" . > NUL\n    ECHO [V] The installer [%%i] has been moved to the project root directory.\n)\nECHO.\n\nECHO =================================================\nECHO  BUILD SUCCESSFUL!\nECHO =================================================\nECHO.\nPAUSE",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `fortuna`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n\n---\n\n## The Age of Perfection (The Great Simplification)\n\nThe Penta-Hybrid architecture, while a triumph of technical integration, proved to be a strategic dead end. Its complexity became a fortress, making rapid iteration and onboarding of new intelligence (both human and AI) prohibitively expensive. The kingdom was powerful but brittle.\n\nA new doctrine was forged: **Simplicity is the ultimate sophistication.**\n\nThe decision was made to execute \"The Great Simplification.\" The multi-language backend (Python, Rust, Go) was decommissioned. The kingdom was reforged upon a new, elegant, and vastly more powerful two-pillar system:\n\n1.  **A Unified Python Backend:** A single, asynchronous Python service, built on FastAPI, would serve as the kingdom's engine.\n2.  **A Modern TypeScript Frontend:** A dedicated Next.js application would serve as the kingdom's command deck.\n\nThis act of creative destruction liberated the project, enabling a new era of unprecedented velocity.\n\n---\n\n## The Three-Pillar Doctrine\n\nWith the new two-pillar foundation in place, the backend itself was perfected into a three-pillar intelligence engine, a concept that defines the modern era of the Fortuna Faucet:\n\n*   **Pillar 1: The Future (The Planner):** The resilient `OddsEngine` and its fleet of adapters, responsible for finding the day's strategic opportunities.\n*   **Pillar 2: The Past (The Archive):** The perfected `ChartScraper` and `ResultsParser`, responsible for building our historical data warehouse from the ground truth of Equibase PDFs.\n*   **Pillar 3: The Present (The Finisher):** The weaponized `LiveOddsMonitor`, armed with the API-driven `BetfairAdapter`, designed to conquer the final moments of toteboard volatility.\n\nThese three pillars, orchestrated by the fully autonomous `fortuna_watchman.py`, represented the pinnacle of the project's original vision. The kingdom was, for a time, considered \"perfected.\"\n\n---\n\n## The Windows Ascension (The Impossible Dream)\n\nThe perfected kingdom was powerful, but it was still a tool for developers. The final, grandest vision was to transform it into a true, professional-grade application for its sole operator. This campaign, known as \"The Impossible Dream,\" was to forge the **Fortuna Faucet - Windows Native Edition.**\n\nThis era saw the rapid creation of a new, third layer of the kingdom, built upon the foundation of the previous work:\n\n*   **The Electron Shell:** The Next.js frontend was wrapped in an Electron container, transforming it from a website into a true, installable desktop application with its own window, icon, and system tray integration.\n*   **The Engine Room:** The Python backend was re-architected to run as a persistent, background **Windows Service**, making it a true, always-on component of the operating system, independent of the UI.\n*   **The Native GUI:** A dedicated Tkinter-based \"Observatory\" was forged\u2014a standalone GUI mission control for monitoring the health and performance of the background service.\n*   **The One-Click Kingdom:** A complete suite of professional tooling (including installation scripts, a setup wizard, and launchers) was created to provide a seamless, zero-friction installation and management experience.\n\nThis ascension represents the current state of the art, transforming a powerful engine into a polished, autonomous, and user-focused product.\n\n\n---\n\n## The Era of the Windows Kingdom (October 2025)\n\nWith the core engine stabilized and the command deck providing a clear view of the data, the project's focus shifted from pure data acquisition to the operator's experience. This era marked a profound transformation, elevating the project from a collection of powerful but disparate scripts into a cohesive, professional-grade, and resilient native Windows application.\n\nThis campaign, guided by a new \"Grand Strategy\" blueprint, was executed with rapid precision, resulting in a complete overhaul of the user-facing toolkit:\n\n-   **A Bulletproof Foundation:** The installation and launch scripts were re-architected from the ground up. They became intelligent and self-healing, featuring pre-flight system checks, automated port conflict resolution, active health-check loops, and automated repair utilities.\n-   **A Professional Toolkit:** The operator was empowered with a suite of new tools, including an interactive setup wizard, a real-time CLI status monitor, and a full-fledged graphical \"Data Management Console\" for monitoring, filtering, and analyzing data.\n-   **A Unified Command Console (`SERVICE_MANAGER.bat`):** Unify all individual scripts under a single, user-friendly, menu-driven service manager, providing a 'single pane of glass' for all common operations.\n\nThis era solidified the kingdom's foundations, making it not just powerful, but stable, reliable, and a pleasure to operate. The Faucet was no longer just an engine; it was a complete, professional-grade machine.\n\n---\n\n## The Gauntlet of CI/CD (Late October 2025)\n\nWith a professional-grade application in hand, the final frontier was professional-grade *delivery*. This campaign focused on automating the creation of the MSI installer through a continuous integration pipeline, a process that proved to be a formidable challenge.\n\nThe kingdom's engineers faced a relentless series of cryptic build errors from the WiX Toolset, a hostile environment that tested their resolve. Through a series of rapid, iterative fixes\u2014addressing everything from component GUIDs and 64-bit architecture mismatches to obscure linker errors and frontend dependency warnings\u2014they systematically conquered each obstacle.\n\nThis trial by fire culminated in a triumphant success: a fully automated GitHub Actions workflow that reliably compiles, links, and delivers a polished, distributable MSI installer. This victory transformed the project's delivery model from a manual, error-prone process into a repeatable, one-click release pipeline, marking the true completion of the \"Windows Ascension.\"\n\n---\n\n## The Great Unbundling (Late October 2025)\n\nThe CI/CD pipeline was technically successful, but it revealed a deeper, philosophical flaw in the architecture. The installer, while automated, was a fragile monolith. It attempted to bundle raw source code (Python, JavaScript) and orchestrate their setup on the user's machine using post-install scripts. This approach was fraught with peril, vulnerable to failures from network issues, corporate firewalls, and unpredictable machine states.\n\nA final, decisive architectural mandate was issued, informed by the wisdom of external AI consultants: **The application must be delivered, not assembled.**\n\nThis mandate triggered \"The Great Unbundling,\" a swift and transformative refactoring of the entire delivery pipeline:\n\n*   **The Backend Forged:** The Python backend was no longer treated as source code to be installed, but as a product to be delivered. **PyInstaller** was used to forge the entire FastAPI service\u2014interpreter and all dependencies\u2014into a single, standalone `.exe`.\n*   **The Frontend Solidified:** The Next.js frontend was no longer a service to be run, but a static asset to be displayed. The `npm run build` process was configured to produce a clean, static HTML/CSS/JS export.\n*   **The Installer Perfected:** With the application components now self-contained, the MSI installer's role was radically simplified. All complex post-install scripting was eliminated. The WiX toolset was now used for its core competency: reliably copying pre-compiled, robust artifacts to the user's machine.\n\nThis final act of architectural purification created the \"Three-Executable Architecture\" (the backend executable, the Electron wrapper, and the MSI installer itself), achieving true portability and eliminating an entire class of deployment failures. The Windows Ascension was not just complete; it was perfected.",
    "JSON_BACKUP_MANIFEST.md": "# Checkmate Ultimate Solo: JSON Backup Manifest (Total Recall Edition)\n\n**Purpose:** To provide a single, complete, and verified list of direct links to the JSON backups of all CORE and Operational files. This is the definitive entry point for external AI code review.\n\n---\n\n## 1.0 CORE Architecture (JSON Backups)\n\n### Python Backend\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/api.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/engine.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/models.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/__init__.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/base.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/utils.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/betfair_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/pointsbet_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/racing_and_sports_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/tvg_adapter.py.json\n\n### TypeScript Frontend\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/package.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/package-lock.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/next.config.mjs.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/tailwind.config.ts.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/tsconfig.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/page.tsx.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/layout.tsx.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/globals.css.json\n\n---\n\n## 2.0 Operational & Tooling (JSON Backups)\n\n### Project Tooling\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/.gitignore.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/convert_to_json.py.json\n\n### Environment & Setup\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/setup_windows.bat.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/.env.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/requirements.txt.json\n\n### Strategic Blueprints\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/README.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/ARCHITECTURAL_MANDATE.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/HISTORY.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/STATUS.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/WISDOM.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/PROJECT_MANIFEST.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/ROADMAP_APPENDICES.md.json",
    "MANIFEST_SCRIPTS.json": "[\n    \"scripts/audit_rebranding.py\",\n    \"scripts/convert_to_json.py\",\n    \"scripts/create_shortcuts.py\",\n    \"scripts/fortuna-quick-start.ps1\"\n]\n",
    "PROJECT_MANIFEST.md": "# Checkmate V8: Project Manifest (Final)\n\n**Purpose:** To categorize all files, distinguishing between the active **CORE** system and **LEGACY** components.\n\n---\n\n## CORE ARCHITECTURE (Ultimate Solo)\n\n*   `.env.example`: **CORE** - Centralized configuration template.\n*   `ARCHITECTURAL_MANDATE.md`: **CORE** - The project's final strategic blueprint.\n*   `README.md`: **CORE** - The primary entry point.\n*   `STATUS.md`: **CORE** - The final status report.\n*   `setup_windows.bat`: **CORE** - The environment setup script for the CORE architecture.\n\n---\n\n## LEGACY & HISTORICAL ARTIFACTS\n\n*   `launcher.py`: **LEGACY** - The orchestrator for the deprecated Penta-Hybrid system.\n*   All other files and directories not listed in CORE are considered **LEGACY** R&D assets.",
    "PSEUDOCODE.MD": "# Fortuna Faucet - Comprehensive Pseudocode Blueprint\n\n---\n\n## GLOBAL OVERVIEW\n\n```\nSYSTEM FortunaFaucet:\n  PURPOSE:\n    - Collect global horse/greyhound/harness racing data.\n    - Normalize, analyze, and surface betting opportunities.\n    - Expose intelligence via API + UI command deck.\n  ARCHITECTURE:\n    - Pillar1: Python Async Backend (fast data orchestration).\n    - Pillar2: TypeScript/Next.js Frontend (interactive dashboard).\n  SUPPORTING ARTIFACTS:\n    - Streamlit utility dashboard.\n    - Chart scraping pipeline.\n    - Windows automation scripts.\n    - Extensive documentation + roadmaps.\n```\n\n---\n\n## BACKEND CORE (python_service)\n\n### Configuration & Logging\n\n```\nMODULE config.Settings:\n  LOAD environment variables via pydantic-settings.\n  KEY FIELDS:\n    API_KEY (mandatory security token)\n    BETFAIR credentials (optional but required for adapters)\n    TVG, RACING_AND_SPORTS, POINTSBET tokens (optional)\n    GREYHOUND_API_URL, THE_RACING_API_KEY (optional)\n    REDIS_URL default \"redis://localhost\"\n    ALLOWED_ORIGINS default [local dev origins]\n  EXPORT get_settings() with lru_cache for singleton behavior.\n\nMODULE logging_config.configure_logging():\n  SETUP structlog + logging.basicConfig\n  FORMAT logs as JSON with timestamp, level, logger name, stack info.\n```\n\n### Data Contracts\n\n```\nMODULE models:\n  DEFINE OddsData:\n    FIELDS: win Decimal>1, source str, last_updated datetime\n    VALIDATE win > 1 when present.\n\n  DEFINE Runner:\n    FIELDS: number (1-99), name <=100 chars, scratched flag (default False),\n            selection_id optional, odds dict[provider->OddsData],\n            jockey/trainer optional metadata.\n\n  DEFINE Race:\n    FIELDS: id str, venue str, race_number (1-20),\n            start_time datetime, runners list[Runner],\n            source str, optional qualification_score, race_name, distance.\n    VALIDATE unique runner numbers per race.\n\n  DEFINE SourceInfo:\n    name, status (\"SUCCESS\"/\"FAILED\"), races_fetched count,\n    optional error_message, fetch_duration float.\n\n  DEFINE FetchMetadata:\n    fetch_time datetime, sources_queried list[str],\n    sources_successful int, total_races int.\n\n  DEFINE AggregatedResponse:\n    date date, races list[Race], sources list[SourceInfo],\n    metadata FetchMetadata.\n\n  DEFINE QualifiedRacesResponse:\n    criteria dict[str,Any], races list[Race].\n```\n\n### Adapter Framework\n\n```\nABSTRACT BaseAdapter(source_name, base_url, timeout=20, max_retries=3):\n  PROVIDES async fetch_races(date, http_client) -> Dict\n    (implemented by subclasses).\n  PROVIDES make_request(http_client, method, url, **kwargs):\n    - Compose full URL when relative.\n    - Wrap request with tenacity AsyncRetrying (max_retries, exponential backoff).\n    - Log attempts; on success return response.json().\n    - On retry exhaustion log error and return None.\n\n  PROVIDES get_status() -> {\"adapter_name\": source_name, \"status\": \"OK\"}.\n  PROVIDES _format_response(races, start_time, is_success, error_message):\n    - Compute fetch_duration.\n    - Package races list + source_info block.\n```\n\n### Adapter Inventory (python_service/adapters)\n\n_For each source, implement fetch logic, parse HTML/JSON, convert to Race/Runner models, leverage parse_odds utility._\n\n```\nUTILITY parse_odds(odds_input):\n  HANDLE ints/floats directly.\n  HANDLE fractional strings \"num/den\" => 1 + num/den.\n  HANDLE \"evens\"/\"evs\" => 2.0.\n  FALLBACK to float parse else return 999.0 sentinel.\n\nMIXIN BetfairAuthMixin:\n  MAINTAIN session_token + token_expiry.\n  _authenticate(http_client):\n    IF cached token valid beyond +5min -> reuse.\n    ELSE POST to Betfair identity endpoint with credentials.\n    - On success store token + expiry (3 hours).\n    - On failure raise ConnectionError.\n\nADAPTER BetfairAdapter(BetfairAuthMixin, BaseAdapter):\n  SOURCE \"BetfairExchange\", base_url Betfair REST.\n  fetch_races(date):\n    - Authenticate.\n    - Build market_filter for eventTypeId \"7\" (horse racing).\n    - POST listMarketCatalogue with WIN markets in date window.\n    - If empty -> success with error_message.\n    - Else parse catalogue into races via _parse_race.\n  _parse_race:\n    - Build Runner for each runnerName, selectionId, sortPriority.\n    - Race ID \"bf_{marketId}\", venue event.venue, race_number via regex \"Rxx\".\n    - start_time from ISO string.\n  get_live_odds_for_market(market_id):\n    - Authenticate, POST listMarketBook with EX_TRADED price data.\n    - Extract lastPriceTraded for ACTIVE runners into Decimal map.\n    - Return selectionId->Decimal.\n\nADAPTER BetfairGreyhoundAdapter:\n  IDENTICAL structure; eventTypeId \"4339\"; Race ID prefix \"bfg_\".\n\nADAPTER TVGAdapter:\n  REQUIRE TVG_API_KEY.\n  fetch_races:\n    - GET tracks for date (country US).\n    - For each track, GET races summary, then detail per race.\n    - Parse to Race with _parse_tvg_race (skip scratched).\n  _parse_tvg_race:\n    - Program numbers sanitized via helper (strip letters).\n    - Extract odds via parse_odds (current or morning line).\n    - Compose Race ID with track code + date + race number.\n\nADAPTER RacingAndSportsAdapter:\n  REQUIRE token; on missing return FAILED status.\n  fetch_races:\n    - GET v1/racing/meetings with date & jurisdiction AUS.\n    - Iterate meetings/races, parse to Race via _parse_ras_race.\n  _parse_ras_race:\n    - Runners with runnerNumber, horseName, scratched flag.\n    - start_time iso parse.\n\nADAPTER RacingAndSportsGreyhoundAdapter:\n  Similar to above but endpoint v1/greyhound/meetings, Race prefix \"rasg_\".\n\nADAPTER AtTheRacesAdapter:\n  Scrape https://www.attheraces.com.\n  fetch_races:\n    - GET /racecards; parse meeting links.\n    - For each link -> fetch, parse track/time, race_number via active nav.\n    - Build Race with start_time based on current date + race time (no timezone).\n    - _parse_runner: extract horse number, name, best odds button -> parse to Decimal.\n\nADAPTER SportingLifeAdapter:\n  Scrape sportinglife.com racecards.\n  Similar approach: gather race links, parse track/time, nav for race_number, runners via cards.\n\nADAPTER TimeformAdapter:\n  Scrape timeform.com racecards.\n  Collect links, parse race page, determine race number via list of times, parse runner rows.\n\nADAPTER HarnessAdapter:\n  GET https://data.ustrotting.com/api/racenet/racing/card/{date}.\n  Parse meetings -> races -> runners (postPosition).\n  Convert morningLineOdds (if not fractional, append \"/1\"). Parse to Decimal.\n\nADAPTER GreyhoundAdapter:\n  Requires GREYHOUND_API_URL or raise ValueError.\n  fetch_races:\n    - GET v1/cards/{date}.\n    - Parse cards -> races -> runners (filter scratched). Convert odds.win decimals >1 to OddsData.\n\nADAPTER GbgbApiAdapter:\n  GET https://api.gbgb.org.uk/api/results/meeting/{date}.\n  Parse meetings/races/traps.\n  Race start_time from iso (replace 'Z' with +00:00). Distance appended as string.\n  Runners: parse sp fractional odds via parse_odds; assign OddsData.\n\nADAPTER TheRacingApiAdapter:\n  Requires THE_RACING_API_KEY.\n  fetch_races:\n    - GET racecards?date={date}&course=all&region=gb,ire.\n    - Parse racecards -> Race entries (race_id prefix \"tra_\").\n    - Runners: use odds list first entry's odds_decimal -> Decimal.\n\nADAPTER OddscheckerAdapter:\n  Scrape oddschecker horse racing.\n  fetch_races:\n    - GET /horse-racing -> meeting links.\n    - For each meeting fetch race links, then parse table rows -> Runners with odds.\n  Race result _format_response dumps Race models as dicts (model_dump).\n\nADAPTER PointsBetGreyhoundAdapter:\n  Placeholder (non-functional) -> returns SUCCESS with error message.\n\nADAPTER BrisnetAdapter, DRFAdapter, EquibaseAdapter, FanDuelAdapter,\n        HorseRacingNationAdapter, NYRABetsAdapter, PuntersAdapter,\n        RacingPostAdapter, RacingTVAdapter, TabAdapter, TwinSpiresAdapter,\n        XpressbetAdapter, TemplateAdapter:\n  Stubs returning empty responses with Not Implemented notice.\n```\n\n### Analyzer Layer\n\n```\nMODULE analyzer:\n  FUNCTION _get_best_win_odds(runner):\n    - Pull min win odds from runner.odds values < 999.\n    - Return Decimal or None.\n\n  ABSTRACT BaseAnalyzer:\n    - qualify_races(races) -> Dict (implemented by concrete analyzers).\n\n  CLASS TrifectaAnalyzer(BaseAnalyzer):\n    PARAMETERS: max_field_size=10, min_favorite_odds=2.5, min_second_favorite_odds=4.0 (Decimal).\n    METHOD qualify_races(races):\n      - For each race compute score via _evaluate_race.\n      - Filter races with scores -> assign race.qualification_score.\n      - Sort descending by score.\n      - Return {\"criteria\": {params}, \"races\": qualified_list}.\n    METHOD _evaluate_race(race):\n      - Filter non-scratched runners.\n      - Collect best odds for each runner; require >=2.\n      - Sort by odds ascending -> favorite, second favorite.\n      - Apply filters:\n          field_size <= max_field_size,\n          favorite_odds >= min_favorite_odds,\n          second_favorite_odds >= min_second_favorite_odds.\n      - Compute field_score = (max_field_size - field_size)/max_field_size.\n      - Normalize fav/second odds scores (cap 10/15).\n      - Weighted combination (field 0.3, odds 0.7).\n      - Return final_score *100 rounded to 2 decimals.\n\n  CLASS AnalyzerEngine:\n    - On init register 'trifecta' -> TrifectaAnalyzer.\n    - get_analyzer(name, **overrides):\n        if name missing -> raise ValueError.\n        instantiate analyzer with overrides for parameters.\n```\n\n### Engine Orchestration\n\n```\nCLASS OddsEngine(config):\n  INIT:\n    - Store config.\n    - Instantiate adapters list (major active ones: Betfair, BetfairGreyhound, TVG, R&S horse + greyhound,\n      AtTheRaces, SportingLife, Timeform, TheRacingApi, Gbgb, Harness).\n    - Create httpx.AsyncClient.\n    - Connect redis via redis.asyncio.from_url(config.REDIS_URL, decode_responses=True).\n    - Log redis initialization.\n\n  close():\n    - Close http_client.\n    - Close redis_client.\n\n  get_all_adapter_statuses():\n    - Return [adapter.get_status() for adapter in adapters].\n\n  _time_adapter_fetch(adapter, date):\n    - Record start, await adapter.fetch_races(date, http_client), compute duration.\n    - Return tuple (adapter.source_name, result_dict, duration).\n\n  _race_key(race):\n    - Lowercase trimmed venue + race_number + formatted start_time (HH:MM).\n\n  _dedupe_races(races):\n    - Build map by _race_key.\n    - If new key -> store race.\n    - Else merge runners (update odds per runner number, append new ones).\n    - Return deduped list.\n\n  fetch_all_odds(date, source_filter=None):\n    - Compose cache_key \"fortuna:races:{date}\".\n    - If no source_filter -> attempt redis GET, parse via AggregatedResponse.model_validate_json; return on hit.\n    - Determine target_adapters (filtered by name if provided).\n    - Launch async gather of _time_adapter_fetch for all targets (return_exceptions=True).\n    - For each result:\n        * If exception -> log error, skip.\n        * Extract source_info, override fetch_duration with measured duration.\n        * Append to sources list.\n        * If status SUCCESS -> extend all_races with result['races'].\n    - Dedupe races.\n    - Compose response_obj = AggregatedResponse(date parsed, races deduped, sources, metadata containing fetch_time, sources_queried, count success, total_races).\n    - If no source_filter -> store in redis with TTL 300 seconds.\n    - Return response_obj.model_dump().\n```\n\n### API Layer (FastAPI)\n\n```\nAPP fastapi.FastAPI(title \"Checkmate Ultimate Solo API\", version \"2.1\", lifespan context manager):\n  lifespan():\n    - configure_logging().\n    - Load settings via get_settings().\n    - Attach OddsEngine(config=settings) to app.state.engine.\n    - Attach AnalyzerEngine to app.state.analyzer_engine.\n    - On shutdown, engine.close().\n  MIDDLEWARE:\n    - SlowAPI rate limiting (Limiter key_func get_remote_address, 60/min for adapter status, 30/min for race endpoints).\n    - CORSMiddleware with allowed origins from settings.\n  DEPENDENCIES:\n    - verify_api_key (ensures X-API-Key matches settings.API_KEY except for /health).\n    - get_engine to fetch engine from app state.\n\nROUTES:\n  GET /health:\n    - Return {\"status\": \"ok\", \"timestamp\": now}.\n\n  GET /api/adapters/status:\n    - Rate limited 60/min.\n    - Requires API key.\n    - Return engine.get_all_adapter_statuses().\n    - On error -> HTTP 500.\n\n  GET /api/races/qualified/{analyzer_name} (response_model QualifiedRacesResponse):\n    - Rate limited 30/min.\n    - Query params: race_date optional (default today), optional overrides for analyzer params.\n    - Steps:\n        * Determine date_str.\n        * aggregated_data = await engine.fetch_all_odds(date_str).\n        * Extract races (list of Race models already validated).\n        * analyzer_engine = app.state.analyzer_engine.\n        * Filter overrides (non-None) into custom_params.\n        * analyzer = analyzer_engine.get_analyzer(analyzer_name, **custom_params).\n        * result = analyzer.qualify_races(races).\n        * Return QualifiedRacesResponse(**result).\n    - Handle ValueError -> 404 (missing analyzer).\n    - Handle general exception -> 500.\n\n  GET /api/races (response_model AggregatedResponse):\n    - Rate limited 30/min.\n    - Query: race_date optional, source optional.\n    - Determine date, call engine.fetch_all_odds(date_str, source).\n    - Return aggregated data (model_dump).\n```\n\n### Security\n\n```\nMODULE security:\n  DEFINE API_KEY_NAME \"X-API-Key\".\n  USE fastapi.security.APIKeyHeader auto_error True.\n  verify_api_key(header_value):\n    - Fetch settings.\n    - Compare to settings.API_KEY via secrets.compare_digest.\n    - If match -> return True.\n    - Else raise HTTP 403 \"Invalid or missing API Key\".\n```\n\n### Tests\n\n```\ntests/test_legacy_scenarios.py:\n  PURPOSE: Validate TrifectaAnalyzer behavior through API route.\n\n  HELPER create_mock_runner(number, odds_val, scratched=False):\n    - Build Runner with OddsData using decimal odds.\n\n  DEFINE Mock Races (Race models):\n    - MOCK_RACE_PASS: 5 runners, odds 3.0, 4.5 etc (passes filters).\n    - MOCK_RACE_FAIL_FIELD_SIZE: 11 runners -> exceed field_size.\n    - MOCK_RACE_FAIL_FAV_ODDS: favorite odds 2.0 (below threshold).\n    - MOCK_RACE_FAIL_2ND_FAV_ODDS: second favorite 3.5 (below threshold).\n\n  TEST test_trifecta_analyzer_with_legacy_scenarios:\n    - Patch OddsEngine.fetch_all_odds to AsyncMock returning races list.\n    - Use FastAPI TestClient (fixture 'client').\n    - GET /api/races/qualified/trifecta with headers (X-API-Key).\n    - Assert status 200.\n    - Expect exactly 1 qualified race (LEGACY_PASS_1) + criteria check.\n    - Assert mocked engine fetch awaited once.\n```\n\n### Auxiliary Scripts (Backend / Tooling)\n\n```\nSCRIPT convert_to_json.py:\n  PURPOSE: Convert manifest-listed files into JSON snapshots (sandboxed read).\n  STEPS:\n    - Configuration: MANIFEST_FILES, OUTPUT_DIR, TIMEOUT.\n    - extract_and_normalize_path(line): handle markdown links, backtick paths, bullet lists; convert GitHub raw URLs to local paths.\n    - convert_file_to_json_sandboxed(file_path):\n        * Launch subprocess to safely read file (avoid sandbox issues).\n        * Terminate if exceeds timeout.\n    - main():\n        * Parse manifests -> gather unique paths.\n        * For each path, sandbox read.\n        * Save JSON {file_path, content} into OUTPUT_DIR mirroring structure.\n        * Report successes/failures; exit 1 if failures.\n\nSCRIPT create_fortuna_json.py:\n  PURPOSE: Generate FORTUNA_ALL_PART1/2 JSON bundles.\n  PROCESS:\n    - Parse manifests -> gather unique paths.\n    - For each file:\n        * Read content.\n        * Categorize: if path starts with \"python_service/\" or \"tests/\" -> Part1; else Part2.\n    - Write JSON dumps with indentation.\n    - Report counts; exit 1 if failures.\n\nSCRIPT chart_scraper.py (ChartScraper class):\n  - Manage directories results_archive/{pdf,pdf_unlocked,csv}.\n  - Determine yesterday date formats for summary + PDF.\n  - _get_yesterday_tracks: fetch Equibase summary page, parse track IDs.\n  - _download_and_parse_chart(track_code, chart_date):\n      * Build PDF URL pattern.\n      * Download PDF (check content-type/length).\n      * Save locked/unlocked (via pikepdf).\n      * Use tabula.read_pdf to extract tables -> combine -> CSV.\n  - run(): orchestrates directories, fetch tracks, iterate, throttle with sleep(1).\n\nSCRIPT command_deck.py (Streamlit):\n  - Configure Streamlit page.\n  - Load DEV_API_KEY from environment (fallback test key).\n  - cached helper get_api_data endpoint -> fetch using requests.\n  - UI:\n      * Title + description.\n      * Sidebar select analyzer (currently only trifecta) and \"Clear Cache\" button.\n      * Display qualified races in DataFrame (normalize nested runners) or info/error messages.\n      * Display adapter status DataFrame.\n\nSCRIPT results_parser.py (ChartParser):\n  - Provide count_runners(chart_text) scanning \"Past Performance Running Line Preview\" section; count lines starting with digit until blank or \"Trainers:\".\n\nSCRIPT live_monitor.py (LiveOddsMonitor class):\n  - INIT: store config, instantiate BetfairAdapter.\n  - monitor_race(race, http_client):\n      * If race ID not from Betfair -> log warning, return race unchanged.\n      * Extract market_id.\n      * Call adapter.get_live_odds_for_market.\n      * Update each runner's odds dict with new OddsData (timestamp now) when selection_id matches.\n      * Return updated race.\n\nSCRIPT fortuna_watchman.py (Watchman orchestrator):\n  - INIT: load settings, instantiate OddsEngine, AnalyzerEngine, LiveOddsMonitor.\n  - get_initial_targets():\n      * fetch today's aggregated data.\n      * Acquire analyzer (trifecta).\n      * Evaluate races -> sorted by score; log top 5.\n  - run_tactical_monitoring(targets):\n      * With httpx.AsyncClient loop:\n          - Determine races within next 5 minutes.\n          - For each such race call live_monitor.monitor_race.\n          - Remove monitored race from list.\n          - Sleep 30 seconds; exit when no active targets.\n  - execute_daily_protocol():\n      * Log start.\n      * Acquire initial targets; if any run monitoring, else log none.\n      * Close odds_engine.\n      * Log completion.\n  - main() entrypoint -> configure logging, instantiate Watchman, run execute_daily_protocol.\n\nWINDOWS Scripts:\n  - setup_windows.bat:\n      * Verify python installed.\n      * Create venv (.venv) if missing.\n      * Activate & install python_service/requirements.txt.\n      * Verify Node.js; npm install under web_platform/frontend.\n      * Print final instructions.\n\n  - run_fortuna.bat:\n      * Launch backend uvicorn in new window (activating venv).\n      * Launch frontend Next.js in new window.\n      * Wait 5 sec, open browser http://localhost:3000.\n```\n\n---\n\n## REDIS & CACHING\n\n```\nBACKEND relies on redis.asyncio client:\n  - namespace \"fortuna:races:{date}\" for aggregated responses (no source filter).\n  - store JSON serialized AggregatedResponse for 5 minutes.\n  - On retrieval, validate via Pydantic before returning.\n\nERROR HANDLING:\n  - redis GET/SET exceptions logged but don't halt main flow.\n```\n\n---\n\n## DOCUMENTATION (Selected Highlights)\n\n```\nARCHITECTURAL_MANDATE.md:\n  - Defines Two-Pillar architecture, Prime Directive.\n  - Emphasizes OddsEngine, BaseAdapter, Adapter Fleet, Pydantic models, TrifectaAnalyzer.\n\nHISTORY.md:\n  - Chronicles project eras from \"Utopian\" to \"Liberation\".\n  - Explains environment hostility and shift to portable engine.\n\nROADMAP_APPENDICES.md:\n  - Catalog of adapter backlog categories, intelligence leads, future campaigns (Analyst expansion, legacy tests, dashboard).\n\nWISDOM.md:\n  - Provides virtues/vices for agents (operational protocols).\n  - Reinforces verifying instructions, small commits, reliance on Project Lead.\n\nREADME.md:\n  - Quick start instructions (setup_windows.bat, run_fortuna.bat).\n  - API usage note (API key header requirement).\n\n.env.example:\n  - Template for backend credentials + configuration options.\n```\n\n---\n\n## FRONTEND PILLAR (web_platform/frontend)\n\n### Configuration & Tooling\n\n```\nENV: Next.js 14 + React 18, Tailwind CSS, TypeScript.\n\nFiles:\n  - .env.local.example: requires NEXT_PUBLIC_API_KEY + API_URL.\n  - next.config.mjs: sets rewrites to proxy /api/* to backend 8000.\n  - package.json: dependencies (next, react, socket.io-client), dev dependencies (Tailwind, TypeScript).\n  - tailwind.config.ts + postcss.config.js: standard Tailwind setup.\n  - tsconfig.json: configure compiler options (strict false, noEmit, Next plugin).\n```\n\n### UI Components\n\n```\nCOMPONENT LiveRaceDashboard (client component):\n  STATE:\n    races list\n    criteria object\n    loading boolean\n    error string\n    lastUpdate timestamp\n    params {max_field_size, min_favorite_odds, min_second_favorite_odds}\n      - Initialized from localStorage (if available) else defaults.\n      - Persist params back to localStorage on change.\n\n  EFFECTS:\n    - On mount: fetchQualifiedRaces(initialLoad=True).\n    - Set interval every 30s -> fetchQualifiedRaces(False).\n    - Cleanup interval on unmount.\n\n  fetchQualifiedRaces(isInitialLoad):\n    - Show loading on initial.\n    - Reset error.\n    - Fetch API key from NEXT_PUBLIC_API_KEY (error if missing).\n    - Build query string from params.\n    - GET `/api/races/qualified/trifecta` with X-API-Key header.\n    - On success: set races, criteria, lastUpdate.\n    - On failure: set error message.\n    - Toggle loading false when initial load complete.\n\n  handleParamChange:\n    - Update params with slider values.\n\n  RENDER:\n    - Title, last update timestamp.\n    - Control panel with range inputs for parameters (display current values).\n    - Conditional messages for loading/error.\n    - Summary of number of qualified races.\n    - Grid of RaceCard components for each race.\n\nCOMPONENT RaceCard:\n  PROPS: race (matching Race interface).\n  PROCESS:\n    - Filter out scratched runners.\n    - Sort active runners by number.\n    - Count unique odds sources across runners.\n    - Determine best odds per runner (min win < 999).\n    - formatTimeUntilPost helper -> difference between start_time and now (hours/mins).\n    - Render card with:\n        * Header (venue, race number, time to post).\n        * Qualification score badge (color-coded thresholds).\n        * Race condition grid (distance, surface default 'Dirt', field size, sources count).\n        * Runner list with stylized badges for top 3 positions (gold/silver/bronze), odds display with source.\n```\n\n---\n\n## COMMAND DECK (Streamlit)\n\n```\nAPPLICATION command_deck.py:\n  - Provide alternate dashboard for backend monitoring.\n  - Uses st.cache_data for API calls (TTL 30s) with manual clear button.\n  - Displays qualified races normalized into DataFrame (runners flattened).\n  - Displays adapter statuses DataFrame.\n  - Utilizes environment variable DEV_API_KEY or fallback.\n```\n\n---\n\n## DATA PROCESSING UTILITIES\n\n```\nChartScraper workflow:\n  - Determine yesterday's tracks from Equibase summary HTML.\n  - For each track, attempt to download combined PDF (size check).\n  - Unlock PDF via pikepdf to remove encryption.\n  - Extract tables with tabula (lattice mode).\n  - Concatenate to CSV for archival.\n  - Delay between requests (1 second) to be polite.\n\nChartParser (results_parser.py):\n  - Parse extracted text to count number of runners by reading the \"Past Performance Running Line Preview\" section.\n```\n\n---\n\n## PROJECT AUTOMATION & DEPLOYMENT\n\n```\nsetup_windows.bat:\n  - Single entry script to prepare backend + frontend dependencies on Windows.\n\nrun_fortuna.bat:\n  - Launch backend server via uvicorn (auto reload) in new CMD window.\n  - Launch Next.js dev server in another window.\n  - After delay, open default browser to frontend.\n\nfortuna_watchman.py:\n  - Could be scheduled (e.g., cron/Task Scheduler) to run daily.\n  - Integrates OddsEngine + Analyzer + LiveOddsMonitor for real-time monitoring.\n\nlive_monitor.py:\n  - Designed to be invoked close to post time to refresh odds from Betfair.\n\nRedis caching:\n  - Requires running redis instance (default local) for performance.\n```\n\n---\n\n## END-TO-END FLOW (Narrative Pseudocode)\n\n```\nFUNCTION DailyOperation():\n  INIT settings = get_settings()\n  INIT odds_engine = OddsEngine(settings)\n  INIT analyzer_engine = AnalyzerEngine()\n  INIT http_client (within odds_engine)\n  INIT redis cache.\n\n  FOR each requested API call (/api/races or /api/races/qualified):\n    VERIFY API key via security.verify_api_key.\n    IF aggregated data cached (and no source filter):\n      RETRIEVE from Redis.\n    ELSE:\n      PARALLEL fetch using adapters:\n        - Each adapter fetch_races(date, http_client)\n        - Standardize Race/Runner structures.\n      MERGE all races with dedupe. (Odds aggregated per runner).\n      BUILD AggregatedResponse.\n      CACHE (if applicable).\n    IF route is /qualified:\n      analyzer = analyzer_engine.get_analyzer(\"trifecta\", overrides)\n      qualified = analyzer.qualify_races(races)\n      RETURN QualifiedRacesResponse.\n\n  FRONTEND LiveRaceDashboard:\n    PERIODICALLY fetch /api/races/qualified/trifecta with user-adjusted parameters.\n    DISPLAY race cards with scoring, countdown, best odds per runner.\n\n  COMMAND_DECK (Streamlit):\n    - Provide alternative interface for developers/operators.\n\n  WATCHMAN automation:\n    - At start of day: fetch all races, filter top opportunities.\n    - As race times approach: call LiveOddsMonitor to augment with live Betfair odds.\n    - Continue until all targets monitored; shutdown.\n\n  CHART PIPELINE (optional offline run):\n    - Use ChartScraper to download PDFs and convert to CSV for historical analysis.\n    - Use ChartParser to interpret extracted text.\n\n  DOCUMENTATION:\n    - Guides architecture decisions, historical context, roadmap, operational wisdom.\n```\n\n---\n\n## SUMMARY\n\n```\nFortunaFaucet encapsulates:\n  - Hardened async backend with resilient adapters, serializer models, caching, analysis engine, HTTP API, security.\n  - Multi-source adapter fleet supporting APIs and HTML scrapes, with placeholders for future expansion.\n  - Analyzer framework currently featuring Trifecta strategy with scoring.\n  - Redis-backed caching and rate-limited FastAPI endpoints.\n  - Automated watchman for daily operations and live odds integration.\n  - Frontend Next.js dashboard + Streamlit command deck for visualization.\n  - Comprehensive documentation capturing mission, history, roadmap, and operational protocols.\n  - Tooling scripts for data archiving and Windows-based development workflows.\n```\n\n---",
    "README.md": "# \ud83d\udc34 Fortuna Faucet - Racing Analysis Engine\n\nWelcome to Fortuna Faucet! This guide provides instructions for both end-users and developers.\n\n## Getting Started: The Official Installation\n\nThe easiest way to get started is with our official MSI installer, which handles all setup and configuration automatically.\n\n1.  **Download the Installer:**\n    *   Go to the [latest release page](https://github.com/masonj0/fortuna/releases/latest) on GitHub.\n    *   Download the `Fortuna-Faucet-Setup-vX.X.X.msi` file.\n\n2.  **Run the Installer:**\n    *   Double-click the downloaded `.msi` file.\n    *   Follow the on-screen instructions in the setup wizard.\n\nOnce installed, a \"Fortuna Faucet\" folder will be created in your Start Menu. The application's backend will run automatically as a background service, and you can access the dashboard via the Start Menu shortcut.\n\n---\n\n## For Developers\n\nThis section contains instructions for developers who wish to contribute to the project or manage the environment manually.\n\n### Core Architecture\n\nThe project has a distinct architecture for production and development environments.\n\n*   **Production Architecture (in the MSI):**\n    *   **Standalone Backend:** The Python backend is compiled into a single, self-contained executable (`fortuna-api`) using **PyInstaller**. This bundles the Python interpreter and all dependencies, requiring no Python installation on the user's machine.\n    *   **Static Frontend:** The Next.js frontend is exported as a set of static HTML, CSS, and JavaScript assets. These are served directly from the filesystem by the Electron application.\n    *   **Electron Wrapper:** The Electron app acts as a shell, launching the backend executable as a background process and loading the static frontend.\n\n*   **Development Architecture:**\n    *   **Backend (`python_service/`):** An asynchronous FastAPI application run from a local Python virtual environment.\n    *   **Frontend (`web_platform/frontend/`):** A standard Next.js development server that enables hot-reloading for rapid UI development.\n    *   **Unified Launcher (`run_dev_environment.bat`):** The primary entry point for local development, managing both backend and frontend services.\n\n### Manual Development Setup\n\n1.  **Prerequisites:** Python 3.11+, Node.js (LTS), Git.\n2.  **Clone:** `git clone https://github.com/masonj0/fortuna.git`\n3.  **Run the Setup Script:** For a one-time setup of both the Python virtual environment and Node.js dependencies, simply run the `run_dev_environment.bat` script.\n\n### Quick Start (No Installation Required)\n\nFor developers and advanced users who want to run the application directly from source without a formal installation, the `scripts/fortuna-quick-start.ps1` script provides a powerful alternative.\n\n*   **What it does:** This PowerShell script automates all pre-flight checks, dependency installations, and launches both the backend and frontend servers concurrently. It also includes robust process management and cleanup.\n*   **How to use:**\n    1.  Ensure your system meets the prerequisites (Python, Node.js).\n    2.  Run `run_dev_environment.bat` once to create the initial virtual environment.\n    3.  From a PowerShell terminal, execute `.\\scripts\\fortuna-quick-start.ps1`.\n*   **Options:** The script includes parameters for skipping dependency checks (`-SkipChecks`) and running only the backend (`-NoFrontend`) for maximum flexibility.\n\n### Creating a Release Build (MSI Installer)\n\nThe project uses the WiX Toolset to create a professional, distributable MSI installer based on the production architecture.\n\n*   **Build Orchestrator:** The entire build process is automated and managed by the `scripts/build_msi.ps1` PowerShell script.\n*   **Key Build Steps:**\n    1.  The script first compiles the entire Python backend into a standalone executable using **PyInstaller**.\n    2.  Next, it builds the Next.js frontend into a static export.\n    3.  Finally, it uses the **WiX Toolset** (`heat.exe`, `candle.exe`, `light.exe`) to harvest these pre-built artifacts and package them into a clean, reliable MSI installer.\n*   **CI/CD:** The build is fully automated via GitHub Actions, as defined in `.github/workflows/build_msi.yml`. To create a release build locally, ensure the WiX Toolset is installed and run the `scripts/build_msi.ps1` script from a PowerShell terminal.\n",
    "README_WINDOWS.md": "# \ud83d\udc34 Fortuna Faucet - Windows Installation Guide (for End Users)\n\nWelcome to Fortuna Faucet! Installing the application is now a simple, one-step process.\n\n## The Official Installation Method\n\n1.  **Go to the Latest Release Page:**\n    *   Navigate to our official GitHub Releases page: [https://github.com/masonj0/fortuna/releases/latest](https://github.com/masonj0/fortuna/releases/latest)\n\n2.  **Download the Installer:**\n    *   Look for the file named `Fortuna-Faucet-Setup-vX.X.X.msi` (the version number will change).\n    *   Download this file to your computer.\n\n3.  **Run the Installer:**\n    *   Double-click the downloaded `.msi` file.\n    *   Follow the on-screen instructions in the setup wizard.\n\nOnce the installation is complete, you will find a \"Fortuna Faucet\" folder in your Start Menu. This folder contains a shortcut to launch the **Fortuna Faucet Dashboard**. The application's backend will run automatically as a background service whenever the application is open.\n\nThat's it! All previous methods involving Python scripts or batch files are now obsolete.\n",
    "REBRANDING_AUDIT.md": "# Fortuna Faucet: Rebranding Audit Report\n\nThis report lists all files containing legacy branding terms (`checkmate`, `solo`).\n\n---\n\n- `./.env`\n- `./AGENTS.md`\n- `./ARCHITECTURAL_MANDATE_V8.1.md`\n- `./GEMINI_ONBOARDING.md`\n- `./HISTORY.md`\n- `./JSON_BACKUP_MANIFEST.md`\n- `./MANIFEST2.md`\n- `./MANIFEST3.md`\n- `./PROJECT_MANIFEST.md`\n- `./Procfile`\n- `./ROADMAP.md`\n- `./ROADMAP_APPENDICES.md`\n- `./WISDOM.md`\n- `./attic/ARCHITECTURAL_MANDATE_V7.2.md`\n- `./attic/build_python_service.py`\n- `./attic/checkmate_app.py`\n- `./attic/checkmate_engine.py`\n- `./attic/checkmate_monitor_v1.html`\n- `./attic/dashboard.py`\n- `./attic/desktop_app/App.xaml`\n- `./attic/desktop_app/App.xaml.cs`\n- `./attic/desktop_app/CheckmateDeck.csproj`\n- `./attic/desktop_app/Models/AdapterStatusDisplay.cs`\n- `./attic/desktop_app/Models/DisplayRace.cs`\n- `./attic/desktop_app/Services/DatabaseService.cs`\n- `./attic/desktop_app/Services/IDatabaseService.cs`\n- `./attic/desktop_app/ViewModels/MainViewModel.cs`\n- `./attic/desktop_app/Views/MainWindow.xaml`\n- `./attic/desktop_app/Views/MainWindow.xaml.cs`\n- `./attic/launcher.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_api.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_betfair_modern_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_fanduel_api_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_logic.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_models.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_racingpost_modern_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_run.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_services.py`\n- `./attic/legacy_tests_pre_triage/test_checkmate_v7.py`\n- `./attic/legacy_tests_pre_triage/test_python_service.py`\n- `./attic/portable_demo_v2.py`\n- `./attic/rust_engine/rust_engine/Cargo.toml`\n- `./attic/rust_engine/rust_engine/benches/analysis_benchmark.rs`\n- `./attic/rust_engine/rust_engine/src/lib.rs`\n- `./attic/rust_engine/rust_engine/src/main.rs`\n- `./attic/the_one_script.py`\n- `./attic/tipsheet_generator.py`\n- `./attic/vba_source/Module_Charts.bas`\n- `./attic/vba_source/Module_DB.bas`\n- `./attic/vba_source/Module_UI.bas`\n- `./checkmate_web/engine.py`\n- `./checkmate_web/main.py`\n- `./checkmate_web/static/app.js`\n- `./checkmate_web/static/index.html`\n- `./command_deck.py`\n- `./diagnostic_report.txt`\n- `./launch_and_hunt.py`\n- `./launch_checkmate.bat`\n- `./launch_command_deck.bat`\n- `./manual_override_tool.py`\n- `./pg_schemas/historical_races.sql`\n- `./pytest.ini`\n- `./python_service/api.py`\n- `./python_service/checkmate_service.py`\n- `./python_service/minimal_service.py`\n- `./python_service/windows_service_wrapper.py`\n- `./run_server.py`\n- `./rust_engine/tests/integration_tests.rs`\n- `./shared_database/schema.sql`\n- `./src/checkmate_v7/adapters/AndWereOff.py`\n- `./src/checkmate_v7/adapters/Stablemates.py`\n- `./src/checkmate_v7/adapters/__init__.py`\n- `./src/checkmate_v7/api.py`\n- `./src/checkmate_v7/base.py`\n- `./src/checkmate_v7/cockpit.py`\n- `./src/checkmate_v7/config.py`\n- `./src/checkmate_v7/database.py`\n- `./src/checkmate_v7/headless_monitor.py`\n- `./src/checkmate_v7/logic.py`\n- `./src/checkmate_v7/models.py`\n- `./src/checkmate_v7/run.py`\n- `./src/checkmate_v7/services.py`\n- `./src/checkmate_v7/settings.py`\n- `./src/paddock_parser/prediction_engine.py`\n- `./web_platform/api_gateway/package-lock.json`\n- `./web_platform/api_gateway/src/server.ts`\n- `./web_platform/api_gateway/src/services/DatabaseService.ts`\n- `./web_platform/frontend/.next/server/app/page.js`\n- `./web_platform/frontend/app/layout.tsx`\n- `./web_platform/frontend/src/components/RaceCard.tsx`\n- `./web_platform/frontend/src/types/racing.ts`\n",
    "ROADMAP_APPENDICES.md": "# \ud83d\uddfa\ufe0f Fortuna Faucet - Roadmap & Accomplishments\n\nThis document tracks the strategic evolution of the Fortuna Faucet project.\n\n## Phase 1: Core Engine Development (Complete)\n- **Objective:** Build a robust, scalable data extraction and analysis engine.\n- **Status:** COMPLETE.\n\n## Phase 2: The Golden Path - UX Overhaul (Complete)\n- **Objective:** Transform the developer-centric tool into a seamless, professional-grade Windows application for non-technical users.\n- **Status:** COMPLETE.\n\n## Phase 3: The Turnkey Solution - Professional Release Pipeline (Complete)\n- **Objective:** Eliminate all manual setup steps and create an enterprise-grade, automated build and release system.\n- **Status:** COMPLETE.\n\n### Key Accomplishments & Completed Operations:\n\n1.  **Operation: The Great Housekeeping**\n    - Purified the repository architecture, deprecated legacy codebases and scripts, and established a clean foundation.\n    - Forged a new, programmatic manifest generation system.\n\n2.  **Operation: The Blueprint**\n    - Established the professional directory structure for an enterprise-grade build system.\n    - Implemented the master WiX product definition and the PowerShell build orchestrator.\n\n3.  **Operation: The Assembly Line**\n    - Fully automated the MSI build process with a GitHub Actions CI/CD workflow.\n\n4.  **Operation: The Proving Ground**\n    - Forged a complete suite of automated PowerShell scripts to test and validate the integrity of every installer artifact (install, silent deploy, uninstall).\n\n5.  **Operation: The User's Keys**\n    - Created the final, user-facing toolkit of scripts for easy lifecycle management (install, uninstall, repair).\n\n6.  **Operation: Modernize the Assembly Line**\n    - Performed a surgical upgrade to the CI/CD pipeline to resolve a critical GitHub Actions deprecation, ensuring continued operational readiness.\n\n7.  **Operation: The Forge**\n    - Executed a critical architectural overhaul of the entire release pipeline.\n    - Replaced the fragile, runtime-dependent installer with a robust \"Three-Executable Architecture.\"\n    - The Python backend is now a standalone executable compiled with PyInstaller, and the frontend is a static export, eliminating all runtime dependencies and post-install scripting.\n\n## Phase 4: User Experience & Feature Enhancement (Next Steps)\n- **Objective:** Enhance the core user experience and expand the analytical capabilities of the engine.\n- **Status:** PENDING.\n- **Potential Missions:**\n  - **Operation: The Monolith:** Unify the disparate GUI tools (launcher, setup wizard) into a single, tabbed application for a seamless user experience.\n  - **Operation: The Interpreter:** Implement a user-friendly error-handling system that translates technical errors into simple, actionable advice.\n  - **Data Persistence & Caching:** Implement a local SQLite database to cache race data, improving performance and enabling offline access.",
    "STATUS.md": "# Project Status: Foundation Rebuilt, Hardening in Progress\n\n**Date:** 2025-10-03\n\n## Current State\n\n*   **Architecture:** The backend has been successfully rebuilt into a superior, asynchronous FastAPI application, as defined by 'Operation: Grand Synthesis'. The new foundation is stable, tested, and features a resilient `BaseAdapter` pattern.\n\n*   **Status:** The foundational refactoring is complete. The first two data adapters (`Betfair`, `TVG`) have been implemented on the new architecture. We are now in a new phase of development: **'Phase 2: Hardening & Expansion.'**\n\n*   **Documentation:** All core strategic documents and manifests have been synchronized with the new technical reality.\n\n*   **Next Steps:** Our immediate priority is to act on the verified intelligence from our Oracle (Jules1003). The next missions will focus on implementing critical API security features (rate limiting, authentication) and continuing the build-out of our adapter fleet.",
    "USER_GUIDE.md": "# \ud83c\udfaf Fortuna Faucet: Complete User Guide for Windows Hobbyists\n\n## What Is This Amazing Software?\n\n**Fortuna Faucet** is a professional-grade horse racing analysis platform that:\n- \ud83d\udcca Aggregates data from **20+ global racing sources** simultaneously\n- \ud83e\udd16 Uses AI-powered analysis to find value betting opportunities\n- \ud83d\udcc8 Provides live odds monitoring via Betfair Exchange\n- \ud83c\udf10 Features a beautiful web dashboard for real-time insights\n- \ud83d\udd04 Runs automatically in the background like a professional service\n\nThink of it as your personal racing intelligence agency!\n\n---\n\n## \ud83d\ude80 Quick Start (15 Minutes to Racing!)\n\n### Step 1: One-Click Installation\n1. Extract all files to `C:\\FortunaFaucet` (or your preferred location)\n2. **Right-click** `INSTALL_FORTUNA.bat` \u2192 **Run as Administrator**\n3. Wait 3-5 minutes while it automatically installs:\n   - Python 3.11 (if needed)\n   - Node.js (if needed)\n   - All required packages\n\n### Step 2: Quick Configuration\n1. **Double-click** `setup_wizard.py` in your folder\n2. Follow the friendly prompts to configure:\n   - Your private API key (auto-generated)\n   - Betfair credentials (optional, for live odds)\n3. The wizard creates your `.env` file automatically!\n\n### Step 3: Launch!\n- **Double-click** the \"Launch Fortuna\" shortcut on your desktop\n- Wait 10 seconds for services to start\n- Your dashboard opens automatically in your browser! \ud83c\udf89\n\n---\n\n## \ud83c\udfae Using Your New Command Center\n\n### The Dashboard (http://localhost:3000)\nYour racing command center features:\n\n**\ud83d\udcca Statistics Panel** (Top of screen)\n- **Qualified Races**: How many races meet your criteria\n- **Premium Targets**: High-score opportunities (80%+)\n- **Next Race**: Countdown to the next qualifying race\n- **Avg Field Size**: Average number of horses\n\n**\ud83c\udf9b\ufe0f Smart Filters** (Middle section)\nCustomize what you see:\n- **Min Score Slider**: Only show races above X% match\n- **Max Field Size**: Filter by number of runners (8, 10, 12, or Any)\n- **Sort By**: Order by score, time, or track name\n\n**\ud83c\udfc7 Race Cards** (Main display)\nEach card shows:\n- Track name and race number\n- Qualification score (color-coded!)\n- Race conditions (distance, surface)\n- Top 3 contenders with best odds\n- Data source count\n\n### Color Coding System\n- \ud83d\udd34 **Red (80%+)**: Premium betting opportunity!\n- \ud83d\udfe1 **Yellow (60-79%)**: Good value potential\n- \ud83d\udfe2 **Green (<60%)**: Meets minimum criteria\n\n---\n\n## \ud83d\udd27 Advanced Features\n\n### Live Odds Monitoring\nOnce you've added Betfair credentials:\n1. The system automatically tracks races approaching post time\n2. Updates odds every 30 seconds for races within 5 minutes\n3. Highlights dramatic odds movements\n\n### Desktop Monitor Tool\nRun `fortuna_monitor.py` for a real-time status window:\n- Shows all data source health\n- Performance graphs (with matplotlib)\n- Success rates and fetch durations\n- Quick \"Refresh Now\" button\n\n### Auto-Start on Windows Boot\nRun `SCHEDULE_FORTUNA.bat` (as Administrator):\n- Fortuna starts when you log into Windows\n- Daily 3 AM restart for fresh data\n- Runs silently in the background\n\n---\n\n## \ud83c\udfaf Understanding the \"Trifecta Analyzer\"\n\nThis is the brain! It scores races on three factors:\n\n### Factor 1: Field Size (smaller is better)\n- **Why**: Fewer horses = easier to predict\n- **Default**: Maximum 10 runners\n\n### Factor 2: Favorite's Odds (higher is better)\n- **Why**: If the favorite is 2.5+, the race is wide open\n- **Default**: Minimum 2.5\n\n### Factor 3: Second Favorite's Odds (higher is better)\n- **Why**: Confirms multiple horses are competitive\n- **Default**: Minimum 4.0\n\n**The Score**: Combines all three into a 0-100% match rating!\n\n---\n\n## \ud83d\udcda System Architecture (Simplified)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \ud83c\udf10 Next.js Dashboard (Port 3000)    \u2502\n\u2502     Your beautiful web interface        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 API Calls\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   \ud83d\udc0d Python FastAPI Backend (Port 8000) \u2502\n\u2502   - OddsEngine: Fetches from 20+ sources\u2502\n\u2502   - TrifectaAnalyzer: Scores races      \u2502\n\u2502   - LiveOddsMonitor: Betfair tracking   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 Async Requests\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \ud83d\udd0c Adapter Fleet (20+ sources)      \u2502\n\u2502  TVG \u2022 Betfair \u2022 TimeForm \u2022 GBGB       \u2502\n\u2502  RacingAndSports \u2022 USTA \u2022 And more!     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n---\n\n## \ud83d\udd10 Security Notes\n\n### API Keys\n- **Your local API_KEY**: Only for communication between YOUR backend and frontend\n- Never shared online, never exposed\n- Auto-generated during setup\n\n### External API Keys (Optional)\nAdd these to `.env` for more data sources:\n```\nTVG_API_KEY=\"your_tvg_key\"\nRACING_AND_SPORTS_TOKEN=\"your_ras_token\"\nTHE_RACING_API_KEY=\"your_theracingapi_key\"\n```\n\nGet keys from:\n- TVG: https://www.tvg.com/promos/developer-api\n- Racing and Sports: https://www.racingandsports.com/data-api/\n- The Racing API: https://www.theracingapi.com/\n\n---\n\n## \ud83d\udee0\ufe0f Troubleshooting\n\n### \"Backend Offline\" Error\n```batch\n# Stop everything cleanly\nSTOP_FORTUNA.bat\n\n# Wait 10 seconds, then restart\nLAUNCH_FORTUNA.bat\n```\n\n### Dashboard Loads But No Data\n1. Open `http://localhost:8000/health` in browser\n2. Should show: `{\"status\": \"OK\"}`\n3. If not, check Python backend window for errors\n\n### \"Port Already In Use\" Error\nSomeone else is using port 8000 or 3000:\n```batch\n# Windows: Kill processes on those ports\nnetstat -ano | findstr :8000\ntaskkill /PID [number] /F\n\nnetstat -ano | findstr :3000\ntaskkill /PID [number] /F\n```\n\n### Reset Everything\n```batch\n# Nuclear option: Clean slate\nSTOP_FORTUNA.bat\ndel .env\nsetup_wizard.py\nINSTALL_FORTUNA.bat\n```\n\n---\n\n## \ud83d\udcd6 File Structure Explained\n\n### Critical Files (Don't Delete!)\n- `.env` - Your configuration (API keys, settings)\n- `requirements.txt` - Python packages list\n- `package.json` - Node.js packages list\n\n### Convenience Scripts\n- `LAUNCH_FORTUNA.bat` - Start everything\n- `STOP_FORTUNA.bat` - Stop everything\n- `RESTART_FORTUNA.bat` - Clean restart\n- `setup_wizard.py` - Interactive config tool\n\n### Python Backend (`python_service/`)\n- `api.py` - Web server (FastAPI)\n- `engine.py` - Master data orchestrator\n- `analyzer.py` - Race scoring logic\n- `models.py` - Data structure definitions\n- `adapters/` - Individual data source plugins\n\n### Frontend (`web_platform/frontend/`)\n- `src/app/page.tsx` - Main dashboard\n- `src/components/RaceCard.tsx` - Individual race display\n- `.env.local` - Frontend API key\n\n---\n\n## \ud83c\udf93 Customization Ideas\n\n### Change Analyzer Thresholds\nEdit `python_service/analyzer.py`:\n```python\nclass TrifectaAnalyzer(BaseAnalyzer):\n    def __init__(self,\n                 max_field_size: int = 8,      # \u2190 Change this\n                 min_favorite_odds: float = 3.0, # \u2190 Or this\n                 min_second_favorite_odds: float = 5.0): # \u2190 Or this\n```\n\n### Add New Data Sources\n1. Copy `python_service/adapters/template_adapter.py`\n2. Rename and implement the `fetch_races()` method\n3. Register in `python_service/adapters/__init__.py`\n4. Add to `python_service/engine.py` adapter list\n\n### Customize Dashboard Colors\nEdit `web_platform/frontend/tailwind.config.ts`:\n```typescript\ntheme: {\n  extend: {\n    colors: {\n      'fortuna-primary': '#your-hex-color',\n    }\n  }\n}\n```\n\n---\n\n## \ud83d\udca1 Pro Tips\n\n### Tip 1: Use Windows Task Scheduler\nRun `SCHEDULE_FORTUNA.bat` for:\n- Auto-start on login\n- Daily 3 AM maintenance restart\n\n### Tip 2: Monitor Multiple Days\nThe analyzer works for \"today\" by default, but you can query any date:\n```\nhttp://localhost:8000/api/races/qualified/trifecta?race_date=2025-10-25\n```\n\n### Tip 3: Export Data\nThe API returns pure JSON. Use tools like:\n- **Postman** for testing\n- **PowerShell** for scripting:\n```powershell\nInvoke-RestMethod -Uri \"http://localhost:8000/api/races/qualified/trifecta\" `\n  -Headers @{\"X-API-Key\"=\"your_key\"} | ConvertTo-Json -Depth 10\n```\n\n### Tip 4: Mobile Access\nIf you want to check from your phone on the same WiFi:\n1. Find your PC's IP: `ipconfig` in Command Prompt\n2. Open firewall port 3000\n3. Access from phone: `http://192.168.1.X:3000`\n\n---\n\n## \ud83c\udf89 You're Ready!\n\nThis is a **professional-grade** system that you now control. It was built with years of racing analytics experience and modern software practices.\n\n### What You Can Do Now:\n\u2705 Track races from 20+ global sources\n\u2705 Identify value opportunities with AI scoring\n\u2705 Monitor live odds movements\n\u2705 Run 24/7 as a background service\n\u2705 Customize thresholds and filters\n\u2705 Expand with new data sources\n\n**Welcome to the world of algorithmic racing analysis!** \ud83c\udfc7\ud83d\ude80\n\n---\n\n## \ud83d\udcde Additional Resources\n\n### Project Documentation\n- `HISTORY.md` - Project evolution story\n- `ARCHITECTURAL_MANDATE.md` - System design principles\n- `WISDOM.md` - Developer best practices\n- `ROADMAP_APPENDICES.md` - Future expansion ideas\n\n### Useful Commands\n```batch\n# View all active Python processes\ntasklist | findstr python\n\n# Check if ports are available\nnetstat -ano | findstr :8000\nnetstat -ano | findstr :3000\n\n# Update Python packages\n.venv\\Scripts\\activate\npip install --upgrade -r requirements.txt\n```\n\n### Need Help?\n1. Check `fortuna_restart.log` for error history\n2. Run `fortuna_monitor.py` to see real-time system status\n3. Verify `.env` file has all required keys\n\nHappy Racing! \ud83c\udfb0\ud83c\udfc6",
    "VERSION.txt": "1.0",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2)---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "assets/sounds/.gitkeep": "# This directory is for audio alert sound files (e.g., alert_premium.wav)",
    "backend.log": "2025-10-24 14:33:28 [warning  ] encryption_key_not_found       file=.key recommendation=Run 'python manage_secrets.py' to generate a key.\nINFO:     Started server process [27354]\nINFO:     Waiting for application startup.\n{\"event\": \"Server startup sequence initiated.\", \"logger\": \"python_service.api\", \"level\": \"info\", \"timestamp\": \"2025-10-24T14:33:28.143122Z\"}\n{\"event\": \"Initializing FortunaEngine...\", \"logger\": \"python_service.engine\", \"level\": \"info\", \"timestamp\": \"2025-10-24T14:33:28.143361Z\"}\n{\"event\": \"Configuration loaded.\", \"logger\": \"python_service.engine\", \"level\": \"info\", \"timestamp\": \"2025-10-24T14:33:28.143455Z\"}\n{\"event\": \"Initializing adapters...\", \"logger\": \"python_service.engine\", \"level\": \"info\", \"timestamp\": \"2025-10-24T14:33:28.143531Z\"}\n{\"event\": \"Fortuna build type: full\", \"logger\": \"python_service.engine\", \"level\": \"info\", \"timestamp\": \"2025-10-24T14:33:28.143656Z\"}\n{\"event\": \"CRITICAL FAILURE during FortunaEngine initialization.\", \"logger\": \"python_service.engine\", \"level\": \"critical\", \"timestamp\": \"2025-10-24T14:33:28.143906Z\", \"exception\": \"Traceback (most recent call last):\\n  File \\\"/app/python_service/engine.py\\\", line 73, in __init__\\n    RacingAndSportsGreyhoundAdapter(config=self.config),\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/python_service/adapters/racing_and_sports_greyhound_adapter.py\\\", line 20, in __init__\\n    raise AdapterConfigError(self.source_name, \\\"RACING_AND_SPORTS_TOKEN is not configured.\\\")\\npython_service.core.exceptions.AdapterConfigError: [Racing and Sports Greyhound] RACING_AND_SPORTS_TOKEN is not configured.\"}\n{\"event\": \"FATAL: Failed to initialize FortunaEngine during server startup.\", \"logger\": \"python_service.api\", \"level\": \"critical\", \"timestamp\": \"2025-10-24T14:33:28.145351Z\", \"exception\": \"Traceback (most recent call last):\\n  File \\\"/app/python_service/api.py\\\", line 53, in lifespan\\n    app.state.engine = FortunaEngine(config=settings)\\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/python_service/engine.py\\\", line 104, in __init__\\n    raise e\\n  File \\\"/app/python_service/engine.py\\\", line 73, in __init__\\n    RacingAndSportsGreyhoundAdapter(config=self.config),\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/python_service/adapters/racing_and_sports_greyhound_adapter.py\\\", line 20, in __init__\\n    raise AdapterConfigError(self.source_name, \\\"RACING_AND_SPORTS_TOKEN is not configured.\\\")\\npython_service.core.exceptions.AdapterConfigError: [Racing and Sports Greyhound] RACING_AND_SPORTS_TOKEN is not configured.\"}\nERROR:    Traceback (most recent call last):\n  File \"/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/starlette/routing.py\", line 677, in lifespan\n    async with self.lifespan_context(app) as maybe_state:\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jules/.pyenv/versions/3.12.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/python_service/api.py\", line 59, in lifespan\n    raise e\n  File \"/app/python_service/api.py\", line 53, in lifespan\n    app.state.engine = FortunaEngine(config=settings)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/python_service/engine.py\", line 104, in __init__\n    raise e\n  File \"/app/python_service/engine.py\", line 73, in __init__\n    RacingAndSportsGreyhoundAdapter(config=self.config),\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/python_service/adapters/racing_and_sports_greyhound_adapter.py\", line 20, in __init__\n    raise AdapterConfigError(self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\")\npython_service.core.exceptions.AdapterConfigError: [Racing and Sports Greyhound] RACING_AND_SPORTS_TOKEN is not configured.\n\nERROR:    Application startup failed. Exiting.\n",
    "check_port.py": "# check_port.py\nimport socket\nimport time\n\ndef check_server_status(host, port):\n    \"\"\"Checks if the server is accessible.\"\"\"\n    time.sleep(5) # Give server time to start\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        try:\n            s.connect((host, port))\n            print(\"SERVER CHECK: SUCCESS! Server is running and accessible.\")\n            return True\n        except ConnectionRefusedError:\n            print(\"SERVER CHECK: FAILED! Server is not accessible.\")\n            return False\n\nif __name__ == \"__main__\":\n    check_server_status(\"127.0.0.1\", 8000)\n",
    "config.ini": "[analysis]\nqualification_score = 75.0\nfield_size_optimal_min = 4\nfield_size_optimal_max = 6\nfield_size_acceptable_min = 7\nfield_size_acceptable_max = 8\nfield_size_optimal_points = 30\nfield_size_acceptable_points = 10\nfield_size_penalty_points = -20\nfav_odds_points = 30\nmax_fav_odds = 3.5\nsecond_fav_odds_points = 40\nmin_2nd_fav_odds = 4.0\n\n[system]\napi_rate_limit = 60",
    "configure_startup.py": "# configure_startup.py\nimport winreg\nimport sys\nfrom pathlib import Path\n\nclass StartupManager:\n    \"\"\"Manage Windows startup registry entries for the current user.\"\"\"\n\n    REGISTRY_PATH = r\"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n    APP_NAME = \"FortunaFaucetTray\"\n\n    @classmethod\n    def is_enabled(cls) -> bool:\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_READ)\n            winreg.QueryValueEx(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            return True\n        except FileNotFoundError:\n            return False\n\n    @classmethod\n    def enable(cls):\n        launcher_path = Path(__file__).parent / \"launcher.ps1\"\n        cmd = f'powershell.exe -WindowStyle Hidden -File \"{launcher_path}\"'\n\n        key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n        winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, cmd)\n        winreg.CloseKey(key)\n        print(\"Startup enabled.\")\n\n    @classmethod\n    def disable(cls):\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n            winreg.DeleteValue(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            print(\"Startup disabled.\")\n        except FileNotFoundError:\n            print(\"Already disabled.\")\n\nif __name__ == '__main__':\n    if len(sys.argv) > 1:\n        if sys.argv[1] == 'enable': StartupManager.enable()\n        elif sys.argv[1] == 'disable': StartupManager.disable()\n        elif sys.argv[1] == 'status': print(f\"Startup is currently {'enabled' if StartupManager.is_enabled() else 'disabled'}\")\n    else:\n        print(\"Usage: python configure_startup.py [enable|disable|status]\")\n",
    "create_fortuna_json.py": "# DEPRECATED\n# This script is no longer in use and is superseded by ARCHIVE_PROJECT.py\n\nimport sys\n\nprint(\"ERROR: This script is deprecated.\", file=sys.stderr)\nprint(\"Please use 'python ARCHIVE_PROJECT.py' to generate the project archives.\", file=sys.stderr)\nsys.exit(1)",
    "fortuna_app.py": "import tkinter as tk\nfrom tkinter import ttk, messagebox, scrolledtext, font\nimport subprocess\nimport threading\nimport time\nimport requests\nimport psutil\nimport socket\nimport sys\nimport os\nfrom pathlib import Path\n\n# --- Control Panel Tab (from former launcher_gui.py) ---\nclass ControlPanelTab(tk.Frame):\n    def __init__(self, parent, master_app):\n        super().__init__(parent, bg='#1a1a2e')\n        self.master_app = master_app\n        self.backend_proc = None\n        self.frontend_proc = None\n        self.backend_unresponsive_count = 0\n        self.frontend_unresponsive_count = 0\n        self.first_launch = not (Path(os.environ[\"USERPROFILE\"]) / \"Desktop\" / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\").exists()\n        self._create_ui()\n        self.monitor_thread = threading.Thread(target=self.monitor_services, daemon=True)\n        self.monitor_thread.start()\n\n    def log_output(self, message):\n        self.log_text.config(state=tk.NORMAL)\n        self.log_text.insert(tk.END, f\"[{time.strftime('%H:%M:%S')}] {message}\\n\")\n        self.log_text.config(state=tk.DISABLED)\n        self.log_text.see(tk.END)\n\n    def smart_start(self):\n        \"\"\"On first launch, run verification, create shortcuts, and then start.\"\"\"\n        if messagebox.askokcancel(\"First-Time Setup\", \"Welcome to Fortuna Faucet!\\n\\nThis first launch will verify your system and create a desktop shortcut for easy access. Proceed?\"):\n            # Steal and run the logic from the System Tools Tab\n            self.master_app.notebook.select(self.master_app.system_tools_tab)\n            self.master_app.system_tools_tab.run_verification()\n            self.master_app.system_tools_tab.run_create_shortcuts()\n\n            # Once done, revert to a normal start button\n            messagebox.showinfo(\"Setup Complete\", \"Setup is complete! The main services will now start.\")\n            self.launch_btn.config(text=\"\u25b6 START FORTUNA\", bg='#00ff88', command=self.launch_services)\n            self.launch_services()\n\n    def _create_ui(self):\n        title = tk.Label(self, text=\"\ud83d\udc34 System Control Panel\", font=(\"Segoe UI\", 16, \"bold\"), bg='#1a1a2e', fg='#00ff88')\n        title.pack(pady=20)\n\n        status_frame = tk.Frame(self, bg='#1a1a2e')\n        status_frame.pack(fill=tk.X, padx=40, pady=10)\n\n        tk.Label(status_frame, text=\"Backend Service (API)\", font=(\"Segoe UI\", 10), bg='#1a1a2e', fg='#ffffff').pack(anchor=\"w\")\n        self.backend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg='#0f3460', highlightthickness=0)\n        self.backend_status_canvas.pack(fill=tk.X, pady=(0, 10))\n        self.backend_indicator = self.backend_status_canvas.create_oval(15, 10, 35, 30, fill='#ff4444', outline='')\n        self.backend_text = self.backend_status_canvas.create_text(55, 20, text=\"Stopped\", fill='#ffffff', anchor=\"w\", font=(\"Segoe UI\", 9))\n\n        tk.Label(status_frame, text=\"Frontend Dashboard (UI)\", font=(\"Segoe UI\", 10), bg='#1a1a2e', fg='#ffffff').pack(anchor=\"w\")\n        self.frontend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg='#0f3460', highlightthickness=0)\n        self.frontend_status_canvas.pack(fill=tk.X)\n        self.frontend_indicator = self.frontend_status_canvas.create_oval(15, 10, 35, 30, fill='#ff4444', outline='')\n        self.frontend_text = self.frontend_status_canvas.create_text(55, 20, text=\"Stopped\", fill='#ffffff', anchor=\"w\", font=(\"Segoe UI\", 9))\n\n        button_frame = tk.Frame(self, bg='#1a1a2e')\n        button_frame.pack(fill=tk.X, padx=40, pady=20)\n\n        self.launch_btn = tk.Button(button_frame, text=\"\u25b6 START FORTUNA\", font=(\"Segoe UI\", 14, \"bold\"), bg='#00ff88', fg='#000000', height=2, relief=tk.FLAT)\n        if self.first_launch:\n            self.launch_btn.config(text=\"\u25b6 FIRST-TIME START & SETUP\", bg=\"#ff9900\", command=self.smart_start)\n        else:\n            self.launch_btn.config(command=self.launch_services)\n        self.launch_btn.pack(fill=tk.X, pady=(0, 10))\n\n        self.stop_btn = tk.Button(button_frame, text=\"\u23f9 STOP SERVICES\", font=(\"Segoe UI\", 12), bg='#ff4444', fg='#ffffff', command=self.stop_services, state=tk.DISABLED, height=1, relief=tk.FLAT)\n        self.stop_btn.pack(fill=tk.X)\n\n        self.log_text = scrolledtext.ScrolledText(self, height=5, bg=\"#000000\", fg=\"#00ff88\", state=tk.DISABLED)\n        self.log_text.pack(pady=10, padx=40, fill=tk.X)\n\n    def check_ports(self, ports=[8000, 3000]):\n        unavailable_ports = []\n        for port in ports:\n            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n                if s.connect_ex(('127.0.0.1', port)) == 0:\n                    unavailable_ports.append(port)\n        return unavailable_ports\n\n    def launch_services(self):\n        unavailable = self.check_ports()\n        if unavailable:\n            messagebox.showerror(\"Port Conflict\", f\"Cannot launch. Port(s) {', '.join(map(str, unavailable))} are already in use by another application.\")\n            return\n\n        self.launch_btn.config(state=tk.DISABLED)\n        self.update_status(\"backend\", \"starting\", \"Launching...\")\n        self.update_status(\"frontend\", \"starting\", \"Launching...\")\n\n        try:\n            venv_python = Path(\".venv/Scripts/python.exe\")\n            self.backend_proc = subprocess.Popen(\n                [str(venv_python), \"-m\", \"uvicorn\", \"python_service.api:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"],\n                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=Path(__file__).parent, creationflags=subprocess.CREATE_NEW_PROCESS_GROUP\n            )\n        except Exception as e:\n            self.update_status(\"backend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        try:\n            self.frontend_proc = subprocess.Popen(\n                [\"npm\", \"run\", \"dev\"], shell=True,\n                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=\"web_platform/frontend\", creationflags=subprocess.CREATE_NEW_PROCESS_GROUP\n            )\n        except Exception as e:\n            self.update_status(\"frontend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        self.stop_btn.config(state=tk.NORMAL)\n\n    def stop_services(self):\n        self.stop_btn.config(state=tk.DISABLED)\n        for proc_name in [\"backend\", \"frontend\"]:\n            proc = getattr(self, f\"{proc_name}_proc\")\n            if proc and proc.poll() is None:\n                try:\n                    parent = psutil.Process(proc.pid)\n                    for child in parent.children(recursive=True):\n                        child.kill()\n                    parent.kill()\n                except psutil.NoSuchProcess:\n                    pass\n            setattr(self, f\"{proc_name}_proc\", None)\n        self.launch_btn.config(state=tk.NORMAL)\n\n    def restart_service(self, service_name: str):\n        \"\"\"Gracefully stop and restart a single failed service.\"\"\"\n        proc_attr = f\"{service_name}_proc\"\n        proc = getattr(self, proc_attr)\n\n        # Stop the specific process\n        if proc and proc.poll() is None:\n            try:\n                parent = psutil.Process(proc.pid)\n                for child in parent.children(recursive=True):\n                    child.kill()\n                parent.kill()\n            except psutil.NoSuchProcess:\n                pass\n        setattr(self, proc_attr, None)\n\n        # Wait a moment\n        time.sleep(2)\n\n        # Relaunch the specific process\n        self.update_status(service_name, \"starting\", \"Attempting auto-restart...\")\n        try:\n            if service_name == \"backend\":\n                venv_python = Path(\".venv/Scripts/python.exe\")\n                new_proc = subprocess.Popen(\n                    [str(venv_python), \"-m\", \"uvicorn\", \"python_service.api:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"],\n                    stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=Path(__file__).parent.parent, creationflags=subprocess.CREATE_NEW_PROCESS_GROUP\n                )\n            else: # frontend\n                new_proc = subprocess.Popen(\n                    [\"npm\", \"run\", \"dev\"], shell=True,\n                    stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=\"web_platform/frontend\", creationflags=subprocess.CREATE_NEW_PROCESS_GROUP\n                )\n            setattr(self, proc_attr, new_proc)\n        except Exception as e:\n            self.update_status(service_name, \"error\", f\"Auto-restart failed: {e}\")\n\n    def monitor_services(self):\n        while True:\n            # --- Backend Monitoring ---\n            if self.backend_proc and self.backend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:8000/health\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"backend\", \"ok\", \"Healthy (200 OK)\")\n                        self.backend_unresponsive_count = 0 # Reset counter on success\n                    else:\n                        self.update_status(\"backend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"backend\", \"unresponsive\", \"Unresponsive\")\n                    self.backend_unresponsive_count += 1\n                    if self.backend_unresponsive_count >= 3: # If unresponsive for 3 cycles (15s)\n                        self.log_output(\"Backend unresponsive. Attempting automatic restart...\")\n                        self.restart_service(\"backend\")\n                        self.backend_unresponsive_count = 0 # Reset after attempt\n            else:\n                self.update_status(\"backend\", \"stopped\", \"Stopped\")\n\n            # --- Frontend Monitoring ---\n            if self.frontend_proc and self.frontend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:3000\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"frontend\", \"ok\", \"Healthy (200 OK)\")\n                        self.frontend_unresponsive_count = 0\n                    else:\n                        self.update_status(\"frontend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"frontend\", \"unresponsive\", \"Unresponsive\")\n                    self.frontend_unresponsive_count += 1\n                    if self.frontend_unresponsive_count >= 3:\n                        self.log_output(\"Frontend unresponsive. Attempting automatic restart...\")\n                        self.restart_service(\"frontend\")\n                        self.frontend_unresponsive_count = 0\n            else:\n                self.update_status(\"frontend\", \"stopped\", \"Stopped\")\n            time.sleep(5)\n\n    def update_status(self, service: str, status: str, message: str):\n        colors = {\"ok\": \"#00ff88\", \"unresponsive\": \"#ffcc00\", \"error\": \"#ff4444\", \"stopped\": \"#ff4444\", \"starting\": \"#0f6cbd\"}\n        canvas = getattr(self, f\"{service}_status_canvas\")\n        indicator = getattr(self, f\"{service}_indicator\")\n        text = getattr(self, f\"{service}_text\")\n\n        canvas.itemconfig(indicator, fill=colors.get(status, \"#404060\"))\n        canvas.itemconfig(text, text=message)\n\n# --- Setup Wizard Tab (from former setup_wizard_gui.py) ---\nclass SetupWizardTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg='#1a1a2e')\n        self.current_step = 0\n        self.settings = {}\n        self._create_widgets()\n        self.show_step(0)\n\n    def _create_widgets(self):\n        header = tk.Label(self, text=\"\ud83d\udd27 First-Time Setup & Configuration\", font=(\"Segoe UI\", 16, \"bold\"), bg='#1a1a2e', fg='#ffffff')\n        header.pack(pady=20)\n        self.step_label = tk.Label(self, text=\"Step 1 of 4: Generate API Key\", font=(\"Segoe UI\", 11), bg='#1a1a2e', fg='#ffffff')\n        self.step_label.pack(pady=10)\n        self.content_frame = tk.Frame(self, bg='#1a1a2e')\n        self.content_frame.pack(fill=tk.BOTH, expand=True, padx=30, pady=20)\n        button_frame = tk.Frame(self, bg='#1a1a2e')\n        button_frame.pack(fill=tk.X, padx=30, pady=20)\n        self.prev_btn = tk.Button(button_frame, text=\"< Back\", command=self.previous_step, state=tk.DISABLED, bg='#404060', fg='#ffffff', padx=20)\n        self.prev_btn.pack(side=tk.LEFT)\n        self.next_btn = tk.Button(button_frame, text=\"Next >\", command=self.next_step, bg='#00ff88', fg='#000000', font=(\"Segoe UI\", 11, \"bold\"), padx=20)\n        self.next_btn.pack(side=tk.RIGHT)\n\n    def show_step(self, step_index):\n        self._clear_content()\n        self.current_step = step_index\n        if step_index == 0: self._show_step_1()\n        elif step_index == 1: self._show_step_2()\n        elif step_index == 2: self._show_step_3()\n        elif step_index == 3: self._show_step_4()\n        self.update_buttons()\n\n    def _show_step_1(self):\n        tk.Label(self.content_frame, text=\"\ud83d\udd10 Secure API Key\", font=(\"Segoe UI\", 12, \"bold\"), bg='#1a1a2e', fg='#ffffff').pack(anchor=\"w\")\n        tk.Label(self.content_frame, text=\"A secure API key will be generated and stored.\", wraplength=600, justify=tk.LEFT, bg='#1a1a2e', fg='#cccccc').pack(anchor=\"w\", pady=10)\n        # ... Add API key generation logic and display ...\n\n    def _show_step_2(self):\n        tk.Label(self.content_frame, text=\"\ud83c\udfc7 Betfair Exchange (Optional)\", font=(\"Segoe UI\", 12, \"bold\"), bg='#1a1a2e', fg='#ffffff').pack(anchor=\"w\")\n        # ... Add Betfair configuration form ...\n\n    def _show_step_3(self):\n        tk.Label(self.content_frame, text=\"\u2713 Verifying Setup\", font=(\"Segoe UI\", 12, \"bold\"), bg='#1a1a2e', fg='#00ff88').pack(anchor=\"w\")\n        # ... Add verification checks logic ...\n\n    def _show_step_4(self):\n        tk.Label(self.content_frame, text=\"\ud83c\udf89 Setup Complete!\", font=(\"Segoe UI\", 14, \"bold\"), bg='#1a1a2e', fg='#00ff88').pack(pady=20)\n        self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n\n    def next_step(self):\n        if self.current_step < 3: self.show_step(self.current_step + 1)\n    def previous_step(self):\n        if self.current_step > 0: self.show_step(self.current_step - 1)\n    def finish_setup(self):\n        messagebox.showinfo(\"Setup Complete\", \"Your configuration has been saved.\")\n\n    def _clear_content(self):\n        for widget in self.content_frame.winfo_children(): widget.destroy()\n\n    def update_buttons(self):\n        self.prev_btn.config(state=tk.NORMAL if self.current_step > 0 else tk.DISABLED)\n        if self.current_step == 3:\n            self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n        else:\n            self.next_btn.config(text=\"Next >\", command=self.next_step)\n\n# --- System Tools Tab ---\nclass SystemToolsTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg='#1a1a2e')\n        self._create_ui()\n\n    def _create_ui(self):\n        title = tk.Label(self, text=\"\u2699\ufe0f System Tools\", font=(\"Segoe UI\", 16, \"bold\"), bg='#1a1a2e', fg='#ffffff')\n        title.pack(pady=20)\n        tk.Button(self, text=\"Create Desktop Shortcuts\", command=self.run_create_shortcuts, font=(\"Segoe UI\", 12)).pack(pady=10, padx=40, fill=tk.X)\n        tk.Button(self, text=\"Verify Installation\", command=self.run_verification, font=(\"Segoe UI\", 12)).pack(pady=10, padx=40, fill=tk.X)\n        self.output_box = scrolledtext.ScrolledText(self, height=10, bg=\"#0f3460\", fg=\"#ffffff\", state=tk.DISABLED)\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n    def log_output(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n\n    def run_create_shortcuts(self):\n        self.log_output(\"--- Creating Desktop Shortcut ---\")\n        try:\n            from win32com.client import Dispatch\n            desktop = Path(os.environ[\"USERPROFILE\"]) / \"Desktop\"\n            app_path = Path(__file__).resolve()\n            shortcut_path = desktop / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\"\n\n            if shortcut_path.exists():\n                self.log_output(\"\ud83d\udfe1 Shortcut already exists. Overwriting.\")\n\n            shell = Dispatch(\"WScript.Shell\")\n            shortcut = shell.CreateShortCut(str(shortcut_path))\n            shortcut.TargetPath = sys.executable\n            shortcut.Arguments = f'\"{app_path}\"'\n            shortcut.WorkingDirectory = str(app_path.parent)\n\n            ico_path = app_path.parent / \"fortuna.ico\"\n            if ico_path.exists():\n                shortcut.IconLocation = str(ico_path)\n            else:\n                self.log_output(\"\ud83d\udfe1 Icon file not found, using default.\")\n\n            shortcut.save()\n            self.log_output(\"\u2705 Success: Shortcut created on Desktop.\")\n        except ImportError:\n            self.log_output(\"\u274c ERROR: 'pywin32' is not installed. Cannot create shortcuts.\")\n            self.log_output(\"  Please run: pip install pywin32\")\n        except Exception as e:\n            self.log_output(f\"\u274c ERROR: An unexpected error occurred: {e}\")\n\n    def run_verification(self):\n        self.log_output(\"\\n--- Verifying System Setup ---\")\n        verifications = [\n            (\"Python 3.11+\", lambda: sys.version_info >= (3, 11)),\n            (\"Python Virtual Env (.venv)\", lambda: Path(\".venv\").exists() and Path(\".venv/Scripts/python.exe\").exists()),\n            (\"Node.js (npm)\", lambda: subprocess.run(\"npm -v\", shell=True, capture_output=True).returncode == 0),\n            (\"Frontend Dependencies (node_modules)\", lambda: Path(\"web_platform/frontend/node_modules\").exists()),\n        ]\n\n        all_ok = True\n        for name, check in verifications:\n            result = check()\n            self.log_output(f\"- {name}: {'\u2705 OK' if result else '\u274c FAILED'}\")\n            if not result:\n                all_ok = False\n\n        if all_ok:\n            self.log_output(\"\\n\u2705 All checks passed. System is ready.\")\n        else:\n            self.log_output(\"\\n\u274c Some checks failed. Please review the log.\")\n\n# --- Main Application Window ---\nclass FortunaApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"\ud83d\udc34 Fortuna Faucet\")\n        self.geometry(\"700x550\")\n        self.configure(bg='#1a1a2e')\n\n        style = ttk.Style()\n        style.theme_use('clam')\n        style.configure(\"TNotebook\", background='#1a1a2e', borderwidth=0)\n        style.configure(\"TNotebook.Tab\", background=\"#404060\", foreground=\"#ffffff\", padding=[10, 5])\n        style.map(\"TNotebook.Tab\", background=[(\"selected\", \"#0f6cbd\")])\n\n        self.notebook = ttk.Notebook(self)\n\n        self.control_panel_tab = ControlPanelTab(self.notebook, self)\n        self.setup_wizard_tab = SetupWizardTab(self.notebook)\n        self.system_tools_tab = SystemToolsTab(self.notebook)\n\n        self.notebook.add(self.control_panel_tab, text='Control Panel')\n        self.notebook.add(self.setup_wizard_tab, text='Setup & Config')\n        self.notebook.add(self.system_tools_tab, text='System Tools')\n\n        self.notebook.pack(expand=True, fill='both', padx=10, pady=10)\n\n    def on_closing(self):\n        if self.control_panel_tab.backend_proc or self.control_panel_tab.frontend_proc:\n            if messagebox.askokcancel(\"Quit\", \"Services are still running. Do you want to stop them and exit?\"):\n                self.control_panel_tab.stop_services()\n                self.destroy()\n        else:\n            self.destroy()\n\n# --- NEW: Self-Setup UI and Logic ---\nclass SetupApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - First-Time Setup\")\n        self.geometry(\"700x500\")\n        self.configure(bg='#1a1a2e')\n\n        self.protocol(\"WM_DELETE_WINDOW\", self.quit)\n\n        header_font = tk.font.Font(family=\"Segoe UI\", size=16, weight=\"bold\")\n        body_font = tk.font.Font(family=\"Segoe UI\", size=10)\n        button_font = tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\")\n\n        tk.Label(self, text=\"\ud83d\udce6 Welcome to Fortuna Faucet\", font=header_font, bg='#1a1a2e', fg='#00ff88').pack(pady=(20, 10))\n        tk.Label(self, text=\"The necessary dependencies are not installed. Click 'Start Installation' to begin.\", font=body_font, bg='#1a1a2e', fg='#ffffff').pack(pady=(0, 20))\n\n        self.install_button = tk.Button(self, text=\"\u25b6\ufe0f Start Installation\", font=button_font, bg='#00ff88', fg='#000000', command=self.start_installation, relief=tk.FLAT, padx=20, pady=10)\n        self.install_button.pack(pady=10)\n\n        self.output_box = scrolledtext.ScrolledText(self, height=15, bg=\"#0f3460\", fg=\"#cccccc\", state=tk.DISABLED, relief=tk.FLAT, bd=0, padx=10, pady=10)\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n        self.status_label = tk.Label(self, text=\"Waiting to start...\", font=body_font, bg='#1a1a2e', fg='#ffffff')\n        self.status_label.pack(pady=10)\n\n    def log(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n        self.update_idletasks()\n\n    def start_installation(self):\n        self.install_button.config(state=tk.DISABLED, text=\"Installation in progress...\")\n        self.log(\"--- Starting installation ---\")\n        self.status_label.config(text=\"Installing... Please be patient, this may take several minutes.\")\n        threading.Thread(target=self.run_install_commands, daemon=True).start()\n\n    def run_command(self, command):\n        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', errors='replace', shell=True)\n        for line in iter(process.stdout.readline, ''):\n            self.log(line.strip())\n        process.wait()\n        return process.returncode\n\n    def run_install_commands(self):\n        commands = [\n            (\"1/3: Creating Python virtual environment...\", f'{sys.executable} -m venv .venv'),\n            (\"2/3: Installing Python dependencies...\", '\\\"' + str(Path(\".venv/Scripts/python.exe\")) + '\\\" -m pip install -r requirements.txt'),\n            (\"3/3: Installing Node.js dependencies...\", 'npm install --prefix web_platform/frontend')\n        ]\n\n        for i, (msg, cmd) in enumerate(commands):\n            self.log(f'\\\\n--- STEP {msg} ---')\n            return_code = self.run_command(cmd)\n            if return_code != 0:\n                self.log(f'\\\\n--- ERROR: Step {i+1} failed with code {return_code}. ---')\n                self.status_label.config(text=\"Installation Failed. Please see log for details.\", fg=\"#ff4444\")\n                self.install_button.config(state=tk.NORMAL, text=\"Retry Installation\")\n                return\n\n        self.log(\"\\\\n--- \u2705 INSTALLATION COMPLETE! ---\")\n        self.status_label.config(text=\"Setup successful! You can now launch the application.\", fg=\"#00ff88\")\n        self.install_button.destroy()\n        launch_button = tk.Button(self, text=\"\ud83d\ude80 Launch Fortuna\", font=tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\"), bg='#00ff88', fg='#000000', command=self.launch_app, relief=tk.FLAT, padx=20, pady=10)\n        launch_button.pack(pady=10)\n\n    def launch_app(self):\n        self.destroy()\n        # Relaunch the script to start the main app\n        subprocess.Popen([sys.executable, __file__])\n\n# --- NEW: Main Execution Block ---\nif __name__ == \"__main__\":\n    VENV_PATH = Path(__file__).parent / \".venv\"\n    if not VENV_PATH.exists() or not (VENV_PATH / \"Scripts\" / \"python.exe\").exists():\n        # If the virtual environment doesn't exist, run the setup wizard.\n        setup_app = SetupApp()\n        setup_app.mainloop()\n    else:\n        # Otherwise, run the main application.\n        app = FortunaApp()\n        app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n        app.mainloop()",
    "fortuna_monitor.py": "# fortuna_monitor.py - Windows-Optimized Version\n\nimport asyncio\nimport httpx\nimport tkinter as tk\nfrom tkinter import ttk, messagebox, filedialog\nfrom datetime import datetime\nimport os\nfrom collections import deque\nimport threading\nimport psutil\nimport sys\nimport time\n\n# Try to import matplotlib for graphs\ntry:\n    from matplotlib.figure import Figure\n    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n    GRAPHS_AVAILABLE = True\nexcept ImportError:\n    GRAPHS_AVAILABLE = False\n\nAPI_BASE_URL = \"http://localhost:8000\"\n\nclass PerformanceTracker:\n    def __init__(self, max_history=100):\n        self.timestamps = deque(maxlen=max_history)\n        self.race_counts = deque(maxlen=max_history)\n        self.fetch_durations = deque(maxlen=max_history)\n        self.success_rates = deque(maxlen=max_history)\n        self.cpu_usage = deque(maxlen=max_history)\n        self.memory_usage = deque(maxlen=max_history)\n\n    def add_datapoint(self, races, duration, success_rate):\n        self.timestamps.append(datetime.now())\n        self.race_counts.append(races)\n        self.fetch_durations.append(duration)\n        self.success_rates.append(success_rate)\n        self.cpu_usage.append(psutil.cpu_percent(interval=None))\n        process = psutil.Process(os.getpid())\n        self.memory_usage.append(process.memory_info().rss / 1024 / 1024) # MB\n\n    def export_to_csv(self, filename):\n        import csv\n        history = self.get_history()\n        with open(filename, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Timestamp', 'Races', 'Duration', 'Success Rate', 'CPU %', 'Memory MB'])\n            for i in range(len(history['times'])):\n                writer.writerow([\n                    history['times'][i].isoformat(),\n                    history['races'][i],\n                    history['durations'][i],\n                    history['success'][i],\n                    history['cpu'][i],\n                    history['memory'][i]\n                ])\n\n    def get_history(self):\n        return {\n            'times': list(self.timestamps),\n            'races': list(self.race_counts),\n            'durations': list(self.fetch_durations),\n            'success': list(self.success_rates),\n            'cpu': list(self.cpu_usage),\n            'memory': list(self.memory_usage)\n        }\n\nclass FortunaAdvancedMonitor(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - Advanced Monitor\")\n        self.geometry(\"900x650\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.performance = PerformanceTracker()\n        self.running = True\n        self._create_widgets()\n        self.after(100, self.start_fetch_thread)\n\n    def _create_widgets(self):\n        self._create_control_panel()\n        # ... (rest of the widget creation)\n\n    def _create_control_panel(self):\n        control_frame = tk.Frame(self, bg='#1a1a2e')\n        control_frame.pack(fill=tk.X, padx=15, pady=10)\n\n        tk.Button(\n            control_frame,\n            text=\"\ud83d\udcca Export Performance Data\",\n            command=self.export_data,\n            bg='#0f3460',\n            fg='#ffffff',\n            font=('Segoe UI', 10, 'bold'),\n            relief=tk.FLAT,\n            padx=25,\n            pady=10\n        ).pack(side=tk.LEFT, padx=5)\n\n        tk.Button(\n            control_frame,\n            text=\"\ud83d\udcbb System Info\",\n            command=self.show_system_info,\n            bg='#0f3460',\n            fg='#ffffff',\n            font=('Segoe UI', 10, 'bold'),\n            relief=tk.FLAT,\n            padx=25,\n            pady=10\n        ).pack(side=tk.LEFT, padx=5)\n\n    def start_fetch_thread(self):\n        self.fetch_thread = threading.Thread(target=self._fetch_data_loop, daemon=True)\n        self.fetch_thread.start()\n\n    def _fetch_data_loop(self):\n        while self.running:\n            try:\n                # Use httpx for async requests\n                with httpx.Client(headers={\"X-API-KEY\": self.api_key}, timeout=5) as client:\n                    response = client.get(f\"{API_BASE_URL}/api/adapters/status\")\n                if response.status_code == 200:\n                    data = response.json()\n                    # Add performance datapoint\n                    total_races = sum(a.get('races_fetched', 0) for a in data)\n                    successful_adapters = [a for a in data if a.get('status') == 'SUCCESS']\n                    success_rate = (len(successful_adapters) / len(data) * 100) if data else 0\n                    avg_duration = sum(a.get('fetch_duration', 0) for a in successful_adapters) / len(successful_adapters) if successful_adapters else 0\n                    self.performance.add_datapoint(total_races, avg_duration, success_rate)\n\n                    self.after(0, self.update_ui, data)\n            except httpx.RequestError:\n                pass\n            time.sleep(10) # Refresh interval\n\n    def update_ui(self, data):\n        # This is where you would update the tkinter UI with the new data\n        # For example, you might update a treeview or a graph\n        pass\n\n    def export_data(self):\n        filename = filedialog.asksaveasfilename(\n            defaultextension=\".csv\",\n            filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")],\n            initialfile=f\"fortuna_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n        )\n        if filename:\n            try:\n                self.performance.export_to_csv(filename)\n                messagebox.showinfo(\"Success\", f\"Data exported to {filename}\")\n            except Exception as e:\n                messagebox.showerror(\"Error\", f\"Export failed: {e}\")\n\n    def show_system_info(self):\n        vm = psutil.virtual_memory()\n        info = f\"\"\"\nSystem Information:\n\nCPU Usage: {psutil.cpu_percent(interval=1)}%\nCPU Cores: {psutil.cpu_count()}\nMemory Total: {vm.total / 1024 / 1024 / 1024:.2f} GB\nMemory Available: {vm.available / 1024 / 1024 / 1024:.2f} GB\nMemory Used: {vm.percent}%\n\nDisk Usage: {psutil.disk_usage('/').percent}%\nPython Version: {sys.version.split()[0]}\n\"\"\"\n        messagebox.showinfo(\"System Information\", info)\n\n    def on_closing(self):\n        self.running = False\n        self.destroy()\n\nif __name__ == '__main__':\n    # Load .env variables\n    try:\n        from dotenv import load_dotenv\n        load_dotenv()\n    except ImportError:\n        print(\"Warning: dotenv is not installed. Script assumes environment variables are set.\")\n    app = FortunaAdvancedMonitor()\n    app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n    app.mainloop()",
    "frontend.log": "\n> frontend@0.1.0 dev\n> next dev\n\n \u26a0 Specified \"rewrites\" will not automatically work with \"output: export\". See more info here: https://nextjs.org/docs/messages/export-no-custom-routes\n \u26a0 Specified \"rewrites\" will not automatically work with \"output: export\". See more info here: https://nextjs.org/docs/messages/export-no-custom-routes\n  \u25b2 Next.js 14.2.33\n  - Local:        http://localhost:3000\n\n \u2713 Starting...\n \u26a0 Specified \"rewrites\" will not automatically work with \"output: export\". See more info here: https://nextjs.org/docs/messages/export-no-custom-routes\n> [PWA] PWA support is disabled\n> [PWA] PWA support is disabled\n \u26a0 Specified \"rewrites\" will not automatically work with \"output: export\". See more info here: https://nextjs.org/docs/messages/export-no-custom-routes\n \u2713 Ready in 7.5s\n \u25cb Compiling / ...\n \u2713 Compiled / in 7.4s (587 modules)\n GET / 200 in 8101ms\n \u2713 Compiled in 743ms (298 modules)\n \u2713 Compiled /_not-found in 344ms (567 modules)\n GET /health 404 in 452ms\n GET /health 404 in 21ms\n GET /health 404 in 21ms\n GET /health 404 in 33ms\n \u2713 Compiled in 375ms (581 modules)\n \u2713 Compiled in 268ms (581 modules)\n \u2713 Compiled in 329ms (581 modules)\n \u2713 Compiled in 2.5s (578 modules)\n \u2713 Compiled in 237ms (578 modules)\n \u2713 Compiled in 526ms (578 modules)\n",
    "launcher.ps1": "<#\n.SYNOPSIS\n    Launches the Fortuna Faucet System Tray application.\n#>\n\nWrite-Host \"\ud83d\ude80 Launching Fortuna Faucet in System Tray...\" -ForegroundColor Cyan\n\n$VenvPath = \".\\\\.venv\\\\Scripts\\\\pythonw.exe\"\n$TrayAppPath = \".\\\\fortuna_tray.py\"\n\nif (-not (Test-Path $VenvPath)) {\n    Write-Host \"\u274c ERROR: Virtual environment not found at $VenvPath\" -ForegroundColor Red\n    Write-Host \"Please run run_dev_environment.bat first.\"\n    Read-Host \"Press Enter to exit\"\n    exit 1\n}\n\nStart-Process -FilePath $VenvPath -ArgumentList $TrayAppPath -WindowStyle Hidden\n\nWrite-Host \"\u2705 Fortuna Faucet is now running in your system tray.\" -ForegroundColor Green\nWrite-Host \"Right-click the icon for options.\"\nStart-Sleep -Seconds 5\n",
    "manual_override_tool.py": "import argparse\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Manual Override Tool for Checkmate Data Warehouse.\")\n    parser.add_argument(\"--file\", required=True, help=\"Path to the CSV file for ingestion.\")\n    parser.add_argument(\"--user\", required=True, help=\"The user ID performing the override.\")\n    args = parser.parse_args()\n\n    print(f\"Executing manual override by '{args.user}' for file '{args.file}'...\")\n\n    # 1. Connect to PostgreSQL\n    # engine = create_engine('postgresql://user:password@host:port/database')\n\n    # 2. Read and validate the CSV data\n    # race_df = pd.read_csv(args.file)\n    # ... validation logic ...\n\n    # 3. Add the manual_override_by column\n    # race_df['manual_override_by'] = args.user\n\n    # 4. Insert data into the 'historical_races' table\n    # race_df.to_sql('historical_races', engine, if_exists='append', index=False)\n\n    print(\"Manual override completed successfully.\")\n\nif __name__ == \"__main__\":\n    main()",
    "pyproject.toml": "[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"paddock-parser-ng\"\nversion = \"0.1.0\"\ndescription = \"A toolkit to identify the best racecards for betting.\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\n\n[project.scripts]\npaddock_parser_ui = \"paddock_parser.entry_points:run_terminal_ui\"\npaddock_parser_dashboard = \"paddock_parser.entry_points:run_dashboard\"\npaddock_parser_predict = \"paddock_parser.entry_points:run_prediction_engine\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n\n# Configuration for the Ruff linter\n[tool.ruff]\n# Allow lines to be up to 120 characters long.\nline-length = 120\n\n[tool.ruff.lint]\n# Enable Pyflakes (F), pycodestyle (E, W), and isort (I) rules.\nselect = [\"E\", \"F\", \"W\", \"I\"]\nignore = []\n\n[tool.ruff.lint.isort]\n# Sort imports within their sections alphabetically.\nforce-single-line = true\n",
    "pytest.ini": "[pytest]\npythonpath = python_service\nnorecursedirs = attic tests/checkmate_v7\ntestpaths = tests/adapters tests/api tests/database tests/ui tests/utils tests/test_backtester.py tests/test_fetcher.py tests/test_forager_client.py tests/test_log_analyzer.py tests/test_merger.py tests/test_pipeline.py tests/test_python_service.py tests/test_scorer.py tests/test_api.py tests/test_legacy_scenarios.py\n",
    "requirements-dev.txt": "aiosqlite==0.21.0\naltair==5.5.0\naltgraph==0.17.4\nannotated-types==0.7.0\nanyio==3.7.1\nattrs==25.4.0\nbeautifulsoup4==4.14.2\nblack==23.11.0\nblinker==1.9.0\ncachetools==6.2.1\ncertifi==2024.6.2\ncffi==2.0.0\ncharset-normalizer==3.4.4\nclick==8.3.0\ncontourpy==1.3.3\ncryptography==46.0.3\ncycler==0.12.1\nDeprecated==1.2.18\ndistro==1.9.0\nfastapi==0.104.1\nfonttools==4.60.1\ngitdb==4.0.12\nGitPython==3.1.45\ngreenlet==3.2.4\nh11==0.16.0\nh2==4.3.0\nhpack==4.1.0\nhttpcore==1.0.9\nhttptools==0.7.1\nhttpx==0.25.1\nhyperframe==6.1.0\nidna==3.11\niniconfig==2.3.0\njaraco.classes==3.4.0\njaraco.context==6.0.1\njaraco.functools==4.3.0\njeepney==0.9.0\nJinja2==3.1.6\njsonschema==4.25.1\njsonschema-specifications==2025.9.1\nkeyring==25.6.0\nkiwisolver==1.4.9\nlimits==5.6.0\nlxml==6.0.2\nmarkdown-it-py==4.0.0\nMarkupSafe==3.0.3\nmatplotlib==3.8.2\nmdurl==0.1.2\nmore-itertools==10.8.0\nmypy_extensions==1.1.0\nnarwhals==2.9.0\nnumpy==1.26.4\npackaging==25.0\npandas==2.3.3\npathspec==0.12.1\npikepdf==9.11.0\npillow==11.3.0\nplatformdirs==4.5.0\nplaywright==1.55.0\npluggy==1.6.0\nprotobuf==6.33.0\npsutil==7.1.1\npsycopg2-binary==2.9.11\npyarrow==21.0.0\npycparser==2.23\npydantic==2.5.0\npydantic-settings==2.1.0\npydantic_core==2.14.1\npydeck==0.9.1\npyee==13.0.0\nPygments==2.19.2\npyinstaller==6.16.0\npyinstaller-hooks-contrib==2025.9\npyparsing==3.2.5\npytest==7.4.3\npytest-asyncio==0.21.1\npython-dateutil==2.9.0.post0\npython-dotenv==1.0.0\npytz==2025.2\nPyYAML==6.0.3\nredis==5.0.1\nreferencing==0.37.0\nrequests==2.32.5\nrespx==0.22.0\nrich==14.2.0\nrpds-py==0.28.0\nSecretStorage==3.4.0\nselectolax==0.4.0\nsetuptools==80.9.0\nsix==1.17.0\nslowapi==0.1.9\nsmmap==5.0.2\nsniffio==1.3.1\nsoupsieve==2.8\nSQLAlchemy==2.0.44\nstarlette==0.27.0\nstreamlit==1.50.0\nstructlog==23.2.0\ntabula-py==2.10.0\ntenacity==8.2.3\ntoml==0.10.2\ntornado==6.5.2\ntyping_extensions==4.15.0\ntzdata==2025.2\nurllib3==2.5.0\nuvicorn==0.24.0\nuvloop==0.22.1\nwatchdog==6.0.0\nwatchfiles==1.1.1\nwebsockets==15.0.1\nwrapt==1.17.3\n",
    "requirements.txt": "# Fortuna Faucet - Master Dependency List\n\n# --- Core Backend (FastAPI & Async) ---\naiosqlite==0.21.0\nkeyring==25.6.0\ntenacity==9.1.2\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.2\npydantic-settings==2.1.0\nhttpx[http2]==0.27.0\nslowapi==0.1.9\nstructlog==24.1.0\npython-dotenv==1.0.0\n\n# --- Data Processing & Utilities ---\npandas==2.1.3\nbeautifulsoup4==4.12.2\nselectolax==0.4.0\npsutil==7.1.1\nlxml==5.1.0\n\n# --- Caching Layer ---\nredis==5.0.1\n\n# --- Windows Native Edition ---\npywin32==306; sys_platform == 'win32'\ncolorama==0.4.6; sys_platform == 'win32'\nwindows-toasts; sys_platform == 'win32'\nmatplotlib==3.8.2; sys_platform == 'win32'\npystray==0.19.5; sys_platform == 'win32'\npillow==10.1.0; sys_platform == 'win32'\n\n# --- Data Warehouse & ETL (Optional) ---\nSQLAlchemy==2.0.23\npsycopg2-binary==2.9.9\n\n# --- Historical Data Parsing (ChartScraper) ---\npikepdf==8.13.0\ntabula-py==2.7.0\nrequests==2.31.0\n\n# --- Code Quality & Testing ---\nruff==0.1.6\npytest==8.3.2\nrespx==0.22.0\npytest-asyncio==1.2.0\npyinstaller==6.1.0\n",
    "run_dev_environment.bat": "@echo off\nsetlocal enabledelayedexpansion\n\n:: ============================================================================\n:: Fortuna Faucet - Unified Development Environment Runner\n:: ============================================================================\n:: This script automates the setup and launch of the full development\n:: environment (Python backend + Next.js frontend).\n::\n:: It will:\n:: 1. Check for required dependencies (Python 3.11+, Node.js).\n:: 2. Create and populate the Python virtual environment if missing.\n:: 3. Install frontend Node modules if missing.\n:: 4. Launch both backend and frontend servers concurrently.\n:: ============================================================================\n\ntitle Fortuna Faucet Dev Runner\n\n:: --- Phase 1: Pre-flight Checks ---\necho [1/4] Running pre-flight checks...\n\n:: Check for Python\npython --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo [ERROR] Python is not found in your PATH. Please install Python 3.11 or later.\n    pause\n    exit /b 1\n)\n\n:: Check for Node.js\nnpm --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo [ERROR] Node.js (npm) is not found in your PATH. Please install Node.js (LTS).\n    pause\n    exit /b 1\n)\necho [OK] All prerequisites found.\necho.\n\n:: --- Phase 2: Environment Setup ---\necho [2/4] Verifying development environment...\n\n:: Check for Python virtual environment\nif not exist \".venv\" (\n    echo [INFO] Python virtual environment not found. Creating it now...\n    python -m venv .venv\n    if %errorlevel% neq 0 (\n        echo [ERROR] Failed to create Python virtual environment.\n        pause\n        exit /b 1\n    )\n    echo [INFO] Virtual environment created.\n)\n\n:: Check for Python dependencies\necho [INFO] Installing/verifying Python dependencies...\ncall .\\.venv\\Scripts\\activate.bat\npip install -r requirements.txt\nif %errorlevel% neq 0 (\n    echo [ERROR] Failed to install Python dependencies from requirements.txt.\n    pause\n    exit /b 1\n)\ncall .\\.venv\\Scripts\\deactivate.bat\necho [OK] Python environment is ready.\necho.\n\n:: Check for frontend dependencies\nif not exist \"web_platform\\frontend\\node_modules\" (\n    echo [INFO] Frontend dependencies (node_modules) not found. Installing now...\n    npm install --prefix web_platform/frontend\n    if %errorlevel% neq 0 (\n        echo [ERROR] Failed to install frontend dependencies.\n        pause\n        exit /b 1\n    )\n)\necho [OK] Frontend environment is ready.\necho.\n\n\n:: --- Phase 3: Launch Services ---\necho [3/4] Launching services...\necho [INFO] Starting Python backend server in a new window...\nstart \"Fortuna Backend\" cmd /c \"call .\\.venv\\Scripts\\activate.bat && python -m uvicorn python_service.api:app --host 127.0.0.1 --port 8000\"\n\necho [INFO] Starting Next.js frontend server in a new window...\nstart \"Fortuna Frontend\" cmd /c \"npm run dev --prefix web_platform/frontend\"\n\necho.\n\n:: --- Phase 4: Open Browser ---\necho [4/4] Opening application in browser...\necho [INFO] Waiting 10 seconds for servers to initialize...\ntimeout /t 10 /nobreak >nul\nstart http://localhost:3000\n\necho.\necho ============================================================================\necho  All services launched! You can close this window.\necho ============================================================================\necho.\n\npause\nexit /b 0\n",
    "scripts/audit_rebranding.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Rebranding Audit Script\n# ==============================================================================\n# This script performs a comprehensive, read-only audit of the project to\n# identify all files containing legacy branding terms.\n# ==============================================================================\n\nimport os\n\n# --- CONFIGURATION ---\nTARGET_TERMS = ['checkmate', 'solo']\nEXCLUDED_DIRS = ['.git', '.venv', 'node_modules', 'build', 'dist', '__pycache__', 'ReviewableJSON']\nEXCLUDED_FILES = ['audit_rebranding.py', 'REBRANDING_AUDIT.md']\nOUTPUT_FILE = 'REBRANDING_AUDIT.md'\n# -------------------\n\ndef search_file_for_terms(file_path, terms):\n    \"\"\"Searches a single file for a list of terms, case-insensitively.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read().lower()\n            for term in terms:\n                if term in content:\n                    return True\n    except Exception as e:\n        print(f\"[WARNING] Could not read file {file_path}: {e}\")\n    return False\n\ndef main():\n    \"\"\"Main orchestrator for the audit.\"\"\"\n    print(\"--- Starting Rebranding Audit ---\")\n    affected_files = []\n    for root, dirs, files in os.walk('.', topdown=True):\n        # Exclude specified directories\n        dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS]\n\n        for filename in files:\n            if filename in EXCLUDED_FILES:\n                continue\n\n            file_path = os.path.join(root, filename)\n\n            # Check filename itself\n            if any(term in filename.lower() for term in TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in filename: {file_path}\")\n                continue # No need to search content if filename matches\n\n            # Check file content\n            if search_file_for_terms(file_path, TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in content: {file_path}\")\n\n    print(f\"\\n--- Audit Complete. Found {len(affected_files)} affected files. ---\")\n\n    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n        f.write('# Fortuna Faucet: Rebranding Audit Report\\n\\n')\n        f.write('This report lists all files containing legacy branding terms (`checkmate`, `solo`).\\n\\n---\\n\\n')\n        if affected_files:\n            for file_path in sorted(affected_files):\n                f.write(f\"- `{file_path.replace(os.sep, '/')}`\\n\")\n        else:\n            f.write('No files with legacy branding were found.\\n')\n\n    print(f\"[SUCCESS] Report written to {OUTPUT_FILE}\")\n\nif __name__ == \"__main__\":\n    main()",
    "scripts/build_msi.ps1": "# Comprehensive MSI build pipeline for Fortuna Faucet\n# Version 3.0 - Three-Executable Architecture\n\nparam(\n    [ValidateSet(\"Debug\", \"Release\")]\n    [string]$Configuration = \"Release\",\n    [string]$Version = \"0.0.0\", # This will be overridden by VERSION.txt in the script\n    [string]$OutputPath = \".\\dist\"\n)\n\n$ErrorActionPreference = \"Stop\"\n\n# --- ASCII-Safe Helper Functions ---\nfunction Write-Header {\n    $title = $args[0]\n    Write-Host (\"=\" * 70) -ForegroundColor Cyan\n    Write-Host $title -ForegroundColor Cyan\n    Write-Host (\"=\" * 70) -ForegroundColor Cyan\n}\nfunction Write-Success { Write-Host \"[SUCCESS] $($args[0])\" -ForegroundColor Green }\nfunction Write-Error { Write-Host \"[ERROR] $($args[0])\" -ForegroundColor Red }\nfunction Write-Info { Write-Host \"[INFO] $($args[0])\" -ForegroundColor Yellow }\n\n# ==================== PHASE 0: DYNAMIC CONFIGURATION ====================\nWrite-Header \"Phase 0: Loading Dynamic Configuration\"\n$AppVersion = (Get-Content -Path \".\\VERSION.txt\" -Raw).Trim()\nWrite-Success \"Application version loaded from VERSION.txt: $AppVersion\"\n\n# ==================== PHASE 1: PREREQUISITES ====================\nWrite-Header \"Phase 1: Checking Prerequisites\"\n@(\"python\", \"npm\", \"heat.exe\", \"candle.exe\", \"light.exe\") | ForEach-Object {\n    if (-not (Get-Command $_ -ErrorAction SilentlyContinue)) {\n        Write-Error \"$_ not found in PATH. Please ensure it is installed and accessible.\"\n        exit 1\n    }\n    Write-Success \"$_ found in PATH.\"\n}\n\n# ==================== PHASE 2: BUILD BACKEND EXECUTABLE ====================\nWrite-Header \"Phase 2: Building Standalone Backend\"\nWrite-Info \"Installing Python dependencies and running PyInstaller...\"\n# Activate venv if it exists, otherwise assume packages are globally available\nif (Test-Path \".\\.venv\\Scripts\\Activate.ps1\") {\n    & \".\\.venv\\Scripts\\Activate.ps1\"\n}\npython -m pip install -r requirements.txt\npyinstaller --onefile --name fortuna-api --add-data \"python_service:python_service\" python_service/api.py\nWrite-Success \"Backend executable created at .\\dist\\fortuna-api\"\n\n\n# ==================== PHASE 3: BUILD STATIC FRONTEND ====================\nWrite-Header \"Phase 3: Building Static Frontend\"\nWrite-Info \"Installing Node.js dependencies and running Next.js build...\"\nPush-Location \".\\web_platform\\frontend\"\nnpm install\nnpm run build\nPop-Location\nWrite-Success \"Static frontend created at .\\web_platform\\frontend\\out\"\n\n# ==================== PHASE 4: PREPARE & HARVEST FILES ====================\nWrite-Header \"Phase 4: Preparing & Harvesting Files for WiX\"\n$buildDir = \".\\wix_build\"\nif (Test-Path $buildDir) { Remove-Item $buildDir -Recurse -Force }\nNew-Item -ItemType Directory -Path $buildDir -Force | Out-Null\n\nWrite-Info \"Harvesting backend executable...\"\n& heat.exe file \".\\dist\\fortuna-api\" -o \"$buildDir\\backend_files.wxs\" `\n    -gg -sf -srd -cg BackendFileGroup -dr INSTALLFOLDER -var \"var.BackendSourceDir\"\n\nWrite-Info \"Harvesting frontend static files...\"\n& heat.exe dir \".\\web_platform\\frontend\\out\" -o \"$buildDir\\frontend_files.wxs\" `\n    -gg -sf -srd -cg FrontendFileGroup -dr INSTALLFOLDER -var \"var.FrontendSourceDir\"\n\nWrite-Success \"File harvesting complete.\"\n\n# ==================== PHASE 5: COMPILATION ====================\nWrite-Header \"Phase 5: Compiling WiX Sources\"\n$objDir = \"$buildDir\\obj\"\nNew-Item -ItemType Directory -Path $objDir -Force | Out-Null\nCopy-Item \".\\wix\\*.wxs\" \"$buildDir\"\n\n@(\"$buildDir\\product.wxs\", \"$buildDir\\backend_files.wxs\", \"$buildDir\\frontend_files.wxs\") | ForEach-Object {\n    Write-Info \"Compiling $(Split-Path $_ -Leaf)...\"\n    & candle.exe $_ -o \"$objDir\\\" `\n        -ext WixUtilExtension `\n        -d\"BackendSourceDir=.\\dist\" `\n        -d\"FrontendSourceDir=.\\web_platform\\frontend\\out\" `\n        -dVersion=\"$AppVersion\" `\n        -arch x64\n    if ($LASTEXITCODE -ne 0) { throw \"Compilation failed for $_\" }\n}\nWrite-Success \"Compilation complete.\"\n\n# ==================== PHASE 6: LINKING ====================\nWrite-Header \"Phase 6: Linking MSI Package\"\nNew-Item -ItemType Directory -Path $OutputPath -Force | Out-Null\n$msiPath = \"$OutputPath\\Fortuna-Faucet-$AppVersion-x64.msi\"\n\nWrite-Info \"Linking objects into MSI...\"\n& light.exe -out $msiPath (Get-ChildItem \"$objDir\\*.wixobj\") `\n    -sw1076 `\n    -ext WixUIExtension -ext WixUtilExtension `\n    -cultures:en-us -b $buildDir\n\nif ($LASTEXITCODE -ne 0) { throw \"MSI linking failed\" }\n\n$fileSize = (Get-Item $msiPath).Length / 1MB\nWrite-Success \"MSI created: $msiPath ($($fileSize.ToString('F2')) MB)\"\n\n# ==================== PHASE 7: METADATA ====================\nWrite-Header \"Phase 7: Generating Installation Metadata\"\n$metadata = @{\n    Version = $AppVersion\n    BuildDate = (Get-Date -Format \"yyyy-MM-dd HH:mm:ss\")\n    Configuration = $Configuration\n    FileSize_MB = [math]::Round($fileSize, 2)\n    SHA256 = (Get-FileHash $msiPath -Algorithm SHA256).Hash\n} | ConvertTo-Json -Depth 5\n\n$metadata | Out-File \"$OutputPath\\metadata.json\" -Encoding UTF8\nWrite-Success \"Metadata saved.\"\n\nWrite-Host \"\"\nWrite-Header \"Build Complete\"\nWrite-Success \"Ready for distribution!\"\nWrite-Info \"MSI: $msiPath\"\nWrite-Info \"Metadata: $OutputPath\\metadata.json\"\n",
    "scripts/convert_to_json.py": "# convert_to_json.py\n# This script now contains the full, enlightened logic to handle all manifest formats and path styles.\n\nimport json\nimport os\nimport re\nimport sys\nfrom multiprocessing import Process, Queue\n\n# --- Configuration ---\nMANIFEST_FILES = ['MANIFEST2.md', 'MANIFEST3.md']\nOUTPUT_DIR = 'ReviewableJSON'\nFILE_PROCESSING_TIMEOUT = 10\nEXCLUDED_FILES = ['package-lock.json']\n\n# --- ENLIGHTENED PARSING LOGIC (V2) ---\ndef extract_and_normalize_path(line: str) -> str | None:\n    \"\"\"\n    Extracts a file path from a line, handling multiple formats, and normalizes it.\n    Handles:\n    - Markdown links: `* [display](path)`\n    - Plain paths in backticks: ``- `path.py` - description``\n    - Plain paths with list markers: `- path/to/file.py`\n    \"\"\"\n    line = line.strip()\n    if not line or line.startswith('#'):\n        return None\n\n    # 1. Check for Markdown link format\n    md_match = re.search(r'\\[.*\\]\\((https?://[^\\)]+)\\)', line)\n    if md_match:\n        path = md_match.group(1)\n    else:\n        # 2. Check for paths in backticks\n        bt_match = re.search(r'`([^`]+)`', line)\n        if bt_match:\n            path = bt_match.group(1)\n        else:\n            # 3. Assume plain path, stripping list markers\n            path = re.sub(r'^[*-]\\s*', '', line).split(' ')[0]\n\n    # --- Path Standardization ---\n    if not path or not ('.' in path or '/' in path):\n        return None # Not a valid path\n\n    # If it's a full raw GitHub URL, extract the local path\n    if path.startswith('https://raw.githubusercontent.com/'):\n        path = '/'.join(path.split('/main/')[1:])\n\n    # Final check for valid file extensions or structure\n    if not re.search(r'(\\.[a-zA-Z0-9]+$)|(^[\\w/]+$)', path):\n        return None\n\n    return path.strip()\n\n# --- SANDBOXED FILE READ (Unchanged) ---\ndef _sandboxed_file_read(file_path, q):\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n        q.put({\"file_path\": file_path, \"content\": content})\n    except Exception as e:\n        q.put({\"error\": str(e)})\n\ndef convert_file_to_json_sandboxed(file_path):\n    q = Queue()\n    p = Process(target=_sandboxed_file_read, args=(file_path, q))\n    p.start()\n    p.join(timeout=FILE_PROCESSING_TIMEOUT)\n    if p.is_alive():\n        p.terminate()\n        p.join()\n        return {\"error\": f\"Timeout: File processing took longer than {FILE_PROCESSING_TIMEOUT} seconds.\"}\n    if not q.empty():\n        return q.get()\n    return {\"error\": \"Unknown error in sandboxed read process.\"}\n\n# --- Main Orchestrator ---\ndef main():\n    print(f\"\\n{'='*60}\\nStarting IRONCLAD JSON backup process... (Enlightened Scribe Edition)\\n{'='*60}\")\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    all_local_paths = []\n    for manifest in MANIFEST_FILES:\n        print(f\"--> Parsing manifest: {manifest}\")\n        if not os.path.exists(manifest):\n            print(f\"    [WARNING] Manifest not found: {manifest}\")\n            continue\n\n        with open(manifest, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n\n        paths_found = 0\n        for line in lines:\n            path = extract_and_normalize_path(line)\n            if path:\n                all_local_paths.append(path)\n                paths_found += 1\n        print(f\"    --> Found {paths_found} valid file paths.\")\n\n    if not all_local_paths:\n        print(\"\\n[FATAL] No valid file paths found in any manifest. Aborting.\")\n        sys.exit(1)\n\n    unique_local_paths = sorted(list(set(all_local_paths)))\n    print(f\"\\nFound a total of {len(unique_local_paths)} unique files to process.\")\n    processed_count, failed_count = 0, 0\n\n    for local_path in unique_local_paths:\n        print(f\"\\nProcessing: {local_path}\")\n        json_data = convert_file_to_json_sandboxed(local_path)\n        if json_data and \"error\" not in json_data:\n            output_path = os.path.join(OUTPUT_DIR, local_path + '.json')\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n            with open(output_path, 'w', encoding='utf-8') as f:\n                json.dump(json_data, f, indent=4)\n            print(f\"    [SUCCESS] Saved backup to {output_path}\")\n            processed_count += 1\n        else:\n            error_msg = json_data.get(\"error\", \"Unknown error\") if json_data else \"File not found\"\n            print(f\"    [ERROR] Failed to process {local_path}: {error_msg}\")\n            failed_count += 1\n\n    print(f\"\\n{'='*60}\\nBackup process complete.\\nSuccessfully processed: {processed_count}/{len(unique_local_paths)}\\nFailed/Skipped: {failed_count}\\n{'='*60}\")\n\n    if failed_count > 0:\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()",
    "scripts/fortuna-quick-start.ps1": "# ====================================================================\n# Fortuna Faucet - Quick Start Script (No Installation Required)\n# ====================================================================\n# This script runs Fortuna directly from source without any MSI\n# Useful for development and testing before packaging\n# ====================================================================\n\nparam(\n    [switch]$SkipChecks,\n    [switch]$NoFrontend\n)\n\n$ErrorActionPreference = 'Stop'\n$OriginalLocation = Get-Location\n\n# ============= CONFIGURATION =============\n$PROJECT_ROOT = Split-Path -Parent $MyInvocation.MyCommand.Path\n$VENV_PATH = Join-Path $PROJECT_ROOT \".venv\"\n$PYTHON_EXE = Join-Path $VENV_PATH \"Scripts\\python.exe\"\n$BACKEND_DIR = Join-Path $PROJECT_ROOT \"python_service\"\n$FRONTEND_DIR = Join-Path $PROJECT_ROOT \"web_platform\\frontend\"\n$BACKEND_PORT = 8000\n$FRONTEND_PORT = 3000\n\n# ============= HELPER FUNCTIONS =============\n\nfunction Write-Status {\n    param([string]$Message, [string]$Status = \"INFO\")\n    $Color = switch ($Status) {\n        \"OK\"      { \"Green\" }\n        \"ERROR\"   { \"Red\" }\n        \"WARNING\" { \"Yellow\" }\n        default   { \"Cyan\" }\n    }\n    Write-Host \"[$Status] $Message\" -ForegroundColor $Color\n}\n\nfunction Test-CommandExists {\n    param([string]$Command)\n    try {\n        Get-Command $Command -ErrorAction Stop | Out-Null\n        return $true\n    } catch {\n        return $false\n    }\n}\n\nfunction Test-PortAvailable {\n    param([int]$Port)\n    try {\n        $Listener = [System.Net.Sockets.TcpListener]::new([System.Net.IPAddress]::Any, $Port)\n        $Listener.Start()\n        $Listener.Stop()\n        return $true\n    } catch {\n        return $false\n    }\n}\n\nfunction Stop-ProcessOnPort {\n    param([int]$Port)\n    $Connection = Get-NetTCPConnection -LocalPort $Port -ErrorAction SilentlyContinue\n    if ($Connection) {\n        $ProcessId = $Connection.OwningProcess\n        Write-Status \"Killing process $ProcessId on port $Port\" \"WARNING\"\n        Stop-Process -Id $ProcessId -Force -ErrorAction SilentlyContinue\n        Start-Sleep -Seconds 2\n    }\n}\n\nfunction Wait-ForBackend {\n    param([int]$MaxAttempts = 30)\n\n    Write-Status \"Waiting for backend to start (http://127.0.0.1:$BACKEND_PORT/health)...\"\n\n    for ($i = 1; $i -le $MaxAttempts; $i++) {\n        try {\n            $Response = Invoke-WebRequest -Uri \"http://127.0.0.1:$BACKEND_PORT/health\" -UseBasicParsing -TimeoutSec 2\n            if ($Response.StatusCode -eq 200) {\n                Write-Status \"Backend is healthy!\" \"OK\"\n                return $true\n            }\n        } catch {\n            Write-Host \".\" -NoNewline\n            Start-Sleep -Seconds 1\n        }\n    }\n\n    Write-Status \"Backend failed to start after $MaxAttempts seconds\" \"ERROR\"\n    return $false\n}\n\n# ============= PREFLIGHT CHECKS =============\n\nWrite-Host \"`n========================================\" -ForegroundColor Cyan\nWrite-Host \" Fortuna Faucet - Quick Start\" -ForegroundColor Cyan\nWrite-Host \"========================================`n\" -ForegroundColor Cyan\n\nif (-not $SkipChecks) {\n    Write-Status \"Running preflight checks...\"\n\n    # Check Python\n    if (-not (Test-Path $PYTHON_EXE)) {\n        Write-Status \"Python virtual environment not found at $VENV_PATH\" \"ERROR\"\n        Write-Status \"Please run setup script first or create venv manually\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"Python venv found\" \"OK\"\n\n    # Check Node.js\n    if (-not (Test-CommandExists \"node\")) {\n        Write-Status \"Node.js not found in PATH\" \"ERROR\"\n        Write-Status \"Install from: https://nodejs.org/\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"Node.js found: $(node --version)\" \"OK\"\n\n    # Check npm\n    if (-not (Test-CommandExists \"npm\")) {\n        Write-Status \"npm not found\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"npm found: $(npm --version)\" \"OK\"\n\n    # Check if ports are available\n    if (-not (Test-PortAvailable $BACKEND_PORT)) {\n        Write-Status \"Port $BACKEND_PORT is already in use\" \"WARNING\"\n        Stop-ProcessOnPort $BACKEND_PORT\n    }\n\n    if (-not $NoFrontend -and -not (Test-PortAvailable $FRONTEND_PORT)) {\n        Write-Status \"Port $FRONTEND_PORT is already in use\" \"WARNING\"\n        Stop-ProcessOnPort $FRONTEND_PORT\n    }\n\n    # Check Python dependencies\n    Write-Status \"Checking Python dependencies...\"\n    $PipList = & $PYTHON_EXE -m pip list\n    if ($PipList -notmatch \"fastapi\") {\n        Write-Status \"Python dependencies not installed\" \"WARNING\"\n        Write-Status \"Installing dependencies...\"\n        & $PYTHON_EXE -m pip install -r (Join-Path $BACKEND_DIR \"requirements.txt\")\n    } else {\n        Write-Status \"Python dependencies OK\" \"OK\"\n    }\n\n    # Check Node dependencies\n    if (-not $NoFrontend) {\n        Write-Status \"Checking Node.js dependencies...\"\n        $NodeModules = Join-Path $FRONTEND_DIR \"node_modules\"\n        if (-not (Test-Path $NodeModules)) {\n            Write-Status \"Node.js dependencies not installed\" \"WARNING\"\n            Write-Status \"Installing dependencies...\"\n            Push-Location $FRONTEND_DIR\n            npm install\n            Pop-Location\n        } else {\n            Write-Status \"Node.js dependencies OK\" \"OK\"\n        }\n    }\n\n    Write-Host \"\"\n}\n\n# ============= LAUNCH BACKEND =============\n\nWrite-Status \"Starting backend server...\"\n\n$BackendJob = Start-Job -ScriptBlock {\n    param($PythonExe, $BackendDir)\n    Set-Location $BackendDir\n    & $PythonExe -m uvicorn api:app --host 127.0.0.1 --port 8000 --reload\n} -ArgumentList $PYTHON_EXE, $BACKEND_DIR\n\nWrite-Status \"Backend job started (ID: $($BackendJob.Id))\"\n\n# Wait for backend to be healthy\nif (-not (Wait-ForBackend)) {\n    Write-Status \"Backend startup failed. Checking logs...\" \"ERROR\"\n    Receive-Job $BackendJob\n    Stop-Job $BackendJob\n    Remove-Job $BackendJob\n    exit 1\n}\n\n# ============= LAUNCH FRONTEND =============\n\nif (-not $NoFrontend) {\n    Write-Status \"Starting frontend dev server...\"\n\n    $FrontendJob = Start-Job -ScriptBlock {\n        param($FrontendDir)\n        Set-Location $FrontendDir\n        npm run dev\n    } -ArgumentList $FRONTEND_DIR\n\n    Write-Status \"Frontend job started (ID: $($FrontendJob.Id))\"\n\n    # Wait a bit for frontend to start\n    Start-Sleep -Seconds 5\n\n    Write-Status \"Opening browser...\" \"OK\"\n    Start-Process \"http://localhost:$FRONTEND_PORT\"\n}\n\n# ============= MONITORING =============\n\nWrite-Host \"`n========================================\" -ForegroundColor Green\nWrite-Host \" Fortuna is now running!\" -ForegroundColor Green\nWrite-Host \"========================================\" -ForegroundColor Green\nWrite-Host \"\"\nWrite-Status \"Backend:  http://127.0.0.1:$BACKEND_PORT\" \"OK\"\nif (-not $NoFrontend) {\n    Write-Status \"Frontend: http://127.0.0.1:$FRONTEND_PORT\" \"OK\"\n}\nWrite-Host \"\"\nWrite-Host \"Press Ctrl+C to stop all services\" -ForegroundColor Yellow\nWrite-Host \"\"\n\ntry {\n    while ($true) {\n        Start-Sleep -Seconds 2\n\n        # Check if jobs are still running\n        if ($BackendJob.State -eq \"Failed\" -or $BackendJob.State -eq \"Stopped\") {\n            Write-Status \"Backend has stopped unexpectedly!\" \"ERROR\"\n            Receive-Job $BackendJob\n            break\n        }\n\n        if (-not $NoFrontend -and ($FrontendJob.State -eq \"Failed\" -or $FrontendJob.State -eq \"Stopped\")) {\n            Write-Status \"Frontend has stopped unexpectedly!\" \"ERROR\"\n            Receive-Job $FrontendJob\n            break\n        }\n    }\n} finally {\n    # ============= CLEANUP =============\n    Write-Host \"`n`nShutting down...\" -ForegroundColor Yellow\n\n    if ($BackendJob) {\n        Write-Status \"Stopping backend...\"\n        Stop-Job $BackendJob -ErrorAction SilentlyContinue\n        Remove-Job $BackendJob -Force -ErrorAction SilentlyContinue\n    }\n\n    if ($FrontendJob) {\n        Write-Status \"Stopping frontend...\"\n        Stop-Job $FrontendJob -ErrorAction SilentlyContinue\n        Remove-Job $FrontendJob -Force -ErrorAction SilentlyContinue\n    }\n\n    # Kill any remaining processes on the ports\n    Stop-ProcessOnPort $BACKEND_PORT\n    if (-not $NoFrontend) {\n        Stop-ProcessOnPort $FRONTEND_PORT\n    }\n\n    Set-Location $OriginalLocation\n    Write-Status \"Cleanup complete\" \"OK\"\n}\n\n# ============= USAGE EXAMPLES =============\n<#\n.SYNOPSIS\nQuick start script for Fortuna Faucet (no installation required)\n\n.DESCRIPTION\nLaunches the backend and frontend servers directly from source code\nUseful for development and testing before creating an MSI installer\n\n.PARAMETER SkipChecks\nSkip all preflight dependency checks (faster startup)\n\n.PARAMETER NoFrontend\nOnly start the backend API server (no UI)\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1\nStarts both backend and frontend with full checks\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1 -NoFrontend\nStarts only the backend API (useful for API testing)\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1 -SkipChecks\nFast startup (assumes all dependencies are already installed)\n#>",
    "scripts/get_api_key.py": "# scripts/get_api_key.py\nimport sys\nimport os\n\n# This is a workaround to ensure the script can find the python_service module,\n# especially when run from the packaged Electron app.\n# It assumes this script is in `resources/app/scripts` and the service is in `resources/app/python_service`.\ntry:\n    # Get the directory of the current script.\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    # Go up one level to the `app` directory and add `python_service` to the path.\n    project_root = os.path.dirname(script_dir)\n    sys.path.append(project_root)\n    from python_service.credentials_manager import SecureCredentialsManager\nexcept ImportError as e:\n    # If the import fails, write the error to stderr and exit.\n    # This helps in debugging path issues in the production environment.\n    print(f\"Error: Failed to import SecureCredentialsManager. Details: {e}\", file=sys.stderr)\n    sys.exit(1)\n\ndef retrieve_and_print_key():\n    \"\"\"\n    Retrieves the API key using the SecureCredentialsManager and prints it to stdout.\n    If the key is not found, it prints an empty string.\n    If an error occurs, it prints the error to stderr.\n    \"\"\"\n    try:\n        api_key = SecureCredentialsManager.get_api_key()\n        if api_key:\n            print(api_key, end='') # Print the key directly to stdout\n        else:\n            print(\"\", end='') # Print empty string if no key is found\n    except Exception as e:\n        print(f\"An error occurred while retrieving the API key: {e}\", file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    retrieve_and_print_key()\n",
    "scripts/install_fortuna_gui.bat": "@echo off\nREM Interactive MSI installation with standard Windows UI\n\ntitle Fortuna Faucet Installation Wizard\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Administrator privileges required\n    echo Please right-click this file and select \"Run as Administrator\"\n    pause\n    exit /b 1\n)\n\nREM Assumes the MSI is in the 'dist' subfolder relative to the project root\nmsiexec.exe /i \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" /L*v \"%TEMP%\\fortuna_install.log\"\n\nif %errorlevel% equ 0 (\n    echo Installation completed successfully!\n    echo Access dashboard at: http://localhost:3000\n) else (\n    echo Installation failed. Log: %TEMP%\\fortuna_install.log\n)\npause",
    "scripts/install_fortuna_silent.bat": "@echo off\nREM Automated deployment (no UI, minimal interaction)\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\nREM Assumes the MSI is in the 'dist' subfolder relative to the project root\nmsiexec.exe /i \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" ^\n    /qn ^\n    /l*v \"%TEMP%\\fortuna_silent_install.log\" ^\n    /norestart ^\n    ALLUSERS=1 ^\n    INSTALLSCOPE=perMachine\n\nexit /b %errorlevel%",
    "scripts/modify_wix_project.ps1": "# scripts/modify_wix_project.ps1\n# This script is called by the `msiProjectCreated` hook in electron-builder.\n# It receives the path to the auto-generated project.wxs file and modifies it in place\n# to add our custom post-install validation logic.\n\nparam (\n    [string]$WxsPath\n)\n\n$ErrorActionPreference = \"Stop\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $LogMessage = \"$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') - $Message\"\n    Add-Content -Path (Join-Path $env:TEMP \"fortuna-wix-hook.log\") -Value $LogMessage\n}\n\nWrite-Log \"--- Starting WiX Project Modification ---\"\nWrite-Log \"Received WXS Path: $WxsPath\"\n\nif (-not (Test-Path $WxsPath)) {\n    Write-Log \"[FATAL] WXS file not found at path: $WxsPath\"\n    exit 1\n}\n\n# Read the XML content of the .wxs file\n[xml]$WxsContent = Get-Content -Path $WxsPath\n\n# Define the XML nodes for our custom action\n$CustomActionXml = @'\n    <!-- 1. Find PowerShell.exe -->\n    <Property Id=\"POWERSHELL\">\n      <RegistrySearch Id=\"PowerShellPath\" Root=\"HKLM\" Key=\"SOFTWARE\\Microsoft\\PowerShell\\1\\ShellIds\\Microsoft.PowerShell\" Name=\"Path\" Type=\"raw\" />\n    </Property>\n    <Condition Message=\"PowerShell is required to complete this installation.\"><![CDATA[Installed OR POWERSHELL]]></Condition>\n\n    <!-- 2. Add the validation script to the installer's binary table -->\n    <Binary Id=\"ValidateInstallScript\" SourceFile=\"resources\\app\\scripts\\validate_installation.ps1\" />\n\n    <!-- 3. Define the Custom Action to run the script -->\n    <CustomAction Id=\"ValidateInstallation\"\n                  Directory=\"INSTALLDIR\"\n                  ExeCommand=\"[POWERSHELL] -NoProfile -ExecutionPolicy Bypass -File &quot;[#ValidateInstallScript]&quot; -InstallPath &quot;[INSTALLDIR]&quot;\"\n                  Execute=\"deferred\"\n                  Return=\"check\"\n                  Impersonate=\"no\" />\n\n    <!-- 4. Schedule the Custom Action -->\n    <InstallExecuteSequence>\n        <Custom Action=\"ValidateInstallation\" After=\"InstallFinalize\">NOT Installed</Custom>\n    </InstallExecuteSequence>\n'@\n\n# Create an XML fragment from our string\n$Fragment = [xml](\"<Fragment>$CustomActionXml</Fragment>\")\n\n# Find the <Product> node in the main WXS file\n$ProductNode = $WxsContent.Wix.Product\n\nif (-not $ProductNode) {\n    Write-Log \"[FATAL] Could not find <Product> node in the WXS file.\"\n    exit 1\n}\n\n# Import and append each child node from our fragment into the <Product> node\n$Fragment.Fragment.ChildNodes | ForEach-Object {\n    $ImportedNode = $WxsContent.ImportNode($_, $true)\n    $ProductNode.AppendChild($ImportedNode)\n    Write-Log \"Appended node: $($ImportedNode.LocalName)\"\n}\n\n# Save the modified XML back to the file\n$WxsContent.Save($WxsPath)\n\nWrite-Log \"--- WiX Project Modification Successful ---\"\nexit 0\n",
    "scripts/prepare_minimal_build.py": "# scripts/prepare_minimal_build.py\nimport os\nimport shutil\n\n# This script prepares the source tree for a 'minimal' build.\n# A minimal build includes only the core application and a small, curated\n# set of essential data adapters, excluding the larger, more specialized ones.\n\nADAPTERS_TO_KEEP = [\n    \"__init__.py\",\n    \"base_adapter.py\",\n    \"handler_factory.py\",\n    # --- Essential Adapters ---\n    \"betfair_adapter.py\",\n    \"sporting_life_adapter.py\",\n    \"racing_post_adapter.py\",\n]\n\ndef main():\n    \"\"\"\n    Removes non-essential adapter files from the python_service/adapters\n    directory to create a minimal build artifact.\n    \"\"\"\n    adapters_dir = os.path.join(\"python_service\", \"adapters\")\n    if not os.path.isdir(adapters_dir):\n        print(f\"[ERROR] Adapters directory not found at: {adapters_dir}\")\n        exit(1)\n\n    print(f\"Scanning adapters directory: {adapters_dir}\")\n    removed_count = 0\n    for filename in os.listdir(adapters_dir):\n        if filename not in ADAPTERS_TO_KEEP:\n            file_path = os.path.join(adapters_dir, filename)\n            try:\n                if os.path.isfile(file_path):\n                    os.remove(file_path)\n                    print(f\"  - Removed file: {filename}\")\n                    removed_count += 1\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n                    print(f\"  - Removed directory: {filename}\")\n                    removed_count += 1\n            except OSError as e:\n                print(f\"[ERROR] Failed to remove {file_path}: {e}\")\n                exit(1)\n\n    print(f\"\\nMinimal build preparation complete. Removed {removed_count} non-essential adapter(s).\")\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/prepare_portable_python.ps1": "# scripts/prepare_portable_python.ps1\n# This script creates a self-contained, portable Python environment for the Electron app.\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Helper Functions ---\nfunction Write-Header {\n    param([string]$title)\n    Write-Host (\"=\" * 60) -ForegroundColor Green\n    Write-Host $title -ForegroundColor Green\n    Write-Host (\"=\" * 60) -ForegroundColor Green\n}\nfunction Write-Info {\n    param([string]$message)\n    Write-Host \"[INFO] $message\" -ForegroundColor Yellow\n}\nfunction Write-Success {\n    param([string]$message)\n    Write-Host \"[SUCCESS] $message\" -ForegroundColor Cyan\n}\n\n# --- Configuration ---\nWrite-Header \"Step 1: Initializing Configuration\"\n$PythonEmbedUrl = \"https://www.python.org/ftp/python/3.11.7/python-3.11.7-embed-amd64.zip\"\n$TempDir = \".\\temp_build\"\n$PythonDir = \".\\electron\\python\"\n$PythonZipPath = Join-Path $TempDir \"python_embed.zip\"\n$PythonExePath = Join-Path $PythonDir \"python.exe\"\n$RequirementsPath = \".\\requirements.txt\"\nWrite-Success \"Configuration loaded.\"\n\n# --- Clean and Prepare Directories ---\nWrite-Header \"Step 2: Preparing Directories\"\nif (Test-Path $PythonDir) {\n    Write-Info \"Removing existing portable Python directory...\"\n    Remove-Item $PythonDir -Recurse -Force\n}\nif (Test-Path $TempDir) {\n    Remove-Item $TempDir -Recurse -Force\n}\nNew-Item -ItemType Directory -Path $TempDir -Force | Out-Null\nNew-Item -ItemType Directory -Path $PythonDir -Force | Out-Null\nWrite-Success \"Directories are clean and ready.\"\n\n# --- Download and Extract Python ---\nWrite-Header \"Step 3: Acquiring Embeddable Python\"\nWrite-Info \"Downloading Python from $PythonEmbedUrl...\"\nInvoke-WebRequest -Uri $PythonEmbedUrl -OutFile $PythonZipPath\nWrite-Info \"Extracting Python to $PythonDir...\"\nExpand-Archive -Path $PythonZipPath -DestinationPath $PythonDir -Force\nWrite-Success \"Portable Python environment created at $PythonDir\"\n\n# --- Install Dependencies ---\nWrite-Header \"Step 4: Installing Dependencies\"\nWrite-Info \"Unpacking the base Python library...\"\n# The embeddable package comes with python311._pth. We need to unpack the stdlib zip file.\n# First, find the name of the zip file (e.g., python311.zip)\n$StdLibZip = Get-ChildItem -Path $PythonDir -Filter \"python*.zip\" | Select-Object -First 1\nif ($StdLibZip) {\n    Write-Info \"Found Standard Library package: $($StdLibZip.Name)\"\n    Expand-Archive -Path $StdLibZip.FullName -DestinationPath (Join-Path $PythonDir \"Lib\") -Force\n    # Remove the now-unnecessary ._pth file to enable normal module resolution\n    Remove-Item (Join-Path $PythonDir \"python*._pth\")\n    Write-Success \"Standard library unpacked.\"\n} else {\n    Write-Host \"[WARNING] Python standard library zip not found. This may cause issues.\" -ForegroundColor Yellow\n}\n\nWrite-Info \"Installing pip...\"\n& $PythonExePath -m ensurepip\n$SitePackagesDir = Join-Path $PythonDir \"Lib\\site-packages\"\nWrite-Info \"Installing project dependencies into $SitePackagesDir...\"\n& $PythonExePath -m pip install --upgrade pip\n& $PythonExePath -m pip install -r $RequirementsPath --target $SitePackagesDir\nWrite-Success \"All dependencies installed.\"\n\n# --- Cleanup ---\nWrite-Header \"Step 5: Cleaning Up\"\nRemove-Item $TempDir -Recurse -Force\nWrite-Success \"Temporary files removed.\"\n\nWrite-Header \"Portable Python Environment is Ready!\"\n",
    "scripts/repair_fortuna.bat": "@echo off\nREM Repair corrupted or missing files\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\necho Repairing Fortuna Faucet installation...\n\nREM /f flag performs repair. Assumes MSI is in the 'dist' folder.\nmsiexec.exe /f \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" ^\n    /qn ^\n    /l*v \"%TEMP%\\fortuna_repair.log\"\n\nif %errorlevel% equ 0 (\n    echo Repair completed successfully.\n) else (\n    echo Repair failed. Check log: %TEMP%\\fortuna_repair.log\n)\n\nexit /b %errorlevel%",
    "scripts/setup_embedded_python.ps1": "# Download and prepare portable Python\n$pythonVersion = \"3.11.7\"\n$pythonUrl = \"https://www.python.org/ftp/python/$pythonVersion/python-$pythonVersion-embed-amd64.zip\"\n$buildDir = \".\\build\"\n$pythonDir = \"$buildDir\\python\"\n\nWrite-Host \"[INFO] Setting up embedded Python...\" -ForegroundColor Green\n\n# Create build directory if it doesn't exist\nif (-not (Test-Path $buildDir)) {\n    New-Item -ItemType Directory -Path $buildDir | Out-Null\n}\n\n# Download\nif (-not (Test-Path \"$buildDir\\python-embed.zip\")) {\n    Write-Host \"[DOWNLOAD] Downloading Python $pythonVersion...\"\n    Invoke-WebRequest -Uri $pythonUrl -OutFile \"$buildDir\\python-embed.zip\"\n}\n\n# Extract\nif (Test-Path $pythonDir) {\n    Remove-Item $pythonDir -Recurse -Force\n}\nExpand-Archive -Path \"$buildDir\\python-embed.zip\" -DestinationPath $pythonDir -Force\n\n# Install pip\nWrite-Host \"[INFO] Installing pip...\"\n$getpip = \"$buildDir\\get-pip.py\"\nInvoke-WebRequest -Uri \"https://bootstrap.pypa.io/get-pip.py\" -OutFile $getpip\n& \"$pythonDir\\python.exe\" $getpip\n\n# Install requirements\nWrite-Host \"[INFO] Installing Python dependencies...\"\n# Note: --target is used to install packages to a specific directory, which is essential for embedded/portable environments.\n& \"$pythonDir\\Scripts\\pip.exe\" install --quiet -r \"requirements.txt\" --target \"$pythonDir\\Lib\\site-packages\"\n\nWrite-Host \"[SUCCESS] Embedded Python ready at $pythonDir\" -ForegroundColor Green\n",
    "scripts/uninstall_fortuna.bat": "@echo off\nREM Complete removal of Fortuna Faucet\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\necho WARNING: This will remove Fortuna Faucet completely.\nset /p confirm=\"Are you sure? (y/N): \"\n\nif /i not \"%confirm%\"==\"y\" exit /b 0\n\nREM Find and remove MSI by UpgradeCode\nfor /f \"tokens=2 delims=\" %%A in ('wmic product where \"Name like 'Fortuna Faucet%%'\" get IdentifyingNumber /value') do (\n    for /f \"tokens=2 delims==\" %%B in (\"%%A\") do (\n        msiexec.exe /x %%B /qn /l*v \"%TEMP%\\fortuna_uninstall.log\"\n    )\n)\n\nREM Clean up directories\nif exist \"%PROGRAMFILES%\\Fortuna Faucet\" rmdir /s /q \"%PROGRAMFILES%\\Fortuna Faucet\" 2>nul\nif exist \"%APPDATA%\\Fortuna Faucet\" rmdir /s /q \"%APPDATA%\\Fortuna Faucet\" 2>nul\n\necho Uninstall complete.",
    "scripts/validate_installation.ps1": "param (\n    [string][Parameter(Mandatory=$true)] $InstallPath\n)\n\nfunction Write-Log {\n    param ([string]$Message)\n    # This log file is temporary and will be rolled back if the installation fails.\n    # Its primary purpose is for debugging the installer itself.\n    Add-Content -Path \"$env:TEMP\\fortuna_validation.log\" -Value \"$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') - $Message\"\n}\n\ntry {\n    Write-Log \"--- Starting Installation Validation ---\"\n    Write-Log \"Install Path: $InstallPath\"\n\n    $pythonExe = Join-Path $InstallPath \"python\\python.exe\"\n    Write-Log \"Python Executable Path: $pythonExe\"\n\n    if (-not (Test-Path $pythonExe)) {\n        Write-Log \"[ERROR] python.exe not found at the expected location.\"\n        # The script must exit with a non-zero code to trigger the MSI rollback.\n        exit 1\n    }\n\n    Write-Log \"Python executable found. Testing execution...\"\n\n    # Attempt to execute python.exe --version\n    $process = Start-Process -FilePath $pythonExe -ArgumentList \"--version\" -Wait -PassThru -NoNewWindow\n\n    if ($process.ExitCode -ne 0) {\n        Write-Log \"[ERROR] python.exe failed to execute correctly. Exit Code: $($process.ExitCode)\"\n        exit 1\n    }\n\n    Write-Log \"Python execution successful. Validation passed.\"\n    Write-Log \"--- Validation Complete ---\"\n\n    # Exit with 0 for success\n    exit 0\n}\ncatch {\n    Write-Log \"[FATAL] An unexpected error occurred during validation: $_\"\n    # Exit with a non-zero code to signal failure to the installer\n    exit 1\n}\n",
    "setup.py": "# setup.py\nfrom setuptools import setup, find_packages\n\nwith open('requirements.txt') as f:\n    requirements = f.read().splitlines()\n\nsetup(\n    name='fortuna_engine',\n    version='1.0.0',\n    packages=find_packages(),\n    author='Jules',\n    author_email='',\n    description='The Python backend for the Fortuna Faucet application.',\n    long_description='This package contains the FastAPI server and all related data adapters and analysis tools.',\n    install_requires=requirements,\n    entry_points={\n        'console_scripts': [\n            'fortuna-engine=python_service.run_api:main',\n        ],\n    },\n    include_package_data=True,\n    package_data={\n        'python_service': ['*.py'],\n    },\n)\n",
    "setup_wizard.py": "# setup_wizard.py\nimport secrets\nimport os\n\nDOTENV_PATH = '.env'\nDOTENV_FULL_EXAMPLE_PATH = '.env.full.example'\n\ndef generate_api_key():\n    \"\"\"Generates a secure, URL-safe API key.\"\"\"\n    return secrets.token_urlsafe(32)\n\ndef run_quick_start():\n    \"\"\"\n    'Quick Start' setup. Creates a .env file with only the essential,\n    automatically generated API_KEY.\n    \"\"\"\n    print(\"--- Fortuna Faucet Quick Start Setup ---\")\n\n    if os.path.exists(DOTENV_PATH):\n        print(f\"\u2705 An existing '{DOTENV_PATH}' file was found. Setup is already complete.\")\n        print(\"To re-run setup, please delete the existing .env file.\")\n        return\n\n    api_key = generate_api_key()\n\n    try:\n        with open(DOTENV_PATH, 'w') as f:\n            f.write(f'# Auto-generated by Fortuna Faucet Setup Wizard\\n')\n            f.write(f'API_KEY=\"{api_key}\"\\n\\n')\n            f.write('# To enable advanced features, see .env.full.example\\n')\n\n        print(f\"\u2705 Successfully created '{DOTENV_PATH}' with a new secure API key.\")\n        print(\"\\nQuick Start is complete! You can now launch the application.\")\n\n    except IOError as e:\n        print(f\"\u274c ERROR: Could not write to '{DOTENV_PATH}'. Please check file permissions.\")\n        print(e)\n\ndef create_advanced_template():\n    \"\"\"\n    Creates the .env.full.example for advanced users.\n    \"\"\"\n    template = \"\"\"# .env.full.example\n# For advanced users. Copy these contents to your .env file to enable them.\n\n# --- Application Security (Required) ---\n# This is automatically generated by the setup wizard.\n# API_KEY=\"YOUR_SECRET_API_KEY_HERE\"\n\n# --- Betfair API Credentials (Required for LiveOddsMonitor) ---\nBETFAIR_APP_KEY=\"YOUR_APP_KEY_HERE\"\nBETFAIR_USERNAME=\"YOUR_USERNAME_HERE\"\nBETFAIR_PASSWORD=\"YOUR_PASSWORD_HERE\"\n\n# --- Optional Adapter Keys ---\nTVG_API_KEY=\"\"\nRACING_AND_SPORTS_TOKEN=\"\"\nPOINTSBET_API_KEY=\"\"\n\n# --- CORS Configuration (Optional) ---\nALLOWED_ORIGINS=\"http://localhost:3000\"\n\n# --- Greyhound Adapter (Optional) ---\nGREYHOUND_API_URL=\"\"\n\n# --- The Racing API (Optional but Recommended) ---\nTHE_RACING_API_KEY=\"\"\n\n# --- Optional Caching Backend ---\nREDIS_URL=\"\"\n\"\"\"\n    try:\n        with open(DOTENV_FULL_EXAMPLE_PATH, 'w') as f:\n            f.write(template)\n        print(f\"\u2705 Advanced configuration template created at '{DOTENV_FULL_EXAMPLE_PATH}'\")\n    except IOError:\n        pass # Don't bother users if this fails\n\nif __name__ == '__main__':\n    run_quick_start()\n    create_advanced_template()\n    print(\"\\n-------------------------------------------\")\n    input(\"Press Enter to exit...\")\n",
    "windows_service.py": "# windows_service.py\nimport win32serviceutil\nimport win32service\nimport win32event\nimport servicemanager\nimport socket\nimport sys\nimport os\nimport subprocess\nfrom pathlib import Path\n\nclass FortunaBackendService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaFaucetBackend\"\n    _svc_display_name_ = \"Fortuna Faucet Racing Analysis Service\"\n    _svc_description_ = \"Background service for continuous racing data monitoring.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.stop_event = win32event.CreateEvent(None, 0, 0, None)\n        self.backend_process = None\n        socket.setdefaulttimeout(60)\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        win32event.SetEvent(self.stop_event)\n        if self.backend_process:\n            self.backend_process.terminate()\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(servicemanager.EVENTLOG_INFORMATION_TYPE, servicemanager.PYS_SERVICE_STARTED, (self._svc_name_, ''))\n        self.main()\n\n    def main(self):\n        install_dir = Path(__file__).parent.resolve()\n        venv_python = install_dir / \".venv\" / \"Scripts\" / \"python.exe\"\n        api_module_dir = install_dir / \"python_service\"\n\n        env = os.environ.copy()\n        env_file = install_dir / \".env\"\n        if env_file.exists():\n            with open(env_file) as f:\n                for line in f:\n                    if '=' in line and not line.startswith('#'):\n                        key, value = line.strip().split('=', 1)\n                        env[key] = value.strip('\\\"')\n\n        self.backend_process = subprocess.Popen(\n            [str(venv_python), \"-m\", \"uvicorn\", \"api:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"],\n            cwd=str(api_module_dir),\n            env=env\n        )\n\n        win32event.WaitForSingleObject(self.stop_event, win32event.INFINITE)\n\nif __name__ == '__main__':\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaBackendService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaBackendService)\n",
    "wix/WixUI_CustomInstallDir.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:WixUI=\"http://schemas.microsoft.com/wix/WixUIExtension\">\n  <Fragment>\n    <UI Id=\"WixUI_CustomInstallDir\">\n        <DialogRef Id=\"BrowseDlg\" />\n        <DialogRef Id=\"DiskCostDlg\" />\n        <DialogRef Id=\"ErrorDlg\" />\n        <DialogRef Id=\"FatalError\" />\n        <DialogRef Id=\"FilesInUse\" />\n        <DialogRef Id=\"MsiRMFilesInUse\" />\n        <DialogRef Id=\"PrepareDlg\" />\n        <DialogRef Id=\"UserExit\" />\n        <DialogRef Id=\"WelcomeDlg\" />\n        <DialogRef Id=\"InstallDirDlg\" />\n        <DialogRef Id=\"VerifyReadyDlg\" />\n\n        <!-- Use our custom progress dialog instead of the default -->\n        <DialogRef Id=\"InstallProgressDlg\" />\n\n        <Publish Dialog=\"WelcomeDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"InstallDirDlg\">1</Publish>\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"WelcomeDlg\">1</Publish>\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Next\" Event=\"SetTargetPath\" Value=\"[WIXUI_INSTALLDIR]\" Order=\"1\" />\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"VerifyReadyDlg\" Order=\"2\">1</Publish>\n        <Publish Dialog=\"VerifyReadyDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"InstallDirDlg\" Order=\"1\">NOT Installed</Publish>\n        <Publish Dialog=\"VerifyReadyDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"MaintenanceTypeDlg\" Order=\"2\">Installed</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n",
    "wix/WixUI_CustomProgress.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\">\n  <Fragment>\n    <UI>\n      <!-- Override the default InstallProgress dialog -->\n      <Dialog Id=\"InstallProgressDlg\" Width=\"370\" Height=\"270\" Title=\"Fortuna Faucet Installation\" Modeless=\"yes\">\n        <Control Id=\"Title\" Type=\"Title\" X=\"20\" Y=\"6\" Width=\"330\" Height=\"18\" Text=\"Installation Progress\" />\n        <Control Id=\"BannerBitmap\" Type=\"Bitmap\" X=\"0\" Y=\"0\" Width=\"370\" Height=\"44\" TabSkip=\"no\" Text=\"WixUI_Bmp_Banner\" />\n        <Control Id=\"Back\" Type=\"PushButton\" X=\"180\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Back\" Disabled=\"yes\" />\n        <Control Id=\"Next\" Type=\"PushButton\" X=\"236\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Next\" Disabled=\"yes\" />\n        <Control Id=\"Cancel\" Type=\"PushButton\" X=\"304\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"Cancel\" />\n\n        <Control Id=\"ActionText\" Type=\"Text\" X=\"70\" Y=\"80\" Width=\"280\" Height=\"20\" TabSkip=\"no\">\n          <Subscribe Event=\"ActionText\" Attribute=\"Text\" />\n        </Control>\n        <Control Id=\"Description\" Type=\"Text\" X=\"35\" Y=\"55\" Width=\"300\" Height=\"20\" Text=\"Please wait while the installer copies files.\" />\n\n        <!-- This is the new control to display the current filename -->\n        <Control Id=\"CurrentFileText\" Type=\"Text\" X=\"70\" Y=\"100\" Width=\"280\" Height=\"20\">\n            <Subscribe Event=\"SetProgress\" Attribute=\"Text\" />\n        </Control>\n\n        <Control Id=\"ProgressBar\" Type=\"ProgressBar\" X=\"35\" Y=\"120\" Width=\"300\" Height=\"10\" ProgressBlocks=\"yes\" Text=\"Progress\">\n          <Subscribe Event=\"SetProgress\" Attribute=\"Progress\" />\n        </Control>\n      </Dialog>\n\n      <!-- The Publish element must be a child of UI, not Dialog -->\n      <Publish Dialog=\"InstallProgressDlg\" Control=\"Cancel\" Event=\"SpawnDialog\" Value=\"CancelDlg\">1</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n",
    "wix/product.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:util=\"http://schemas.microsoft.com/wix/UtilExtension\">\n\n  <Product\n    Id=\"*\"\n    Name=\"Fortuna Faucet - Racing Analysis Engine\"\n    Language=\"1033\"\n    Version=\"$(var.Version)\"\n    Manufacturer=\"Mason J0 Studios\"\n    UpgradeCode=\"12345678-1234-1234-1234-123456789012\">\n\n    <Package\n      InstallerVersion=\"200\"\n      Compressed=\"yes\"\n      InstallScope=\"perMachine\"\n      Platform=\"x64\"\n      Description=\"Horse racing analysis platform\"\n      Comments=\"Professional-grade installer\"/>\n\n    <Media Id=\"1\" Cabinet=\"fortuna.cab\" EmbedCab=\"yes\"/>\n\n    <!-- Directory Structure -->\n    <Directory Id=\"TARGETDIR\" Name=\"SourceDir\">\n      <Directory Id=\"ProgramFiles64Folder\">\n        <Directory Id=\"INSTALLFOLDER\" Name=\"Fortuna Faucet\">\n        </Directory>\n      </Directory>\n      <Directory Id=\"ProgramMenuFolder\">\n        <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Faucet\"/>\n      </Directory>\n    </Directory>\n\n    <!-- Features -->\n    <Feature Id=\"ProductFeature\" Title=\"Fortuna Faucet\" Level=\"1\">\n        <ComponentGroupRef Id=\"BackendFileGroup\"/>\n        <ComponentGroupRef Id=\"FrontendFileGroup\"/>\n        <ComponentGroupRef Id=\"ShortcutsComponentGroup\"/>\n    </Feature>\n\n    <!-- Shortcuts -->\n    <ComponentGroup Id=\"ShortcutsComponentGroup\" Directory=\"ApplicationProgramsFolder\">\n      <Component Id=\"ApplicationShortcuts\" Guid=\"*\">\n          <util:InternetShortcut Id=\"DashboardShortcut\" Name=\"Fortuna Faucet Dashboard\" Target=\"http://localhost:3000\"/>\n          <Shortcut Id=\"UninstallShortcut\" Name=\"Uninstall Fortuna Faucet\" Description=\"Remove this application\" Target=\"[SystemFolder]msiexec.exe\" Arguments=\"/x [ProductCode]\" Advertise=\"no\"/>\n          <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\"/>\n          <RegistryValue Root=\"HKCU\" Key=\"Software\\Fortuna Faucet\" Name=\"Installed\" Type=\"integer\" Value=\"1\" KeyPath=\"yes\"/>\n      </Component>\n    </ComponentGroup>\n\n    <!-- UI -->\n    <UI>\n      <UIRef Id=\"WixUI_InstallDir\" />\n      <Publish Dialog=\"WelcomeDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"InstallDirDlg\" Order=\"2\">1</Publish>\n      <Publish Dialog=\"InstallDirDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"WelcomeDlg\">1</Publish>\n    </UI>\n    <UIRef Id=\"WixUI_Common\" />\n    <Property Id=\"WIXUI_INSTALLDIR\" Value=\"INSTALLFOLDER\" />\n    <WixVariable Id=\"WixUILicenseRtf\" Value=\"electron\\assets\\license.rtf\"/>\n    <WixVariable Id=\"WixUIBannerBmp\" Value=\"electron\\assets\\banner.bmp\"/>\n    <WixVariable Id=\"WixUIDialogBmp\" Value=\"electron\\assets\\dialog.bmp\"/>\n\n    <Condition Message=\"Windows 7 or later (64-bit) is required\">\n      <![CDATA[Installed OR (VersionNT64 >= 601)]]>\n    </Condition>\n\n  </Product>\n</Wix>\n"
}