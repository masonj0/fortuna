{
    ".github/dependabot.yml": "# To get started with Dependabot version updates, you'll need to specify which\n# package ecosystems to update and where the package manifests are located.\n# Please see the documentation for all configuration options:\n# https://docs.github.com/github/administering-a-repository/configuration-options-for-dependency-updates\n\nversion: 2\nupdates:\n  - package-ecosystem: \"pip\" # See documentation for possible values\n    directory: \"/\" # Location of package manifests\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/web_platform/frontend\"\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/electron\"\n    schedule:\n      interval: \"daily\"\n",
    ".github/workflows/build-msi.yml": "name: Build Fortuna Web Service MSI (Experimental)\n\non:\n  push:\n    branches:\n      - 'main'\n    paths:\n      - 'web_platform/**'\n      - 'python_service/**'\n      - 'fortuna-webservice.spec'\n      - '.github/workflows/build-msi.yml'\n\npermissions:\n  contents: read\n  actions: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  BACKEND_DIR: 'python_service'\n\njobs:\n  system-check:\n    name: '\u2699\ufe0f System Prerequisites'\n    runs-on: windows-latest\n    timeout-minutes: 5\n    outputs:\n      disk_free_gb: ${{ steps.system.outputs.disk_gb }}\n    steps:\n      - name: Verify Build Tools\n        run: |\n          Set-StrictMode -Version Latest\n          $tools = @('dotnet', 'python', 'node', 'npm', 'git')\n          foreach ($tool in $tools) {\n            Write-Host \"Checking for $($tool)...\"\n            Get-Command $tool -ErrorAction SilentlyContinue\n            if (-not $?) {\n              Write-Host \"\u274c FATAL: Build tool '$tool' not found in PATH.\" -ForegroundColor Red\n              exit 1\n            }\n          }\n          Write-Host \"\u2705 All critical build tools are present.\" -ForegroundColor Green\n      - name: Check Disk Space\n        id: system\n        run: |\n          Set-StrictMode -Version Latest\n          $disk = Get-Volume | Where-Object { $_.DriveLetter -eq 'C' }\n          $freeGB = [math]::Round($disk.SizeRemaining / 1GB, 2)\n          if ($freeGB -lt 10) {\n            Write-Host \"\u26a0\ufe0f WARNING: Low disk space. Only $freeGB GB free (10+ GB recommended).\" -ForegroundColor Yellow\n          } else {\n            Write-Host \"\u2705 Disk space check passed ($freeGB GB free).\" -ForegroundColor Green\n          }\n          \"disk_gb=$freeGB\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend'\n    timeout-minutes: 15\n    runs-on: windows-latest\n    needs: system-check\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4.1.1 # Pinned to SHA\n      - name: Setup Node.js\n        uses: actions/setup-node@v4.0.2 # Pinned to SHA\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'web_platform/frontend/package-lock.json'\n      - name: Frontend - Install & Build\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          cd web_platform/frontend\n          npm ci\n          npm audit --audit-level=moderate # Added security check\n          npm run build\n      - name: Verify Frontend Build\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $outDir = 'web_platform/frontend/out'\n          if (-not (Test-Path $outDir)) {\n            Write-Host \"\u274c FATAL: Build output directory 'out' not created\" -ForegroundColor Red\n            exit 1\n          }\n          $fileCount = (Get-ChildItem -Path $outDir -Recurse -File | Measure-Object).Count\n          if ($fileCount -eq 0) {\n            Write-Host \"\u274c FATAL: Build output directory is empty\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 Frontend build verified ($fileCount files)\" -ForegroundColor Green\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: frontend-build-output\n          path: web_platform/frontend/out\n          retention-days: 1\n\n  build-backend:\n    name: '\ud83d\udc0d Build Backend'\n    timeout-minutes: 20\n    runs-on: windows-latest\n    env:\n      PYTHONUTF8: \"1\"\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4.1.1 # Pinned to SHA\n      - name: Setup Python\n        uses: actions/setup-python@v5.0.0 # Pinned to SHA\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: '${{ env.BACKEND_DIR }}/requirements.txt'\n      - name: '\u2705 [MONITOR] Ensure Required Directories Exist'\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          New-Item -ItemType Directory -Path \"python_service/adapters\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"python_service/data\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"python_service/json\" -Force | Out-Null\n          Write-Host \"\u2705 Ensured required data, json, and adapters directories exist.\"\n      - name: '\u2705 [MONITOR] Verify Critical Files'\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          if (-not (Test-Path \"python_service/main.py\")) { throw \"\u274c FATAL: python_service/main.py not found\" }\n          Write-Host \"\u2705 Critical files verified.\"\n      - name: Backend - Install Dependencies\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip\n          pip install -r ${{ env.BACKEND_DIR }}/requirements-dev.txt\n      - name: Backend - Security Audit\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          pip-audit -r ${{ env.BACKEND_DIR }}/requirements.txt --local\n      - name: Verify PyInstaller Entry Point\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $specFile = \"fortuna-webservice.spec\"\n          if (-not (Test-Path $specFile)) { throw \"\u274c FATAL: Spec file not found: $specFile\" }\n          $specContent = Get-Content $specFile -Raw\n          if ($specContent -match \"Analysis\\(\\s*\\[?'([^']+)'\") {\n            $entryPoint = $matches[1]\n            $entryPointPath = $entryPoint -replace '/', '\\'\n            if (Test-Path $entryPointPath) {\n              Write-Host \"\u2705 Entry point file exists: $entryPointPath\" -ForegroundColor Green\n            } else {\n              throw \"\u274c FATAL: Entry point file NOT found: $entryPointPath\"\n            }\n          } else {\n            throw \"\u26a0\ufe0f WARNING: Could not parse entry point from spec file\"\n          }\n      - name: Backend - Build with PyInstaller\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          pyinstaller fortuna-webservice.spec --noconfirm\n      - name: Verify Executable Size\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $exePath = \"dist/fortuna-webservice.exe\"\n          if (-not (Test-Path $exePath)) {\n            Write-Host \"\u274c FATAL: Executable not found\" -ForegroundColor Red\n            exit 1\n          }\n          $size = (Get-Item $exePath).Length / 1MB\n          if ($size -lt 10) {\n            Write-Host \"\u274c FATAL: Executable is suspiciously small: $($size) MB. Build may be incomplete.\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 Backend executable size is reasonable: $([math]::Round($size, 2)) MB\" -ForegroundColor Green\n      - name: Upload Backend Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: backend-executable\n          path: dist/fortuna-webservice.exe\n          retention-days: 1\n          if-no-files-found: error\n\n  diagnose-asgi-imports:\n    name: '\ud83d\udd0d ASGI Import Killer (Pre-Smoke Diagnostic)'\n    runs-on: windows-latest\n    timeout-minutes: 15\n    needs: build-backend\n    steps:\n      - name: \ud83d\udce5 Checkout Repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 1\n\n      - name: \u2699\ufe0f Setup Python (EXACT VERSION)\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: \ud83d\udccb Capture Python Info\n        run: |\n          Set-StrictMode -Version Latest\n          Write-Host \"Python executable: $(which python)\" -ForegroundColor Cyan\n          python --version\n          python -m site\n          python -c \"import sys; print('Prefix:', sys.prefix); print('Base prefix:', sys.base_prefix)\"\n\n      - name: \ud83d\udce5 Install Requirements (Exactly as Backend Build)\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel --quiet\n          \n          Write-Host \"Installing requirements.txt...\" -ForegroundColor Cyan\n          pip install -r \"${{ env.BACKEND_DIR }}/requirements.txt\" -v 2>&1 | Tee-Object \"install-requirements.log\"\n          \n          if (Test-Path \"${{ env.BACKEND_DIR }}/requirements-dev.txt\") {\n            Write-Host \"Installing requirements-dev.txt...\" -ForegroundColor Cyan\n            pip install -r \"${{ env.BACKEND_DIR }}/requirements-dev.txt\" -v 2>&1 | Tee-Object -Append \"install-requirements.log\"\n          }\n          \n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c pip install failed\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 All dependencies installed\" -ForegroundColor Green\n\n      - name: \ud83d\udce6 Capture Installed Packages\n        run: |\n          pip list | Tee-Object \"installed-packages.txt\"\n          pip freeze | Tee-Object \"pip-freeze.txt\"\n\n      - name: \ud83e\uddea PHASE 1 System Imports\n        run: |\n          python -c @'\n          import sys\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 1 SYSTEM IMPORTS\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('os', 'filesystem'),\n              ('sys', 'system'),\n              ('json', 'serialization'),\n              ('asyncio', 'async I/O'),\n              ('pathlib', 'paths'),\n              ('typing', 'type hints'),\n              ('importlib', 'import utilities'),\n          ]\n          \n          failed = []\n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:20} [{desc}]\")\n              except Exception as e:\n                  print(f\"\u274c {mod_name:20} ERROR: {e}\")\n                  failed.append((mod_name, str(e)))\n          \n          if failed:\n              print(f\"\\n\u274c CRITICAL: {len(failed)} system imports failed\")\n              sys.exit(1)\n          \n          print(f\"\\n\u2705 Phase 1 complete\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 2 Web Framework Core\n        run: |\n          python -c @'\n          import sys\n          import traceback\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 2 WEB FRAMEWORK\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('fastapi', 'web framework'),\n              ('uvicorn', 'ASGI server'),\n              ('starlette', 'ASGI toolkit'),\n              ('starlette.applications', 'ASGI app'),\n              ('starlette.routing', 'routing'),\n          ]\n          \n          failed = []\n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:30} [{desc}]\")\n              except ImportError as e:\n                  print(f\"\u274c {mod_name:30} ImportError: {e}\")\n                  failed.append((mod_name, str(e)))\n              except Exception as e:\n                  print(f\"\u26a0\ufe0f  {mod_name:30} {type(e).__name__}: {e}\")\n          \n          if failed:\n              print(f\"\\n\u274c {len(failed)} core framework imports failed\")\n              for mod, err in failed:\n                  print(f\"  - {mod}\")\n              sys.exit(1)\n          \n          print(f\"\\n\u2705 Phase 2 complete\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 3 Pydantic & Data Validation\n        run: |\n          python -c @'\n          import sys\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 3 PYDANTIC\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('pydantic', 'validation'),\n              ('pydantic_core', 'core'),\n              ('pydantic_settings', 'settings'),\n          ]\n          \n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:30} [{desc}]\")\n              except Exception as e:\n                  print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")\n                  sys.exit(1)\n          \n          print(f\"\\n\u2705 Phase 3 complete\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 4 Async/IO Utilities\n        run: |\n          python -c @'\n          import sys\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 4 ASYNC IO\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('anyio', 'async compat'),\n              ('httpcore', 'HTTP core'),\n              ('httpx', 'HTTP client'),\n              ('aiosqlite', 'async DB'),\n          ]\n          \n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:30} [{desc}]\")\n              except Exception as e:\n                  print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")\n                  sys.exit(1)\n          \n          print(f\"\\n\u2705 Phase 4 complete\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 5 Optional Dependencies (non-critical)\n        continue-on-error: true\n        run: |\n          python -c @'\n          import sys\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 5 OPTIONAL DEPENDENCIES\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('slowapi', 'rate limiting'),\n              ('structlog', 'logging'),\n              ('tenacity', 'retries'),\n          ]\n          \n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:30} [{desc}]\")\n              except Exception as e:\n                  print(f\"\u26a0\ufe0f  {mod_name:30} not critical: {type(e).__name__}\")\n          \n          print(f\"\\n\u2705 Phase 5 complete (warnings OK)\")\n          '@\n\n      - name: \ud83e\uddea PHASE 6 Application Directory Structure\n        run: |\n          Set-StrictMode -Version Latest\n          \n          python -c @'\n          import os\n          from pathlib import Path\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 6 DIRECTORY STRUCTURE\")\n          print(\"=\"*80)\n          \n          cwd = Path.cwd()\n          python_service = cwd / \"python_service\"\n          \n          print(f\"\\nCurrent directory: {cwd}\")\n          print(f\"\\npython_service exists: {python_service.exists()}\")\n          if python_service.exists():\n              print(f\"  Contents:\")\n              for item in python_service.iterdir():\n                  print(f\"    - {item.name}\")\n              \n              main_py = python_service / \"main.py\"\n              api_py = python_service / \"api.py\"\n              \n              print(f\"\\n  main.py: {main_py.exists()} ({main_py.stat().st_size if main_py.exists() else 'N/A'} bytes)\")\n              print(f\"  api.py: {api_py.exists()} ({api_py.stat().st_size if api_py.exists() else 'N/A'} bytes)\")\n          '@\n\n      - name: \ud83e\uddea PHASE 7 CRITICAL - Application Module Imports\n        run: |\n          python -c @'\n          import sys\n          import traceback\n          from pathlib import Path\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 7 MODULE IMPORTS\")\n          print(\"=\"*80)\n          \n          # Step 1: python_service\n          print(\"\\n[Step 1] Importing python_service...\")\n          try:\n              import python_service\n              print(f\"\u2705 python_service imported\")\n              print(f\"   Location: {python_service.__file__}\")\n          except Exception as e:\n              print(f\"\u274c FATAL: python_service import failed\")\n              print(f\"   Error: {type(e).__name__}: {e}\")\n              traceback.print_exc()\n              sys.exit(1)\n          \n          # Step 2: Get app object\n          print(\"\\n[Step 2] Retrieving 'app' object from main...\")\n          try:\n              from python_service.main import app\n              print(f\"\u2705 app object retrieved\")\n              print(f\"   Type: {type(app)}\")\n              print(f\"   Class: {app.__class__.__name__}\")\n              print(f\"   Module: {app.__class__.__module__}\")\n          except Exception as e:\n              print(f\"\u274c FATAL: Could not get app object\")\n              print(f\"   Error: {type(e).__name__}: {e}\")\n              traceback.print_exc()\n              sys.exit(1)\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"\u2705 ALL APPLICATION IMPORTS SUCCESSFUL\")\n          print(\"=\"*80)\n          print(\"\\nThe ASGI app is fully importable.\")\n          print(\"Uvicorn should be able to load it successfully.\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c APPLICATION IMPORT TEST FAILED\" -ForegroundColor Red\n            exit 1\n          }\n\n      - name: \ud83d\udccb Generate ASGI Diagnostic Report\n        if: always()\n        run: |\n          Set-StrictMode -Version Latest\n          $report = @()\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report += \"\u2551              ASGI IMPORT KILLER - DIAGNOSTIC REPORT                        \u2551\"\n          $report += \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\"\n          $report += \"\"\n          $report += \"Timestamp: $(Get-Date -Format 'o')\"\n          $report += \"Python: $(python --version)\"\n          $report += \"\"\n          $report += \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\"\n          if ($LASTEXITCODE -eq 0) { $result = 'PASS \u2705' } else { $result = 'FAIL \u274c' }\n          $report += \"\u2502 RESULT: $result \u2502\"\n          $report += \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\"\n          $report += \"\"\n          $report += \"If this passed:\"\n          $report += \"  \u2705 All required dependencies are installed\"\n          $report += \"  \u2705 python_service.main is importable\"\n          $report += \"  \u2705 FastAPI app is accessible\"\n          $report += \"  \u2705 The executable should work\"\n          $report += \"  \u2705 Uvicorn WILL be able to load the app\"\n          $report += \"\"\n          $report += \"If this failed:\"\n          $report += \"  \u274c See error output above for the exact problem\"\n          $report += \"  \u274c Fix the import error in your code\"\n          $report += \"  \u274c Common issues:\"\n          $report += \"     - Missing dependency in requirements.txt\"\n          $report += \"     - Syntax error in api.py or main.py\"\n          $report += \"     - Circular import in api.py\"\n          $report += \"     - api.py imports a module that fails\"\n          $report += \"\"\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report | Tee-Object \"asgi-diagnostic-report.txt\"\n\n      - name: \ud83d\udce4 Upload Diagnostic Artifacts\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: asgi-import-diagnostics-experimental-${{ github.run_id }}\n          path: |\n            install-requirements.log\n            installed-packages.txt\n            pip-freeze.txt\n            asgi-diagnostic-report.txt\n          retention-days: 30\n          if-no-files-found: warn\n\n  smoke-test-service:\n    name: '\ud83e\uddea Smoke Test Service (Backend + Frontend)'\n    timeout-minutes: 15\n    needs: [build-backend, build-frontend, diagnose-asgi-imports]\n    runs-on: windows-latest\n    env:\n      API_KEY: \"a_secure_test_api_key_that_is_long_enough_for_smoke_test\"\n      FORTUNA_PORT: 8100\n      SMOKE_FRONTEND_PORT: 3300\n      SMOKE_FRONTEND_URL: \"http://localhost:3300\"\n      SMOKE_HEADING_SELECTOR: \"h1:has-text('Fortuna Faucet')\"\n      SMOKE_SCREENSHOT_PATH: \"smoke-test-screenshot.png\"\n      SMOKE_FAILURE_SCREENSHOT_PATH: \"smoke-test-screenshot-FAILURE.png\"\n    steps:\n      - name: Get Playwright Version\n        id: playwright-version\n        shell: pwsh\n        run: echo \"VERSION=$(python -c 'from importlib.metadata import version; print(version(\"playwright\"))')\" >> $env:GITHUB_OUTPUT\n      - name: Cache Playwright browsers\n        uses: actions/cache@88522ab9f39a2ea568f7027ed67a8d8f9e9d59c3 # v4.0.2\n        id: playwright-cache\n        with:\n          path: C:\\Users\\runneradmin\\AppData\\Local\\ms-playwright\n          key: ${{ runner.os }}-playwright-${{ steps.playwright-version.outputs.VERSION }}\n      - name: Download Artifacts\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          path: ./artifacts\n      - name: '\ud83d\udee1\ufe0f Configure Firewall for Smoke Test'\n        shell: pwsh\n        run: |\n          New-NetFirewallRule -DisplayName \"Allow Fortuna Smoke Test\" -Direction Inbound -Action Allow -Protocol TCP -LocalPort ${{ env.FORTUNA_PORT }}\n          Write-Host \"\u2705 Firewall rule added for port ${{ env.FORTUNA_PORT }}.\"\n      - name: Stage Files\n        shell: pwsh\n        run: |\n          Get-ChildItem -Path \"./artifacts/backend-executable\" | ForEach-Object { Move-Item -Path $_.FullName -Destination \".\" -Force }\n          New-Item -ItemType Directory -Path \"./frontend\" -Force\n          Get-ChildItem -Path \"./artifacts/frontend-build-output\" | ForEach-Object { Move-Item -Path $_.FullName -Destination \"./frontend\" -Force }\n      - name: Run Backend and Frontend\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          New-Item -ItemType Directory -Path \"data\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"logs\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"json\" -Force | Out-Null\n          $backendProcess = Start-Process -FilePath \"./fortuna-webservice.exe\" -PassThru -RedirectStandardOutput \"backend-out.log\" -RedirectStandardError \"backend-err.log\"\n          Set-Content -Path \"backend.pid\" -Value $backendProcess.Id\n          Push-Location ./frontend\n          $frontendProcess = Start-Process python -ArgumentList \"-m http.server ${{ env.SMOKE_FRONTEND_PORT }}\" -PassThru -RedirectStandardOutput \"../frontend-out.log\" -RedirectStandardError \"../frontend-err.log\"\n          Pop-Location\n          Set-Content -Path \"frontend.pid\" -Value $frontendProcess.Id\n      - name: Deep Integration Test (Poll Health Endpoint)\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $healthUrl = \"http://127.0.0.1:${{ env.FORTUNA_PORT }}/health\"\n          $maxAttempts = 15\n          $delaySeconds = 2\n          $success = $false\n          For ($i=1; $i -le $maxAttempts; $i++) {\n            try {\n              $response = Invoke-WebRequest -Uri $healthUrl -UseBasicParsing -TimeoutSec 2\n              if ($response.StatusCode -eq 200) {\n                Write-Host \"\u2705 Health check passed on attempt $i.\"\n                New-Item -Path . -Name ready -ItemType File\n                $success = $true\n                break\n              }\n            } catch {\n              Write-Host \"Attempt $i of $maxAttempts failed. Retrying in $delaySeconds seconds...\"\n              Start-Sleep -Seconds $delaySeconds\n            }\n          }\n          if (-not $success) {\n            Write-Host \"\u274c Health check failed after $maxAttempts attempts.\"\n            exit 1\n          }\n      - name: '\ud83d\udd75\ufe0f\u200d\u2640\ufe0f Enhanced Forensic Analysis'\n        if: failure()\n        shell: pwsh\n        run: |\n          Write-Host \"--- \ud83d\udd75\ufe0f\u200d\u2640\ufe0f FORENSIC ANALYSIS \ud83d\udd75\ufe0f\u200d\u2640\ufe0f ---\"\n\n          Write-Host \"`n--- 1. ENVIRONMENT VARIABLES ---\"\n          Get-ChildItem Env: | Sort-Object Name | Format-Table -AutoSize | Out-String -Width 4096\n\n          Write-Host \"`n--- 2. FILE SYSTEM SNAPSHOT ---\"\n          Get-ChildItem -Recurse | Out-String -Width 4096\n\n          Write-Host \"`n--- 3. NETWORK PORT USAGE (netstat) ---\"\n          try {\n            netstat -anb\n          } catch {\n            Write-Host \"  (netstat -anb failed, attempting without -b)\"\n            netstat -an\n          }\n\n          Write-Host \"`n--- 4. BACKEND STDOUT (backend-out.log) ---\"\n          if (Test-Path backend-out.log) { Get-Content backend-out.log -Raw }\n\n          Write-Host \"`n--- 5. BACKEND STDERR (backend-err.log) ---\"\n          if (Test-Path backend-err.log) { Get-Content backend-err.log -Raw }\n\n          Write-Host \"`n--- END OF FORENSIC ANALYSIS ---\"\n      - name: Frontend UI Verification\n        continue-on-error: true\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          if (-not (Test-Path ready)) {\n            Write-Host \"Skipping UI verification: backend not ready.\"\n            exit 0\n          }\n          pip install playwright==1.48.2\n          python -m playwright install chromium\n          $scriptContent = @\"\n          import sys, os\n          from playwright.sync_api import sync_playwright, expect\n\n          def run_verification():\n              with sync_playwright() as p:\n                  browser = p.chromium.launch()\n                  page = browser.new_page()\n                  page.tracing.start(screenshots=True, snapshots=True)\n                  try:\n                      url = os.environ[\"SMOKE_FRONTEND_URL\"]\n                      page.goto(url, wait_until='networkidle', timeout=20000)\n                      heading = page.locator(os.environ[\"SMOKE_HEADING_SELECTOR\"])\n                      expect(heading).to_be_visible(timeout=10000)\n                      page.screenshot(path=os.environ[\"SMOKE_SCREENSHOT_PATH\"])\n                      page.tracing.stop(path=\"trace-success.zip\")\n                      sys.exit(0)\n                  except Exception as e:\n                      print(f\"Error: {e}\", file=sys.stderr)\n                      page.screenshot(path=os.environ[\"SMOKE_FAILURE_SCREENSHOT_PATH\"])\n                      page.tracing.stop(path=\"trace-failure.zip\")\n                      sys.exit(1)\n                  finally:\n                      browser.close()\n\n          if __name__ == \"__main__\":\n              run_verification()\n          \"@\n          Set-Content -Path \"verify_frontend.py\" -Value $scriptContent\n          python verify_frontend.py\n      - name: Upload Verification Artifacts\n        if: always()\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: smoke-test-artifacts\n          path: |\n            ${{ env.SMOKE_SCREENSHOT_PATH }}\n            ${{ env.SMOKE_FAILURE_SCREENSHOT_PATH }}\n            trace-*.zip\n          if-no-files-found: warn\n      - name: Teardown Processes and Firewall\n        if: always()\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          if (Test-Path \"backend.pid\") { Get-Content \"backend.pid\" | ForEach-Object { Stop-Process -Id $_ -Force -ErrorAction SilentlyContinue } }\n          if (Test-Path \"frontend.pid\") { Get-Content \"frontend.pid\" | ForEach-Object { Stop-Process -Id $_ -Force -ErrorAction SilentlyContinue } }\n          Remove-NetFirewallRule -DisplayName \"Allow Fortuna Smoke Test\" -ErrorAction SilentlyContinue\n\n  package-and-test:\n    name: '\ud83c\udfc6 Package & Test Electron Installer'\n    timeout-minutes: 25\n    needs: [build-frontend, smoke-test-service]\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4.1.1 # Pinned to SHA\n      - name: Setup Node.js for Electron\n        uses: actions/setup-node@v4.0.2 # Pinned to SHA\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'electron/package-lock.json'\n      - name: Download All Build Artifacts\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          path: ./temp-artifacts\n      - name: Stage Artifacts for Packaging\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          New-Item -ItemType Directory -Path \"./electron/web-ui-build\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"./electron/resources\" -Force | Out-Null\n          Move-Item -Path \"./temp-artifacts/frontend-build-output/*\" -Destination \"./electron/web-ui-build/out\" -Force\n          Move-Item -Path \"./temp-artifacts/backend-executable/fortuna-webservice.exe\" -Destination \"./electron/resources/fortuna-backend.exe\" -Force\n      - name: Verify Staged Artifacts\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $backendPath = \"./electron/resources/fortuna-backend.exe\"\n          $frontendDir = \"./electron/web-ui-build/out\"\n          if (-not (Test-Path $backendPath)) {\n            Write-Host \"\u274c FATAL: Backend executable not found at $backendPath\" -ForegroundColor Red\n            exit 1\n          }\n          $frontendFiles = (Get-ChildItem -Path $frontendDir -Recurse -File | Measure-Object).Count\n          if ($frontendFiles -eq 0) {\n            Write-Host \"\u274c FATAL: No files found in frontend directory $frontendDir\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 Artifacts staged successfully: Backend executable and $frontendFiles frontend files.\" -ForegroundColor Green\n      - name: Critical Integration Test\n        shell: pwsh\n        env:\n          API_KEY: \"a_secure_test_api_key_that_is_long_enough\"\n        run: |\n          Set-StrictMode -Version Latest\n          $exe = \"./electron/resources/fortuna-backend.exe\"\n          # ... existing integration test ...\n      - name: Electron - Install & Package MSI\n        working-directory: electron\n        shell: pwsh\n        run: |\n          npm ci\n          npx electron-builder --config electron-builder-config.yml --publish never\n      - name: Code Sign MSI\n        if: github.event_name == 'push' && contains(github.ref, 'refs/tags/')\n        shell: pwsh\n        run: |\n          # ... code signing script ...\n      - name: Upload Final MSI Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: fortuna-installer-windows-${{ github.sha }}\n          path: electron/dist/*.msi\n          retention-days: 7\n      - name: Create GitHub Release\n        if: github.event_name == 'push' && contains(github.ref, 'refs/tags/')\n        id: create_release\n        uses: softprops/action-gh-release@c062e08bd532815e2082a85e87e3ef29c3e6d191 # v2.2.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          body: |\n            MSI Installer for Fortuna Faucet.\n            Built from commit ${{ github.sha }}.\n          draft: false\n          prerelease: false\n      - name: Upload Release Asset\n        if: github.event_name == 'push' && contains(github.ref, 'refs/tags/')\n        uses: actions/upload-release-asset@a3c3b214041997193b7385d10a241e57c1975e53 # v1.0.2\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.create_release.outputs.upload_url }}\n          asset_path: electron/dist/*.msi\n          asset_name: fortuna-faucet-${{ github.ref_name }}.msi\n          asset_content_type: application/octet-stream\n",
    ".github/workflows/build-web-service-msi-gpt5.yml": "name: Build Fortuna Faucet Web Service Installer (Omega Overkill)\n\non:\n  push:\n    branches:\n      - main\n    tags:\n      - 'v*'\n    paths:\n      - 'web_platform/**'\n      - 'python_service/**'\n      - 'fortuna-backend-webservice.spec'\n      - '.github/workflows/build-web-service-msi-gpt5.yml'\n  workflow_dispatch:\n\npermissions:\n  contents: read\n  actions: read\n  checks: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\ndefaults:\n  run:\n    shell: pwsh\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  DOTNET_VERSION: '8.0.x'\n  PYTHONUTF8: '1'\n  PIP_DISABLE_PIP_VERSION_CHECK: '1'\n  PIP_NO_PYTHON_VERSION_WARNING: '1'\n  NPM_CONFIG_FUND: 'false'\n  NPM_CONFIG_AUDIT: 'false'\n  FORCE_COLOR: '3'\n  FRONTEND_DIR: 'web_platform/frontend'\n  FRONTEND_BUILD_DIR: 'web_platform/frontend/out'\n  BACKEND_DIR: 'python_service'\n  WIX_DIR: 'build_wix'\n  BACKEND_SPEC: 'fortuna-backend-webservice.spec'\n  SERVICE_PORT: '8102'\n  HEALTH_ENDPOINT: '/health'\n  API_KEY: 'a_secure_test_api_key_that_is_long_enough_for_smoke_test'\n  MSI_STAGING_DIR: 'build_wix/staging'\n  MSI_OUTPUT_DIR: 'dist'\n  WIX_VERSION: '4.0.5'\n\njobs:\n  system-check:\n    name: '\u2699\ufe0f System Prerequisites'\n    runs-on: windows-latest\n    timeout-minutes: 5\n    outputs:\n      disk_free_gb: ${{ steps.system.outputs.disk_gb }}\n    steps:\n      - name: Verify Build Tools\n        run: |\n          Set-StrictMode -Version Latest\n          $tools = @('dotnet', 'python', 'node', 'npm', 'git')\n          foreach ($tool in $tools) {\n            Write-Host \"Checking for $($tool)...\"\n            Get-Command $tool -ErrorAction SilentlyContinue\n            if (-not $?) {\n              Write-Host \"\u274c FATAL: Build tool '$tool' not found in PATH.\" -ForegroundColor Red\n              exit 1\n            }\n          }\n          Write-Host \"\u2705 All critical build tools are present.\" -ForegroundColor Green\n      - name: Check Disk Space\n        id: system\n        run: |\n          Set-StrictMode -Version Latest\n          $disk = Get-Volume | Where-Object { $_.DriveLetter -eq 'C' }\n          $freeGB = [math]::Round($disk.SizeRemaining / 1GB, 2)\n          if ($freeGB -lt 10) {\n            Write-Host \"\u26a0\ufe0f WARNING: Low disk space. Only $freeGB GB free (10+ GB recommended).\" -ForegroundColor Yellow\n          } else {\n            Write-Host \"\u2705 Disk space check passed ($freeGB GB free).\" -ForegroundColor Green\n          }\n          \"disk_gb=$freeGB\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n  repo-preflight:\n    name: '\ud83e\uddea Repo Preflight & Integrity'\n    runs-on: windows-latest\n    needs: system-check\n    timeout-minutes: 5\n    outputs:\n      frontend_lock_hash: ${{ steps.hashes.outputs.frontend_lock_hash }}\n      backend_requirements_hash: ${{ steps.hashes.outputs.backend_requirements_hash }}\n      wix_definition_hash: ${{ steps.hashes.outputs.wix_definition_hash }}\n      semver: ${{ steps.meta.outputs.semver }}\n      short_sha: ${{ steps.meta.outputs.short_sha }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Derive Build Metadata\n        id: meta\n        run: |\n          Set-StrictMode -Version Latest\n          $ref = \"${{ github.ref }}\"\n          if ($ref -like 'refs/tags/v*') {\n            $semver = $ref -replace 'refs/tags/v', ''\n          } else {\n            $semver = \"0.0.${{ github.run_number }}\"\n          }\n          $shortSha = \"${{ github.sha }}\".Substring(0,7)\n          \"semver=$semver\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"short_sha=$shortSha\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          Write-Host \"\ud83d\udd16 Version: $semver ($shortSha)\"\n\n      - name: Validate Critical Files Exist\n        run: |\n          Set-StrictMode -Version Latest\n          $paths = @(\n            \"${{ env.FRONTEND_DIR }}/package.json\",\n            \"${{ env.FRONTEND_DIR }}/package-lock.json\",\n            \"${{ env.BACKEND_DIR }}/requirements.txt\",\n            \"${{ env.BACKEND_DIR }}/main.py\",\n            \"${{ env.BACKEND_SPEC }}\",\n            \"${{ env.WIX_DIR }}/Product_WithService.wxs\"\n          )\n          foreach ($path in $paths) {\n            if (-not (Test-Path $path)) {\n              Write-Host \"\u274c FATAL: Required path missing: $path\" -ForegroundColor Red\n              exit 1\n            }\n          }\n          Write-Host \"\u2705 All critical files confirmed.\"\n\n      - name: Capture Integrity Hashes\n        id: hashes\n        run: |\n          Set-StrictMode -Version Latest\n          $frontend = (Get-FileHash \"${{ env.FRONTEND_DIR }}/package-lock.json\" -Algorithm SHA256).Hash\n          $backend = (Get-FileHash \"${{ env.BACKEND_DIR }}/requirements.txt\" -Algorithm SHA256).Hash\n          $wix = (Get-FileHash \"${{ env.WIX_DIR }}/Product_WithService.wxs\" -Algorithm SHA256).Hash\n          \"frontend_lock_hash=$frontend\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"backend_requirements_hash=$backend\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          \"wix_definition_hash=$wix\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n      - name: Upload Integrity Snapshot\n        uses: actions/upload-artifact@v4\n        with:\n          name: repo-preflight-${{ github.run_id }}\n          path: |\n            ${{ env.FRONTEND_DIR }}/package-lock.json\n            ${{ env.BACKEND_DIR }}/requirements.txt\n            ${{ env.WIX_DIR }}/Product_WithService.wxs\n          retention-days: 3\n\n  frontend-quality:\n    name: '\ud83e\uddfc Frontend Quality Gates'\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    needs: repo-preflight\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: '${{ env.FRONTEND_DIR }}/package-lock.json'\n\n      - name: Install Dependencies\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm ci --prefer-offline --no-audit --no-fund\n\n      - name: Run Lint (if defined)\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          $pkg = Get-Content package.json -Raw | ConvertFrom-Json\n          if ($pkg.scripts.PSObject.Properties.Name -contains 'lint') {\n            Write-Host \"\ud83e\uddf9 Running npm run lint\"\n            npm run lint\n          } else {\n            Write-Host \"\u2139\ufe0f No lint script defined, skipping.\"\n          }\n\n      - name: Run Tests (if defined)\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          $pkg = Get-Content package.json -Raw | ConvertFrom-Json\n          if ($pkg.scripts.PSObject.Properties.Name -contains 'test') {\n            Write-Host \"\ud83e\uddea Running npm test -- --watch=false\"\n            npm test -- --watch=false\n          } else {\n            Write-Host \"\u2139\ufe0f No test script defined, skipping.\"\n          }\n\n      - name: Security Audit (non-blocking)\n        continue-on-error: true\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm audit --audit-level=critical\n\n  backend-quality:\n    name: '\ud83e\uddef Backend Quality Gates'\n    runs-on: ubuntu-latest\n    timeout-minutes: 20\n    needs: repo-preflight\n    env:\n      BACKEND_REQUIREMENTS_HASH: ${{ needs.repo-preflight.outputs.backend_requirements_hash }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: |\n            ${{ env.BACKEND_DIR }}/requirements.txt\n            ${{ env.BACKEND_DIR }}/requirements-dev.txt\n\n      - name: Install Dependencies\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel\n          pip install -r \"${{ env.BACKEND_DIR }}/requirements.txt\"\n          if (Test-Path \"${{ env.BACKEND_DIR }}/requirements-dev.txt\") {\n            pip install -r \"${{ env.BACKEND_DIR }}/requirements-dev.txt\"\n          } else {\n            Write-Host \"\u2139\ufe0f requirements-dev.txt not found, skipping.\"\n          }\n\n      - name: Bytecode Compile (Fail Fast)\n        run: |\n          Set-StrictMode -Version Latest\n          python -m compileall -q \"${{ env.BACKEND_DIR }}\"\n\n      - name: Run Pytest (if available)\n        run: |\n          Set-StrictMode -Version Latest\n          python -c 'import importlib.util, sys; sys.exit(0 if importlib.util.find_spec(\"pytest\") else 1)'\n          if ($LASTEXITCODE -eq 0) {\n            Write-Host \"\ud83e\uddea pytest detected, running suite...\"\n            cd \"${{ env.BACKEND_DIR }}\"\n            python -m pytest --maxfail=1 --disable-warnings\n          } else {\n            Write-Host \"\u2139\ufe0f pytest not installed; skipping tests.\"\n          }\n\n      - name: pip-audit (non-blocking)\n        continue-on-error: true\n        run: |\n          Set-StrictMode -Version Latest\n          pip install pip-audit\n          pip-audit -r ${{ env.BACKEND_DIR }}/requirements.txt\n\n  sbom:\n    name: '\ud83d\udcc4 SBOM Snapshot'\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    needs: repo-preflight\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Generate SBOM (SPDX)\n        uses: anchore/sbom-action@v0\n        with:\n          output-file: sbom.spdx.json\n          format: spdx-json\n\n      - name: Upload SBOM\n        uses: actions/upload-artifact@v4\n        with:\n          name: sbom-${{ github.run_id }}\n          path: sbom.spdx.json\n          retention-days: 7\n\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend'\n    runs-on: windows-latest\n    timeout-minutes: 20\n    needs: [repo-preflight, frontend-quality]\n    env:\n      FRONTEND_LOCK_HASH: ${{ needs.repo-preflight.outputs.frontend_lock_hash }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: '${{ env.FRONTEND_DIR }}/package-lock.json'\n\n      - name: Prime npm Cache\n        uses: actions/cache@v4\n        with:\n          path: ~\\AppData\\Local\\npm-cache\n          key: ${{ runner.os }}-npm-${{ env.NODE_VERSION }}-${{ env.FRONTEND_LOCK_HASH }}\n          restore-keys: |\n            ${{ runner.os }}-npm-${{ env.NODE_VERSION }}-\n\n      - name: Install Dependencies\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm ci --prefer-offline --no-audit --no-fund\n\n      - name: Build Frontend\n        run: |\n          Set-StrictMode -Version Latest\n          cd \"${{ env.FRONTEND_DIR }}\"\n          npm run build\n\n      - name: Verify Build Output\n        run: |\n          Set-StrictMode -Version Latest\n          $outDir = Resolve-Path \"${{ env.FRONTEND_BUILD_DIR }}\"\n          if (-not (Test-Path $outDir)) {\n             Write-Host \"\u274c FATAL: Build directory not found\" -ForegroundColor Red\n             exit 1\n          }\n          $files = Get-ChildItem -Path $outDir -Recurse -File\n          if ($files.Count -eq 0) {\n             Write-Host \"\u274c FATAL: Build directory empty\" -ForegroundColor Red\n             exit 1\n          }\n          Write-Host \"\u2705 Frontend built: $($files.Count) files.\"\n\n      - name: Generate Artifact Manifest\n        run: |\n          Set-StrictMode -Version Latest\n          $outDir = Resolve-Path \"${{ env.FRONTEND_BUILD_DIR }}\"\n          $manifestPath = \"frontend-manifest.tsv\"\n          \"RelativePath`tSizeBytes`tSHA256\" | Out-File $manifestPath -Encoding utf8\n          Get-ChildItem -Path $outDir -Recurse -File | ForEach-Object {\n            $relative = $_.FullName.Substring($outDir.Path.Length).TrimStart('\\','/')\n            $hash = (Get-FileHash $_.FullName -Algorithm SHA256).Hash\n            \"$relative`t$($_.Length)`t$hash\" | Out-File $manifestPath -Encoding utf8 -Append\n          }\n\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: frontend-build-${{ github.run_id }}\n          path: ${{ env.FRONTEND_BUILD_DIR }}\n          retention-days: 3\n\n      - name: Upload Manifest\n        uses: actions/upload-artifact@v4\n        with:\n          name: frontend-manifest-${{ github.run_id }}\n          path: frontend-manifest.tsv\n          retention-days: 3\n\n  build-backend:\n    name: '\ud83d\udc0d Build Backend'\n    runs-on: windows-latest\n    timeout-minutes: 25\n    needs: [repo-preflight, build-frontend, backend-quality]\n    env:\n      BACKEND_REQUIREMENTS_HASH: ${{ needs.repo-preflight.outputs.backend_requirements_hash }}\n      BUILD_VERSION: ${{ needs.repo-preflight.outputs.semver }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Download Frontend Artifact\n        uses: actions/download-artifact@v4\n        with:\n          name: frontend-build-${{ github.run_id }}\n          path: temp-frontend\n\n      - name: Stage Frontend for PyInstaller\n        run: |\n          Set-StrictMode -Version Latest\n          $dest = \"staging/ui\"\n          New-Item -ItemType Directory -Path $dest -Force | Out-Null\n          Copy-Item -Path \"temp-frontend/*\" -Destination $dest -Recurse -Force\n          Write-Host \"\u2705 Frontend staged for inclusion.\"\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: |\n            ${{ env.BACKEND_DIR }}/requirements.txt\n            ${{ env.BACKEND_DIR }}/requirements-dev.txt\n\n      - name: Install Dependencies\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel\n          pip install -r \"${{ env.BACKEND_DIR }}/requirements.txt\"\n          if (Test-Path \"${{ env.BACKEND_DIR }}/requirements-dev.txt\") {\n            pip install -r \"${{ env.BACKEND_DIR }}/requirements-dev.txt\"\n          }\n\n      - name: Freeze Dependency Snapshot\n        run: |\n          Set-StrictMode -Version Latest\n          pip freeze | Out-File backend-freeze.txt -Encoding utf8\n\n      - name: Create Required Backend Directories\n        run: |\n          Set-StrictMode -Version Latest\n          New-Item -ItemType Directory -Path \"${{ env.BACKEND_DIR }}/data\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"${{ env.BACKEND_DIR }}/json\" -Force | Out-Null\n          Write-Host \"\u2705 Created required backend directories for PyInstaller.\" -ForegroundColor Green\n\n      - name: Build with PyInstaller\n        env:\n          FORTUNA_VERSION: ${{ needs.repo-preflight.outputs.semver }}\n        run: |\n          Set-StrictMode -Version Latest\n          pyinstaller \"${{ env.BACKEND_SPEC }}\" --clean --log-level=WARN --noconfirm\n\n      - name: Verify Executable\n        run: |\n          Set-StrictMode -Version Latest\n          $exePath = \"dist/fortuna-backend.exe\"\n          if (-not (Test-Path $exePath)) {\n            Write-Host \"\u274c FATAL: Executable not found\" -ForegroundColor Red\n            exit 1\n          }\n          $hash = (Get-FileHash $exePath -Algorithm SHA256).Hash\n          $size = (Get-Item $exePath).Length / 1MB\n          if ($size -lt 10) {\n            Write-Host \"\u274c FATAL: Executable is suspiciously small: $($size) MB. Build may be incomplete.\" -ForegroundColor Red\n            exit 1\n          }\n          \"fortuna-backend.exe`t$hash\" | Out-File backend-sha256.tsv -Encoding utf8\n          Write-Host \"\u2705 Backend ready: $([math]::Round($size, 2)) MB ($hash)\"\n\n      - name: Upload Backend Executable\n        uses: actions/upload-artifact@v4\n        with:\n          name: backend-executable-${{ github.run_id }}\n          path: dist/fortuna-backend.exe\n          retention-days: 3\n\n      - name: Upload Backend Metadata\n        uses: actions/upload-artifact@v4\n        with:\n          name: backend-metadata-${{ github.run_id }}\n          path: |\n            backend-sha256.tsv\n            backend-freeze.txt\n          retention-days: 7\n\n  diagnose-asgi-imports:\n    name: '\ud83d\udd0d ASGI Import Killer (Pre-Smoke Diagnostic)'\n    runs-on: windows-latest\n    timeout-minutes: 15\n    needs: build-backend\n    steps:\n      - name: \ud83d\udce5 Checkout Repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 1\n\n      - name: \u2699\ufe0f Setup Python (EXACT VERSION)\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: \ud83d\udccb Capture Python Info\n        run: |\n          Set-StrictMode -Version Latest\n          Write-Host \"Python executable: $(which python)\" -ForegroundColor Cyan\n          python --version\n          python -m site\n          python -c \"import sys; print('Prefix:', sys.prefix); print('Base prefix:', sys.base_prefix)\"\n\n      - name: \ud83d\udce5 Install Requirements (Exactly as Backend Build)\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel --quiet\n          \n          Write-Host \"Installing requirements.txt...\" -ForegroundColor Cyan\n          pip install -r \"${{ env.BACKEND_DIR }}/requirements.txt\" -v 2>&1 | Tee-Object \"install-requirements.log\"\n          \n          if (Test-Path \"${{ env.BACKEND_DIR }}/requirements-dev.txt\") {\n            Write-Host \"Installing requirements-dev.txt...\" -ForegroundColor Cyan\n            pip install -r \"${{ env.BACKEND_DIR }}/requirements-dev.txt\" -v 2>&1 | Tee-Object -Append \"install-requirements.log\"\n          }\n          \n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c pip install failed\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 All dependencies installed\" -ForegroundColor Green\n\n      - name: \ud83d\udce6 Capture Installed Packages\n        run: |\n          pip list | Tee-Object \"installed-packages.txt\"\n          pip freeze | Tee-Object \"pip-freeze.txt\"\n\n      - name: \ud83e\uddea PHASE 1 System Imports\n        run: |\n          python -c @'\n          import sys\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 1 SYSTEM-LEVEL IMPORTS\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('os', 'filesystem'),\n              ('sys', 'system'),\n              ('json', 'serialization'),\n              ('asyncio', 'async I/O'),\n              ('pathlib', 'paths'),\n              ('typing', 'type hints'),\n              ('importlib', 'import utilities'),\n          ]\n          \n          failed = []\n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:20} [{desc}]\")\n              except Exception as e:\n                  print(f\"\u274c {mod_name:20} ERROR: {e}\")\n                  failed.append((mod_name, str(e)))\n          \n          if failed:\n              print(f\"\\n\u274c CRITICAL: {len(failed)} system imports failed\")\n              sys.exit(1)\n          \n          print(f\"\\n\u2705 Phase 1 complete\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 2 Web Framework Core\n        run: |\n          python -c @'\n          import sys\n          import traceback\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 2 WEB FRAMEWORK CORE\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('fastapi', 'web framework'),\n              ('uvicorn', 'ASGI server'),\n              ('starlette', 'ASGI toolkit'),\n              ('starlette.applications', 'ASGI app'),\n              ('starlette.routing', 'routing'),\n          ]\n          \n          failed = []\n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:30} [{desc}]\")\n              except ImportError as e:\n                  print(f\"\u274c {mod_name:30} ImportError: {e}\")\n                  failed.append((mod_name, str(e)))\n              except Exception as e:\n                  print(f\"\u26a0\ufe0f  {mod_name:30} {type(e).__name__}: {e}\")\n          \n          if failed:\n              print(f\"\\n\u274c {len(failed)} core framework imports failed\")\n              for mod, err in failed:\n                  print(f\"  - {mod}\")\n              sys.exit(1)\n          \n          print(f\"\\n\u2705 Phase 2 complete\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 3 Pydantic & Data Validation\n        run: |\n          python -c @'\n          import sys\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 3 PYDANTIC & DATA VALIDATION\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('pydantic', 'validation'),\n              ('pydantic_core', 'core'),\n              ('pydantic_settings', 'settings'),\n          ]\n          \n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:30} [{desc}]\")\n              except Exception as e:\n                  print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")\n                  sys.exit(1)\n          \n          print(f\"\\n\u2705 Phase 3 complete\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 4 Async/IO Utilities\n        run: |\n          python -c @'\n          import sys\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 4 ASYNC/IO UTILITIES\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('anyio', 'async compat'),\n              ('httpcore', 'HTTP core'),\n              ('httpx', 'HTTP client'),\n              ('aiosqlite', 'async DB'),\n          ]\n          \n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:30} [{desc}]\")\n              except Exception as e:\n                  print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")\n                  sys.exit(1)\n          \n          print(f\"\\n\u2705 Phase 4 complete\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 5 Optional Dependencies (non-critical)\n        continue-on-error: true\n        run: |\n          python -c @'\n          import sys\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 5 OPTIONAL DEPENDENCIES (non-critical)\")\n          print(\"=\"*80)\n          \n          modules = [\n              ('slowapi', 'rate limiting'),\n              ('structlog', 'logging'),\n              ('tenacity', 'retries'),\n          ]\n          \n          for mod_name, desc in modules:\n              try:\n                  __import__(mod_name)\n                  print(f\"\u2705 {mod_name:30} [{desc}]\")\n              except Exception as e:\n                  print(f\"\u26a0\ufe0f  {mod_name:30} not critical: {type(e).__name__}\")\n          \n          print(f\"\\n\u2705 Phase 5 complete (warnings OK)\")\n          '@\n\n      - name: \ud83e\uddea PHASE 6 Application Directory Structure\n        run: |\n          Set-StrictMode -Version Latest\n          \n          python -c @'\n          import os\n          from pathlib import Path\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 6 APPLICATION DIRECTORY STRUCTURE\")\n          print(\"=\"*80)\n          \n          cwd = Path.cwd()\n          python_service = cwd / \"python_service\"\n          \n          print(f\"\\nCurrent directory: {cwd}\")\n          print(f\"\\npython_service exists: {python_service.exists()}\")\n          if python_service.exists():\n              print(f\"  Contents:\")\n              for item in python_service.iterdir():\n                  print(f\"    - {item.name}\")\n              \n              main_py = python_service / \"main.py\"\n              api_py = python_service / \"api.py\"\n              \n              print(f\"\\n  main.py: {main_py.exists()} ({main_py.stat().st_size if main_py.exists() else 'N/A'} bytes)\")\n              print(f\"  api.py: {api_py.exists()} ({api_py.stat().st_size if api_py.exists() else 'N/A'} bytes)\")\n          '@\n\n      - name: \ud83e\uddea PHASE 7 CRITICAL - Application Module Imports\n        run: |\n          python -c @'\n          import sys\n          import traceback\n          from pathlib import Path\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"PHASE 7 APPLICATION MODULE IMPORTS (CRITICAL)\")\n          print(\"=\"*80)\n          \n          # Step 1: python_service\n          print(\"\\n[Step 1] Importing python_service...\")\n          try:\n              import python_service\n              print(f\"\u2705 python_service imported\")\n              print(f\"   Location: {python_service.__file__}\")\n          except Exception as e:\n              print(f\"\u274c FATAL: python_service import failed\")\n              print(f\"   Error: {type(e).__name__}: {e}\")\n              traceback.print_exc()\n              sys.exit(1)\n          \n          # Step 2: Get app object\n          print(\"\\n[Step 2] Retrieving 'app' object from main...\")\n          try:\n              from python_service.main import app\n              print(f\"\u2705 app object retrieved\")\n              print(f\"   Type: {type(app)}\")\n              print(f\"   Class: {app.__class__.__name__}\")\n              print(f\"   Module: {app.__class__.__module__}\")\n          except Exception as e:\n              print(f\"\u274c FATAL: Could not get app object\")\n              print(f\"   Error: {type(e).__name__}: {e}\")\n              traceback.print_exc()\n              sys.exit(1)\n          \n          print(\"\\n\" + \"=\"*80)\n          print(\"\u2705 ALL APPLICATION IMPORTS SUCCESSFUL\")\n          print(\"=\"*80)\n          print(\"\\nThe ASGI app is fully importable.\")\n          print(\"Uvicorn should be able to load it successfully.\")\n          '@\n          \n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c APPLICATION IMPORT TEST FAILED\" -ForegroundColor Red\n            exit 1\n          }\n\n      - name: \ud83d\udccb Generate ASGI Diagnostic Report\n        if: always()\n        run: |\n          Set-StrictMode -Version Latest\n          $report = @()\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report += \"\u2551              ASGI IMPORT KILLER - DIAGNOSTIC REPORT                        \u2551\"\n          $report += \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\"\n          $report += \"\"\n          $report += \"Timestamp: $(Get-Date -Format 'o')\"\n          $report += \"Python: $(python --version)\"\n          $report += \"\"\n          $report += \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\"\n          $result = if ($LASTEXITCODE -eq 0) { 'PASS \u2705' } else { 'FAIL \u274c' }\n          $report += \"\u2502 RESULT: $result \u2502\"\n          $report += \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\"\n          $report += \"\"\n          $report += \"If this passed:\"\n          $report += \"  \u2705 All required dependencies are installed\"\n          $report += \"  \u2705 python_service.main is importable\"\n          $report += \"  \u2705 FastAPI app is accessible\"\n          $report += \"  \u2705 The executable should work\"\n          $report += \"  \u2705 Uvicorn WILL be able to load the app\"\n          $report += \"\"\n          $report += \"If this failed:\"\n          $report += \"  \u274c See error output above for the exact problem\"\n          $report += \"  \u274c Fix the import error in your code\"\n          $report += \"  \u274c Common issues:\"\n          $report += \"     - Missing dependency in requirements.txt\"\n          $report += \"     - Syntax error in api.py or main.py\"\n          $report += \"     - Circular import in api.py\"\n          $report += \"     - api.py imports a module that fails\"\n          $report += \"\"\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report | Tee-Object \"asgi-diagnostic-report.txt\"\n\n      - name: \ud83d\udce4 Upload Diagnostic Artifacts\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: asgi-import-diagnostics-${{ github.run_id }}\n          path: |\n            install-requirements.log\n            installed-packages.txt\n            pip-freeze.txt\n            asgi-diagnostic-report.txt\n          retention-days: 30\n          if-no-files-found: warn\n\n  smoke-test:\n    name: '\ud83d\udd2c Smoke Test (Diagnostic Overkill)'\n    runs-on: windows-latest\n    timeout-minutes: 30\n    needs: [build-backend, diagnose-asgi-imports]\n    steps:\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      # PHASE 0: PRE-EXECUTION FORENSICS\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      - name: \ud83d\udce5 Download Executable\n        uses: actions/download-artifact@v4\n        with:\n          name: backend-exe-${{ github.run_id }}\n          path: dist\n\n      - name: \ud83c\udfd7\ufe0f Setup Directories & Capture Baseline\n        run: |\n          Set-StrictMode -Version Latest\n\n          # Create diagnostic structure\n          New-Item -ItemType Directory -Path \"service-logs\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"diagnostics\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"diagnostics/exe-analysis\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"diagnostics/runtime-trace\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"diagnostics/import-analysis\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"diagnostics/environment\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"data\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"json\" -Force | Out-Null\n\n          # Baseline system state\n          Get-Process | Out-File \"diagnostics/baseline-processes.txt\"\n          Get-NetTCPConnection -ErrorAction SilentlyContinue | Out-File \"diagnostics/baseline-network.txt\"\n          [Environment]::GetEnvironmentVariables() | Out-File \"diagnostics/baseline-env.txt\"\n\n          Write-Host \"\u2705 Diagnostic directories created\" -ForegroundColor Green\n\n      - name: \ud83d\udd2c Analyze Executable (Pre-Execution)\n        run: |\n          Set-StrictMode -Version Latest\n\n          $exe = \"dist/fortuna-backend.exe\"\n\n          # File properties\n          $info = Get-Item $exe\n          $size = $info.Length / 1MB\n\n          @\"\n          === EXECUTABLE ANALYSIS ===\n          Path: $($info.FullName)\n          Size: $([math]::Round($size, 2)) MB\n          Created: $($info.CreationTime)\n          Modified: $($info.LastWriteTime)\n          Attributes: $($info.Attributes)\n          \"@ | Tee-Object \"diagnostics/exe-analysis/exe-properties.txt\"\n\n          # PE signature check\n          $bytes = [System.IO.File]::ReadAllBytes($exe)\n          $peSignature = \"{0:X2}{1:X2}\" -f $bytes[0], $bytes[1]\n          if ($peSignature -eq \"4D5A\") {\n            Write-Host \"\u2705 Valid PE signature: $peSignature\" -ForegroundColor Green\n          } else {\n            Write-Host \"\u274c INVALID PE signature: $peSignature (expected 4D5A)\" -ForegroundColor Red\n            exit 1\n          }\n\n          # Check for embedded dependencies (more robustly)\n          $searchString = \"uvicorn\"\n          # Use Select-String instead of findstr to avoid exit code 1 issues\n          if (Select-String -Path $exe -Pattern $searchString -Quiet -SimpleMatch) {\n              Write-Host \"\u2705 Found '$searchString' reference.\"\n          } else {\n              Write-Host \"\u2139\ufe0f '$searchString' not found in binary (likely packed). Continuing...\" -ForegroundColor Gray\n          }\n\n      - name: \ud83d\udd12 Configure Firewall & Network\n        run: |\n          Set-StrictMode -Version Latest\n\n          # Create firewall rule\n          try {\n            New-NetFirewallRule `\n              -DisplayName \"FortunaSmoke\" `\n              -Direction Inbound `\n              -Action Allow `\n              -Protocol TCP `\n              -LocalPort ${{ env.SERVICE_PORT }} `\n              -ErrorAction Stop\n            Write-Host \"\u2705 Firewall rule created\" -ForegroundColor Green\n          } catch {\n            Write-Host \"\u26a0\ufe0f  Firewall rule may exist: $_\" -ForegroundColor Yellow\n          }\n\n          # Allow port in Windows Defender\n          try {\n            netsh advfirewall firewall add rule name=\"FortunaSmokeHTTP\" dir=in action=allow protocol=tcp localport=${{ env.SERVICE_PORT }} | Out-File \"diagnostics/firewall-netsh.log\"\n          } catch {\n            Write-Host \"\u26a0\ufe0f  netsh command issue (non-critical)\" -ForegroundColor Yellow\n          }\n\n          # Baseline netstat\n          netstat -ano | Out-File \"diagnostics/network-baseline.txt\"\n\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      # PHASE 1: PRE-LAUNCH PYTHON/ASGI VALIDATION\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      - name: \ud83d\udc0d Test PyInstaller Python Environment (Mimic Executable)\n        run: |\n          Set-StrictMode -Version Latest\n\n          # Create a test script that mimics what the executable should do\n          $testScript = @'\n          import sys\n          import os\n          import traceback\n\n          print(\"=\" * 80)\n          print(\"PRE-LAUNCH PYTHON ENVIRONMENT CHECK\")\n          print(\"=\" * 80)\n\n          # 1. System paths\n          print(\"\\n1. PYTHON ENVIRONMENT:\")\n          print(f\"   Python: {sys.executable}\")\n          print(f\"   Version: {sys.version}\")\n          print(f\"   Platform: {sys.platform}\")\n          print(f\"   Prefix: {sys.prefix}\")\n\n          # 2. Module search paths\n          print(\"\\n2. MODULE SEARCH PATHS:\")\n          for i, p in enumerate(sys.path):\n              print(f\"   [{i}] {p}\")\n\n          # 3. Critical imports (same as in PyInstaller spec)\n          critical_modules = [\n              'fastapi',\n              'uvicorn',\n              'pydantic',\n              'pydantic_core',\n              'pydantic_settings',\n              'aiosqlite',\n              'slowapi',\n              'structlog',\n              'starlette',\n              'starlette.staticfiles',\n              'anyio',\n              'httpcore',\n              'httpx',\n          ]\n\n          print(\"\\n3. CRITICAL MODULE IMPORTS:\")\n          failed = []\n          for mod in critical_modules:\n              try:\n                  __import__(mod)\n                  print(f\"   \u2705 {mod}\")\n              except ImportError as e:\n                  print(f\"   \u274c {mod}: {e}\")\n                  failed.append((mod, str(e)))\n              except Exception as e:\n                  print(f\"   \u26a0\ufe0f  {mod}: {type(e).__name__}: {e}\")\n\n          # 4. Attempt to import web_service modules\n          print(\"\\n4. APPLICATION MODULES (web_service.backend):\")\n          app_modules = [\n              'web_service',\n              'web_service.backend',\n              'web_service.backend.main',\n              'web_service.backend.api',\n          ]\n\n          for mod in app_modules:\n              try:\n                  __import__(mod)\n                  print(f\"   \u2705 {mod}\")\n              except ImportError as e:\n                  print(f\"   \u274c {mod}: {e}\")\n                  failed.append((mod, str(e)))\n                  traceback.print_exc()\n              except Exception as e:\n                  print(f\"   \u26a0\ufe0f  {mod}: {type(e).__name__}: {e}\")\n                  traceback.print_exc()\n\n          # 5. Test ASGI app instantiation\n          print(\"\\n5. ASGI APP INSTANTIATION:\")\n          try:\n              from web_service.backend.main import app\n              print(f\"   \u2705 Successfully imported app from main\")\n              print(f\"   App type: {type(app)}\")\n              print(f\"   App class: {app.__class__.__name__}\")\n          except ImportError as e:\n              print(f\"   \u274c Failed to import app: {e}\")\n              traceback.print_exc()\n              failed.append((\"main.app\", str(e)))\n          except Exception as e:\n              print(f\"   \u26a0\ufe0f  {type(e).__name__}: {e}\")\n              traceback.print_exc()\n\n          # Summary\n          print(\"\\n\" + \"=\" * 80)\n          if failed:\n              print(f\"FAILURES: {len(failed)} module(s) failed\")\n              for mod, err in failed:\n                  print(f\"  - {mod}\")\n                  print(f\"    {err[:100]}\")\n              sys.exit(1)\n          else:\n              print(\"\u2705 ALL CHECKS PASSED\")\n              sys.exit(0)\n          '@\n\n          $testScript | Out-File \"diagnostics/import-analysis/pre-launch-test.py\" -Encoding utf8\n\n          python \"diagnostics/import-analysis/pre-launch-test.py\" 2>&1 | Tee-Object \"diagnostics/import-analysis/pre-launch-output.txt\"\n\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u26a0\ufe0f  Pre-launch Python check failed (but executable may still work)\" -ForegroundColor Yellow\n          }\n\n      - name: \ud83d\udd0d Inspect Executable Contents (Strings Dump)\n        run: |\n          Set-StrictMode -Version Latest\n\n          $exe = \"dist/fortuna-backend.exe\"\n\n          # Extract strings from executable (look for module names, ports, etc.)\n          # Note: This requires PowerShell Get-Content binary reading\n          $content = [System.IO.File]::ReadAllBytes($exe)\n          $text = [System.Text.Encoding]::ASCII.GetString($content)\n\n          # Extract readable strings\n          $strings = [regex]::Matches($text, '[A-Za-z0-9_.\\-/]+') | ForEach-Object { $_.Value } | Sort-Object -Unique\n\n          # Filter for interesting ones\n          $interestingStrings = $strings | Where-Object {\n            $_ -match '(uvicorn|fastapi|web_service|backend|main|api|asgi|starlette)' -or\n            $_.Length -gt 20 -and $_ -match '(\\.py|\\.so|\\.dll|Protocol|http)'\n          }\n\n          Write-Host \"Found $($interestingStrings.Count) interesting strings in executable\" -ForegroundColor Cyan\n          $interestingStrings | Out-File \"diagnostics/exe-analysis/interesting-strings.txt\"\n          $interestingStrings | Out-Host\n\n      - name: \ud83d\udcca Capture Environment for Service Launch\n        run: |\n          Set-StrictMode -Version Latest\n\n          $env | Out-File \"diagnostics/environment/launch-environment.txt\"\n\n          $envVars = @{\n            'API_KEY' = $env:API_KEY\n            'FORTUNA_PORT' = $env:FORTUNA_PORT\n            'FORTUNA_ENV' = $env:FORTUNA_ENV\n            'PYTHONPATH' = $env:PYTHONPATH\n            'PATH' = $env:PATH\n            'TEMP' = $env:TEMP\n            'TMP' = $env:TMP\n          }\n\n          @\"\n          === SERVICE LAUNCH ENVIRONMENT ===\n          API_KEY: $($envVars['API_KEY'] ? '***SET***' : 'NOT SET')\n          FORTUNA_PORT: $($envVars['FORTUNA_PORT'])\n          FORTUNA_ENV: $($envVars['FORTUNA_ENV'])\n          PYTHONPATH: $($envVars['PYTHONPATH'])\n          TEMP: $($envVars['TEMP'])\n\n          Full environment:\n          \"@ | Out-File \"diagnostics/environment/service-environment.txt\"\n\n          $envVars.GetEnumerator() | ForEach-Object {\n            \"$($_.Key)=$($_.Value)\" | Out-File -Append \"diagnostics/environment/service-environment.txt\"\n          }\n\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      # PHASE 2: SERVICE LAUNCH WITH OBSESSIVE TRACING\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      - name: \ud83d\ude80 Start Service with Full Output Capture\n        run: |\n          Set-StrictMode -Version Latest\n\n          $exe = Resolve-Path \"dist/fortuna-backend.exe\"\n          $outLog = \"service-logs/stdout.txt\"\n          $errLog = \"service-logs/stderr.txt\"\n\n          Write-Host \"Starting service...\" -ForegroundColor Cyan\n          Write-Host \"Executable: $exe\" -ForegroundColor Cyan\n          Write-Host \"Port: ${{ env.SERVICE_PORT }}\" -ForegroundColor Cyan\n          Write-Host \"API_KEY: ***\" -ForegroundColor Cyan\n\n          # Set environment for subprocess\n          $env:API_KEY = \"${{ env.API_KEY }}\"\n          $env:FORTUNA_PORT = \"${{ env.SERVICE_PORT }}\"\n          $env:FORTUNA_ENV = \"smoke-test\"\n          $env:PYTHONUNBUFFERED = \"1\"  # Force unbuffered output\n\n          # Start process with full I/O redirection\n          $proc = Start-Process `\n            -FilePath $exe `\n            -PassThru `\n            -RedirectStandardOutput $outLog `\n            -RedirectStandardError $errLog `\n            -NoNewWindow\n\n          $pid = $proc.Id\n          Write-Host \"\u2705 Service process started with PID: $pid\" -ForegroundColor Green\n          $pid | Out-File \"service.pid\" -Encoding ascii\n\n          # Don't wait - proceed to health check\n          Start-Sleep -Seconds 5\n\n          # Check if process is still alive\n          if (Get-Process -Id $pid -ErrorAction SilentlyContinue) {\n            Write-Host \"\u2705 Process still alive after 5 seconds\" -ForegroundColor Green\n          } else {\n            Write-Host \"\u274c FATAL: Process died immediately\" -ForegroundColor Red\n            Write-Host \"=== STDOUT ===\" -ForegroundColor Red\n            Get-Content $outLog\n            Write-Host \"=== STDERR ===\" -ForegroundColor Red\n            Get-Content $errLog\n            exit 1\n          }\n\n      - name: \ud83d\udcca Monitor Process While Running\n        run: |\n          Set-StrictMode -Version Latest\n\n          $pid = Get-Content \"service.pid\" -Raw -ErrorAction SilentlyContinue\n          if ($pid) {\n            $proc = Get-Process -Id $pid -ErrorAction SilentlyContinue\n            if ($proc) {\n              @\"\n              === PROCESS INFO ===\n              PID: $pid\n              Name: $($proc.ProcessName)\n              Memory: $([math]::Round($proc.WorkingSet / 1MB, 2)) MB\n              CPU Time: $($proc.TotalProcessorTime)\n              Threads: $($proc.Threads.Count)\n              Handle Count: $($proc.HandleCount)\n              \"@ | Tee-Object \"diagnostics/runtime-trace/process-info.txt\"\n            }\n          }\n\n          # Network state while running\n          netstat -ano | Out-File \"diagnostics/network-running.txt\"\n\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      # PHASE 3: HEALTH CHECK WITH AGGRESSIVE RETRIES & DEBUGGING\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      - name: \ud83d\udc93 Health Check (Retry Loop with Diagnostics)\n        run: |\n          Set-StrictMode -Version Latest\n\n          $url = \"http://127.0.0.1:${{ env.SERVICE_PORT }}${{ env.HEALTH_ENDPOINT }}\"\n          $maxRetries = 60  # 60 retries = 2 minutes\n          $retryInterval = 2\n          $attempt = 0\n          $success = $false\n\n          Write-Host \"Health check URL: $url\" -ForegroundColor Cyan\n          Write-Host \"Max retries: $maxRetries | Interval: $retryInterval seconds\" -ForegroundColor Cyan\n\n          $healthLog = \"diagnostics/runtime-trace/health-check.log\"\n\n          while ($attempt -lt $maxRetries -and -not $success) {\n            $attempt++\n            $elapsed = ($attempt - 1) * $retryInterval\n\n            Write-Host \"Attempt $attempt/$maxRetries (${elapsed}s elapsed)...\" -ForegroundColor Yellow\n\n            try {\n              # Attempt 1: Test-NetConnection (TCP)\n              Write-Host \"  [TCP Check]...\" -ForegroundColor Gray\n              $tcpTest = Test-NetConnection -ComputerName 127.0.0.1 -Port ${{ env.SERVICE_PORT }} -ErrorAction Stop\n              if ($tcpTest.TcpTestSucceeded) {\n                Write-Host \"  \u2705 TCP Connection successful\" -ForegroundColor Green\n                \"[$attempt] TCP connection successful\" | Out-File -Append $healthLog\n              } else {\n                Write-Host \"  \u274c TCP connection failed\" -ForegroundColor Red\n                \"[$ attempt] TCP connection failed\" | Out-File -Append $healthLog\n                throw \"TCP connection failed\"\n              }\n\n              # Attempt 2: HTTP Request\n              Write-Host \"  [HTTP GET]...\" -ForegroundColor Gray\n              $response = Invoke-WebRequest `\n                -Uri $url `\n                -UseBasicParsing `\n                -TimeoutSec 10 `\n                -ErrorAction Stop\n\n              if ($response.StatusCode -eq 200) {\n                Write-Host \"\u2705 HEALTH CHECK PASSED (HTTP $($response.StatusCode))\" -ForegroundColor Green\n                $response.Content | Out-File \"diagnostics/runtime-trace/health-response.json\"\n                $response.Content | Out-File -Append $healthLog\n                $success = $true\n                break\n              } else {\n                Write-Host \"\u26a0\ufe0f  Unexpected status: $($response.StatusCode)\" -ForegroundColor Yellow\n                \"[$attempt] Status $($response.StatusCode)\" | Out-File -Append $healthLog\n              }\n\n            } catch [System.Net.WebException] {\n              $ex = $_\n              Write-Host \"  \u274c Request failed: $($ex.Exception.Message)\" -ForegroundColor Red\n              \"[$attempt] WebException: $($ex.Exception.Message)\" | Out-File -Append $healthLog\n\n            } catch [System.Net.Sockets.SocketException] {\n              $ex = $_\n              Write-Host \"  \u274c Socket error: $($ex.Exception.Message)\" -ForegroundColor Red\n              \"[$attempt] SocketException: $($ex.Exception.Message)\" | Out-File -Append $healthLog\n\n            } catch {\n              Write-Host \"  \u274c Error: $_\" -ForegroundColor Red\n              \"$attempt] Exception: $_\" | Out-File -Append $healthLog\n            }\n\n            # Capture logs between attempts\n            $stdoutTail = Get-Content \"service-logs/stdout.txt\" -Tail 5 -ErrorAction SilentlyContinue\n            $stderrTail = Get-Content \"service-logs/stderr.txt\" -Tail 5 -ErrorAction SilentlyContinue\n\n            if ($stderrTail) {\n              Write-Host \"  [STDERR tail]:\" -ForegroundColor Gray\n              $stderrTail | ForEach-Object { Write-Host \"    $_\" -ForegroundColor Red }\n            }\n\n            if ($attempt -lt $maxRetries) {\n              Start-Sleep -Seconds $retryInterval\n            }\n          }\n\n          if (-not $success) {\n            Write-Host \"\u274c FATAL: Health check failed after $maxRetries attempts\" -ForegroundColor Red\n\n            # FULL DIAGNOSTICS ON FAILURE\n            Write-Host \"`n=== FULL DIAGNOSTIC DUMP ===\" -ForegroundColor Red\n\n            Write-Host \"`n[STDOUT - Last 50 lines]\" -ForegroundColor Cyan\n            Get-Content \"service-logs/stdout.txt\" -Tail 50\n\n            Write-Host \"`n[STDERR - Last 50 lines]\" -ForegroundColor Cyan\n            Get-Content \"service-logs/stderr.txt\" -Tail 50\n\n            Write-Host \"`n[Process Status]\" -ForegroundColor Cyan\n            $pid = Get-Content \"service.pid\" -Raw\n            Get-Process -Id $pid -ErrorAction SilentlyContinue | Format-List\n\n            Write-Host \"`n[Port Binding Check]\" -ForegroundColor Cyan\n            netstat -ano | grep -E \"127\\.0\\.0\\.1:${{ env.SERVICE_PORT }}\" 2>$null || `\n              netstat -ano | Select-String \"127.0.0.1\" | Select-String \"${{ env.SERVICE_PORT }}\"\n\n            Write-Host \"`n[Firewall Rules]\" -ForegroundColor Cyan\n            Get-NetFirewallRule -DisplayName \"*Fortuna*\" -ErrorAction SilentlyContinue | Format-List\n\n            exit 1\n          }\n\n      - name: \ud83d\udd0c Test API Endpoint\n        run: |\n          Set-StrictMode -Version Latest\n\n          $url = \"http://127.0.0.1:${{ env.SERVICE_PORT }}/api/races\"\n          $headers = @{ 'X-API-Key' = \"${{ env.API_KEY }}\" }\n\n          Write-Host \"Testing API endpoint: $url\" -ForegroundColor Cyan\n\n          try {\n            $response = Invoke-WebRequest `\n              -Uri $url `\n              -Headers $headers `\n              -UseBasicParsing `\n              -TimeoutSec 10\n\n            Write-Host \"\u2705 API Response: HTTP $($response.StatusCode)\" -ForegroundColor Green\n            Write-Host \"Response size: $($response.Content.Length) bytes\" -ForegroundColor Cyan\n            $response.Content | Out-File \"diagnostics/runtime-trace/api-response.json\"\n\n          } catch {\n            Write-Host \"\u26a0\ufe0f  API call failed (service running, but endpoint issue): $_\" -ForegroundColor Yellow\n          }\n\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      # PHASE 4: POST-EXECUTION FORENSICS\n      # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      - name: \ud83d\udcca Post-Test Forensics\n        if: failure()\n        run: |\n          Set-StrictMode -Version Latest\n\n          \"=== TOP PROCESSES ===\" | Out-File \"diagnostics/forensics.log\"\n          Get-Process | Sort-Object CPU -Descending | Select-Object -First 20 | Out-File -Append \"diagnostics/forensics.log\"\n\n          \"=== NETWORK CONNECTIONS ===\" | Out-File -Append \"diagnostics/forensics.log\"\n          netstat -ano | Out-File -Append \"diagnostics/forensics.log\"\n\n          \"=== EVENT VIEWER (Last 20 errors) ===\" | Out-File -Append \"diagnostics/forensics.log\"\n          Get-EventLog -LogName System -EntryType Error -Newest 20 -ErrorAction SilentlyContinue | Out-File -Append \"diagnostics/forensics.log\"\n\n          \"=== DISK SPACE ===\" | Out-File -Append \"diagnostics/forensics.log\"\n          Get-Volume | Out-File -Append \"diagnostics/forensics.log\"\n\n          \"=== REGISTRY (FortunaWebService) ===\" | Out-File -Append \"diagnostics/forensics.log\"\n          Get-ItemProperty -Path \"HKLM:\\Software\\FortunaWebService\" -ErrorAction SilentlyContinue | Out-File -Append \"diagnostics/forensics.log\"\n\n      - name: \ud83d\udce4 Upload All Diagnostics\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: smoke-test-diagnostics-${{ github.run_id }}\n          path: |\n            service-logs/\n            diagnostics/\n            service.pid\n          retention-days: 30\n          if-no-files-found: warn\n\n      - name: \ud83e\uddf9 Cleanup\n        if: always()\n        run: |\n          if (Test-Path 'service.pid') {\n            try {\n              $pid = Get-Content 'service.pid' -Raw\n              Stop-Process -Id $pid -Force -ErrorAction SilentlyContinue\n              Write-Host \"\u2705 Service process terminated\" -ForegroundColor Green\n            } catch {\n              Write-Host \"\u26a0\ufe0f  Could not terminate process\" -ForegroundColor Yellow\n            }\n          }\n\n          Remove-NetFirewallRule -DisplayName \"FortunaSmoke\" -ErrorAction SilentlyContinue\n          Remove-NetFirewallRule -DisplayName \"FortunaSmokeHTTP\" -ErrorAction SilentlyContinue\n\n  package-msi-service:\n    name: '\ud83d\udcbf Package Service MSI'\n    runs-on: windows-latest\n    timeout-minutes: 25\n    needs: [repo-preflight, smoke-test]\n    env:\n      WIX_HASH: ${{ needs.repo-preflight.outputs.wix_definition_hash }}\n      BUILD_VERSION: ${{ needs.repo-preflight.outputs.semver }}\n      SHORT_SHA: ${{ needs.repo-preflight.outputs.short_sha }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Download Backend\n        uses: actions/download-artifact@v4\n        with:\n          name: backend-executable-${{ github.run_id }}\n          path: dist\n\n      - name: Stage Artifacts\n        id: stage\n        run: |\n          Set-StrictMode -Version Latest\n          $staging = \"${{ env.MSI_STAGING_DIR }}\"\n          New-Item -ItemType Directory -Path $staging -Force | Out-Null\n          Move-Item -Path \"dist/fortuna-backend.exe\" -Destination \"$staging/fortuna-webservice.exe\" -Force\n          $msiName = \"Fortuna-WebService-${{ env.BUILD_VERSION }}-${{ env.SHORT_SHA }}.msi\".Replace('/', '-')\n          \"msi_name=$msiName\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n          Write-Host \"\u2705 Staged for MSI: $msiName\"\n\n      - name: Setup .NET SDK\n        uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: ${{ env.DOTNET_VERSION }}\n\n      - name: Cache NuGet\n        uses: actions/cache@v4\n        with:\n          path: ~/.nuget/packages\n          key: ${{ runner.os }}-nuget-${{ env.WIX_HASH }}\n\n      - name: Prepare WiX Project\n        run: |\n          Set-StrictMode -Version Latest\n          Copy-Item \"${{ env.WIX_DIR }}/Product_WithService.wxs\" \"${{ env.WIX_DIR }}/Product.wxs\" -Force\n          $wixProj = @(\n            '<Project Sdk=\"WixToolset.Sdk/${{ env.WIX_VERSION }}\">'\n            '  <PropertyGroup>'\n            '    <OutputName>${{ steps.stage.outputs.msi_name }}</OutputName>'\n            '    <OutputType>Package</OutputType>'\n            '    <DefineConstants>SourceDir=staging</DefineConstants>'\n            '    <Platforms>x64</Platforms>'\n            '    <Version>${{ env.BUILD_VERSION }}</Version>'\n            '  </PropertyGroup>'\n            '  <ItemGroup>'\n            '    <PackageReference Include=\"WixToolset.Util.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '    <PackageReference Include=\"WixToolset.Firewall.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '    <PackageReference Include=\"WixToolset.UI.wixext\" Version=\"${{ env.WIX_VERSION }}\" />'\n            '  </ItemGroup>'\n            '  <ItemGroup>'\n            '    <Compile Include=\"Product.wxs\" />'\n            '  </ItemGroup>'\n            '</Project>'\n          )\n          Set-Content \"${{ env.WIX_DIR }}/Fortuna.wixproj\" -Value $wixProj -Encoding utf8\n\n      - name: Build MSI\n        working-directory: ${{ env.WIX_DIR }}\n        run: |\n          Set-StrictMode -Version Latest\n          dotnet build Fortuna.wixproj -c Release -p:Platform=x64 -p:Version=\"${{ env.BUILD_VERSION }}\"\n          $msiFile = \"bin/x64/Release/${{ steps.stage.outputs.msi_name }}\"\n          if (-not (Test-Path $msiFile)) { throw \"MSI not created\" }\n          $hash = (Get-FileHash $msiFile -Algorithm SHA256).Hash\n          $hash | Out-File \"$msiFile.sha256\" -Encoding utf8\n          Write-Host \"\u2705 MSI Built: $hash\"\n\n      - name: Upload MSI + Hash\n        uses: actions/upload-artifact@v4\n        with:\n          name: fortuna-service-msi-${{ github.run_id }}\n          path: |\n            ${{ env.WIX_DIR }}/bin/x64/Release/*.msi\n            ${{ env.WIX_DIR }}/bin/x64/Release/*.sha256\n          retention-days: 10\n\n  create-release:\n    name: '\ud83d\ude80 Create Release'\n    runs-on: ubuntu-latest\n    if: startsWith(github.ref, 'refs/tags/')\n    needs: package-msi-service\n    permissions:\n      contents: write\n    steps:\n      - name: Download MSI\n        uses: actions/download-artifact@v4\n        with:\n          pattern: fortuna-service-msi-*\n          merge-multiple: true\n          path: assets\n\n      - name: Download SBOM\n        uses: actions/download-artifact@v4\n        with:\n          name: sbom-${{ github.run_id }}\n          path: assets\n\n      - name: Generate Checksums\n        run: |\n          cd assets\n          ls *.msi\n          sha256sum *.msi > SHASUMS256.txt\n\n      - name: Publish Release\n        uses: softprops/action-gh-release@v2\n        with:\n          files: |\n            assets/*.msi\n            assets/*.sha256\n            assets/SHASUMS256.txt\n            assets/sbom.spdx.json\n          generate_release_notes: true\n",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `fortuna`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n\n---\n\n## The Age of Perfection (The Great Simplification)\n\nThe Penta-Hybrid architecture, while a triumph of technical integration, proved to be a strategic dead end. Its complexity became a fortress, making rapid iteration and onboarding of new intelligence (both human and AI) prohibitively expensive. The kingdom was powerful but brittle.\n\nA new doctrine was forged: **Simplicity is the ultimate sophistication.**\n\nThe decision was made to execute \"The Great Simplification.\" The multi-language backend (Python, Rust, Go) was decommissioned. The kingdom was reforged upon a new, elegant, and vastly more powerful two-pillar system:\n\n1.  **A Unified Python Backend:** A single, asynchronous Python service, built on FastAPI, would serve as the kingdom's engine.\n2.  **A Modern TypeScript Frontend:** A dedicated Next.js application would serve as the kingdom's command deck.\n\nThis act of creative destruction liberated the project, enabling a new era of unprecedented velocity.\n\n---\n\n## The Three-Pillar Doctrine\n\nWith the new two-pillar foundation in place, the backend itself was perfected into a three-pillar intelligence engine, a concept that defines the modern era of the Fortuna Faucet:\n\n*   **Pillar 1: The Future (The Planner):** The resilient `OddsEngine` and its fleet of adapters, responsible for finding the day's strategic opportunities.\n*   **Pillar 2: The Past (The Archive):** The perfected `ChartScraper` and `ResultsParser`, responsible for building our historical data warehouse from the ground truth of Equibase PDFs.\n*   **Pillar 3: The Present (The Finisher):** The weaponized `LiveOddsMonitor`, armed with the API-driven `BetfairAdapter`, designed to conquer the final moments of toteboard volatility.\n\nThese three pillars, orchestrated by the fully autonomous `fortuna_watchman.py`, represented the pinnacle of the project's original vision. The kingdom was, for a time, considered \"perfected.\"\n\n---\n\n## The Windows Ascension (The Impossible Dream)\n\nThe perfected kingdom was powerful, but it was still a tool for developers. The final, grandest vision was to transform it into a true, professional-grade application for its sole operator. This campaign, known as \"The Impossible Dream,\" was to forge the **Fortuna Faucet - Windows Native Edition.**\n\nThis era saw the rapid creation of a new, third layer of the kingdom, built upon the foundation of the previous work:\n\n*   **The Electron Shell:** The Next.js frontend was wrapped in an Electron container, transforming it from a website into a true, installable desktop application with its own window, icon, and system tray integration.\n*   **The Engine Room:** The Python backend was re-architected to run as a persistent, background **Windows Service**, making it a true, always-on component of the operating system, independent of the UI.\n*   **The Native GUI:** A dedicated Tkinter-based \"Observatory\" was forged\u2014a standalone GUI mission control for monitoring the health and performance of the background service.\n*   **The One-Click Kingdom:** A complete suite of professional tooling (including installation scripts, a setup wizard, and launchers) was created to provide a seamless, zero-friction installation and management experience.\n\nThis ascension represents the current state of the art, transforming a powerful engine into a polished, autonomous, and user-focused product.\n\n\n---\n\n## The Era of the Windows Kingdom (October 2025)\n\nWith the core engine stabilized and the command deck providing a clear view of the data, the project's focus shifted from pure data acquisition to the operator's experience. This era marked a profound transformation, elevating the project from a collection of powerful but disparate scripts into a cohesive, professional-grade, and resilient native Windows application.\n\nThis campaign, guided by a new \"Grand Strategy\" blueprint, was executed with rapid precision, resulting in a complete overhaul of the user-facing toolkit:\n\n-   **A Bulletproof Foundation:** The installation and launch scripts were re-architected from the ground up. They became intelligent and self-healing, featuring pre-flight system checks, automated port conflict resolution, active health-check loops, and automated repair utilities.\n-   **A Professional Toolkit:** The operator was empowered with a suite of new tools, including an interactive setup wizard, a real-time CLI status monitor, and a full-fledged graphical \"Data Management Console\" for monitoring, filtering, and analyzing data.\n-   **A Unified Command Console (`SERVICE_MANAGER.bat`):** Unify all individual scripts under a single, user-friendly, menu-driven service manager, providing a 'single pane of glass' for all common operations.\n\nThis era solidified the kingdom's foundations, making it not just powerful, but stable, reliable, and a pleasure to operate. The Faucet was no longer just an engine; it was a complete, professional-grade machine.\n\n---\n\n## The Gauntlet of CI/CD (Late October 2025)\n\nWith a professional-grade application in hand, the final frontier was professional-grade *delivery*. This campaign focused on automating the creation of the MSI installer through a continuous integration pipeline, a process that proved to be a formidable challenge.\n\nThe kingdom's engineers faced a relentless series of cryptic build errors from the WiX Toolset, a hostile environment that tested their resolve. Through a series of rapid, iterative fixes\u2014addressing everything from component GUIDs and 64-bit architecture mismatches to obscure linker errors and frontend dependency warnings\u2014they systematically conquered each obstacle.\n\nThis trial by fire culminated in a triumphant success: a fully automated GitHub Actions workflow that reliably compiles, links, and delivers a polished, distributable MSI installer. This victory transformed the project's delivery model from a manual, error-prone process into a repeatable, one-click release pipeline, marking the true completion of the \"Windows Ascension.\"\n\n---\n\n## The Great Unbundling (Late October 2025)\n\nThe CI/CD pipeline was technically successful, but it revealed a deeper, philosophical flaw in the architecture. The installer, while automated, was a fragile monolith. It attempted to bundle raw source code (Python, JavaScript) and orchestrate their setup on the user's machine using post-install scripts. This approach was fraught with peril, vulnerable to failures from network issues, corporate firewalls, and unpredictable machine states.\n\nA final, decisive architectural mandate was issued, informed by the wisdom of external AI consultants: **The application must be delivered, not assembled.**\n\nThis mandate triggered \"The Great Unbundling,\" a swift and transformative refactoring of the entire delivery pipeline:\n\n*   **The Backend Forged:** The Python backend was no longer treated as source code to be installed, but as a product to be delivered. **PyInstaller** was used to forge the entire FastAPI service\u2014interpreter and all dependencies\u2014into a single, standalone `.exe`.\n*   **The Frontend Solidified:** The Next.js frontend was no longer a service to be run, but a static asset to be displayed. The `npm run build` process was configured to produce a clean, static HTML/CSS/JS export.\n*   **The Installer Perfected:** With the application components now self-contained, the MSI installer's role was radically simplified. All complex post-install scripting was eliminated. The WiX toolset was now used for its core competency: reliably copying pre-compiled, robust artifacts to the user's machine.\n\nThis final act of architectural purification created the \"Three-Executable Architecture\" (the backend executable, the Electron wrapper, and the MSI installer itself), achieving true portability and eliminating an entire class of deployment failures. The Windows Ascension was not just complete; it was perfected.",
    "package-lock.json": "{\n  \"name\": \"app\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"dependencies\": {\n        \"@playwright/test\": \"^1.56.1\"\n      }\n    },\n    \"node_modules/@playwright/test\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/@playwright/test/-/test-1.56.1.tgz\",\n      \"integrity\": \"sha512-vSMYtL/zOcFpvJCW71Q/OEGQb7KYBPAdKh35WNSkaZA75JlAO8ED8UN6GUNTm3drWomcbcqRPFqQbLae8yBTdg==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"playwright\": \"1.56.1\"\n      },\n      \"bin\": {\n        \"playwright\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      }\n    },\n    \"node_modules/fsevents\": {\n      \"version\": \"2.3.2\",\n      \"resolved\": \"https://registry.npmjs.org/fsevents/-/fsevents-2.3.2.tgz\",\n      \"integrity\": \"sha512-xiqMQR4xAeHTuB9uWm+fFRcIOgKBMiOBP+eXiyT7jsgVCq1bkVygt00oASowB7EdtpOHaaPgKt812P9ab+DDKA==\",\n      \"hasInstallScript\": true,\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"os\": [\n        \"darwin\"\n      ],\n      \"engines\": {\n        \"node\": \"^8.16.0 || ^10.6.0 || >=11.0.0\"\n      }\n    },\n    \"node_modules/playwright\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/playwright/-/playwright-1.56.1.tgz\",\n      \"integrity\": \"sha512-aFi5B0WovBHTEvpM3DzXTUaeN6eN0qWnTkKx4NQaH4Wvcmc153PdaY2UBdSYKaGYw+UyWXSVyxDUg5DoPEttjw==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"playwright-core\": \"1.56.1\"\n      },\n      \"bin\": {\n        \"playwright\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      },\n      \"optionalDependencies\": {\n        \"fsevents\": \"2.3.2\"\n      }\n    },\n    \"node_modules/playwright-core\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/playwright-core/-/playwright-core-1.56.1.tgz\",\n      \"integrity\": \"sha512-hutraynyn31F+Bifme+Ps9Vq59hKuUCz7H1kDOcBs+2oGguKkWTU50bBWrtz34OUWmIwpBTWDxaRPXrIXkgvmQ==\",\n      \"license\": \"Apache-2.0\",\n      \"bin\": {\n        \"playwright-core\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      }\n    }\n  }\n}\n",
    "python_service/adapters/betfair_greyhound_adapter.py": "# python_service/adapters/betfair_greyhound_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairGreyhoundAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching greyhound racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairGreyhounds\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for greyhound races on a given date.\"\"\"\n        await self._authenticate(self.http_client)\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            self.http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"4339\"],  # Greyhound Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Failed to parse a Betfair Greyhound market.\",\n                    exc_info=True,\n                    market=market,\n                )\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Optional[Race]:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bfg_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 480m').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "python_service/db/init.py": "# python_service/db/init.py\nimport os\nimport sqlite3\n\nfrom ..config import get_settings\n\n\ndef initialize_database():\n    \"\"\"\n    Initializes the database based on the configuration.\n    Currently supports a simple SQLite fallback for local testing.\n    \"\"\"\n    settings = get_settings()\n    db_type = getattr(settings, \"DATABASE_TYPE\", \"sqlite\").lower()\n\n    if db_type == \"sqlite\":\n        # DATABASE_URL for sqlite will be like 'sqlite:///./fortuna.db'\n        db_path = settings.DATABASE_URL.split(\"///\")[1]\n\n        # Ensure the directory for the database exists\n        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n\n        try:\n            conn = sqlite3.connect(db_path)\n            cursor = conn.cursor()\n\n            # The schema is based on the provided pg_schemas, adapted for SQLite\n            # This is a simplified version for demonstration.\n            cursor.execute(\n                \"\"\"\n            CREATE TABLE IF NOT EXISTS races (\n                id TEXT PRIMARY KEY,\n                venue TEXT NOT NULL,\n                race_number INTEGER NOT NULL,\n                start_time TEXT NOT NULL,\n                source TEXT,\n                field_size INTEGER\n            )\n            \"\"\"\n            )\n\n            cursor.execute(\n                \"\"\"\n            CREATE TABLE IF NOT EXISTS runners (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                race_id TEXT,\n                number INTEGER,\n                name TEXT,\n                odds REAL,\n                FOREIGN KEY (race_id) REFERENCES races (id)\n            )\n            \"\"\"\n            )\n\n            conn.commit()\n            conn.close()\n            print(\"SQLite database initialized successfully.\")\n        except sqlite3.Error as e:\n            print(f\"Error initializing SQLite database: {e}\")\n            raise\n",
    "python_service/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "python_service/tests/test_manual_override.py": "# python_service/tests/test_manual_override.py\nimport pytest\n\nfrom python_service.manual_override_manager import ManualOverrideManager\n\n\n@pytest.fixture\ndef manager():\n    # The manager is now in-memory and doesn't need a path\n    return ManualOverrideManager()\n\n\ndef test_register_and_retrieve(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n    content = \"<html>Manual content</html>\"\n    content_type = \"text/html\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    success = manager.submit_manual_data(\n        request_id=request_id,\n        raw_content=content,\n        content_type=content_type,\n    )\n\n    assert success\n\n    # Verify that the data can be retrieved correctly\n    retrieved_data = manager.get_manual_data(adapter_name=adapter, url=url)\n    assert retrieved_data is not None\n    retrieved_content, retrieved_type = retrieved_data\n    assert retrieved_content == content\n    assert retrieved_type == content_type\n\n    # Verify that data is consumed after retrieval\n    assert manager.get_manual_data(adapter_name=adapter, url=url) is None\n",
    "web_platform/api_gateway/src/server.ts": "// server.ts - Complete API Gateway with Database Integration and WebSocket\n\nimport express from 'express';\nimport { createServer } from 'http';\nimport { Server as SocketServer } from 'socket.io';\nimport cors from 'cors';\nimport sqlite3 from 'sqlite3';\nimport { open, Database } from 'sqlite';\nimport path from 'path';\n\n// Types\ninterface Race {\n  race_id: string;\n  track_name: string;\n  race_number: number | null;\n  post_time: string | null;\n  checkmate_score: number;\n  qualified: boolean;\n  trifecta_factors_json: string | null;\n  raw_data_json: string | null;\n  updated_at: string;\n}\n\ninterface AdapterStatus {\n  adapter_name: string;\n  status: string;\n  last_run: string;\n  races_found: number;\n  execution_time_ms: number;\n  error_message: string | null;\n}\n\n// Database Service\nclass DatabaseService {\n  private db: Database | null = null;\n  private dbPath: string;\n\n  constructor() {\n    this.dbPath = process.env.FORTUNA_DB_PATH || path.join(process.cwd(), '..', '..', 'shared_database', 'races.db');\n  }\n\n  async connect(): Promise<void> {\n    try {\n      this.db = await open({\n        filename: this.dbPath,\n        driver: sqlite3.Database\n      });\n      console.log(`[INFO] Connected to database: ${this.dbPath}`);\n    } catch (error) {\n      console.error('[ERROR] Failed to connect to database:', error);\n      throw error;\n    }\n  }\n\n  async getQualifiedRaces(): Promise<Race[]> {\n    if (!this.db) throw new Error('Database not connected');\n    try {\n      const races = await this.db.all<Race[]>(`\n        SELECT race_id, track_name, race_number, post_time,\n               checkmate_score, qualified, trifecta_factors_json,\n               raw_data_json, updated_at\n        FROM live_races\n        WHERE qualified = 1\n        ORDER BY checkmate_score DESC, post_time ASC\n      `);\n      return races;\n    } catch (error) {\n      console.error('[ERROR] Failed to fetch qualified races:', error);\n      return [];\n    }\n  }\n\n  async getAllRaces(): Promise<Race[]> {\n    if (!this.db) throw new Error('Database not connected');\n    try {\n      const races = await this.db.all<Race[]>(`\n        SELECT race_id, track_name, race_number, post_time,\n               checkmate_score, qualified, trifecta_factors_json,\n               raw_data_json, updated_at\n        FROM live_races\n        ORDER BY post_time ASC\n      `);\n      return races;\n    } catch (error) {\n      console.error('[ERROR] Failed to fetch all races:', error);\n      return [];\n    }\n  }\n\n  async getAdapterStatuses(): Promise<AdapterStatus[]> {\n    if (!this.db) throw new Error('Database not connected');\n    try {\n      const statuses = await this.db.all<AdapterStatus[]>(`\n        SELECT adapter_name, status, last_run, races_found,\n               execution_time_ms, error_message\n        FROM adapter_status\n        ORDER BY last_run DESC\n      `);\n      return statuses;\n    } catch (error) {\n      console.error('[ERROR] Failed to fetch adapter statuses:', error);\n      return [];\n    }\n  }\n\n  async getRaceById(raceId: string): Promise<Race | null> {\n    if (!this.db) throw new Error('Database not connected');\n    try {\n      const race = await this.db.get<Race>(`\n        SELECT race_id, track_name, race_number, post_time,\n               checkmate_score, qualified, trifecta_factors_json,\n               raw_data_json, updated_at\n        FROM live_races\n        WHERE race_id = ?\n      `, raceId);\n      return race || null;\n    } catch (error) {\n      console.error('[ERROR] Failed to fetch race by ID:', error);\n      return null;\n    }\n  }\n}\n\n// Initialize Express and Socket.IO\nconst app = express();\nconst httpServer = createServer(app);\nconst io = new SocketServer(httpServer, {\n  cors: { origin: process.env.ALLOWED_ORIGINS || 'http://localhost:3000' }\n});\n\napp.use(cors());\napp.use(express.json());\n\nconst dbService = new DatabaseService();\n\n// API Endpoints\napp.get('/api/status', (req, res) => {\n  res.json({\n    status: 'online',\n    timestamp: new Date().toISOString(),\n    service: 'Checkmate API Gateway'\n  });\n});\n\napp.get('/api/races', async (req, res) => {\n  try {\n    const races = await dbService.getAllRaces();\n    res.json({ success: true, count: races.length, races });\n  } catch (error) {\n    res.status(500).json({ success: false, error: 'Failed to fetch races' });\n  }\n});\n\napp.get('/api/races/qualified', async (req, res) => {\n  try {\n    const races = await dbService.getQualifiedRaces();\n    res.json({ success: true, count: races.length, races });\n  } catch (error) {\n    res.status(500).json({ success: false, error: 'Failed to fetch qualified races' });\n  }\n});\n\napp.get('/api/races/:raceId', async (req, res) => {\n  try {\n    const race = await dbService.getRaceById(req.params.raceId);\n    if (race) {\n      res.json({ success: true, race });\n    } else {\n      res.status(404).json({ success: false, error: 'Race not found' });\n    }\n  } catch (error) {\n    res.status(500).json({ success: false, error: 'Failed to fetch race' });\n  }\n});\n\napp.get('/api/adapters/status', async (req, res) => {\n  try {\n    const statuses = await dbService.getAdapterStatuses();\n    res.json({ success: true, count: statuses.length, adapters: statuses });\n  } catch (error) {\n    res.status(500).json({ success: false, error: 'Failed to fetch adapter statuses' });\n  }\n});\n\n// WebSocket Connection Handling\nio.on('connection', (socket) => {\n  console.log(`[WebSocket] Client connected: ${socket.id}`);\n\n  dbService.getQualifiedRaces().then(races => {\n    socket.emit('races_update', { races });\n  });\n\n  dbService.getAdapterStatuses().then(statuses => {\n    socket.emit('adapters_update', { adapters: statuses });\n  });\n\n  socket.on('disconnect', () => {\n    console.log(`[WebSocket] Client disconnected: ${socket.id}`);\n  });\n\n  socket.on('request_update', async () => {\n    const races = await dbService.getQualifiedRaces();\n    const statuses = await dbService.getAdapterStatuses();\n    socket.emit('races_update', { races });\n    socket.emit('adapters_update', { adapters: statuses });\n  });\n});\n\n// Broadcast updates to all clients periodically\nasync function broadcastUpdates() {\n  try {\n    const races = await dbService.getQualifiedRaces();\n    const statuses = await dbService.getAdapterStatuses();\n\n    io.emit('races_update', { races });\n    io.emit('adapters_update', { adapters: statuses });\n  } catch (error) {\n    console.error('[ERROR] Failed to broadcast updates:', error);\n  }\n}\n\n// Start Server\nconst PORT = process.env.PORT || 8080;\n\nasync function startServer() {\n  try {\n    await dbService.connect();\n\n    httpServer.listen(PORT, () => {\n      console.log('='.repeat(70));\n      console.log(`  Checkmate API Gateway`);\n      console.log(`  Running on port ${PORT}`);\n      console.log(`  Database: ${dbService['dbPath']}`);\n      console.log('='.repeat(70));\n    });\n\n    setInterval(broadcastUpdates, 15000);\n\n  } catch (error) {\n    console.error('[FATAL] Failed to start server:', error);\n    process.exit(1);\n  }\n}\n\n// Graceful shutdown\nprocess.on('SIGINT', async () => {\n  console.log('\\n[INFO] Shutting down gracefully...');\n  httpServer.close();\n  process.exit(0);\n});\n\nprocess.on('SIGTERM', async () => {\n  console.log('\\n[INFO] Shutting down gracefully...');\n  httpServer.close();\n  process.exit(0);\n});\n\nstartServer();",
    "web_platform/api_gateway/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"commonjs\",\n    \"lib\": [\"ES2020\"],\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}",
    "web_platform/frontend/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"lib\": [\n      \"dom\",\n      \"dom.iterable\",\n      \"esnext\"\n    ],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": false,\n    \"noEmit\": true,\n    \"incremental\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ]\n  },\n  \"include\": [\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\",\n    \"out/types/**/*.ts\"\n  ],\n  \"exclude\": [\n    \"node_modules\"\n  ]\n}\n"
}