{
    ".github/dependabot.yml": "# To get started with Dependabot version updates, you'll need to specify which\n# package ecosystems to update and where the package manifests are located.\n# Please see the documentation for all configuration options:\n# https://docs.github.com/github/administering-a-repository/configuration-options-for-dependency-updates\n\nversion: 2\nupdates:\n  - package-ecosystem: \"pip\" # See documentation for possible values\n    directory: \"/\" # Location of package manifests\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/web_platform/frontend\"\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/electron\"\n    schedule:\n      interval: \"daily\"\n",
    ".github/workflows/build-electron-from-ws-claude.yml": "name: Build Electron App (Claude's Hardened Version)\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n\npermissions:\n  contents: read\n  actions: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  PYTHONUTF8: \"1\"\n\njobs:\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend for Electron'\n    runs-on: windows-latest\n    timeout-minutes: 15\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n      - name: Setup Node.js\n        uses: actions/setup-node@39370e3970a6d050c480ffad4ff0ed4d3fdee5af # v4.1.0\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'web_platform/frontend/package-lock.json'\n      - name: Frontend - Install & Build\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          cd web_platform/frontend\n          npm ci --prefer-offline\n          npm run build\n      - name: Verify Frontend Build\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $outDir = 'web_platform/frontend/out'\n          if (-not (Test-Path $outDir)) { throw \"\u274c FATAL: Build output directory 'out' not created\" }\n          if ((Get-ChildItem -Path $outDir -Recurse -File).Count -eq 0) { throw \"\u274c FATAL: Build output directory is empty\" }\n          Write-Host \"\u2705 Frontend build verified.\"\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: frontend-build-electron-${{ github.run_id }}\n          path: web_platform/frontend/out\n          retention-days: 1\n\n  build-backend:\n    name: '\ud83d\udc0d Build Backend for Electron'\n    runs-on: windows-latest\n    timeout-minutes: 20\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n      - name: Setup Python\n        uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'python_service/requirements-dev.txt'\n      - name: Backend - Install Dependencies\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          python -m pip install --upgrade pip\n          pip install -r python_service/requirements-dev.txt\n      - name: Backend - Build with PyInstaller\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          pyinstaller fortuna-backend-electron.spec --clean --log-level WARN --noconfirm\n      - name: Verify Backend Build\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $exePath = \"dist/fortuna-backend.exe\"\n          if (-not (Test-Path $exePath)) { throw \"\u274c FATAL: Backend executable not created at $exePath\" }\n          Write-Host \"\u2705 Backend executable verified.\"\n      - name: Upload Backend Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: backend-executable-electron-${{ github.run_id }}\n          path: dist/fortuna-backend.exe\n          retention-days: 1\n\n  smoke-test-electron:\n    name: '\ud83d\udd2c Smoke Test Electron App'\n    needs: [build-frontend, build-backend]\n    runs-on: windows-latest\n    timeout-minutes: 15\n    env:\n      SMOKE_SCREENSHOT_PATH: \"smoke-test-electron.png\"\n      SMOKE_FAILURE_SCREENSHOT_PATH: \"smoke-test-electron-FAILURE.png\"\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Download Artifacts\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          path: ./temp-artifacts/\n      \n      - name: Stage Artifacts for Electron\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          New-Item -ItemType Directory -Path \"electron/resources\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"electron/web-ui-build\" -Force | Out-Null\n\n          $frontendSource = \"./temp-artifacts/frontend-build-electron-${{ github.run_id }}/\"\n          $backendSource = \"./temp-artifacts/backend-executable-electron-${{ github.run_id }}/fortuna-backend.exe\"\n          \n          Copy-Item -Path $frontendSource* -Destination \"electron/web-ui-build/\" -Recurse -Force\n          Copy-Item -Path $backendSource -Destination \"electron/resources/fortuna-backend.exe\" -Force\n          \n          Write-Host \"\u2705 Frontend and backend artifacts staged for Electron.\"\n\n      - name: Setup Node.js for Electron\n        uses: actions/setup-node@39370e3970a6d050c480ffad4ff0ed4d3fdee5af # v4.1.0\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'electron/package-lock.json'\n\n      - name: Install Electron Dependencies\n        working-directory: electron\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          npm ci --prefer-offline\n\n      - name: Install Playwright for Python\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          pip install playwright\n          python -m playwright install chromium\n      \n      - name: Launch Electron App in Background\n        working-directory: electron\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $process = Start-Process \"npm\" -ArgumentList \"start\" -PassThru -RedirectStandardOutput \"electron-out.log\" -RedirectStandardError \"electron-err.log\"\n          Set-Content -Path \"electron.pid\" -Value $process.Id\n          Write-Host \"\u2705 Electron app launched with PID: $($process.Id)\"\n          Start-Sleep -Seconds 15 # Wait for app to initialize\n\n      - name: Verify Electron App with Playwright\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $script = @\"\n          import sys, os, asyncio\n          from playwright.async_api import async_playwright, expect\n\n          async def run_verification():\n              async with async_playwright() as p:\n                  # Electron apps launch on a random port, so we can't connect via URL.\n                  # Instead, we launch a browser context and assume the Electron window is the first one.\n                  browser = await p.chromium.launch(headless=False) # Must be headful to see window\n                  page = browser.contexts[0].pages[0]\n                  await page.wait_for_load_state('domcontentloaded', timeout=20000)\n                  \n                  try:\n                      await expect(page.locator(\"h1:has-text('Fortuna Faucet')\")).to_be_visible(timeout=10000)\n                      await page.screenshot(path=os.environ[\"SMOKE_SCREENSHOT_PATH\"])\n                      print(\"\u2705 Electron UI verification successful\")\n                      await browser.close()\n                      sys.exit(0)\n                  except Exception as e:\n                      print(f\"\u274c Error during Electron verification: {e}\", file=sys.stderr)\n                      await page.screenshot(path=os.environ[\"SMOKE_FAILURE_SCREENSHOT_PATH\"])\n                      await browser.close()\n                      sys.exit(1)\n\n          if __name__ == \"__main__\":\n              asyncio.run(run_verification())\n          \"@\n          Set-Content -Path \"verify_electron.py\" -Value $script\n          python verify_electron.py\n\n      - name: Upload Verification Artifacts\n        if: always()\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: smoke-test-evidence-electron-${{ github.run_id }}\n          path: |\n            ${{ env.SMOKE_SCREENSHOT_PATH }}\n            ${{ env.SMOKE_FAILURE_SCREENSHOT_PATH }}\n            electron/electron-out.log\n            electron/electron-err.log\n          if-no-files-found: warn\n\n      - name: Teardown Electron Process\n        if: always()\n        shell: pwsh\n        run: |\n          if (Test-Path \"electron.pid\") {\n            $pid = Get-Content \"electron.pid\"\n            Stop-Process -Id $pid -Force -ErrorAction SilentlyContinue\n            Write-Host \"\u2705 Stopped Electron process $pid\"\n          }\n\n  package-electron-msi:\n    name: ' MSI Package Electron App'\n    needs: [smoke-test-electron]\n    runs-on: windows-latest\n    timeout-minutes: 25\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Download Validated Artifacts\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          path: ./temp-artifacts/\n\n      - name: Stage Artifacts for Packaging\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          New-Item -ItemType Directory -Path \"electron/resources\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"electron/web-ui-build\" -Force | Out-Null\n          Copy-Item -Path \"./temp-artifacts/frontend-build-electron-${{ github.run_id }}/*\" -Destination \"electron/web-ui-build/\" -Recurse -Force\n          Copy-Item -Path \"./temp-artifacts/backend-executable-electron-${{ github.run_id }}/fortuna-backend.exe\" -Destination \"electron/resources/fortuna-backend.exe\" -Force\n          Write-Host \"\u2705 Artifacts staged for final packaging.\"\n\n      - name: Setup Node.js for Electron Builder\n        uses: actions/setup-node@39370e3970a6d050c480ffad4ff0ed4d3fdee5af # v4.1.0\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'electron/package-lock.json'\n      \n      - name: Install Dependencies\n        working-directory: electron\n        run: npm ci --prefer-offline\n\n      - name: Package MSI Installer\n        working-directory: electron\n        run: npx electron-builder --win --publish=never\n\n      - name: Verify MSI Creation\n        shell: pwsh\n        run: |\n          $msiFiles = Get-ChildItem -Path \"electron/dist/*.msi\"\n          if ($msiFiles.Count -eq 0) { throw \"\u274c FATAL: No MSI file created\" }\n          Write-Host \"\u2705 MSI installer created successfully.\"\n      \n      - name: Upload Final MSI Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: fortuna-installer-electron-claude-${{ github.run_id }}\n          path: electron/dist/*.msi\n          retention-days: 7\n",
    ".github/workflows/build-web-service-msi-claude.yml": "name: Build Fortuna Faucet MSI (WiX v4) - Claude\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n\n# Restrict permissions to minimum necessary\npermissions:\n  contents: read\n  actions: read\n\n# Prevent concurrent builds on same ref\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  PYTHONUTF8: \"1\"\n  # Cache keys for better cache hits\n  FRONTEND_CACHE_KEY: ${{ hashFiles('web_service/frontend/package-lock.json') }}\n  BACKEND_CACHE_KEY: ${{ hashFiles('web_service/backend/requirements-dev.txt') }}\n\njobs:\n  # ============================================================================\n  # JOB 1: BUILD FRONTEND\n  # ============================================================================\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend'\n    runs-on: windows-latest\n    timeout-minutes: 15\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n        with:\n          fetch-depth: 0\n\n      - name: Setup Node.js\n        uses: actions/setup-node@39370e3970a6d050c480ffad4ff0ed4d3fdee5af # v4.1.0\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'web_service/frontend/package-lock.json'\n\n      - name: Frontend - Install & Build\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          cd web_service/frontend\n          npm ci --prefer-offline\n          npm run build\n\n      - name: Verify Frontend Build\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $outDir = 'web_service/frontend/out'\n          if (-not (Test-Path $outDir)) {\n            Write-Host \"\u274c FATAL: Build output directory 'out' not created\" -ForegroundColor Red\n            exit 1\n          }\n          $fileCount = (Get-ChildItem -Path $outDir -Recurse -File | Measure-Object).Count\n          if ($fileCount -eq 0) {\n            Write-Host \"\u274c FATAL: Build output directory is empty\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 Frontend build verified: $fileCount files created\" -ForegroundColor Green\n\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: frontend-build-${{ github.run_id }}\n          path: web_service/frontend/out\n          retention-days: 1\n          if-no-files-found: error\n\n  # ============================================================================\n  # JOB 2: BUILD BACKEND\n  # ============================================================================\n  build-backend:\n    name: '\ud83d\udc0d Build Backend'\n    needs: [build-frontend]\n    runs-on: windows-latest\n    timeout-minutes: 20\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n        with:\n          fetch-depth: 0\n\n      - name: Download Frontend Artifact\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: frontend-build-${{ github.run_id }}\n          path: web_service/frontend/out\n\n      - name: Setup Python\n        uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'web_service/backend/requirements-dev.txt'\n\n      - name: Backend - Install Dependencies\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          python -m pip install --upgrade pip\n          pip install -r web_service/backend/requirements-dev.txt\n\n      - name: Verify PyInstaller Entry Point\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $specFile = \"fortuna-webservice.spec\"\n          if (-not (Test-Path $specFile)) {\n            Write-Host \"\u274c FATAL: Spec file not found: $specFile\" -ForegroundColor Red\n            exit 1\n          }\n          $specContent = Get-Content $specFile -Raw\n          if ($specContent -match \"Analysis\\(\\s*\\[?'([^']+)'\") {\n            $entryPoint = $matches[1]\n            $entryPointPath = $entryPoint -replace '/', '\\'\n            if (Test-Path $entryPointPath) {\n              Write-Host \"\u2705 Entry point file exists: $entryPointPath\" -ForegroundColor Green\n            } else {\n              Write-Host \"\u274c FATAL: Entry point file NOT found: $entryPointPath\" -ForegroundColor Red\n              exit 1\n            }\n          } else {\n            Write-Host \"\u26a0\ufe0f WARNING: Could not parse entry point from spec file\" -ForegroundColor Yellow\n          }\n\n      - name: Backend - Build with PyInstaller\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          pyinstaller fortuna-webservice.spec --clean --log-level WARN --noconfirm\n\n      - name: Verify Backend Build\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $exePath = \"dist/fortuna-webservice.exe\"\n          if (-not (Test-Path $exePath)) {\n            Write-Host \"\u274c FATAL: Backend executable not created at $exePath\" -ForegroundColor Red\n            exit 1\n          }\n          $fileSize = (Get-Item $exePath).Length / 1MB\n          Write-Host \"\u2705 Backend executable verified: $($fileSize.ToString('F2')) MB\" -ForegroundColor Green\n\n      - name: Upload Backend Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: backend-executable-${{ github.run_id }}\n          path: dist/fortuna-webservice.exe\n          retention-days: 1\n          if-no-files-found: error\n\n  # ============================================================================\n  # JOB 3: SMOKE TEST SERVICE\n  # ============================================================================\n  smoke-test-service:\n    name: '\ud83d\udd2c Smoke Test Service'\n    needs: [build-backend]\n    runs-on: windows-latest\n    timeout-minutes: 15\n    env:\n      API_KEY: \"a_secure_test_api_key_that_is_long_enough_for_smoke_test\"\n      FORTUNA_MODE: \"webservice\"\n      FORTUNA_PORT: 8088\n      SMOKE_FRONTEND_URL: \"http://localhost:8088\"\n      SMOKE_HEADING_SELECTOR: \"h1:has-text('Fortuna Faucet')\"\n      SMOKE_SCREENSHOT_PATH: \"smoke-test-screenshot.png\"\n      SMOKE_FAILURE_SCREENSHOT_PATH: \"smoke-test-screenshot-FAILURE.png\"\n    steps:\n      - name: Download Backend Artifact\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: backend-executable-${{ github.run_id }}\n          path: .\n\n      - name: Configure Firewall\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          New-NetFirewallRule -DisplayName \"Allow Fortuna Smoke Test\" `\n            -Direction Inbound `\n            -Action Allow `\n            -Protocol TCP `\n            -LocalPort ${{ env.FORTUNA_PORT }} `\n            -ErrorAction SilentlyContinue\n          Write-Host \"\u2705 Firewall rule configured for port ${{ env.FORTUNA_PORT }}\" -ForegroundColor Green\n\n      - name: Start Web Service\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $backendProcess = Start-Process -FilePath \"./fortuna-webservice.exe\" `\n            -PassThru `\n            -RedirectStandardOutput \"backend-out.log\" `\n            -RedirectStandardError \"backend-err.log\"\n          Set-Content -Path \"backend.pid\" -Value $backendProcess.Id\n          Write-Host \"\u2705 Backend started with PID: $($backendProcess.Id)\" -ForegroundColor Green\n          Start-Sleep -Seconds 10\n\n      - name: Health Check\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Continue\"\n          $healthUrl = \"http://127.0.0.1:${{ env.FORTUNA_PORT }}/health\"\n          $maxAttempts = 15\n          $delaySeconds = 2\n          $success = $false\n\n          For ($i = 1; $i -le $maxAttempts; $i++) {\n            try {\n              $response = Invoke-WebRequest -Uri $healthUrl -UseBasicParsing -TimeoutSec 2\n              if ($response.StatusCode -eq 200) {\n                Write-Host \"\u2705 Health check passed on attempt $i\" -ForegroundColor Green\n                $success = $true\n                break\n              }\n            } catch {\n              Write-Host \"Attempt $i of $maxAttempts failed. Retrying in $delaySeconds seconds...\" -ForegroundColor Yellow\n              Start-Sleep -Seconds $delaySeconds\n            }\n          }\n\n          if (-not $success) {\n            Write-Host \"\u274c Health check failed after $maxAttempts attempts\" -ForegroundColor Red\n            exit 1\n          }\n\n      - name: Setup Playwright\n        if: success() || failure()\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          pip install playwright\n          python -m playwright install chromium\n\n      - name: Frontend UI Verification\n        if: success() || failure()\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $scriptContent = @\"\n          import sys, os\n          from playwright.sync_api import sync_playwright, expect\n\n          def run_verification():\n              with sync_playwright() as p:\n                  browser = p.chromium.launch()\n                  context = browser.new_context()\n                  context.tracing.start(screenshots=True, snapshots=True)\n                  page = context.new_page()\n                  try:\n                      url = os.environ[\"SMOKE_FRONTEND_URL\"]\n                      page.goto(url, wait_until='networkidle', timeout=20000)\n                      heading = page.locator(os.environ[\"SMOKE_HEADING_SELECTOR\"])\n                      expect(heading).to_be_visible(timeout=10000)\n                      page.screenshot(path=os.environ[\"SMOKE_SCREENSHOT_PATH\"])\n                      print(\"\u2705 Frontend verification successful\")\n                      context.tracing.stop(path = \"trace.zip\")\n                      sys.exit(0)\n                  except Exception as e:\n                      print(f\"\u274c Error: {e}\", file=sys.stderr)\n                      page.screenshot(path=os.environ[\"SMOKE_FAILURE_SCREENSHOT_PATH\"])\n                      context.tracing.stop(path = \"trace.zip\")\n                      sys.exit(1)\n                  finally:\n                      browser.close()\n\n          if __name__ == \"__main__\":\n              run_verification()\n          \"@\n          Set-Content -Path \"verify_frontend.py\" -Value $scriptContent\n          python verify_frontend.py\n\n      - name: Upload Verification Screenshot\n        if: always()\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: smoke-test-screenshot-${{ github.run_id }}\n          path: |\n            ${{ env.SMOKE_SCREENSHOT_PATH }}\n            ${{ env.SMOKE_FAILURE_SCREENSHOT_PATH }}\n            trace.zip\n          if-no-files-found: warn\n\n      - name: Collect Forensic Logs\n        if: always()\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Continue\"\n          $logFile = \"forensic-analysis.log\"\n\n          \"=== FORENSIC ANALYSIS ===\" | Out-File $logFile -Encoding utf8\n          \"`n--- ENVIRONMENT VARIABLES ---\" | Out-File $logFile -Append -Encoding utf8\n          Get-ChildItem Env: | Sort-Object Name | Format-Table -AutoSize | Out-String -Width 4096 | Out-File $logFile -Append -Encoding utf8\n\n          \"`n--- RUNNING PROCESSES ---\" | Out-File $logFile -Append -Encoding utf8\n          Get-Process | Format-Table -AutoSize | Out-String -Width 4096 | Out-File $logFile -Append -Encoding utf8\n\n          \"`n--- NETWORK CONNECTIONS ---\" | Out-File $logFile -Append -Encoding utf8\n          netstat -ano | Out-File $logFile -Append -Encoding utf8\n\n          \"`n--- BACKEND STDOUT ---\" | Out-File $logFile -Append -Encoding utf8\n          if (Test-Path backend-out.log) { Get-Content backend-out.log -Raw | Out-File $logFile -Append -Encoding utf8 }\n\n          \"`n--- BACKEND STDERR ---\" | Out-File $logFile -Append -Encoding utf8\n          if (Test-Path backend-err.log) { Get-Content backend-err.log -Raw | Out-File $logFile -Append -Encoding utf8 }\n\n          Write-Host \"\u2705 Forensic analysis written to $logFile\" -ForegroundColor Green\n\n      - name: Upload Forensic Analysis\n        if: always()\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: forensic-analysis-${{ github.run_id }}\n          path: |\n            forensic-analysis.log\n            backend-out.log\n            backend-err.log\n          retention-days: 7\n          if-no-files-found: ignore\n\n      - name: Teardown Processes\n        if: always()\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Continue\"\n          if (Test-Path \"backend.pid\") {\n            $pid = Get-Content \"backend.pid\"\n            Stop-Process -Id $pid -Force -ErrorAction SilentlyContinue\n            Write-Host \"\u2705 Stopped process $pid\" -ForegroundColor Green\n          }\n          Remove-NetFirewallRule -DisplayName \"Allow Fortuna Smoke Test\" -ErrorAction SilentlyContinue\n\n  # ============================================================================\n  # JOB 4: PACKAGE SERVICE MSI\n  # ============================================================================\n  package-msi-service:\n    name: '\ud83d\udcbf Package Service MSI'\n    needs: [smoke-test-service]\n    runs-on: windows-latest\n    timeout-minutes: 20\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n        with:\n          fetch-depth: 0\n\n      - name: Download Backend Executable\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: backend-executable-${{ github.run_id }}\n          path: ./dist\n\n      - name: Stage Build Artifacts\n        id: stage_files\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $staging = \"build_wix/staging\"\n          New-Item -ItemType Directory -Path $staging -Force | Out-Null\n\n          # Move backend executable\n          Move-Item -Path \"./dist/fortuna-webservice.exe\" -Destination \"$staging/fortuna-webservice.exe\" -Force\n\n          # Determine MSI name\n          $branchName = \"${{ github.ref_name }}\"\n          $msiName = if ($branchName -match \"main\") {\n            \"Fortuna-WebService-Nightly.msi\"\n          } else {\n            \"Fortuna-WebService-$($branchName -replace '/', '-').msi\"\n          }\n\n          Write-Host \"MSI will be named: $msiName\" -ForegroundColor Green\n          \"msi_name=$msiName\" | Out-File -FilePath $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n      - name: Setup .NET 8 SDK\n        uses: actions/setup-dotnet@3e891b0cb619bf60e2c25674b222b8940e2c1c25 # v4.1.0\n        with:\n          dotnet-version: '8.0.x'\n\n      - name: Remove Conflicting WXS File\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $conflictFile = \"build_wix/Product_WithoutService.wxs\"\n          if (Test-Path $conflictFile) {\n            Remove-Item $conflictFile -Force\n            Write-Host \"\u2705 Removed conflicting file: $conflictFile\" -ForegroundColor Green\n          }\n\n      - name: Generate WiX Project File\n        working-directory: build_wix\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $msiOutputName = \"${{ steps.stage_files.outputs.msi_name }}\".Replace('.msi', '')\n          $wixProjContent = @\"\n          <Project Sdk=\"WixToolset.Sdk/4.0.5\">\n            <PropertyGroup>\n              <OutputName>$msiOutputName</OutputName>\n              <OutputType>Package</OutputType>\n              <DefineConstants>SourceDir=staging</DefineConstants>\n              <Platforms>x64</Platforms>\n              <EnableDefaultCompileItems>false</EnableDefaultCompileItems>\n            </PropertyGroup>\n            <ItemGroup>\n              <PackageReference Include=\"WixToolset.Util.wixext\" Version=\"4.0.5\" />\n              <PackageReference Include=\"WixToolset.Firewall.wixext\" Version=\"4.0.5\" />\n              <PackageReference Include=\"WixToolset.UI.wixext\" Version=\"4.0.5\" />\n            </ItemGroup>\n            <ItemGroup>\n              <Compile Include=\"Product_WithService.wxs\" />\n            </ItemGroup>\n          </Project>\n          \"@\n          Set-Content -Path \"Fortuna.wixproj\" -Value $wixProjContent -Encoding UTF8\n          Write-Host \"\u2705 Generated WiX project file\" -ForegroundColor Green\n\n      - name: Build MSI\n        working-directory: build_wix\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          $packageVersion = \"${{ github.run_number }}.${{ github.run_attempt }}.0\"\n          dotnet build Fortuna.wixproj -c Release -p:Platform=x64 -p:Version=$packageVersion\n\n          $msiPath = \"bin/x64/Release/${{ steps.stage_files.outputs.msi_name }}\"\n          if (-not (Test-Path $msiPath)) {\n            Write-Host \"\u274c FATAL: Service MSI was not created at $msiPath\" -ForegroundColor Red\n            exit 1\n          }\n\n          New-Item -ItemType Directory -Path \"dist\" -Force | Out-Null\n          Copy-Item -Path $msiPath -Destination \"dist/\" -Force\n          Write-Host \"\u2705 MSI built successfully\" -ForegroundColor Green\n\n      - name: Upload MSI Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: fortuna-installer-service-${{ github.run_id }}\n          path: build_wix/dist/*.msi\n          retention-days: 7\n          if-no-files-found: error\n\n  # ============================================================================\n  # JOB 5: CREATE GITHUB RELEASE (only on tags)\n  # ============================================================================\n  create-release:\n    name: '\ud83d\ude80 Create GitHub Release'\n    needs: [package-msi-service]\n    runs-on: ubuntu-latest\n    if: startsWith(github.ref, 'refs/tags/')\n    permissions:\n      contents: write\n    steps:\n      - name: Download MSI Artifact\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          pattern: fortuna-installer-service-*\n          path: installers/\n          merge-multiple: true\n\n      - name: Create Release\n        uses: softprops/action-gh-release@c062e08bd532815e2082a85e87e3ef29c3e6d191 # v2.2.0\n        with:\n          files: installers/*.msi\n          body: |\n            \ud83d\ude80 **Fortuna Faucet Production Release**\n\n            Native Windows Service Installer.\n\n            ### Installation\n            1. Download the MSI installer below\n            2. Run the installer with administrator privileges\n            3. Follow the setup wizard\n\n            ### What's Included\n            - FastAPI backend service\n            - Next.js frontend (static build)\n            - Windows Service integration\n            - Firewall configuration\n\n          draft: false\n          prerelease: false\n          generate_release_notes: true\n",
    ".github/workflows/build-electron-msi-grok.yml": "name: Build Fortuna Faucet MSI (Electron) - Grok\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n\npermissions:\n  contents: write\n  actions: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  PYTHONUTF8: \"1\"\n\njobs:\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend'\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n        with:\n          fetch-depth: 0\n      - name: Setup Node.js\n        uses: actions/setup-node@39370e3970a6d050c480ffad4ff0ed4d3fdee5af # v4.1.0\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'web_platform/frontend/package-lock.json'\n      - name: Frontend - Install & Build\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          cd web_platform/frontend\n          npm ci\n          npm run build\n      - name: Verify Frontend Build\n        shell: pwsh\n        run: |\n          if (-not (Test-Path 'web_platform/frontend/out/index.html')) { throw \"\u274c Missing index.html\" }\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: frontend-build\n          path: web_platform/frontend/out\n          retention-days: 1\n\n  build-and-test:\n    name: '\ud83d\udc0d Build & Smoke Test'\n    needs: [build-frontend]\n    runs-on: windows-latest\n    env:\n      SMOKE_FRONTEND_URL: \"http://localhost:3000\"\n      SMOKE_HEADING_SELECTOR: \"h1\"\n      SMOKE_SCREENSHOT_PATH: \"smoke-test.png\"\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n      \n      - name: Setup Python\n        uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'python_service/requirements.txt'\n\n      - name: Download Frontend Artifact\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: frontend-build\n          path: web_platform/frontend/out\n\n      - name: Install Dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r python_service/requirements.txt\n          pip install playwright pytest-playwright\n\n      - name: Get Playwright Version\n        id: playwright-version\n        shell: pwsh\n        run: echo \"VERSION=$(python -c 'from importlib.metadata import version; print(version(\"playwright\"))')\" >> $env:GITHUB_OUTPUT\n\n      - name: Cache Playwright Browsers\n        uses: actions/cache@88522ab9f39a2ea568f7027ed67a8d8f9e9d59c3 # v4.0.2\n        id: playwright-cache\n        with:\n          path: C:\\Users\\runneradmin\\AppData\\Local\\ms-playwright\n          key: ${{ runner.os }}-playwright-${{ steps.playwright-version.outputs.VERSION }}\n\n      - name: Install Playwright Browsers\n        if: steps.playwright-cache.outputs.cache-hit != 'true'\n        run: python -m playwright install --with-deps chromium\n\n      - name: Backend - Build with PyInstaller\n        run: pyinstaller fortuna-backend-electron.spec --clean --log-level WARN --noconfirm\n\n      - name: Run Electron App (Background)\n        shell: pwsh\n        run: |\n          cd electron\n          npm ci\n          $p = Start-Process -FilePath \"npm\" -ArgumentList \"start\" -PassThru -RedirectStandardOutput \"electron.log\" -RedirectStandardError \"electron.err\"\n          $p.Id | Out-File \"electron.pid\"\n          Start-Sleep -Seconds 10\n\n      - name: '\ud83d\udcf8 Playwright Verification'\n        shell: pwsh\n        run: |\n          $script = @\"\n          import sys, os, time\n          from playwright.sync_api import sync_playwright, expect\n\n          url = os.environ[\"SMOKE_FRONTEND_URL\"]\n          print(f\"Testing URL: {url}\")\n\n          with sync_playwright() as p:\n              browser = p.chromium.launch()\n              context = browser.new_context()\n              context.tracing.start(screenshots=True, snapshots=True)\n              page = context.new_page()\n              try:\n                  page.goto(url, wait_until='domcontentloaded', timeout=10000)\n                  expect(page.locator(\"body\")).to_be_visible(timeout=10000)\n                  page.screenshot(path=os.environ[\"SMOKE_SCREENSHOT_PATH\"])\n                  print(\"\u2705 Screenshot captured.\")\n                  context.tracing.stop(path=\"trace.zip\")\n              except Exception as e:\n                  print(f\"\u274c Error: {e}\")\n                  page.screenshot(path=\"FAILURE.png\")\n                  context.tracing.stop(path=\"trace.zip\")\n                  sys.exit(1)\n              finally:\n                  browser.close()\n          \"@\n          Set-Content -Path \"verify.py\" -Value $script\n          python verify.py\n\n      - name: Upload Screenshot & Logs\n        if: always()\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: smoke-test-evidence\n          path: |\n            *.png\n            electron.log\n            electron.err\n            trace.zip\n\n      - name: Cleanup Process\n        if: always()\n        shell: pwsh\n        run: if (Test-Path \"electron.pid\") { Stop-Process -Id (Get-Content \"electron.pid\") -Force -ErrorAction SilentlyContinue }\n\n      - name: Upload Validated EXE\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: backend-executable\n          path: dist/fortuna-backend.exe\n\n  package-electron-msi:\n    name: '\ud83d\udce6 Package Electron MSI'\n    needs: [build-and-test]\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n      \n      - name: Download Validated Executable\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: backend-executable\n          path: electron/resources\n\n      - name: Setup Node.js for Electron Builder\n        uses: actions/setup-node@39370e3970a6d050c480ffad4ff0ed4d3fdee5af # v4.1.0\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'electron/package.json'\n\n      - name: Build Electron MSI\n        working-directory: electron\n        run: npx electron-builder --win --publish=never\n\n      - name: Verify MSI\n        shell: pwsh\n        run: if (-not (Test-Path \"dist/*.msi\")) { throw \"\u274c MSI build failed\" }\n\n      - name: Upload MSI\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: fortuna-installer\n          path: electron/dist/*.msi\n          if-no-files-found: error\n\n  create-release:\n    name: '\ud83d\ude80 Create Release'\n    needs: [package-electron-msi]\n    runs-on: ubuntu-latest\n    if: startsWith(github.ref, 'refs/tags/')\n    steps:\n      - name: Download MSI\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: fortuna-installer\n          path: dist\n      - name: Create Release\n        uses: softprops/action-gh-release@c062e08bd532815e2082a85e87e3ef29c3e6d191 # v2.2.0\n        with:\n          files: dist/*.msi\n          generate_release_notes: true\n",
    ".github/workflows/build-web-service-msi-grok.yml": "name: Build Fortuna Faucet MSI (WiX v4) - Grok\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n\npermissions:\n  contents: write\n  actions: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  PYTHONUTF8: \"1\"\n\njobs:\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend'\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n        with:\n          fetch-depth: 0\n      - name: Setup Node.js\n        uses: actions/setup-node@39370e3970a6d050c480ffad4ff0ed4d3fdee5af # v4.1.0\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'web_service/frontend/package-lock.json'\n      - name: Frontend - Install & Build\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          cd web_service/frontend\n          npm ci\n          npm run build\n      - name: Verify Frontend Build\n        shell: pwsh\n        run: |\n          if (-not (Test-Path 'web_service/frontend/out/index.html')) { throw \"\u274c Missing index.html\" }\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: frontend-build\n          path: web_service/frontend/out\n          retention-days: 1\n\n  build-and-test:\n    name: '\ud83d\udc0d Build & Smoke Test'\n    needs: [build-frontend]\n    runs-on: windows-latest\n    env:\n      FORTUNA_PORT: 8088\n      SMOKE_FRONTEND_URL: \"http://localhost:8088\"\n      SMOKE_HEADING_SELECTOR: \"h1\"\n      SMOKE_SCREENSHOT_PATH: \"smoke-test.png\"\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Setup Python\n        id: setup-python\n        uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'web_service/backend/requirements-dev.txt'\n\n      - name: Download Frontend Artifact\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: frontend-build\n          path: web_service/frontend/out\n\n      - name: Install Dependencies\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Stop\"\n          ${{ steps.setup-python.outputs.python-path }} -m pip install --upgrade pip\n          ${{ steps.setup-python.outputs.python-path }} -m pip install -r web_service/backend/requirements-dev.txt\n          ${{ steps.setup-python.outputs.python-path }} -m pip install playwright pytest-playwright\n\n      - name: Get Playwright Version\n        id: playwright-version\n        shell: pwsh\n        run: echo \"VERSION=$(${{ steps.setup-python.outputs.python-path }} -c 'from importlib.metadata import version; print(version(\"playwright\"))')\" >> $env:GITHUB_OUTPUT\n\n      - name: Cache Playwright Browsers\n        uses: actions/cache@88522ab9f39a2ea568f7027ed67a8d8f9e9d59c3 # v4.0.2\n        id: playwright-cache\n        with:\n          path: C:\\Users\\runneradmin\\AppData\\Local\\ms-playwright\n          key: ${{ runner.os }}-playwright-${{ steps.playwright-version.outputs.VERSION }}\n\n      - name: Install Playwright Browsers\n        if: steps.playwright-cache.outputs.cache-hit != 'true'\n        shell: pwsh\n        run: ${{ steps.setup-python.outputs.python-path }} -m playwright install --with-deps chromium\n\n      - name: Create Web Service PyInstaller Spec\n        shell: pwsh\n        run: |\n          cp fortuna-backend-electron.spec fortuna-webservice.spec\n          (Get-Content fortuna-webservice.spec) -replace 'python_service/main.py', 'web_service/backend/main.py' | Set-Content fortuna-webservice.spec\n          (Get-Content fortuna-webservice.spec) -replace 'python_service/data', 'web_service/backend/data' | Set-Content fortuna-webservice.spec\n          (Get-Content fortuna-webservice.spec) -replace 'python_service/json', 'web_service/backend/json' | Set-Content fortuna-webservice.spec\n          (Get-Content fortuna-webservice.spec) -replace 'python_service/adapters', 'web_service/backend/adapters' | Set-Content fortuna-webservice.spec\n          (Get-Content fortuna-webservice.spec) -replace 'fortuna-backend', 'fortuna-webservice' | Set-Content fortuna-webservice.spec\n\n      - name: Backend - Build with PyInstaller\n        shell: pwsh\n        run: ${{ steps.setup-python.outputs.python-path }} -m pyinstaller fortuna-webservice.spec --clean --log-level WARN --noconfirm\n\n      - name: '\ud83d\udee1\ufe0f Open Firewall'\n        shell: pwsh\n        run: New-NetFirewallRule -DisplayName \"SmokeTest\" -Direction Inbound -Action Allow -Protocol TCP -LocalPort ${{ env.FORTUNA_PORT }}\n\n      - name: Run Backend (Background)\n        shell: pwsh\n        run: |\n          New-Item -ItemType Directory -Path \"data\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"logs\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"json\" -Force | Out-Null\n          Write-Host \"\ud83d\udcc2 Runtime directories created.\"\n          $env:FORTUNA_PORT = \"${{ env.FORTUNA_PORT }}\"\n          $env:FORTUNA_MODE = \"webservice\"\n          $p = Start-Process -FilePath \"dist/fortuna-webservice.exe\" -PassThru -RedirectStandardOutput \"backend.log\" -RedirectStandardError \"backend.err\"\n          $p.Id | Out-File \"backend.pid\"\n          Write-Host \"\ud83d\ude80 Service started with PID $($p.Id) on port $env:FORTUNA_PORT\"\n          Start-Sleep -Seconds 5\n\n      - name: Health Check\n        shell: pwsh\n        run: |\n          $ErrorActionPreference = \"Continue\"\n          $healthUrl = \"http://127.0.0.1:${{ env.FORTUNA_PORT }}/health\"\n          $maxAttempts = 15\n          $delaySeconds = 2\n          $success = $false\n\n          For ($i = 1; $i -le $maxAttempts; $i++) {\n            try {\n              $response = Invoke-WebRequest -Uri $healthUrl -UseBasicParsing -TimeoutSec 2\n              if ($response.StatusCode -eq 200) {\n                Write-Host \"\u2705 Health check passed on attempt $i\" -ForegroundColor Green\n                $success = $true\n                break\n              }\n            } catch {\n              Write-Host \"Attempt $i of $maxAttempts failed. Retrying in $delaySeconds seconds...\" -ForegroundColor Yellow\n              Start-Sleep -Seconds $delaySeconds\n            }\n          }\n\n          if (-not $success) {\n            Write-Host \"\u274c Health check failed after $maxAttempts attempts\" -ForegroundColor Red\n            exit 1\n          }\n      \n      - name: '\ud83d\udcf8 Playwright Verification'\n        shell: pwsh\n        run: |\n          $script = @\"\n          import sys, os, time\n          from playwright.sync_api import sync_playwright, expect\n\n          url = os.environ[\"SMOKE_FRONTEND_URL\"]\n          print(f\"Testing URL: {url}\")\n\n          with sync_playwright() as p:\n              browser = p.chromium.launch()\n              context = browser.new_context()\n              context.tracing.start(screenshots=True, snapshots=True)\n              page = context.new_page()\n              try:\n                  for i in range(10):\n                      try:\n                          page.goto(url, wait_until='domcontentloaded', timeout=5000)\n                          break\n                      except:\n                          print(f\"Waiting for server... ({i+1}/10)\")\n                          time.sleep(2)\n                  \n                  expect(page.locator(\"body\")).to_be_visible(timeout=10000)\n                  page.screenshot(path=os.environ[\"SMOKE_SCREENSHOT_PATH\"])\n                  print(\"\u2705 Screenshot captured.\")\n                  context.tracing.stop(path=\"trace.zip\")\n              except Exception as e:\n                  print(f\"\u274c Error: {e}\")\n                  page.screenshot(path=\"FAILURE.png\")\n                  context.tracing.stop(path=\"trace.zip\")\n                  sys.exit(1)\n              finally:\n                  browser.close()\n          \"@\n          Set-Content -Path \"verify.py\" -Value $script\n          ${{ steps.setup-python.outputs.python-path }} verify.py\n\n      - name: Upload Screenshot\n        if: always()\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: smoke-test-evidence\n          path: |\n            *.png\n            backend.log\n            backend.err\n            trace.zip\n\n      - name: '\ud83d\udd75\ufe0f Inspect Backend Logs (On Failure)'\n        if: failure()\n        shell: pwsh\n        run: |\n          Write-Host \"::group::Backend Error Log (Why did it crash?)\"\n          if (Test-Path \"backend.err\") { Get-Content \"backend.err\" } else { Write-Host \"No error log found.\" }\n          Write-Host \"::endgroup::\"\n\n          Write-Host \"::group::Backend Output Log\"\n          if (Test-Path \"backend.log\") { Get-Content \"backend.log\" }\n          Write-Host \"::endgroup::\"\n\n      - name: Upload Validated EXE\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: backend-executable\n          path: dist/fortuna-webservice.exe\n\n      - name: Cleanup Firewall & Process\n        if: always()\n        shell: pwsh\n        run: |\n          if (Test-Path \"backend.pid\") { Stop-Process -Id (Get-Content \"backend.pid\") -Force -ErrorAction SilentlyContinue }\n          Remove-NetFirewallRule -DisplayName \"SmokeTest\" -ErrorAction SilentlyContinue\n          Remove-NetFirewallRule -DisplayName \"Allow Fortuna Smoke Test\" -ErrorAction SilentlyContinue\n\n  package-msi-service:\n    name: '\ud83d\udcbf Package Service MSI'\n    needs: [build-and-test]\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Download Validated Executable\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: backend-executable\n          path: build_wix/staging\n\n      - name: Setup .NET 8 (for WiX)\n        uses: actions/setup-dotnet@3e891b0cb619bf60e2c25674b222b8940e2c1c25 # v4.1.0\n        with:\n          dotnet-version: '8.0.x'\n      \n      - name: Copy WXS File\n        shell: pwsh\n        run: cp wix/product_webservice.wxs build_wix/Product_WithService.wxs\n\n      - name: Remove Conflicting WXS\n        shell: pwsh\n        run: |\n           if (Test-Path \"build_wix/Product_WithoutService.wxs\") { Remove-Item \"build_wix/Product_WithoutService.wxs\" -Force }\n\n      - name: Generate WiX Project File (Dynamic Name)\n        working-directory: build_wix\n        shell: pwsh\n        run: |\n          $msiName = \"Fortuna-WebService-${{ github.run_number }}\"\n          \n          $wixProjContent = @\"\n          <Project Sdk=\"WixToolset.Sdk/4.0.5\">\n            <PropertyGroup>\n              <OutputName>$msiName</OutputName>\n              <OutputType>Package</OutputType>\n              <DefineConstants>SourceDir=staging</DefineConstants>\n              <Platforms>x64</Platforms>\n              <EnableDefaultCompileItems>false</EnableDefaultCompileItems>\n            </PropertyGroup>\n            <ItemGroup>\n              <PackageReference Include=\"WixToolset.Util.wixext\" Version=\"4.0.5\" />\n              <PackageReference Include=\"WixToolset.Firewall.wixext\" Version=\"4.0.5\" />\n              <PackageReference Include=\"WixToolset.UI.wixext\" Version=\"4.0.5\" />\n            </ItemGroup>\n            <ItemGroup>\n              <Compile Include=\"Product_WithService.wxs\" />\n            </ItemGroup>\n          </Project>\n          \"@\n          Set-Content -Path \"Fortuna.wixproj\" -Value $wixProjContent -Encoding UTF8\n\n      - name: Build MSI (Inject Version)\n        working-directory: build_wix\n        run: |\n          $packageVersion = \"${{ github.run_number }}.${{ github.run_attempt }}.0\"\n          dotnet build Fortuna.wixproj -c Release -p:Platform=x64 -p:Version=$packageVersion\n\n      - name: Upload MSI\n        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3\n        with:\n          name: fortuna-installer\n          path: build_wix/bin/x64/Release/*.msi\n          if-no-files-found: error\n\n  create-release:\n    name: '\ud83d\ude80 Create Release'\n    needs: [package-msi-service]\n    runs-on: ubuntu-latest\n    if: startsWith(github.ref, 'refs/tags/')\n    steps:\n      - name: Download MSI\n        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8\n        with:\n          name: fortuna-installer\n          path: dist\n      - name: Create Release\n        uses: softprops/action-gh-release@c062e08bd532815e2082a85e87e3ef29c3e6d191 # v2.2.0\n        with:\n          files: dist/*.msi\n          generate_release_notes: true\n",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `fortuna`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n\n---\n\n## The Age of Perfection (The Great Simplification)\n\nThe Penta-Hybrid architecture, while a triumph of technical integration, proved to be a strategic dead end. Its complexity became a fortress, making rapid iteration and onboarding of new intelligence (both human and AI) prohibitively expensive. The kingdom was powerful but brittle.\n\nA new doctrine was forged: **Simplicity is the ultimate sophistication.**\n\nThe decision was made to execute \"The Great Simplification.\" The multi-language backend (Python, Rust, Go) was decommissioned. The kingdom was reforged upon a new, elegant, and vastly more powerful two-pillar system:\n\n1.  **A Unified Python Backend:** A single, asynchronous Python service, built on FastAPI, would serve as the kingdom's engine.\n2.  **A Modern TypeScript Frontend:** A dedicated Next.js application would serve as the kingdom's command deck.\n\nThis act of creative destruction liberated the project, enabling a new era of unprecedented velocity.\n\n---\n\n## The Three-Pillar Doctrine\n\nWith the new two-pillar foundation in place, the backend itself was perfected into a three-pillar intelligence engine, a concept that defines the modern era of the Fortuna Faucet:\n\n*   **Pillar 1: The Future (The Planner):** The resilient `OddsEngine` and its fleet of adapters, responsible for finding the day's strategic opportunities.\n*   **Pillar 2: The Past (The Archive):** The perfected `ChartScraper` and `ResultsParser`, responsible for building our historical data warehouse from the ground truth of Equibase PDFs.\n*   **Pillar 3: The Present (The Finisher):** The weaponized `LiveOddsMonitor`, armed with the API-driven `BetfairAdapter`, designed to conquer the final moments of toteboard volatility.\n\nThese three pillars, orchestrated by the fully autonomous `fortuna_watchman.py`, represented the pinnacle of the project's original vision. The kingdom was, for a time, considered \"perfected.\"\n\n---\n\n## The Windows Ascension (The Impossible Dream)\n\nThe perfected kingdom was powerful, but it was still a tool for developers. The final, grandest vision was to transform it into a true, professional-grade application for its sole operator. This campaign, known as \"The Impossible Dream,\" was to forge the **Fortuna Faucet - Windows Native Edition.**\n\nThis era saw the rapid creation of a new, third layer of the kingdom, built upon the foundation of the previous work:\n\n*   **The Electron Shell:** The Next.js frontend was wrapped in an Electron container, transforming it from a website into a true, installable desktop application with its own window, icon, and system tray integration.\n*   **The Engine Room:** The Python backend was re-architected to run as a persistent, background **Windows Service**, making it a true, always-on component of the operating system, independent of the UI.\n*   **The Native GUI:** A dedicated Tkinter-based \"Observatory\" was forged\u2014a standalone GUI mission control for monitoring the health and performance of the background service.\n*   **The One-Click Kingdom:** A complete suite of professional tooling (including installation scripts, a setup wizard, and launchers) was created to provide a seamless, zero-friction installation and management experience.\n\nThis ascension represents the current state of the art, transforming a powerful engine into a polished, autonomous, and user-focused product.\n\n\n---\n\n## The Era of the Windows Kingdom (October 2025)\n\nWith the core engine stabilized and the command deck providing a clear view of the data, the project's focus shifted from pure data acquisition to the operator's experience. This era marked a profound transformation, elevating the project from a collection of powerful but disparate scripts into a cohesive, professional-grade, and resilient native Windows application.\n\nThis campaign, guided by a new \"Grand Strategy\" blueprint, was executed with rapid precision, resulting in a complete overhaul of the user-facing toolkit:\n\n-   **A Bulletproof Foundation:** The installation and launch scripts were re-architected from the ground up. They became intelligent and self-healing, featuring pre-flight system checks, automated port conflict resolution, active health-check loops, and automated repair utilities.\n-   **A Professional Toolkit:** The operator was empowered with a suite of new tools, including an interactive setup wizard, a real-time CLI status monitor, and a full-fledged graphical \"Data Management Console\" for monitoring, filtering, and analyzing data.\n-   **A Unified Command Console (`SERVICE_MANAGER.bat`):** Unify all individual scripts under a single, user-friendly, menu-driven service manager, providing a 'single pane of glass' for all common operations.\n\nThis era solidified the kingdom's foundations, making it not just powerful, but stable, reliable, and a pleasure to operate. The Faucet was no longer just an engine; it was a complete, professional-grade machine.\n\n---\n\n## The Gauntlet of CI/CD (Late October 2025)\n\nWith a professional-grade application in hand, the final frontier was professional-grade *delivery*. This campaign focused on automating the creation of the MSI installer through a continuous integration pipeline, a process that proved to be a formidable challenge.\n\nThe kingdom's engineers faced a relentless series of cryptic build errors from the WiX Toolset, a hostile environment that tested their resolve. Through a series of rapid, iterative fixes\u2014addressing everything from component GUIDs and 64-bit architecture mismatches to obscure linker errors and frontend dependency warnings\u2014they systematically conquered each obstacle.\n\nThis trial by fire culminated in a triumphant success: a fully automated GitHub Actions workflow that reliably compiles, links, and delivers a polished, distributable MSI installer. This victory transformed the project's delivery model from a manual, error-prone process into a repeatable, one-click release pipeline, marking the true completion of the \"Windows Ascension.\"\n\n---\n\n## The Great Unbundling (Late October 2025)\n\nThe CI/CD pipeline was technically successful, but it revealed a deeper, philosophical flaw in the architecture. The installer, while automated, was a fragile monolith. It attempted to bundle raw source code (Python, JavaScript) and orchestrate their setup on the user's machine using post-install scripts. This approach was fraught with peril, vulnerable to failures from network issues, corporate firewalls, and unpredictable machine states.\n\nA final, decisive architectural mandate was issued, informed by the wisdom of external AI consultants: **The application must be delivered, not assembled.**\n\nThis mandate triggered \"The Great Unbundling,\" a swift and transformative refactoring of the entire delivery pipeline:\n\n*   **The Backend Forged:** The Python backend was no longer treated as source code to be installed, but as a product to be delivered. **PyInstaller** was used to forge the entire FastAPI service\u2014interpreter and all dependencies\u2014into a single, standalone `.exe`.\n*   **The Frontend Solidified:** The Next.js frontend was no longer a service to be run, but a static asset to be displayed. The `npm run build` process was configured to produce a clean, static HTML/CSS/JS export.\n*   **The Installer Perfected:** With the application components now self-contained, the MSI installer's role was radically simplified. All complex post-install scripting was eliminated. The WiX toolset was now used for its core competency: reliably copying pre-compiled, robust artifacts to the user's machine.\n\nThis final act of architectural purification created the \"Three-Executable Architecture\" (the backend executable, the Electron wrapper, and the MSI installer itself), achieving true portability and eliminating an entire class of deployment failures. The Windows Ascension was not just complete; it was perfected.",
    "package-lock.json": "{\n  \"name\": \"app\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"dependencies\": {\n        \"@playwright/test\": \"^1.56.1\"\n      }\n    },\n    \"node_modules/@playwright/test\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/@playwright/test/-/test-1.56.1.tgz\",\n      \"integrity\": \"sha512-vSMYtL/zOcFpvJCW71Q/OEGQb7KYBPAdKh35WNSkaZA75JlAO8ED8UN6GUNTm3drWomcbcqRPFqQbLae8yBTdg==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"playwright\": \"1.56.1\"\n      },\n      \"bin\": {\n        \"playwright\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      }\n    },\n    \"node_modules/fsevents\": {\n      \"version\": \"2.3.2\",\n      \"resolved\": \"https://registry.npmjs.org/fsevents/-/fsevents-2.3.2.tgz\",\n      \"integrity\": \"sha512-xiqMQR4xAeHTuB9uWm+fFRcIOgKBMiOBP+eXiyT7jsgVCq1bkVygt00oASowB7EdtpOHaaPgKt812P9ab+DDKA==\",\n      \"hasInstallScript\": true,\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"os\": [\n        \"darwin\"\n      ],\n      \"engines\": {\n        \"node\": \"^8.16.0 || ^10.6.0 || >=11.0.0\"\n      }\n    },\n    \"node_modules/playwright\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/playwright/-/playwright-1.56.1.tgz\",\n      \"integrity\": \"sha512-aFi5B0WovBHTEvpM3DzXTUaeN6eN0qWnTkKx4NQaH4Wvcmc153PdaY2UBdSYKaGYw+UyWXSVyxDUg5DoPEttjw==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"playwright-core\": \"1.56.1\"\n      },\n      \"bin\": {\n        \"playwright\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      },\n      \"optionalDependencies\": {\n        \"fsevents\": \"2.3.2\"\n      }\n    },\n    \"node_modules/playwright-core\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/playwright-core/-/playwright-core-1.56.1.tgz\",\n      \"integrity\": \"sha512-hutraynyn31F+Bifme+Ps9Vq59hKuUCz7H1kDOcBs+2oGguKkWTU50bBWrtz34OUWmIwpBTWDxaRPXrIXkgvmQ==\",\n      \"license\": \"Apache-2.0\",\n      \"bin\": {\n        \"playwright-core\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      }\n    }\n  }\n}\n",
    "python_service/adapters/betfair_greyhound_adapter.py": "# python_service/adapters/betfair_greyhound_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairGreyhoundAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching greyhound racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairGreyhounds\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for greyhound races on a given date.\"\"\"\n        await self._authenticate(self.http_client)\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            self.http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"4339\"],  # Greyhound Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Failed to parse a Betfair Greyhound market.\",\n                    exc_info=True,\n                    market=market,\n                )\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Optional[Race]:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bfg_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 480m').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "python_service/db/init.py": "# python_service/db/init.py\nimport os\nimport sqlite3\n\nfrom ..config import get_settings\n\n\ndef initialize_database():\n    \"\"\"\n    Initializes the database based on the configuration.\n    Currently supports a simple SQLite fallback for local testing.\n    \"\"\"\n    settings = get_settings()\n    db_type = getattr(settings, \"DATABASE_TYPE\", \"sqlite\").lower()\n\n    if db_type == \"sqlite\":\n        # DATABASE_URL for sqlite will be like 'sqlite:///./fortuna.db'\n        db_path = settings.DATABASE_URL.split(\"///\")[1]\n\n        # Ensure the directory for the database exists\n        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n\n        try:\n            conn = sqlite3.connect(db_path)\n            cursor = conn.cursor()\n\n            # The schema is based on the provided pg_schemas, adapted for SQLite\n            # This is a simplified version for demonstration.\n            cursor.execute(\n                \"\"\"\n            CREATE TABLE IF NOT EXISTS races (\n                id TEXT PRIMARY KEY,\n                venue TEXT NOT NULL,\n                race_number INTEGER NOT NULL,\n                start_time TEXT NOT NULL,\n                source TEXT,\n                field_size INTEGER\n            )\n            \"\"\"\n            )\n\n            cursor.execute(\n                \"\"\"\n            CREATE TABLE IF NOT EXISTS runners (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                race_id TEXT,\n                number INTEGER,\n                name TEXT,\n                odds REAL,\n                FOREIGN KEY (race_id) REFERENCES races (id)\n            )\n            \"\"\"\n            )\n\n            conn.commit()\n            conn.close()\n            print(\"SQLite database initialized successfully.\")\n        except sqlite3.Error as e:\n            print(f\"Error initializing SQLite database: {e}\")\n            raise\n",
    "python_service/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "python_service/tests/test_manual_override.py": "# python_service/tests/test_manual_override.py\nimport pytest\n\nfrom python_service.manual_override_manager import ManualOverrideManager\n\n\n@pytest.fixture\ndef manager():\n    # The manager is now in-memory and doesn't need a path\n    return ManualOverrideManager()\n\n\ndef test_register_and_retrieve(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n    content = \"<html>Manual content</html>\"\n    content_type = \"text/html\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    success = manager.submit_manual_data(\n        request_id=request_id,\n        raw_content=content,\n        content_type=content_type,\n    )\n\n    assert success\n\n    # Verify that the data can be retrieved correctly\n    retrieved_data = manager.get_manual_data(adapter_name=adapter, url=url)\n    assert retrieved_data is not None\n    retrieved_content, retrieved_type = retrieved_data\n    assert retrieved_content == content\n    assert retrieved_type == content_type\n\n    # Verify that data is consumed after retrieval\n    assert manager.get_manual_data(adapter_name=adapter, url=url) is None\n",
    "web_platform/api_gateway/src/server.ts": "// server.ts - Complete API Gateway with Database Integration and WebSocket\n\nimport express from 'express';\nimport { createServer } from 'http';\nimport { Server as SocketServer } from 'socket.io';\nimport cors from 'cors';\nimport sqlite3 from 'sqlite3';\nimport { open, Database } from 'sqlite';\nimport path from 'path';\n\n// Types\ninterface Race {\n  race_id: string;\n  track_name: string;\n  race_number: number | null;\n  post_time: string | null;\n  checkmate_score: number;\n  qualified: boolean;\n  trifecta_factors_json: string | null;\n  raw_data_json: string | null;\n  updated_at: string;\n}\n\ninterface AdapterStatus {\n  adapter_name: string;\n  status: string;\n  last_run: string;\n  races_found: number;\n  execution_time_ms: number;\n  error_message: string | null;\n}\n\n// Database Service\nclass DatabaseService {\n  private db: Database | null = null;\n  private dbPath: string;\n\n  constructor() {\n    this.dbPath = process.env.FORTUNA_DB_PATH || path.join(process.cwd(), '..', '..', 'shared_database', 'races.db');\n  }\n\n  async connect(): Promise<void> {\n    try {\n      this.db = await open({\n        filename: this.dbPath,\n        driver: sqlite3.Database\n      });\n      console.log(`[INFO] Connected to database: ${this.dbPath}`);\n    } catch (error) {\n      console.error('[ERROR] Failed to connect to database:', error);\n      throw error;\n    }\n  }\n\n  async getQualifiedRaces(): Promise<Race[]> {\n    if (!this.db) throw new Error('Database not connected');\n    try {\n      const races = await this.db.all<Race[]>(`\n        SELECT race_id, track_name, race_number, post_time,\n               checkmate_score, qualified, trifecta_factors_json,\n               raw_data_json, updated_at\n        FROM live_races\n        WHERE qualified = 1\n        ORDER BY checkmate_score DESC, post_time ASC\n      `);\n      return races;\n    } catch (error) {\n      console.error('[ERROR] Failed to fetch qualified races:', error);\n      return [];\n    }\n  }\n\n  async getAllRaces(): Promise<Race[]> {\n    if (!this.db) throw new Error('Database not connected');\n    try {\n      const races = await this.db.all<Race[]>(`\n        SELECT race_id, track_name, race_number, post_time,\n               checkmate_score, qualified, trifecta_factors_json,\n               raw_data_json, updated_at\n        FROM live_races\n        ORDER BY post_time ASC\n      `);\n      return races;\n    } catch (error) {\n      console.error('[ERROR] Failed to fetch all races:', error);\n      return [];\n    }\n  }\n\n  async getAdapterStatuses(): Promise<AdapterStatus[]> {\n    if (!this.db) throw new Error('Database not connected');\n    try {\n      const statuses = await this.db.all<AdapterStatus[]>(`\n        SELECT adapter_name, status, last_run, races_found,\n               execution_time_ms, error_message\n        FROM adapter_status\n        ORDER BY last_run DESC\n      `);\n      return statuses;\n    } catch (error) {\n      console.error('[ERROR] Failed to fetch adapter statuses:', error);\n      return [];\n    }\n  }\n\n  async getRaceById(raceId: string): Promise<Race | null> {\n    if (!this.db) throw new Error('Database not connected');\n    try {\n      const race = await this.db.get<Race>(`\n        SELECT race_id, track_name, race_number, post_time,\n               checkmate_score, qualified, trifecta_factors_json,\n               raw_data_json, updated_at\n        FROM live_races\n        WHERE race_id = ?\n      `, raceId);\n      return race || null;\n    } catch (error) {\n      console.error('[ERROR] Failed to fetch race by ID:', error);\n      return null;\n    }\n  }\n}\n\n// Initialize Express and Socket.IO\nconst app = express();\nconst httpServer = createServer(app);\nconst io = new SocketServer(httpServer, {\n  cors: { origin: process.env.ALLOWED_ORIGINS || 'http://localhost:3000' }\n});\n\napp.use(cors());\napp.use(express.json());\n\nconst dbService = new DatabaseService();\n\n// API Endpoints\napp.get('/api/status', (req, res) => {\n  res.json({\n    status: 'online',\n    timestamp: new Date().toISOString(),\n    service: 'Checkmate API Gateway'\n  });\n});\n\napp.get('/api/races', async (req, res) => {\n  try {\n    const races = await dbService.getAllRaces();\n    res.json({ success: true, count: races.length, races });\n  } catch (error) {\n    res.status(500).json({ success: false, error: 'Failed to fetch races' });\n  }\n});\n\napp.get('/api/races/qualified', async (req, res) => {\n  try {\n    const races = await dbService.getQualifiedRaces();\n    res.json({ success: true, count: races.length, races });\n  } catch (error) {\n    res.status(500).json({ success: false, error: 'Failed to fetch qualified races' });\n  }\n});\n\napp.get('/api/races/:raceId', async (req, res) => {\n  try {\n    const race = await dbService.getRaceById(req.params.raceId);\n    if (race) {\n      res.json({ success: true, race });\n    } else {\n      res.status(404).json({ success: false, error: 'Race not found' });\n    }\n  } catch (error) {\n    res.status(500).json({ success: false, error: 'Failed to fetch race' });\n  }\n});\n\napp.get('/api/adapters/status', async (req, res) => {\n  try {\n    const statuses = await dbService.getAdapterStatuses();\n    res.json({ success: true, count: statuses.length, adapters: statuses });\n  } catch (error) {\n    res.status(500).json({ success: false, error: 'Failed to fetch adapter statuses' });\n  }\n});\n\n// WebSocket Connection Handling\nio.on('connection', (socket) => {\n  console.log(`[WebSocket] Client connected: ${socket.id}`);\n\n  dbService.getQualifiedRaces().then(races => {\n    socket.emit('races_update', { races });\n  });\n\n  dbService.getAdapterStatuses().then(statuses => {\n    socket.emit('adapters_update', { adapters: statuses });\n  });\n\n  socket.on('disconnect', () => {\n    console.log(`[WebSocket] Client disconnected: ${socket.id}`);\n  });\n\n  socket.on('request_update', async () => {\n    const races = await dbService.getQualifiedRaces();\n    const statuses = await dbService.getAdapterStatuses();\n    socket.emit('races_update', { races });\n    socket.emit('adapters_update', { adapters: statuses });\n  });\n});\n\n// Broadcast updates to all clients periodically\nasync function broadcastUpdates() {\n  try {\n    const races = await dbService.getQualifiedRaces();\n    const statuses = await dbService.getAdapterStatuses();\n\n    io.emit('races_update', { races });\n    io.emit('adapters_update', { adapters: statuses });\n  } catch (error) {\n    console.error('[ERROR] Failed to broadcast updates:', error);\n  }\n}\n\n// Start Server\nconst PORT = process.env.PORT || 8080;\n\nasync function startServer() {\n  try {\n    await dbService.connect();\n\n    httpServer.listen(PORT, () => {\n      console.log('='.repeat(70));\n      console.log(`  Checkmate API Gateway`);\n      console.log(`  Running on port ${PORT}`);\n      console.log(`  Database: ${dbService['dbPath']}`);\n      console.log('='.repeat(70));\n    });\n\n    setInterval(broadcastUpdates, 15000);\n\n  } catch (error) {\n    console.error('[FATAL] Failed to start server:', error);\n    process.exit(1);\n  }\n}\n\n// Graceful shutdown\nprocess.on('SIGINT', async () => {\n  console.log('\\n[INFO] Shutting down gracefully...');\n  httpServer.close();\n  process.exit(0);\n});\n\nprocess.on('SIGTERM', async () => {\n  console.log('\\n[INFO] Shutting down gracefully...');\n  httpServer.close();\n  process.exit(0);\n});\n\nstartServer();",
    "web_platform/api_gateway/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"commonjs\",\n    \"lib\": [\"ES2020\"],\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}",
    "web_platform/frontend/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"lib\": [\n      \"dom\",\n      \"dom.iterable\",\n      \"esnext\"\n    ],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": false,\n    \"noEmit\": true,\n    \"incremental\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ]\n  },\n  \"include\": [\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\",\n    \"out/types/**/*.ts\"\n  ],\n  \"exclude\": [\n    \"node_modules\"\n  ]\n}\n"
}