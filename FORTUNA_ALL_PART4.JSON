{
    ".github/actions/run-smoke-test/action.yml": "name: 'Run 4-Step Diagnostic Smoke Test'\ndescription: 'Installs an MSI, then runs a 4-step diagnostic to verify file installation, service status, port binding, and API health, finishing with a Paparazzi screenshot.'\n\ninputs:\n  msi-artifact-name:\n    description: 'The name of the MSI artifact to download.'\n    required: true\n  service-name:\n    description: 'The name of the Windows Service to verify (e.g., FortunaWebService).'\n    required: true\n  executable-path:\n    description: 'The full, absolute path to the installed service executable to verify.'\n    required: true\n  port:\n    description: 'The port to check for a listener.'\n    required: true\n  firewall-rule-name:\n    description: 'The name of the firewall rule to create.'\n    required: true\n\nruns:\n  using: \"composite\"\n  steps:\n    - name: \ud83d\udce5 Download MSI Artifact\n      uses: actions/download-artifact@v4\n      with:\n        name: ${{ inputs.msi-artifact-name }}\n        path: installer\n\n    - name: \ud83d\udee1\ufe0f Firewall & Install\n      shell: pwsh\n      run: |\n        New-NetFirewallRule -DisplayName \"${{ inputs.firewall-rule-name }}\" -Direction Inbound -LocalPort ${{ inputs.port }} -Protocol TCP -Action Allow\n        if (Get-Service -Name \"${{ inputs.service-name }}\" -ErrorAction SilentlyContinue) {\n          sc.exe stop \"${{ inputs.service-name }}\" 2>&1 | Out-Null\n          sc.exe delete \"${{ inputs.service-name }}\" 2>&1 | Out-Null\n        }\n        $msi = Get-ChildItem installer -Filter \"*.msi\" -Recurse | Select-Object -First 1\n        if (!$msi) { throw \"No MSI found\" }\n        Write-Host \"Installing $($msi.Name)...\"\n        $msiPath = $msi.FullName\n        $args = \"/i `\"$msiPath`\" /qn /L*v installation.log\"\n        $proc = Start-Process msiexec.exe -ArgumentList $args -Wait -NoNewWindow -PassThru\n        if ($proc.ExitCode -ne 0) {\n          Get-Content installation.log -Tail 50\n          throw \"Install failed with code $($proc.ExitCode)\"\n        }\n\n    - name: \"\u2705 Create Required Runtime Directories Post-Install\"\n      shell: pwsh\n      run: |\n        $installRoot = Split-Path -Path \"${{ inputs.executable-path }}\" -Parent\n        if (-not (Test-Path $installRoot)) {\n          Write-Error \"Installation directory not found at $installRoot. Cannot create runtime directories.\"\n          exit 1\n        }\n        New-Item -Path \"$installRoot\\data\" -ItemType Directory -Force | Out-Null\n        New-Item -Path \"$installRoot\\json\" -ItemType Directory -Force | Out-Null\n        New-Item -Path \"$installRoot\\logs\" -ItemType Directory -Force | Out-Null\n        Write-Host \"\u2705 Created data, json, and logs directories in $installRoot\"\n\n    - name: '\ud83d\udd2c Complete Smoke Test (3-Layer Defense)'\n      shell: pwsh\n      run: |\n        Set-StrictMode -Version Latest\n        $ErrorActionPreference = \"Stop\"\n\n        # --- LAYER 1: INSTALLATION & FILE VERIFICATION ---\n        Write-Host \"`n--- DEFENSE LAYER 1: VERIFYING INSTALLATION ---\"\n        $installRoot = Split-Path -Path \"${{ inputs.executable-path }}\" -Parent\n        if (-not (Test-Path $installRoot)) {\n          Write-Error \"\u274c LAYER 1 FAILED: Install directory not found: $installRoot\"\n          exit 1\n        }\n        $mainExe = Get-ChildItem -Path $installRoot -Filter \"*.exe\" -Recurse | Where-Object { $_.Name -notmatch 'uninstall' } | Select -First 1\n        if (-not $mainExe) { Write-Error \"\u274c LAYER 1 FAILED: Main executable not found.\"; exit 1 }\n        Write-Host \"\u2705 Layer 1 Passed: Found main executable ($($mainExe.Name)).\"\n\n        # --- LAYER 2: PROCESS VERIFICATION ---\n        Write-Host \"`n--- DEFENSE LAYER 2: VERIFYING PROCESS STARTUP ---\"\n        $svc = Get-Service \"${{ inputs.service-name }}\" -ErrorAction SilentlyContinue\n        if (!$svc) {\n          Write-Error \"\u274c LAYER 2 FAILED: Service '${{ inputs.service-name }}' is NOT registered!\"\n          exit 1\n        }\n        if ($svc.Status -ne 'Running') {\n          Start-Service \"${{ inputs.service-name }}\"\n          Start-Sleep -Seconds 10\n        }\n        $svc = Get-Service \"${{ inputs.service-name }}\"\n        if ($svc.Status -ne 'Running') {\n          Write-Error \"\u274c LAYER 2 FAILED: Service failed to start. Status: $($svc.Status)\"\n          Get-EventLog -LogName System -Source \"Service Control Manager\" -Newest 20 | Format-Table -AutoSize\n          exit 1\n        }\n        Write-Host \"\u2705 Layer 2 Passed: Service is RUNNING.\"\n\n        # Inserted Backend Alive Check\n        Write-Host \"--- Verifying backend process stability (10s alive check) ---\"\n        Start-Sleep -Seconds 10\n        $svcProcess = Get-CimInstance win32_service | where name -eq \"${{ inputs.service-name }}\" | select -ExpandProperty ProcessId\n        if ($null -eq (Get-Process -Id $svcProcess -ErrorAction SilentlyContinue)) {\n          Write-Error \"\u274c Backend process crashed within 10 seconds of starting.\"\n          exit 1\n        }\n        Write-Host \"\u2705 Backend process is still alive.\"\n\n        # --- LAYER 3: NETWORK VERIFICATION ---\n        Write-Host \"`n--- DEFENSE LAYER 3: VERIFYING NETWORK ENDPOINT ---\"\n        $maxAttempts = 10\n        $healthUrl = \"http://localhost:${{ inputs.port }}/health\"\n        for ($i = 1; $i -le $maxAttempts; $i++) {\n          try {\n            Write-Host \"Attempt $i/${maxAttempts}: Pinging $healthUrl...\"\n            $response = Invoke-WebRequest -Uri $healthUrl -Method Get -UseBasicParsing -ErrorAction Stop\n            if ($response.StatusCode -eq 200) {\n              Write-Host \"\u2705\u2705\u2705 SMOKE TEST PASSED ALL 3 DEFENSE LAYERS \u2705\u2705\u2705\"\n              exit 0\n            }\n          } catch {\n            Write-Host \"\u23f3 Waiting for service...\"\n            Start-Sleep -Seconds 5\n          }\n        }\n        Write-Error \"\u274c LAYER 3 FAILED: Service Failed Health Check after $maxAttempts attempts\"\n        exit 1\n\n    - name: '\ud83d\udcf8 The Paparazzi (Visual Proof)'\n      shell: pwsh\n      run: |\n        Write-Host \"Installing Playwright...\"\n        npm install playwright\n        npx playwright install chromium --with-deps\n\n        $url = \"http://127.0.0.1:${{ inputs.port }}/docs\"\n\n        node -e \"\n          const { chromium } = require('playwright');\n          (async () => {\n            try {\n              const browser = await chromium.launch();\n              const page = await browser.newPage();\n              await page.goto('$url', { timeout: 15000 });\n              await page.waitForSelector('.swagger-ui', { timeout: 5000 }).catch(() => console.log('UI not fully loaded, snapping anyway...'));\n              await page.screenshot({ path: 'proof-of-life.png', fullPage: true });\n              await browser.close();\n            } catch (e) {\n              console.error(e); process.exit(1);\n            }\n          })();\n        \"\n\n    - name: Upload Visual Proof\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: visual-proof-${{ github.run_id }}\n        path: proof-of-life.png\n\n    - name: \ud83e\uddf9 Cleanup\n      if: always()\n      shell: pwsh\n      run: |\n        sc.exe stop ${{ inputs.service-name }}\n        sc.exe delete ${{ inputs.service-name }}\n        Remove-NetFirewallRule -DisplayName \"${{ inputs.firewall-rule-name }}\" -ErrorAction SilentlyContinue\n",
    ".github/workflows/codeql.yml": "# System Timestamp: 2025-12-24 18:00:00\n# HELPFUL HINT: Configure GitHub Branch Protection rules to require this workflow to pass before merging to main.\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n    branches: [\"main\"]\n  schedule:\n    - cron: '40 7 * * 4'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: ['javascript', 'python' ]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Setup Python\n      if: matrix.language == 'python'\n      uses: actions/setup-python@v5\n      with:\n        python-version: '3.11'\n\n    - name: Setup Node.js\n      if: matrix.language == 'javascript'\n      uses: actions/setup-node@v4\n      with:\n        node-version: '20'\n\n    - name: Install Python dependencies\n      if: matrix.language == 'python'\n      run: |\n        python -m pip install uv\n        uv pip install --system -r web_service/backend/requirements-dev.txt\n    - name: Install JavaScript dependencies\n      if: matrix.language == 'javascript'\n      run: |\n        npm install --prefix web_service/frontend\n        npm install --prefix electron\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v4\n      with:\n        languages: ${{ matrix.language }}\n\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v4\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v4\n",
    "Dockerfile": "# Main Application Stage\nFROM python:3.10.11-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    curl \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Copy requirements\nCOPY web_service/backend/requirements.txt /app/web_service/backend/\n\n# Install Python dependencies\nRUN pip install --no-cache-dir -r /app/web_service/backend/requirements.txt\n\n# Copy backend code\nCOPY web_service/backend /app/web_service/backend\nCOPY web_service/__init__.py /app/web_service/\n\n# Copy pre-built frontend assets\nCOPY web_service/frontend/public /app/web_service/frontend/public\n\n# Create required directories\nRUN mkdir -p /app/web_service/backend/data \\\n    && mkdir -p /app/web_service/backend/json \\\n    && mkdir -p /app/web_service/backend/logs\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:8000/api/health || exit 1\n\n# Set entrypoint\nWORKDIR /app\nENV PYTHONUNBUFFERED=1\nEXPOSE 8000\n\nCMD [\"python\", \"-m\", \"web_service.backend.main\"]\n",
    "PREV_ARCHITECTURAL_MANDATE_V8.1.md": "# ARCHITECTURAL MANDATE V8.1\nProject: Checkmate V7: The Ultimate Engine\nStatus: LOCKED & FINAL\nDate: 2025-09-26\n\n## 1.0 Abstract & Guiding Principles\n\nThis document is the final, locked architectural specification for the Checkmate V7 project. It reflects our strategic pivot to a CLI-first, two-stack system. It is required reading for all AI teammates and serves as the single source of truth for the system's design.\n\n### 1.1 The Two-Stack Architecture\n\nThe system is composed of two distinct, collaborating technology stacks:\n\n1.  **THE ENGINE (Python Backend):** A powerful, headless data processing and analysis application. Its sole purpose is to perform the heavy lifting and expose its capabilities via a JSON API.\n    *   `models.py` - THE BLUEPRINT (Data Structures & Contracts)\n    *   `logic.py` - THE BRAIN (Pure, Stateless Analysis)\n    *   `services.py` - THE GATEWAY (I/O & Orchestration)\n    *   `api.py` - THE CONDUCTOR (Stateless HTTP Interface)\n\n2.  **THE COCKPIT (User Interface):** The project's primary user interface. As of V8.1 and ROADMAP V5.0, this is implemented as a powerful, interactive Text User Interface (TUI) within the `run.py` script. It remains a pure client of The Engine.\n\n### 1.2 Guiding Policies\n\nAll implementation work must adhere to policies for Configuration via Environment, Comprehensive Structured Logging, and Graceful Error Handling.\n\n---\n\n## 2.0 Implementation Specification\n\n### 2.1 The Python Engine\n\nThe specifications for `models.py`, `logic.py`, `services.py`, and `api.py` remain the canonical blueprint for the Python backend. Their primary role is to serve the Cockpit.\n\n### 2.2 DEPRECATIONS\n\nThe primary user interface is now the \"Ultimate TUI\" defined in `ROADMAP V5.0`. The previously planned React application, along with the original Python-based `dashboard.py`, are now **DEPRECATED** and will be archived.\n\n### 2.3 The Headless Monitor\n\nThe `headless_monitor.py` remains a critical, first-class tool for developers and headless agents to monitor the status of The Engine's API. It is an essential part of the project's infrastructure and is not deprecated.",
    "REPORTS_README.md": "# Fortuna Faucet - Race Reporting System\n\nThis subsystem allows you to generate automated race reports using GitHub Actions, without needing to maintain a permanent server.\n\n## \ud83d\ude80 Quick Start (5 Minutes)\n\n1.  **File Setup**: Ensure `.github/workflows/generate-race-report.yml` and `scripts/test_api_query.py` are in your repository.\n2.  **Add Secret**: Go to **Settings -> Secrets and variables -> Actions** and add `API_KEY`.\n3.  **Run**: Go to the **Actions** tab, select **Fortuna - Instant Filtered Race Report**, and click **Run workflow**.\n\n## \ud83d\udd04 Workflow Lifecycle\n\n1.  **Setup**: Installs Python 3.10 and dependencies.\n2.  **Backend Launch**: Spins up the FastAPI backend on `localhost:8000`.\n3.  **Health Check**: Polls until the backend is ready.\n4.  **Query**: Fetches qualified races from `/api/races/qualified/trifecta`.\n5.  **Generate**: Creates a polished HTML report (`race-report.html`).\n6.  **Cleanup**: Uploads artifacts and shuts down the backend.\n\n## \ud83d\udce5 Downloading Reports\n\n1.  Go to the **Actions** tab in GitHub.\n2.  Click on a completed run.\n3.  Scroll down to **Artifacts**.\n4.  Download `fortuna-race-report-[RUN_NUMBER]`.\n5.  Extract the zip file to view the HTML report.\n\n## \ud83e\uddea Local Testing\n\nYou can verify the logic locally before pushing to GitHub:\n\n```bash\n# Terminal 1: Start Backend\npython -m uvicorn web_service.backend.main:app --port 8000\n\n# Terminal 2: Run Query Script\npython scripts/test_api_query.py\n```\n",
    "USER_GUIDE.md": "# \ud83c\udfaf Fortuna Faucet: Complete User Guide for Windows Hobbyists\n\n## What Is This Amazing Software?\n\n**Fortuna Faucet** is a professional-grade horse racing analysis platform that:\n- \ud83d\udcca Aggregates data from **20+ global racing sources** simultaneously\n- \ud83e\udd16 Uses AI-powered analysis to find value betting opportunities\n- \ud83d\udcc8 Provides live odds monitoring via Betfair Exchange\n- \ud83c\udf10 Features a beautiful web dashboard for real-time insights\n- \ud83d\udd04 Runs automatically in the background like a professional service\n\nThink of it as your personal racing intelligence agency!\n\n---\n\n## \ud83d\ude80 Quick Start (15 Minutes to Racing!)\n\n### Step 1: One-Click Installation\n1. Extract all files to `C:\\FortunaFaucet` (or your preferred location)\n2. **Right-click** `INSTALL_FORTUNA.bat` \u2192 **Run as Administrator**\n3. Wait 3-5 minutes while it automatically installs:\n   - Python 3.11 (if needed)\n   - Node.js (if needed)\n   - All required packages\n\n### Step 2: Quick Configuration\n1. **Double-click** `setup_wizard.py` in your folder\n2. Follow the friendly prompts to configure:\n   - Your private API key (auto-generated)\n   - Betfair credentials (optional, for live odds)\n3. The wizard creates your `.env` file automatically!\n\n### Step 3: Launch!\n- **Double-click** the \"Launch Fortuna\" shortcut on your desktop\n- Wait 10 seconds for services to start\n- Your dashboard opens automatically in your browser! \ud83c\udf89\n\n---\n\n## \ud83c\udfae Using Your New Command Center\n\n### The Dashboard (http://localhost:3000)\nYour racing command center features:\n\n**\ud83d\udcca Statistics Panel** (Top of screen)\n- **Qualified Races**: How many races meet your criteria\n- **Premium Targets**: High-score opportunities (80%+)\n- **Next Race**: Countdown to the next qualifying race\n- **Avg Field Size**: Average number of horses\n\n**\ud83c\udf9b\ufe0f Smart Filters** (Middle section)\nCustomize what you see:\n- **Min Score Slider**: Only show races above X% match\n- **Max Field Size**: Filter by number of runners (8, 10, 12, or Any)\n- **Sort By**: Order by score, time, or track name\n\n**\ud83c\udfc7 Race Cards** (Main display)\nEach card shows:\n- Track name and race number\n- Qualification score (color-coded!)\n- Race conditions (distance, surface)\n- Top 3 contenders with best odds\n- Data source count\n\n### Color Coding System\n- \ud83d\udd34 **Red (80%+)**: Premium betting opportunity!\n- \ud83d\udfe1 **Yellow (60-79%)**: Good value potential\n- \ud83d\udfe2 **Green (<60%)**: Meets minimum criteria\n\n---\n\n## \ud83d\udd27 Advanced Features\n\n### Live Odds Monitoring\nOnce you've added Betfair credentials:\n1. The system automatically tracks races approaching post time\n2. Updates odds every 30 seconds for races within 5 minutes\n3. Highlights dramatic odds movements\n\n### Desktop Monitor Tool\nRun `fortuna_monitor.py` for a real-time status window:\n- Shows all data source health\n- Performance graphs (with matplotlib)\n- Success rates and fetch durations\n- Quick \"Refresh Now\" button\n\n### Auto-Start on Windows Boot\nRun `SCHEDULE_FORTUNA.bat` (as Administrator):\n- Fortuna starts when you log into Windows\n- Daily 3 AM restart for fresh data\n- Runs silently in the background\n\n---\n\n## \ud83c\udfaf Understanding the \"Trifecta Analyzer\"\n\nThis is the brain! It scores races on three factors:\n\n### Factor 1: Field Size (smaller is better)\n- **Why**: Fewer horses = easier to predict\n- **Default**: Maximum 10 runners\n\n### Factor 2: Favorite's Odds (higher is better)\n- **Why**: If the favorite is 2.5+, the race is wide open\n- **Default**: Minimum 2.5\n\n### Factor 3: Second Favorite's Odds (higher is better)\n- **Why**: Confirms multiple horses are competitive\n- **Default**: Minimum 4.0\n\n**The Score**: Combines all three into a 0-100% match rating!\n\n---\n\n## \ud83d\udcda System Architecture (Simplified)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \ud83c\udf10 Next.js Dashboard (Port 3000)    \u2502\n\u2502     Your beautiful web interface        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 API Calls\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   \ud83d\udc0d Python FastAPI Backend (Port 8000) \u2502\n\u2502   - OddsEngine: Fetches from 20+ sources\u2502\n\u2502   - TrifectaAnalyzer: Scores races      \u2502\n\u2502   - LiveOddsMonitor: Betfair tracking   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 Async Requests\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \ud83d\udd0c Adapter Fleet (20+ sources)      \u2502\n\u2502  TVG \u2022 Betfair \u2022 TimeForm \u2022 GBGB       \u2502\n\u2502  RacingAndSports \u2022 USTA \u2022 And more!     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n---\n\n## \ud83d\udd10 Security Notes\n\n### API Keys\n- **Your local API_KEY**: Only for communication between YOUR backend and frontend\n- Never shared online, never exposed\n- Auto-generated during setup\n\n### External API Keys (Optional)\nAdd these to `.env` for more data sources:\n```\nTVG_API_KEY=\"your_tvg_key\"\nRACING_AND_SPORTS_TOKEN=\"your_ras_token\"\nTHE_RACING_API_KEY=\"your_theracingapi_key\"\n```\n\nGet keys from:\n- TVG: https://www.tvg.com/promos/developer-api\n- Racing and Sports: https://www.racingandsports.com/data-api/\n- The Racing API: https://www.theracingapi.com/\n\n---\n\n## \ud83d\udee0\ufe0f Troubleshooting\n\n### \"Backend Offline\" Error\n```batch\n# Stop everything cleanly\nSTOP_FORTUNA.bat\n\n# Wait 10 seconds, then restart\nLAUNCH_FORTUNA.bat\n```\n\n### Dashboard Loads But No Data\n1. Open `http://localhost:8000/health` in browser\n2. Should show: `{\"status\": \"OK\"}`\n3. If not, check Python backend window for errors\n\n### \"Port Already In Use\" Error\nSomeone else is using port 8000 or 3000:\n```batch\n# Windows: Kill processes on those ports\nnetstat -ano | findstr :8000\ntaskkill /PID [number] /F\n\nnetstat -ano | findstr :3000\ntaskkill /PID [number] /F\n```\n\n### Reset Everything\n```batch\n# Nuclear option: Clean slate\nSTOP_FORTUNA.bat\ndel .env\nsetup_wizard.py\nINSTALL_FORTUNA.bat\n```\n\n---\n\n## \ud83d\udcd6 File Structure Explained\n\n### Critical Files (Don't Delete!)\n- `.env` - Your configuration (API keys, settings)\n- `requirements.txt` - Python packages list\n- `package.json` - Node.js packages list\n\n### Convenience Scripts\n- `LAUNCH_FORTUNA.bat` - Start everything\n- `STOP_FORTUNA.bat` - Stop everything\n- `RESTART_FORTUNA.bat` - Clean restart\n- `setup_wizard.py` - Interactive config tool\n\n### Python Backend (`python_service/`)\n- `api.py` - Web server (FastAPI)\n- `engine.py` - Master data orchestrator\n- `analyzer.py` - Race scoring logic\n- `models.py` - Data structure definitions\n- `adapters/` - Individual data source plugins\n\n### Frontend (`web_platform/frontend/`)\n- `src/app/page.tsx` - Main dashboard\n- `src/components/RaceCard.tsx` - Individual race display\n- `.env.local` - Frontend API key\n\n---\n\n## \ud83c\udf93 Customization Ideas\n\n### Change Analyzer Thresholds\nEdit `python_service/analyzer.py`:\n```python\nclass TrifectaAnalyzer(BaseAnalyzer):\n    def __init__(self,\n                 max_field_size: int = 8,      # \u2190 Change this\n                 min_favorite_odds: float = 3.0, # \u2190 Or this\n                 min_second_favorite_odds: float = 5.0): # \u2190 Or this\n```\n\n### Add New Data Sources\n1. Copy `python_service/adapters/template_adapter.py`\n2. Rename and implement the `fetch_races()` method\n3. Register in `python_service/adapters/__init__.py`\n4. Add to `python_service/engine.py` adapter list\n\n### Customize Dashboard Colors\nEdit `web_platform/frontend/tailwind.config.ts`:\n```typescript\ntheme: {\n  extend: {\n    colors: {\n      'fortuna-primary': '#your-hex-color',\n    }\n  }\n}\n```\n\n---\n\n## \ud83d\udca1 Pro Tips\n\n### Tip 1: Use Windows Task Scheduler\nRun `SCHEDULE_FORTUNA.bat` for:\n- Auto-start on login\n- Daily 3 AM maintenance restart\n\n### Tip 2: Monitor Multiple Days\nThe analyzer works for \"today\" by default, but you can query any date:\n```\nhttp://localhost:8000/api/races/qualified/trifecta?race_date=2025-10-25\n```\n\n### Tip 3: Export Data\nThe API returns pure JSON. Use tools like:\n- **Postman** for testing\n- **PowerShell** for scripting:\n```powershell\nInvoke-RestMethod -Uri \"http://localhost:8000/api/races/qualified/trifecta\" `\n  -Headers @{\"X-API-Key\"=\"your_key\"} | ConvertTo-Json -Depth 10\n```\n\n### Tip 4: Mobile Access\nIf you want to check from your phone on the same WiFi:\n1. Find your PC's IP: `ipconfig` in Command Prompt\n2. Open firewall port 3000\n3. Access from phone: `http://192.168.1.X:3000`\n\n---\n\n## \ud83c\udf89 You're Ready!\n\nThis is a **professional-grade** system that you now control. It was built with years of racing analytics experience and modern software practices.\n\n### What You Can Do Now:\n\u2705 Track races from 20+ global sources\n\u2705 Identify value opportunities with AI scoring\n\u2705 Monitor live odds movements\n\u2705 Run 24/7 as a background service\n\u2705 Customize thresholds and filters\n\u2705 Expand with new data sources\n\n**Welcome to the world of algorithmic racing analysis!** \ud83c\udfc7\ud83d\ude80\n\n---\n\n## \ud83d\udcde Additional Resources\n\n### Project Documentation\n- `HISTORY.md` - Project evolution story\n- `ARCHITECTURAL_MANDATE.md` - System design principles\n- `WISDOM.md` - Developer best practices\n- `ROADMAP_APPENDICES.md` - Future expansion ideas\n\n### Useful Commands\n```batch\n# View all active Python processes\ntasklist | findstr python\n\n# Check if ports are available\nnetstat -ano | findstr :8000\nnetstat -ano | findstr :3000\n\n# Update Python packages\n.venv\\Scripts\\activate\npip install --upgrade -r requirements.txt\n```\n\n### Need Help?\n1. Check `fortuna_restart.log` for error history\n2. Run `fortuna_monitor.py` to see real-time system status\n3. Verify `.env` file has all required keys\n\nHappy Racing! \ud83c\udfb0\ud83c\udfc6",
    "debug_installer.ps1": "# 1. Get the location of this script\n$currentDir = $PSScriptRoot\n\n# 2. Find all .msi files in this folder\n$msiFiles = Get-ChildItem -Path $currentDir -Filter \"*.msi\"\n\n# 3. Validate we found exactly one MSI\nif ($msiFiles.Count -eq 0) {\n    Write-Host \"\u274c Error: No MSI files found in $currentDir\" -ForegroundColor Red\n    Read-Host \"Press Enter to exit...\"\n    Exit\n}\nif ($msiFiles.Count -gt 1) {\n    Write-Host \"\u274c Error: Multiple MSI files found. I don't know which one to run:\" -ForegroundColor Red\n    $msiFiles | ForEach-Object { Write-Host \" - $($_.Name)\" }\n    Read-Host \"Press Enter to exit...\"\n    Exit\n}\n\n# 4. Set up file paths\n$targetMsi = $msiFiles[0].FullName\n$logFile = Join-Path -Path $currentDir -ChildPath \"install_debug.log\"\n\nWrite-Host \"------------------------------------------------\" -ForegroundColor Cyan\nWrite-Host \"\ud83d\ude80 Target Found: $($msiFiles[0].Name)\" -ForegroundColor Green\nWrite-Host \"\ud83d\udcdd Log File:     $logFile\" -ForegroundColor Yellow\nWrite-Host \"------------------------------------------------\" -ForegroundColor Cyan\n\n# 5. Run MSIEXEC\n# /i   = Install\n# /L*v = Log all information (Verbose)\ntry {\n    Start-Process -FilePath \"msiexec.exe\" -ArgumentList \"/i `\"$targetMsi`\" /L*v `\"$logFile`\"\" -Wait\n    Write-Host \"\u2705 Installer finished.\" -ForegroundColor Green\n}\ncatch {\n    Write-Host \"\u274c Failed to launch msiexec.\" -ForegroundColor Red\n    Write-Error $_\n}\n\n# 6. Pause so you can read the output\nRead-Host \"Press Enter to close this window...\"\n",
    "e2e/get-race-info.py": "import json\nimport os\nimport glob\nfrom datetime import datetime\n\ndef get_latest_race_file(data_dir):\n    \"\"\"Finds the most recently modified race data file in the directory.\"\"\"\n    list_of_files = glob.glob(os.path.join(data_dir, '*.json'))\n    if not list_of_files:\n        return None\n    latest_file = max(list_of_files, key=os.path.getmtime)\n    return latest_file\n\ndef main():\n    data_dir = os.path.join('web_service', 'backend', 'data')\n    output_file = 'race-info.txt'\n\n    if not os.path.exists(data_dir):\n        with open(output_file, 'w') as f:\n            f.write(\"Data directory not found.\\n\")\n        return\n\n    latest_file = get_latest_race_file(data_dir)\n\n    if not latest_file:\n        with open(output_file, 'w') as f:\n            f.write(\"No race data files found.\\n\")\n        return\n\n    try:\n        with open(latest_file, 'r') as f:\n            race_data = json.load(f)\n    except (json.JSONDecodeError, IOError) as e:\n        with open(output_file, 'w') as f:\n            f.write(f\"Error reading race data file: {e}\\n\")\n        return\n\n    if not race_data or not isinstance(race_data, list):\n        with open(output_file, 'w') as f:\n            f.write(\"Race data is empty or not in the expected format.\\n\")\n        return\n\n    # Assuming the first race in the list is the one we want.\n    # A better approach might be to sort by start_time if available.\n    latest_race = race_data[0]\n\n    venue = latest_race.get('venue', 'N/A')\n    race_number = latest_race.get('raceNumber', 'N/A') # Use alias\n    runners = latest_race.get('runners', [])\n    num_runners = len(runners)\n\n    with open(output_file, 'w') as f:\n        f.write(f\"Latest Race Info:\\n\")\n        f.write(f\"  Track: {venue}\\n\")\n        f.write(f\"  Race #: {race_number}\\n\")\n        f.write(f\"  Field Size: {num_runners}\\n\")\n\nif __name__ == \"__main__\":\n    main()\n",
    "electron/resources/.gitkeep": "",
    "electron/secure-settings-manager.js": "// electron/secure-settings-manager.js\nconst { app } = require('electron');\nconst fs = require('fs');\nconst path = require('path');\n\nconst SETTINGS_FILE = path.join(app.getPath('userData'), 'settings.json');\n\nclass SecureSettingsManager {\n constructor() {\n this.settings = this.loadSettings();\n }\n\n loadSettings() {\n try {\n if (fs.existsSync(SETTINGS_FILE)) {\n const data = fs.readFileSync(SETTINGS_FILE, 'utf-8');\n return JSON.parse(data);\n }\n } catch (error) {\n console.error('Error loading settings:', error);\n }\n return {};\n }\n\n saveSettings() {\n try {\n fs.writeFileSync(SETTINGS_FILE, JSON.stringify(this.settings, null, 2));\n } catch (error) {\n console.error('Error saving settings:', error);\n }\n }\n\n getApiKey() {\n return this.settings.apiKey || null;\n }\n\n saveApiKey(apiKey) {\n this.settings.apiKey = apiKey;\n this.saveSettings();\n return { success: true };\n }\n\n getBetfairCredentials() {\n return this.settings.betfair || null;\n }\n\n saveBetfairCredentials(credentials) {\n this.settings.betfair = credentials;\n this.saveSettings();\n return { success: true };\n }\n}\n\nmodule.exports = new SecureSettingsManager();\n",
    "fortuna-desktop.spec": "# -*- mode: python ; coding: utf-8 -*-\nfrom PyInstaller.utils.hooks import collect_submodules, collect_data_files\nfrom pathlib import Path\nimport sys\nimport os\n\nblock_cipher = None\n\n# Absolute paths avoid CI confusion\nproject_root = Path(os.getcwd()).absolute()\nbackend_root = project_root / 'web_service' / 'backend'\nfrontend_out = project_root / 'web_service' / 'frontend' / 'public'\n\nprint(f\"[SPEC] Project Root: {project_root}\")\nprint(f\"[SPEC] Frontend: {frontend_out}\")\n\nif not frontend_out.exists():\n    print(\"[SPEC] WARNING: Frontend public dir not found. Build might fail at runtime.\")\n\ndatas = [\n    (str(frontend_out), 'public'),\n    (str(backend_root / 'data'), 'web_service/backend/data'),\n    (str(backend_root / 'json'), 'web_service/backend/json')\n]\n\n# Collect Uvicorn & FastAPI internals\ndatas += collect_data_files('uvicorn')\ndatas += collect_data_files('fastapi')\n\nhiddenimports = [\n    'uvicorn', 'uvicorn.logging', 'uvicorn.loops', 'uvicorn.loops.auto',\n    'uvicorn.protocols', 'uvicorn.protocols.http', 'uvicorn.protocols.http.auto',\n    'uvicorn.lifespan.on',\n    'fastapi', 'starlette', 'pydantic', 'structlog', 'tenacity',\n    'webview', 'webview.platforms.winforms', 'clr',\n    'win32timezone', 'win32service', 'win32event', 'servicemanager'\n]\nhiddenimports += collect_submodules('web_service.backend')\n\na = Analysis(\n    [str(project_root / 'run_desktop_app.py')],\n    pathex=[str(project_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\nexe = EXE(\n    pyz,\n    a.scripts,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    name='Fortuna-Desktop',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    runtime_tmpdir=None,\n    console=False, # GUI Mode\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\ncoll = COLLECT(\n    exe,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    name='Fortuna-Desktop',\n)",
    "fortuna_launcher.py": "#!/usr/bin/env python3\n\"\"\"\nFortuna Faucet - Enhanced Standalone Launcher for Windows 10 Home\nNo Docker, no special permissions, just pure Python magic\nRun this file and your browser opens automatically with all the bells and whistles\n\"\"\"\n\nimport sys\nimport os\nimport subprocess\nimport threading\nimport time\nimport webbrowser\nimport socket\nimport json\nfrom pathlib import Path\nfrom typing import Optional\nfrom datetime import datetime\n\n# ====================================================================\n# CONFIGURATION\n# ====================================================================\nAPP_NAME = \"Fortuna Faucet\"\nAPP_VERSION = \"3.1.0\"\nDEFAULT_HOST = \"127.0.0.1\"\nDEFAULT_PORT = 8000\nBACKEND_STARTUP_TIMEOUT = 15\nHEALTH_CHECK_ATTEMPTS = 30\nLOG_DIR = Path(\"logs\")\nLOG_DIR.mkdir(exist_ok=True)\n\n# ====================================================================\n# COLORS FOR WINDOWS CONSOLE\n# ====================================================================\nclass Colors:\n    \"\"\"ANSI color codes\"\"\"\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKCYAN = '\\033[96m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n    RESET = '\\033[0m'\n\n# Try to enable ANSI colors on Windows 10\ntry:\n    import ctypes\n    kernel32 = ctypes.windll.kernel32\n    kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)\nexcept:\n    pass\n\n# ====================================================================\n# LOGGING\n# ====================================================================\nclass Logger:\n    \"\"\"Dual logging to console and file\"\"\"\n    def __init__(self):\n        self.log_file = LOG_DIR / f\"fortuna_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n\n    def write(self, level: str, message: str):\n        \"\"\"Write to both console and file\"\"\"\n        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n        log_line = f\"[{timestamp}] [{level}] {message}\"\n\n        with open(self.log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(log_line + \"\\n\")\n\nlogger = Logger()\n\n# ====================================================================\n# HELPER FUNCTIONS\n# ====================================================================\ndef print_banner():\n    \"\"\"Print welcome banner\"\"\"\n    banner = f\"\"\"\n{Colors.BOLD}{Colors.OKGREEN}\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                            \u2551\n\u2551              \ud83d\udc34  {APP_NAME} v{APP_VERSION}  \ud83d\udc34              \u2551\n\u2551         Enhanced Launcher - Windows 10 Home Ready         \u2551\n\u2551                                                            \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n{Colors.ENDC}\n\"\"\"\n    print(banner)\n\ndef print_success(msg: str, icon: str = \"\u2713\"):\n    \"\"\"Print success message\"\"\"\n    output = f\"{Colors.OKGREEN}{icon}{Colors.ENDC} {msg}\"\n    print(output)\n    logger.write(\"SUCCESS\", msg)\n\ndef print_warning(msg: str, icon: str = \"\u26a0\"):\n    \"\"\"Print warning message\"\"\"\n    output = f\"{Colors.WARNING}{icon}{Colors.ENDC} {msg}\"\n    print(output)\n    logger.write(\"WARNING\", msg)\n\ndef print_error(msg: str, icon: str = \"\u2717\"):\n    \"\"\"Print error message\"\"\"\n    output = f\"{Colors.FAIL}{icon}{Colors.ENDC} {msg}\"\n    print(output)\n    logger.write(\"ERROR\", msg)\n\ndef print_info(msg: str, icon: str = \"\u2139\"):\n    \"\"\"Print info message\"\"\"\n    output = f\"{Colors.OKBLUE}{icon}{Colors.ENDC} {msg}\"\n    print(output)\n    logger.write(\"INFO\", msg)\n\ndef print_step(step_num: int, total: int, msg: str):\n    \"\"\"Print step counter\"\"\"\n    output = f\"\\n{Colors.BOLD}[{step_num}/{total}] {msg}{Colors.ENDC}\"\n    print(output)\n    logger.write(\"STEP\", f\"[{step_num}/{total}] {msg}\")\n\ndef print_section(title: str):\n    \"\"\"Print section divider\"\"\"\n    output = f\"\\n{Colors.BOLD}{Colors.OKCYAN}{'\u2500' * 60}{Colors.ENDC}\"\n    print(output)\n    print(f\"{Colors.BOLD}{Colors.OKCYAN}{title}{Colors.ENDC}\")\n    print(f\"{Colors.BOLD}{Colors.OKCYAN}{'\u2500' * 60}{Colors.ENDC}\\n\")\n\n# ====================================================================\n# ENVIRONMENT CHECKS\n# ====================================================================\ndef check_python_version() -> bool:\n    \"\"\"Check if Python version is compatible\"\"\"\n    if sys.version_info < (3, 10):\n        print_error(f\"Python 3.10+ required, you have {sys.version_info.major}.{sys.version_info.minor}\")\n        return False\n    print_success(f\"Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n    return True\n\ndef check_project_structure() -> bool:\n    \"\"\"Check if we're in the right directory\"\"\"\n    required_dirs = [\n        \"web_service/backend\",\n        \"web_platform/frontend\"\n    ]\n    required_files = [\n        \"web_service/backend/requirements.txt\",\n        \"web_platform/frontend/package.json\"\n    ]\n\n    print_info(\"Checking project structure...\")\n    all_good = True\n    for d in required_dirs:\n        if Path(d).exists():\n            print_success(f\"Found: {d}\")\n        else:\n            print_error(f\"Missing: {d}\")\n            all_good = False\n\n    for f in required_files:\n        if Path(f).exists():\n            print_success(f\"Found: {f}\")\n        else:\n            print_error(f\"Missing: {f}\")\n            all_good = False\n\n    return all_good\n\ndef check_port_available(port: int) -> bool:\n    \"\"\"Check if port is available\"\"\"\n    try:\n        sock = socket.create_connection((\"127.0.0.1\", port), timeout=1)\n        sock.close()\n        print_error(f\"Port {port} is already in use by another application\")\n        return False\n    except (socket.timeout, ConnectionRefusedError, OSError):\n        print_success(f\"Port {port} is available\")\n        return True\n\n# ====================================================================\n# DEPENDENCY CHECK & INSTALL\n# ====================================================================\ndef check_and_install_dependencies() -> bool:\n    \"\"\"Check if dependencies are installed, install if needed\"\"\"\n    print_info(\"Checking Python dependencies...\")\n\n    required_packages = {\n        \"fastapi\": \"FastAPI web framework\",\n        \"uvicorn\": \"ASGI server\",\n        \"pydantic\": \"Data validation\",\n    }\n\n    missing = []\n    for package, description in required_packages.items():\n        try:\n            __import__(package)\n            print_success(f\"{description} (installed)\")\n        except ImportError:\n            print_warning(f\"{description} (NOT installed)\")\n            missing.append(package)\n\n    if not missing:\n        print_success(\"All core dependencies satisfied!\")\n        return True\n\n    print()\n    print_info(f\"Installing {len(missing)} missing package(s)...\")\n    print_info(\"This may take 2-3 minutes on first run...\")\n    print()\n\n    try:\n        subprocess.run(\n            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\"],\n            check=True,\n            capture_output=True,\n            timeout=120\n        )\n\n        subprocess.run(\n            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + missing,\n            check=True,\n            capture_output=True,\n            timeout=300\n        )\n        print_success(\"Dependencies installed successfully!\")\n        return True\n    except subprocess.CalledProcessError as e:\n        print_error(f\"Failed to install dependencies: {e}\")\n        print_info(\"Try running manually in PowerShell:\")\n        print(f\"  python -m pip install -r web_service/backend/requirements.txt\")\n        logger.write(\"ERROR\", f\"Dependency installation failed: {e}\")\n        return False\n    except subprocess.TimeoutExpired:\n        print_error(\"Installation timed out (took too long)\")\n        return False\n\n# ====================================================================\n# FRONTEND BUILD\n# ====================================================================\ndef build_frontend() -> bool:\n    \"\"\"Build Next.js frontend if needed\"\"\"\n    frontend_dir = Path(\"web_platform/frontend\")\n    build_dir = frontend_dir / \"out\"\n\n    if build_dir.exists() and (build_dir / \"index.html\").exists():\n        print_success(\"Frontend already built\")\n        return True\n\n    print_info(\"Frontend build required...\")\n\n    # Check for Node.js\n    try:\n        subprocess.run([\"npm\", \"--version\"], capture_output=True, timeout=5, check=True)\n    except:\n        print_warning(\"Node.js not found - frontend may not load properly\")\n        print_info(\"To fix: Install Node.js from https://nodejs.org/\")\n        logger.write(\"WARNING\", \"Node.js not found for frontend build\")\n        return True\n\n    print_info(\"Building frontend (this takes ~30 seconds)...\")\n    print_info(\"(Progress shown in logs)\")\n\n    try:\n        subprocess.run(\n            [\"npm\", \"ci\"],\n            cwd=str(frontend_dir),\n            capture_output=True,\n            timeout=120,\n            check=True\n        )\n        subprocess.run(\n            [\"npm\", \"run\", \"build\"],\n            cwd=str(frontend_dir),\n            capture_output=True,\n            timeout=180,\n            check=True\n        )\n        print_success(\"Frontend built successfully\")\n        return True\n    except subprocess.TimeoutExpired:\n        print_warning(\"Frontend build timed out, continuing anyway...\")\n        logger.write(\"WARNING\", \"Frontend build timed out\")\n        return True\n    except subprocess.CalledProcessError as e:\n        print_warning(f\"Frontend build failed: {e}\")\n        logger.write(\"WARNING\", f\"Frontend build failed: {e}\")\n        return True\n    except Exception as e:\n        print_warning(f\"Frontend build error: {e}\")\n        logger.write(\"WARNING\", f\"Frontend build error: {e}\")\n        return True\n\n# ====================================================================\n# BACKEND SERVER\n# ====================================================================\ndef start_backend() -> Optional[subprocess.Popen]:\n    \"\"\"Start the FastAPI backend server\"\"\"\n    print_info(\"Starting FastAPI server...\")\n\n    try:\n        process = subprocess.Popen(\n            [\n                sys.executable,\n                \"-m\", \"uvicorn\",\n                \"web_service.backend.main:app\",\n                \"--host\", DEFAULT_HOST,\n                \"--port\", str(DEFAULT_PORT),\n                \"--log-level\", \"info\"\n            ],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            bufsize=1\n        )\n\n        # Give it a moment to start\n        time.sleep(1)\n\n        if process.poll() is not None:\n            # Process exited already\n            stdout, stderr = process.communicate()\n            print_error(f\"Backend failed to start: {stderr[:200]}\")\n            logger.write(\"ERROR\", f\"Backend startup failed: {stderr}\")\n            return None\n\n        print_success(\"Backend server started\")\n        logger.write(\"SUCCESS\", \"Backend server started successfully\")\n        return process\n\n    except Exception as e:\n        print_error(f\"Failed to start backend: {e}\")\n        logger.write(\"ERROR\", f\"Backend start exception: {e}\")\n        return None\n\ndef wait_for_backend_ready(max_retries: int = HEALTH_CHECK_ATTEMPTS) -> bool:\n    \"\"\"Wait for backend to respond to health check\"\"\"\n    import urllib.request\n    import urllib.error\n\n    print_info(\"Waiting for backend to be ready...\")\n\n    for attempt in range(max_retries):\n        try:\n            response = urllib.request.urlopen(\n                f\"http://{DEFAULT_HOST}:{DEFAULT_PORT}/api/health\",\n                timeout=2\n            )\n            if response.status == 200:\n                elapsed = attempt + 1\n                print_success(f\"Backend ready in {elapsed} second(s)\")\n                logger.write(\"SUCCESS\", f\"Backend health check passed in {elapsed}s\")\n                return True\n        except (urllib.error.URLError, urllib.error.HTTPError, Exception):\n            if attempt < max_retries - 1:\n                time.sleep(1)\n\n    print_error(\"Backend did not respond after 30 seconds\")\n    logger.write(\"ERROR\", \"Backend health check failed - no response after 30s\")\n    return False\n\n# ====================================================================\n# BROWSER LAUNCHER\n# ====================================================================\ndef open_browser():\n    \"\"\"Open browser to the application\"\"\"\n    url = f\"http://{DEFAULT_HOST}:{DEFAULT_PORT}\"\n    try:\n        print_info(f\"Opening browser at {url}...\")\n        webbrowser.open(url)\n        time.sleep(1)  # Give browser time to open\n        print_success(\"Browser opened!\")\n        logger.write(\"SUCCESS\", f\"Browser opened at {url}\")\n    except Exception as e:\n        print_warning(f\"Could not open browser automatically: {e}\")\n        print_info(f\"Please manually open: {url}\")\n        logger.write(\"WARNING\", f\"Browser auto-open failed: {e}\")\n\n# ====================================================================\n# SYSTEM INFO\n# ====================================================================\ndef print_system_info():\n    \"\"\"Print system information\"\"\"\n    print_section(\"System Information\")\n    print_success(f\"Python: {sys.version.split()[0]}\")\n    print_success(f\"Platform: {sys.platform}\")\n    print_success(f\"Current Directory: {Path.cwd()}\")\n    print_success(f\"Log Directory: {LOG_DIR.absolute()}\")\n    print()\n\n# ====================================================================\n# MAIN APPLICATION\n# ====================================================================\ndef main():\n    \"\"\"Main entry point\"\"\"\n    print_banner()\n    print_system_info()\n\n    # Step 1: Environment validation\n    print_step(1, 5, \"Validating environment...\")\n    if not check_python_version():\n        return 1\n    if not check_project_structure():\n        return 1\n    if not check_port_available(DEFAULT_PORT):\n        return 1\n    print()\n\n    # Step 2: Dependencies\n    print_step(2, 5, \"Installing dependencies...\")\n    if not check_and_install_dependencies():\n        return 1\n    print()\n\n    # Step 3: Frontend build\n    print_step(3, 5, \"Building frontend...\")\n    build_frontend()\n    print()\n\n    # Step 4: Start backend\n    print_step(4, 5, \"Starting backend server...\")\n    backend_process = start_backend()\n    if not backend_process:\n        return 1\n\n    if not wait_for_backend_ready():\n        backend_process.terminate()\n        logger.write(\"ERROR\", \"Application startup failed - health check timeout\")\n        return 1\n    print()\n\n    # Step 5: Open browser\n    print_step(5, 5, \"Launching browser...\")\n    open_browser()\n    print()\n\n    # Success!\n    print(f\"{Colors.BOLD}{Colors.OKGREEN}\")\n    print(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\")\n    print(\"\u2551                                                            \u2551\")\n    print(\"\u2551          \ud83c\udf89  FORTUNA IS RUNNING!  \ud83c\udf89                     \u2551\")\n    print(\"\u2551                                                            \u2551\")\n    print(f\"\u2551  Access your app at: http://{DEFAULT_HOST}:{DEFAULT_PORT:<5}                      \u2551\")\n    print(\"\u2551                                                            \u2551\")\n    print(f\"\u2551  Log file: {LOG_DIR / 'fortuna_*.log':<40}  \u2551\")\n    print(\"\u2551                                                            \u2551\")\n    print(\"\u2551  Press Ctrl+C to stop the server                          \u2551\")\n    print(\"\u2551                                                            \u2551\")\n    print(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\")\n    print(f\"{Colors.ENDC}\")\n    print()\n\n    # Keep running\n    try:\n        while True:\n            time.sleep(0.1)\n    except KeyboardInterrupt:\n        print()\n        print_info(\"Shutting down gracefully...\")\n        backend_process.terminate()\n        try:\n            backend_process.wait(timeout=5)\n        except subprocess.TimeoutExpired:\n            backend_process.kill()\n        print_success(\"Fortuna stopped successfully\")\n        logger.write(\"SUCCESS\", \"Application stopped gracefully by user\")\n        return 0\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n",
    "playwright_test.js": "const { chromium } = require('playwright');\nconst { test, expect } = require('@playwright/test');\n\n(async () => {\n  const browser = await chromium.launch();\n  const page = await browser.newPage();\n\n  // Navigate to the dashboard\n  await page.goto('http://localhost:3001');\n\n  // Wait for the initial loading to complete.\n  // We expect the skeleton loaders to disappear.\n  await expect(page.locator('div:has-text(\"Loading races...\")')).toHaveCount(0, { timeout: 15000 });\n\n  // Check for the manual override panel\n  const overridePanel = page.locator('div:has-text(\"Fetch Failed: AtTheRaces\")');\n  await expect(overridePanel).toBeVisible({ timeout: 10000 });\n\n  // Check for the text area with the correct URL\n  // The date is a placeholder, as it can change. The important part is the base URL.\n  const textArea = overridePanel.locator('textarea');\n  await expect(textArea).toHaveAttribute('value', /https:\\/\\/www\\.attheraces\\.com\\/racecards\\/\\d{4}-\\d{2}-\\d{2}/);\n\n\n  // Take a screenshot for visual confirmation\n  await page.screenshot({ path: 'manual-override-panel.png' });\n\n  await browser.close();\n})();\n",
    "podman-compose.yml": "version: '3.8'\n\nservices:\n  fortuna:\n    build: .\n    container_name: fortuna-faucet\n    ports:\n      - \"8000:8000\"\n    environment:\n      - PYTHONUNBUFFERED=1\n      - FORTUNA_MODE=podman\n    volumes:\n      - ./web_service/backend/data:/app/web_service/backend/data\n      - ./web_service/backend/logs:/app/web_service/backend/logs\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 5s\n",
    "pytest.ini": "[pytest]\npythonpath = .\ntestpaths = tests\npython_files = test_*.py\naddopts = -v\nasyncio_mode = auto\nasyncio_default_fixture_loop_scope = function\n",
    "scripts/convert_to_json.py": "# convert_to_json.py\n# This script now contains the full, enlightened logic to handle all manifest formats and path styles.\n\nimport json\nimport os\nimport sys\nfrom multiprocessing import Process\nfrom multiprocessing import Queue\n\n# --- Configuration ---\nMANIFEST_FILES = [\n    \"MANIFEST_PART1_BACKEND.json\",\n    \"MANIFEST_PART2_FRONTEND.json\",\n    \"MANIFEST_PART3_SUPPORT.json\",\n    \"MANIFEST_PART4_ROOT.json\",\n]\nOUTPUT_DIR = \"ReviewableJSON\"\nFILE_PROCESSING_TIMEOUT = 10\nEXCLUDED_FILES = [\"package-lock.json\"]\nMAX_FILE_SIZE_MB = 10  # Max file size in megabytes\n\n\ndef read_json_manifest(manifest_path: str) -> list[str]:\n    \"\"\"Reads a JSON manifest file and returns a list of file paths.\"\"\"\n    try:\n        with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except (json.JSONDecodeError, FileNotFoundError):\n        return []\n\n\n# --- SANDBOXED FILE READ (Unchanged) ---\ndef _sandboxed_file_read(file_path, q):\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            content = f.read()\n        q.put({\"file_path\": file_path, \"content\": content})\n    except Exception as e:\n        q.put({\"error\": str(e)})\n\n\ndef convert_file_to_json_sandboxed(file_path):\n    # --- Pre-flight check: File size ---\n    try:\n        file_size = os.path.getsize(file_path)\n        if file_size > MAX_FILE_SIZE_MB * 1024 * 1024:\n            return {\"error\": f\"File exceeds {MAX_FILE_SIZE_MB}MB size limit.\"}\n    except FileNotFoundError:\n        return {\"error\": \"File not found.\"}\n    except Exception as e:\n        return {\"error\": f\"Could not check file size: {e}\"}\n\n    q = Queue()\n    p = Process(target=_sandboxed_file_read, args=(file_path, q))\n    p.start()\n    p.join(timeout=FILE_PROCESSING_TIMEOUT)\n\n    try:\n        if p.is_alive():\n            print(f\"    [WARNING] Process for {file_path} timed out. Attempting graceful termination...\")\n            p.terminate()\n            p.join(timeout=2)  # Give it a moment to terminate gracefully\n\n            if p.is_alive():\n                print(f\"    [ERROR] Graceful termination failed. Forcibly killing process...\")\n                p.kill()  # The ultimate \"just die\"\n                p.join()\n            return {\"error\": f\"Timeout: File processing took longer than {FILE_PROCESSING_TIMEOUT} seconds.\"}\n\n        if not q.empty():\n            return q.get()\n        return {\"error\": \"Unknown error in sandboxed read process.\"}\n    finally:\n        # \u2705 Properly close and flush the queue\n        try:\n            while not q.empty():\n                q.get_nowait()\n        except Exception:\n            pass\n        q.close()\n        q.join_thread()\n\n\n# --- Main Orchestrator ---\ndef main():\n    print(f\"\\n{'=' * 60}\\nStarting IRONCLAD JSON backup process... (Enlightened Scribe Edition)\\n{'=' * 60}\")\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    all_local_paths = []\n    for manifest in MANIFEST_FILES:\n        print(f\"--> Parsing manifest: {manifest}\")\n        paths = read_json_manifest(manifest)\n        if paths:\n            all_local_paths.extend(paths)\n            print(f\"    --> Found {len(paths)} valid file paths.\")\n        else:\n            print(f\"    [WARNING] Manifest not found or is empty: {manifest}\")\n\n    if not all_local_paths:\n        print(\"\\n[FATAL] No valid file paths found in any manifest. Aborting.\")\n        sys.exit(1)\n\n    unique_local_paths = sorted(list(set(all_local_paths)))\n    print(f\"\\nFound a total of {len(unique_local_paths)} unique files to process.\")\n    processed_count, failed_count = 0, 0\n\n    for local_path in unique_local_paths:\n        if os.path.basename(local_path) in EXCLUDED_FILES:\n            print(f\"\\n--> Skipping excluded file: {local_path}\")\n            failed_count += 1\n            continue\n        print(f\"\\nProcessing: {local_path}\")\n        json_data = convert_file_to_json_sandboxed(local_path)\n        if json_data and \"error\" not in json_data:\n            output_path = os.path.join(OUTPUT_DIR, local_path + \".json\")\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(json_data, f, indent=4)\n            print(f\"    [SUCCESS] Saved backup to {output_path}\")\n            processed_count += 1\n        else:\n            error_msg = json_data.get(\"error\", \"Unknown error\") if json_data else \"File not found\"\n            print(f\"    [ERROR] Failed to process {local_path}: {error_msg}\")\n            failed_count += 1\n\n    print(f\"\\n{'=' * 60}\")\n    print(\"Backup process complete.\")\n    print(f\"Successfully processed: {processed_count}/{len(unique_local_paths)}\")\n    print(f\"Failed/Skipped: {failed_count}\")\n    print(f\"{'=' * 60}\")\n\n    if failed_count > 0:\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/fortuna-quick-start.ps1": "<#\n.SYNOPSIS\n    Fortuna Supreme Developer Bootstrapper (v2.0)\n    Aligns with CI/CD 'Champion' workflows for robust local development.\n\n.DESCRIPTION\n    - Auto-detects and kills blocking processes on ports 8000/3000\n    - Validates Python/Node environments\n    - Installs dependencies using fast caching strategies (npm ci)\n    - Launches Backend (FastAPI) and Frontend (Next.js) in parallel\n\n.PARAMETER Clean\n    Removes build artifacts and caches (.next, __pycache__, etc.) before starting.\n\n.PARAMETER Production\n    Builds the frontend for production instead of running in dev mode.\n\n.PARAMETER NoFrontend\n    Launches only the backend API.\n#>\n\nparam(\n    [switch]$SkipChecks,\n    [switch]$NoFrontend,\n    [switch]$Production,\n    [switch]$Clean,\n    [switch]$Help,\n    [string]$PythonExecutable\n)\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Configuration ---\n$PROJECT_ROOT = Resolve-Path \"$PSScriptRoot\\..\"\n$BACKEND_DIR  = Join-Path $PROJECT_ROOT \"web_service\\backend\"\n$FRONTEND_DIR = Join-Path $PROJECT_ROOT \"web_service\\frontend\"\n$PYTHON_CMD   = if ($PythonExecutable) { $PythonExecutable } else { \"py -3.11\" }\n\n# --- Helper Functions ---\nfunction Show-Step($msg) { Write-Host \"`n\ud83d\udd35 $msg\" -ForegroundColor Cyan }\nfunction Show-Success($msg) { Write-Host \"   \u2705 $msg\" -ForegroundColor Green }\nfunction Show-Warn($msg) { Write-Host \"   \u26a0\ufe0f  $msg\" -ForegroundColor Yellow }\nfunction Show-Fail($msg) { Write-Host \"   \u274c $msg\" -ForegroundColor Red; exit 1 }\n\nfunction Clear-BuildCache {\n    Show-Step \"Cleaning build caches (-Clean active)...\"\n    $paths = @(\n        (Join-Path $FRONTEND_DIR \".next\"),\n        (Join-Path $FRONTEND_DIR \"node_modules\\.cache\"),\n        (Join-Path $BACKEND_DIR \"__pycache__\"),\n        (Join-Path $BACKEND_DIR \"*.spec\")\n    )\n    foreach ($p in $paths) {\n        if (Test-Path $p) {\n            Remove-Item -Path $p -Recurse -Force -ErrorAction SilentlyContinue\n            Write-Host \"   Deleted: $p\" -ForegroundColor Gray\n        }\n    }\n    Show-Success \"Cache cleared.\"\n}\n\nfunction Check-Port($port, $name) {\n    $process = Get-NetTCPConnection -LocalPort $port -State Listen -ErrorAction SilentlyContinue | Select-Object -ExpandProperty OwningProcess -Unique\n    if ($process) {\n        Show-Warn \"Port $port ($name) is blocked by PID $process. Killing it...\"\n        Stop-Process -Id $process -Force\n        Show-Success \"Port $port freed.\"\n    }\n}\n\n# --- Main Execution ---\n\nWrite-Host \"`n\ud83d\ude80 FORTUNA SUPREME BOOTSTRAPPER\" -ForegroundColor Magenta\nWrite-Host \"=================================\" -ForegroundColor Gray\n\nif ($Help) { Get-Help $PSCommandPath -Detailed; exit }\nif ($Clean) { Clear-BuildCache }\n\n# 1. Pre-flight Checks\nif (-not $SkipChecks) {\n    Show-Step \"System Health Check\"\n    Check-Port 8000 \"Backend API\"\n    Check-Port 3000 \"Frontend UI\"\n}\n\n# 2. Backend Setup\nShow-Step \"Preparing Backend (Python)...\"\nif (-not (Test-Path $BACKEND_DIR)) { Show-Fail \"Backend directory not found at: $BACKEND_DIR\" }\n\n# Check for Python\ntry {\n    & $PYTHON_CMD --version\n    Show-Success \"Python executable found.\"\n} catch {\n    Show-Fail \"Python not found in PATH or specified executable is invalid.\"\n}\n\n# Upgrade Pip & Wheel\nWrite-Host \"   Upgrading pip/wheel...\" -NoNewline\n& $PYTHON_CMD -m pip install --upgrade pip wheel --quiet\nWrite-Host \" Done.\" -ForegroundColor Green\n\n# Verify Critical Imports\nWrite-Host \"   Verifying dependencies...\" -NoNewline\n$testImport = & $PYTHON_CMD -c \"import fastapi, uvicorn, structlog; print('OK')\" 2>$null\nif ($testImport -match \"OK\") {\n    Write-Host \" OK (Skipping install)\" -ForegroundColor Green\n} else {\n    Write-Host \" Missing.\" -ForegroundColor Yellow\n    Show-Warn \"Installing requirements from requirements.txt...\"\n    Push-Location $BACKEND_DIR\n    & $PYTHON_CMD -m pip install -r requirements.txt\n    Pop-Location\n}\n\n# 3. Frontend Setup\nif (-not $NoFrontend) {\n    Show-Step \"Preparing Frontend (Node.js)...\"\n    if (-not (Test-Path $FRONTEND_DIR)) { Show-Fail \"Frontend directory not found at: $FRONTEND_DIR\" }\n\n    Push-Location $FRONTEND_DIR\n\n    # Smart Install (npm ci vs install)\n    if (Test-Path \"node_modules\") {\n        Show-Success \"Node modules present.\"\n    } else {\n        Show-Warn \"Installing dependencies (npm ci)...\"\n        npm ci --silent\n    }\n\n    # Production Build Logic\n    if ($Production) {\n        Show-Step \"Building for Production...\"\n        npm run build\n        Show-Success \"Production build complete.\"\n    }\n\n    Pop-Location\n}\n\n# 4. Launch Sequence\nShow-Step \"Launching Services...\"\n\n# In CI, we need to use Start-Job to get process output and add a wait\n# loop to ensure the service is ready before tests run.\nif ($env:CI) {\n    Show-Warn \"CI environment detected. Using Start-Job for backend...\"\n    $job = Start-Job -ScriptBlock {\n        # This script block runs in a separate process\n        param($path, $cmd)\n        Set-Location $path\n        & $cmd -m uvicorn main:app --port 8000 --host 0.0.0.0\n    } -ArgumentList $BACKEND_DIR, $PYTHON_CMD\n\n    Show-Success \"Backend job started (Job ID: $($job.Id))\"\n\n    # Wait for the backend to become healthy (up to 30 seconds)\n    $healthCheckUrl = \"http://localhost:8000/health\"\n    Write-Host \"   Pinging backend health endpoint ($healthCheckUrl)...\" -NoNewline\n    $timeout = 30\n    $start = Get-Date\n    $healthy = $false\n    while ((Get-Date) -lt $start.AddSeconds($timeout)) {\n        try {\n            $response = Invoke-WebRequest -Uri $healthCheckUrl -UseBasicParsing -TimeoutSec 2\n            if ($response.StatusCode -eq 200) {\n                Write-Host \" OK\" -ForegroundColor Green\n                Show-Success \"Backend is healthy and responding.\"\n                $healthy = $true\n                break\n            }\n        } catch {\n            # Catch exceptions for connection refused, etc.\n        }\n        Start-Sleep -Seconds 1\n        Write-Host \".\" -NoNewline\n    }\n\n    if (-not $healthy) {\n        Write-Host \" FAILED\" -ForegroundColor Red\n        Show-Fail \"Backend did not start within the $timeout-second timeout.\"\n        Receive-Job $job # Display any output from the failed job\n        Stop-Job $job\n        exit 1\n    }\n\n} else {\n    # -- LOCAL DEVELOPMENT (Existing Logic) --\n    $backendScript = \"cd `\"$BACKEND_DIR`\"; & $PYTHON_CMD -m uvicorn main:app --reload --port 8000\"\n    Start-Process pwsh -ArgumentList \"-NoExit\", \"-Command\", $backendScript -WindowStyle Normal\n    Show-Success \"Backend launched on Port 8000\"\n}\n\n# Launch Frontend (No changes needed here for now)\nif (-not $NoFrontend) {\n    if ($env:CI) {\n        # In CI, we would typically build and serve statically, but for this\n        # script's purpose, we'll assume the backend handles the UI\n        Show-Warn \"Frontend launch skipped in CI mode for this script.\"\n    } else {\n        $cmd = if ($Production) { \"start\" } else { \"dev\" }\n        $frontendScript = \"cd `\"$FRONTEND_DIR`\"; npm run $cmd\"\n        Start-Process pwsh -ArgumentList \"-NoExit\", \"-Command\", $frontendScript -WindowStyle Normal\n        Show-Success \"Frontend launched on Port 3000 ($cmd mode)\"\n    }\n}\n\n# Keep script running if interactive, otherwise exit for CI\nif ($env:CI) {\n    Write-Host \"`n\u2728 CI run complete. Exiting.\" -ForegroundColor Cyan\n} else {\n    Write-Host \"`n\u2728 Fortuna is running! Press Ctrl+C in the popup windows to stop.\" -ForegroundColor Cyan\n}\n",
    "scripts/generate_summary.py": "#!/usr/bin/env python3\n\"\"\"Generate GitHub Actions step summary with SmartFetcher health.\"\"\"\n\nimport json\nimport os\nfrom datetime import datetime\nfrom pathlib import Path\n\n\ndef main():\n    lines = [\"## \ud83d\udc34 Race Report Summary\\n\"]\n\n    # Metadata & Thresholds\n    metadata = {}\n    if Path(\"report-metadata.json\").exists():\n        try:\n            with open(\"report-metadata.json\") as f:\n                metadata = json.load(f)\n        except:\n            pass\n\n    # High-level metrics\n    metrics = {}\n    if Path(\"metrics.json\").exists():\n        try:\n            with open(\"metrics.json\") as f:\n                metrics = json.load(f)\n        except:\n            pass\n\n    # Warning Banner\n    race_count = metadata.get(\"race_count\", 0)\n    if race_count < 2:\n        lines.append(\"> [!WARNING]\\n\")\n        lines.append(\"> **Low race count detected!** Only {} qualified races found. Upstream sources may be degraded.\\n\".format(race_count))\n    elif metrics.get(\"errors\"):\n        lines.append(\"> [!IMPORTANT]\\n\")\n        lines.append(\"> Pipeline completed with {} non-fatal warnings.\\n\".format(len(metrics[\"errors\"])))\n\n    # Run info\n    lines.append(f\"**Generated:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\")\n    lines.append(f\"**Run Mode:** `{metadata.get('run_mode', 'N/A')}` | **Canary:** `{metadata.get('canary_health', 'N/A')}`\")\n    lines.append(f\"**Duration:** {metrics.get('duration_seconds', 0):.1f}s\")\n    lines.append(\"\")\n\n    # Results\n    if Path(\"qualified_races.json\").exists():\n        try:\n            with open(\"qualified_races.json\") as f:\n                data = json.load(f)\n            races = data.get(\"races\", [])\n\n            lines.append(\"### \ud83d\udcca Results\\n\")\n            lines.append(f\"**Qualified Races:** {len(races)}\")\n\n            if races:\n                venues = {}\n                for race in races:\n                    v = race.get(\"venue\", \"Unknown\")\n                    venues[v] = venues.get(v, 0) + 1\n\n                lines.append(f\"**Venues:** {len(venues)}\")\n                lines.append(\"\")\n                lines.append(\"| Venue | Races |\")\n                lines.append(\"|-------|-------|\")\n                for v, c in sorted(venues.items(), key=lambda x: -x[1])[:10]:\n                    lines.append(f\"| {v} | {c} |\")\n        except Exception as e:\n            lines.append(f\"\u26a0\ufe0f Error: {e}\")\n    else:\n        lines.append(\"### \u26a0\ufe0f No Results\\n\")\n        lines.append(\"No qualified races file generated.\")\n\n    lines.append(\"\")\n\n    # Browser verification\n    if Path(\"browser_verification.json\").exists():\n        try:\n            with open(\"browser_verification.json\") as f:\n                data = json.load(f)\n            lines.append(\"### \ud83c\udf10 Browser Status\\n\")\n\n            # Show test results\n            for name, result in data.get(\"tests\", {}).items():\n                status = \"\u2705\" if result.get(\"passed\") else \"\u274c\"\n                duration = result.get(\"duration_ms\", 0)\n                lines.append(f\"- {status} **{name}**: {result.get('message', 'N/A')} ({duration:.0f}ms)\")\n            \n            # Recommendations\n            recs = data.get(\"recommendations\", [])\n            if recs:\n                lines.append(\"\\n**Recommendations:**\")\n                for rec in recs[:3]:\n                    lines.append(f\"- {rec.get('message', '')}\")\n        except:\n            pass\n\n    lines.append(\"\")\n\n    # SmartFetcher Health\n    if Path(\"smartfetcher_health.json\").exists():\n        try:\n            with open(\"smartfetcher_health.json\") as f:\n                health = json.load(f)\n            \n            lines.append(\"### \ud83d\udd27 SmartFetcher Health\\n\")\n            if health.get(\"engines_used\"):\n                lines.append(\"**Engines Used:** \" + \", \".join(health[\"engines_used\"]))\n            else:\n                lines.append(\"*No engine health data captured in this run.*\")\n        except:\n            pass\n\n    lines.append(\"\")\n\n    # Adapter Firewall\n    if Path(\"adapter_stats.json\").exists():\n        try:\n            with open(\"adapter_stats.json\") as f:\n                stats = json.load(f)\n\n            firewalled = [s.get('name') for s in stats if s.get('consecutive_failures', 0) > 5]\n            at_risk = [s.get('name') for s in stats if 3 < s.get('consecutive_failures', 0) <= 5]\n\n            if firewalled or at_risk:\n                lines.append(\"### \ud83d\udd25 Adapter Firewall & Health\\n\")\n                if firewalled:\n                    lines.append(\"**Firewalled (Disabled):**\\n\")\n                    for name in firewalled:\n                        lines.append(f\"- \ud83d\udeab `{name}`\")\n                if at_risk:\n                    lines.append(\"\\n**At Risk (Close to firewall):**\\n\")\n                    for name in at_risk:\n                        lines.append(f\"- \u26a0\ufe0f `{name}`\")\n                lines.append(\"\")\n        except:\n            pass\n\n    lines.append(\"\\n---\")\n    lines.append(\"*Generated by Fortuna Race Pipeline*\")\n\n    print(\"\\n\".join(lines))\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/realtime-race-monitor.ps1": "<#\n.SYNOPSIS\n    Fortuna Real-Time Race Monitor (v1.0)\n    Builds, launches, and queries the backend service to provide live racecard comparisons.\n#>\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Configuration ---\n$PYTHON_VERSION = \"3.11\"\n$BACKEND_DIR    = \"web_service/backend\"\n$SPEC_FILE      = \"fortuna-unified.spec\"\n$SERVICE_PORT   = 8102\n$API_KEY        = \"a_secure_test_api_key_that_is_long_enough\" # Mock key for local execution\n\n# --- Helper Functions ---\nfunction Show-Step($msg) { Write-Host \"`n\ud83d\ude80 $msg\" -ForegroundColor Cyan }\nfunction Show-Success($msg) { Write-Host \"   \u2705 $msg\" -ForegroundColor Green }\nfunction Show-Warn($msg) { Write-Host \"   \u26a0\ufe0f  $msg\" -ForegroundColor Yellow }\nfunction Show-Fail($msg) { Write-Host \"   \u274c $msg\" -ForegroundColor Red; exit 1 }\n\n# --- Main Execution ---\ntry {\n    # 1. Environment Setup & Dependency Installation\n    Show-Step \"Preparing environment...\"\n    try {\n        $pyVer = & python --version 2>&1\n        if ($pyVer -notmatch $PYTHON_VERSION) {\n            Show-Warn \"Python version mismatch. Expected $($PYTHON_VERSION), found $($pyVer).\"\n        }\n        Show-Success \"Found Python: $pyVer\"\n    } catch {\n        Show-Fail \"Python not found. Please ensure Python $($PYTHON_VERSION) is in your PATH.\"\n    }\n\n    Show-Step \"Installing dependencies...\"\n    try {\n        python -m pip install --upgrade pip --quiet\n        pip install -r \"$($BACKEND_DIR)/requirements.txt\"\n        pip install pyinstaller==6.6.0\n        Show-Success \"All Python dependencies are installed.\"\n    } catch {\n        Show-Fail \"Failed to install dependencies. Check logs for details.\"\n    }\n\n\n    # 2. Build the Backend Executable\n    Show-Step \"Building backend executable with PyInstaller...\"\n\n    # Clean previous builds\n    if (Test-Path \"dist\") { Remove-Item -Recurse -Force \"dist\" }\n    if (Test-Path \"build\") { Remove-Item -Recurse -Force \"build\" }\n\n    # PyInstaller requires these directories to exist at build time\n    New-Item -ItemType Directory -Path \"$($BACKEND_DIR)/data\", \"$($BACKEND_DIR)/json\", \"$($BACKEND_DIR)/logs\" -Force | Out-Null\n\n    try {\n        pyinstaller --noconfirm --clean $SPEC_FILE\n        Show-Success \"Backend executable built successfully.\"\n    } catch {\n        Show-Fail \"PyInstaller build failed. See output for details.\"\n    }\n\n    # 3. Launch the Backend Service\n    Show-Step \"Launching backend service...\"\n    $exePath = Resolve-Path \"dist/fortuna-webservice/fortuna-webservice.exe\"\n    if (-not (Test-Path $exePath)) {\n        Show-Fail \"Could not find the built executable at $($exePath).\"\n    }\n\n    # The executable needs its runtime directories in its own folder\n    $exeDir = Split-Path $exePath -Parent\n    New-Item -ItemType Directory -Path \"$($exeDir)/data\", \"$($exeDir)/json\", \"$($exeDir)/logs\" -Force | Out-Null\n    Show-Success \"Created runtime directories in $($exeDir).\"\n\n    # Start the process in the background\n    $process = Start-Process -FilePath $exePath -WindowStyle Hidden -PassThru\n    $Global:BackendProcessId = $process.Id # Store PID for cleanup\n    Show-Success \"Backend service is starting in the background (PID: $($Global:BackendProcessId)).\"\n\n\n    # 4. Health Check & API Query\n    Show-Step \"Waiting for service to become healthy...\"\n    $healthUrl = \"http://localhost:$($SERVICE_PORT)/health\"\n    $maxRetries = 20\n    $retryDelay = 3 # seconds\n\n    for ($i = 0; $i -lt $maxRetries; $i++) {\n        try {\n            $response = Invoke-WebRequest -Uri $healthUrl -UseBasicParsing\n            if ($response.StatusCode -eq 200) {\n                Show-Success \"Service is healthy and responding.\"\n                break\n            }\n        } catch {\n            Write-Host \"   ... waiting ($($i+1)/$($maxRetries))\"\n            Start-Sleep -Seconds $retryDelay\n        }\n        if ($i -eq $maxRetries - 1) {\n            Show-Fail \"Service failed to start within the timeout period.\"\n        }\n    }\n\n    Show-Step \"Querying API for live race data...\"\n    $racesUrl = \"http://localhost:$($SERVICE_PORT)/api/races\"\n    $headers = @{ \"X-API-Key\" = $API_KEY }\n    try {\n        $apiResponse = Invoke-RestMethod -Uri $racesUrl -Headers $headers -Method Get\n        Show-Success \"Successfully fetched data for $($apiResponse.races.Count) races.\"\n    } catch {\n        Show-Fail \"Failed to query the API. Error: $($_.Exception.Message)\"\n    }\n\n\n    # 5. Process and Format Data\n    Show-Step \"Formatting race comparison...\"\n    $now = [datetime]::UtcNow\n    $upcomingRaces = $apiResponse.races | Where-Object { [datetime]$_.startTime -gt $now } | Sort-Object startTime | Select-Object -First 3\n\n    $output = @()\n    $output += \"--- Fortuna Real-Time Race Monitor ---\"\n    $output += \"Generated: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss UTC')\"\n    $output += \"========================================\"\n\n    foreach ($race in $upcomingRaces) {\n        $raceTime = [datetime]$race.startTime\n        $timeToPost = New-TimeSpan -Start $now -End $raceTime\n        $output += \"\"\n        $output += \"$($race.venue) - Race $($race.race_number) ($($raceTime.ToLocalTime().ToString('h:mm tt')))\"\n        $output += \"Starts in: $($timeToPost.Minutes)m $($timeToPost.Seconds)s\"\n        $output += \"----------------------------------------\"\n        $output += \"{0,-25} {1,-15} {2,-15}\" -f \"Runner\", \"Best Odds\", \"Source\"\n        $output += \"{0,-25} {1,-15} {2,-15}\" -f \"-----\", \"---------\", \"------\"\n\n        foreach ($runner in $race.runners) {\n            $bestOdds = $null\n            $bestSource = \"N/A\"\n            if ($runner.odds) {\n                $oddsValues = $runner.odds.psobject.Properties | ForEach-Object { $_.Value }\n                if($oddsValues) {\n                    $best = $oddsValues | Sort-Object win -Descending | Select-Object -First 1\n                    if($best -and $best.win){\n                        $bestOdds = $best.win\n                        $bestSource = $best.source\n                    }\n                }\n            }\n            $output += \"{0,-25} {1,-15} {2,-15}\" -f $runner.name, $bestOdds, $bestSource\n        }\n    }\n\n    $output += \"========================================\"\n\n    # Display the formatted output in the console\n    $output | Out-Host\n\n} finally {\n    # 6. Cleanup\n    Show-Step \"Cleaning up...\"\n    if ($Global:BackendProcessId) {\n        try {\n            Stop-Process -Id $Global:BackendProcessId -Force\n            Show-Success \"Backend service (PID: $($Global:BackendProcessId)) stopped.\"\n        } catch {\n            Show-Warn \"Could not stop backend service (PID: $($Global:BackendProcessId)). It may have already exited.\"\n        }\n    } else {\n        Show-Success \"No backend process to stop.\"\n    }\n}\n",
    "scripts/test_api_query.py": "#!/usr/bin/env python\n\"\"\"\nSimple Fortuna Race Data Query Script\n\nThis is a lightweight script for testing the race data API locally.\nIt queries for filtered races and outputs the results.\n\nUsage:\n  python scripts/test_api_query.py\n\nThe script expects the backend to be running on http://127.0.0.1:8000\n\"\"\"\n\nimport json\nimport os\nimport sys\nimport time\nfrom datetime import datetime\n\ntry:\n    import requests\nexcept ImportError:\n    print(\"\u274c Error: 'requests' module not found.\")\n    print(\"Install it with: pip install requests\")\n    sys.exit(1)\n\n\n# Configuration\nAPI_BASE_URL = os.getenv(\"FORTUNA_API_URL\", \"http://127.0.0.1:8000\")\nAPI_KEY = os.getenv(\"API_KEY\", \"a_secure_test_api_key_that_is_long_enough\")\nTIMEOUT = 10\n\n\ndef log(message, level=\"INFO\"):\n    \"\"\"Print timestamped log message.\"\"\"\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    emoji = {\"INFO\": \"\u2139\ufe0f\", \"SUCCESS\": \"\u2705\", \"ERROR\": \"\u274c\", \"WARNING\": \"\u26a0\ufe0f\"}\n    print(f\"[{timestamp}] {emoji.get(level, '\u2022')} {message}\")\n\n\ndef check_backend_health():\n    \"\"\"Check if the backend API is responding.\"\"\"\n    log(\"Checking backend health...\", \"INFO\")\n    try:\n        response = requests.get(\n            f\"{API_BASE_URL}/api/health\",\n            timeout=TIMEOUT,\n            headers={\"X-API-Key\": API_KEY},\n        )\n        if response.status_code == 200:\n            log(\"Backend is healthy\", \"SUCCESS\")\n            return True\n    except requests.RequestException as e:\n        log(f\"Health check failed: {e}\", \"ERROR\")\n        return False\n    return False\n\n\ndef fetch_filtered_races():\n    \"\"\"Fetch trifecta-qualified races from the API.\"\"\"\n    endpoint = \"/api/races/qualified/trifecta\"\n    url = f\"{API_BASE_URL}{endpoint}\"\n\n    log(f\"Querying {url}\", \"INFO\")\n\n    try:\n        headers = {\"X-API-Key\": API_KEY}\n        response = requests.get(url, timeout=TIMEOUT, headers=headers)\n        response.raise_for_status()\n\n        data = response.json()\n        races = data.get(\"races\", [])\n\n        log(f\"Retrieved {len(races)} qualified races\", \"SUCCESS\")\n        return data\n\n    except requests.exceptions.Timeout:\n        log(f\"Request timed out after {TIMEOUT} seconds\", \"ERROR\")\n        return None\n    except requests.exceptions.ConnectionError as e:\n        log(f\"Connection error: {e}\", \"ERROR\")\n        log(f\"Is the backend running at {API_BASE_URL}?\", \"WARNING\")\n        return None\n    except requests.exceptions.HTTPError as e:\n        log(f\"HTTP error: {response.status_code} {response.reason}\", \"ERROR\")\n        return None\n    except json.JSONDecodeError:\n        log(\"Response was not valid JSON\", \"ERROR\")\n        return None\n    except Exception as e:\n        log(f\"Unexpected error: {e}\", \"ERROR\")\n        return None\n\n\ndef display_races(races_data):\n    \"\"\"Pretty-print the races to console.\"\"\"\n    if not races_data:\n        log(\"No data to display\", \"WARNING\")\n        return\n\n    races = races_data.get(\"races\", [])\n\n    print(\"\\\\n\" + \"=\" * 80)\n    print(f\"FORTUNA FILTERED RACE REPORT - {len(races)} Races\")\n    print(\"=\" * 80 + \"\\\\n\")\n\n    if not races:\n        print(\"\u274c No qualified races found at this time.\\\\n\")\n        return\n\n    for idx, race in enumerate(races, 1):\n        venue = race.get(\"venue\", \"Unknown\")\n        race_num = race.get(\"race_number\", \"?\")\n        start_time = race.get(\"startTime\", \"N/A\")\n        runners = race.get(\"runners\", [])\n\n        print(f\"[{idx}] {venue} - Race {race_num}\")\n        print(f\"    Post Time: {start_time}\")\n        print(f\"    Runners: {len(runners)}\")\n        print(\"\\\\n    Horse Name                  | Win Odds | Best Source\")\n        print(\"    \" + \"-\" * 60)\n\n        for runner in runners:\n            name = runner.get(\"name\", \"Unknown\")\n            odds_data = runner.get(\"odds\", {})\n\n            # Find best win odds\n            best_odds = \"N/A\"\n            best_source = \"N/A\"\n            if odds_data:\n                best_val = 0.0\n                for source, odds_obj in odds_data.items():\n                    win_odds = odds_obj.get(\"win\", 0.0)\n                    if win_odds > best_val:\n                        best_val = win_odds\n                        best_odds = f\"{best_val:.2f}\"\n                        best_source = source\n\n            # Truncate long names\n            display_name = name[:28]\n            print(f\"    {display_name:28} | {best_odds:>8} | {best_source}\")\n\n        print()\n\n\ndef save_to_json(races_data, filename=\"qualified_races.json\"):\n    \"\"\"Save race data to JSON file.\"\"\"\n    try:\n        with open(filename, \"w\", encoding=\"utf-8\") as f:\n            json.dump(races_data, f, indent=2)\n        log(f\"Saved race data to {filename}\", \"SUCCESS\")\n        return True\n    except Exception as e:\n        log(f\"Failed to save JSON: {e}\", \"ERROR\")\n        return False\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    log(\"=== Fortuna Race Data Query ===\", \"INFO\")\n    log(f\"API URL: {API_BASE_URL}\", \"INFO\")\n\n    # Check backend health\n    if not check_backend_health():\n        log(\"Backend is not responding\", \"ERROR\")\n        log(\"Make sure to start the backend with:\", \"WARNING\")\n        log(\"  python -m uvicorn web_service.backend.main:app --port 8000\", \"WARNING\")\n        return 1\n\n    # Fetch races\n    races_data = fetch_filtered_races()\n    if not races_data:\n        log(\"Failed to fetch race data\", \"ERROR\")\n        return 1\n\n    # Display results\n    display_races(races_data)\n\n    # Save to JSON\n    save_to_json(races_data)\n\n    log(\"Complete\", \"SUCCESS\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n",
    "tests/adapters/test_gbgb_api_adapter.py": "# tests/adapters/test_gbgb_api_adapter.py\n\nfrom datetime import date\nfrom decimal import Decimal\nfrom unittest.mock import AsyncMock\n\nimport pytest\n\nfrom python_service.adapters.gbgb_api_adapter import GbgbApiAdapter\nfrom tests.conftest import get_test_settings\n\n\n@pytest.fixture\ndef gbgb_adapter():\n    \"\"\"Returns a GbgbApiAdapter instance for testing.\"\"\"\n    return GbgbApiAdapter(config=get_test_settings())\n\n\n@pytest.mark.asyncio\nasync def test_get_gbgb_races_successfully(gbgb_adapter):\n    \"\"\"\n    SPEC: The GbgbApiAdapter should correctly parse a standard API response,\n    creating Race and Runner objects with the correct data, including fractional odds.\n    \"\"\"\n    # ARRANGE\n    mock_date = date.today().strftime(\"%Y-%m-%d\")\n    mock_api_response = [\n        {\n            \"trackName\": \"Towcester\",\n            \"races\": [\n                {\n                    \"raceId\": 12345,\n                    \"raceNumber\": 1,\n                    \"raceTime\": f\"{date.today().isoformat()}T18:00:00Z\",\n                    \"raceTitle\": \"The October Sprint\",\n                    \"raceDistance\": 500,\n                    \"traps\": [\n                        {\"trapNumber\": 1, \"dogName\": \"Rapid Rover\", \"sp\": \"5/2\"},\n                        {\"trapNumber\": 2, \"dogName\": \"Speedy Sue\", \"sp\": \"EVS\"},\n                        {\"trapNumber\": 3, \"dogName\": \"Lazy Larry\", \"sp\": \"10/1\"},\n                    ],\n                }\n            ],\n        }\n    ]\n    gbgb_adapter._fetch_data = AsyncMock(return_value=mock_api_response)\n\n    # ACT\n    races = await gbgb_adapter.get_races(mock_date)\n\n    # ASSERT\n    assert len(races) == 1\n    race = races[0]\n    assert race.venue == \"Towcester\"\n    assert race.race_number == 1\n    assert race.race_name == \"The October Sprint\"\n    assert race.distance == \"500m\"\n    assert len(race.runners) == 3\n\n    runner1 = next(r for r in race.runners if r.number == 1)\n    assert runner1.name == \"Rapid Rover\"\n    assert runner1.odds[\"GBGB\"].win == Decimal(\"3.5\")\n\n    runner2 = next(r for r in race.runners if r.number == 2)\n    assert runner2.name == \"Speedy Sue\"\n    assert runner2.odds[\"GBGB\"].win == Decimal(\"2.0\")\n\n    runner3 = next(r for r in race.runners if r.number == 3)\n    assert runner3.name == \"Lazy Larry\"\n    assert runner3.odds[\"GBGB\"].win == Decimal(\"11.0\")\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_fetch_failure(gbgb_adapter):\n    \"\"\"\n    Tests that get_races returns an empty list when _fetch_data returns None.\n    \"\"\"\n    # ARRANGE\n    mock_date = date.today().strftime(\"%Y-%m-%d\")\n    gbgb_adapter._fetch_data = AsyncMock(return_value=None)\n\n    # ACT\n    races = await gbgb_adapter.get_races(mock_date)\n\n    # ASSERT\n    assert races == []\n",
    "tests/adapters/test_twinspires_adapter.py": "# tests/adapters/test_twinspires_adapter.py\nimport pytest\nfrom python_service.adapters.twinspires_adapter import TwinSpiresAdapter\nfrom unittest.mock import MagicMock, AsyncMock\nfrom pathlib import Path\nimport pytest\n\nfrom python_service.adapters.twinspires_adapter import TwinSpiresAdapter\nfrom python_service.models import Race\n\n# A mock settings object to satisfy the adapter's config dependency\nclass MockSettings:\n    pass\n\n@pytest.fixture\ndef adapter():\n    return TwinSpiresAdapter(config=MockSettings())\n\n@pytest.mark.asyncio\nasync def test_get_races_from_fixture(adapter, mocker):\n    \"\"\"\n    Test that the adapter can correctly parse a local HTML fixture.\n    This test validates the end-to-end parsing logic, including runner data,\n    using the offline implementation.\n    \"\"\"\n    # Mock the async fetch method to return a controlled response\n    mock_response = mocker.MagicMock()\n    mock_response.status = 200\n    mock_response.text = Path(\"tests/fixtures/twinspires_racecard.html\").read_text()\n\n    adapter._fetch_with_retry = AsyncMock(return_value=mock_response)\n\n    # Call the method under test\n    races = await adapter.get_races(date=\"2025-11-12\")\n\n    # Assertions\n    assert isinstance(races, list)\n    assert len(races) == 1\n\n    # Check the race for correct parsing\n    race = races[0]\n    assert race.venue == \"Churchill Downs\"\n    assert race.race_number == 5\n\n    # Check that runners were parsed correctly\n    assert len(race.runners) == 4\n\n    # Verify a specific runner's details\n    runner_1 = next((r for r in race.runners if r.number == 1), None)\n    assert runner_1 is not None\n    assert runner_1.name == \"Braveheart\"\n    assert not runner_1.scratched\n    assert runner_1.odds[\"TwinSpires\"].win == 3.5\n\n    # Verify a scratched runner\n    runner_3 = next((r for r in race.runners if r.number == 3), None)\n    assert runner_3 is not None\n    assert runner_3.name == \"Steady Eddy\"\n    assert runner_3.scratched\n    assert not runner_3.odds\n",
    "tests/fixtures/timeform_modern_sample.html": "<div class=\"rp-horseTable_mainRow\">\n  <a class=\"rp-horseTable_horse-name\">Braveheart</a>\n  <span class=\"rp-horseTable_horse-number\">(1)</span>\n  <button class=\"rp-bet-placer-btn__odds\">5/2</button>\n</div>\n<div class=\"rp-horseTable_mainRow\">\n  <a class=\"rp-horseTable_horse-name\">Speedster</a>\n  <span class=\"rp-horseTable_horse-number\">(2)</span>\n  <button class=\"rp-bet-placer-btn__odds\">10/1</button>\n</div>\n<div class=\"rp-horseTable_mainRow\">\n  <a class=\"rp-horseTable_horse-name\">Steady Eddy</a>\n  <span class=\"rp-horseTable_horse-number\">(3)</span>\n  <button class=\"rp-bet-placer-btn__odds\">EVENS</button>\n</div>\n",
    "tests/test_ci_sanity.py": "def test_ci_pipeline_is_alive():\n    \"\"\"Basic TDD sanity check to ensure pytest is running in CI.\"\"\"\n    assert True",
    "tests/test_models/test_validation.py": "import pytest\nfrom pydantic import ValidationError\n\nfrom python_service.models import Race\n\n\ndef test_race_model_valid_data():\n    \"\"\"Tests that the Race model can be created with valid data.\"\"\"\n    race_data = {\n        \"id\": \"test_race_123\",\n        \"venue\": \"Test Park\",\n        \"race_number\": 1,\n        \"start_time\": \"2025-10-20T12:00:00Z\",\n        \"runners\": [],\n        \"source\": \"test_source\",\n    }\n    race = Race(**race_data)\n    assert race.id == \"test_race_123\"\n    assert race.venue == \"Test Park\"\n\n\ndef test_race_model_invalid_data():\n    \"\"\"Tests that the Race model raises a ValidationError with invalid data.\"\"\"\n    invalid_race_data = {\n        \"id\": \"test_race_456\",\n        \"venue\": 12345,  # Invalid type\n        \"race_number\": \"two\",  # Invalid type\n        \"start_time\": \"not-a-date\",\n        \"runners\": \"not-a-list\",\n        \"source\": \"test_source\",\n    }\n    with pytest.raises(ValidationError):\n        Race(**invalid_race_data)\n",
    "tests/test_msi_installation.ps1": "param([string]$MsiPath = \".\\dist\\Fortuna-Faucet-2.1.0-x64.msi\")\n\nWrite-Host \"Testing MSI Installation...\" -ForegroundColor Cyan\n\n# Test 1: File integrity\nWrite-Host \"\u2022 Verifying MSI structure...\"\nif (Test-Path $MsiPath) {\n    Write-Host \"\u2713 MSI file exists\"\n} else {\n    Write-Error \"MSI file not found\"\n    exit 1\n}\n\n# Test 2: Installation\nWrite-Host \"\u2022 Testing interactive installation...\"\n& msiexec.exe /i $MsiPath /l*v \"test_install.log\"\n\n# Test 3: Verify installation\nWrite-Host \"\u2022 Verifying files were installed...\"\n$programFiles = \"$env:PROGRAMFILES\\Fortuna Faucet\"\nif (Test-Path $programFiles) {\n    Write-Host \"\u2713 Installation successful\"\n} else {\n    Write-Error \"Installation failed\"\n    exit 1\n}\n\n# Test 4: Registry entries\nWrite-Host \"\u2022 Checking registry entries...\"\n$regPath = \"HKLM:\\Software\\Fortuna Faucet\"\nif (Test-Path $regPath) {\n    Write-Host \"\u2713 Registry entries found\"\n} else {\n    Write-Error \"Registry entries missing\"\n    exit 1\n}",
    "web_service/__init__.py": "\"\"\"Web service package for Fortuna Faucet.\"\"\"\n__version__ = \"1.0.0\"\n__all__ = [\"backend\"]\n",
    "web_service/backend/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .mixins import BetfairAuthMixin\n\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching horse racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairExchange\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for a given date.\"\"\"\n        if not await self._authenticate(self.http_client):\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"7\"],  # Horse Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\", \"US\", \"FR\", \"ZA\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\"Failed to parse a Betfair market.\", exc_info=True, market=market)\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bf_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 1m Mdn Stks').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "web_service/backend/adapters/equibase_adapter.py": "# python_service/adapters/equibase_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .mixins import BrowserHeadersMixin, DebugMixin\nfrom .utils.odds_validator import create_odds_data\n\n\nclass EquibaseAdapter(BrowserHeadersMixin, DebugMixin, BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Equibase race entries, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Equibase\"\n    BASE_URL = \"https://www.equibase.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(\n            primary_engine=BrowserEngine.PLAYWRIGHT,\n            enable_js=True,\n            block_resources=True,\n        )\n\n    def _get_headers(self) -> dict:\n        return self._get_browser_headers(host=\"www.equibase.com\")\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        index_url = f\"/entries/{date}\"\n        index_response = await self.make_request(\"GET\", index_url, headers=self._get_headers())\n        if not index_response or not index_response.text:\n            self.logger.warning(\"Failed to fetch Equibase index page\", url=index_url)\n            return None\n\n        self._save_debug_html(index_response.text, f\"equibase_index_{date}\")\n\n        parser = HTMLParser(index_response.text)\n        race_links = [link.attributes[\"href\"] for link in parser.css(\"a.entry-race-level\")]\n\n        semaphore = asyncio.Semaphore(5)\n\n        async def fetch_single_html(race_url: str):\n            async with semaphore:\n                try:\n                    response = await self.make_request(\"GET\", race_url, headers=self._get_headers())\n                    return response.text if response else \"\"\n                except Exception as e:\n                    self.logger.warning(\"Failed to fetch race page\", url=race_url, error=str(e))\n                    return \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": [p for p in html_pages if p], \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        date = raw_data[\"date\"]\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first(\"div.track-information strong\")\n                if not venue_node:\n                    continue\n                venue = clean_text(venue_node.text())\n\n                race_number_node = parser.css_first(\"div.race-information strong\")\n                if not race_number_node:\n                    continue\n                race_number_text = race_number_node.text().replace(\"Race\", \"\").strip()\n                if not race_number_text.isdigit():\n                    continue\n                race_number = int(race_number_text)\n\n                post_time_node = parser.css_first(\"p.post-time span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text().strip()\n                start_time = self._parse_post_time(date, post_time_str)\n\n                runners = []\n                runner_nodes = parser.css(\"table.entries-table tbody tr\")\n                for node in runner_nodes:\n                    if runner := self._parse_runner(node):\n                        runners.append(runner)\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"eqb_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse Equibase race page.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first(\"td:nth-child(1)\")\n            if not number_node or not number_node.text(strip=True).isdigit():\n                return None\n            number = int(number_node.text(strip=True))\n\n            name_node = node.css_first(\"td:nth-child(3)\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            odds_node = node.css_first(\"td:nth-child(10)\")\n            odds_str = clean_text(odds_node.text()) if odds_node else \"\"\n\n            scratched = \"scratched\" in node.attributes.get(\"class\", \"\").lower()\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if odds_data := create_odds_data(self.source_name, win_odds):\n                    odds[self.source_name] = odds_data\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError, IndexError):\n            self.logger.warning(\"Could not parse Equibase runner, skipping.\", exc_info=True)\n            return None\n\n    def _parse_post_time(self, date_str: str, time_str: str) -> datetime:\n        \"\"\"Parses a time string like 'Post Time: 12:30 PM ET' into a datetime object.\"\"\"\n        time_part = time_str.split(\" \")[-2] + \" \" + time_str.split(\" \")[-1]\n        dt_str = f\"{date_str} {time_part}\"\n        return datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n",
    "web_service/backend/adapters/racing_and_sports_adapter.py": "# python_service/adapters/racing_and_sports_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race, Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSports\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(\n            source_name=self.SOURCE_NAME,\n            base_url=self.BASE_URL,\n            config=config\n        )\n        if not getattr(config, \"RACING_AND_SPORTS_TOKEN\", None):\n            raise AdapterConfigError(\n                self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\"\n            )\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch horse racing meetings from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            \"GET\", \"v1/racing/meetings\", headers=headers, params=params\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parse meetings data into Race objects.\"\"\"\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\n                \"No 'meetings' in RacingAndSports response or invalid format.\"\n            )\n            return []\n\n        races = []\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed := self._parse_race(meeting, race_summary):\n                        races.append(parsed)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse race\",\n                        venue=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return races\n\n    def _parse_race(\n        self, meeting: Dict[str, Any], race: Dict[str, Any]\n    ) -> Optional[Race]:\n        \"\"\"Parse a single race from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        try:\n            start_time = datetime.fromisoformat(start_time_str)\n        except (ValueError, TypeError):\n            self.logger.warning(\n                \"Invalid start time\", start_time_str=start_time_str, race_id=race_id\n            )\n            return None\n\n        return Race(\n            id=f\"ras_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/twinspires_adapter.py": "\"\"\"\nTwinSpires Racing Adapter - Production Implementation\n\nUses Scrapling's AsyncStealthySession for anti-bot bypass with:\n- Persistent session pooling\n- Exponential backoff retry logic\n- Comprehensive selector strategies\n- Detailed diagnostics for debugging\n\"\"\"\n\nimport asyncio\nimport logging\nimport os\nimport re\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\nfrom scrapling.parser import Selector\n\nfrom ..models import OddsData, Race, Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .constants import MAX_VALID_ODDS\nfrom .mixins import DebugMixin\nfrom .utils.odds_validator import create_odds_data\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy, StealthMode\n\nlogger = logging.getLogger(__name__)\n\n\nclass TwinSpiresAdapter(DebugMixin, BaseAdapterV3):\n    \"\"\"\n    Production adapter for TwinSpires racing data.\n\n    Features:\n    - StealthySession with automatic Playwright fallback\n    - Exponential backoff retry logic\n    - Comprehensive selector strategies\n    - Debug HTML capture for failure analysis\n    \"\"\"\n\n    SOURCE_NAME = \"TwinSpires\"\n    BASE_URL = \"https://www.twinspires.com\"\n\n    # Selector strategies - ordered by reliability\n    RACE_CONTAINER_SELECTORS = [\n        'div[class*=\"RaceCard\"]',\n        'div[class*=\"race-card\"]',\n        'div[data-testid*=\"race\"]',\n        'div[data-race-id]',\n        'section[class*=\"race\"]',\n        'article[class*=\"race\"]',\n        '.race-container',\n        '[data-race]',\n        # Broader fallbacks\n        'div[class*=\"card\"][class*=\"race\" i]',\n        'div[class*=\"event\"]',\n    ]\n\n    TRACK_NAME_SELECTORS = [\n        '[class*=\"track-name\"]',\n        '[class*=\"trackName\"]',\n        '[data-track-name]',\n        'h2[class*=\"track\"]',\n        'h3[class*=\"track\"]',\n        '.track-title',\n        '[class*=\"venue\"]',\n    ]\n\n    RACE_NUMBER_SELECTORS = [\n        '[class*=\"race-number\"]',\n        '[class*=\"raceNumber\"]',\n        '[class*=\"race-num\"]',\n        '[data-race-number]',\n        'span[class*=\"number\"]',\n    ]\n\n    POST_TIME_SELECTORS = [\n        'time[datetime]',\n        '[class*=\"post-time\"]',\n        '[class*=\"postTime\"]',\n        '[class*=\"mtp\"]',  # Minutes to post\n        '[data-post-time]',\n        '[class*=\"race-time\"]',\n    ]\n\n    RUNNER_ROW_SELECTORS = [\n        'tr[class*=\"runner\"]',\n        'div[class*=\"runner\"]',\n        'li[class*=\"runner\"]',\n        '[data-runner-id]',\n        'div[class*=\"horse-row\"]',\n        'tr[class*=\"horse\"]',\n        'div[class*=\"entry\"]',\n        '.runner-row',\n        '.horse-entry',\n    ]\n\n    def __init__(self, config=None):\n        super().__init__(\n            source_name=self.SOURCE_NAME,\n            base_url=self.BASE_URL,\n            config=config,\n            enable_cache=True,\n            cache_ttl=180.0,\n            rate_limit=1.5  # Slightly more conservative\n        )\n        self.attempted_url: Optional[str] = None\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        \"\"\"\n        TwinSpires has strong anti-bot protections.\n        Using CAMOUFLAGE stealth mode and blocking non-essential resources.\n        \"\"\"\n        return FetchStrategy(\n            primary_engine=BrowserEngine.CAMOUFOX,\n            enable_js=True,\n            stealth_mode=StealthMode.CAMOUFLAGE,\n            block_resources=True,\n            max_retries=3,\n            timeout=45,\n        )\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetch race data from TwinSpires for given date.\n\n        Args:\n            date: Date string in YYYY-MM-DD format\n\n        Returns:\n            Dictionary with races data or None on failure\n        \"\"\"\n        self.logger.info(f\"Fetching TwinSpires races for {date}\")\n\n        # Try multiple URL patterns\n        url_patterns = [\n            f\"{self.BASE_URL}/bet/todays-races/time\",\n            f\"{self.BASE_URL}/racing/entries/{date}\",\n            f\"{self.BASE_URL}/races/today\",\n        ]\n\n        for url in url_patterns:\n            self.attempted_url = url\n            self.logger.info(f\"Trying URL pattern: {url}\")\n\n            try:\n                response = await self.make_request(\n                    \"GET\",\n                    url,\n                    network_idle=True,\n                    wait_selector='div[class*=\"race\"], [class*=\"RaceCard\"], [class*=\"track\"]',\n                )\n            except Exception as e:\n                self.logger.warning(f\"Failed to fetch {url}: {e}\")\n                continue\n\n            if response and response.status == 200:\n                # Save debug HTML\n                self._save_debug_html(response.text, f'twinspires_{date}')\n\n                # Extract races\n                races_data = self._extract_races_from_page(response, date)\n\n                if races_data:\n                    self.logger.info(f\"Successfully extracted {len(races_data)} races from {url}\")\n                    return {\n                        \"races\": races_data,\n                        \"date\": date,\n                        \"source\": \"twinspires_live\",\n                        \"url\": url,\n                    }\n                else:\n                    self.logger.warning(f\"No races extracted from {url}, trying next pattern\")\n\n        self.logger.error(\"All URL patterns failed\")\n        return None\n\n    def _extract_races_from_page(self, response, date: str) -> List[dict]:\n        \"\"\"\n        Extract race information from page response.\n\n        Uses multiple selector strategies with fallback.\n        \"\"\"\n        races_data = []\n        page = Selector(response.text)\n\n        # Try each selector pattern\n        race_elements = []\n        selector_used = None\n\n        for selector in self.RACE_CONTAINER_SELECTORS:\n            try:\n                elements = page.css(selector)\n                if elements and len(elements) > 0:\n                    # Verify these look like race containers\n                    sample = elements[0]\n                    sample_text = str(sample.html) if hasattr(sample, 'html') else str(sample)\n\n                    # Quick sanity check - should have some race-like content\n                    if any(kw in sample_text.lower() for kw in ['race', 'post', 'horse', 'runner', 'odds']):\n                        race_elements = elements\n                        selector_used = selector\n                        break\n            except Exception as e:\n                self.logger.debug(f\"Selector '{selector}' failed: {e}\")\n                continue\n\n        if race_elements:\n            self.logger.info(f\"Found {len(race_elements)} race containers using: '{selector_used}'\")\n        else:\n            self.logger.warning(\"No race containers found with any selector\")\n            # Return full page for further analysis\n            return [{\n                \"html\": response.text,\n                \"track\": \"Unknown\",\n                \"race_number\": 0,\n                \"date\": date,\n                \"full_page\": True,\n            }]\n\n        # Extract data from each race element\n        for i, race_elem in enumerate(race_elements, 1):\n            try:\n                race_data = self._extract_single_race_data(race_elem, i, date)\n                if race_data:\n                    races_data.append(race_data)\n            except Exception as e:\n                self.logger.warning(f\"Failed to extract race {i}: {e}\")\n                continue\n\n        return races_data\n\n    def _extract_single_race_data(self, race_elem, default_num: int, date: str) -> Optional[dict]:\n        \"\"\"Extract data from a single race element.\"\"\"\n        try:\n            # Get HTML string\n            html = str(race_elem.html) if hasattr(race_elem, 'html') else str(race_elem)\n\n            # Extract track name\n            track_name = self._find_with_selectors(race_elem, self.TRACK_NAME_SELECTORS)\n            if not track_name:\n                track_name = f\"Track {default_num}\"\n\n            # Extract race number\n            race_num_text = self._find_with_selectors(race_elem, self.RACE_NUMBER_SELECTORS)\n            race_number = default_num\n            if race_num_text:\n                digits = ''.join(filter(str.isdigit, race_num_text))\n                if digits:\n                    race_number = int(digits)\n\n            # Extract post time\n            post_time_text = self._find_with_selectors(race_elem, self.POST_TIME_SELECTORS)\n\n            return {\n                \"html\": html,\n                \"track\": track_name.strip(),\n                \"race_number\": race_number,\n                \"post_time_text\": post_time_text,\n                \"date\": date,\n                \"full_page\": False,\n            }\n\n        except Exception as e:\n            self.logger.debug(f\"Extract single race error: {e}\")\n            return None\n\n    def _find_with_selectors(self, element, selectors: List[str]) -> Optional[str]:\n        \"\"\"Try multiple selectors and return first matching text.\"\"\"\n        for selector in selectors:\n            try:\n                found = element.css_first(selector)\n                if found:\n                    text = found.text.strip() if hasattr(found, 'text') else str(found).strip()\n                    if text:\n                        return text\n            except Exception:\n                continue\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parse extracted race data into Race objects.\"\"\"\n        if not raw_data or \"races\" not in raw_data:\n            self.logger.warning(\"No races data to parse\")\n            return []\n\n        races_list = raw_data[\"races\"]\n        date_str = raw_data.get(\"date\", datetime.now().strftime(\"%Y-%m-%d\"))\n\n        self.logger.info(f\"Parsing {len(races_list)} races\")\n\n        parsed_races = []\n\n        for race_data in races_list:\n            try:\n                race = self._parse_single_race(race_data, date_str)\n                if race and race.runners:\n                    parsed_races.append(race)\n                    self.logger.debug(\n                        f\"Parsed race\",\n                        track=race.venue,\n                        race=race.race_number,\n                        runners=len(race.runners)\n                    )\n            except Exception as e:\n                self.logger.warning(\n                    f\"Failed to parse race\",\n                    track=race_data.get(\"track\"),\n                    error=str(e),\n                    exc_info=True\n                )\n                continue\n\n        self.logger.info(f\"Successfully parsed {len(parsed_races)} races with runners\")\n        return parsed_races\n\n    def _parse_single_race(self, race_data: dict, date_str: str) -> Optional[Race]:\n        \"\"\"Parse a single race from extracted data.\"\"\"\n        html = race_data.get(\"html\", \"\")\n        if not html:\n            return None\n\n        page = Selector(html)\n\n        track_name = race_data.get(\"track\", \"Unknown\")\n        race_number = race_data.get(\"race_number\", 1)\n\n        # Parse start time\n        start_time = self._parse_post_time(\n            race_data.get(\"post_time_text\"),\n            page,\n            date_str\n        )\n\n        # Parse runners\n        runners = self._parse_runners(page)\n\n        # Generate race ID\n        track_id = re.sub(r'[^a-z0-9]', '', track_name.lower())\n        date_compact = date_str.replace('-', '')\n        race_id = f\"ts_{track_id}_{date_compact}_R{race_number}\"\n\n        # Determine discipline\n        discipline = self._detect_discipline(page, html)\n\n        return Race(\n            id=race_id,\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            discipline=discipline,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _parse_post_time(\n        self,\n        time_text: Optional[str],\n        page,\n        date_str: str\n    ) -> Optional[datetime]:\n        \"\"\"Parse post time from text or page elements.\"\"\"\n        base_date = datetime.strptime(date_str, \"%Y-%m-%d\").date()\n\n        # Try provided time text first\n        if time_text:\n            parsed = self._parse_time_string(time_text, base_date)\n            if parsed:\n                return parsed\n\n        # Try finding time in page\n        for selector in self.POST_TIME_SELECTORS:\n            elem = page.css_first(selector)\n            if not elem:\n                continue\n\n            # Check datetime attribute\n            dt_attr = elem.attrib.get('datetime') if hasattr(elem, 'attrib') else None\n            if dt_attr:\n                try:\n                    return datetime.fromisoformat(dt_attr.replace('Z', '+00:00'))\n                except ValueError:\n                    pass\n\n            # Try text content\n            text = elem.text.strip() if hasattr(elem, 'text') else str(elem).strip()\n            parsed = self._parse_time_string(text, base_date)\n            if parsed:\n                return parsed\n\n        # Default to now + 1 hour if nothing found\n        self.logger.debug(\"Could not determine post time, using default\")\n        return datetime.combine(base_date, datetime.now().time()) + timedelta(hours=1)\n\n    def _parse_time_string(self, time_str: str, base_date) -> Optional[datetime]:\n        \"\"\"Parse various time string formats.\"\"\"\n        if not time_str:\n            return None\n\n        # Clean up string\n        time_clean = re.sub(r'\\s+(EST|EDT|CST|CDT|MST|MDT|PST|PDT|ET|PT|CT|MT)$', '', time_str, flags=re.I)\n        time_clean = time_clean.strip()\n\n        # Handle \"MTP\" (minutes to post) format\n        mtp_match = re.search(r'(\\d+)\\s*(?:min|mtp)', time_clean, re.I)\n        if mtp_match:\n            minutes = int(mtp_match.group(1))\n            return datetime.now() + timedelta(minutes=minutes)\n\n        # Try various time formats\n        formats = [\n            '%I:%M %p',      # 3:45 PM\n            '%I:%M%p',       # 3:45PM\n            '%H:%M',         # 15:45\n            '%I:%M:%S %p',   # 3:45:00 PM\n        ]\n\n        for fmt in formats:\n            try:\n                time_obj = datetime.strptime(time_clean, fmt).time()\n                return datetime.combine(base_date, time_obj)\n            except ValueError:\n                continue\n\n        return None\n\n    def _parse_runners(self, page) -> List[Runner]:\n        \"\"\"Parse runner information from race HTML.\"\"\"\n        runners = []\n\n        # Find runner elements\n        runner_elements = []\n        for selector in self.RUNNER_ROW_SELECTORS:\n            try:\n                elements = page.css(selector)\n                if elements and len(elements) > 0:\n                    runner_elements = elements\n                    self.logger.debug(f\"Found {len(elements)} runners with: {selector}\")\n                    break\n            except Exception:\n                continue\n\n        if not runner_elements:\n            self.logger.debug(\"No runner elements found\")\n            return runners\n\n        for i, elem in enumerate(runner_elements):\n            try:\n                runner = self._parse_single_runner(elem, i + 1)\n                if runner:\n                    runners.append(runner)\n            except Exception as e:\n                self.logger.debug(f\"Failed to parse runner {i + 1}: {e}\")\n                continue\n\n        return runners\n\n    def _parse_single_runner(self, elem, default_number: int) -> Optional[Runner]:\n        \"\"\"Parse a single runner element.\"\"\"\n        # Get element content\n        elem_str = str(elem.html) if hasattr(elem, 'html') else str(elem)\n        elem_lower = elem_str.lower()\n\n        # Check if scratched\n        scratched = any(s in elem_lower for s in ['scratched', 'scr', 'scratch'])\n\n        # Extract program number\n        number_selectors = [\n            '[class*=\"program\"]',\n            '[class*=\"saddle\"]',\n            '[class*=\"post\"]',\n            '[class*=\"number\"]',\n            '[data-program-number]',\n            'td:first-child',\n        ]\n\n        number = None\n        for selector in number_selectors:\n            try:\n                num_elem = elem.css_first(selector)\n                if num_elem:\n                    num_text = num_elem.text.strip() if hasattr(num_elem, 'text') else str(num_elem)\n                    digits = ''.join(filter(str.isdigit, num_text))\n                    if digits:\n                        number = int(digits)\n                        break\n            except Exception:\n                continue\n\n        if number is None:\n            number = default_number\n\n        # Extract horse name\n        name_selectors = [\n            '[class*=\"horse-name\"]',\n            '[class*=\"horseName\"]',\n            '[class*=\"runner-name\"]',\n            'a[class*=\"name\"]',\n            '[data-horse-name]',\n            'td:nth-child(2)',\n        ]\n\n        name = None\n        for selector in name_selectors:\n            try:\n                name_elem = elem.css_first(selector)\n                if name_elem:\n                    name_text = name_elem.text.strip() if hasattr(name_elem, 'text') else None\n                    if name_text and len(name_text) > 1:\n                        # Clean up name\n                        name = re.sub(r'\\([^)]*\\)', '', name_text).strip()\n                        break\n            except Exception:\n                continue\n\n        if not name:\n            return None\n\n        # Extract odds\n        odds = {}\n        if not scratched:\n            odds_selectors = [\n                '[class*=\"odds\"]',\n                '[class*=\"ml\"]',  # Morning line\n                '[class*=\"morning-line\"]',\n                '[data-odds]',\n            ]\n\n            for selector in odds_selectors:\n                try:\n                    odds_elem = elem.css_first(selector)\n                    if odds_elem:\n                        odds_text = odds_elem.text.strip() if hasattr(odds_elem, 'text') else None\n                        if odds_text and odds_text.upper() not in ['SCR', 'SCRATCHED', '--', 'N/A']:\n                            win_odds = parse_odds_to_decimal(odds_text)\n                            if odds_data := create_odds_data(self.source_name, win_odds):\n                                odds[self.source_name] = odds_data\n                                break\n                except Exception:\n                    continue\n\n        return Runner(\n            number=number,\n            name=name,\n            scratched=scratched,\n            odds=odds,\n        )\n\n    def _detect_discipline(self, page, html: str) -> str:\n        \"\"\"Detect race discipline (Thoroughbred, Harness, etc).\"\"\"\n        html_lower = html.lower()\n\n        if any(kw in html_lower for kw in ['harness', 'trotter', 'pacer', 'standardbred']):\n            return \"Harness\"\n        elif any(kw in html_lower for kw in ['quarter horse', 'quarterhorse']):\n            return \"Quarter Horse\"\n        elif any(kw in html_lower for kw in ['greyhound', 'dog']):\n            return \"Greyhound\"\n\n        # Try finding breed element\n        breed_selectors = ['[class*=\"breed\"]', '[class*=\"type\"]', '[data-breed]']\n        for selector in breed_selectors:\n            try:\n                elem = page.css_first(selector)\n                if elem:\n                    text = elem.text.strip().lower() if hasattr(elem, 'text') else ''\n                    if 'harness' in text:\n                        return \"Harness\"\n                    elif 'quarter' in text:\n                        return \"Quarter Horse\"\n            except Exception:\n                continue\n\n        return \"Thoroughbred\"\n\n    async def cleanup(self):\n        \"\"\"Cleanup resources.\"\"\"\n        await self.close()\n        self.logger.info(\"TwinSpires adapter cleaned up\")\n",
    "web_service/backend/adapters/universal_adapter.py": "# python_service/adapters/universal_adapter.py\nimport json\nfrom typing import Any, List\n\nfrom selectolax.parser import HTMLParser\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\n\n\nclass UniversalAdapter(BaseAdapterV3):\n    \"\"\"\n    An adapter that executes logic from a declarative JSON definition file.\n    NOTE: This is a simplified proof-of-concept implementation.\n    Standardized on selectolax for performance.\n    \"\"\"\n\n    def __init__(self, config, definition_path: str):\n        with open(definition_path, \"r\") as f:\n            self.definition = json.load(f)\n\n        super().__init__(\n            source_name=self.definition[\"adapter_name\"],\n            base_url=self.definition[\"base_url\"],\n            config=config,\n        )\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Executes the fetch steps defined in the JSON definition.\"\"\"\n        self.logger.info(f\"Executing Universal Adapter PoC for {self.source_name}\")\n        response = await self.make_request(\"GET\", self.definition[\"start_url\"])\n        if not response:\n            return None\n\n        parser = HTMLParser(response.text)\n        # Assuming the first step is a simple CSS selector for track links\n        track_links = [self.base_url + a.attributes[\"href\"] for a in parser.css(self.definition[\"steps\"][0][\"selector\"]) if a.attributes.get(\"href\")]\n\n        # In a full implementation, we would fetch and return each track page's content.\n        # For this PoC, we are not fetching the individual track links.\n        self.logger.warning(\"UniversalAdapter is a proof-of-concept and does not fully fetch all data.\")\n        return track_links\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a proof-of-concept and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/config.py": "# python_service/config.py\nimport os\nimport sys\nfrom functools import lru_cache\nfrom pathlib import Path\nfrom typing import List\nfrom typing import Optional\n\nimport structlog\nfrom pydantic import Field\nfrom pydantic import model_validator\nfrom pydantic_settings import BaseSettings\n\nfrom .credentials_manager import SecureCredentialsManager\n\n# --- Encryption Setup ---\ntry:\n    from cryptography.fernet import Fernet\n\n    ENCRYPTION_ENABLED = True\nexcept ImportError:\n    ENCRYPTION_ENABLED = False\n\nKEY_FILE = Path(\".key\")\nCIPHER = None\nif ENCRYPTION_ENABLED and KEY_FILE.exists():\n    with open(KEY_FILE, \"rb\") as f:\n        key = f.read()\n    CIPHER = Fernet(key)\n\n\ndef decrypt_value(value: Optional[str]) -> str:\n    \"\"\"If a value is encrypted, decrypts it. Otherwise, returns it as is.\"\"\"\n    if value and value.startswith(\"encrypted:\") and CIPHER:\n        try:\n            return CIPHER.decrypt(value[10:].encode()).decode()\n        except Exception:\n            structlog.get_logger(__name__).error(\"Decryption failed on field.\")\n            return \"\"  # Fallback to an empty string on failure\n    return value or \"\"  # Ensure a non-None return value even if input is None\n\n\nclass Settings(BaseSettings):\n    API_KEY: str = Field(\"\")\n\n    # --- API Gateway Configuration ---\n    UVICORN_HOST: str = \"127.0.0.1\"\n    FORTUNA_PORT: int = 8000\n    UVICORN_RELOAD: bool = True\n\n    # --- Database Configuration ---\n    DATABASE_TYPE: str = \"sqlite\"\n    DATABASE_URL: str = \"sqlite:///./fortuna.db\"\n\n    # --- Optional Betfair Credentials ---\n    BETFAIR_APP_KEY: Optional[str] = None\n\n    # --- Caching & Performance ---\n    REDIS_URL: str = \"redis://localhost:6379\"\n    CACHE_TTL_SECONDS: int = 1800  # 30 minutes\n    MAX_CONCURRENT_REQUESTS: int = 10\n    HTTP_POOL_CONNECTIONS: int = 100\n    HTTP_POOL_MAXSIZE: int = 100\n    HTTP_MAX_KEEPALIVE: int = 50\n    DEFAULT_TIMEOUT: int = 30\n    ADAPTER_TIMEOUT: int = 20\n\n    # --- Logging ---\n    LOG_LEVEL: str = \"INFO\"\n\n    # --- Optional Adapter Keys ---\n    NEXT_PUBLIC_API_KEY: Optional[str] = None  # Allow frontend key to be present in .env\n    TVG_API_KEY: Optional[str] = None\n    RACING_AND_SPORTS_TOKEN: Optional[str] = None\n    POINTSBET_API_KEY: Optional[str] = None\n    GREYHOUND_API_URL: Optional[str] = None\n    THE_RACING_API_KEY: Optional[str] = None\n\n    # --- CORS Configuration ---\n    ALLOWED_ORIGINS: List[str] = [\"http://localhost:3000\", \"http://localhost:3001\"]\n\n    # --- Dynamic Path Configuration ---\n    # This determines the path to static files, crucial for PyInstaller builds\n    STATIC_FILES_DIR: Optional[str] = None\n\n    model_config = {\"env_file\": \".env\", \"case_sensitive\": True}\n\n    @model_validator(mode=\"after\")\n    def process_settings(self) -> \"Settings\":\n        \"\"\"\n        This validator runs after the initial settings are loaded from .env and\n        performs two key functions:\n        1. If API_KEY is missing, it falls back to the SecureCredentialsManager.\n        2. It decrypts any fields that were loaded from the .env file.\n        \"\"\"\n        # 1. Fallback for API_KEY\n        if not self.API_KEY:\n            self.API_KEY = SecureCredentialsManager.get_credential(\"api_key\") or \"MISSING\"\n\n        # 2. Security validation for API_KEY\n        insecure_keys = {\"test\", \"changeme\", \"default\", \"secret\", \"password\", \"admin\"}\n        if self.API_KEY in insecure_keys:\n            structlog.get_logger(__name__).warning(\n                \"insecure_api_key\",\n                key=self.API_KEY,\n                recommendation=\"The API_KEY should be a long, random string for security.\",\n            )\n\n        # 2. Decrypt sensitive fields\n        self.BETFAIR_APP_KEY = decrypt_value(self.BETFAIR_APP_KEY)\n\n        # 3. Set the static files directory for packaged apps\n        if getattr(sys, \"frozen\", False):\n            # Running in a PyInstaller bundle\n            self.STATIC_FILES_DIR = os.path.join(sys._MEIPASS, \"ui\")\n        else:\n            # Running in a normal Python environment\n            self.STATIC_FILES_DIR = None  # Not needed for local dev\n\n        return self\n\n\n@lru_cache()\ndef get_settings() -> Settings:\n    \"\"\"Loads settings and performs a proactive check for legacy paths.\"\"\"\n    log = structlog.get_logger(__name__)\n    if ENCRYPTION_ENABLED and not KEY_FILE.exists():\n        log.warning(\n            \"encryption_key_not_found\",\n            file=str(KEY_FILE),\n            recommendation=\"Run 'python manage_secrets.py' to generate a key.\",\n        )\n\n    settings = Settings()\n\n    # --- Legacy Path Detection ---\n    legacy_paths = [\"attic/\", \"checkmate_web/\", \"vba_source/\"]\n    for path in legacy_paths:\n        if os.path.exists(path):\n            log.warning(\n                \"legacy_path_detected\",\n                path=path,\n                recommendation=\"This directory is obsolete and should be removed for optimal performance and security.\",\n            )\n\n    return settings\n",
    "web_service/backend/db/init.py": "# python_service/db/init.py\nimport os\nimport sqlite3\n\nfrom ..config import get_settings\n\n\ndef initialize_database():\n    \"\"\"\n    Initializes the database based on the configuration.\n    Currently supports a simple SQLite fallback for local testing.\n    \"\"\"\n    settings = get_settings()\n    db_type = getattr(settings, \"DATABASE_TYPE\", \"sqlite\").lower()\n\n    if db_type == \"sqlite\":\n        # DATABASE_URL for sqlite will be like 'sqlite:///./fortuna.db'\n        db_path = settings.DATABASE_URL.split(\"///\")[1]\n\n        # Ensure the directory for the database exists\n        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n\n        try:\n            conn = sqlite3.connect(db_path)\n            cursor = conn.cursor()\n\n            # The schema is based on the provided pg_schemas, adapted for SQLite\n            # This is a simplified version for demonstration.\n            cursor.execute(\n                \"\"\"\n            CREATE TABLE IF NOT EXISTS races (\n                id TEXT PRIMARY KEY,\n                venue TEXT NOT NULL,\n                race_number INTEGER NOT NULL,\n                start_time TEXT NOT NULL,\n                source TEXT,\n                field_size INTEGER\n            )\n            \"\"\"\n            )\n\n            cursor.execute(\n                \"\"\"\n            CREATE TABLE IF NOT EXISTS runners (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                race_id TEXT,\n                number INTEGER,\n                name TEXT,\n                odds REAL,\n                FOREIGN KEY (race_id) REFERENCES races (id)\n            )\n            \"\"\"\n            )\n\n            conn.commit()\n            conn.close()\n            print(\"SQLite database initialized successfully.\")\n        except sqlite3.Error as e:\n            print(f\"Error initializing SQLite database: {e}\")\n            raise\n",
    "web_service/backend/health.py": "# python_service/health.py\nfrom datetime import datetime\nfrom typing import Dict\nfrom typing import List\n\nimport psutil\nimport structlog\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\nlog = structlog.get_logger(__name__)\n\n\nclass HealthMonitor:\n    def __init__(self):\n        self.adapter_health: Dict[str, Dict] = {}\n        self.system_metrics: List[Dict] = []\n        self.max_metrics_history = 100\n\n    def record_adapter_response(self, adapter_name: str, success: bool, duration: float):\n        if adapter_name not in self.adapter_health:\n            self.adapter_health[adapter_name] = {\n                \"total_requests\": 0,\n                \"successful_requests\": 0,\n                \"failed_requests\": 0,\n                \"avg_response_time\": 0.0,\n                \"last_success\": None,\n                \"last_failure\": None,\n            }\n\n        health = self.adapter_health[adapter_name]\n        health[\"total_requests\"] += 1\n\n        if success:\n            health[\"successful_requests\"] += 1\n            health[\"last_success\"] = datetime.now().isoformat()\n        else:\n            health[\"failed_requests\"] += 1\n            health[\"last_failure\"] = datetime.now().isoformat()\n\n        health[\"avg_response_time\"] = (\n            health[\"avg_response_time\"] * (health[\"total_requests\"] - 1) + duration\n        ) / health[\"total_requests\"]\n\n    def get_system_metrics(self) -> Dict:\n        cpu_percent = psutil.cpu_percent(interval=1)\n        memory = psutil.virtual_memory()\n        disk = psutil.disk_usage(\"/\")\n\n        metrics = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"cpu_percent\": cpu_percent,\n            \"memory_percent\": memory.percent,\n            \"memory_available_gb\": round(memory.available / (1024**3), 2),\n            \"disk_percent\": disk.percent,\n            \"disk_free_gb\": round(disk.free / (1024**3), 2),\n        }\n\n        self.system_metrics.append(metrics)\n        if len(self.system_metrics) > self.max_metrics_history:\n            self.system_metrics.pop(0)\n\n        return metrics\n\n    def get_health_report(self) -> Dict:\n        system_metrics = self.get_system_metrics()\n        return {\n            \"status\": \"healthy\" if self.is_system_healthy() else \"degraded\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"system\": system_metrics,\n            \"adapters\": self.adapter_health,\n            \"metrics_history\": self.system_metrics[-10:],\n        }\n\n    def is_system_healthy(self) -> bool:\n        if not self.system_metrics:\n            return True\n        latest = self.system_metrics[-1]\n        return latest[\"cpu_percent\"] < 80 and latest[\"memory_percent\"] < 85 and latest[\"disk_percent\"] < 90\n\n\nimport time\nfrom fastapi import Response\nfrom .version import get_version\n\n# Global instance for the application to use\nhealth_monitor = HealthMonitor()\nstart_time = time.time()\n\n\n@router.get(\"/health/detailed\", tags=[\"Health\"])\nasync def get_detailed_health():\n    \"\"\"Provides a comprehensive health check of the system.\"\"\"\n    return health_monitor.get_health_report()\n\n\n@router.get(\"/health\", tags=[\"Health\"])\nasync def get_basic_health(response: Response):\n    \"\"\"Provides a basic health check for load balancers and uptime monitoring.\"\"\"\n    uptime_seconds = time.time() - start_time\n    # Simple dependency check: assume healthy if we have adapter data\n    dependencies_healthy = len(health_monitor.adapter_health) > 0\n    status = \"ok\" if dependencies_healthy else \"degraded\"\n\n    # The service is still \"healthy\" even if degraded. The status is in the payload.\n    # if not dependencies_healthy:\n    #     response.status_code = 503 # Service Unavailable\n\n    return {\n        \"status\": status,\n        \"timestamp\": datetime.now().isoformat(),\n        \"version\": get_version(),\n        \"uptime_seconds\": int(uptime_seconds),\n        \"dependencies\": {\n            \"database\": \"connected\", # Placeholder\n            \"external_api\": \"healthy\" # Placeholder\n        }\n    }\n",
    "web_service/backend/manual_override_manager.py": "# python_service/manual_override_manager.py\nimport hashlib\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\n\nfrom pydantic import BaseModel\nfrom pydantic import Field\n\n\nclass ManualOverrideRequest(BaseModel):\n    request_id: str\n    adapter_name: str\n    url: str\n    timestamp: datetime = Field(default_factory=datetime.now)\n    status: str = \"pending\"  # pending, submitted, skipped\n\n\nclass ManualOverrideManager:\n    def __init__(self):\n        self._requests: Dict[str, ManualOverrideRequest] = {}\n        self._data: Dict[str, Tuple[str, str]] = {}  # request_id -> (content, content_type)\n\n    def _generate_id(self, adapter_name: str, url: str) -> str:\n        \"\"\"Generates a consistent ID for a given adapter and URL.\"\"\"\n        return hashlib.sha256(f\"{adapter_name}:{url}\".encode()).hexdigest()[:16]\n\n    def register_failure(self, adapter_name: str, url: str) -> str:\n        \"\"\"\n        Registers a failed fetch attempt and returns a unique request ID.\n        If a pending request for this exact resource already exists, it returns the existing ID.\n        \"\"\"\n        request_id = self._generate_id(adapter_name, url)\n        if request_id not in self._requests or self._requests[request_id].status != \"pending\":\n            request = ManualOverrideRequest(request_id=request_id, adapter_name=adapter_name, url=url)\n            self._requests[request_id] = request\n        return request_id\n\n    def submit_manual_data(self, request_id: str, raw_content: str, content_type: str) -> bool:\n        \"\"\"Submits manual data for a pending request.\"\"\"\n        if request_id in self._requests and self._requests[request_id].status == \"pending\":\n            self._data[request_id] = (raw_content, content_type)\n            self._requests[request_id].status = \"submitted\"\n            return True\n        return False\n\n    def skip_request(self, request_id: str) -> bool:\n        \"\"\"Marks a pending request as skipped.\"\"\"\n        if request_id in self._requests and self._requests[request_id].status == \"pending\":\n            self._requests[request_id].status = \"skipped\"\n            return True\n        return False\n\n    def get_pending_requests(self) -> List[ManualOverrideRequest]:\n        \"\"\"Returns a list of all requests that are currently pending.\"\"\"\n        return [req for req in self._requests.values() if req.status == \"pending\"]\n\n    def get_manual_data(self, adapter_name: str, url: str) -> Optional[Tuple[str, str]]:\n        \"\"\"\n        Retrieves submitted manual data for a given adapter and URL, if it exists.\n        Once retrieved, the data is consumed and will not be returned again.\n        \"\"\"\n        request_id = self._generate_id(adapter_name, url)\n        if request_id in self._data:\n            # Data is single-use; remove it after retrieval.\n            return self._data.pop(request_id)\n        return None\n\n    def clear_old_requests(self, max_age_hours: int = 24):\n        \"\"\"Removes requests and associated data older than a specified age.\"\"\"\n        cutoff = datetime.now() - timedelta(hours=max_age_hours)\n        old_request_ids = [req_id for req_id, req in self._requests.items() if req.timestamp < cutoff]\n        for req_id in old_request_ids:\n            self._requests.pop(req_id, None)\n            self._data.pop(req_id, None)\n",
    "web_service/backend/notifications.py": "# python_service/notifications.py\n\nimport sys\n\nimport structlog\n\nlog = structlog.get_logger(__name__)\n\n\ndef send_toast(title: str, message: str):\n    \"\"\"\n    Sends a desktop notification. This function is platform-aware and will only\n    attempt to send a toast on Windows. On other operating systems, it will\n    log the notification content.\n    \"\"\"\n    if sys.platform == \"win32\":\n        try:\n            from windows_toasts import Toast\n            from windows_toasts import WindowsToaster\n\n            toaster = WindowsToaster(title)\n            new_toast = Toast()\n            new_toast.text_fields = [message]\n            toaster.show_toast(new_toast)\n            log.info(\"Sent Windows toast notification.\", title=title, message=message)\n        except ImportError:\n            log.warning(\n                \"windows_toasts library not found, skipping notification.\",\n                recommendation=\"Install with: pip install windows-toasts\",\n            )\n        except Exception:\n            log.error(\"Failed to send Windows toast notification.\", exc_info=True)\n    else:\n        log.info(\n            \"Skipping toast notification on non-Windows platform.\",\n            platform=sys.platform,\n            title=title,\n            message=message,\n        )\n",
    "web_service/backend/requirements-x86.txt": "#\n# This file is a modified version of requirements.txt for x86 architecture compatibility.\n# Some packages are pinned to older versions that provide x86 wheels.\n#\naiosqlite==0.17.0\n    # via -r web_service/backend/requirements.in\naltgraph==0.17.4\n    # via pyinstaller\nannotated-types==0.7.0\n    # via pydantic\nanyio==3.7.1\n    # via\n    #   httpx\n    #   starlette\n    #   watchfiles\nasync-timeout==5.0.1\n    # via redis\nbeautifulsoup4==4.12.3\n    # via -r web_service/backend/requirements.in\nblack==24.4.2\n    # via -r web_service/backend/requirements.in\nbuild==1.2.1\n    # via pip-tools\ncertifi==2024.7.4\n    # via\n    #   -r web_service/backend/requirements.in\n    #   httpcore\n    #   httpx\n    #   requests\ncffi==1.16.0\n    # via cryptography\ncharset-normalizer==3.3.2\n    # via requests\nclick==8.1.7\n    # via\n    #   black\n    #   pip-tools\n    #   rich-toolkit\n    #   typer\n    #   uvicorn\ncryptography==42.0.8\n    # via\n    #   -r web_service/backend/requirements.in\n    #   secretstorage\ndeprecated==1.2.14\n    # via limits\ndnspython==2.7.0\n    # via email-validator\nemail-validator==2.3.0\n    # via fastapi\nexceptiongroup==1.3.1\n    # via\n    #   anyio\n    #   pytest\nfastapi==0.111.0\n    # via -r web_service/backend/requirements.in\nfastapi-cli==0.0.20\n    # via fastapi\ngreenlet==1.1.2  # x86 PINNED\n    # via\n    #   -r web_service/backend/requirements.in\n    #   sqlalchemy\nh11==0.14.0\n    # via\n    #   httpcore\n    #   uvicorn\nh2==4.1.0\n    # via httpx\nhpack==4.0.0\n    # via h2\nhttpcore==1.0.5\n    # via httpx\nhttptools==0.7.1\n    # via uvicorn\nhttpx[http2]==0.27.0\n    # via\n    #   -r web_service/backend/requirements.in\n    #   fastapi\nhyperframe==6.0.1\n    # via h2\nidna==3.7\n    # via\n    #   anyio\n    #   email-validator\n    #   httpx\n    #   requests\nimportlib-metadata==8.7.1\n    # via\n    #   build\n    #   keyring\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\niniconfig==2.0.0\n    # via pytest\njaraco-classes==3.4.0\n    # via keyring\njaraco-context==4.3.0\n    # via keyring\njaraco-functools==4.3.0\n    # via keyring\njeepney==0.8.0\n    # via\n    #   keyring\n    #   secretstorage\njinja2==3.1.6\n    # via fastapi\nkeyring==25.2.1\n    # via -r web_service/backend/requirements.in\nlimits==3.14.1\n    # via slowapi\nmarkdown-it-py==3.0.0\n    # via rich\nmarkupsafe==3.0.3\n    # via jinja2\nmdurl==0.1.2\n    # via markdown-it-py\nmore-itertools==10.3.0\n    # via\n    #   jaraco-classes\n    #   jaraco-functools\nmypy-extensions==1.0.0\n    # via black\nnumpy==1.23.5  # x86 PINNED\n    # via\n    #   -r web_service/backend/requirements.in\n    #   pandas\n    #   scipy\norjson==3.11.5\n    # via fastapi\npackaging==24.1\n    # via\n    #   black\n    #   build\n    #   limits\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\n    #   pytest\npandas==1.5.3  # x86 PINNED\n    # via -r web_service/backend/requirements.in\npathspec==0.12.1\n    # via black\npip-tools==7.4.1\n    # via -r web_service/backend/requirements.in\nplatformdirs==4.2.2\n    # via black\npluggy==1.5.0\n    # via pytest\npsutil==5.9.8\n    # via -r web_service/backend/requirements.in\npsycopg2-binary==2.9.9\n    # via -r web_service/backend/requirements.in\npycparser==2.22\n    # via cffi\npydantic==2.8.2\n    # via\n    #   fastapi\n    #   pydantic-settings\npydantic-core==2.20.1\n    # via pydantic\npydantic-settings==2.3.4\n    # via -r web_service/backend/requirements.in\npygments==2.18.0\n    # via rich\npyinstaller==6.5.0\n    # via -r web_service/backend/requirements.in\npyinstaller-hooks-contrib==2024.6\n    # via pyinstaller\npyproject-hooks==1.1.0\n    # via\n    #   build\n    #   pip-tools\npytest==8.2.2\n    # via\n    #   -r web_service/backend/requirements.in\n    #   pytest-asyncio\npytest-asyncio==0.23.7\n    # via -r web_service/backend/requirements.in\npython-dateutil==2.9.0.post0\n    # via pandas\npython-dotenv==1.0.1\n    # via\n    #   pydantic-settings\n    #   uvicorn\npython-multipart==0.0.20\n    # via fastapi\npytz==2024.1\n    # via pandas\npyyaml==6.0.3\n    # via uvicorn\nredis==5.0.6\n    # via -r web_service/backend/requirements.in\nrequests==2.32.5\n    # via -r web_service/backend/requirements.in\nrich==14.2.0\n    # via\n    #   rich-toolkit\n    #   typer\nrich-toolkit==0.17.1\n    # via fastapi-cli\nscipy==1.10.1  # x86 PINNED\n    # via -r web_service/backend/requirements.in\nsecretstorage==3.3.3\n    # via keyring\nselectolax==0.4.0\n    # via -r web_service/backend/requirements.in\nshellingham==1.5.4\n    # via typer\nsix==1.16.0\n    # via python-dateutil\nslowapi==0.1.9\n    # via -r web_service/backend/requirements.in\nsniffio==1.3.1\n    # via\n    #   anyio\n    #   httpx\nsoupsieve==2.5\n    # via beautifulsoup4\nsqlalchemy==1.4.46  # x86 PINNED\n    # via -r web_service/backend/requirements.in\nstarlette==0.37.2\n    # via fastapi\nstructlog==24.2.0\n    # via -r web_service/backend/requirements.in\ntenacity==8.2.3\n    # via -r web_service/backend/requirements.in\ntomli==2.3.0\n    # via\n    #   black\n    #   build\n    #   fastapi-cli\n    #   pip-tools\n    #   pytest\ntyper==0.21.0\n    # via fastapi-cli\ntyping-extensions==4.12.2\n    # via\n    #   aiosqlite\n    #   black\n    #   exceptiongroup\n    #   fastapi\n    #   limits\n    #   pydantic\n    #   pydantic-core\n    #   rich-toolkit\n    #   starlette\n    #   typer\n    #   uvicorn\nujson==5.11.0\n    # via fastapi\nurllib3==2.6.2\n    # via\n    #   -r web_service/backend/requirements.in\n    #   requests\nuvicorn==0.30.1\n    # via\n    #   -r web_service/backend/requirements.in\n    #   fastapi\n    #   fastapi-cli\nhttptools==0.7.1\n    # via uvicorn\nwebsockets==15.0.1\n    # via uvicorn\nwatchfiles==1.1.1\n    # via uvicorn\nwebsockets==15.0.1\n    # via uvicorn\nwheel==0.43.0\n    # via\n    #   -r web_service/backend/requirements.in\n    #   pip-tools\nwrapt==1.16.0\n    # via deprecated\nzipp==3.23.0\n    # via importlib-metadata\n",
    "web_service/backend/tests/test_web_service_manual_override.py": "# python_service/tests/test_manual_override.py\nimport pytest\n\n# Use an absolute import as a workaround for the broken test environment.\n# Pytest is not recognizing this directory as part of a package, so relative imports fail.\nimport sys\nfrom pathlib import Path\n# Add repo root to path to allow absolute imports\nsys.path.insert(0, str(Path(__file__).resolve().parents[3]))\n\nfrom web_service.backend.manual_override_manager import ManualOverrideManager\n\n\n@pytest.fixture\ndef manager():\n    # The manager is now in-memory and doesn't need a path\n    return ManualOverrideManager()\n\n\ndef test_register_and_retrieve(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n    content = \"<html>Manual content</html>\"\n    content_type = \"text/html\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    success = manager.submit_manual_data(\n        request_id=request_id,\n        raw_content=content,\n        content_type=content_type,\n    )\n\n    assert success\n\n    # Verify that the data can be retrieved correctly\n    retrieved_data = manager.get_manual_data(adapter_name=adapter, url=url)\n    assert retrieved_data is not None\n    retrieved_content, retrieved_type = retrieved_data\n    assert retrieved_content == content\n    assert retrieved_type == content_type\n\n    # Verify that data is consumed after retrieval\n    assert manager.get_manual_data(adapter_name=adapter, url=url) is None\n",
    "web_service/backend/validators.py": "# web_service/backend/validators.py\nfrom pydantic import BaseModel, validator, Field\nfrom typing import Any\nfrom datetime import datetime, timedelta, timezone\n\nclass RaceValidator(BaseModel):\n    \"\"\"Strict validation for race data.\"\"\"\n    venue: str = Field(..., min_length=1)\n    race_number: int = Field(..., ge=1, le=20)\n    start_time: datetime\n    runners: list[dict] = Field(..., min_items=2)\n\n    @validator('runners')\n    def validate_runners(cls, v):\n        \"\"\"Ensure runners have required fields.\"\"\"\n        for runner in v:\n            if not runner.get('name'):\n                raise ValueError(\"Runner missing name\")\n            if 'odds' not in runner and 'number' not in runner:\n                raise ValueError(\"Runner missing odds or number\")\n        return v\n\n    @validator('start_time')\n    def validate_time_reasonable(cls, v):\n        \"\"\"Check race time is reasonable (not too far in past/future).\"\"\"\n        # Ensure comparison is timezone-aware if the input is aware, or naive if naive.\n        if v.tzinfo is not None:\n            now = datetime.now(timezone.utc)\n        else:\n            now = datetime.utcnow()\n\n        if v < now - timedelta(hours=24):\n            raise ValueError(f\"Race time too far in past: {v} vs {now}\")\n        if v > now + timedelta(days=7):\n            raise ValueError(f\"Race time too far in future: {v} vs {now}\")\n        return v\n\nclass DataValidationPipeline:\n    \"\"\"Validates and cleans data between adapter and parser.\"\"\"\n\n    @staticmethod\n    def validate_raw_response(adapter_name: str, raw_data: Any) -> tuple[bool, str]:\n        \"\"\"Quick validation of raw adapter response.\"\"\"\n        if raw_data is None:\n            return False, \"Null response\"\n\n        if isinstance(raw_data, dict):\n            if not raw_data:\n                return False, \"Empty dict\"\n            if 'error' in raw_data:\n                return False, f\"Error in response: {raw_data['error']}\"\n\n        if isinstance(raw_data, str):\n            if len(raw_data) < 100:\n                return False, \"Response too short\"\n            if 'error' in raw_data.lower() or '404' in raw_data:\n                return False, \"Error indicators in HTML\"\n\n        return True, \"OK\"\n\n    @staticmethod\n    def validate_parsed_races(races: list) -> tuple[list, list[str]]:\n        \"\"\"Validate parsed races and return valid ones + warnings.\"\"\"\n        valid_races = []\n        warnings = []\n\n        for i, race in enumerate(races):\n            try:\n                # Use Pydantic validation\n                if hasattr(race, \"dict\"):\n                    data = race.dict()\n                else:\n                    data = race\n                RaceValidator(**data)\n                valid_races.append(race)\n            except Exception as e:\n                warnings.append(f\"Race {i} validation failed: {str(e)}\")\n\n        return valid_races, warnings\n",
    "web_service/frontend/app/components/EmptyState.tsx": "// web_platform/frontend/src/components/EmptyState.tsx\nimport React from 'react';\n\ninterface EmptyStateProps {\n  title: string;\n  message: string;\n  actionButton?: React.ReactNode;\n}\n\nexport const EmptyState: React.FC<EmptyStateProps> = ({ title, message, actionButton }) => {\n  return (\n    <div className=\"text-center p-8 bg-gray-800/50 border border-gray-700 rounded-lg mt-8\">\n      <svg\n        className=\"mx-auto h-12 w-12 text-gray-500\"\n        fill=\"none\"\n        viewBox=\"0 0 24 24\"\n        stroke=\"currentColor\"\n        aria-hidden=\"true\"\n      >\n        <path\n          vectorEffect=\"non-scaling-stroke\"\n          strokeLinecap=\"round\"\n          strokeLinejoin=\"round\"\n          strokeWidth={2}\n          d=\"M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z\"\n        />\n      </svg>\n      <h3 className=\"mt-2 text-xl font-semibold text-white\">{title}</h3>\n      <p className=\"mt-1 text-md text-gray-400\">\n        {message}\n      </p>\n      {actionButton && <div className=\"mt-6\">{actionButton}</div>}\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/RaceCard.tsx": "// web_platform/frontend/src/components/RaceCard.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\nimport type { Race, Runner } from '../types/racing';\n\n// Local types removed, now importing from '../types/racing'\n\ninterface RaceCardProps {\n  race: Race;\n}\n\nconst Countdown: React.FC<{ startTime: string }> = ({ startTime }) => {\n  const [currentTime, setCurrentTime] = useState(new Date());\n\n  useEffect(() => {\n    const timer = setInterval(() => setCurrentTime(new Date()), 1000);\n    return () => clearInterval(timer);\n  }, []);\n\n  const getCountdown = (startTimeStr: string) => {\n    const postTime = new Date(startTimeStr);\n    const diff = postTime.getTime() - currentTime.getTime();\n\n    if (diff <= 0) return { text: \"RACE COMPLETE\", color: \"text-gray-500\" };\n\n    const minutes = Math.floor(diff / 60000);\n    const seconds = Math.floor((diff % 60000) / 1000).toString().padStart(2, '0');\n\n    let color = \"text-green-400\";\n    if (minutes < 2) color = \"text-red-500 font-bold animate-pulse\";\n    else if (minutes < 10) color = \"text-yellow-400\";\n\n    return { text: `${minutes}:${seconds} to post`, color };\n  };\n\n  const countdown = getCountdown(startTime);\n\n  return (\n    <span className={`font-mono text-sm ${countdown.color}`}>{countdown.text}</span>\n  );\n};\n\nexport const RaceCard: React.FC<RaceCardProps> = ({ race }) => {\n  const activeRunners = race.runners.filter(r => !r.scratched);\n  activeRunners.sort((a, b) => a.number - b.number);\n\n  const getUniqueSourcesCount = (runners: Runner[]): number => {\n    const sources = new Set();\n    runners.forEach(runner => {\n      if (runner.odds) {\n        Object.keys(runner.odds).forEach(source => sources.add(source));\n      }\n    });\n    return sources.size;\n  };\n\n  const getBestOdds = (runner: Runner): { odds: number, source: string } | null => {\n    if (!runner.odds) return null;\n  const validOdds = Object.values(runner.odds).filter(o => o.win !== null && o.win !== undefined && o.win < 999);\n    if (validOdds.length === 0) return null;\n  const best = validOdds.reduce((min, o) => (o.win ?? 999) < (min.win ?? 999) ? o : min);\n    return { odds: best.win!, source: best.source };\n  };\n\n  return (\n    <div className={`race-card-enhanced border rounded-lg p-4 bg-gray-800 shadow-lg hover:border-purple-500 transition-all ${race.qualification_score && race.qualification_score >= 80 ? 'card-premium' : 'border-gray-700'}`}>\n      {/* Header with Smart Status Indicators */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <h2 className=\"text-2xl font-bold text-white\">{race.venue}</h2>\n            <div className=\"flex gap-2 text-sm text-gray-400\">\n              <span>Race {race.race_number}</span>\n              <span>\u2022</span>\n              <Countdown startTime={race.start_time} />\n            </div>\n            {race.favorite && (\n              <div className=\"flex items-center gap-2 mt-2 text-sm text-yellow-400\">\n                <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-4 w-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n                  <path d=\"M9.049 2.927c.3-.921 1.603-.921 1.902 0l1.07 3.292a1 1 0 00.95.69h3.462c.969 0 1.371 1.24.588 1.81l-2.8 2.034a1 1 0 00-.364 1.118l1.07 3.292c.3.921-.755 1.688-1.54 1.118l-2.8-2.034a1 1 0 00-1.175 0l-2.8 2.034c-.784.57-1.838-.197-1.539-1.118l1.07-3.292a1 1 0 00-.364-1.118L2.98 8.72c-.783-.57-.38-1.81.588-1.81h3.461a1 1 0 00.951-.69l1.07-3.292z\" />\n                </svg>\n                <span className=\"font-semibold\">Favorite: {race.favorite.name}</span>\n              </div>\n            )}\n          </div>\n        </div>\n\n        {race.qualification_score && (\n          <div className={`px-4 py-2 rounded-full text-center ${\n            race.qualification_score >= 80 ? 'bg-red-500/20 text-red-400 border border-red-500/30' :\n            race.qualification_score >= 60 ? 'bg-yellow-500/20 text-yellow-400 border border-yellow-500/30' :\n            'bg-green-500/20 text-green-400 border border-green-500/30'\n          }`}>\n            <div className=\"font-bold text-lg\">{race.qualification_score.toFixed(0)}%</div>\n            <div className=\"text-xs\">Score</div>\n          </div>\n        )}\n      </div>\n\n      {/* Race Conditions Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Distance</div>\n          <div className=\"text-sm font-semibold text-white\">{race.distance || 'N/A'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Surface</div>\n          <div className=\"text-sm font-semibold text-white\">{race.surface || 'Dirt'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Field</div>\n          <div className=\"text-sm font-semibold text-white\">{activeRunners.length}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Sources</div>\n          <div className=\"text-sm font-semibold text-white\">{getUniqueSourcesCount(race.runners)}</div>\n        </div>\n      </div>\n\n      {/* Interactive Runner Rows */}\n      <div className=\"runners-table space-y-2\">\n        {activeRunners.map((runner, idx) => {\n          const bestOddsInfo = getBestOdds(runner);\n          return (\n            <div key={runner.number} className=\"runner-row group hover:bg-purple-500/10 transition-all rounded-md p-3\">\n              <div className=\"flex items-center justify-between\">\n                <div className=\"flex items-center gap-4 flex-1\">\n                  <div className={`w-10 h-10 rounded-full flex items-center justify-center font-bold transition-all group-hover:scale-110 text-gray-900 shadow-lg ${idx === 0 ? 'bg-gradient-to-br from-yellow-400 to-yellow-600 shadow-yellow-500/50' : idx === 1 ? 'bg-gradient-to-br from-gray-300 to-gray-500 shadow-gray-400/50' : idx === 2 ? 'bg-gradient-to-br from-orange-400 to-orange-600 shadow-orange-500/50' : 'bg-gray-700 text-gray-300'}`}>\n                    {runner.number}\n                  </div>\n                  <div className=\"flex flex-col\">\n                    <span className=\"font-bold text-white text-lg\">{runner.name}</span>\n                    <div className=\"flex gap-3 text-sm text-gray-400\">\n                      {runner.jockey && <span>J: {runner.jockey}</span>}\n                      {runner.trainer && <span>T: {runner.trainer}</span>}\n                    </div>\n                  </div>\n                </div>\n                {bestOddsInfo && (\n                  <div className=\"text-right\">\n                    <div className=\"text-2xl font-bold text-emerald-400\">{bestOddsInfo.odds.toFixed(2)}</div>\n                    <div className=\"text-xs text-gray-500\">via {bestOddsInfo.source}</div>\n                  </div>\n                )}\n              </div>\n            </div>\n          );\n        })}\n      </div>\n    </div>\n  );\n};",
    "web_service/frontend/app/components/StatusDetailModal.tsx": "// web_platform/frontend/src/components/StatusDetailModal.tsx\nimport React from 'react';\n\ninterface StatusDetailModalProps {\n  isOpen: boolean;\n  onClose: () => void;\n  status: {\n      title: string;\n      details: string | Record<string, any>;\n  };\n}\n\nexport const StatusDetailModal: React.FC<StatusDetailModalProps> = ({ isOpen, onClose, status }) => {\n  if (!isOpen) {\n    return null;\n  }\n\n  const { title, details } = status;\n  const isDetailsString = typeof details === 'string';\n\n  // Determine status color only if details is an object with a status property\n  const statusColor = !isDetailsString && (details.status === 'SUCCESS' || details.status === 'OK')\n    ? 'text-green-400'\n    : 'text-gray-300'; // Default color\n\n  return (\n    <div className=\"fixed inset-0 bg-black/60 flex items-center justify-center z-50\" onClick={onClose}>\n      <div className=\"bg-gray-800 border border-gray-700 rounded-lg shadow-xl p-6 max-w-lg w-full\" onClick={e => e.stopPropagation()}>\n        <div className=\"flex justify-between items-start mb-4\">\n          <h3 className=\"text-xl font-bold text-white\">{title}</h3>\n          <button onClick={onClose} className=\"text-gray-400 hover:text-white\">&times;</button>\n        </div>\n        <div className=\"space-y-2 text-sm max-h-96 overflow-y-auto pr-2\">\n            {isDetailsString ? (\n                <div className=\"text-gray-300 whitespace-pre-wrap bg-gray-900/50 p-4 rounded-md\">{details}</div>\n            ) : (\n                Object.entries(details).map(([key, value]) => (\n                    <div key={key} className=\"grid grid-cols-3 gap-4 border-b border-gray-700/50 py-2\">\n                    <span className=\"font-semibold text-gray-400 capitalize\">{key.replace(/_/g, ' ')}</span>\n                    <span className={`col-span-2 break-words ${key === 'status' ? statusColor : 'text-gray-300'}`}>\n                        {typeof value === 'object' ? JSON.stringify(value, null, 2) : String(value)}\n                    </span>\n                    </div>\n                ))\n            )}\n        </div>\n        <button\n          onClick={onClose}\n          className=\"bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded w-full mt-6\"\n        >\n          Close\n        </button>\n      </div>\n    </div>\n  );\n};\n",
    "web_service/frontend/app/hooks/useWebSocket.ts": "// web_platform/frontend/src/hooks/useWebSocket.ts\n'use client';\n\nimport { useState, useEffect, useRef } from 'react';\n\ninterface WebSocketOptions {\n  apiKey: string | null;\n  port?: number | null; // Port is now optional\n}\n\nexport const useWebSocket = <T>(path: string, options: WebSocketOptions) => {\n  const [data, setData] = useState<T | null>(null);\n  const [isConnected, setIsConnected] = useState(false);\n  const webSocketRef = useRef<WebSocket | null>(null);\n\n  useEffect(() => {\n    if (!path || !options.apiKey) {\n      console.log('[useWebSocket] Missing path or API key. Aborting connection.');\n      if (webSocketRef.current) {\n        webSocketRef.current.close();\n      }\n      return;\n    }\n\n    // Use relative URL for same-origin, or build full URL if port is provided\n    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';\n    const host = options.port ? `localhost:${options.port}` : window.location.host;\n    const wsUrl = `${protocol}//${host}${path}?api_key=${options.apiKey}`;\n\n    console.log(`[useWebSocket] Attempting to connect to: ${wsUrl}`);\n\n    const ws = new WebSocket(wsUrl);\n    webSocketRef.current = ws;\n\n    ws.onopen = () => {\n      console.log('WebSocket connection established.');\n      setIsConnected(true);\n    };\n\n    ws.onmessage = (event) => {\n      try {\n        const messageData = JSON.parse(event.data);\n        setData(messageData);\n      } catch (error) {\n        console.error('Error parsing WebSocket message:', error);\n      }\n    };\n\n    ws.onerror = (error) => {\n      console.error('WebSocket error:', error);\n    };\n\n    ws.onclose = (event) => {\n      console.log(`WebSocket connection closed: ${event.code} ${event.reason}`);\n      setIsConnected(false);\n      webSocketRef.current = null;\n    };\n\n    return () => {\n      if (ws.readyState === WebSocket.OPEN) {\n        ws.close();\n      }\n    };\n  }, [path, options.apiKey, options.port]);\n\n  return { data, isConnected };\n};\n",
    "web_service/frontend/app/types/racing.ts": "// web_platform/frontend/src/types/racing.ts\n// This file is the central source of truth for frontend racing data types.\n\n// --- Runner & Odds Interfaces ---\nexport interface OddsData {\n  win: number | null;\n  place: number | null;\n  show: number | null;\n  source: string;\n  last_updated: string;\n}\n\nexport interface Runner {\n  number: number;\n  name: string;\n  scratched: boolean;\n  selection_id?: number;\n  odds: Record<string, OddsData>;\n  jockey?: string;\n  trainer?: string;\n}\n\n// --- Race Interface ---\n// This interface matches the shape of the data returned by the API for the dashboard.\nexport interface Race {\n  id: string;\n  venue: string;\n  race_number: number;\n  start_time: string;\n  runners: Runner[];\n  source: string;\n  qualification_score?: number;\n  distance?: string;\n  surface?: string;\n  favorite?: Runner;\n  isErrorPlaceholder?: boolean;\n  errorMessage?: string;\n}\n\n// --- API Response Interfaces ---\nexport interface SourceInfo {\n  name: string;\n  status: 'SUCCESS' | 'FAILED' | 'CONFIG_ERROR' | 'PENDING';\n  racesFetched: number;\n  fetchDuration: number;\n  errorMessage?: string;\n  attemptedUrl?: string;\n}\n\nexport interface AdapterError {\n  adapterName: string;\n  errorMessage: string;\n  attemptedUrl?: string;\n}\n\nexport interface AggregatedRacesResponse {\n  races: Race[];\n  errors: AdapterError[];\n  source_info: SourceInfo[];\n}\n\n// --- Analysis Factor Interfaces (retained from previous version) ---\nexport interface Factor {\n    points: number;\n    ok: boolean;\n    reason: string;\n}\n\nexport interface TrifectaFactors {\n    [key: string]: Factor;\n}\n",
    "web_service/frontend/tailwind.config.ts": "import type { Config } from 'tailwindcss'\n\nconst config: Config = {\n  darkMode: 'media',\n  content: [\n    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/components/**/*.{js,ts,jsx,tsx,mdx}',\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\nexport default config",
    "wix/product_webservice.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:fire=\"http://schemas.microsoft.com/wix/FirewallExtension\"\n     xmlns:util=\"http://schemas.microsoft.com/wix/UtilExtension\">\n\n  <Product Id=\"*\"\n           Name=\"Fortuna Web Service\"\n           Language=\"1033\"\n           Version=\"$(var.Version)\"\n           Manufacturer=\"Fortuna Development Team\"\n           UpgradeCode=\"A3A4A3B6-2313-4375-9A97-15206C81454A\">\n\n    <Package InstallerVersion=\"200\" Compressed=\"yes\" InstallScope=\"perMachine\" />\n    <MajorUpgrade DowngradeErrorMessage=\"A newer version of [ProductName] is already installed.\" />\n    <MediaTemplate EmbedCab=\"yes\" />\n\n    <Property Id=\"ARPNOREPAIR\" Value=\"no\" />\n    <Property Id=\"ARPNOMODIFY\" Value=\"yes\" />\n\n    <UI>\n      <UIRef Id=\"WixUI_Minimal\" />\n    </UI>\n\n    <WixVariable Id=\"WixUILicenseRtf\" Value=\"electron\\assets\\license.rtf\"/>\n    <WixVariable Id=\"WixUIBannerBmp\"  Value=\"electron\\assets\\banner.bmp\"/>\n    <WixVariable Id=\"WixUIDialogBmp\"  Value=\"electron\\assets\\dialog.bmp\"/>\n\n    <Feature Id=\"ProductFeature\" Title=\"Fortuna Web Service\" Level=\"1\">\n      <ComponentGroupRef Id=\"WebServiceComponents\" />\n      <ComponentRef Id=\"ApplicationShortcut\" />\n    </Feature>\n  </Product>\n\n  <Fragment>\n    <Directory Id=\"TARGETDIR\" Name=\"SourceDir\">\n      <Directory Id=\"ProgramFilesFolder\">\n        <Directory Id=\"INSTALLDIR\" Name=\"FortunaWebService\"/>\n      </Directory>\n      <Directory Id=\"ProgramMenuFolder\">\n        <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Web Service\"/>\n      </Directory>\n      <Directory Id=\"CommonAppDataFolder\">\n        <Directory Id=\"FortunaData\" Name=\"FortunaWebService\"/>\n      </Directory>\n    </Directory>\n  </Fragment>\n\n  <Fragment>\n    <ComponentGroup Id=\"WebServiceComponents\" Directory=\"INSTALLDIR\">\n      <Component Id=\"WebServiceExecutable\" Guid=\"3F2A4A9C-4055-4D62-812E-B715A0123594\">\n        <File Id=\"WebServiceExe\" Source=\"staging/fortuna-webservice.exe\" KeyPath=\"yes\"/>\n        <ServiceInstall Id=\"FortunaWebService\"\n                        Name=\"FortunaWebService\"\n                        DisplayName=\"Fortuna Web Service\"\n                        Description=\"Provides live odds and race data via a web interface.\"\n                        Start=\"auto\"\n                        Type=\"ownProcess\"\n                        ErrorControl=\"normal\"\n                        Account=\"NetworkService\"/>\n        <ServiceControl Id=\"StartFortunaWebService\"\n                        Name=\"FortunaWebService\"\n                        Start=\"install\"\n                        Stop=\"both\"\n                        Remove=\"uninstall\"\n                        Wait=\"yes\"/>\n        <fire:FirewallException Id=\"FortunaFirewall\"\n                                Name=\"FortunaWebService\"\n                                Port=\"8088\"\n                                Protocol=\"tcp\"\n                                Scope=\"any\"/>\n      </Component>\n    </ComponentGroup>\n  </Fragment>\n\n  <Fragment>\n    <DirectoryRef Id=\"ApplicationProgramsFolder\">\n      <Component Id=\"ApplicationShortcut\" Guid=\"5E95E5B9-4F3D-4B9A-819B-9149C5E4700F\">\n        <util:InternetShortcut Id=\"DashboardShortcut\"\n                               Name=\"Fortuna Dashboard\"\n                               Target=\"http://localhost:8088\"/>\n        <Shortcut Id=\"UninstallProduct\"\n                  Name=\"Uninstall Fortuna Web Service\"\n                  Target=\"[SystemFolder]msiexec.exe\"\n                  Arguments=\"/x [ProductCode]\"\n                  Description=\"Uninstalls Fortuna Web Service\"/>\n        <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\"/>\n        <RegistryValue Root=\"HKCU\"\n                       Key=\"Software\\FortunaWebService\"\n                       Name=\"installed\"\n                       Type=\"integer\"\n                       Value=\"1\"\n                       KeyPath=\"yes\"/>\n      </Component>\n    </DirectoryRef>\n  </Fragment>\n</Wix>\n"
}