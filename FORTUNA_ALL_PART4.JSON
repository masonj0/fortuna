{
    ".github/actions/run-asgi-diagnostics/action.yml": "name: 'Run ASGI Import Killer Diagnostics'\ndescription: 'Runs a multi-phase diagnostic to verify Python ASGI application imports.'\n\ninputs:\n  python-version:\n    description: 'The version of Python to use.'\n    required: true\n  backend-dir:\n    description: 'The directory of the backend service to test.'\n    required: true\n  backend-module-path:\n    description: 'The Python module path for the backend service (e.g., web_service.backend).'\n    required: true\n\nruns:\n  using: \"composite\"\n  steps:\n      - name: \u2699\ufe0f Setup Python (EXACT VERSION)\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ inputs.python-version }}\n\n      - name: \ud83d\udccb Capture Python Info\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          Write-Host \"Python executable: $(which python)\" -ForegroundColor Cyan\n          python --version\n          python -m site\n          python -c \"import sys; print('Prefix:', sys.prefix); print('Base prefix:', sys.base_prefix)\"\n\n      - name: \ud83d\udce5 Install Requirements (Exactly as Backend Build)\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel --quiet\n\n          Write-Host \"Installing requirements.txt...\" -ForegroundColor Cyan\n          pip install -r (Join-Path \"${{ inputs.backend-dir }}\" \"requirements.txt\") -v 2>&1 | Tee-Object \"install-requirements.log\"\n\n          if (Test-Path (Join-Path \"${{ inputs.backend-dir }}\" \"requirements-dev.txt\")) {\n            Write-Host \"Installing requirements-dev.txt...\" -ForegroundColor Cyan\n            pip install -r (Join-Path \"${{ inputs.backend-dir }}\" \"requirements-dev.txt\") -v 2>&1 | Tee-Object -Append \"install-requirements.log\"\n          }\n\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c pip install failed\" -ForegroundColor Red\n            exit 1\n          }\n\n          Write-Host \"\u2705 All dependencies installed\" -ForegroundColor Green\n\n      - name: \ud83d\udce6 Capture Installed Packages\n        shell: pwsh\n        run: |\n          pip list | Tee-Object \"installed-packages.txt\"\n          pip freeze | Tee-Object \"pip-freeze.txt\"\n\n      - name: \ud83d\udc0d Set PYTHONPATH\n        shell: pwsh\n        run: |\n          echo \"PYTHONPATH=${{ github.workspace }}\" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append\n          Write-Host \"PYTHONPATH set to ${{ github.workspace }}\"\n\n      - name: \ud83e\uddea PHASE 1 System Imports\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 1 SYSTEM-LEVEL IMPORTS\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('os', 'filesystem'), ('sys', 'system'), ('json', 'serialization'),\",\n            \"    ('asyncio', 'async I/O'), ('pathlib', 'paths'), ('typing', 'type hints'),\",\n            \"    ('importlib', 'import utilities')\",\n            ']',\n            'failed = []',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:20} [{desc}]\")',\n            '    except ImportError as e:',\n            '        print(f\"\u274c {mod_name:20} ImportError: {e}\")',\n            '        failed.append(mod_name)',\n            'if failed:',\n            '    print(f\"\\n\u274c {len(failed)} system imports failed\")',\n            '    sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 1 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 2 Web Framework Core\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'import traceback',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 2 WEB FRAMEWORK CORE\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('fastapi', 'web framework'),\",\n            \"    ('uvicorn', 'ASGI server'),\",\n            \"    ('starlette', 'ASGI toolkit'),\",\n            \"    ('starlette.applications', 'ASGI app'),\",\n            \"    ('starlette.routing', 'routing'),\",\n            ']',\n            'failed = []',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except ImportError as e:',\n            '        print(f\"\u274c {mod_name:30} ImportError: {e}\")',\n            '        failed.append((mod_name, str(e)))',\n            '    except Exception as e:',\n            '        print(f\"\u26a0\ufe0f  {mod_name:30} {type(e).__name__}: {e}\")',\n            'if failed:',\n            '    print(f\"\\n\u274c {len(failed)} core framework imports failed\")',\n            '    for mod, err in failed:',\n            '        print(f\"  - {mod}\")',\n            '    sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 2 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 3 Pydantic & Data Validation\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 3 PYDANTIC & DATA VALIDATION\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('pydantic', 'validation'),\",\n            \"    ('pydantic_core', 'core'),\",\n            \"    ('pydantic_settings', 'settings'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")',\n            '        sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 3 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 4 Async/IO Utilities\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 4 ASYNC/IO UTILITIES\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('anyio', 'async compat'),\",\n            \"    ('httpcore', 'HTTP core'),\",\n            \"    ('httpx', 'HTTP client'),\",\n            \"    ('aiosqlite', 'async DB'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")',\n            '        sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 4 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 5 Optional Dependencies (non-critical)\n        shell: pwsh\n        continue-on-error: true\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 5 OPTIONAL DEPENDENCIES (non-critical)\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('slowapi', 'rate limiting'),\",\n            \"    ('structlog', 'logging'),\",\n            \"    ('tenacity', 'retries'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u26a0\ufe0f  {mod_name:30} not critical: {type(e).__name__}\")',\n            'print(f\"\\n\u2705 Phase 5 complete (warnings OK)\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n\n      - name: \ud83e\uddea PHASE 6 Application Directory Structure\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n\n          $script = @(\n            'import os',\n            'from pathlib import Path',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 6 APPLICATION DIRECTORY STRUCTURE\")',\n            'print(\"=\"*80)',\n            'cwd = Path.cwd()',\n            'backend_dir = cwd / \"${{ inputs.backend-dir }}\"',\n            'print(f\"\\nCurrent directory: {cwd}\")',\n            'print(f\"\\nBackend directory exists: {backend_dir.exists()}\")',\n            'if backend_dir.exists():',\n            '    print(f\"  Contents:\")',\n            '    for item in backend_dir.iterdir():',\n            '        print(f\"    - {item.name}\")',\n            '    main_py = backend_dir / \"main.py\"',\n            '    api_py = backend_dir / \"api.py\"',\n            '    print(f''\\n  main.py: {main_py.stat().st_size if main_py.exists() else \"N/A\"} bytes'')',\n            '    print(f''  api.py: {api_py.stat().st_size if api_py.exists() else \"N/A\"} bytes'')'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n\n      - name: \ud83e\uddea PHASE 7 CRITICAL - Application Module Imports\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'import traceback',\n            'import importlib',\n            'from pathlib import Path',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 7 APPLICATION MODULE IMPORTS (CRITICAL)\")',\n            'print(\"=\"*80)',\n            'backend_module_path = \"${{ inputs.backend-module-path }}\"',\n            'print(f\"\\n[Step 1] Dynamically importing module: {backend_module_path}\")',\n            'try:',\n            '    backend_module = importlib.import_module(backend_module_path)',\n            '    print(f\"\u2705 {backend_module_path} imported successfully\")',\n            'except Exception as e:',\n            '    print(f\"\u274c FATAL: {backend_module_path} import failed\")',\n            '    print(f\"   Error: {type(e).__name__}: {e}\")',\n            '    traceback.print_exc()',\n            '    sys.exit(1)',\n            'print(''\\\\n[Step 2] Retrieving \"app\" object from the API submodule...'')',\n            'api_module_path = f\"{backend_module_path}.api\"',\n            'try:',\n            '    api_module = importlib.import_module(api_module_path)',\n            '    app = getattr(api_module, \"app\")',\n            '    print(f\"\u2705 app object retrieved from {api_module_path}\")',\n            '    print(f\"   Type: {type(app)}\")',\n            '    print(f\"   Class: {app.__class__.__name__}\")',\n            '    print(f\"   Module: {app.__class__.__module__}\")',\n            'except (ImportError, AttributeError) as e:',\n            '    print(f\"\u274c FATAL: Could not get app object from {api_module_path}\")',\n            '    print(f\"   Error: {type(e).__name__}: {e}\")',\n            '    traceback.print_exc()',\n            '    sys.exit(1)',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"\u2705 ALL APPLICATION IMPORTS SUCCESSFUL\")',\n            'print(\"=\"*80)',\n            'print(\"\\nThe ASGI app is fully importable.\")',\n            'print(\"Uvicorn should be able to load it successfully.\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c APPLICATION IMPORT TEST FAILED\" -ForegroundColor Red\n            exit 1\n          }\n\n      - name: \ud83d\udccb Generate ASGI Diagnostic Report\n        if: always()\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $report = @()\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report += \"\u2551              ASGI IMPORT KILLER - DIAGNOSTIC REPORT                        \u2551\"\n          $report += \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\"\n          $report += \"\"\n          $report += \"Timestamp: $(Get-Date -Format 'o')\"\n          $report += \"Python: $(python --version)\"\n          $report += \"\"\n          $report += \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\"\n          $result = if ($LASTEXITCODE -eq 0) { 'PASS \u2705' } else { 'FAIL \u274c' }\n          $report += \"\u2502 RESULT: $result \u2502\"\n          $report += \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\"\n          $report += \"\"\n          $report += \"If this passed:\"\n          $report += \"  \u2705 All required dependencies are installed\"\n          $report += \"  \u2705 python_service.main is importable\"\n          $report += \"  \u2705 FastAPI app is accessible\"\n          $report += \"  \u2705 The executable should work\"\n          $report += \"  \u2705 Uvicorn WILL be able to load the app\"\n          $report += \"\"\n          $report += \"If this failed:\"\n          $report += \"  \u274c See error output above for the exact problem\"\n          $report += \"  \u274c Fix the import error in your code\"\n          $report += \"  \u274c Common issues:\"\n          $report += \"     - Missing dependency in requirements.txt\"\n          $report += \"     - Syntax error in api.py or main.py\"\n          $report += \"     - Circular import in api.py\"\n          $report += \"     - api.py imports a module that fails\"\n          $report += \"\"\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report | Tee-Object \"asgi-diagnostic-report.txt\"\n\n      - name: \ud83d\udce4 Upload Diagnostic Artifacts\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: asgi-import-diagnostics-${{ github.run_id }}\n          path: |\n            install-requirements.log\n            installed-packages.txt\n            pip-freeze.txt\n            asgi-diagnostic-report.txt\n          retention-days: 30\n          if-no-files-found: warn\n",
    ".github/workflows/build-msi-revived.yml": "# System Timestamp: 2025-12-13 13:01:00\nname: \ud83e\udddf \ud83c\udfdb\ufe0f Fortuna Web Service MSI (The Veteran Reborn)\n\non:\n  push:\n    branches: [\"main\"]\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.11' # \ud83d\ude80 CRITICAL: 3.12 breaks x86 builds\n  DOTNET_VERSION: '8.0.x'\n  WIX_VERSION: '4.0.5'\n  FORTUNA_PORT: '8102'\n  # Mock Keys to prevent backend crash\n  API_KEY: mock_key\n  TVG_API_KEY: mock\n  GREYHOUND_API_URL: http://mock\n  FORTUNA_ENV: smoke-test\n  # Paths\n  FRONTEND_DIR: 'web_platform/frontend'\n  BACKEND_DIR: 'web_service/backend'\n  WIX_DIR: 'build_wix'\n\njobs:\n  # 1. BUILD FRONTEND (Architecture Neutral)\n  build-frontend:\n    name: '\ud83c\udfa8 Build Frontend'\n    runs-on: windows-latest\n    timeout-minutes: 20\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: '${{ env.FRONTEND_DIR }}/package-lock.json'\n\n      - name: Install & Build\n        run: |\n          cd ${{ env.FRONTEND_DIR }}\n          npm ci --prefer-offline --no-audit\n          npm run build\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: frontend-dist\n          path: ${{ env.FRONTEND_DIR }}/out\n\n  # 2. BUILD BACKEND (Matrix: x64 & x86)\n  build-backend:\n    name: '\ud83d\udc0d Build Backend (${{ matrix.arch }})'\n    runs-on: windows-latest\n    needs: build-frontend\n    strategy:\n      matrix:\n        arch: [x64, x86]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/download-artifact@v4\n        with:\n          name: frontend-dist\n          path: ${{ env.FRONTEND_DIR }}/out\n\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          architecture: ${{ matrix.arch }}\n          cache: 'pip'\n\n      - name: \ud83e\uddfe Create Architecture Constraints\n        id: constraints\n        shell: pwsh\n        run: |\n          $file = \"constraints.txt\"\n          if ('${{ matrix.arch }}' -eq 'x86') {\n            # \ud83d\ude80 SAFE MODE: Pin versions with known 32-bit wheels\n            \"numpy==1.23.5`r`npandas==1.5.3\" | Set-Content $file\n            Write-Host \"\u2705 Created x86 constraints (Safe Mode)\"\n          } else {\n            New-Item $file -ItemType File -Force\n            Write-Host \"\u2705 Created x64 constraints (Modern Mode)\"\n          }\n          \"file=$file\" | Out-File $env:GITHUB_OUTPUT -Append\n\n      - name: Install Dependencies\n        run: |\n          python -m pip install --upgrade pip setuptools wheel\n          # \ud83d\ude80 Apply Constraints\n          pip install -r ${{ env.BACKEND_DIR }}/requirements.txt -c ${{ steps.constraints.outputs.file }}\n          pip install pyinstaller==6.6.0 pywin32\n\n      - name: Build Backend (PyInstaller)\n        run: |\n          # CRITICAL: Target service_entry.py for Windows Service\n          # CRITICAL: Add win32timezone to prevent Error 1053\n          pyinstaller --noconfirm --onedir --clean --name fortuna-backend --hidden-import=win32timezone --hidden-import=win32serviceutil --add-data \"web_service/backend;backend\" web_service/backend/service_entry.py\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: backend-dist-${{ matrix.arch }}\n          path: dist/fortuna-backend/\n\n  # 3. PACKAGE MSI (Matrix: x64 & x86)\n  package-msi:\n    name: '\ud83d\udcbf Package MSI (${{ matrix.arch }})'\n    runs-on: windows-latest\n    needs: build-backend\n    strategy:\n      matrix:\n        arch: [x64, x86]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/download-artifact@v4\n        with:\n          name: backend-dist-${{ matrix.arch }}\n          path: staging/backend\n\n      - name: Create Restart Service Batch Script\n        shell: cmd\n        run: |\n          echo @echo off > staging\\backend\\restart_service.bat\n          echo net stop FortunaService >> staging\\backend\\restart_service.bat\n          echo net start FortunaService >> staging\\backend\\restart_service.bat\n\n      - name: '\u2696\ufe0f The Dietician (Size Analysis)'\n        shell: pwsh\n        run: |\n          $size = (Get-ChildItem staging -Recurse | Measure-Object -Property Length -Sum).Sum / 1MB\n          Write-Host \"Total Payload: $([math]::Round($size, 2)) MB\"\n\n      - uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: ${{ env.DOTNET_VERSION }}\n\n      - name: Build MSI\n        working-directory: ${{ env.WIX_DIR }}\n        run: |\n          # \ud83d\ude80 Pass Matrix Arch to WiX\n          dotnet build Fortuna.wixproj -c Release -p:Platform=${{ matrix.arch }} -p:Version=\"0.0.${{ github.run_number }}\" -p:SourceDir=\"../staging/backend\" -p:ServicePort=\"${{ env.FORTUNA_PORT }}\"\n\n      - name: Rename & Hash\n        run: |\n          $releaseDir = \"${{ env.WIX_DIR }}/bin/${{ matrix.arch }}/Release\"\n          $msi = Get-ChildItem -Path $releaseDir -Filter \"*.msi\" | Select -First 1\n          $target = \"FortunaService-${{ matrix.arch }}-${{ github.run_number }}.msi\"\n          Move-Item $msi.FullName -Destination \"$releaseDir/$target\" -Force\n          Write-Host \"\u2705 MSI Ready: $target\"\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: msi-${{ matrix.arch }}\n          path: ${{ env.WIX_DIR }}/bin/${{ matrix.arch }}/Release/*.msi\n\n  # 4. SMOKE TEST (Matrix: x64 & x86)\n  smoke-test:\n    name: '\ud83d\udd2c Smoke Test (${{ matrix.arch }})'\n    runs-on: windows-latest\n    needs: package-msi\n    strategy:\n      matrix:\n        arch: [x64, x86]\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: msi-${{ matrix.arch }}\n          path: installer\n\n      - name: Install MSI\n        run: |\n          $msi = Get-ChildItem installer/*.msi | Select -First 1\n          Start-Process msiexec.exe -ArgumentList \"/i `\"$($msi.FullName)`\" /qn /L*v install.log\" -Wait\n\n      - name: Verify Service & Port\n        shell: pwsh\n        env:\n          ARCH: ${{ matrix.arch }}\n        run: |\n          # \ud83d\ude80 DYNAMIC PATH LOGIC\n          $progFiles = if ($env:ARCH -eq 'x86') { ${env:ProgramFiles(x86)} } else { $env:ProgramFiles }\n          $installRoot = \"$progFiles\\FortunaWeb\"\n\n          if (-not (Test-Path $installRoot)) { throw \"\u274c Install dir not found at $installRoot\" }\n\n          Write-Host \"Waiting for service...\"\n          Start-Sleep -Seconds 10\n\n          $response = Invoke-WebRequest -Uri \"http://localhost:${{ env.FORTUNA_PORT }}/health\" -UseBasicParsing\n          if ($response.StatusCode -eq 200) { Write-Host \"\u2705 Service Healthy\" } else { throw \"\u274c Service Failed\" }\n\n      - name: '\ud83d\udcf8 Paparazzi (Visual Proof)'\n        run: |\n          npm install playwright\n          npx playwright install chromium --with-deps\n          # FIX: Point to /docs\n          $url = \"http://127.0.0.1:${{ env.FORTUNA_PORT }}/docs\"\n          node -e \"const { chromium } = require('playwright'); (async () => { const browser = await chromium.launch(); const page = await browser.newPage(); await page.goto('$url'); await page.screenshot({ path: 'proof.png' }); await browser.close(); })();\"\n\n      - uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: proof-${{ matrix.arch }}\n          path: proof.png",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `fortuna`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n\n---\n\n## The Age of Perfection (The Great Simplification)\n\nThe Penta-Hybrid architecture, while a triumph of technical integration, proved to be a strategic dead end. Its complexity became a fortress, making rapid iteration and onboarding of new intelligence (both human and AI) prohibitively expensive. The kingdom was powerful but brittle.\n\nA new doctrine was forged: **Simplicity is the ultimate sophistication.**\n\nThe decision was made to execute \"The Great Simplification.\" The multi-language backend (Python, Rust, Go) was decommissioned. The kingdom was reforged upon a new, elegant, and vastly more powerful two-pillar system:\n\n1.  **A Unified Python Backend:** A single, asynchronous Python service, built on FastAPI, would serve as the kingdom's engine.\n2.  **A Modern TypeScript Frontend:** A dedicated Next.js application would serve as the kingdom's command deck.\n\nThis act of creative destruction liberated the project, enabling a new era of unprecedented velocity.\n\n---\n\n## The Three-Pillar Doctrine\n\nWith the new two-pillar foundation in place, the backend itself was perfected into a three-pillar intelligence engine, a concept that defines the modern era of the Fortuna Faucet:\n\n*   **Pillar 1: The Future (The Planner):** The resilient `OddsEngine` and its fleet of adapters, responsible for finding the day's strategic opportunities.\n*   **Pillar 2: The Past (The Archive):** The perfected `ChartScraper` and `ResultsParser`, responsible for building our historical data warehouse from the ground truth of Equibase PDFs.\n*   **Pillar 3: The Present (The Finisher):** The weaponized `LiveOddsMonitor`, armed with the API-driven `BetfairAdapter`, designed to conquer the final moments of toteboard volatility.\n\nThese three pillars, orchestrated by the fully autonomous `fortuna_watchman.py`, represented the pinnacle of the project's original vision. The kingdom was, for a time, considered \"perfected.\"\n\n---\n\n## The Windows Ascension (The Impossible Dream)\n\nThe perfected kingdom was powerful, but it was still a tool for developers. The final, grandest vision was to transform it into a true, professional-grade application for its sole operator. This campaign, known as \"The Impossible Dream,\" was to forge the **Fortuna Faucet - Windows Native Edition.**\n\nThis era saw the rapid creation of a new, third layer of the kingdom, built upon the foundation of the previous work:\n\n*   **The Electron Shell:** The Next.js frontend was wrapped in an Electron container, transforming it from a website into a true, installable desktop application with its own window, icon, and system tray integration.\n*   **The Engine Room:** The Python backend was re-architected to run as a persistent, background **Windows Service**, making it a true, always-on component of the operating system, independent of the UI.\n*   **The Native GUI:** A dedicated Tkinter-based \"Observatory\" was forged\u2014a standalone GUI mission control for monitoring the health and performance of the background service.\n*   **The One-Click Kingdom:** A complete suite of professional tooling (including installation scripts, a setup wizard, and launchers) was created to provide a seamless, zero-friction installation and management experience.\n\nThis ascension represents the current state of the art, transforming a powerful engine into a polished, autonomous, and user-focused product.\n\n\n---\n\n## The Era of the Windows Kingdom (October 2025)\n\nWith the core engine stabilized and the command deck providing a clear view of the data, the project's focus shifted from pure data acquisition to the operator's experience. This era marked a profound transformation, elevating the project from a collection of powerful but disparate scripts into a cohesive, professional-grade, and resilient native Windows application.\n\nThis campaign, guided by a new \"Grand Strategy\" blueprint, was executed with rapid precision, resulting in a complete overhaul of the user-facing toolkit:\n\n-   **A Bulletproof Foundation:** The installation and launch scripts were re-architected from the ground up. They became intelligent and self-healing, featuring pre-flight system checks, automated port conflict resolution, active health-check loops, and automated repair utilities.\n-   **A Professional Toolkit:** The operator was empowered with a suite of new tools, including an interactive setup wizard, a real-time CLI status monitor, and a full-fledged graphical \"Data Management Console\" for monitoring, filtering, and analyzing data.\n-   **A Unified Command Console (`SERVICE_MANAGER.bat`):** Unify all individual scripts under a single, user-friendly, menu-driven service manager, providing a 'single pane of glass' for all common operations.\n\nThis era solidified the kingdom's foundations, making it not just powerful, but stable, reliable, and a pleasure to operate. The Faucet was no longer just an engine; it was a complete, professional-grade machine.\n\n---\n\n## The Gauntlet of CI/CD (Late October 2025)\n\nWith a professional-grade application in hand, the final frontier was professional-grade *delivery*. This campaign focused on automating the creation of the MSI installer through a continuous integration pipeline, a process that proved to be a formidable challenge.\n\nThe kingdom's engineers faced a relentless series of cryptic build errors from the WiX Toolset, a hostile environment that tested their resolve. Through a series of rapid, iterative fixes\u2014addressing everything from component GUIDs and 64-bit architecture mismatches to obscure linker errors and frontend dependency warnings\u2014they systematically conquered each obstacle.\n\nThis trial by fire culminated in a triumphant success: a fully automated GitHub Actions workflow that reliably compiles, links, and delivers a polished, distributable MSI installer. This victory transformed the project's delivery model from a manual, error-prone process into a repeatable, one-click release pipeline, marking the true completion of the \"Windows Ascension.\"\n\n---\n\n## The Great Unbundling (Late October 2025)\n\nThe CI/CD pipeline was technically successful, but it revealed a deeper, philosophical flaw in the architecture. The installer, while automated, was a fragile monolith. It attempted to bundle raw source code (Python, JavaScript) and orchestrate their setup on the user's machine using post-install scripts. This approach was fraught with peril, vulnerable to failures from network issues, corporate firewalls, and unpredictable machine states.\n\nA final, decisive architectural mandate was issued, informed by the wisdom of external AI consultants: **The application must be delivered, not assembled.**\n\nThis mandate triggered \"The Great Unbundling,\" a swift and transformative refactoring of the entire delivery pipeline:\n\n*   **The Backend Forged:** The Python backend was no longer treated as source code to be installed, but as a product to be delivered. **PyInstaller** was used to forge the entire FastAPI service\u2014interpreter and all dependencies\u2014into a single, standalone `.exe`.\n*   **The Frontend Solidified:** The Next.js frontend was no longer a service to be run, but a static asset to be displayed. The `npm run build` process was configured to produce a clean, static HTML/CSS/JS export.\n*   **The Installer Perfected:** With the application components now self-contained, the MSI installer's role was radically simplified. All complex post-install scripting was eliminated. The WiX toolset was now used for its core competency: reliably copying pre-compiled, robust artifacts to the user's machine.\n\nThis final act of architectural purification created the \"Three-Executable Architecture\" (the backend executable, the Electron wrapper, and the MSI installer itself), achieving true portability and eliminating an entire class of deployment failures. The Windows Ascension was not just complete; it was perfected.",
    "README.md": "# \ud83d\udc34 Fortuna Faucet - Developer's Guide\n\nThis guide provides technical instructions for developers. **For end-user installation, please see the [User Guide (README_WINDOWS.md)](README_WINDOWS.md).**\n\n---\n\n## Core Architecture\n\nThe project has a distinct architecture for production and development environments. Understanding this separation is key to effective development.\n\n*   **Production Architecture (MSI Installer):**\n    *   **Standalone Backend:** The Python backend is compiled into a single, self-contained executable (`fortuna-api.exe`) using **PyInstaller**. This bundles the Python interpreter and all dependencies, requiring no Python installation on the user's machine.\n    *   **Static Frontend:** The Next.js frontend is exported as a set of static HTML, CSS, and JavaScript assets.\n    *   **Electron Wrapper:** The Electron app acts as a lightweight shell, launching the backend executable as a background process and loading the static frontend directly from the filesystem.\n\n*   **Development Architecture:**\n    *   **Backend (`python_service/`):** An asynchronous FastAPI application run from a local Python virtual environment.\n    *   **Frontend (`web_platform/frontend/`):** A standard Next.js development server that enables hot-reloading for rapid UI development.\n\n## Development Environment\n\n### 1. Prerequisites\n\n*   Python 3.12+\n*   Node.js (LTS)\n*   Git\n\n### 2. Initial One-Time Setup\n\nFor your first time setting up the project, run the main setup script. This will create the Python virtual environment and install all necessary dependencies for both the backend and frontend.\n\n```bash\ngit clone https://github.com/masonj0/fortuna.git\ncd fortuna\nrun_dev_environment.bat\n```\n\n### 3. Daily Execution (Backend)\n\nTo start the backend server, use the new official launcher script. This script ensures the server starts correctly and avoids common import errors.\n\n```bash\n# From the project root, with your virtual environment activated\npython run_backend.py\n```\n\nThis script will check for dependencies, ensure the environment is correct, and launch the Uvicorn server.\n\n**(Frontend)** To start the frontend server for UI development, run the following command in a separate terminal:\n\n```bash\nnpm run dev --prefix web_platform/frontend\n```\n\n---\n## Web Service Development Environment\n\nThis section details the setup for the new web service architecture, which is independent of the original Electron application.\n\n### Backend (`web_service/backend/`)\n\n1.  **Navigate to the backend directory:**\n    ```bash\n    cd web_service/backend\n    ```\n2.  **Create a virtual environment:**\n    ```bash\n    python -m venv .venv\n    ```\n3.  **Activate the virtual environment:**\n    *   Windows: `.venv\\Scripts\\activate`\n    *   macOS/Linux: `source .venv/bin/activate`\n4.  **Install dependencies:**\n    ```bash\n    pip install -r requirements-dev.txt\n    ```\n5.  **Run the development server:**\n    ```bash\n    python main.py\n    ```\n\n### Frontend (`web_service/frontend/`)\n\n1.  **Navigate to the frontend directory:**\n    ```bash\n    cd web_service/frontend\n    ```\n2.  **Install dependencies:**\n    ```bash\n    npm install\n    ```\n3.  **Run the development server:**\n    ```bash\n    npm run dev\n    ```\n---\n\n## Configuration\n\nThe backend server port can be configured using an environment variable.\n\n*   **`FORTUNA_PORT`**: Sets the port for the backend API service. Defaults to `8000` if not specified.\n\n**Example (PowerShell):**\n```powershell\n$env:FORTUNA_PORT=8088\npython run_backend.py\n```\n\n---\n\n## Key Scripts & Tooling\n\n*   **`run_dev_environment.bat`**: The master script for the **initial one-time setup** of the development environment.\n*   **`scripts/fortuna-quick-start.ps1`**: The recommended script for **daily execution**, providing robust process management for both backend and frontend servers.\n*   **`scripts/build_msi.ps1`**: The local build orchestrator. This script runs the entire production build pipeline: it compiles the backend with PyInstaller, builds the static frontend, and packages everything into an MSI installer using the WiX Toolset.\n*   **`ARCHIVE_PROJECT.py`**: The \"True Scribe.\" This script programmatically scans the repository and generates the `FORTUNA_ALL_PART*.JSON` archive files, which are the authoritative source for project-wide code reviews.\n*   **`.github/workflows/build-msi.yml`**: The CI/CD pipeline definition for GitHub Actions, which automates the creation of the release MSI installer.\n",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2)---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "python_service/adapters/at_the_races_adapter.py": "# python_service/adapters/at_the_races_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass AtTheRacesAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for attheraces.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"AtTheRaces\"\n    BASE_URL = \"https://www.attheraces.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        Returns a dictionary containing the HTML content and the date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch AtTheRaces index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        links = {a[\"href\"] for a in index_soup.select(\"a.race-time-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        all_races = []\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to AtTheRacesAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n                header_element = soup.select_one(\"h1.heading-racecard-title\")\n                if not header_element:\n                    continue\n                header = header_element.get_text()\n                track_name_raw, race_time = [p.strip() for p in header.split(\"|\")[:2]]\n                track_name = normalize_venue_name(track_name_raw)\n                active_link = soup.select_one(\"a.race-time-link.active\")\n                race_number = 1\n                if active_link:\n                    parent_div = active_link.find_parent(\"div\", \"races\")\n                    if parent_div:\n                        all_links = parent_div.select(\"a.race-time-link\")\n                        race_number = all_links.index(active_link) + 1\n\n                start_time = datetime.combine(race_date, datetime.strptime(race_time, \"%H:%M\").time())\n\n                runners = [self._parse_runner(row) for row in soup.select(\"div.card-horse\")]\n                race = Race(\n                    id=f\"atr_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, IndexError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from AtTheRaces, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_element = row.select_one(\"h3.horse-name a\")\n            if not name_element:\n                return None\n            name = clean_text(name_element.get_text())\n\n            num_element = row.select_one(\"span.horse-number\")\n            if not num_element:\n                return None\n            num_str = clean_text(num_element.get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n\n            odds_element = row.select_one(\"button.best-odds\")\n            odds_str = clean_text(odds_element.get_text()) if odds_element else \"\"\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {\n                    self.source_name: OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n                }\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on AtTheRaces, skipping runner.\")\n            return None\n",
    "python_service/adapters/base_adapter_v3.py": "# python_service/adapters/base_v3.py\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom typing import Any\nfrom typing import AsyncGenerator\nfrom typing import List\n\nimport httpx\nimport structlog\nfrom tenacity import RetryError\nfrom tenacity import retry\nfrom tenacity import stop_after_attempt\nfrom tenacity import wait_exponential\n\nfrom ..core.exceptions import AdapterHttpError\nfrom ..manual_override_manager import ManualOverrideManager\nfrom ..models import Race\n\n\nclass BaseAdapterV3(ABC):\n    \"\"\"\n    Abstract base class for all V3 data adapters.\n    Enforces a standardized fetch/parse pattern and includes robust request handling.\n    \"\"\"\n\n    def __init__(self, source_name: str, base_url: str, config=None, timeout: int = 20):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.config = config\n        self.timeout = timeout\n        self.logger = structlog.get_logger(adapter_name=self.source_name)\n        self.http_client: httpx.AsyncClient = None  # Injected by the engine\n        self.manual_override_manager: ManualOverrideManager = None\n        self.supports_manual_override = True  # Can be overridden by subclasses\n\n    def enable_manual_override(self, manager: ManualOverrideManager):\n        \"\"\"Injects the manual override manager into the adapter.\"\"\"\n        self.manual_override_manager = manager\n\n    @abstractmethod\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw data (e.g., HTML, JSON) for the given date.\n        This is the only method that should perform network operations.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        Parses the raw data retrieved by _fetch_data into a list of Race objects.\n        This method should be a pure function with no side effects.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        Orchestrates the fetch-then-parse pipeline for the adapter.\n        This public method should not be overridden by subclasses.\n        \"\"\"\n        raw_data = None\n\n        if self.manual_override_manager:\n            # This is not a full URL, but a representative key for the fetch operation\n            # Subclasses might need to override get_races to provide a more specific URL if needed\n            lookup_key = f\"{self.base_url}/racecards/{date}\"\n            manual_data = self.manual_override_manager.get_manual_data(self.source_name, lookup_key)\n            if manual_data:\n                self.logger.info(\"Using manually submitted data for request\", url=lookup_key)\n                # Reconstruct a dictionary similar to what _fetch_data would return\n                # This may need adjustment based on adapter specifics\n                raw_data = {\"pages\": [manual_data[0]], \"date\": date}\n\n        if raw_data is None:\n            try:\n                raw_data = await self._fetch_data(date)\n            except AdapterHttpError as e:\n                if self.manual_override_manager and self.supports_manual_override:\n                    self.manual_override_manager.register_failure(self.source_name, e.url)\n                raise  # Reraise the exception to be handled by the OddsEngine\n\n        if raw_data is not None:\n            parsed_races = self._parse_races(raw_data)\n            for race in parsed_races:\n                yield race\n\n    @retry(\n        wait=wait_exponential(multiplier=1, min=2, max=10),\n        stop=stop_after_attempt(3),\n        reraise=True,  # Reraise the final exception to be caught by get_races\n    )\n    async def make_request(self, http_client: httpx.AsyncClient, method: str, url: str, **kwargs) -> httpx.Response:\n        \"\"\"\n        Makes a resilient HTTP request with built-in retry logic using tenacity.\n        \"\"\"\n        # Ensure the URL is correctly formed, whether it's relative or absolute\n        full_url = url if url.startswith(\"http\") else f\"{self.base_url.rstrip('/')}/{url.lstrip('/')}\"\n\n        try:\n            self.logger.info(\"Making request\", method=method.upper(), url=full_url)\n            response = await http_client.request(method, full_url, timeout=self.timeout, **kwargs)\n            response.raise_for_status()  # Raise an exception for 4xx/5xx responses\n            return response\n        except httpx.HTTPStatusError as e:\n            self.logger.error(\n                \"HTTP Status Error during request\",\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            )\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            ) from e\n        except (httpx.RequestError, RetryError) as e:\n            self.logger.error(\"Request Error or Retry Error\", error=str(e))\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=503,  # Service Unavailable\n                url=full_url,\n            ) from e\n\n    def get_status(self) -> dict:\n        \"\"\"\n        Returns a dictionary representing the adapter's current status.\n        Subclasses can extend this to include more specific health checks.\n        \"\"\"\n        return {\n            \"adapter_name\": self.source_name,\n            \"status\": \"OK\",  # Basic status; can be enhanced in subclasses\n        }\n",
    "python_service/adapters/betfair_datascientist_adapter.py": "# python_service/adapters/betfair_datascientist_adapter.py\n\nfrom datetime import datetime\nfrom io import StringIO\nfrom typing import List\nfrom typing import Optional\n\nimport pandas as pd\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass BetfairDataScientistAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for the Betfair Data Scientist CSV models, migrated to BaseAdapterV3.\n    \"\"\"\n\n    ADAPTER_NAME = \"BetfairDataScientist\"\n\n    def __init__(self, model_name: str, url: str, config=None):\n        source_name = f\"{self.ADAPTER_NAME}_{model_name}\"\n        super().__init__(source_name=source_name, base_url=url, config=config)\n        self.model_name = model_name\n\n    async def _fetch_data(self, date: str) -> Optional[StringIO]:\n        \"\"\"Fetches the raw CSV data from the Betfair Data Scientist model endpoint.\"\"\"\n        endpoint = f\"?date={date}&presenter=RatingsPresenter&csv=true\"\n        self.logger.info(f\"Fetching data from {self.base_url}{endpoint}\")\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return StringIO(response.text) if response and response.text else None\n\n    def _parse_races(self, raw_data: Optional[StringIO]) -> List[Race]:\n        \"\"\"Parses the raw CSV data into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n        try:\n            df = pd.read_csv(raw_data)\n            if df.empty:\n                self.logger.warning(\"Received empty CSV from Betfair Data Scientist.\")\n                return []\n\n            df = df.rename(\n                columns={\n                    \"meetings.races.bfExchangeMarketId\": \"market_id\",\n                    \"meetings.races.runners.bfExchangeSelectionId\": \"selection_id\",\n                    \"meetings.races.runners.ratedPrice\": \"rated_price\",\n                    \"meetings.races.raceName\": \"race_name\",\n                    \"meetings.name\": \"meeting_name\",\n                    \"meetings.races.raceNumber\": \"race_number\",\n                    \"meetings.races.runners.runnerName\": \"runner_name\",\n                    \"meetings.races.runners.clothNumber\": \"saddle_cloth\",\n                }\n            )\n            races: List[Race] = []\n            for market_id, group in df.groupby(\"market_id\"):\n                race_info = group.iloc[0]\n                runners = []\n                for _, row in group.iterrows():\n                    rated_price = row.get(\"rated_price\")\n                    odds_data = {}\n                    if pd.notna(rated_price):\n                        odds_data[self.source_name] = OddsData(\n                            win=float(rated_price),\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                    runners.append(\n                        Runner(\n                            name=str(row.get(\"runner_name\", \"Unknown\")),\n                            number=int(row.get(\"saddle_cloth\", 0)),\n                            odds=odds_data,\n                        )\n                    )\n\n                race = Race(\n                    id=str(market_id),\n                    venue=normalize_venue_name(str(race_info.get(\"meeting_name\", \"\"))),\n                    race_number=int(race_info.get(\"race_number\", 0)),\n                    start_time=datetime.now(),  # Placeholder, not provided in source\n                    runners=runners,\n                    source=self.source_name,\n                )\n                races.append(race)\n            self.logger.info(f\"Normalized {len(races)} races from {self.model_name}.\")\n            return races\n        except (pd.errors.ParserError, KeyError) as e:\n            self.logger.error(\n                \"Failed to parse Betfair Data Scientist CSV.\",\n                exc_info=True,\n                error=str(e),\n            )\n            return []\n",
    "python_service/adapters/oddschecker_adapter.py": "# python_service/adapters/oddschecker_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass OddscheckerAdapter(BaseAdapterV3):\n    \"\"\"Adapter for scraping horse racing odds from Oddschecker, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"Oddschecker\"\n    BASE_URL = \"https://www.oddschecker.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date. This involves a multi-level fetch.\n        \"\"\"\n        # Note: Oddschecker doesn't seem to support historical dates well in its main nav,\n        # but we build the URL as if it does for future compatibility.\n        index_url = f\"/horse-racing/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Oddschecker index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        # Find all links to individual race pages\n        race_links = {a[\"href\"] for a in index_soup.select(\"a.race-time-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings from different races into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to OddscheckerAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n                race = self._parse_race_page(soup, race_date)\n                if race:\n                    all_races.append(race)\n            except (AttributeError, IndexError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from Oddschecker, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_race_page(self, soup: BeautifulSoup, race_date) -> Optional[Race]:\n        track_name_node = soup.select_one(\"h1.meeting-name\")\n        if not track_name_node:\n            return None\n        track_name = track_name_node.get_text(strip=True)\n\n        race_time_node = soup.select_one(\"span.race-time\")\n        if not race_time_node:\n            return None\n        race_time_str = race_time_node.get_text(strip=True)\n\n        # Heuristic to find race number from navigation\n        active_link = soup.select_one(\"a.race-time-link.active\")\n        race_number = 1\n        if active_link:\n            all_links = soup.select(\"a.race-time-link\")\n            try:\n                race_number = all_links.index(active_link) + 1\n            except ValueError:\n                pass  # Keep default race number if active link not in all links\n\n        start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n        runners = [runner for row in soup.select(\"tr.race-card-row\") if (runner := self._parse_runner_row(row))]\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"oc_{track_name.lower().replace(' ', '')}_{start_time.strftime('%Y%m%d')}_r{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _parse_runner_row(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"span.selection-name\")\n            if not name_node:\n                return None\n            name = name_node.get_text(strip=True)\n\n            odds_node = row.select_one(\"span.bet-button-odds-desktop, span.best-price\")\n            if not odds_node:\n                return None\n            odds_str = odds_node.get_text(strip=True)\n\n            number_node = row.select_one(\"td.runner-number\")\n            if not number_node or not number_node.get_text(strip=True).isdigit():\n                return None\n            number = int(number_node.get_text(strip=True))\n\n            if not name or not odds_str:\n                return None\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_dict = {}\n            if win_odds and win_odds < 999:\n                odds_dict[self.source_name] = OddsData(\n                    win=win_odds, source=self.source_name, last_updated=datetime.now()\n                )\n\n            return Runner(number=number, name=name, odds=odds_dict)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on Oddschecker, skipping runner.\")\n            return None\n",
    "python_service/adapters/pointsbet_greyhound_adapter.py": "# python_service/adapters/pointsbet_greyhound_adapter.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n# NOTE: This is a hypothetical implementation based on a potential API structure.\n\n\nclass PointsBetGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"Adapter for the hypothetical PointsBet Greyhound API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"PointsBetGreyhound\"\n    BASE_URL = \"https://api.pointsbet.com/api/v2/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches all greyhound events for a given date.\"\"\"\n        endpoint = f\"sports/greyhound-racing/events/by-date/{date}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json().get(\"events\", []) if response else None\n\n    def _parse_races(self, raw_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw event data into a list of standardized Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for event in raw_data:\n            try:\n                if not event.get(\"competitors\") or not event.get(\"startTime\"):\n                    continue\n\n                runners = []\n                for competitor in event.get(\"competitors\", []):\n                    price = competitor.get(\"price\")\n                    if not price:\n                        continue\n\n                    odds_val = Decimal(str(price))\n                    odds = {\n                        self.source_name: OddsData(\n                            win=odds_val,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n                    runner = Runner(\n                        number=competitor.get(\"number\", 99),\n                        name=competitor.get(\"name\", \"Unknown\"),\n                        odds=odds,\n                    )\n                    runners.append(runner)\n\n                if runners:\n                    race_id = event.get(\"id\")\n                    if not race_id:\n                        continue\n\n                    race = Race(\n                        id=f\"pbg_{race_id}\",\n                        venue=event.get(\"venue\", {}).get(\"name\", \"Unknown Venue\"),\n                        start_time=datetime.fromisoformat(event[\"startTime\"]),\n                        race_number=event.get(\"raceNumber\", 1),\n                        runners=runners,\n                        source=self.source_name,\n                    )\n                    races.append(race)\n            except (KeyError, TypeError, ValueError):\n                self.logger.warning(\n                    \"Failed to parse PointsBet Greyhound event.\",\n                    event=event,\n                    exc_info=True,\n                )\n                continue\n        return races\n",
    "python_service/adapters/template_adapter.py": "# python_service/adapters/template_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TemplateAdapter(BaseAdapterV3):\n    \"\"\"\n    A template for creating new adapters, based on the BaseAdapterV3 pattern.\n    This adapter is a non-functional stub.\n    \"\"\"\n\n    SOURCE_NAME = \"[IMPLEMENT ME] Example Source\"\n    BASE_URL = \"https://api.example.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        # self.api_key = config.EXAMPLE_API_KEY # Uncomment if needed\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/adapters/twinspires_adapter.py": "# python_service/adapters/twinspires_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TwinSpiresAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for twinspires.com.\n    This is a placeholder for a full implementation using the discovered JSON API.\n    \"\"\"\n\n    SOURCE_NAME = \"TwinSpires\"\n    BASE_URL = \"https://www.twinspires.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Reads HTML content from a local fixture file instead of making a live API call.\n        This is a temporary measure to allow development while the live API is blocking requests.\n        \"\"\"\n        # Read the local HTML fixture\n        try:\n            with open(\"tests/fixtures/twinspires_sample.html\", \"r\") as f:\n                html_content = f.read()\n        except FileNotFoundError:\n            self.logger.error(\"TwinSpires test fixture not found.\")\n            return None\n\n        # To maintain the data structure the parser expects, we will create a mock\n        # raw_data object that resembles the original API response, but includes\n        # the HTML content.\n        return {\n            \"html_content\": html_content,\n            \"mock_track_data\": {\"trackId\": \"cd\", \"trackName\": \"Churchill Downs\", \"raceType\": \"Thoroughbred\"},\n            \"mock_race_card\": {\"raceNumber\": 5, \"postTime\": \"2025-10-26T16:30:00Z\"},\n        }\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Parses race and runner data from the mock raw_data object, which now\n        includes the HTML content from the local fixture.\n        \"\"\"\n        if not raw_data or \"html_content\" not in raw_data:\n            return []\n\n        self.logger.info(\"Parsing TwinSpires data from local fixture.\")\n\n        html_content = raw_data[\"html_content\"]\n        track = raw_data[\"mock_track_data\"]\n        race_card = raw_data[\"mock_race_card\"]\n\n        # Parse the runners from the HTML content\n        runners = self._parse_runners_from_html(html_content)\n\n        try:\n            start_time = datetime.fromisoformat(race_card.get(\"postTime\").replace(\"Z\", \"+00:00\"))\n\n            race = Race(\n                id=f\"ts_{track.get('trackId')}_{race_card.get('raceNumber')}\",\n                venue=track.get(\"trackName\"),\n                race_number=race_card.get(\"raceNumber\"),\n                start_time=start_time,\n                discipline=track.get(\"raceType\", \"Unknown\"),\n                runners=runners,\n                source=self.SOURCE_NAME,\n            )\n            return [race]\n        except Exception as e:\n            self.logger.warning(\n                \"Failed to parse race card from mock data.\",\n                error=e,\n                exc_info=True,\n            )\n            return []\n\n    def _parse_runners_from_html(self, html_content: str) -> List[Runner]:\n        \"\"\"Parses runner data from a race card's HTML content.\"\"\"\n        runners = []\n        soup = BeautifulSoup(html_content, \"html.parser\")\n        runner_elements = soup.select(\"li.runner\")\n\n        for element in runner_elements:\n            try:\n                scratched = \"scratched\" in element.get(\"class\", [])\n\n                number_tag = element.select_one(\"span.runner-number\")\n                name_tag = element.select_one(\"span.runner-name\")\n                odds_tag = element.select_one(\"span.runner-odds\")\n\n                if not all([number_tag, name_tag, odds_tag]):\n                    continue\n\n                number = int(number_tag.text.strip())\n                name = name_tag.text.strip()\n                odds_str = odds_tag.text.strip()\n\n                odds = {}\n                if not scratched and odds_str not in [\"SCR\", \"\"]:\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    if win_odds:\n                        odds[self.SOURCE_NAME] = OddsData(\n                            win=win_odds,\n                            source=self.SOURCE_NAME,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=number,\n                        name=name,\n                        scratched=scratched,\n                        odds=odds,\n                    )\n                )\n            except (ValueError, TypeError) as e:\n                self.logger.warning(\"Failed to parse a runner, skipping.\", error=e, exc_info=True)\n                continue\n\n        return runners\n\n    async def _get_races_async(self, date: str) -> List[Race]:\n        raw_data = await self._fetch_data(date)\n        return self._parse_races(raw_data)\n\n    def get_races(self, date: str) -> List[Race]:\n        \"\"\"\n        Orchestrates the fetching and parsing of race data for a given date.\n        This method will be called by the FortunaEngine.\n        \"\"\"\n        self.logger.info(f\"Getting races for {date} from {self.SOURCE_NAME}\")\n        # This is a synchronous wrapper for the async orchestrator\n        # It's a temporary measure to allow me to see the API response.\n        import asyncio\n\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        races = loop.run_until_complete(self._get_races_async(date))\n        return races\n",
    "python_service/auditor.py": "\"\"\"\nThe Auditor: Real-Time Race Verification System\n\nThis module runs as a background thread within the Python Backend.\nIt verifies predictions against official results and calculates profitability.\n\nRequirements:\n    pip install aiosqlite httpx beautifulsoup4 lxml structlog\n\"\"\"\n\nimport asyncio\nimport sqlite3\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, List, Any\nfrom dataclasses import dataclass\nimport httpx\nfrom bs4 import BeautifulSoup\nimport structlog\nimport re\n\nlogger = structlog.get_logger()\n\n\n@dataclass\nclass OfficialResult:\n    \"\"\"Represents official race results from Equibase/GBGB\"\"\"\n    race_id: str\n    finishers: List[Dict[str, Any]]  # List of {name, position, place_payout}\n\n\nclass AuditorEngine:\n    \"\"\"\n    Real-time verification engine that tracks predictions and verifies them\n    against official results.\n    \"\"\"\n    \n    def __init__(self, db_path: str = \"audit.db\"):\n        self.db_path = db_path\n        self.http_client = httpx.AsyncClient(timeout=30.0, follow_redirects=True)\n        self.TOTE_UNIT = 2.00  # Standard $2.00 bet unit\n        self._running = False\n        self._init_database()\n\n        # Simple mapping for UK racecourses\n        self.TRACK_CODE_MAP = {\n            \"DON\": \"Doncaster\",\n            \"LING\": \"Lingfield\",\n            \"NCLE\": \"Newcastle\",\n            \"WOLV\": \"Wolverhampton\",\n            \"CHELT\": \"Cheltenham\",\n        }\n    \n    def _init_database(self):\n        \"\"\"Initialize the SQLite database schema\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS audit_log (\n                race_id TEXT PRIMARY KEY,\n                track_code TEXT NOT NULL,\n                race_number INTEGER NOT NULL,\n                predicted_horse TEXT NOT NULL,\n                timestamp DATETIME NOT NULL,\n                status TEXT NOT NULL DEFAULT 'PENDING',\n                official_payout REAL DEFAULT 0.00,\n                net_profit REAL DEFAULT 0.00,\n                CHECK (status IN ('PENDING', 'CASHED', 'BURNED'))\n            )\n        \"\"\")\n        \n        # Index for faster pending race queries\n        cursor.execute(\"\"\"\n            CREATE INDEX IF NOT EXISTS idx_status_timestamp \n            ON audit_log(status, timestamp)\n        \"\"\")\n        \n        conn.commit()\n        conn.close()\n        logger.info(\"Database initialized\", db_path=self.db_path)\n    \n    async def snapshot_qualifier(\n        self, \n        venue_code: str, \n        race_date: str, \n        race_number: int, \n        predicted_horse: str\n    ) -> bool:\n        \"\"\"\n        Phase 1: The Snapshot\n        Called by OddsEngine when a race qualifies as a bet.\n        \n        Args:\n            venue_code: Track code (e.g., \"GP\", \"SA\")\n            race_date: Date in YYYYMMDD format\n            race_number: Race number\n            predicted_horse: Name of predicted horse\n            \n        Returns:\n            True if snapshot saved, False if already exists\n        \"\"\"\n        race_id = self._generate_race_id(venue_code, race_date, race_number)\n        \n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute(\"\"\"\n                INSERT INTO audit_log \n                (race_id, track_code, race_number, predicted_horse, timestamp, status)\n                VALUES (?, ?, ?, ?, ?, 'PENDING')\n            \"\"\", (race_id, venue_code, race_number, predicted_horse, datetime.now()))\n            \n            conn.commit()\n            conn.close()\n            \n            logger.info(\n                \"Snapshot saved for verification\",\n                race_id=race_id,\n                horse=predicted_horse\n            )\n            return True\n            \n        except sqlite3.IntegrityError:\n            logger.warning(\"Race already tracked\", race_id=race_id)\n            return False\n    \n    async def run_audit_loop(self):\n        \"\"\"\n        Phase 2: The Fetcher\n        Runs continuously to check results for pending races.\n        \"\"\"\n        self._running = True\n        logger.info(\"Audit loop started\")\n        \n        while self._running:\n            try:\n                # Find pending races from the last 60 minutes\n                cutoff_time = datetime.now() - timedelta(minutes=60)\n                pending_races = self._get_pending_races(cutoff_time)\n                \n                if not pending_races:\n                    logger.debug(\"No pending races to audit\")\n                    await asyncio.sleep(120)\n                    continue\n                \n                logger.info(f\"Found {len(pending_races)} pending races to verify\")\n                \n                # Fetch official results (batch by track to be polite)\n                tracks_to_check = set(race['track_code'] for race in pending_races)\n                \n                for track_code in tracks_to_check:\n                    track_races = [r for r in pending_races if r['track_code'] == track_code]\n                    \n                    for race in track_races:\n                        official_result = await self._fetch_official_result(\n                            race['track_code'],\n                            race['race_number']\n                        )\n                        \n                        if official_result:\n                            self._determine_verdict(race, official_result)\n                        \n                        # Be polite to the server\n                        await asyncio.sleep(2)\n                \n            except Exception as e:\n                logger.error(\"Error in audit loop\", error=str(e), exc_info=True)\n            \n            await asyncio.sleep(120)\n    \n    def stop_audit_loop(self):\n        \"\"\"Stop the audit loop gracefully\"\"\"\n        self._running = False\n        logger.info(\"Audit loop stopped\")\n    \n    def _get_pending_races(self, cutoff_time: datetime) -> List[Dict]:\n        \"\"\"Get all pending races after cutoff time\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n            SELECT * FROM audit_log\n            WHERE status = 'PENDING' AND timestamp > ?\n            ORDER BY timestamp ASC\n        \"\"\", (cutoff_time,))\n        \n        races = [dict(row) for row in cursor.fetchall()]\n        conn.close()\n        \n        return races\n    \n    def _determine_verdict(self, prediction: Dict, official_result: OfficialResult):\n        \"\"\"\n        Phase 3: The Verdict & Economics\n        Determine if prediction was correct and calculate profit/loss.\n        \"\"\"\n        did_place = False\n        payout = 0.00\n        \n        # Check if our horse is in the official \"Place\" payouts\n        # Note: \"Place\" in US racing covers 1st and 2nd\n        for finisher in official_result.finishers:\n            if (finisher['name'].upper() == prediction['predicted_horse'].upper() and\n                finisher.get('place_payout', 0) > 0):\n                did_place = True\n                payout = finisher['place_payout']\n                break\n        \n        # Calculate Net Profit based on $2.00 Unit\n        if did_place:\n            new_status = 'CASHED'\n            net_profit = payout - self.TOTE_UNIT\n            logger.info(\n                \"\ud83d\udcb0 CASHED\",\n                race_id=prediction['race_id'],\n                horse=prediction['predicted_horse'],\n                payout=payout,\n                profit=net_profit\n            )\n        else:\n            new_status = 'BURNED'\n            net_profit = -self.TOTE_UNIT  # Lost the $2.00 stake\n            logger.warning(\n                \"\ud83d\udd25 BURNED\",\n                race_id=prediction['race_id'],\n                horse=prediction['predicted_horse'],\n                loss=net_profit\n            )\n        \n        # Update the Source of Truth\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n            UPDATE audit_log\n            SET status = ?, official_payout = ?, net_profit = ?\n            WHERE race_id = ?\n        \"\"\", (new_status, payout, net_profit, prediction['race_id']))\n        \n        conn.commit()\n        conn.close()\n    \n    async def _find_race_url(self, track_code: str, race_number: int) -> Optional[str]:\n        \"\"\"Finds the specific race URL from the main results page.\"\"\"\n        try:\n            base_url = \"https://www.attheraces.com\"\n            results_url = f\"{base_url}/results\"\n            \n            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n            response = await self.http_client.get(results_url, headers=headers)\n            response.raise_for_status()\n            \n            soup = BeautifulSoup(response.text, 'lxml')\n            track_name = self.TRACK_CODE_MAP.get(track_code.upper())\n            if not track_name:\n                logger.warning(\"Track code not mapped\", track_code=track_code)\n                return None\n\n            # Use a case-insensitive regex to make the search more robust\n            track_header = soup.find('h2', string=re.compile(track_name, re.IGNORECASE))\n            if not track_header:\n                logger.debug(\"Track not found on results page\", track_name=track_name)\n                return None\n\n            # Find the parent container of the track's results\n            track_container = track_header.find_parent(class_='panel')\n            if not track_container:\n                logger.debug(\"Could not find track container\", track_name=track_name)\n                return None\n\n            # Get all race links for that track and select by index\n            race_links = track_container.select('a[href*=\"/racecard/\"]')\n            if len(race_links) >= race_number:\n                race_path = race_links[race_number - 1]['href']\n                return f\"{base_url}{race_path}\"\n            else:\n                logger.debug(\"Race number out of bounds for track\", race_number=race_number, track_name=track_name)\n                return None\n        \n        except Exception as e:\n            logger.error(\"Error finding race URL\", error=str(e), exc_info=True)\n            return None\n\n    async def _fetch_official_result(\n        self,\n        track_code: str,\n        race_number: int\n    ) -> Optional[OfficialResult]:\n        \"\"\"\n        Helper: Scraper Logic for attheraces.com\n        \"\"\"\n        try:\n            race_url = await self._find_race_url(track_code, race_number)\n            if not race_url:\n                return None\n            \n            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n            response = await self.http_client.get(race_url, headers=headers)\n            \n            if response.status_code == 404:\n                logger.debug(\"Results page not found (404)\", url=race_url)\n                return None\n            \n            response.raise_for_status()\n\n            soup = BeautifulSoup(response.text, 'lxml')\n            race_result = self._parse_attheraces_results(soup, track_code, race_number)\n            \n            if race_result:\n                logger.info(\"Official results fetched\", track=track_code, race=race_number)\n                return race_result\n            else:\n                logger.debug(\"Results not yet posted or parsed\", track=track_code, race=race_number)\n                return None\n                \n        except httpx.HTTPError as e:\n            logger.warning(\"Failed to fetch results page\", url=getattr(e.request, 'url', ''), error=str(e))\n            return None\n        except Exception as e:\n            logger.error(\"Error parsing results\", track=track_code, race=race_number, error=str(e), exc_info=True)\n            return None\n\n    def _parse_attheraces_results(\n        self,\n        soup: BeautifulSoup,\n        track_code: str,\n        race_number: int\n    ) -> Optional[OfficialResult]:\n        \"\"\"\n        Parse attheraces.com HTML to extract race results using a table-based approach.\n        \"\"\"\n        results_table = None\n        all_tables = soup.find_all('table')\n        for table in all_tables:\n            header_cells = table.select('thead th')\n            if any(\"Horse\" in cell.text for cell in header_cells):\n                results_table = table\n                break\n\n        if not results_table:\n            logger.debug(\"Could not find a suitable results table on the page.\")\n            return None\n\n        finishers = []\n        rows = results_table.select('tbody tr')\n        \n        for row in rows:\n            cells = row.find_all('td')\n            if len(cells) < 3:\n                continue\n            \n            try:\n                pos_text = cells[0].text.strip()\n                try:\n                    position = int(pos_text)\n                except ValueError:\n                    position = 99\n                \n                horse_name_el = cells[2].select_one('a[href*=\"/form/horse/\"]')\n                if not horse_name_el:\n                    continue\n                \n                horse_name = horse_name_el.text.strip()\n                \n                finisher = {\n                    'name': horse_name,\n                    'position': position,\n                    'place_payout': 0.0,\n                }\n                finishers.append(finisher)\n\n            except (ValueError, IndexError) as e:\n                logger.warning(\"Could not parse a result row\", error=str(e))\n                continue\n        \n        if not finishers:\n            logger.debug(\"Table found, but could not parse any finishers.\")\n            return None\n\n        win_payout = 0.0\n        try:\n            betting_returns_header = soup.find('h3', string=re.compile(r'Betting returns'))\n            if betting_returns_header:\n                betting_returns_table = betting_returns_header.find_next('table')\n                if betting_returns_table:\n                    win_row = betting_returns_table.find('td', string=re.compile(r'Win'))\n                    if win_row:\n                        payout_str = win_row.find_next_sibling('td').text\n                        payout_match = re.search(r'[\\d\\.]+', payout_str)\n                        if payout_match:\n                            win_payout = float(payout_match.group(0))\n        except Exception as e:\n            logger.warning(\"Could not parse win payout\", error=str(e))\n\n        for f in finishers:\n            if f['position'] == 1:\n                f['place_payout'] = win_payout\n                break\n\n        race_id = self._generate_race_id(track_code, datetime.now().strftime(\"%Y%m%d\"), race_number)\n        return OfficialResult(race_id=race_id, finishers=finishers)\n    \n    def _generate_race_id(self, venue_code: str, race_date: str, race_number: int) -> str:\n        \"\"\"Generate unique race ID\"\"\"\n        return f\"{venue_code.upper()}-{race_date}-{race_number:02d}\"\n    \n    def get_rolling_metrics(self, minutes: int = 60) -> Dict[str, Any]:\n        \"\"\"\n        Phase 4: Dashboard Metrics\n        Returns stats for the UI \"Last Hour\" overlay.\n        \n        Args:\n            minutes: Rolling window in minutes (default 60)\n            \n        Returns:\n            Dictionary with strike_rate, net_profit, and volume\n        \"\"\"\n        cutoff = datetime.now() - timedelta(minutes=minutes)\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n            SELECT \n                COUNT(*) as total,\n                SUM(CASE WHEN status = 'CASHED' THEN 1 ELSE 0 END) as wins,\n                SUM(net_profit) as profit\n            FROM audit_log\n            WHERE timestamp > ? AND status != 'PENDING'\n        \"\"\", (cutoff,))\n        \n        row = cursor.fetchone()\n        conn.close()\n        \n        total = row[0] or 0\n        wins = row[1] or 0\n        profit = row[2] or 0.0\n        \n        strike_rate = (wins / total * 100) if total > 0 else 0.0\n        \n        return {\n            \"strike_rate\": round(strike_rate, 2),\n            \"net_profit\": round(profit, 2),\n            \"volume\": total,\n            \"window_minutes\": minutes\n        }\n    \n    def get_recent_activity(self, limit: int = 10) -> List[Dict]:\n        \"\"\"Get recent audit activity for display\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n            SELECT * FROM audit_log\n            ORDER BY timestamp DESC\n            LIMIT ?\n        \"\"\", (limit,))\n        \n        activity = [dict(row) for row in cursor.fetchall()]\n        conn.close()\n        \n        return activity\n    \n    async def cleanup(self):\n        \"\"\"Cleanup resources\"\"\"\n        self.stop_audit_loop()\n        await self.http_client.aclose()\n        logger.info(\"Auditor engine cleaned up\")\n\n\nasync def smoke_test_auditor():\n    \"\"\"A simple test to verify the new scraper logic.\"\"\"\n    logger.info(\"Starting Auditor smoke test...\")\n    auditor = AuditorEngine(db_path=\"smoke_test_audit.db\")\n\n    # We need a race that has results. Let's assume Doncaster, Race 1.\n    track_code = \"DON\"\n    race_number = 1\n    \n    logger.info(f\"Attempting to fetch results for {track_code} Race {race_number}\")\n    \n    # Directly call the fetcher\n    official_result = await auditor._fetch_official_result(track_code, race_number)\n    \n    if official_result and official_result.finishers:\n        logger.info(\"Smoke test PASSED. Successfully fetched and parsed results.\")\n        print(\"\\n--- SMOKE TEST RESULTS ---\")\n        print(f\"Race ID: {official_result.race_id}\")\n        print(\"Finishers:\")\n        for finisher in official_result.finishers:\n            print(f\"  Position: {finisher['position']}, Name: {finisher['name']}, Payout: {finisher['place_payout']}\")\n        print(\"------------------------\\n\")\n    else:\n        logger.error(\"Smoke test FAILED. Could not fetch or parse results.\")\n        print(\"\\n--- SMOKE TEST FAILED ---\")\n        print(\"No results were returned. Check the logs for errors.\")\n        print(\"-----------------------\\n\")\n\n    await auditor.cleanup()\n    # Clean up the test database\n    import os\n    if os.path.exists(\"smoke_test_audit.db\"):\n        os.remove(\"smoke_test_audit.db\")\n\nif __name__ == \"__main__\":\n    # To run the smoke test: python -m python_service.auditor\n    structlog.configure(\n        processors=[\n            structlog.processors.add_log_level,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.dev.ConsoleRenderer(),\n        ]\n    )\n    asyncio.run(smoke_test_auditor())\n",
    "python_service/config.py": "# python_service/config.py\nimport os\nimport sys\nfrom functools import lru_cache\nfrom pathlib import Path\nfrom typing import List\nfrom typing import Optional\n\nimport structlog\nfrom pydantic import Field\nfrom pydantic import model_validator\nfrom pydantic_settings import BaseSettings\n\nfrom .credentials_manager import SecureCredentialsManager\n\n# --- Encryption Setup ---\ntry:\n    from cryptography.fernet import Fernet\n\n    ENCRYPTION_ENABLED = True\nexcept ImportError:\n    ENCRYPTION_ENABLED = False\n\nKEY_FILE = Path(\".key\")\nCIPHER = None\nif ENCRYPTION_ENABLED and KEY_FILE.exists():\n    with open(KEY_FILE, \"rb\") as f:\n        key = f.read()\n    CIPHER = Fernet(key)\n\n\ndef decrypt_value(value: Optional[str]) -> str:\n    \"\"\"If a value is encrypted, decrypts it. Otherwise, returns it as is.\"\"\"\n    if value and value.startswith(\"encrypted:\") and CIPHER:\n        try:\n            return CIPHER.decrypt(value[10:].encode()).decode()\n        except Exception:\n            structlog.get_logger(__name__).error(\"Decryption failed on field.\")\n            return \"\"  # Fallback to an empty string on failure\n    return value or \"\"  # Ensure a non-None return value even if input is None\n\n\nclass Settings(BaseSettings):\n    API_KEY: str = Field(\"\")\n\n    # --- API Gateway Configuration ---\n    UVICORN_HOST: str = \"127.0.0.1\"\n    FORTUNA_PORT: int = 8000\n    UVICORN_RELOAD: bool = True\n\n    # --- Database Configuration ---\n    DATABASE_TYPE: str = \"sqlite\"\n    DATABASE_URL: str = \"sqlite:///./fortuna.db\"\n\n    # --- Optional Betfair Credentials ---\n    BETFAIR_APP_KEY: Optional[str] = None\n\n    # --- Caching & Performance ---\n    REDIS_URL: str = \"redis://localhost:6379\"\n    CACHE_TTL_SECONDS: int = 1800  # 30 minutes\n    MAX_CONCURRENT_REQUESTS: int = 10\n    HTTP_POOL_CONNECTIONS: int = 100\n    HTTP_POOL_MAXSIZE: int = 100\n    HTTP_MAX_KEEPALIVE: int = 50\n    DEFAULT_TIMEOUT: int = 30\n    ADAPTER_TIMEOUT: int = 20\n\n    # --- Logging ---\n    LOG_LEVEL: str = \"INFO\"\n\n    # --- Optional Adapter Keys ---\n    NEXT_PUBLIC_API_KEY: Optional[str] = None  # Allow frontend key to be present in .env\n    TVG_API_KEY: Optional[str] = None\n    RACING_AND_SPORTS_TOKEN: Optional[str] = None\n    POINTSBET_API_KEY: Optional[str] = None\n    GREYHOUND_API_URL: Optional[str] = None\n    THE_RACING_API_KEY: Optional[str] = None\n\n    # --- CORS Configuration ---\n    ALLOWED_ORIGINS: List[str] = [\"http://localhost:3000\", \"http://localhost:3001\"]\n\n    # --- Dynamic Path Configuration ---\n    # This determines the path to static files, crucial for PyInstaller builds\n    STATIC_FILES_DIR: Optional[str] = None\n\n    model_config = {\"env_file\": \".env\", \"case_sensitive\": True}\n\n    @model_validator(mode=\"after\")\n    def process_settings(self) -> \"Settings\":\n        \"\"\"\n        This validator runs after the initial settings are loaded from .env and\n        performs two key functions:\n        1. If API_KEY is missing, it falls back to the SecureCredentialsManager.\n        2. It decrypts any fields that were loaded from the .env file.\n        \"\"\"\n        # 1. Fallback for API_KEY\n        if not self.API_KEY:\n            self.API_KEY = SecureCredentialsManager.get_credential(\"api_key\") or \"MISSING\"\n\n        # 2. Security validation for API_KEY\n        insecure_keys = {\"test\", \"changeme\", \"default\", \"secret\", \"password\", \"admin\"}\n        if self.API_KEY in insecure_keys:\n            structlog.get_logger(__name__).warning(\n                \"insecure_api_key\",\n                key=self.API_KEY,\n                recommendation=\"The API_KEY should be a long, random string for security.\",\n            )\n\n        # 2. Decrypt sensitive fields\n        self.BETFAIR_APP_KEY = decrypt_value(self.BETFAIR_APP_KEY)\n\n        # 3. Set the static files directory for packaged apps\n        if getattr(sys, \"frozen\", False):\n            # Running in a PyInstaller bundle\n            self.STATIC_FILES_DIR = os.path.join(sys._MEIPASS, \"ui\")\n        else:\n            # Running in a normal Python environment\n            self.STATIC_FILES_DIR = None  # Not needed for local dev\n\n        return self\n\n\n@lru_cache()\ndef get_settings() -> Settings:\n    \"\"\"Loads settings and performs a proactive check for legacy paths.\"\"\"\n    log = structlog.get_logger(__name__)\n    if ENCRYPTION_ENABLED and not KEY_FILE.exists():\n        log.warning(\n            \"encryption_key_not_found\",\n            file=str(KEY_FILE),\n            recommendation=\"Run 'python manage_secrets.py' to generate a key.\",\n        )\n\n    settings = Settings()\n\n    # --- Legacy Path Detection ---\n    legacy_paths = [\"attic/\", \"checkmate_web/\", \"vba_source/\"]\n    for path in legacy_paths:\n        if os.path.exists(path):\n            log.warning(\n                \"legacy_path_detected\",\n                path=path,\n                recommendation=\"This directory is obsolete and should be removed for optimal performance and security.\",\n            )\n\n    return settings\n",
    "python_service/core/exceptions.py": "# python_service/core/exceptions.py\n\"\"\"\nCustom, application-specific exceptions for the Fortuna Faucet service.\n\nThis module defines a hierarchy of exception classes to provide standardized\nerror handling, particularly for the data adapter layer. Using these specific\nexceptions instead of generic ones allows for more precise error handling and\nclearer logging throughout the application.\n\"\"\"\n\n\nclass FortunaException(Exception):\n    \"\"\"Base class for all custom exceptions in this application.\"\"\"\n\n    pass\n\n\nclass AdapterError(FortunaException):\n    \"\"\"Base class for all adapter-related errors.\"\"\"\n\n    def __init__(self, adapter_name: str, message: str):\n        self.adapter_name = adapter_name\n        super().__init__(f\"[{adapter_name}] {message}\")\n\n\nclass AdapterRequestError(AdapterError):\n    \"\"\"Raised for general network or request-related issues.\"\"\"\n\n    pass\n\n\nclass AdapterHttpError(AdapterRequestError):\n    \"\"\"Raised for unsuccessful HTTP responses (e.g., 4xx or 5xx status codes).\"\"\"\n\n    def __init__(self, adapter_name: str, status_code: int, url: str):\n        self.status_code = status_code\n        self.url = url\n        message = f\"Received HTTP {status_code} from {url}\"\n        super().__init__(adapter_name, message)\n\n\nclass AdapterAuthError(AdapterHttpError):\n    \"\"\"Raised specifically for HTTP 401/403 errors, indicating an auth failure.\"\"\"\n\n    pass\n\n\nclass AdapterRateLimitError(AdapterHttpError):\n    \"\"\"Raised specifically for HTTP 429 errors, indicating a rate limit has been hit.\"\"\"\n\n    pass\n\n\nclass AdapterTimeoutError(AdapterRequestError):\n    \"\"\"Raised when a request to an external API times out.\"\"\"\n\n    pass\n\n\nclass AdapterConnectionError(AdapterRequestError):\n    \"\"\"Raised for DNS lookup failures or refused connections.\"\"\"\n\n    pass\n\n\nclass AdapterConfigError(AdapterError):\n    \"\"\"Raised when an adapter is missing necessary configuration (e.g., an API key).\"\"\"\n\n    pass\n\n\nclass AdapterParsingError(AdapterError):\n    \"\"\"Raised when an adapter fails to parse the response from an API.\"\"\"\n\n    pass\n",
    "python_service/engine.py": "# python_service/engine.py\n\nimport asyncio\nimport json\nfrom copy import deepcopy\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Tuple\n\nimport httpx\nimport redis\nimport redis.asyncio as redis_async\nimport structlog\nfrom pydantic import ValidationError\n\nfrom .adapters.at_the_races_adapter import AtTheRacesAdapter\nfrom .adapters.base_adapter_v3 import BaseAdapterV3\nfrom .adapters.betfair_adapter import BetfairAdapter\n\n# from .adapters.betfair_datascientist_adapter import BetfairDataScientistAdapter\nfrom .adapters.betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .adapters.brisnet_adapter import BrisnetAdapter\nfrom .adapters.equibase_adapter import EquibaseAdapter\nfrom .adapters.fanduel_adapter import FanDuelAdapter\nfrom .adapters.gbgb_api_adapter import GbgbApiAdapter\nfrom .adapters.greyhound_adapter import GreyhoundAdapter\nfrom .adapters.harness_adapter import HarnessAdapter\nfrom .adapters.horseracingnation_adapter import HorseRacingNationAdapter\nfrom .adapters.nyrabets_adapter import NYRABetsAdapter\nfrom .adapters.oddschecker_adapter import OddscheckerAdapter\nfrom .adapters.pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .adapters.punters_adapter import PuntersAdapter\nfrom .adapters.racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .adapters.racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .adapters.racingpost_adapter import RacingPostAdapter\nfrom .adapters.racingtv_adapter import RacingTVAdapter\nfrom .adapters.sporting_life_adapter import SportingLifeAdapter\nfrom .adapters.tab_adapter import TabAdapter\nfrom .adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom .adapters.timeform_adapter import TimeformAdapter\nfrom .adapters.tvg_adapter import TVGAdapter\nfrom .adapters.twinspires_adapter import TwinSpiresAdapter\nfrom .adapters.xpressbet_adapter import XpressbetAdapter\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .manual_override_manager import ManualOverrideManager\nfrom .models import AggregatedResponse\nfrom .models import Race\n\nlog = structlog.get_logger(__name__)\n\n\nclass OddsEngine:\n    def __init__(\n        self,\n        config=None,\n        manual_override_manager: ManualOverrideManager = None,\n        connection_manager=None,\n    ):\n        # THE FIX: Import the cache_manager singleton here to ensure tests can\n        # patch and reload it *before* the engine is initialized.\n        from .cache_manager import cache_manager\n\n        self.logger = structlog.get_logger(__name__)\n        self.logger.info(\"Initializing FortunaEngine...\")\n        self.connection_manager = connection_manager\n        self.cache_manager = cache_manager\n\n        try:\n            try:\n                self.config = config or get_settings()\n                self.logger.info(\"Configuration loaded.\")\n            except ValidationError as e:\n                self.logger.warning(\n                    \"Could not load settings, possibly in test environment.\",\n                    error=str(e),\n                )\n                # Create a default/mock config or re-raise if not in a test context\n                from .config import Settings\n\n                self.config = Settings(API_KEY=\"a_secure_test_api_key_that_is_long_enough\")\n\n            # Redis is now handled entirely by the CacheManager.\n\n            self.logger.info(\"Initializing adapters...\")\n            self.adapters: List[BaseAdapterV3] = []\n            adapter_classes = [\n                AtTheRacesAdapter,\n                BetfairAdapter,\n                BetfairGreyhoundAdapter,\n                BrisnetAdapter,\n                EquibaseAdapter,\n                FanDuelAdapter,\n                GbgbApiAdapter,\n                GreyhoundAdapter,\n                HarnessAdapter,\n                HorseRacingNationAdapter,\n                NYRABetsAdapter,\n                OddscheckerAdapter,\n                PuntersAdapter,\n                RacingAndSportsAdapter,\n                RacingAndSportsGreyhoundAdapter,\n                RacingPostAdapter,\n                RacingTVAdapter,\n                SportingLifeAdapter,\n                TabAdapter,\n                TheRacingApiAdapter,\n                TimeformAdapter,\n                TwinSpiresAdapter,\n                TVGAdapter,\n                XpressbetAdapter,\n                PointsBetGreyhoundAdapter,\n            ]\n\n            for adapter_cls in adapter_classes:\n                try:\n                    self.logger.info(f\"Attempting to initialize adapter: {adapter_cls.__name__}\")\n                    adapter_instance = adapter_cls(config=self.config)\n                    self.logger.info(f\"Successfully initialized adapter: {adapter_cls.__name__}\")\n                    if manual_override_manager and getattr(adapter_instance, \"supports_manual_override\", False):\n                        adapter_instance.enable_manual_override(manual_override_manager)\n                    self.adapters.append(adapter_instance)\n                except AdapterConfigError as e:\n                    self.logger.warning(\n                        \"Skipping adapter due to configuration error\",\n                        adapter=adapter_cls.__name__,\n                        error=str(e),\n                    )\n                except Exception:\n                    self.logger.error(\n                        f\"An unexpected error occurred while initializing {adapter_cls.__name__}\",\n                        exc_info=True,\n                    )\n\n            # Special case for BetfairDataScientistAdapter with extra args - DISABLED\n            # try:\n            #     bds_adapter = BetfairDataScientistAdapter(\n            #         model_name=\"ThoroughbredModel\",\n            #         url=\"https://betfair-data-supplier-prod.herokuapp.com/api/widgets/kvs-ratings/datasets\",\n            #         config=self.config,\n            #     )\n            #     if manual_override_manager and getattr(bds_adapter, \"supports_manual_override\", False):\n            #         bds_adapter.enable_manual_override(manual_override_manager)\n            #     self.adapters.append(bds_adapter)\n            # except Exception:\n            #     self.logger.warning(\n            #         \"Failed to initialize adapter: BetfairDataScientistAdapter\",\n            #         exc_info=True,\n            #     )\n\n            self.logger.info(f\"{len(self.adapters)} adapters initialized successfully.\")\n\n            self.logger.info(\"Initializing HTTP client...\")\n            self.http_limits = httpx.Limits(\n                max_connections=self.config.HTTP_POOL_CONNECTIONS,\n                max_keepalive_connections=self.config.HTTP_MAX_KEEPALIVE,\n            )\n            self.http_client = httpx.AsyncClient(limits=self.http_limits, http2=True)\n            self.logger.info(\"HTTP client initialized.\")\n\n            # Assign the shared client to each adapter\n            for adapter in self.adapters:\n                adapter.http_client = self.http_client\n\n            # Initialize semaphore for concurrency limiting\n            self.semaphore = asyncio.Semaphore(self.config.MAX_CONCURRENT_REQUESTS)\n            self.logger.info(\n                \"Concurrency semaphore initialized\",\n                limit=self.config.MAX_CONCURRENT_REQUESTS,\n            )\n\n            self.logger.info(\"FortunaEngine initialization complete.\")\n\n        except Exception:\n            self.logger.critical(\"CRITICAL FAILURE during FortunaEngine initialization.\", exc_info=True)\n            raise\n\n    async def close(self):\n        await self.http_client.aclose()\n\n    def get_all_adapter_statuses(self) -> List[Dict[str, Any]]:\n        return [adapter.get_status() for adapter in self.adapters]\n\n    async def get_from_cache(self, key):\n        return await self.cache_manager.get(key)\n\n    async def set_in_cache(self, key, value, ttl=300):\n        # THE FIX: The keyword argument is 'ttl_seconds', not 'ttl'.\n        await self.cache_manager.set(key, value, ttl_seconds=ttl)\n\n    async def _fetch_with_semaphore(self, adapter: BaseAdapterV3, date: str):\n        \"\"\"Acquires the semaphore before fetching data from an adapter.\"\"\"\n        async with self.semaphore:\n            return await self._time_adapter_fetch(adapter, date)\n\n    async def _time_adapter_fetch(self, adapter: BaseAdapterV3, date: str) -> Tuple[str, Dict[str, Any], float]:\n        \"\"\"\n        Wraps a V3 adapter's fetch call for safe, non-blocking execution,\n        and returns a consistent payload with timing information.\n        \"\"\"\n        start_time = datetime.now()\n        races: List[Race] = []\n        error_message = None\n        is_success = False\n        attempted_url = None\n\n        try:\n            race_data_list = await adapter.get_races(date)\n            races = [Race(**race_data) for race_data in race_data_list]\n            is_success = True\n        except AdapterHttpError as e:\n            self.logger.error(\n                \"HTTP failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                status_code=e.status_code,\n                url=e.url,\n                exc_info=False,\n            )\n            error_message = f\"HTTP Error {e.status_code} for {e.url}\"\n            attempted_url = e.url\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n        except Exception as e:\n            self.logger.error(\n                \"Critical failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                error=str(e),\n                exc_info=True,\n            )\n            error_message = str(e)\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n\n        duration = (datetime.now() - start_time).total_seconds()\n\n        payload = {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": adapter.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": duration,\n                \"attempted_url\": attempted_url,\n            },\n        }\n        return (adapter.source_name, payload, duration)\n\n    def _race_key(self, race: Race) -> str:\n        return f\"{race.venue.lower().strip()}|{race.race_number}|{race.start_time.strftime('%H:%M')}\"\n\n    def _dedupe_races(self, races: List[Race]) -> List[Race]:\n        \"\"\"Deduplicates races and reconciles odds from different sources.\"\"\"\n        race_map: Dict[str, Race] = {}\n        for race in races:\n            key = self._race_key(race)\n            if key not in race_map:\n                race_map[key] = race\n            else:\n                existing_race = race_map[key]\n                runner_map = {r.number: r for r in existing_race.runners}\n                for new_runner in race.runners:\n                    if new_runner.number in runner_map:\n                        existing_runner = runner_map[new_runner.number]\n                        existing_runner.odds.update(new_runner.odds)\n                    else:\n                        existing_race.runners.append(new_runner)\n\n                # Ensure the source is a list and append new source if not present\n                if not isinstance(existing_race.source, list):\n                    existing_race.source = [existing_race.source]\n                if race.source not in existing_race.source:\n                    existing_race.source.append(race.source)\n\n        return list(race_map.values())\n\n    async def _broadcast_update(self, data: Dict[str, Any]):\n        \"\"\"Helper to broadcast data if the connection manager is available.\"\"\"\n        if self.connection_manager:\n            await self.connection_manager.broadcast(data)\n\n    async def fetch_all_odds(self, date: str, source_filter: str = None) -> Dict[str, Any]:\n        \"\"\"\n        Fetches and aggregates race data from all configured adapters.\n        The result of this method is cached and broadcasted via WebSocket.\n        \"\"\"\n        # Construct a cache key\n        cache_key = f\"fortuna_engine_races:{date}:{source_filter or 'all'}\"\n        cached_data = await self.get_from_cache(cache_key)\n        if cached_data:\n            log.info(\"Cache hit for fetch_all_odds\", key=cache_key)\n            return json.loads(cached_data)\n\n        log.info(\"Cache miss for fetch_all_odds\", key=cache_key)\n        target_adapters = self.adapters\n        if source_filter:\n            log.info(\"Applying source filter\", source=source_filter)\n            target_adapters = [a for a in self.adapters if a.source_name.lower() == source_filter.lower()]\n\n        tasks = [self._fetch_with_semaphore(adapter, date) for adapter in target_adapters]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        source_infos = []\n        all_races = []\n        errors = []\n\n        for i, result in enumerate(results):\n            adapter = target_adapters[i]\n            if isinstance(result, Exception):\n                log.error(\"Adapter fetch task failed with an unhandled exception\", adapter=adapter.source_name, error=result)\n                errors.append({\n                    \"adapter_name\": adapter.source_name,\n                    \"error_message\": f\"Unhandled exception: {str(result)}\",\n                    \"attempted_url\": \"Unknown\"\n                })\n                source_infos.append({\n                    \"name\": adapter.source_name,\n                    \"status\": \"FAILED\",\n                    \"error_message\": f\"Unhandled exception: {str(result)}\",\n                })\n            else:\n                _adapter_name, adapter_result, _duration = result\n                source_info = adapter_result.get(\"source_info\", {})\n                source_infos.append(source_info)\n                if source_info.get(\"status\") == \"SUCCESS\":\n                    all_races.extend(adapter_result.get(\"races\", []))\n                else:\n                    errors.append({\n                        \"adapter_name\": adapter.source_name,\n                        \"error_message\": source_info.get(\"error_message\", \"Unknown error\"),\n                        \"attempted_url\": source_info.get(\"attempted_url\")\n                    })\n\n        deduped_races = self._dedupe_races(all_races)\n\n        response_obj = AggregatedResponse(\n            date=datetime.strptime(date, \"%Y-%m-%d\").date(),\n            races=deduped_races,\n            errors=errors,\n            source_info=source_infos,\n            metadata={\n                \"fetch_time\": datetime.now(),\n                \"sources_queried\": [a.source_name for a in target_adapters],\n                \"sources_successful\": len([s for s in source_infos if s[\"status\"] == \"SUCCESS\"]),\n                \"total_races\": len(deduped_races),\n                \"total_errors\": len(errors),\n            },\n        )\n\n        response_data = response_obj.model_dump(by_alias=True)\n\n        # Set the result in the cache\n        await self.set_in_cache(cache_key, json.dumps(response_data, default=str), ttl=300)\n        await self._broadcast_update(response_data)\n        return response_data\n",
    "python_service/etl.py": "# python_service/etl.py\n# ETL pipeline for populating the historical data warehouse\n\nimport json\nimport logging\nimport os\nfrom datetime import date\n\nimport requests\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import text\nfrom sqlalchemy.exc import SQLAlchemyError\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass ScribesArchivesETL:\n    def __init__(self):\n        self.postgres_url = os.getenv(\"POSTGRES_URL\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.api_base_url = \"http://localhost:8000\"\n        self.engine = self._get_db_engine()\n\n    def _get_db_engine(self):\n        if not self.postgres_url:\n            logger.warning(\"POSTGRES_URL not set. ETL will be skipped.\")\n            return None\n        try:\n            return create_engine(self.postgres_url)\n        except Exception as e:\n            logger.error(f\"Failed to create database engine: {e}\", exc_info=True)\n            return None\n\n    def _fetch_race_data(self, target_date: date) -> list:\n        \"\"\"Fetches aggregated race data from the local API.\"\"\"\n        if not self.api_key:\n            raise ValueError(\"API_KEY not found in environment.\")\n\n        url = f\"{self.api_base_url}/api/races?race_date={target_date.isoformat()}\"\n        headers = {\"X-API-KEY\": self.api_key}\n        response = requests.get(url, headers=headers, timeout=120)\n        response.raise_for_status()\n        return response.json().get(\"races\", [])\n\n    def _validate_and_transform(self, race: dict) -> tuple:\n        \"\"\"Validates a race dictionary and transforms it for insertion.\"\"\"\n        if not all(k in race for k in [\"id\", \"venue\", \"race_number\", \"start_time\", \"runners\"]):\n            return (\n                None,\n                \"Missing core fields (id, venue, race_number, start_time, runners)\",\n            )\n\n        active_runners = [r for r in race.get(\"runners\", []) if not r.get(\"scratched\")]\n\n        transformed = {\n            \"race_id\": race[\"id\"],\n            \"venue\": race[\"venue\"],\n            \"race_number\": race[\"race_number\"],\n            \"start_time\": race[\"start_time\"],\n            \"source\": race.get(\"source\"),\n            \"qualification_score\": race.get(\"qualification_score\"),\n            \"field_size\": len(active_runners),\n        }\n        return transformed, None\n\n    def run(self, target_date: date):\n        if not self.engine:\n            return\n\n        logger.info(f\"Starting ETL process for {target_date.isoformat()}...\")\n        try:\n            races = self._fetch_race_data(target_date)\n        except (requests.RequestException, ValueError) as e:\n            logger.error(f\"Failed to fetch race data: {e}\", exc_info=True)\n            return\n\n        clean_records = []\n        quarantined_records = []\n\n        for race in races:\n            transformed, reason = self._validate_and_transform(race)\n            if transformed:\n                clean_records.append(transformed)\n            else:\n                quarantined_records.append(\n                    {\n                        \"race_id\": race.get(\"id\"),\n                        \"source\": race.get(\"source\"),\n                        \"payload\": json.dumps(race),\n                        \"reason\": reason,\n                    }\n                )\n\n        with self.engine.connect() as connection:\n            try:\n                with connection.begin():  # Transaction block\n                    if clean_records:\n                        # Using ON CONFLICT to prevent duplicates\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO historical_races (\n                                race_id, venue, race_number, start_time, source,\n                                qualification_score, field_size\n                            )\n                            VALUES (\n                                :race_id, :venue, :race_number, :start_time, :source,\n                                :qualification_score, :field_size\n                            )\n                            ON CONFLICT (race_id) DO NOTHING;\n                        \"\"\"\n                        )\n                        connection.execute(stmt, clean_records)\n                        logger.info(f\"Inserted/updated {len(clean_records)} records into historical_races.\")\n\n                    if quarantined_records:\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO quarantined_races (race_id, source, payload, reason)\n                            VALUES (:race_id, :source, :payload::jsonb, :reason);\n                        \"\"\"\n                        )\n                        connection.execute(stmt, quarantined_records)\n                        logger.warning(f\"Moved {len(quarantined_records)} records to quarantine.\")\n            except SQLAlchemyError as e:\n                logger.error(f\"Database transaction failed: {e}\", exc_info=True)\n\n        logger.info(\"ETL process finished.\")\n\n\ndef run_etl_for_yesterday():\n    from datetime import timedelta\n\n    yesterday = date.today() - timedelta(days=1)\n    etl = ScribesArchivesETL()\n    etl.run(yesterday)\n",
    "python_service/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "python_service/health.py": "# python_service/health.py\nfrom datetime import datetime\nfrom typing import Dict\nfrom typing import List\n\nimport psutil\nimport structlog\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\nlog = structlog.get_logger(__name__)\n\n\nclass HealthMonitor:\n    def __init__(self):\n        self.adapter_health: Dict[str, Dict] = {}\n        self.system_metrics: List[Dict] = []\n        self.max_metrics_history = 100\n\n    def record_adapter_response(self, adapter_name: str, success: bool, duration: float):\n        if adapter_name not in self.adapter_health:\n            self.adapter_health[adapter_name] = {\n                \"total_requests\": 0,\n                \"successful_requests\": 0,\n                \"failed_requests\": 0,\n                \"avg_response_time\": 0.0,\n                \"last_success\": None,\n                \"last_failure\": None,\n            }\n\n        health = self.adapter_health[adapter_name]\n        health[\"total_requests\"] += 1\n\n        if success:\n            health[\"successful_requests\"] += 1\n            health[\"last_success\"] = datetime.now().isoformat()\n        else:\n            health[\"failed_requests\"] += 1\n            health[\"last_failure\"] = datetime.now().isoformat()\n\n        health[\"avg_response_time\"] = (\n            health[\"avg_response_time\"] * (health[\"total_requests\"] - 1) + duration\n        ) / health[\"total_requests\"]\n\n    def get_system_metrics(self) -> Dict:\n        cpu_percent = psutil.cpu_percent(interval=1)\n        memory = psutil.virtual_memory()\n        disk = psutil.disk_usage(\"/\")\n\n        metrics = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"cpu_percent\": cpu_percent,\n            \"memory_percent\": memory.percent,\n            \"memory_available_gb\": round(memory.available / (1024**3), 2),\n            \"disk_percent\": disk.percent,\n            \"disk_free_gb\": round(disk.free / (1024**3), 2),\n        }\n\n        self.system_metrics.append(metrics)\n        if len(self.system_metrics) > self.max_metrics_history:\n            self.system_metrics.pop(0)\n\n        return metrics\n\n    def get_health_report(self) -> Dict:\n        system_metrics = self.get_system_metrics()\n        return {\n            \"status\": \"healthy\" if self.is_system_healthy() else \"degraded\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"system\": system_metrics,\n            \"adapters\": self.adapter_health,\n            \"metrics_history\": self.system_metrics[-10:],\n        }\n\n    def is_system_healthy(self) -> bool:\n        if not self.system_metrics:\n            return True\n        latest = self.system_metrics[-1]\n        return latest[\"cpu_percent\"] < 80 and latest[\"memory_percent\"] < 85 and latest[\"disk_percent\"] < 90\n\n\n# Global instance for the application to use\nhealth_monitor = HealthMonitor()\n\n\n@router.get(\"/health/detailed\", tags=[\"Health\"])\nasync def get_detailed_health():\n    \"\"\"Provides a comprehensive health check of the system.\"\"\"\n    return health_monitor.get_health_report()\n\n\n@router.get(\"/health\", tags=[\"Health\"])\nasync def get_basic_health():\n    \"\"\"Provides a basic health check for load balancers and uptime monitoring.\"\"\"\n    return {\"status\": \"healthy\"}\n",
    "python_service/health_check.py": "import socket\nimport sys\n\n\ndef is_port_available(port=8000):\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex((\"127.0.0.1\", port))\n        sock.close()\n        return result != 0\n    except Exception:\n        return False\n\n\nif __name__ == \"__main__\":\n    if not is_port_available(8000):\n        print(\"ERROR: Port 8000 already in use. Kill existing process or use different port.\")\n        sys.exit(1)\n    print(\"Port 8000 available \u2713\")\n",
    "python_service/main.py": "import uvicorn\nimport sys\nimport os\nimport asyncio\nfrom multiprocessing import freeze_support\n\n# Force UTF-8 encoding for stdout and stderr, crucial for PyInstaller on Windows\nos.environ[\"PYTHONUTF8\"] = \"1\"\n\n# Import the 'app' object at the top level to make it accessible for import by other modules,\n# such as diagnostic scripts in CI/CD.\nfrom python_service.api import app, HTTPException\n\n# This is the definitive entry point for the Fortuna Faucet backend service.\n# It is designed to be compiled with PyInstaller.\n\n\ndef _configure_sys_path():\n    \"\"\"\n    Dynamically adds project paths to sys.path.\n    This is the robust solution to ensure that string-based imports like\n    \"web_service.backend.api:app\" work correctly when the application is\n    run from a PyInstaller executable. The `_MEIPASS` attribute is a temporary\n    directory created by PyInstaller at runtime.\n    \"\"\"\n    if getattr(sys, \"frozen\", False) and hasattr(sys, \"_MEIPASS\"):\n        # Running in a PyInstaller bundle. The project root is the _MEIPASS directory.\n        project_root = os.path.abspath(sys._MEIPASS)\n\n        # Aggressively add paths to resolve potential module lookup issues in frozen mode.\n        paths_to_add = [\n            project_root,\n            os.path.join(project_root, \"python_service\"),\n        ]\n\n        # Insert paths at the beginning of sys.path in reverse order\n        # to maintain the desired precedence.\n        for path in reversed(paths_to_add):\n            if path not in sys.path:\n                sys.path.insert(0, path)\n                print(f\"INFO: Added path to sys.path: {path}\")\n\n    else:\n        # Running as a normal script. The project root is one level up.\n        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n        if project_root not in sys.path:\n            sys.path.insert(0, project_root)\n            print(f\"INFO: Added project root to sys.path: {project_root}\")\n\n\ndef main():\n    \"\"\"\n    Primary entry point for the Fortuna Faucet backend application.\n    This function configures and runs the Uvicorn server.\n    It's crucial to launch the app this way to ensure PyInstaller's bootloader\n    can correctly resolve the package context.\n    \"\"\"\n    # CRITICAL: This must be called before any other application imports.\n    _configure_sys_path()\n\n    # When packaged, we need to ensure multiprocessing works correctly.\n    if getattr(sys, \"frozen\", False):\n        # CRITICAL for multiprocessing support in frozen mode on Windows.\n        freeze_support()\n\n    from python_service.config import get_settings\n    from fastapi.staticfiles import StaticFiles\n    from fastapi.responses import FileResponse\n    from python_service.port_check import check_port_and_exit_if_in_use\n\n    settings = get_settings()\n\n    # --- Port Sanity Check ---\n    # Before doing anything else, ensure the target port is not already in use.\n    # This prevents a common and confusing crash scenario on startup.\n    check_port_and_exit_if_in_use(settings.FORTUNA_PORT, settings.UVICORN_HOST)\n\n    # --- Conditional UI Serving for Web Service Mode ---\n    # Only serve the UI if the FORTUNA_MODE environment variable is set to 'webservice'.\n    # This prevents the Electron-packaged backend from trying to serve files it doesn't have.\n    if os.environ.get(\"FORTUNA_MODE\") == \"webservice\":\n        # Define the path to the static UI files, accommodating PyInstaller's bundle.\n        if getattr(sys, \"frozen\", False):\n            # In a bundled app, the UI files are in the '_MEIPASS/ui' directory.\n            STATIC_DIR = os.path.join(sys._MEIPASS, \"ui\")\n        else:\n            # In development, they are in the frontend's output directory.\n            STATIC_DIR = os.path.abspath(\n                os.path.join(os.path.dirname(__file__), \"..\", \"web_platform\", \"frontend\", \"out\")\n            )\n\n        # Mount the static assets directory for CSS, JS, etc.\n        if os.path.exists(os.path.join(STATIC_DIR, \"_next\")):\n            app.mount(\"/_next\", StaticFiles(directory=os.path.join(STATIC_DIR, \"_next\")), name=\"next\")\n\n        # Serve the main index.html for any non-API path.\n        @app.get(\"/{full_path:path}\", include_in_schema=False)\n        async def serve_frontend(full_path: str):\n            if full_path.startswith(\"api/\") or full_path.startswith(\"docs\") or full_path == \"health\":\n                # This is an API route, let FastAPI handle it.\n                # A 404 will be raised naturally if no route matches.\n                return\n\n            index_path = os.path.join(STATIC_DIR, \"index.html\")\n            if os.path.exists(index_path):\n                return FileResponse(index_path)\n            else:\n                # This will only be hit if the frontend files are missing entirely.\n                raise HTTPException(\n                    status_code=404,\n                    detail=\"Frontend not found. Please build the frontend and ensure it's in the correct location.\",\n                )\n\n    # CRITICAL FIX FOR PYINSTALLER on WINDOWS: Force event loop policy\n    # This resolves a silent network binding failure where Uvicorn reports startup\n    # but the OS never actually binds the port.\n    if sys.platform == \"win32\" and getattr(sys, 'frozen', False):\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n        print(\"[BOOT] Applied WindowsSelectorEventLoopPolicy for PyInstaller\", file=sys.stderr)\n\n    uvicorn.run(app, host=settings.UVICORN_HOST, port=settings.FORTUNA_PORT, log_level=\"info\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "python_service/tests/test_manual_override.py": "# python_service/tests/test_manual_override.py\nimport pytest\n\nfrom python_service.manual_override_manager import ManualOverrideManager\n\n\n@pytest.fixture\ndef manager():\n    # The manager is now in-memory and doesn't need a path\n    return ManualOverrideManager()\n\n\ndef test_register_and_retrieve(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n    content = \"<html>Manual content</html>\"\n    content_type = \"text/html\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    success = manager.submit_manual_data(\n        request_id=request_id,\n        raw_content=content,\n        content_type=content_type,\n    )\n\n    assert success\n\n    # Verify that the data can be retrieved correctly\n    retrieved_data = manager.get_manual_data(adapter_name=adapter, url=url)\n    assert retrieved_data is not None\n    retrieved_content, retrieved_type = retrieved_data\n    assert retrieved_content == content\n    assert retrieved_type == content_type\n\n    # Verify that data is consumed after retrieval\n    assert manager.get_manual_data(adapter_name=adapter, url=url) is None\n",
    "python_service/utils/odds.py": "# Centralized odds parsing utility, created by Operation: The A+ Trifecta\nfrom decimal import Decimal\nfrom decimal import InvalidOperation\nfrom typing import Optional\nfrom typing import Union\n\n\ndef parse_odds_to_decimal(odds: Union[str, int, float, None]) -> Optional[Decimal]:\n    \"\"\"\n    Parse various odds formats to Decimal for precise financial calculations.\n    Handles fractional, decimal, and special cases ('EVS', 'SP', etc.).\n    Returns None for unparseable or invalid values.\n    \"\"\"\n    if odds is None:\n        return None\n\n    if isinstance(odds, (int, float)):\n        return Decimal(str(odds))\n\n    odds_str = str(odds).strip().upper()\n\n    SPECIAL_CASES = {\n        \"EVS\": Decimal(\"2.0\"),\n        \"EVENS\": Decimal(\"2.0\"),\n        \"SP\": None,\n        \"SCRATCHED\": None,\n        \"SCR\": None,\n        \"\": None,\n    }\n\n    if odds_str in SPECIAL_CASES:\n        return SPECIAL_CASES[odds_str]\n\n    if \"/\" in odds_str:\n        try:\n            parts = odds_str.split(\"/\")\n            if len(parts) != 2:\n                return None\n            num, den = map(Decimal, parts)\n            if den <= 0:\n                return None\n            return Decimal(\"1.0\") + (num / den)\n        except (ValueError, InvalidOperation):\n            return None\n\n    try:\n        return Decimal(odds_str)\n    except (ValueError, InvalidOperation):\n        return None\n",
    "python_service/utils/text.py": "# python_service/utils/text.py\n# Centralized text and name normalization utilities\nimport re\nfrom typing import Optional\n\n\ndef clean_text(text: Optional[str]) -> Optional[str]:\n    \"\"\"Strips leading/trailing whitespace and collapses internal whitespace.\"\"\"\n    if not text:\n        return None\n    return \" \".join(text.strip().split())\n\n\ndef normalize_venue_name(name: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Normalizes a UK or Irish racecourse name to a standard format.\n    Handles common abbreviations and variations.\n    \"\"\"\n    if not name:\n        return None\n\n    # Use a temporary variable for matching, but return the properly cased name\n    cleaned_name_upper = clean_text(name).upper()\n\n    VENUE_MAP = {\n        \"ASCOT\": \"Ascot\",\n        \"AYR\": \"Ayr\",\n        \"BANGOR-ON-DEE\": \"Bangor-on-Dee\",\n        \"CATTERICK BRIDGE\": \"Catterick\",\n        \"CHELMSFORD CITY\": \"Chelmsford\",\n        \"EPSOM DOWNS\": \"Epsom\",\n        \"FONTWELL\": \"Fontwell Park\",\n        \"HAYDOCK\": \"Haydock Park\",\n        \"KEMPTON\": \"Kempton Park\",\n        \"LINGFIELD\": \"Lingfield Park\",\n        \"NEWMARKET (ROWLEY)\": \"Newmarket\",\n        \"NEWMARKET (JULY)\": \"Newmarket\",\n        \"SANDOWN\": \"Sandown Park\",\n        \"STRATFORD\": \"Stratford-on-Avon\",\n        \"YARMOUTH\": \"Great Yarmouth\",\n        \"CURRAGH\": \"Curragh\",\n        \"DOWN ROYAL\": \"Down Royal\",\n    }\n\n    # Check primary map first\n    if cleaned_name_upper in VENUE_MAP:\n        return VENUE_MAP[cleaned_name_upper]\n\n    # Handle cases where the key is the desired output but needs to be mapped from a variation\n    # e.g. CHELMSFORD maps to Chelmsford\n    # Title case the cleaned name for a sensible default\n    title_cased_name = clean_text(name).title()\n    if title_cased_name in VENUE_MAP.values():\n        return title_cased_name\n\n    # Return the title-cased cleaned name as a fallback\n    return title_cased_name\n\n\ndef normalize_course_name(name: str) -> str:\n    if not name:\n        return \"\"\n    name = name.lower().strip()\n    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s-]+\", \"_\", name)\n    return name\n",
    "requirements-dev.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=requirements-dev.txt requirements-dev.in\n#\naltair==5.5.0\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\nanyio==4.11.0\n    # via httpx\nattrs==25.4.0\n    # via\n    #   jsonschema\n    #   referencing\nblack==25.11.0\n    # via -r requirements-dev.in\nblinker==1.9.0\n    # via streamlit\nboolean-py==5.0\n    # via license-expression\ncachecontrol[filecache]==0.14.3\n    # via\n    #   cachecontrol\n    #   pip-audit\ncachetools==6.2.1\n    # via streamlit\ncertifi==2023.7.22\n    # via\n    #   httpcore\n    #   httpx\n    #   requests\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.0\n    # via\n    #   black\n    #   streamlit\ncyclonedx-python-lib==9.1.0\n    # via pip-audit\ndefusedxml==0.7.1\n    # via py-serializable\ndistro==1.9.0\n    # via tabula-py\nfakeredis[lua]==2.23.0\n    # via -r requirements-dev.in\nfilelock==3.20.0\n    # via cachecontrol\ngitdb==4.0.12\n    # via gitpython\ngitpython==3.1.45\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\ngreenlet==3.2.4\n    # via playwright\nh11==0.16.0\n    # via httpcore\nhttpcore==1.0.9\n    # via httpx\nhttpx==0.28.1\n    # via respx\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njinja2==3.1.6\n    # via\n    #   altair\n    #   pydeck\njsonschema==4.25.1\n    # via altair\njsonschema-specifications==2025.9.1\n    # via jsonschema\nlicense-expression==30.4.4\n    # via cyclonedx-python-lib\nlupa==2.6\n    # via fakeredis\nmarkdown-it-py==4.0.0\n    # via rich\nmarkupsafe==3.0.3\n    # via jinja2\nmdurl==0.1.2\n    # via markdown-it-py\nmsgpack==1.1.2\n    # via cachecontrol\nmypy-extensions==1.1.0\n    # via black\nnarwhals==2.9.0\n    # via altair\nnumpy==2.3.4\n    # via\n    #   pandas\n    #   pydeck\n    #   streamlit\n    #   tabula-py\npackageurl-python==0.17.5\n    # via cyclonedx-python-lib\npackaging==25.0\n    # via\n    #   altair\n    #   black\n    #   pip-audit\n    #   pip-requirements-parser\n    #   pytest\n    #   streamlit\npandas==2.3.3\n    # via\n    #   streamlit\n    #   tabula-py\npathspec==0.12.1\n    # via black\npillow==11.3.0\n    # via streamlit\npip-api==0.0.34\n    # via pip-audit\npip-audit==2.9.0\n    # via -r requirements-dev.in\npip-requirements-parser==32.0.1\n    # via pip-audit\nplatformdirs==4.5.0\n    # via\n    #   black\n    #   pip-audit\nplaywright==1.55.0\n    # via -r requirements-dev.in\npluggy==1.6.0\n    # via pytest\nprotobuf==6.33.0\n    # via streamlit\npy-serializable==2.1.0\n    # via cyclonedx-python-lib\npyarrow==21.0.0\n    # via streamlit\npydeck==0.9.1\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\npyee==13.0.0\n    # via playwright\npygments==2.19.2\n    # via\n    #   pytest\n    #   rich\npyparsing==3.2.5\n    # via pip-requirements-parser\npytest==8.4.2\n    # via\n    #   -r requirements-dev.in\n    #   pytest-asyncio\npytest-asyncio==1.2.0\n    # via -r requirements-dev.in\npython-dateutil==2.9.0.post0\n    # via pandas\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==7.0.1\n    # via fakeredis\nreferencing==0.37.0\n    # via\n    #   jsonschema\n    #   jsonschema-specifications\nrequests==2.32.5\n    # via\n    #   cachecontrol\n    #   pip-audit\n    #   streamlit\nrespx==0.22.0\n    # via -r requirements-dev.in\nrich==14.2.0\n    # via pip-audit\nrpds-py==0.28.0\n    # via\n    #   jsonschema\n    #   referencing\nsix==1.17.0\n    # via python-dateutil\nsmmap==5.0.2\n    # via gitdb\nsniffio==1.3.1\n    # via anyio\nsortedcontainers==2.4.0\n    # via\n    #   cyclonedx-python-lib\n    #   fakeredis\nstreamlit==1.50.0\n    # via -r requirements-dev.in\ntabula-py==2.10.0\n    # via -r requirements-dev.in\ntenacity==8.2.3\n    # via streamlit\ntoml==0.10.2\n    # via\n    #   pip-audit\n    #   streamlit\ntornado==6.5.2\n    # via streamlit\ntyping-extensions==4.15.0\n    # via\n    #   altair\n    #   anyio\n    #   pyee\n    #   pytest-asyncio\n    #   referencing\n    #   streamlit\ntzdata==2025.2\n    # via pandas\nurllib3>=2.6.0\n    # via requests\nwatchdog==6.0.0\n    # via streamlit\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools\n",
    "requirements.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=requirements.txt python_service/requirements.in\n#\naiosqlite==0.21.0\n    # via -r python_service/requirements.in\naltgraph==0.17.4\n    # via pyinstaller\nannotated-types==0.7.0\n    # via pydantic\nanyio==3.7.1\n    # via\n    #   fastapi\n    #   httpx\n    #   starlette\nbeautifulsoup4==4.12.2\n    # via -r python_service/requirements.in\nblack==25.11.0\n    # via -r python_service/requirements.in\nbuild==1.3.0\n    # via pip-tools\ncertifi==2025.11.12\n    # via\n    #   -r python_service/requirements.in\n    #   httpcore\n    #   httpx\n    #   requests\ncffi==2.0.0\n    # via cryptography\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.1\n    # via\n    #   black\n    #   pip-tools\n    #   uvicorn\ncryptography==46.0.3\n    # via\n    #   -r python_service/requirements.in\n    #   secretstorage\ndeprecated==1.3.1\n    # via limits\nfastapi==0.104.1\n    # via -r python_service/requirements.in\ngreenlet==3.2.4\n    # via sqlalchemy\nh11==0.16.0\n    # via\n    #   httpcore\n    #   uvicorn\nh2==4.3.0\n    # via httpx\nhpack==4.1.0\n    # via h2\nhttpcore==1.0.9\n    # via httpx\nhttpx[http2]==0.27.0\n    # via -r python_service/requirements.in\nhyperframe==6.1.0\n    # via h2\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njaraco-classes==3.4.0\n    # via keyring\njaraco-context==6.0.1\n    # via keyring\njaraco-functools==4.3.0\n    # via keyring\njeepney==0.9.0\n    # via\n    #   keyring\n    #   secretstorage\nkeyring==25.6.0\n    # via -r python_service/requirements.in\nlimits==5.6.0\n    # via slowapi\nmore-itertools==10.8.0\n    # via\n    #   jaraco-classes\n    #   jaraco-functools\nmypy-extensions==1.1.0\n    # via black\nnumpy==1.26.4\n    # via\n    #   -r python_service/requirements.in\n    #   pandas\n    #   scipy\npackaging==25.0\n    # via\n    #   black\n    #   build\n    #   limits\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\n    #   pytest\npandas==2.1.3\n    # via -r python_service/requirements.in\npathspec==0.12.1\n    # via black\npip-tools==7.5.2\n    # via -r python_service/requirements.in\nplatformdirs==4.5.0\n    # via black\npluggy==1.6.0\n    # via pytest\npsutil==7.1.1\n    # via -r python_service/requirements.in\npsycopg2-binary==2.9.9\n    # via -r python_service/requirements.in\npycparser==2.23\n    # via cffi\npydantic==2.5.2\n    # via\n    #   fastapi\n    #   pydantic-settings\npydantic-core==2.14.5\n    # via pydantic\npydantic-settings==2.1.0\n    # via -r python_service/requirements.in\npyinstaller==6.6.0\n    # via -r python_service/requirements.in\npyinstaller-hooks-contrib==2025.9\n    # via pyinstaller\npyproject-hooks==1.2.0\n    # via\n    #   build\n    #   pip-tools\npytest==8.3.2\n    # via\n    #   -r python_service/requirements.in\n    #   pytest-asyncio\npytest-asyncio==1.2.0\n    # via -r python_service/requirements.in\npython-dateutil==2.9.0.post0\n    # via pandas\npython-dotenv==1.0.0\n    # via pydantic-settings\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==5.0.1\n    # via -r python_service/requirements.in\nrequests==2.32.5\n    # via -r python_service/requirements.in\nscipy==1.16.3\n    # via -r python_service/requirements.in\nsecretstorage==3.4.1\n    # via keyring\nselectolax==0.4.0\n    # via -r python_service/requirements.in\nsix==1.17.0\n    # via python-dateutil\nslowapi==0.1.9\n    # via -r python_service/requirements.in\nsniffio==1.3.1\n    # via\n    #   anyio\n    #   httpx\nsoupsieve==2.8\n    # via beautifulsoup4\nsqlalchemy==2.0.23\n    # via -r python_service/requirements.in\nstarlette==0.27.0\n    # via fastapi\nstructlog==24.1.0\n    # via -r python_service/requirements.in\ntenacity==9.1.2\n    # via -r python_service/requirements.in\ntyping-extensions==4.15.0\n    # via\n    #   aiosqlite\n    #   fastapi\n    #   limits\n    #   pydantic\n    #   pydantic-core\n    #   pytest-asyncio\n    #   sqlalchemy\ntzdata==2025.2\n    # via pandas\nurllib3>=2.6.0\n    # via\n    #   -r python_service/requirements.in\n    #   requests\nuvicorn==0.30.1\n    # via -r python_service/requirements.in\nwheel==0.45.1\n    # via\n    #   -r python_service/requirements.in\n    #   pip-tools\nwrapt==2.0.1\n    # via deprecated\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools\n",
    "scripts/fortuna-quick-start.ps1": "# ====================================================================\n# Fortuna Faucet - Quick Start Script (No Installation Required)\n# ====================================================================\n# This script runs Fortuna directly from source without any MSI\n# Useful for development and testing before packaging\n# ====================================================================\n\nparam(\n    [switch]$SkipChecks,\n    [switch]$NoFrontend\n)\n\n$ErrorActionPreference = 'Stop'\n$OriginalLocation = Get-Location\n\n# ============= CONFIGURATION =============\n$PROJECT_ROOT = Split-Path -Parent $MyInvocation.MyCommand.Path\n$VENV_PATH = Join-Path $PROJECT_ROOT \".venv\"\n$PYTHON_EXE = Join-Path $VENV_PATH \"Scripts\\python.exe\"\n$BACKEND_DIR = Join-Path $PROJECT_ROOT \"python_service\"\n$FRONTEND_DIR = Join-Path $PROJECT_ROOT \"web_platform\\frontend\"\n$BACKEND_PORT = 8000\n$FRONTEND_PORT = 3000\n\n# ============= HELPER FUNCTIONS =============\n\nfunction Write-Status {\n    param([string]$Message, [string]$Status = \"INFO\")\n    $Color = switch ($Status) {\n        \"OK\"      { \"Green\" }\n        \"ERROR\"   { \"Red\" }\n        \"WARNING\" { \"Yellow\" }\n        default   { \"Cyan\" }\n    }\n    Write-Host \"[$Status] $Message\" -ForegroundColor $Color\n}\n\nfunction Test-CommandExists {\n    param([string]$Command)\n    try {\n        Get-Command $Command -ErrorAction Stop | Out-Null\n        return $true\n    } catch {\n        return $false\n    }\n}\n\nfunction Test-PortAvailable {\n    param([int]$Port)\n    try {\n        $Listener = [System.Net.Sockets.TcpListener]::new([System.Net.IPAddress]::Any, $Port)\n        $Listener.Start()\n        $Listener.Stop()\n        return $true\n    } catch {\n        return $false\n    }\n}\n\nfunction Stop-ProcessOnPort {\n    param([int]$Port)\n    $Connection = Get-NetTCPConnection -LocalPort $Port -ErrorAction SilentlyContinue\n    if ($Connection) {\n        $ProcessId = $Connection.OwningProcess\n        Write-Status \"Killing process $ProcessId on port $Port\" \"WARNING\"\n        Stop-Process -Id $ProcessId -Force -ErrorAction SilentlyContinue\n        Start-Sleep -Seconds 2\n    }\n}\n\nfunction Wait-ForBackend {\n    param([int]$MaxAttempts = 30)\n\n    Write-Status \"Waiting for backend to start (http://127.0.0.1:$BACKEND_PORT/health)...\"\n\n    for ($i = 1; $i -le $MaxAttempts; $i++) {\n        try {\n            $Response = Invoke-WebRequest -Uri \"http://127.0.0.1:$BACKEND_PORT/health\" -UseBasicParsing -TimeoutSec 2\n            if ($Response.StatusCode -eq 200) {\n                Write-Status \"Backend is healthy!\" \"OK\"\n                return $true\n            }\n        } catch {\n            Write-Host \".\" -NoNewline\n            Start-Sleep -Seconds 1\n        }\n    }\n\n    Write-Status \"Backend failed to start after $MaxAttempts seconds\" \"ERROR\"\n    return $false\n}\n\n# ============= PREFLIGHT CHECKS =============\n\nWrite-Host \"`n========================================\" -ForegroundColor Cyan\nWrite-Host \" Fortuna Faucet - Quick Start\" -ForegroundColor Cyan\nWrite-Host \"========================================`n\" -ForegroundColor Cyan\n\nif (-not $SkipChecks) {\n    Write-Status \"Running preflight checks...\"\n\n    # Check Python\n    if (-not (Test-Path $PYTHON_EXE)) {\n        Write-Status \"Python virtual environment not found at $VENV_PATH\" \"ERROR\"\n        Write-Status \"Please run setup script first or create venv manually\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"Python venv found\" \"OK\"\n\n    # Check Node.js\n    if (-not (Test-CommandExists \"node\")) {\n        Write-Status \"Node.js not found in PATH\" \"ERROR\"\n        Write-Status \"Install from: https://nodejs.org/\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"Node.js found: $(node --version)\" \"OK\"\n\n    # Check npm\n    if (-not (Test-CommandExists \"npm\")) {\n        Write-Status \"npm not found\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"npm found: $(npm --version)\" \"OK\"\n\n    # Check if ports are available\n    if (-not (Test-PortAvailable $BACKEND_PORT)) {\n        Write-Status \"Port $BACKEND_PORT is already in use\" \"WARNING\"\n        Stop-ProcessOnPort $BACKEND_PORT\n    }\n\n    if (-not $NoFrontend -and -not (Test-PortAvailable $FRONTEND_PORT)) {\n        Write-Status \"Port $FRONTEND_PORT is already in use\" \"WARNING\"\n        Stop-ProcessOnPort $FRONTEND_PORT\n    }\n\n    # Check Python dependencies\n    Write-Status \"Checking Python dependencies...\"\n    $PipList = & $PYTHON_EXE -m pip list\n    if ($PipList -notmatch \"fastapi\") {\n        Write-Status \"Python dependencies not installed\" \"WARNING\"\n        Write-Status \"Installing dependencies...\"\n        & $PYTHON_EXE -m pip install -r (Join-Path $BACKEND_DIR \"requirements.txt\")\n    } else {\n        Write-Status \"Python dependencies OK\" \"OK\"\n    }\n\n    # Check Node dependencies\n    if (-not $NoFrontend) {\n        Write-Status \"Checking Node.js dependencies...\"\n        $NodeModules = Join-Path $FRONTEND_DIR \"node_modules\"\n        if (-not (Test-Path $NodeModules)) {\n            Write-Status \"Node.js dependencies not installed\" \"WARNING\"\n            Write-Status \"Installing dependencies...\"\n            Push-Location $FRONTEND_DIR\n            npm install\n            Pop-Location\n        } else {\n            Write-Status \"Node.js dependencies OK\" \"OK\"\n        }\n    }\n\n    Write-Host \"\"\n}\n\n# ============= LAUNCH BACKEND =============\n\nWrite-Status \"Starting backend server...\"\n\n$BackendJob = Start-Job -ScriptBlock {\n    param($PythonExe, $BackendDir)\n    Set-Location $BackendDir\n    & $PythonExe -m uvicorn api:app --host 127.0.0.1 --port 8000 --reload\n} -ArgumentList $PYTHON_EXE, $BACKEND_DIR\n\nWrite-Status \"Backend job started (ID: $($BackendJob.Id))\"\n\n# Wait for backend to be healthy\nif (-not (Wait-ForBackend)) {\n    Write-Status \"Backend startup failed. Checking logs...\" \"ERROR\"\n    Receive-Job $BackendJob\n    Stop-Job $BackendJob\n    Remove-Job $BackendJob\n    exit 1\n}\n\n# ============= LAUNCH FRONTEND =============\n\nif (-not $NoFrontend) {\n    Write-Status \"Starting frontend dev server...\"\n\n    $FrontendJob = Start-Job -ScriptBlock {\n        param($FrontendDir)\n        Set-Location $FrontendDir\n        npm run dev\n    } -ArgumentList $FRONTEND_DIR\n\n    Write-Status \"Frontend job started (ID: $($FrontendJob.Id))\"\n\n    # Wait a bit for frontend to start\n    Start-Sleep -Seconds 5\n\n    Write-Status \"Opening browser...\" \"OK\"\n    Start-Process \"http://localhost:$FRONTEND_PORT\"\n}\n\n# ============= MONITORING =============\n\nWrite-Host \"`n========================================\" -ForegroundColor Green\nWrite-Host \" Fortuna is now running!\" -ForegroundColor Green\nWrite-Host \"========================================\" -ForegroundColor Green\nWrite-Host \"\"\nWrite-Status \"Backend:  http://127.0.0.1:$BACKEND_PORT\" \"OK\"\nif (-not $NoFrontend) {\n    Write-Status \"Frontend: http://127.0.0.1:$FRONTEND_PORT\" \"OK\"\n}\nWrite-Host \"\"\nWrite-Host \"Press Ctrl+C to stop all services\" -ForegroundColor Yellow\nWrite-Host \"\"\n\ntry {\n    while ($true) {\n        Start-Sleep -Seconds 2\n\n        # Check if jobs are still running\n        if ($BackendJob.State -eq \"Failed\" -or $BackendJob.State -eq \"Stopped\") {\n            Write-Status \"Backend has stopped unexpectedly!\" \"ERROR\"\n            Receive-Job $BackendJob\n            break\n        }\n\n        if (-not $NoFrontend -and ($FrontendJob.State -eq \"Failed\" -or $FrontendJob.State -eq \"Stopped\")) {\n            Write-Status \"Frontend has stopped unexpectedly!\" \"ERROR\"\n            Receive-Job $FrontendJob\n            break\n        }\n    }\n} finally {\n    # ============= CLEANUP =============\n    Write-Host \"`n`nShutting down...\" -ForegroundColor Yellow\n\n    if ($BackendJob) {\n        Write-Status \"Stopping backend...\"\n        Stop-Job $BackendJob -ErrorAction SilentlyContinue\n        Remove-Job $BackendJob -Force -ErrorAction SilentlyContinue\n    }\n\n    if ($FrontendJob) {\n        Write-Status \"Stopping frontend...\"\n        Stop-Job $FrontendJob -ErrorAction SilentlyContinue\n        Remove-Job $FrontendJob -Force -ErrorAction SilentlyContinue\n    }\n\n    # Kill any remaining processes on the ports\n    Stop-ProcessOnPort $BACKEND_PORT\n    if (-not $NoFrontend) {\n        Stop-ProcessOnPort $FRONTEND_PORT\n    }\n\n    Set-Location $OriginalLocation\n    Write-Status \"Cleanup complete\" \"OK\"\n}\n\n# ============= USAGE EXAMPLES =============\n<#\n.SYNOPSIS\nQuick start script for Fortuna Faucet (no installation required)\n\n.DESCRIPTION\nLaunches the backend and frontend servers directly from source code\nUseful for development and testing before creating an MSI installer\n\n.PARAMETER SkipChecks\nSkip all preflight dependency checks (faster startup)\n\n.PARAMETER NoFrontend\nOnly start the backend API server (no UI)\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1\nStarts both backend and frontend with full checks\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1 -NoFrontend\nStarts only the backend API (useful for API testing)\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1 -SkipChecks\nFast startup (assumes all dependencies are already installed)\n#>",
    "web_platform/api_gateway/package-lock.json": "{\n  \"name\": \"api_gateway\",\n  \"version\": \"1.0.0\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"name\": \"api_gateway\",\n      \"version\": \"1.0.0\",\n      \"dependencies\": {\n        \"cors\": \"^2.8.5\",\n        \"dotenv\": \"^16.3.1\",\n        \"express\": \"^4.18.2\",\n        \"socket.io\": \"^4.7.4\",\n        \"sqlite\": \"^5.1.1\",\n        \"sqlite3\": \"^5.1.7\"\n      },\n      \"devDependencies\": {\n        \"@types/cors\": \"^2.8.17\",\n        \"@types/express\": \"^4.17.21\",\n        \"@types/node\": \"^20.10.0\",\n        \"ts-node\": \"^10.9.2\",\n        \"typescript\": \"^5.3.3\"\n      }\n    },\n    \"node_modules/@cspotcode/source-map-support\": {\n      \"version\": \"0.8.1\",\n      \"resolved\": \"https://registry.npmjs.org/@cspotcode/source-map-support/-/source-map-support-0.8.1.tgz\",\n      \"integrity\": \"sha512-IchNf6dN4tHoMFIn/7OE8LWZ19Y6q/67Bmf6vnGREv8RSbBVb9LPJxEcnwrcwX6ixSvaiGoomAUvu4YSxXrVgw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@jridgewell/trace-mapping\": \"0.3.9\"\n      },\n      \"engines\": {\n        \"node\": \">=12\"\n      }\n    },\n    \"node_modules/@gar/promisify\": {\n      \"version\": \"1.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/@gar/promisify/-/promisify-1.1.3.tgz\",\n      \"integrity\": \"sha512-k2Ty1JcVojjJFwrg/ThKi2ujJ7XNLYaFGNB/bWT9wGR+oSMJHMa5w+CUq6p/pVrKeNNgA7pCqEcjSnHVoqJQFw==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/@jridgewell/resolve-uri\": {\n      \"version\": \"3.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz\",\n      \"integrity\": \"sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=6.0.0\"\n      }\n    },\n    \"node_modules/@jridgewell/sourcemap-codec\": {\n      \"version\": \"1.5.5\",\n      \"resolved\": \"https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.5.tgz\",\n      \"integrity\": \"sha512-cYQ9310grqxueWbl+WuIUIaiUaDcj7WOq5fVhEljNVgRfOUhY9fy2zTvfoqWsnebh8Sl70VScFbICvJnLKB0Og==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@jridgewell/trace-mapping\": {\n      \"version\": \"0.3.9\",\n      \"resolved\": \"https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.9.tgz\",\n      \"integrity\": \"sha512-3Belt6tdc8bPgAtbcmdtNJlirVoTmEb5e2gC94PnkwEW9jI6CAHUeoG85tjWP5WquqfavoMtMwiG4P926ZKKuQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@jridgewell/resolve-uri\": \"^3.0.3\",\n        \"@jridgewell/sourcemap-codec\": \"^1.4.10\"\n      }\n    },\n    \"node_modules/@npmcli/fs\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/@npmcli/fs/-/fs-1.1.1.tgz\",\n      \"integrity\": \"sha512-8KG5RD0GVP4ydEzRn/I4BNDuxDtqVbOdm8675T49OIG/NGhaK0pjPX7ZcDlvKYbA+ulvVK3ztfcF4uBdOxuJbQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"@gar/promisify\": \"^1.0.1\",\n        \"semver\": \"^7.3.5\"\n      }\n    },\n    \"node_modules/@npmcli/move-file\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/@npmcli/move-file/-/move-file-1.1.2.tgz\",\n      \"integrity\": \"sha512-1SUf/Cg2GzGDyaf15aR9St9TWlb+XvbZXWpDx8YKs7MLzMH/BCeopv+y9vzrzgkfykCGuWOlSu3mZhj2+FQcrg==\",\n      \"deprecated\": \"This functionality has been moved to @npmcli/fs\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"mkdirp\": \"^1.0.4\",\n        \"rimraf\": \"^3.0.2\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/@socket.io/component-emitter\": {\n      \"version\": \"3.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/@socket.io/component-emitter/-/component-emitter-3.1.2.tgz\",\n      \"integrity\": \"sha512-9BCxFwvbGg/RsZK9tjXd8s4UcwR0MWeFQ1XEKIQVVvAGJyINdrqKMcTRyLoK8Rse1GjzLV9cwjWV1olXRWEXVA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@tootallnate/once\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/@tootallnate/once/-/once-1.1.2.tgz\",\n      \"integrity\": \"sha512-RbzJvlNzmRq5c3O09UipeuXno4tA1FE6ikOjxZK0tuxVv3412l64l5t1W5pj4+rJq9vpkm/kwiR07aZXnsKPxw==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/@tsconfig/node10\": {\n      \"version\": \"1.0.11\",\n      \"resolved\": \"https://registry.npmjs.org/@tsconfig/node10/-/node10-1.0.11.tgz\",\n      \"integrity\": \"sha512-DcRjDCujK/kCk/cUe8Xz8ZSpm8mS3mNNpta+jGCA6USEDfktlNvm1+IuZ9eTcDbNk41BHwpHHeW+N1lKCz4zOw==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@tsconfig/node12\": {\n      \"version\": \"1.0.11\",\n      \"resolved\": \"https://registry.npmjs.org/@tsconfig/node12/-/node12-1.0.11.tgz\",\n      \"integrity\": \"sha512-cqefuRsh12pWyGsIoBKJA9luFu3mRxCA+ORZvA4ktLSzIuCUtWVxGIuXigEwO5/ywWFMZ2QEGKWvkZG1zDMTag==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@tsconfig/node14\": {\n      \"version\": \"1.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/@tsconfig/node14/-/node14-1.0.3.tgz\",\n      \"integrity\": \"sha512-ysT8mhdixWK6Hw3i1V2AeRqZ5WfXg1G43mqoYlM2nc6388Fq5jcXyr5mRsqViLx/GJYdoL0bfXD8nmF+Zn/Iow==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@tsconfig/node16\": {\n      \"version\": \"1.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/@tsconfig/node16/-/node16-1.0.4.tgz\",\n      \"integrity\": \"sha512-vxhUy4J8lyeyinH7Azl1pdd43GJhZH/tP2weN8TntQblOY+A0XbT8DJk1/oCPuOOyg/Ja757rG0CgHcWC8OfMA==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/body-parser\": {\n      \"version\": \"1.19.6\",\n      \"resolved\": \"https://registry.npmjs.org/@types/body-parser/-/body-parser-1.19.6.tgz\",\n      \"integrity\": \"sha512-HLFeCYgz89uk22N5Qg3dvGvsv46B8GLvKKo1zKG4NybA8U2DiEO3w9lqGg29t/tfLRJpJ6iQxnVw4OnB7MoM9g==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/connect\": \"*\",\n        \"@types/node\": \"*\"\n      }\n    },\n    \"node_modules/@types/connect\": {\n      \"version\": \"3.4.38\",\n      \"resolved\": \"https://registry.npmjs.org/@types/connect/-/connect-3.4.38.tgz\",\n      \"integrity\": \"sha512-K6uROf1LD88uDQqJCktA4yzL1YYAK6NgfsI0v/mTgyPKWsX1CnJ0XPSDhViejru1GcRkLWb8RlzFYJRqGUbaug==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/node\": \"*\"\n      }\n    },\n    \"node_modules/@types/cors\": {\n      \"version\": \"2.8.19\",\n      \"resolved\": \"https://registry.npmjs.org/@types/cors/-/cors-2.8.19.tgz\",\n      \"integrity\": \"sha512-mFNylyeyqN93lfe/9CSxOGREz8cpzAhH+E93xJ4xWQf62V8sQ/24reV2nyzUWM6H6Xji+GGHpkbLe7pVoUEskg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/node\": \"*\"\n      }\n    },\n    \"node_modules/@types/express\": {\n      \"version\": \"4.17.23\",\n      \"resolved\": \"https://registry.npmjs.org/@types/express/-/express-4.17.23.tgz\",\n      \"integrity\": \"sha512-Crp6WY9aTYP3qPi2wGDo9iUe/rceX01UMhnF1jmwDcKCFM6cx7YhGP/Mpr3y9AASpfHixIG0E6azCcL5OcDHsQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/body-parser\": \"*\",\n        \"@types/express-serve-static-core\": \"^4.17.33\",\n        \"@types/qs\": \"*\",\n        \"@types/serve-static\": \"*\"\n      }\n    },\n    \"node_modules/@types/express-serve-static-core\": {\n      \"version\": \"4.19.6\",\n      \"resolved\": \"https://registry.npmjs.org/@types/express-serve-static-core/-/express-serve-static-core-4.19.6.tgz\",\n      \"integrity\": \"sha512-N4LZ2xG7DatVqhCZzOGb1Yi5lMbXSZcmdLDe9EzSndPV2HpWYWzRbaerl2n27irrm94EPpprqa8KpskPT085+A==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/node\": \"*\",\n        \"@types/qs\": \"*\",\n        \"@types/range-parser\": \"*\",\n        \"@types/send\": \"*\"\n      }\n    },\n    \"node_modules/@types/http-errors\": {\n      \"version\": \"2.0.5\",\n      \"resolved\": \"https://registry.npmjs.org/@types/http-errors/-/http-errors-2.0.5.tgz\",\n      \"integrity\": \"sha512-r8Tayk8HJnX0FztbZN7oVqGccWgw98T/0neJphO91KkmOzug1KkofZURD4UaD5uH8AqcFLfdPErnBod0u71/qg==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/mime\": {\n      \"version\": \"1.3.5\",\n      \"resolved\": \"https://registry.npmjs.org/@types/mime/-/mime-1.3.5.tgz\",\n      \"integrity\": \"sha512-/pyBZWSLD2n0dcHE3hq8s8ZvcETHtEuF+3E7XVt0Ig2nvsVQXdghHVcEkIWjy9A0wKfTn97a/PSDYohKIlnP/w==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/node\": {\n      \"version\": \"20.19.26\",\n      \"resolved\": \"https://registry.npmjs.org/@types/node/-/node-20.19.26.tgz\",\n      \"integrity\": \"sha512-0l6cjgF0XnihUpndDhk+nyD3exio3iKaYROSgvh/qSevPXax3L8p5DBRFjbvalnwatGgHEQn2R88y2fA3g4irg==\",\n      \"license\": \"MIT\",\n      \"peer\": true,\n      \"dependencies\": {\n        \"undici-types\": \"~6.21.0\"\n      }\n    },\n    \"node_modules/@types/qs\": {\n      \"version\": \"6.14.0\",\n      \"resolved\": \"https://registry.npmjs.org/@types/qs/-/qs-6.14.0.tgz\",\n      \"integrity\": \"sha512-eOunJqu0K1923aExK6y8p6fsihYEn/BYuQ4g0CxAAgFc4b/ZLN4CrsRZ55srTdqoiLzU2B2evC+apEIxprEzkQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/range-parser\": {\n      \"version\": \"1.2.7\",\n      \"resolved\": \"https://registry.npmjs.org/@types/range-parser/-/range-parser-1.2.7.tgz\",\n      \"integrity\": \"sha512-hKormJbkJqzQGhziax5PItDUTMAM9uE2XXQmM37dyd4hVM+5aVl7oVxMVUiVQn2oCQFN/LKCZdvSM0pFRqbSmQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/@types/send\": {\n      \"version\": \"0.17.5\",\n      \"resolved\": \"https://registry.npmjs.org/@types/send/-/send-0.17.5.tgz\",\n      \"integrity\": \"sha512-z6F2D3cOStZvuk2SaP6YrwkNO65iTZcwA2ZkSABegdkAh/lf+Aa/YQndZVfmEXT5vgAp6zv06VQ3ejSVjAny4w==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/mime\": \"^1\",\n        \"@types/node\": \"*\"\n      }\n    },\n    \"node_modules/@types/serve-static\": {\n      \"version\": \"1.15.8\",\n      \"resolved\": \"https://registry.npmjs.org/@types/serve-static/-/serve-static-1.15.8.tgz\",\n      \"integrity\": \"sha512-roei0UY3LhpOJvjbIP6ZZFngyLKl5dskOtDhxY5THRSpO+ZI+nzJ+m5yUMzGrp89YRa7lvknKkMYjqQFGwA7Sg==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/http-errors\": \"*\",\n        \"@types/node\": \"*\",\n        \"@types/send\": \"*\"\n      }\n    },\n    \"node_modules/abbrev\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/abbrev/-/abbrev-1.1.1.tgz\",\n      \"integrity\": \"sha512-nne9/IiQ/hzIhY6pdDnbBtz7DjPTKrY00P/zvPSm5pOFkl6xuGrGnXn/VtTNNfNtAfZ9/1RtehkszU9qcTii0Q==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/accepts\": {\n      \"version\": \"1.3.8\",\n      \"resolved\": \"https://registry.npmjs.org/accepts/-/accepts-1.3.8.tgz\",\n      \"integrity\": \"sha512-PYAthTa2m2VKxuvSD3DPC/Gy+U+sOA1LAuT8mkmRuvw+NACSaeXEQ+NHcVF7rONl6qcaxV3Uuemwawk+7+SJLw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"mime-types\": \"~2.1.34\",\n        \"negotiator\": \"0.6.3\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/acorn\": {\n      \"version\": \"8.15.0\",\n      \"resolved\": \"https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz\",\n      \"integrity\": \"sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"bin\": {\n        \"acorn\": \"bin/acorn\"\n      },\n      \"engines\": {\n        \"node\": \">=0.4.0\"\n      }\n    },\n    \"node_modules/acorn-walk\": {\n      \"version\": \"8.3.4\",\n      \"resolved\": \"https://registry.npmjs.org/acorn-walk/-/acorn-walk-8.3.4.tgz\",\n      \"integrity\": \"sha512-ueEepnujpqee2o5aIYnvHU6C0A42MNdsIDeqy5BydrkuC5R1ZuUFnm27EeFJGoEHJQgn3uleRvmTXaJgfXbt4g==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"acorn\": \"^8.11.0\"\n      },\n      \"engines\": {\n        \"node\": \">=0.4.0\"\n      }\n    },\n    \"node_modules/agent-base\": {\n      \"version\": \"6.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/agent-base/-/agent-base-6.0.2.tgz\",\n      \"integrity\": \"sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"debug\": \"4\"\n      },\n      \"engines\": {\n        \"node\": \">= 6.0.0\"\n      }\n    },\n    \"node_modules/agent-base/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/agent-base/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/agentkeepalive\": {\n      \"version\": \"4.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/agentkeepalive/-/agentkeepalive-4.6.0.tgz\",\n      \"integrity\": \"sha512-kja8j7PjmncONqaTsB8fQ+wE2mSU2DJ9D4XKoJ5PFWIdRMa6SLSN1ff4mOr4jCbfRSsxR4keIiySJU0N9T5hIQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"humanize-ms\": \"^1.2.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 8.0.0\"\n      }\n    },\n    \"node_modules/aggregate-error\": {\n      \"version\": \"3.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/aggregate-error/-/aggregate-error-3.1.0.tgz\",\n      \"integrity\": \"sha512-4I7Td01quW/RpocfNayFdFVk1qSuoh0E7JrbRJ16nH01HhKFQ88INq9Sd+nd72zqRySlr9BmDA8xlEJ6vJMrYA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"clean-stack\": \"^2.0.0\",\n        \"indent-string\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/ansi-regex\": {\n      \"version\": \"5.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz\",\n      \"integrity\": \"sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/aproba\": {\n      \"version\": \"2.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/aproba/-/aproba-2.1.0.tgz\",\n      \"integrity\": \"sha512-tLIEcj5GuR2RSTnxNKdkK0dJ/GrC7P38sUkiDmDuHfsHmbagTFAxDVIBltoklXEVIQ/f14IL8IMJ5pn9Hez1Ew==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/are-we-there-yet\": {\n      \"version\": \"3.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/are-we-there-yet/-/are-we-there-yet-3.0.1.tgz\",\n      \"integrity\": \"sha512-QZW4EDmGwlYur0Yyf/b2uGucHQMa8aFUP7eu9ddR73vvhFyt4V0Vl3QHPcTNJ8l6qYOBdxgXdnBXQrHilfRQBg==\",\n      \"deprecated\": \"This package is no longer supported.\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"delegates\": \"^1.0.0\",\n        \"readable-stream\": \"^3.6.0\"\n      },\n      \"engines\": {\n        \"node\": \"^12.13.0 || ^14.15.0 || >=16.0.0\"\n      }\n    },\n    \"node_modules/arg\": {\n      \"version\": \"4.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/arg/-/arg-4.1.3.tgz\",\n      \"integrity\": \"sha512-58S9QDqG0Xx27YwPSt9fJxivjYl432YCwfDMfZ+71RAqUrZef7LrKQZ3LHLOwCS4FLNBplP533Zx895SeOCHvA==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/array-flatten\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/array-flatten/-/array-flatten-1.1.1.tgz\",\n      \"integrity\": \"sha512-PCVAQswWemu6UdxsDFFX/+gVeYqKAod3D3UVm91jHwynguOwAvYPhx8nNlM++NqRcK6CxxpUafjmhIdKiHibqg==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/balanced-match\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz\",\n      \"integrity\": \"sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/base64-js\": {\n      \"version\": \"1.5.1\",\n      \"resolved\": \"https://registry.npmjs.org/base64-js/-/base64-js-1.5.1.tgz\",\n      \"integrity\": \"sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\"\n    },\n    \"node_modules/base64id\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/base64id/-/base64id-2.0.0.tgz\",\n      \"integrity\": \"sha512-lGe34o6EHj9y3Kts9R4ZYs/Gr+6N7MCaMlIFA3F1R2O5/m7K06AxfSeO5530PEERE6/WyEg3lsuyw4GHlPZHog==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \"^4.5.0 || >= 5.9\"\n      }\n    },\n    \"node_modules/bindings\": {\n      \"version\": \"1.5.0\",\n      \"resolved\": \"https://registry.npmjs.org/bindings/-/bindings-1.5.0.tgz\",\n      \"integrity\": \"sha512-p2q/t/mhvuOj/UeLlV6566GD/guowlr0hHxClI0W9m7MWYkL1F0hLo+0Aexs9HSPCtR1SXQ0TD3MMKrXZajbiQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"file-uri-to-path\": \"1.0.0\"\n      }\n    },\n    \"node_modules/bl\": {\n      \"version\": \"4.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/bl/-/bl-4.1.0.tgz\",\n      \"integrity\": \"sha512-1W07cM9gS6DcLperZfFSj+bWLtaPGSOHWhPiGzXmvVJbRLdG82sH/Kn8EtW1VqWVA54AKf2h5k5BbnIbwF3h6w==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"buffer\": \"^5.5.0\",\n        \"inherits\": \"^2.0.4\",\n        \"readable-stream\": \"^3.4.0\"\n      }\n    },\n    \"node_modules/body-parser\": {\n      \"version\": \"1.20.3\",\n      \"resolved\": \"https://registry.npmjs.org/body-parser/-/body-parser-1.20.3.tgz\",\n      \"integrity\": \"sha512-7rAxByjUMqQ3/bHJy7D6OGXvx/MMc4IqBn/X0fcM1QUcAItpZrBEYhWGem+tzXH90c+G01ypMcYJBO9Y30203g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"bytes\": \"3.1.2\",\n        \"content-type\": \"~1.0.5\",\n        \"debug\": \"2.6.9\",\n        \"depd\": \"2.0.0\",\n        \"destroy\": \"1.2.0\",\n        \"http-errors\": \"2.0.0\",\n        \"iconv-lite\": \"0.4.24\",\n        \"on-finished\": \"2.4.1\",\n        \"qs\": \"6.13.0\",\n        \"raw-body\": \"2.5.2\",\n        \"type-is\": \"~1.6.18\",\n        \"unpipe\": \"1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\",\n        \"npm\": \"1.2.8000 || >= 1.4.16\"\n      }\n    },\n    \"node_modules/brace-expansion\": {\n      \"version\": \"1.1.12\",\n      \"resolved\": \"https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz\",\n      \"integrity\": \"sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"balanced-match\": \"^1.0.0\",\n        \"concat-map\": \"0.0.1\"\n      }\n    },\n    \"node_modules/buffer\": {\n      \"version\": \"5.7.1\",\n      \"resolved\": \"https://registry.npmjs.org/buffer/-/buffer-5.7.1.tgz\",\n      \"integrity\": \"sha512-EHcyIPBQ4BSGlvjB16k5KgAJ27CIsHY/2JBmCRReo48y9rQ3MaUzWX3KVlBa4U7MyX02HdVj0K7C3WaB3ju7FQ==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"base64-js\": \"^1.3.1\",\n        \"ieee754\": \"^1.1.13\"\n      }\n    },\n    \"node_modules/bytes\": {\n      \"version\": \"3.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/bytes/-/bytes-3.1.2.tgz\",\n      \"integrity\": \"sha512-/Nf7TyzTx6S3yRJObOAV7956r8cr2+Oj8AC5dt8wSP3BQAoeX58NoHyCU8P8zGkNXStjTSi6fzO6F0pBdcYbEg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/cacache\": {\n      \"version\": \"15.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/cacache/-/cacache-15.3.0.tgz\",\n      \"integrity\": \"sha512-VVdYzXEn+cnbXpFgWs5hTT7OScegHVmLhJIR8Ufqk3iFD6A6j5iSX1KuBTfNEv4tdJWE2PzA6IVFtcLC7fN9wQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"@npmcli/fs\": \"^1.0.0\",\n        \"@npmcli/move-file\": \"^1.0.1\",\n        \"chownr\": \"^2.0.0\",\n        \"fs-minipass\": \"^2.0.0\",\n        \"glob\": \"^7.1.4\",\n        \"infer-owner\": \"^1.0.4\",\n        \"lru-cache\": \"^6.0.0\",\n        \"minipass\": \"^3.1.1\",\n        \"minipass-collect\": \"^1.0.2\",\n        \"minipass-flush\": \"^1.0.5\",\n        \"minipass-pipeline\": \"^1.2.2\",\n        \"mkdirp\": \"^1.0.3\",\n        \"p-map\": \"^4.0.0\",\n        \"promise-inflight\": \"^1.0.1\",\n        \"rimraf\": \"^3.0.2\",\n        \"ssri\": \"^8.0.1\",\n        \"tar\": \"^6.0.2\",\n        \"unique-filename\": \"^1.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 10\"\n      }\n    },\n    \"node_modules/call-bind-apply-helpers\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz\",\n      \"integrity\": \"sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"es-errors\": \"^1.3.0\",\n        \"function-bind\": \"^1.1.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/call-bound\": {\n      \"version\": \"1.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/call-bound/-/call-bound-1.0.4.tgz\",\n      \"integrity\": \"sha512-+ys997U96po4Kx/ABpBCqhA9EuxJaQWDQg7295H4hBphv3IZg0boBKuwYpt4YXp6MZ5AmZQnU/tyMTlRpaSejg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bind-apply-helpers\": \"^1.0.2\",\n        \"get-intrinsic\": \"^1.3.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/chownr\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/chownr/-/chownr-2.0.0.tgz\",\n      \"integrity\": \"sha512-bIomtDF5KGpdogkLd9VspvFzk9KfpyyGlS8YFVZl7TGPBHL5snIOnxeshwVgPteQ9b4Eydl+pVbIyE1DcvCWgQ==\",\n      \"license\": \"ISC\",\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/clean-stack\": {\n      \"version\": \"2.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/clean-stack/-/clean-stack-2.2.0.tgz\",\n      \"integrity\": \"sha512-4diC9HaTE+KRAMWhDhrGOECgWZxoevMc5TlkObMqNSsVU62PYzXZ/SMTjzyGAFF1YusgxGcSWTEXBhp0CPwQ1A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/color-support\": {\n      \"version\": \"1.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/color-support/-/color-support-1.1.3.tgz\",\n      \"integrity\": \"sha512-qiBjkpbMLO/HL68y+lh4q0/O1MZFj2RX6X/KmMa3+gJD3z+WwI1ZzDHysvqHGS3mP6mznPckpXmw1nI9cJjyRg==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"bin\": {\n        \"color-support\": \"bin.js\"\n      }\n    },\n    \"node_modules/concat-map\": {\n      \"version\": \"0.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz\",\n      \"integrity\": \"sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/console-control-strings\": {\n      \"version\": \"1.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/console-control-strings/-/console-control-strings-1.1.0.tgz\",\n      \"integrity\": \"sha512-ty/fTekppD2fIwRvnZAVdeOiGd1c7YXEixbgJTNzqcxJWKQnjJ/V1bNEEE6hygpM3WjwHFUVK6HTjWSzV4a8sQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/content-disposition\": {\n      \"version\": \"0.5.4\",\n      \"resolved\": \"https://registry.npmjs.org/content-disposition/-/content-disposition-0.5.4.tgz\",\n      \"integrity\": \"sha512-FveZTNuGw04cxlAiWbzi6zTAL/lhehaWbTtgluJh4/E95DqMwTmha3KZN1aAWA8cFIhHzMZUvLevkw5Rqk+tSQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"safe-buffer\": \"5.2.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/content-type\": {\n      \"version\": \"1.0.5\",\n      \"resolved\": \"https://registry.npmjs.org/content-type/-/content-type-1.0.5.tgz\",\n      \"integrity\": \"sha512-nTjqfcBFEipKdXCv4YDQWCfmcLZKm81ldF0pAopTvyrFGVbcR6P/VAAd5G7N+0tTr8QqiU0tFadD6FK4NtJwOA==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/cookie\": {\n      \"version\": \"0.7.1\",\n      \"resolved\": \"https://registry.npmjs.org/cookie/-/cookie-0.7.1.tgz\",\n      \"integrity\": \"sha512-6DnInpx7SJ2AK3+CTUE/ZM0vWTUboZCegxhC2xiIydHR9jNuTAASBrfEpHhiGOZw/nX51bHt6YQl8jsGo4y/0w==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/cookie-signature\": {\n      \"version\": \"1.0.6\",\n      \"resolved\": \"https://registry.npmjs.org/cookie-signature/-/cookie-signature-1.0.6.tgz\",\n      \"integrity\": \"sha512-QADzlaHc8icV8I7vbaJXJwod9HWYp8uCqf1xa4OfNu1T7JVxQIrUgOWtHdNDtPiywmFbiS12VjotIXLrKM3orQ==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/cors\": {\n      \"version\": \"2.8.5\",\n      \"resolved\": \"https://registry.npmjs.org/cors/-/cors-2.8.5.tgz\",\n      \"integrity\": \"sha512-KIHbLJqu73RGr/hnbrO9uBeixNGuvSQjul/jdFvS/KFSIH1hWVd1ng7zOHx+YrEfInLG7q4n6GHQ9cDtxv/P6g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"object-assign\": \"^4\",\n        \"vary\": \"^1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.10\"\n      }\n    },\n    \"node_modules/create-require\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/create-require/-/create-require-1.1.1.tgz\",\n      \"integrity\": \"sha512-dcKFX3jn0MpIaXjisoRvexIJVEKzaq7z2rZKxf+MSr9TkdmHmsU4m2lcLojrj/FHl8mk5VxMmYA+ftRkP/3oKQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/debug\": {\n      \"version\": \"2.6.9\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-2.6.9.tgz\",\n      \"integrity\": \"sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"2.0.0\"\n      }\n    },\n    \"node_modules/decompress-response\": {\n      \"version\": \"6.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/decompress-response/-/decompress-response-6.0.0.tgz\",\n      \"integrity\": \"sha512-aW35yZM6Bb/4oJlZncMH2LCoZtJXTRxES17vE3hoRiowU2kWHaJKFkSBDnDR+cm9J+9QhXmREyIfv0pji9ejCQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"mimic-response\": \"^3.1.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/deep-extend\": {\n      \"version\": \"0.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/deep-extend/-/deep-extend-0.6.0.tgz\",\n      \"integrity\": \"sha512-LOHxIOaPYdHlJRtCQfDIVZtfw/ufM8+rVj649RIHzcm/vGwQRXFt6OPqIFWsm2XEMrNIEtWR64sY1LEKD2vAOA==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=4.0.0\"\n      }\n    },\n    \"node_modules/delegates\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/delegates/-/delegates-1.0.0.tgz\",\n      \"integrity\": \"sha512-bd2L678uiWATM6m5Z1VzNCErI3jiGzt6HGY8OVICs40JQq/HALfbyNJmp0UDakEY4pMMaN0Ly5om/B1VI/+xfQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/depd\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/depd/-/depd-2.0.0.tgz\",\n      \"integrity\": \"sha512-g7nH6P6dyDioJogAAGprGpCtVImJhpPk/roCzdb3fIh61/s/nPsfR6onyMwkCAR/OlC3yBC0lESvUoQEAssIrw==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/destroy\": {\n      \"version\": \"1.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/destroy/-/destroy-1.2.0.tgz\",\n      \"integrity\": \"sha512-2sJGJTaXIIaR1w4iJSNoN0hnMY7Gpc/n8D4qSCJw8QqFWXf7cuAgnEHxBpweaVcPevC2l3KpjYCx3NypQQgaJg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\",\n        \"npm\": \"1.2.8000 || >= 1.4.16\"\n      }\n    },\n    \"node_modules/detect-libc\": {\n      \"version\": \"2.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/detect-libc/-/detect-libc-2.1.1.tgz\",\n      \"integrity\": \"sha512-ecqj/sy1jcK1uWrwpR67UhYrIFQ+5WlGxth34WquCbamhFA6hkkwiu37o6J5xCHdo1oixJRfVRw+ywV+Hq/0Aw==\",\n      \"license\": \"Apache-2.0\",\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/diff\": {\n      \"version\": \"4.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/diff/-/diff-4.0.2.tgz\",\n      \"integrity\": \"sha512-58lmxKSA4BNyLz+HHMUzlOEpg09FV+ev6ZMe3vJihgdxzgcwZ8VoEEPmALCZG9LmqfVoNMMKpttIYTVG6uDY7A==\",\n      \"dev\": true,\n      \"license\": \"BSD-3-Clause\",\n      \"engines\": {\n        \"node\": \">=0.3.1\"\n      }\n    },\n    \"node_modules/dotenv\": {\n      \"version\": \"16.6.1\",\n      \"resolved\": \"https://registry.npmjs.org/dotenv/-/dotenv-16.6.1.tgz\",\n      \"integrity\": \"sha512-uBq4egWHTcTt33a72vpSG0z3HnPuIl6NqYcTrKEg2azoEyl2hpW0zqlxysq2pK9HlDIHyHyakeYaYnSAwd8bow==\",\n      \"license\": \"BSD-2-Clause\",\n      \"engines\": {\n        \"node\": \">=12\"\n      },\n      \"funding\": {\n        \"url\": \"https://dotenvx.com\"\n      }\n    },\n    \"node_modules/dunder-proto\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz\",\n      \"integrity\": \"sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bind-apply-helpers\": \"^1.0.1\",\n        \"es-errors\": \"^1.3.0\",\n        \"gopd\": \"^1.2.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/ee-first\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/ee-first/-/ee-first-1.1.1.tgz\",\n      \"integrity\": \"sha512-WMwm9LhRUo+WUaRN+vRuETqG89IgZphVSNkdFgeb6sS/E4OrDIN7t48CAewSHXc6C8lefD8KKfr5vY61brQlow==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/emoji-regex\": {\n      \"version\": \"8.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz\",\n      \"integrity\": \"sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/encodeurl\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/encodeurl/-/encodeurl-2.0.0.tgz\",\n      \"integrity\": \"sha512-Q0n9HRi4m6JuGIV1eFlmvJB7ZEVxu93IrMyiMsGC0lrMJMWzRgx6WGquyfQgZVb31vhGgXnfmPNNXmxnOkRBrg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/encoding\": {\n      \"version\": \"0.1.13\",\n      \"resolved\": \"https://registry.npmjs.org/encoding/-/encoding-0.1.13.tgz\",\n      \"integrity\": \"sha512-ETBauow1T35Y/WZMkio9jiM0Z5xjHHmJ4XmjZOq1l/dXz3lr2sRn87nJy20RupqSh1F2m3HHPSp8ShIPQJrJ3A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"iconv-lite\": \"^0.6.2\"\n      }\n    },\n    \"node_modules/encoding/node_modules/iconv-lite\": {\n      \"version\": \"0.6.3\",\n      \"resolved\": \"https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.6.3.tgz\",\n      \"integrity\": \"sha512-4fCk79wshMdzMp2rH06qWrJE4iolqLhCUH+OiuIgU++RB0+94NlDL81atO7GX55uUKueo0txHNtvEyI6D7WdMw==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"safer-buffer\": \">= 2.1.2 < 3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/end-of-stream\": {\n      \"version\": \"1.4.5\",\n      \"resolved\": \"https://registry.npmjs.org/end-of-stream/-/end-of-stream-1.4.5.tgz\",\n      \"integrity\": \"sha512-ooEGc6HP26xXq/N+GCGOT0JKCLDGrq2bQUZrQ7gyrJiZANJ/8YDTxTpQBXGMn+WbIQXNVpyWymm7KYVICQnyOg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"once\": \"^1.4.0\"\n      }\n    },\n    \"node_modules/engine.io\": {\n      \"version\": \"6.6.4\",\n      \"resolved\": \"https://registry.npmjs.org/engine.io/-/engine.io-6.6.4.tgz\",\n      \"integrity\": \"sha512-ZCkIjSYNDyGn0R6ewHDtXgns/Zre/NT6Agvq1/WobF7JXgFff4SeDroKiCO3fNJreU9YG429Sc81o4w5ok/W5g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@types/cors\": \"^2.8.12\",\n        \"@types/node\": \">=10.0.0\",\n        \"accepts\": \"~1.3.4\",\n        \"base64id\": \"2.0.0\",\n        \"cookie\": \"~0.7.2\",\n        \"cors\": \"~2.8.5\",\n        \"debug\": \"~4.3.1\",\n        \"engine.io-parser\": \"~5.2.1\",\n        \"ws\": \"~8.17.1\"\n      },\n      \"engines\": {\n        \"node\": \">=10.2.0\"\n      }\n    },\n    \"node_modules/engine.io-parser\": {\n      \"version\": \"5.2.3\",\n      \"resolved\": \"https://registry.npmjs.org/engine.io-parser/-/engine.io-parser-5.2.3.tgz\",\n      \"integrity\": \"sha512-HqD3yTBfnBxIrbnM1DoD6Pcq8NECnh8d4As1Qgh0z5Gg3jRRIqijury0CL3ghu/edArpUYiYqQiDUQBIs4np3Q==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=10.0.0\"\n      }\n    },\n    \"node_modules/engine.io/node_modules/cookie\": {\n      \"version\": \"0.7.2\",\n      \"resolved\": \"https://registry.npmjs.org/cookie/-/cookie-0.7.2.tgz\",\n      \"integrity\": \"sha512-yki5XnKuf750l50uGTllt6kKILY4nQ1eNIQatoXEByZ5dWgnKqbnqmTrBE5B4N7lrMJKQ2ytWMiTO2o0v6Ew/w==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/engine.io/node_modules/debug\": {\n      \"version\": \"4.3.7\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.3.7.tgz\",\n      \"integrity\": \"sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/engine.io/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/env-paths\": {\n      \"version\": \"2.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/env-paths/-/env-paths-2.2.1.tgz\",\n      \"integrity\": \"sha512-+h1lkLKhZMTYjog1VEpJNG7NZJWcuc2DDk/qsqSTRRCOXiLjeQ1d1/udrUGhqMxUgAlwKNZ0cf2uqan5GLuS2A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/err-code\": {\n      \"version\": \"2.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/err-code/-/err-code-2.0.3.tgz\",\n      \"integrity\": \"sha512-2bmlRpNKBxT/CRmPOlyISQpNj+qSeYvcym/uT0Jx2bMOlKLtSy1ZmLuVxSEKKyor/N5yhvp/ZiG1oE3DEYMSFA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/es-define-property\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz\",\n      \"integrity\": \"sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/es-errors\": {\n      \"version\": \"1.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz\",\n      \"integrity\": \"sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/es-object-atoms\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz\",\n      \"integrity\": \"sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"es-errors\": \"^1.3.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/escape-html\": {\n      \"version\": \"1.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/escape-html/-/escape-html-1.0.3.tgz\",\n      \"integrity\": \"sha512-NiSupZ4OeuGwr68lGIeym/ksIZMJodUGOSCZ/FSnTxcrekbvqrgdUxlJOMpijaKZVjAJrWrGs/6Jy8OMuyj9ow==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/etag\": {\n      \"version\": \"1.8.1\",\n      \"resolved\": \"https://registry.npmjs.org/etag/-/etag-1.8.1.tgz\",\n      \"integrity\": \"sha512-aIL5Fx7mawVa300al2BnEE4iNvo1qETxLrPI/o05L7z6go7fCw1J6EQmbK4FmJ2AS7kgVF/KEZWufBfdClMcPg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/expand-template\": {\n      \"version\": \"2.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/expand-template/-/expand-template-2.0.3.tgz\",\n      \"integrity\": \"sha512-XYfuKMvj4O35f/pOXLObndIRvyQ+/+6AhODh+OKWj9S9498pHHn/IMszH+gt0fBCRWMNfk1ZSp5x3AifmnI2vg==\",\n      \"license\": \"(MIT OR WTFPL)\",\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/express\": {\n      \"version\": \"4.21.2\",\n      \"resolved\": \"https://registry.npmjs.org/express/-/express-4.21.2.tgz\",\n      \"integrity\": \"sha512-28HqgMZAmih1Czt9ny7qr6ek2qddF4FclbMzwhCREB6OFfH+rXAnuNCwo1/wFvrtbgsQDb4kSbX9de9lFbrXnA==\",\n      \"license\": \"MIT\",\n      \"peer\": true,\n      \"dependencies\": {\n        \"accepts\": \"~1.3.8\",\n        \"array-flatten\": \"1.1.1\",\n        \"body-parser\": \"1.20.3\",\n        \"content-disposition\": \"0.5.4\",\n        \"content-type\": \"~1.0.4\",\n        \"cookie\": \"0.7.1\",\n        \"cookie-signature\": \"1.0.6\",\n        \"debug\": \"2.6.9\",\n        \"depd\": \"2.0.0\",\n        \"encodeurl\": \"~2.0.0\",\n        \"escape-html\": \"~1.0.3\",\n        \"etag\": \"~1.8.1\",\n        \"finalhandler\": \"1.3.1\",\n        \"fresh\": \"0.5.2\",\n        \"http-errors\": \"2.0.0\",\n        \"merge-descriptors\": \"1.0.3\",\n        \"methods\": \"~1.1.2\",\n        \"on-finished\": \"2.4.1\",\n        \"parseurl\": \"~1.3.3\",\n        \"path-to-regexp\": \"0.1.12\",\n        \"proxy-addr\": \"~2.0.7\",\n        \"qs\": \"6.13.0\",\n        \"range-parser\": \"~1.2.1\",\n        \"safe-buffer\": \"5.2.1\",\n        \"send\": \"0.19.0\",\n        \"serve-static\": \"1.16.2\",\n        \"setprototypeof\": \"1.2.0\",\n        \"statuses\": \"2.0.1\",\n        \"type-is\": \"~1.6.18\",\n        \"utils-merge\": \"1.0.1\",\n        \"vary\": \"~1.1.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.10.0\"\n      },\n      \"funding\": {\n        \"type\": \"opencollective\",\n        \"url\": \"https://opencollective.com/express\"\n      }\n    },\n    \"node_modules/file-uri-to-path\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/file-uri-to-path/-/file-uri-to-path-1.0.0.tgz\",\n      \"integrity\": \"sha512-0Zt+s3L7Vf1biwWZ29aARiVYLx7iMGnEUl9x33fbB/j3jR81u/O2LbqK+Bm1CDSNDKVtJ/YjwY7TUd5SkeLQLw==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/finalhandler\": {\n      \"version\": \"1.3.1\",\n      \"resolved\": \"https://registry.npmjs.org/finalhandler/-/finalhandler-1.3.1.tgz\",\n      \"integrity\": \"sha512-6BN9trH7bp3qvnrRyzsBz+g3lZxTNZTbVO2EV1CS0WIcDbawYVdYvGflME/9QP0h0pYlCDBCTjYa9nZzMDpyxQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"debug\": \"2.6.9\",\n        \"encodeurl\": \"~2.0.0\",\n        \"escape-html\": \"~1.0.3\",\n        \"on-finished\": \"2.4.1\",\n        \"parseurl\": \"~1.3.3\",\n        \"statuses\": \"2.0.1\",\n        \"unpipe\": \"~1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/forwarded\": {\n      \"version\": \"0.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/forwarded/-/forwarded-0.2.0.tgz\",\n      \"integrity\": \"sha512-buRG0fpBtRHSTCOASe6hD258tEubFoRLb4ZNA6NxMVHNw2gOcwHo9wyablzMzOA5z9xA9L1KNjk/Nt6MT9aYow==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/fresh\": {\n      \"version\": \"0.5.2\",\n      \"resolved\": \"https://registry.npmjs.org/fresh/-/fresh-0.5.2.tgz\",\n      \"integrity\": \"sha512-zJ2mQYM18rEFOudeV4GShTGIQ7RbzA7ozbU9I/XBpm7kqgMywgmylMwXHxZJmkVoYkna9d2pVXVXPdYTP9ej8Q==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/fs-constants\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/fs-constants/-/fs-constants-1.0.0.tgz\",\n      \"integrity\": \"sha512-y6OAwoSIf7FyjMIv94u+b5rdheZEjzR63GTyZJm5qh4Bi+2YgwLCcI/fPFZkL5PSixOt6ZNKm+w+Hfp/Bciwow==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/fs-minipass\": {\n      \"version\": \"2.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/fs-minipass/-/fs-minipass-2.1.0.tgz\",\n      \"integrity\": \"sha512-V/JgOLFCS+R6Vcq0slCuaeWEdNC3ouDlJMNIsacH2VtALiu9mV4LPrHc5cDl8k5aw6J8jwgWWpiTo5RYhmIzvg==\",\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/fs.realpath\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz\",\n      \"integrity\": \"sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/function-bind\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz\",\n      \"integrity\": \"sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==\",\n      \"license\": \"MIT\",\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/gauge\": {\n      \"version\": \"4.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/gauge/-/gauge-4.0.4.tgz\",\n      \"integrity\": \"sha512-f9m+BEN5jkg6a0fZjleidjN51VE1X+mPFQ2DJ0uv1V39oCLCbsGe6yjbBnp7eK7z/+GAon99a3nHuqbuuthyPg==\",\n      \"deprecated\": \"This package is no longer supported.\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"aproba\": \"^1.0.3 || ^2.0.0\",\n        \"color-support\": \"^1.1.3\",\n        \"console-control-strings\": \"^1.1.0\",\n        \"has-unicode\": \"^2.0.1\",\n        \"signal-exit\": \"^3.0.7\",\n        \"string-width\": \"^4.2.3\",\n        \"strip-ansi\": \"^6.0.1\",\n        \"wide-align\": \"^1.1.5\"\n      },\n      \"engines\": {\n        \"node\": \"^12.13.0 || ^14.15.0 || >=16.0.0\"\n      }\n    },\n    \"node_modules/get-intrinsic\": {\n      \"version\": \"1.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz\",\n      \"integrity\": \"sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bind-apply-helpers\": \"^1.0.2\",\n        \"es-define-property\": \"^1.0.1\",\n        \"es-errors\": \"^1.3.0\",\n        \"es-object-atoms\": \"^1.1.1\",\n        \"function-bind\": \"^1.1.2\",\n        \"get-proto\": \"^1.0.1\",\n        \"gopd\": \"^1.2.0\",\n        \"has-symbols\": \"^1.1.0\",\n        \"hasown\": \"^2.0.2\",\n        \"math-intrinsics\": \"^1.1.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/get-proto\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz\",\n      \"integrity\": \"sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"dunder-proto\": \"^1.0.1\",\n        \"es-object-atoms\": \"^1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/github-from-package\": {\n      \"version\": \"0.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/github-from-package/-/github-from-package-0.0.0.tgz\",\n      \"integrity\": \"sha512-SyHy3T1v2NUXn29OsWdxmK6RwHD+vkj3v8en8AOBZ1wBQ/hCAQ5bAQTD02kW4W9tUp/3Qh6J8r9EvntiyCmOOw==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/glob\": {\n      \"version\": \"7.2.3\",\n      \"resolved\": \"https://registry.npmjs.org/glob/-/glob-7.2.3.tgz\",\n      \"integrity\": \"sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==\",\n      \"deprecated\": \"Glob versions prior to v9 are no longer supported\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"fs.realpath\": \"^1.0.0\",\n        \"inflight\": \"^1.0.4\",\n        \"inherits\": \"2\",\n        \"minimatch\": \"^3.1.1\",\n        \"once\": \"^1.3.0\",\n        \"path-is-absolute\": \"^1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \"*\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/isaacs\"\n      }\n    },\n    \"node_modules/gopd\": {\n      \"version\": \"1.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz\",\n      \"integrity\": \"sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/graceful-fs\": {\n      \"version\": \"4.2.11\",\n      \"resolved\": \"https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz\",\n      \"integrity\": \"sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/has-symbols\": {\n      \"version\": \"1.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz\",\n      \"integrity\": \"sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/has-unicode\": {\n      \"version\": \"2.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/has-unicode/-/has-unicode-2.0.1.tgz\",\n      \"integrity\": \"sha512-8Rf9Y83NBReMnx0gFzA8JImQACstCYWUplepDa9xprwwtmgEZUF0h/i5xSA625zB/I37EtrswSST6OXxwaaIJQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/hasown\": {\n      \"version\": \"2.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz\",\n      \"integrity\": \"sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"function-bind\": \"^1.1.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/http-cache-semantics\": {\n      \"version\": \"4.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/http-cache-semantics/-/http-cache-semantics-4.2.0.tgz\",\n      \"integrity\": \"sha512-dTxcvPXqPvXBQpq5dUr6mEMJX4oIEFv6bwom3FDwKRDsuIjjJGANqhBuoAn9c1RQJIdAKav33ED65E2ys+87QQ==\",\n      \"license\": \"BSD-2-Clause\",\n      \"optional\": true\n    },\n    \"node_modules/http-errors\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/http-errors/-/http-errors-2.0.0.tgz\",\n      \"integrity\": \"sha512-FtwrG/euBzaEjYeRqOgly7G0qviiXoJWnvEH2Z1plBdXgbyjv34pHTSb9zoeHMyDy33+DWy5Wt9Wo+TURtOYSQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"depd\": \"2.0.0\",\n        \"inherits\": \"2.0.4\",\n        \"setprototypeof\": \"1.2.0\",\n        \"statuses\": \"2.0.1\",\n        \"toidentifier\": \"1.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/http-proxy-agent\": {\n      \"version\": \"4.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/http-proxy-agent/-/http-proxy-agent-4.0.1.tgz\",\n      \"integrity\": \"sha512-k0zdNgqWTGA6aeIRVpvfVob4fL52dTfaehylg0Y4UvSySvOq/Y+BOyPrgpUrA7HylqvU8vIZGsRuXmspskV0Tg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"@tootallnate/once\": \"1\",\n        \"agent-base\": \"6\",\n        \"debug\": \"4\"\n      },\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/http-proxy-agent/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/http-proxy-agent/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/https-proxy-agent\": {\n      \"version\": \"5.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-5.0.1.tgz\",\n      \"integrity\": \"sha512-dFcAjpTQFgoLMzC2VwU+C/CbS7uRL0lWmxDITmqm7C+7F0Odmj6s9l6alZc6AELXhrnggM2CeWSXHGOdX2YtwA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"agent-base\": \"6\",\n        \"debug\": \"4\"\n      },\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/https-proxy-agent/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/https-proxy-agent/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/humanize-ms\": {\n      \"version\": \"1.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/humanize-ms/-/humanize-ms-1.2.1.tgz\",\n      \"integrity\": \"sha512-Fl70vYtsAFb/C06PTS9dZBo7ihau+Tu/DNCk/OyHhea07S+aeMWpFFkUaXRa8fI+ScZbEI8dfSxwY7gxZ9SAVQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.0.0\"\n      }\n    },\n    \"node_modules/iconv-lite\": {\n      \"version\": \"0.4.24\",\n      \"resolved\": \"https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.4.24.tgz\",\n      \"integrity\": \"sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"safer-buffer\": \">= 2.1.2 < 3\"\n      },\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/ieee754\": {\n      \"version\": \"1.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/ieee754/-/ieee754-1.2.1.tgz\",\n      \"integrity\": \"sha512-dcyqhDvX1C46lXZcVqCpK+FtMRQVdIMN6/Df5js2zouUsqG7I6sFxitIC+7KYK29KdXOLHdu9zL4sFnoVQnqaA==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"BSD-3-Clause\"\n    },\n    \"node_modules/imurmurhash\": {\n      \"version\": \"0.1.4\",\n      \"resolved\": \"https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz\",\n      \"integrity\": \"sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=0.8.19\"\n      }\n    },\n    \"node_modules/indent-string\": {\n      \"version\": \"4.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/indent-string/-/indent-string-4.0.0.tgz\",\n      \"integrity\": \"sha512-EdDDZu4A2OyIK7Lr/2zG+w5jmbuk1DVBnEwREQvBzspBJkCEbRa8GxU1lghYcaGJCnRWibjDXlq779X1/y5xwg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/infer-owner\": {\n      \"version\": \"1.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/infer-owner/-/infer-owner-1.0.4.tgz\",\n      \"integrity\": \"sha512-IClj+Xz94+d7irH5qRyfJonOdfTzuDaifE6ZPWfx0N0+/ATZCbuTPq2prFl526urkQd90WyUKIh1DfBQ2hMz9A==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/inflight\": {\n      \"version\": \"1.0.6\",\n      \"resolved\": \"https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz\",\n      \"integrity\": \"sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==\",\n      \"deprecated\": \"This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"once\": \"^1.3.0\",\n        \"wrappy\": \"1\"\n      }\n    },\n    \"node_modules/inherits\": {\n      \"version\": \"2.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz\",\n      \"integrity\": \"sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/ini\": {\n      \"version\": \"1.3.8\",\n      \"resolved\": \"https://registry.npmjs.org/ini/-/ini-1.3.8.tgz\",\n      \"integrity\": \"sha512-JV/yugV2uzW5iMRSiZAyDtQd+nxtUnjeLt0acNdw98kKLrvuRVyB80tsREOE7yvGVgalhZ6RNXCmEHkUKBKxew==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/ip-address\": {\n      \"version\": \"10.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/ip-address/-/ip-address-10.0.1.tgz\",\n      \"integrity\": \"sha512-NWv9YLW4PoW2B7xtzaS3NCot75m6nK7Icdv0o3lfMceJVRfSoQwqD4wEH5rLwoKJwUiZ/rfpiVBhnaF0FK4HoA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">= 12\"\n      }\n    },\n    \"node_modules/ipaddr.js\": {\n      \"version\": \"1.9.1\",\n      \"resolved\": \"https://registry.npmjs.org/ipaddr.js/-/ipaddr.js-1.9.1.tgz\",\n      \"integrity\": \"sha512-0KI/607xoxSToH7GjN1FfSbLoU0+btTicjsQSWQlh/hZykN8KpmMf7uYwPW3R+akZ6R/w18ZlXSHBYXiYUPO3g==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.10\"\n      }\n    },\n    \"node_modules/is-fullwidth-code-point\": {\n      \"version\": \"3.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz\",\n      \"integrity\": \"sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/is-lambda\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/is-lambda/-/is-lambda-1.0.1.tgz\",\n      \"integrity\": \"sha512-z7CMFGNrENq5iFB9Bqo64Xk6Y9sg+epq1myIcdHaGnbMTYOxvzsEtdYqQUylB7LxfkvgrrjP32T6Ywciio9UIQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/isexe\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz\",\n      \"integrity\": \"sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/lru-cache\": {\n      \"version\": \"6.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/lru-cache/-/lru-cache-6.0.0.tgz\",\n      \"integrity\": \"sha512-Jo6dJ04CmSjuznwJSS3pUeWmd/H0ffTlkXXgwZi+eq1UCmqQwCh+eLsYOYCwY991i2Fah4h1BEMCx4qThGbsiA==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"yallist\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/make-error\": {\n      \"version\": \"1.3.6\",\n      \"resolved\": \"https://registry.npmjs.org/make-error/-/make-error-1.3.6.tgz\",\n      \"integrity\": \"sha512-s8UhlNe7vPKomQhC1qFelMokr/Sc3AgNbso3n74mVPA5LTZwkB9NlXf4XPamLxJE8h0gh73rM94xvwRT2CVInw==\",\n      \"dev\": true,\n      \"license\": \"ISC\"\n    },\n    \"node_modules/make-fetch-happen\": {\n      \"version\": \"9.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/make-fetch-happen/-/make-fetch-happen-9.1.0.tgz\",\n      \"integrity\": \"sha512-+zopwDy7DNknmwPQplem5lAZX/eCOzSvSNNcSKm5eVwTkOBzoktEfXsa9L23J/GIRhxRsaxzkPEhrJEpE2F4Gg==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"agentkeepalive\": \"^4.1.3\",\n        \"cacache\": \"^15.2.0\",\n        \"http-cache-semantics\": \"^4.1.0\",\n        \"http-proxy-agent\": \"^4.0.1\",\n        \"https-proxy-agent\": \"^5.0.0\",\n        \"is-lambda\": \"^1.0.1\",\n        \"lru-cache\": \"^6.0.0\",\n        \"minipass\": \"^3.1.3\",\n        \"minipass-collect\": \"^1.0.2\",\n        \"minipass-fetch\": \"^1.3.2\",\n        \"minipass-flush\": \"^1.0.5\",\n        \"minipass-pipeline\": \"^1.2.4\",\n        \"negotiator\": \"^0.6.2\",\n        \"promise-retry\": \"^2.0.1\",\n        \"socks-proxy-agent\": \"^6.0.0\",\n        \"ssri\": \"^8.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 10\"\n      }\n    },\n    \"node_modules/math-intrinsics\": {\n      \"version\": \"1.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz\",\n      \"integrity\": \"sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      }\n    },\n    \"node_modules/media-typer\": {\n      \"version\": \"0.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/media-typer/-/media-typer-0.3.0.tgz\",\n      \"integrity\": \"sha512-dq+qelQ9akHpcOl/gUVRTxVIOkAJ1wR3QAvb4RsVjS8oVoFjDGTc679wJYmUmknUF5HwMLOgb5O+a3KxfWapPQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/merge-descriptors\": {\n      \"version\": \"1.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/merge-descriptors/-/merge-descriptors-1.0.3.tgz\",\n      \"integrity\": \"sha512-gaNvAS7TZ897/rVaZ0nMtAyxNyi/pdbjbAwUpFQpN70GqnVfOiXpeUUMKRBmzXaSQ8DdTX4/0ms62r2K+hE6mQ==\",\n      \"license\": \"MIT\",\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/methods\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/methods/-/methods-1.1.2.tgz\",\n      \"integrity\": \"sha512-iclAHeNqNm68zFtnZ0e+1L2yUIdvzNoauKU4WBA3VvH/vPFieF7qfRlwUZU+DA9P9bPXIS90ulxoUoCH23sV2w==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/mime\": {\n      \"version\": \"1.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/mime/-/mime-1.6.0.tgz\",\n      \"integrity\": \"sha512-x0Vn8spI+wuJ1O6S7gnbaQg8Pxh4NNHb7KSINmEWKiPE4RKOplvijn+NkmYmmRgP68mc70j2EbeTFRsrswaQeg==\",\n      \"license\": \"MIT\",\n      \"bin\": {\n        \"mime\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=4\"\n      }\n    },\n    \"node_modules/mime-db\": {\n      \"version\": \"1.52.0\",\n      \"resolved\": \"https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz\",\n      \"integrity\": \"sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/mime-types\": {\n      \"version\": \"2.1.35\",\n      \"resolved\": \"https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz\",\n      \"integrity\": \"sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"mime-db\": \"1.52.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/mimic-response\": {\n      \"version\": \"3.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/mimic-response/-/mimic-response-3.1.0.tgz\",\n      \"integrity\": \"sha512-z0yWI+4FDrrweS8Zmt4Ej5HdJmky15+L2e6Wgn3+iK5fWzb6T3fhNFq2+MeTRb064c6Wr4N/wv0DzQTjNzHNGQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=10\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/minimatch\": {\n      \"version\": \"3.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz\",\n      \"integrity\": \"sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"brace-expansion\": \"^1.1.7\"\n      },\n      \"engines\": {\n        \"node\": \"*\"\n      }\n    },\n    \"node_modules/minimist\": {\n      \"version\": \"1.2.8\",\n      \"resolved\": \"https://registry.npmjs.org/minimist/-/minimist-1.2.8.tgz\",\n      \"integrity\": \"sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==\",\n      \"license\": \"MIT\",\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/minipass\": {\n      \"version\": \"3.3.6\",\n      \"resolved\": \"https://registry.npmjs.org/minipass/-/minipass-3.3.6.tgz\",\n      \"integrity\": \"sha512-DxiNidxSEK+tHG6zOIklvNOwm3hvCrbUrdtzY74U6HKTJxvIDfOUL5W5P2Ghd3DTkhhKPYGqeNUIh5qcM4YBfw==\",\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"yallist\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/minipass-collect\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-collect/-/minipass-collect-1.0.2.tgz\",\n      \"integrity\": \"sha512-6T6lH0H8OG9kITm/Jm6tdooIbogG9e0tLgpY6mphXSm/A9u8Nq1ryBG+Qspiub9LjWlBPsPS3tWQ/Botq4FdxA==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/minipass-fetch\": {\n      \"version\": \"1.4.1\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-fetch/-/minipass-fetch-1.4.1.tgz\",\n      \"integrity\": \"sha512-CGH1eblLq26Y15+Azk7ey4xh0J/XfJfrCox5LDJiKqI2Q2iwOLOKrlmIaODiSQS8d18jalF6y2K2ePUm0CmShw==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.1.0\",\n        \"minipass-sized\": \"^1.0.3\",\n        \"minizlib\": \"^2.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      },\n      \"optionalDependencies\": {\n        \"encoding\": \"^0.1.12\"\n      }\n    },\n    \"node_modules/minipass-flush\": {\n      \"version\": \"1.0.5\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-flush/-/minipass-flush-1.0.5.tgz\",\n      \"integrity\": \"sha512-JmQSYYpPUqX5Jyn1mXaRwOda1uQ8HP5KAT/oDSLCzt1BYRhQU0/hDtsB1ufZfEEzMZ9aAVmsBw8+FWsIXlClWw==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/minipass-pipeline\": {\n      \"version\": \"1.2.4\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-pipeline/-/minipass-pipeline-1.2.4.tgz\",\n      \"integrity\": \"sha512-xuIq7cIOt09RPRJ19gdi4b+RiNvDFYe5JH+ggNvBqGqpQXcru3PcRmOZuHBKWK1Txf9+cQ+HMVN4d6z46LZP7A==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/minipass-sized\": {\n      \"version\": \"1.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/minipass-sized/-/minipass-sized-1.0.3.tgz\",\n      \"integrity\": \"sha512-MbkQQ2CTiBMlA2Dm/5cY+9SWFEN8pzzOXi6rlM5Xxq0Yqbda5ZQy9sU75a673FE9ZK0Zsbr6Y5iP6u9nktfg2g==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/minizlib\": {\n      \"version\": \"2.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/minizlib/-/minizlib-2.1.2.tgz\",\n      \"integrity\": \"sha512-bAxsR8BVfj60DWXHE3u30oHzfl4G7khkSuPW+qvpd7jFRHm7dLxOjUk1EHACJ/hxLY8phGJ0YhYHZo7jil7Qdg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"minipass\": \"^3.0.0\",\n        \"yallist\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/mkdirp\": {\n      \"version\": \"1.0.4\",\n      \"resolved\": \"https://registry.npmjs.org/mkdirp/-/mkdirp-1.0.4.tgz\",\n      \"integrity\": \"sha512-vVqVZQyf3WLx2Shd0qJ9xuvqgAyKPLAiqITEtqW0oIUjzo3PePDd6fW9iFz30ef7Ysp/oiWqbhszeGWW2T6Gzw==\",\n      \"license\": \"MIT\",\n      \"bin\": {\n        \"mkdirp\": \"bin/cmd.js\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/mkdirp-classic\": {\n      \"version\": \"0.5.3\",\n      \"resolved\": \"https://registry.npmjs.org/mkdirp-classic/-/mkdirp-classic-0.5.3.tgz\",\n      \"integrity\": \"sha512-gKLcREMhtuZRwRAfqP3RFW+TK4JqApVBtOIftVgjuABpAtpxhPGaDcfvbhNvD0B8iD1oUr/txX35NjcaY6Ns/A==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/ms\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.0.0.tgz\",\n      \"integrity\": \"sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/napi-build-utils\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/napi-build-utils/-/napi-build-utils-2.0.0.tgz\",\n      \"integrity\": \"sha512-GEbrYkbfF7MoNaoh2iGG84Mnf/WZfB0GdGEsM8wz7Expx/LlWf5U8t9nvJKXSp3qr5IsEbK04cBGhol/KwOsWA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/negotiator\": {\n      \"version\": \"0.6.3\",\n      \"resolved\": \"https://registry.npmjs.org/negotiator/-/negotiator-0.6.3.tgz\",\n      \"integrity\": \"sha512-+EUsqGPLsM+j/zdChZjsnX51g4XrHFOIXwfnCVPGlQk/k5giakcKsuxCObBRu6DSm9opw/O6slWbJdghQM4bBg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/node-abi\": {\n      \"version\": \"3.77.0\",\n      \"resolved\": \"https://registry.npmjs.org/node-abi/-/node-abi-3.77.0.tgz\",\n      \"integrity\": \"sha512-DSmt0OEcLoK4i3NuscSbGjOf3bqiDEutejqENSplMSFA/gmB8mkED9G4pKWnPl7MDU4rSHebKPHeitpDfyH0cQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"semver\": \"^7.3.5\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/node-addon-api\": {\n      \"version\": \"7.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/node-addon-api/-/node-addon-api-7.1.1.tgz\",\n      \"integrity\": \"sha512-5m3bsyrjFWE1xf7nz7YXdN4udnVtXK6/Yfgn5qnahL6bCkf2yKt4k3nuTKAtT4r3IG8JNR2ncsIMdZuAzJjHQQ==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/node-gyp\": {\n      \"version\": \"8.4.1\",\n      \"resolved\": \"https://registry.npmjs.org/node-gyp/-/node-gyp-8.4.1.tgz\",\n      \"integrity\": \"sha512-olTJRgUtAb/hOXG0E93wZDs5YiJlgbXxTwQAFHyNlRsXQnYzUaF2aGgujZbw+hR8aF4ZG/rST57bWMWD16jr9w==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"env-paths\": \"^2.2.0\",\n        \"glob\": \"^7.1.4\",\n        \"graceful-fs\": \"^4.2.6\",\n        \"make-fetch-happen\": \"^9.1.0\",\n        \"nopt\": \"^5.0.0\",\n        \"npmlog\": \"^6.0.0\",\n        \"rimraf\": \"^3.0.2\",\n        \"semver\": \"^7.3.5\",\n        \"tar\": \"^6.1.2\",\n        \"which\": \"^2.0.2\"\n      },\n      \"bin\": {\n        \"node-gyp\": \"bin/node-gyp.js\"\n      },\n      \"engines\": {\n        \"node\": \">= 10.12.0\"\n      }\n    },\n    \"node_modules/nopt\": {\n      \"version\": \"5.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/nopt/-/nopt-5.0.0.tgz\",\n      \"integrity\": \"sha512-Tbj67rffqceeLpcRXrT7vKAN8CwfPeIBgM7E6iBkmKLV7bEMwpGgYLGv0jACUsECaa/vuxP0IjEont6umdMgtQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"abbrev\": \"1\"\n      },\n      \"bin\": {\n        \"nopt\": \"bin/nopt.js\"\n      },\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/npmlog\": {\n      \"version\": \"6.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/npmlog/-/npmlog-6.0.2.tgz\",\n      \"integrity\": \"sha512-/vBvz5Jfr9dT/aFWd0FIRf+T/Q2WBsLENygUaFUqstqsycmZAP/t5BvFJTK0viFmSUxiUKTUplWy5vt+rvKIxg==\",\n      \"deprecated\": \"This package is no longer supported.\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"are-we-there-yet\": \"^3.0.0\",\n        \"console-control-strings\": \"^1.1.0\",\n        \"gauge\": \"^4.0.3\",\n        \"set-blocking\": \"^2.0.0\"\n      },\n      \"engines\": {\n        \"node\": \"^12.13.0 || ^14.15.0 || >=16.0.0\"\n      }\n    },\n    \"node_modules/object-assign\": {\n      \"version\": \"4.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz\",\n      \"integrity\": \"sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/object-inspect\": {\n      \"version\": \"1.13.4\",\n      \"resolved\": \"https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.4.tgz\",\n      \"integrity\": \"sha512-W67iLl4J2EXEGTbfeHCffrjDfitvLANg0UlX3wFUUSTx92KXRFegMHUVgSqE+wvhAbi4WqjGg9czysTV2Epbew==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/on-finished\": {\n      \"version\": \"2.4.1\",\n      \"resolved\": \"https://registry.npmjs.org/on-finished/-/on-finished-2.4.1.tgz\",\n      \"integrity\": \"sha512-oVlzkg3ENAhCk2zdv7IJwd/QUD4z2RxRwpkcGY8psCVcCYZNq4wYnVWALHM+brtuJjePWiYF/ClmuDr8Ch5+kg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ee-first\": \"1.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/once\": {\n      \"version\": \"1.4.0\",\n      \"resolved\": \"https://registry.npmjs.org/once/-/once-1.4.0.tgz\",\n      \"integrity\": \"sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==\",\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"wrappy\": \"1\"\n      }\n    },\n    \"node_modules/p-map\": {\n      \"version\": \"4.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/p-map/-/p-map-4.0.0.tgz\",\n      \"integrity\": \"sha512-/bjOqmgETBYB5BoEeGVea8dmvHb2m9GLy1E9W43yeyfP6QQCZGFNa+XRceJEuDB6zqr+gKpIAmlLebMpykw/MQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"aggregate-error\": \"^3.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/sindresorhus\"\n      }\n    },\n    \"node_modules/parseurl\": {\n      \"version\": \"1.3.3\",\n      \"resolved\": \"https://registry.npmjs.org/parseurl/-/parseurl-1.3.3.tgz\",\n      \"integrity\": \"sha512-CiyeOxFT/JZyN5m0z9PfXw4SCBJ6Sygz1Dpl0wqjlhDEGGBP1GnsUVEL0p63hoG1fcj3fHynXi9NYO4nWOL+qQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/path-is-absolute\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz\",\n      \"integrity\": \"sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/path-to-regexp\": {\n      \"version\": \"0.1.12\",\n      \"resolved\": \"https://registry.npmjs.org/path-to-regexp/-/path-to-regexp-0.1.12.tgz\",\n      \"integrity\": \"sha512-RA1GjUVMnvYFxuqovrEqZoxxW5NUZqbwKtYz/Tt7nXerk0LbLblQmrsgdeOxV5SFHf0UDggjS/bSeOZwt1pmEQ==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/prebuild-install\": {\n      \"version\": \"7.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/prebuild-install/-/prebuild-install-7.1.3.tgz\",\n      \"integrity\": \"sha512-8Mf2cbV7x1cXPUILADGI3wuhfqWvtiLA1iclTDbFRZkgRQS0NqsPZphna9V+HyTEadheuPmjaJMsbzKQFOzLug==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"detect-libc\": \"^2.0.0\",\n        \"expand-template\": \"^2.0.3\",\n        \"github-from-package\": \"0.0.0\",\n        \"minimist\": \"^1.2.3\",\n        \"mkdirp-classic\": \"^0.5.3\",\n        \"napi-build-utils\": \"^2.0.0\",\n        \"node-abi\": \"^3.3.0\",\n        \"pump\": \"^3.0.0\",\n        \"rc\": \"^1.2.7\",\n        \"simple-get\": \"^4.0.0\",\n        \"tar-fs\": \"^2.0.0\",\n        \"tunnel-agent\": \"^0.6.0\"\n      },\n      \"bin\": {\n        \"prebuild-install\": \"bin.js\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/promise-inflight\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/promise-inflight/-/promise-inflight-1.0.1.tgz\",\n      \"integrity\": \"sha512-6zWPyEOFaQBJYcGMHBKTKJ3u6TBsnMFOIZSa6ce1e/ZrrsOlnHRHbabMjLiBYKp+n44X9eUI6VUPaukCXHuG4g==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/promise-retry\": {\n      \"version\": \"2.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/promise-retry/-/promise-retry-2.0.1.tgz\",\n      \"integrity\": \"sha512-y+WKFlBR8BGXnsNlIHFGPZmyDf3DFMoLhaflAnyZgV6rG6xu+JwesTo2Q9R6XwYmtmwAFCkAk3e35jEdoeh/3g==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"err-code\": \"^2.0.2\",\n        \"retry\": \"^0.12.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/proxy-addr\": {\n      \"version\": \"2.0.7\",\n      \"resolved\": \"https://registry.npmjs.org/proxy-addr/-/proxy-addr-2.0.7.tgz\",\n      \"integrity\": \"sha512-llQsMLSUDUPT44jdrU/O37qlnifitDP+ZwrmmZcoSKyLKvtZxpyV0n2/bD/N4tBAAZ/gJEdZU7KMraoK1+XYAg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"forwarded\": \"0.2.0\",\n        \"ipaddr.js\": \"1.9.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.10\"\n      }\n    },\n    \"node_modules/pump\": {\n      \"version\": \"3.0.3\",\n      \"resolved\": \"https://registry.npmjs.org/pump/-/pump-3.0.3.tgz\",\n      \"integrity\": \"sha512-todwxLMY7/heScKmntwQG8CXVkWUOdYxIvY2s0VWAAMh/nd8SoYiRaKjlr7+iCs984f2P8zvrfWcDDYVb73NfA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"end-of-stream\": \"^1.1.0\",\n        \"once\": \"^1.3.1\"\n      }\n    },\n    \"node_modules/qs\": {\n      \"version\": \"6.13.0\",\n      \"resolved\": \"https://registry.npmjs.org/qs/-/qs-6.13.0.tgz\",\n      \"integrity\": \"sha512-+38qI9SOr8tfZ4QmJNplMUxqjbe7LKvvZgWdExBOmd+egZTtjLB67Gu0HRX3u/XOq7UU2Nx6nsjvS16Z9uwfpg==\",\n      \"license\": \"BSD-3-Clause\",\n      \"dependencies\": {\n        \"side-channel\": \"^1.0.6\"\n      },\n      \"engines\": {\n        \"node\": \">=0.6\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/range-parser\": {\n      \"version\": \"1.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/range-parser/-/range-parser-1.2.1.tgz\",\n      \"integrity\": \"sha512-Hrgsx+orqoygnmhFbKaHE6c296J+HTAQXoxEF6gNupROmmGJRoyzfG3ccAveqCBrwr/2yxQ5BVd/GTl5agOwSg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/raw-body\": {\n      \"version\": \"2.5.2\",\n      \"resolved\": \"https://registry.npmjs.org/raw-body/-/raw-body-2.5.2.tgz\",\n      \"integrity\": \"sha512-8zGqypfENjCIqGhgXToC8aB2r7YrBX+AQAfIPs/Mlk+BtPTztOvTS01NRW/3Eh60J+a48lt8qsCzirQ6loCVfA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"bytes\": \"3.1.2\",\n        \"http-errors\": \"2.0.0\",\n        \"iconv-lite\": \"0.4.24\",\n        \"unpipe\": \"1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/rc\": {\n      \"version\": \"1.2.8\",\n      \"resolved\": \"https://registry.npmjs.org/rc/-/rc-1.2.8.tgz\",\n      \"integrity\": \"sha512-y3bGgqKj3QBdxLbLkomlohkvsA8gdAiUQlSBJnBhfn+BPxg4bc62d8TcBW15wavDfgexCgccckhcZvywyQYPOw==\",\n      \"license\": \"(BSD-2-Clause OR MIT OR Apache-2.0)\",\n      \"dependencies\": {\n        \"deep-extend\": \"^0.6.0\",\n        \"ini\": \"~1.3.0\",\n        \"minimist\": \"^1.2.0\",\n        \"strip-json-comments\": \"~2.0.1\"\n      },\n      \"bin\": {\n        \"rc\": \"cli.js\"\n      }\n    },\n    \"node_modules/readable-stream\": {\n      \"version\": \"3.6.2\",\n      \"resolved\": \"https://registry.npmjs.org/readable-stream/-/readable-stream-3.6.2.tgz\",\n      \"integrity\": \"sha512-9u/sniCrY3D5WdsERHzHE4G2YCXqoG5FTHUiCC4SIbr6XcLZBY05ya9EKjYek9O5xOAwjGq+1JdGBAS7Q9ScoA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"inherits\": \"^2.0.3\",\n        \"string_decoder\": \"^1.1.1\",\n        \"util-deprecate\": \"^1.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 6\"\n      }\n    },\n    \"node_modules/retry\": {\n      \"version\": \"0.12.0\",\n      \"resolved\": \"https://registry.npmjs.org/retry/-/retry-0.12.0.tgz\",\n      \"integrity\": \"sha512-9LkiTwjUh6rT555DtE9rTX+BKByPfrMzEAtnlEtdEwr3Nkffwiihqe2bWADg+OQRjt9gl6ICdmB/ZFDCGAtSow==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">= 4\"\n      }\n    },\n    \"node_modules/rimraf\": {\n      \"version\": \"3.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz\",\n      \"integrity\": \"sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==\",\n      \"deprecated\": \"Rimraf versions prior to v4 are no longer supported\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"glob\": \"^7.1.3\"\n      },\n      \"bin\": {\n        \"rimraf\": \"bin.js\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/isaacs\"\n      }\n    },\n    \"node_modules/safe-buffer\": {\n      \"version\": \"5.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.2.1.tgz\",\n      \"integrity\": \"sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\"\n    },\n    \"node_modules/safer-buffer\": {\n      \"version\": \"2.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz\",\n      \"integrity\": \"sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/semver\": {\n      \"version\": \"7.7.2\",\n      \"resolved\": \"https://registry.npmjs.org/semver/-/semver-7.7.2.tgz\",\n      \"integrity\": \"sha512-RF0Fw+rO5AMf9MAyaRXI4AV0Ulj5lMHqVxxdSgiVbixSCXoEmmX/jk0CuJw4+3SqroYO9VoUh+HcuJivvtJemA==\",\n      \"license\": \"ISC\",\n      \"bin\": {\n        \"semver\": \"bin/semver.js\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/send\": {\n      \"version\": \"0.19.0\",\n      \"resolved\": \"https://registry.npmjs.org/send/-/send-0.19.0.tgz\",\n      \"integrity\": \"sha512-dW41u5VfLXu8SJh5bwRmyYUbAoSB3c9uQh6L8h/KtsFREPWpbX1lrljJo186Jc4nmci/sGUZ9a0a0J2zgfq2hw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"debug\": \"2.6.9\",\n        \"depd\": \"2.0.0\",\n        \"destroy\": \"1.2.0\",\n        \"encodeurl\": \"~1.0.2\",\n        \"escape-html\": \"~1.0.3\",\n        \"etag\": \"~1.8.1\",\n        \"fresh\": \"0.5.2\",\n        \"http-errors\": \"2.0.0\",\n        \"mime\": \"1.6.0\",\n        \"ms\": \"2.1.3\",\n        \"on-finished\": \"2.4.1\",\n        \"range-parser\": \"~1.2.1\",\n        \"statuses\": \"2.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8.0\"\n      }\n    },\n    \"node_modules/send/node_modules/encodeurl\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/encodeurl/-/encodeurl-1.0.2.tgz\",\n      \"integrity\": \"sha512-TPJXq8JqFaVYm2CWmPvnP2Iyo4ZSM7/QKcSmuMLDObfpH5fi7RUGmd/rTDf+rut/saiDiQEeVTNgAmJEdAOx0w==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/send/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/serve-static\": {\n      \"version\": \"1.16.2\",\n      \"resolved\": \"https://registry.npmjs.org/serve-static/-/serve-static-1.16.2.tgz\",\n      \"integrity\": \"sha512-VqpjJZKadQB/PEbEwvFdO43Ax5dFBZ2UECszz8bQ7pi7wt//PWe1P6MN7eCnjsatYtBT6EuiClbjSWP2WrIoTw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"encodeurl\": \"~2.0.0\",\n        \"escape-html\": \"~1.0.3\",\n        \"parseurl\": \"~1.3.3\",\n        \"send\": \"0.19.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.8.0\"\n      }\n    },\n    \"node_modules/set-blocking\": {\n      \"version\": \"2.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/set-blocking/-/set-blocking-2.0.0.tgz\",\n      \"integrity\": \"sha512-KiKBS8AnWGEyLzofFfmvKwpdPzqiy16LvQfK3yv/fVH7Bj13/wl3JSR1J+rfgRE9q7xUJK4qvgS8raSOeLUehw==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/setprototypeof\": {\n      \"version\": \"1.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.2.0.tgz\",\n      \"integrity\": \"sha512-E5LDX7Wrp85Kil5bhZv46j8jOeboKq5JMmYM3gVGdGH8xFpPWXUMsNrlODCrkoxMEeNi/XZIwuRvY4XNwYMJpw==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/side-channel\": {\n      \"version\": \"1.1.0\",\n      \"resolved\": \"https://registry.npmjs.org/side-channel/-/side-channel-1.1.0.tgz\",\n      \"integrity\": \"sha512-ZX99e6tRweoUXqR+VBrslhda51Nh5MTQwou5tnUDgbtyM0dBgmhEDtWGP/xbKn6hqfPRHujUNwz5fy/wbbhnpw==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"es-errors\": \"^1.3.0\",\n        \"object-inspect\": \"^1.13.3\",\n        \"side-channel-list\": \"^1.0.0\",\n        \"side-channel-map\": \"^1.0.1\",\n        \"side-channel-weakmap\": \"^1.0.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/side-channel-list\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/side-channel-list/-/side-channel-list-1.0.0.tgz\",\n      \"integrity\": \"sha512-FCLHtRD/gnpCiCHEiJLOwdmFP+wzCmDEkc9y7NsYxeF4u7Btsn1ZuwgwJGxImImHicJArLP4R0yX4c2KCrMrTA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"es-errors\": \"^1.3.0\",\n        \"object-inspect\": \"^1.13.3\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/side-channel-map\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/side-channel-map/-/side-channel-map-1.0.1.tgz\",\n      \"integrity\": \"sha512-VCjCNfgMsby3tTdo02nbjtM/ewra6jPHmpThenkTYh8pG9ucZ/1P8So4u4FGBek/BjpOVsDCMoLA/iuBKIFXRA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bound\": \"^1.0.2\",\n        \"es-errors\": \"^1.3.0\",\n        \"get-intrinsic\": \"^1.2.5\",\n        \"object-inspect\": \"^1.13.3\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/side-channel-weakmap\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/side-channel-weakmap/-/side-channel-weakmap-1.0.2.tgz\",\n      \"integrity\": \"sha512-WPS/HvHQTYnHisLo9McqBHOJk2FkHO/tlpvldyrnem4aeQp4hai3gythswg6p01oSoTl58rcpiFAjF2br2Ak2A==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"call-bound\": \"^1.0.2\",\n        \"es-errors\": \"^1.3.0\",\n        \"get-intrinsic\": \"^1.2.5\",\n        \"object-inspect\": \"^1.13.3\",\n        \"side-channel-map\": \"^1.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.4\"\n      },\n      \"funding\": {\n        \"url\": \"https://github.com/sponsors/ljharb\"\n      }\n    },\n    \"node_modules/signal-exit\": {\n      \"version\": \"3.0.7\",\n      \"resolved\": \"https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.7.tgz\",\n      \"integrity\": \"sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true\n    },\n    \"node_modules/simple-concat\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/simple-concat/-/simple-concat-1.0.1.tgz\",\n      \"integrity\": \"sha512-cSFtAPtRhljv69IK0hTVZQ+OfE9nePi/rtJmw5UjHeVyVroEqJXP1sFztKUy1qU+xvz3u/sfYJLa947b7nAN2Q==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\"\n    },\n    \"node_modules/simple-get\": {\n      \"version\": \"4.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/simple-get/-/simple-get-4.0.1.tgz\",\n      \"integrity\": \"sha512-brv7p5WgH0jmQJr1ZDDfKDOSeWWg+OVypG99A/5vYGPqJ6pxiaHLy8nxtFjBA7oMa01ebA9gfh1uMCFqOuXxvA==\",\n      \"funding\": [\n        {\n          \"type\": \"github\",\n          \"url\": \"https://github.com/sponsors/feross\"\n        },\n        {\n          \"type\": \"patreon\",\n          \"url\": \"https://www.patreon.com/feross\"\n        },\n        {\n          \"type\": \"consulting\",\n          \"url\": \"https://feross.org/support\"\n        }\n      ],\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"decompress-response\": \"^6.0.0\",\n        \"once\": \"^1.3.1\",\n        \"simple-concat\": \"^1.0.0\"\n      }\n    },\n    \"node_modules/smart-buffer\": {\n      \"version\": \"4.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/smart-buffer/-/smart-buffer-4.2.0.tgz\",\n      \"integrity\": \"sha512-94hK0Hh8rPqQl2xXc3HsaBoOXKV20MToPkcXvwbISWLEs+64sBq5kFgn2kJDHb1Pry9yrP0dxrCI9RRci7RXKg==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"engines\": {\n        \"node\": \">= 6.0.0\",\n        \"npm\": \">= 3.0.0\"\n      }\n    },\n    \"node_modules/socket.io\": {\n      \"version\": \"4.8.1\",\n      \"resolved\": \"https://registry.npmjs.org/socket.io/-/socket.io-4.8.1.tgz\",\n      \"integrity\": \"sha512-oZ7iUCxph8WYRHHcjBEc9unw3adt5CmSNlppj/5Q4k2RIrhl8Z5yY2Xr4j9zj0+wzVZ0bxmYoGSzKJnRl6A4yg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"accepts\": \"~1.3.4\",\n        \"base64id\": \"~2.0.0\",\n        \"cors\": \"~2.8.5\",\n        \"debug\": \"~4.3.2\",\n        \"engine.io\": \"~6.6.0\",\n        \"socket.io-adapter\": \"~2.5.2\",\n        \"socket.io-parser\": \"~4.2.4\"\n      },\n      \"engines\": {\n        \"node\": \">=10.2.0\"\n      }\n    },\n    \"node_modules/socket.io-adapter\": {\n      \"version\": \"2.5.5\",\n      \"resolved\": \"https://registry.npmjs.org/socket.io-adapter/-/socket.io-adapter-2.5.5.tgz\",\n      \"integrity\": \"sha512-eLDQas5dzPgOWCk9GuuJC2lBqItuhKI4uxGgo9aIV7MYbk2h9Q6uULEh8WBzThoI7l+qU9Ast9fVUmkqPP9wYg==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"debug\": \"~4.3.4\",\n        \"ws\": \"~8.17.1\"\n      }\n    },\n    \"node_modules/socket.io-adapter/node_modules/debug\": {\n      \"version\": \"4.3.7\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.3.7.tgz\",\n      \"integrity\": \"sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/socket.io-adapter/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/socket.io-parser\": {\n      \"version\": \"4.2.4\",\n      \"resolved\": \"https://registry.npmjs.org/socket.io-parser/-/socket.io-parser-4.2.4.tgz\",\n      \"integrity\": \"sha512-/GbIKmo8ioc+NIWIhwdecY0ge+qVBSMdgxGygevmdHj24bsfgtCmcUUcQ5ZzcylGFHsN3k4HB4Cgkl96KVnuew==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@socket.io/component-emitter\": \"~3.1.0\",\n        \"debug\": \"~4.3.1\"\n      },\n      \"engines\": {\n        \"node\": \">=10.0.0\"\n      }\n    },\n    \"node_modules/socket.io-parser/node_modules/debug\": {\n      \"version\": \"4.3.7\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.3.7.tgz\",\n      \"integrity\": \"sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/socket.io-parser/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/socket.io/node_modules/debug\": {\n      \"version\": \"4.3.7\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.3.7.tgz\",\n      \"integrity\": \"sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/socket.io/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/socks\": {\n      \"version\": \"2.8.7\",\n      \"resolved\": \"https://registry.npmjs.org/socks/-/socks-2.8.7.tgz\",\n      \"integrity\": \"sha512-HLpt+uLy/pxB+bum/9DzAgiKS8CX1EvbWxI4zlmgGCExImLdiad2iCwXT5Z4c9c3Eq8rP2318mPW2c+QbtjK8A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ip-address\": \"^10.0.1\",\n        \"smart-buffer\": \"^4.2.0\"\n      },\n      \"engines\": {\n        \"node\": \">= 10.0.0\",\n        \"npm\": \">= 3.0.0\"\n      }\n    },\n    \"node_modules/socks-proxy-agent\": {\n      \"version\": \"6.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/socks-proxy-agent/-/socks-proxy-agent-6.2.1.tgz\",\n      \"integrity\": \"sha512-a6KW9G+6B3nWZ1yB8G7pJwL3ggLy1uTzKAgCb7ttblwqdz9fMGJUuTy3uFzEP48FAs9FLILlmzDlE2JJhVQaXQ==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"agent-base\": \"^6.0.2\",\n        \"debug\": \"^4.3.3\",\n        \"socks\": \"^2.6.2\"\n      },\n      \"engines\": {\n        \"node\": \">= 10\"\n      }\n    },\n    \"node_modules/socks-proxy-agent/node_modules/debug\": {\n      \"version\": \"4.4.3\",\n      \"resolved\": \"https://registry.npmjs.org/debug/-/debug-4.4.3.tgz\",\n      \"integrity\": \"sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ms\": \"^2.1.3\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0\"\n      },\n      \"peerDependenciesMeta\": {\n        \"supports-color\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/socks-proxy-agent/node_modules/ms\": {\n      \"version\": \"2.1.3\",\n      \"resolved\": \"https://registry.npmjs.org/ms/-/ms-2.1.3.tgz\",\n      \"integrity\": \"sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==\",\n      \"license\": \"MIT\",\n      \"optional\": true\n    },\n    \"node_modules/sqlite\": {\n      \"version\": \"5.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/sqlite/-/sqlite-5.1.1.tgz\",\n      \"integrity\": \"sha512-oBkezXa2hnkfuJwUo44Hl9hS3er+YFtueifoajrgidvqsJRQFpc5fKoAkAor1O5ZnLoa28GBScfHXs8j0K358Q==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/sqlite3\": {\n      \"version\": \"5.1.7\",\n      \"resolved\": \"https://registry.npmjs.org/sqlite3/-/sqlite3-5.1.7.tgz\",\n      \"integrity\": \"sha512-GGIyOiFaG+TUra3JIfkI/zGP8yZYLPQ0pl1bH+ODjiX57sPhrLU5sQJn1y9bDKZUFYkX1crlrPfSYt0BKKdkog==\",\n      \"hasInstallScript\": true,\n      \"license\": \"BSD-3-Clause\",\n      \"dependencies\": {\n        \"bindings\": \"^1.5.0\",\n        \"node-addon-api\": \"^7.0.0\",\n        \"prebuild-install\": \"^7.1.1\",\n        \"tar\": \"^6.1.11\"\n      },\n      \"optionalDependencies\": {\n        \"node-gyp\": \"8.x\"\n      },\n      \"peerDependencies\": {\n        \"node-gyp\": \"8.x\"\n      },\n      \"peerDependenciesMeta\": {\n        \"node-gyp\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/ssri\": {\n      \"version\": \"8.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/ssri/-/ssri-8.0.1.tgz\",\n      \"integrity\": \"sha512-97qShzy1AiyxvPNIkLWoGua7xoQzzPjQ0HAH4B0rWKo7SZ6USuPcrUiAFrws0UH8RrbWmgq3LMTObhPIHbbBeQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"minipass\": \"^3.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/statuses\": {\n      \"version\": \"2.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/statuses/-/statuses-2.0.1.tgz\",\n      \"integrity\": \"sha512-RwNA9Z/7PrK06rYLIzFMlaF+l73iwpzsqRIFgbMLbTcLD6cOao82TaWefPXQvB2fOC4AjuYSEndS7N/mTCbkdQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/string_decoder\": {\n      \"version\": \"1.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/string_decoder/-/string_decoder-1.3.0.tgz\",\n      \"integrity\": \"sha512-hkRX8U1WjJFd8LsDJ2yQ/wWWxaopEsABU1XfkM8A+j0+85JAGppt16cr1Whg6KIbb4okU6Mql6BOj+uup/wKeA==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"safe-buffer\": \"~5.2.0\"\n      }\n    },\n    \"node_modules/string-width\": {\n      \"version\": \"4.2.3\",\n      \"resolved\": \"https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz\",\n      \"integrity\": \"sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"emoji-regex\": \"^8.0.0\",\n        \"is-fullwidth-code-point\": \"^3.0.0\",\n        \"strip-ansi\": \"^6.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/strip-ansi\": {\n      \"version\": \"6.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz\",\n      \"integrity\": \"sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==\",\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"ansi-regex\": \"^5.0.1\"\n      },\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/strip-json-comments\": {\n      \"version\": \"2.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-2.0.1.tgz\",\n      \"integrity\": \"sha512-4gB8na07fecVVkOI6Rs4e7T6NOTki5EmL7TUduTs6bu3EdnSycntVJ4re8kgZA+wx9IueI2Y11bfbgwtzuE0KQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.10.0\"\n      }\n    },\n    \"node_modules/tar\": {\n      \"version\": \"6.2.1\",\n      \"resolved\": \"https://registry.npmjs.org/tar/-/tar-6.2.1.tgz\",\n      \"integrity\": \"sha512-DZ4yORTwrbTj/7MZYq2w+/ZFdI6OZ/f9SFHR+71gIVUZhOQPHzVCLpvRnPgyaMpfWxxk/4ONva3GQSyNIKRv6A==\",\n      \"license\": \"ISC\",\n      \"dependencies\": {\n        \"chownr\": \"^2.0.0\",\n        \"fs-minipass\": \"^2.0.0\",\n        \"minipass\": \"^5.0.0\",\n        \"minizlib\": \"^2.1.1\",\n        \"mkdirp\": \"^1.0.3\",\n        \"yallist\": \"^4.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=10\"\n      }\n    },\n    \"node_modules/tar-fs\": {\n      \"version\": \"2.1.4\",\n      \"resolved\": \"https://registry.npmjs.org/tar-fs/-/tar-fs-2.1.4.tgz\",\n      \"integrity\": \"sha512-mDAjwmZdh7LTT6pNleZ05Yt65HC3E+NiQzl672vQG38jIrehtJk/J3mNwIg+vShQPcLF/LV7CMnDW6vjj6sfYQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"chownr\": \"^1.1.1\",\n        \"mkdirp-classic\": \"^0.5.2\",\n        \"pump\": \"^3.0.0\",\n        \"tar-stream\": \"^2.1.4\"\n      }\n    },\n    \"node_modules/tar-fs/node_modules/chownr\": {\n      \"version\": \"1.1.4\",\n      \"resolved\": \"https://registry.npmjs.org/chownr/-/chownr-1.1.4.tgz\",\n      \"integrity\": \"sha512-jJ0bqzaylmJtVnNgzTeSOs8DPavpbYgEr/b0YL8/2GO3xJEhInFmhKMUnEJQjZumK7KXGFhUy89PrsJWlakBVg==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/tar-stream\": {\n      \"version\": \"2.2.0\",\n      \"resolved\": \"https://registry.npmjs.org/tar-stream/-/tar-stream-2.2.0.tgz\",\n      \"integrity\": \"sha512-ujeqbceABgwMZxEJnk2HDY2DlnUZ+9oEcb1KzTVfYHio0UE6dG71n60d8D2I4qNvleWrrXpmjpt7vZeF1LnMZQ==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"bl\": \"^4.0.3\",\n        \"end-of-stream\": \"^1.4.1\",\n        \"fs-constants\": \"^1.0.0\",\n        \"inherits\": \"^2.0.3\",\n        \"readable-stream\": \"^3.1.1\"\n      },\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    },\n    \"node_modules/tar/node_modules/minipass\": {\n      \"version\": \"5.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/minipass/-/minipass-5.0.0.tgz\",\n      \"integrity\": \"sha512-3FnjYuehv9k6ovOEbyOswadCDPX1piCfhV8ncmYtHOjuPwylVWsghTLo7rabjC3Rx5xD4HDx8Wm1xnMF7S5qFQ==\",\n      \"license\": \"ISC\",\n      \"engines\": {\n        \"node\": \">=8\"\n      }\n    },\n    \"node_modules/toidentifier\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/toidentifier/-/toidentifier-1.0.1.tgz\",\n      \"integrity\": \"sha512-o5sSPKEkg/DIQNmH43V0/uerLrpzVedkUh8tGNvaeXpfpuwjKenlSox/2O/BTlZUtEe+JG7s5YhEz608PlAHRA==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=0.6\"\n      }\n    },\n    \"node_modules/ts-node\": {\n      \"version\": \"10.9.2\",\n      \"resolved\": \"https://registry.npmjs.org/ts-node/-/ts-node-10.9.2.tgz\",\n      \"integrity\": \"sha512-f0FFpIdcHgn8zcPSbf1dRevwt047YMnaiJM3u2w2RewrB+fob/zePZcrOyQoLMMO7aBIddLcQIEK5dYjkLnGrQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"@cspotcode/source-map-support\": \"^0.8.0\",\n        \"@tsconfig/node10\": \"^1.0.7\",\n        \"@tsconfig/node12\": \"^1.0.7\",\n        \"@tsconfig/node14\": \"^1.0.0\",\n        \"@tsconfig/node16\": \"^1.0.2\",\n        \"acorn\": \"^8.4.1\",\n        \"acorn-walk\": \"^8.1.1\",\n        \"arg\": \"^4.1.0\",\n        \"create-require\": \"^1.1.0\",\n        \"diff\": \"^4.0.1\",\n        \"make-error\": \"^1.1.1\",\n        \"v8-compile-cache-lib\": \"^3.0.1\",\n        \"yn\": \"3.1.1\"\n      },\n      \"bin\": {\n        \"ts-node\": \"dist/bin.js\",\n        \"ts-node-cwd\": \"dist/bin-cwd.js\",\n        \"ts-node-esm\": \"dist/bin-esm.js\",\n        \"ts-node-script\": \"dist/bin-script.js\",\n        \"ts-node-transpile-only\": \"dist/bin-transpile.js\",\n        \"ts-script\": \"dist/bin-script-deprecated.js\"\n      },\n      \"peerDependencies\": {\n        \"@swc/core\": \">=1.2.50\",\n        \"@swc/wasm\": \">=1.2.50\",\n        \"@types/node\": \"*\",\n        \"typescript\": \">=2.7\"\n      },\n      \"peerDependenciesMeta\": {\n        \"@swc/core\": {\n          \"optional\": true\n        },\n        \"@swc/wasm\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/tunnel-agent\": {\n      \"version\": \"0.6.0\",\n      \"resolved\": \"https://registry.npmjs.org/tunnel-agent/-/tunnel-agent-0.6.0.tgz\",\n      \"integrity\": \"sha512-McnNiV1l8RYeY8tBgEpuodCC1mLUdbSN+CYBL7kJsJNInOP8UjDDEwdk6Mw60vdLLrr5NHKZhMAOSrR2NZuQ+w==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"safe-buffer\": \"^5.0.1\"\n      },\n      \"engines\": {\n        \"node\": \"*\"\n      }\n    },\n    \"node_modules/type-is\": {\n      \"version\": \"1.6.18\",\n      \"resolved\": \"https://registry.npmjs.org/type-is/-/type-is-1.6.18.tgz\",\n      \"integrity\": \"sha512-TkRKr9sUTxEH8MdfuCSP7VizJyzRNMjj2J2do2Jr3Kym598JVdEksuzPQCnlFPW4ky9Q+iA+ma9BGm06XQBy8g==\",\n      \"license\": \"MIT\",\n      \"dependencies\": {\n        \"media-typer\": \"0.3.0\",\n        \"mime-types\": \"~2.1.24\"\n      },\n      \"engines\": {\n        \"node\": \">= 0.6\"\n      }\n    },\n    \"node_modules/typescript\": {\n      \"version\": \"5.9.2\",\n      \"resolved\": \"https://registry.npmjs.org/typescript/-/typescript-5.9.2.tgz\",\n      \"integrity\": \"sha512-CWBzXQrc/qOkhidw1OzBTQuYRbfyxDXJMVJ1XNwUHGROVmuaeiEm3OslpZ1RV96d7SKKjZKrSJu3+t/xlw3R9A==\",\n      \"dev\": true,\n      \"license\": \"Apache-2.0\",\n      \"peer\": true,\n      \"bin\": {\n        \"tsc\": \"bin/tsc\",\n        \"tsserver\": \"bin/tsserver\"\n      },\n      \"engines\": {\n        \"node\": \">=14.17\"\n      }\n    },\n    \"node_modules/undici-types\": {\n      \"version\": \"6.21.0\",\n      \"resolved\": \"https://registry.npmjs.org/undici-types/-/undici-types-6.21.0.tgz\",\n      \"integrity\": \"sha512-iwDZqg0QAGrg9Rav5H4n0M64c3mkR59cJ6wQp+7C4nI0gsmExaedaYLNO44eT4AtBBwjbTiGPMlt2Md0T9H9JQ==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/unique-filename\": {\n      \"version\": \"1.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/unique-filename/-/unique-filename-1.1.1.tgz\",\n      \"integrity\": \"sha512-Vmp0jIp2ln35UTXuryvjzkjGdRyf9b2lTXuSYUiPmzRcl3FDtYqAwOnTJkAngD9SWhnoJzDbTKwaOrZ+STtxNQ==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"unique-slug\": \"^2.0.0\"\n      }\n    },\n    \"node_modules/unique-slug\": {\n      \"version\": \"2.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/unique-slug/-/unique-slug-2.0.2.tgz\",\n      \"integrity\": \"sha512-zoWr9ObaxALD3DOPfjPSqxt4fnZiWblxHIgeWqW8x7UqDzEtHEQLzji2cuJYQFCU6KmoJikOYAZlrTHHebjx2w==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"imurmurhash\": \"^0.1.4\"\n      }\n    },\n    \"node_modules/unpipe\": {\n      \"version\": \"1.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/unpipe/-/unpipe-1.0.0.tgz\",\n      \"integrity\": \"sha512-pjy2bYhSsufwWlKwPc+l3cN7+wuJlK6uz0YdJEOlQDbl6jo/YlPi4mb8agUkVC8BF7V8NuzeyPNqRksA3hztKQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/util-deprecate\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz\",\n      \"integrity\": \"sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==\",\n      \"license\": \"MIT\"\n    },\n    \"node_modules/utils-merge\": {\n      \"version\": \"1.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/utils-merge/-/utils-merge-1.0.1.tgz\",\n      \"integrity\": \"sha512-pMZTvIkT1d+TFGvDOqodOclx0QWkkgi6Tdoa8gC8ffGAAqz9pzPTZWAybbsHHoED/ztMtkv/VoYTYyShUn81hA==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.4.0\"\n      }\n    },\n    \"node_modules/v8-compile-cache-lib\": {\n      \"version\": \"3.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/v8-compile-cache-lib/-/v8-compile-cache-lib-3.0.1.tgz\",\n      \"integrity\": \"sha512-wa7YjyUGfNZngI/vtK0UHAN+lgDCxBPCylVXGp0zu59Fz5aiGtNXaq3DhIov063MorB+VfufLh3JlF2KdTK3xg==\",\n      \"dev\": true,\n      \"license\": \"MIT\"\n    },\n    \"node_modules/vary\": {\n      \"version\": \"1.1.2\",\n      \"resolved\": \"https://registry.npmjs.org/vary/-/vary-1.1.2.tgz\",\n      \"integrity\": \"sha512-BNGbWLfd0eUPabhkXUVm0j8uuvREyTh5ovRa/dyow/BqAbZJyC+5fU+IzQOzmAKzYqYRAISoRhdQr3eIZ/PXqg==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">= 0.8\"\n      }\n    },\n    \"node_modules/which\": {\n      \"version\": \"2.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/which/-/which-2.0.2.tgz\",\n      \"integrity\": \"sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"isexe\": \"^2.0.0\"\n      },\n      \"bin\": {\n        \"node-which\": \"bin/node-which\"\n      },\n      \"engines\": {\n        \"node\": \">= 8\"\n      }\n    },\n    \"node_modules/wide-align\": {\n      \"version\": \"1.1.5\",\n      \"resolved\": \"https://registry.npmjs.org/wide-align/-/wide-align-1.1.5.tgz\",\n      \"integrity\": \"sha512-eDMORYaPNZ4sQIuuYPDHdQvf4gyCF9rEEV/yPxGfwPkRodwEgiMUUXTx/dex+Me0wxx53S+NgUHaP7y3MGlDmg==\",\n      \"license\": \"ISC\",\n      \"optional\": true,\n      \"dependencies\": {\n        \"string-width\": \"^1.0.2 || 2 || 3 || 4\"\n      }\n    },\n    \"node_modules/wrappy\": {\n      \"version\": \"1.0.2\",\n      \"resolved\": \"https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz\",\n      \"integrity\": \"sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/ws\": {\n      \"version\": \"8.17.1\",\n      \"resolved\": \"https://registry.npmjs.org/ws/-/ws-8.17.1.tgz\",\n      \"integrity\": \"sha512-6XQFvXTkbfUOZOKKILFG1PDK2NDQs4azKQl26T0YS5CxqWLgXajbPZ+h4gZekJyRqFU8pvnbAbbs/3TgRPy+GQ==\",\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=10.0.0\"\n      },\n      \"peerDependencies\": {\n        \"bufferutil\": \"^4.0.1\",\n        \"utf-8-validate\": \">=5.0.2\"\n      },\n      \"peerDependenciesMeta\": {\n        \"bufferutil\": {\n          \"optional\": true\n        },\n        \"utf-8-validate\": {\n          \"optional\": true\n        }\n      }\n    },\n    \"node_modules/yallist\": {\n      \"version\": \"4.0.0\",\n      \"resolved\": \"https://registry.npmjs.org/yallist/-/yallist-4.0.0.tgz\",\n      \"integrity\": \"sha512-3wdGidZyq5PB084XLES5TpOSRA3wjXAlIWMhum2kRcv/41Sn2emQ0dycQW4uZXLejwKvg6EsvbdlVL+FYEct7A==\",\n      \"license\": \"ISC\"\n    },\n    \"node_modules/yn\": {\n      \"version\": \"3.1.1\",\n      \"resolved\": \"https://registry.npmjs.org/yn/-/yn-3.1.1.tgz\",\n      \"integrity\": \"sha512-Ux4ygGWsu2c7isFWe8Yu1YluJmqVhxqK2cLXNQA5AcC3QfbGNpM7fu0Y8b/z16pXLnFxZYvWhd3fhBY9DLmC6Q==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=6\"\n      }\n    }\n  }\n}\n",
    "web_platform/api_gateway/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"commonjs\",\n    \"lib\": [\"ES2020\"],\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}",
    "web_platform/frontend/app/layout.tsx": "// web_platform/frontend/app/layout.tsx\nimport './globals.css';\nimport type { Metadata } from 'next';\nimport { Inter } from 'next/font/google';\nimport Providers from './Providers';\n\nconst inter = Inter({ subsets: ['latin'] });\n\nexport const metadata: Metadata = {\n  title: 'Fortuna',\n  description: 'Real-time horse racing analysis.',\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={`${inter.className} bg-white text-gray-900 dark:bg-gray-900 dark:text-gray-100`}>\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}",
    "web_platform/frontend/public/manifest.json": "{\n  \"name\": \"Fortuna Faucet Command Deck\",\n  \"short_name\": \"Fortuna\",\n  \"description\": \"Real-time racing analysis.\",\n  \"start_url\": \"/\",\n  \"display\": \"standalone\",\n  \"background_color\": \"#1a202c\",\n  \"theme_color\": \"#1a202c\",\n  \"icons\": [\n    {\n      \"src\": \"/icons/icon-192x192.png\",\n      \"sizes\": \"192x192\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/icon-512x512.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\"\n    }\n  ]\n}\n",
    "web_platform/frontend/public/sw.js": "if(!self.define){let e,s={};const a=(a,n)=>(a=new URL(a+\".js\",n).href,s[a]||new Promise(s=>{if(\"document\"in self){const e=document.createElement(\"script\");e.src=a,e.onload=s,document.head.appendChild(e)}else e=a,importScripts(a),s()}).then(()=>{let e=s[a];if(!e)throw new Error(`Module ${a} didn\u2019t register its module`);return e}));self.define=(n,t)=>{const i=e||(\"document\"in self?document.currentScript.src:\"\")||location.href;if(s[i])return;let c={};const r=e=>a(e,i),o={module:{uri:i},exports:c,require:r};s[i]=Promise.all(n.map(e=>o[e]||r(e))).then(e=>(t(...e),c))}}define([\"./workbox-4754cb34\"],function(e){\"use strict\";importScripts(),self.skipWaiting(),e.clientsClaim(),e.precacheAndRoute([{url:\"/_next/app-build-manifest.json\",revision:\"b6130f23369e5df052a4061c412f24fa\"},{url:\"/_next/static/YkCCvmjhdkIswKuIgvFNH/_buildManifest.js\",revision:\"c155cce658e53418dec34664328b51ac\"},{url:\"/_next/static/YkCCvmjhdkIswKuIgvFNH/_ssgManifest.js\",revision:\"b6652df95db52feb4daf4eca35380933\"},{url:\"/_next/static/chunks/117-6326cd814d964913.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/816-7254031126ac0a96.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/928.d7f641058b89a54a.js\",revision:\"d7f641058b89a54a\"},{url:\"/_next/static/chunks/app/_not-found/page-e7dc36cd5a340c38.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/app/layout-605479d07717f01e.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/app/page-a2c385e93bfc2dac.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/fd9d1056-af804af0be509bea.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/framework-f66176bb897dc684.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/main-8563e00d234bd632.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/main-app-e0b3e4e952d25145.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/pages/_app-72b849fbd24ac258.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/pages/_error-7ba65e1336b92748.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/polyfills-42372ed130431b0a.js\",revision:\"846118c33b2c0e922d7b3a7676f81f6f\"},{url:\"/_next/static/chunks/webpack-d92cdde7bb2319ca.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/css/a55e4893d0564dbf.css\",revision:\"a55e4893d0564dbf\"},{url:\"/_next/static/media/19cfc7226ec3afaa-s.woff2\",revision:\"9dda5cfc9a46f256d0e131bb535e46f8\"},{url:\"/_next/static/media/21350d82a1f187e9-s.woff2\",revision:\"4e2553027f1d60eff32898367dd4d541\"},{url:\"/_next/static/media/8e9860b6e62d6359-s.woff2\",revision:\"01ba6c2a184b8cba08b0d57167664d75\"},{url:\"/_next/static/media/ba9851c3c22cd980-s.woff2\",revision:\"9e494903d6b0ffec1a1e14d34427d44d\"},{url:\"/_next/static/media/c5fe6dc8356a8c31-s.woff2\",revision:\"027a89e9ab733a145db70f09b8a18b42\"},{url:\"/_next/static/media/df0a9ae256c0569c-s.woff2\",revision:\"d54db44de5ccb18886ece2fda72bdfe0\"},{url:\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",revision:\"65850a373e258f1c897a2b3d75eb74de\"},{url:\"/manifest.json\",revision:\"23bffdb04aba9b85948642cffa772eae\"}],{ignoreURLParametersMatching:[]}),e.cleanupOutdatedCaches(),e.registerRoute(\"/\",new e.NetworkFirst({cacheName:\"start-url\",plugins:[{cacheWillUpdate:async({request:e,response:s,event:a,state:n})=>s&&\"opaqueredirect\"===s.type?new Response(s.body,{status:200,statusText:\"OK\",headers:s.headers}):s}]}),\"GET\"),e.registerRoute(/^https:\\/\\/fonts\\.(?:gstatic)\\.com\\/.*/i,new e.CacheFirst({cacheName:\"google-fonts-webfonts\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:31536e3})]}),\"GET\"),e.registerRoute(/^https:\\/\\/fonts\\.(?:googleapis)\\.com\\/.*/i,new e.StaleWhileRevalidate({cacheName:\"google-fonts-stylesheets\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:604800})]}),\"GET\"),e.registerRoute(/\\.(?:eot|otf|ttc|ttf|woff|woff2|font.css)$/i,new e.StaleWhileRevalidate({cacheName:\"static-font-assets\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:604800})]}),\"GET\"),e.registerRoute(/\\.(?:jpg|jpeg|gif|png|svg|ico|webp)$/i,new e.StaleWhileRevalidate({cacheName:\"static-image-assets\",plugins:[new e.ExpirationPlugin({maxEntries:64,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\/_next\\/image\\?url=.+$/i,new e.StaleWhileRevalidate({cacheName:\"next-image\",plugins:[new e.ExpirationPlugin({maxEntries:64,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:mp3|wav|ogg)$/i,new e.CacheFirst({cacheName:\"static-audio-assets\",plugins:[new e.RangeRequestsPlugin,new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:mp4)$/i,new e.CacheFirst({cacheName:\"static-video-assets\",plugins:[new e.RangeRequestsPlugin,new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:js)$/i,new e.StaleWhileRevalidate({cacheName:\"static-js-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:css|less)$/i,new e.StaleWhileRevalidate({cacheName:\"static-style-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\/_next\\/data\\/.+\\/.+\\.json$/i,new e.StaleWhileRevalidate({cacheName:\"next-data\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:json|xml|csv)$/i,new e.NetworkFirst({cacheName:\"static-data-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>{if(!(self.origin===e.origin))return!1;const s=e.pathname;return!s.startsWith(\"/api/auth/\")&&!!s.startsWith(\"/api/\")},new e.NetworkFirst({cacheName:\"apis\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:16,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>{if(!(self.origin===e.origin))return!1;return!e.pathname.startsWith(\"/api/\")},new e.NetworkFirst({cacheName:\"others\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>!(self.origin===e.origin),new e.NetworkFirst({cacheName:\"cross-origin\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:3600})]}),\"GET\")});\n",
    "web_platform/frontend/src/components/ErrorDisplay.tsx": "// web_platform/frontend/src/components/ErrorDisplay.tsx\n'use client';\n\nimport React from 'react';\n\ninterface ErrorInfo {\n  message: string;\n  suggestion: string;\n  details?: string;\n}\n\ninterface ErrorDisplayProps {\n  error: ErrorInfo;\n}\n\nexport const ErrorDisplay: React.FC<ErrorDisplayProps> = ({ error }) => {\n  return (\n    <div className=\"bg-red-900/20 border border-red-500/30 text-white rounded-lg p-6 max-w-2xl mx-auto my-8\">\n      <div className=\"flex items-center mb-4\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-8 w-8 text-red-400 mr-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n          <path fillRule=\"evenodd\" d=\"M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z\" clipRule=\"evenodd\" />\n        </svg>\n        <h2 className=\"text-2xl font-bold text-red-400\">An Error Occurred</h2>\n      </div>\n      <p className=\"text-lg text-slate-300 mb-2\">{error.message}</p>\n      <p className=\"text-slate-400 mb-6\">{error.suggestion}</p>\n      {error.details && (\n        <details className=\"bg-slate-800/50 rounded-lg p-4\">\n          <summary className=\"cursor-pointer text-sm text-slate-500 hover:text-white\">\n            Technical Details\n          </summary>\n          <pre className=\"text-xs text-slate-400 mt-2 p-2 bg-black/30 rounded overflow-x-auto\">\n            <code>{error.details}</code>\n          </pre>\n        </details>\n      )}\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/RaceFilters.tsx": "// web_platform/frontend/src/components/RaceFilters.tsx\n'use client';\n\nimport { useState, useCallback } from 'react';\nimport { Settings, RotateCcw } from 'lucide-react';\n\ninterface FilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nexport interface RaceFiltersProps {\n  onParamsChange: (params: FilterParams) => void;\n  isLoading: boolean;\n  refetch: () => void;\n}\n\nconst DEFAULT_PARAMS: FilterParams = {\n  maxFieldSize: 10,\n  minFavoriteOdds: 2.5,\n  minSecondFavoriteOdds: 4.0,\n};\n\nexport function RaceFilters({ onParamsChange, isLoading, refetch }: RaceFiltersProps) {\n  const [params, setParams] = useState<FilterParams>(DEFAULT_PARAMS);\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // Handle individual parameter changes\n  const handleChange = useCallback((key: keyof FilterParams, value: number) => {\n    setParams(prev => {\n      const updated = { ...prev, [key]: value };\n      onParamsChange(updated);\n      return updated;\n    });\n    // Debounce the refetch call\n    const timer = setTimeout(() => {\n      refetch();\n    }, 500);\n    return () => clearTimeout(timer);\n  }, [onParamsChange, refetch]);\n\n  // Reset to defaults\n  const handleReset = useCallback(() => {\n    setParams(DEFAULT_PARAMS);\n    onParamsChange(DEFAULT_PARAMS);\n    refetch();\n  }, [onParamsChange, refetch]);\n\n  return (\n    <div className=\"bg-gradient-to-r from-slate-800 to-slate-900 rounded-lg p-4 mb-6 border border-slate-700\">\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-2\">\n          <Settings className=\"w-5 h-5 text-amber-500\" />\n          <h3 className=\"text-lg font-semibold text-white\">Race Filters</h3>\n        </div>\n        <button\n          onClick={() => setIsExpanded(!isExpanded)}\n          className=\"text-sm text-slate-400 hover:text-slate-200 transition\"\n        >\n          {isExpanded ? 'Hide' : 'Show'}\n        </button>\n      </div>\n\n      {isExpanded && (\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 pt-4 border-t border-slate-700\">\n          {/* Max Field Size */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Max Field Size\n              <span className=\"text-amber-500 ml-2\">{params.maxFieldSize}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2\"\n              max=\"20\"\n              value={params.maxFieldSize}\n              onChange={(e) => handleChange('maxFieldSize', parseInt(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Filters races with larger fields</p>\n          </div>\n\n          {/* Min Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"1.5\"\n              max=\"5\"\n              step=\"0.1\"\n              value={params.minFavoriteOdds}\n              onChange={(e) => handleChange('minFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = pickier favorites</p>\n          </div>\n\n          {/* Min Second Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min 2nd Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minSecondFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2.0\"\n              max=\"8\"\n              step=\"0.1\"\n              value={params.minSecondFavoriteOdds}\n              onChange={(e) => handleChange('minSecondFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = better odds separation</p>\n          </div>\n\n          {/* Reset Button */}\n          <div className=\"md:col-span-3 flex justify-end pt-4 border-t border-slate-700\">\n            <button\n              onClick={handleReset}\n              disabled={isLoading}\n              className=\"inline-flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-600 text-slate-200 rounded text-sm font-medium transition disabled:opacity-50\"\n            >\n              <RotateCcw className=\"w-4 h-4\" />\n              Reset to Defaults\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/components/Tabs.tsx": "// src/components/Tabs.tsx\n'use client';\n\nimport React, { useState } from 'react';\n\ntype Tab = {\n  label: string;\n  content: React.ReactNode;\n};\n\ntype TabsProps = {\n  tabs: Tab[];\n};\n\nexport function Tabs({ tabs }: TabsProps) {\n  const [activeTab, setActiveTab] = useState(0);\n\n  return (\n    <div>\n      <div className=\"border-b border-slate-700\">\n        <nav className=\"-mb-px flex space-x-8\" aria-label=\"Tabs\">\n          {tabs.map((tab, index) => (\n            <button\n              key={tab.label}\n              onClick={() => setActiveTab(index)}\n              className={`${\n                activeTab === index\n                  ? 'border-blue-500 text-blue-400'\n                  : 'border-transparent text-slate-400 hover:text-slate-200 hover:border-slate-500'\n              } whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm transition-colors focus:outline-none`}\n            >\n              {tab.label}\n            </button>\n          ))}\n        </nav>\n      </div>\n      <div className=\"mt-8\">{tabs[activeTab].content}</div>\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/hooks/useRealTimeRaces.ts": "import { useState, useEffect } from 'react';\nimport { io, Socket } from 'socket.io-client';\nimport { Race } from '../types/racing';\n\nconst API_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8080';\n\nexport function useRealTimeRaces() {\n  const [races, setRaces] = useState<Race[]>([]);\n  const [isConnected, setIsConnected] = useState(false);\n\n  useEffect(() => {\n    const socket: Socket = io(API_URL);\n\n    socket.on('connect', () => setIsConnected(true));\n    socket.on('disconnect', () => setIsConnected(false));\n\n    socket.on('races_update', (data: { races: Race[] }) => {\n      if (data && Array.isArray(data.races)) {\n        setRaces(data.races);\n      }\n    });\n\n    // Cleanup on component unmount\n    return () => {\n      socket.disconnect();\n    };\n  }, []);\n\n  return { races, isConnected };\n}",
    "web_platform/frontend/src/lib/queryClient.ts": "// web_platform/frontend/src/lib/queryClient.ts\nimport { QueryClient } from '@tanstack/react-query';\n\nexport const queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      retry: 3,\n      staleTime: 1000 * 60 * 5, // 5 minutes\n    },\n  },\n});\n",
    "web_platform/frontend/src/types/electron.d.ts": "// web_platform/frontend/src/types/electron.d.ts\n\n/**\n * This declaration file extends the global Window interface to include the\n * 'electronAPI' object exposed by the preload script. This provides\n * TypeScript with type information for the functions we're using for IPC.\n */\nexport {};\n\ndeclare global {\n  interface Window {\n    electronAPI?: {\n      /**\n       * Asynchronously fetches the secure API key from the main process.\n       * @returns {Promise<string|null>} A promise that resolves with the API key or null if not found.\n       */\n      getApiKey: () => Promise<string | null>;\n      /**\n       * Registers a callback for backend status updates from the main process.\n       * @param callback The function to execute. Receives an object with state and logs.\n       * @returns A function to unsubscribe the listener.\n       */\n      onBackendStatusUpdate: (callback: (status: { state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }) => void) => () => void;\n\n      /**\n       * Sends a command to the main process to restart the backend executable.\n       */\n      restartBackend: () => void;\n\n      /**\n       * Asynchronously fetches the current backend status from the main process.\n       * @returns {Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>}\n       */\n      getBackendStatus: () => Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>;\n      generateApiKey: () => Promise<string>;\n      saveApiKey: (apiKey: string) => Promise<{ success: boolean }>;\n      saveBetfairCredentials: (credentials: { appKey: string; username: string; password: string }) => Promise<{ success: boolean }>;\n      getApiPort: () => Promise<number | null>;\n    };\n  }\n}\n",
    "web_platform/frontend/tailwind.config.ts": "import type { Config } from 'tailwindcss'\n\nconst config: Config = {\n  darkMode: 'media',\n  content: [\n    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/components/**/*.{js,ts,jsx,tsx,mdx}',\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\nexport default config",
    "web_service/backend/adapters/gbgb_api_adapter.py": "# python_service/adapters/gbgb_api_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass GbgbApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for the Greyhound Board of Great Britain API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"GBGB\"\n    BASE_URL = \"https://api.gbgb.org.uk/api/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches the raw meeting data from the GBGB API.\"\"\"\n        endpoint = f\"results/meeting/{date}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, meetings_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw meeting data into a list of Race objects.\"\"\"\n        if not meetings_data:\n            return []\n\n        all_races = []\n        for meeting in meetings_data:\n            track_name = meeting.get(\"trackName\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name):\n                        all_races.append(race)\n                except (KeyError, TypeError):\n                    self.logger.error(\n                        \"Error parsing GBGB race\",\n                        race_id=race_data.get(\"raceId\"),\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: Dict[str, Any], track_name: str) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race_data.get(\"raceId\")\n        race_number = race_data.get(\"raceNumber\")\n        race_time = race_data.get(\"raceTime\")\n\n        if not all([race_id, race_number, race_time]):\n            return None\n\n        return Race(\n            id=f\"gbgb_{race_id}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=datetime.fromisoformat(race_time.replace(\"Z\", \"+00:00\")),\n            runners=self._parse_runners(race_data.get(\"traps\", [])),\n            source=self.source_name,\n            race_name=race_data.get(\"raceTitle\"),\n            distance=f\"{race_data.get('raceDistance')}m\",\n        )\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                trap_number = runner_data.get(\"trapNumber\")\n                dog_name = runner_data.get(\"dogName\")\n                if not all([trap_number, dog_name]):\n                    continue\n\n                odds_data = {}\n                sp = runner_data.get(\"sp\")\n                if sp:\n                    win_odds = parse_odds_to_decimal(sp)\n                    if win_odds and win_odds < 999:\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=trap_number,\n                        name=dog_name,\n                        odds=odds_data,\n                    )\n                )\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Error parsing GBGB runner, skipping.\",\n                    runner_name=runner_data.get(\"dogName\"),\n                )\n                continue\n        return runners\n",
    "web_service/backend/adapters/horseracingnation_adapter.py": "# python_service/adapters/horseracingnation_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass HorseRacingNationAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for horseracingnation.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"HorseRacingNation\"\n    BASE_URL = \"https://www.horseracingnation.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/nyrabets_adapter.py": "# python_service/adapters/nyrabets_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass NYRABetsAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for nyrabets.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"NYRABets\"\n    BASE_URL = \"https://nyrabets.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/racing_and_sports_greyhound_adapter.py": "# python_service/adapters/racing_and_sports_greyhound_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports Greyhound API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSportsGreyhound\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"RACING_AND_SPORTS_TOKEN\") or not config.RACING_AND_SPORTS_TOKEN:\n            raise AdapterConfigError(self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw greyhound meetings data from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            self.http_client,\n            \"GET\",\n            \"v1/greyhound/meetings\",\n            headers=headers,\n            params=params,\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw meetings data into a list of Race objects.\"\"\"\n        all_races = []\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\"No 'meetings' in RacingAndSportsGreyhound response or invalid format.\")\n            return all_races\n\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed_race := self._parse_ras_race(meeting, race_summary):\n                        all_races.append(parsed_race)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse RacingAndSportsGreyhound race, skipping\",\n                        meeting=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return all_races\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"rasg_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=datetime.fromisoformat(start_time_str),\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/racingpost_adapter.py": "# python_service/adapters/racingpost_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingPostAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Racing Post racecards, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"RacingPost\"\n    BASE_URL = \"https://www.racingpost.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw HTML content for all races on a given date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch RacingPost index page\", url=index_url)\n            return None\n\n        index_parser = HTMLParser(index_response.text)\n        links = index_parser.css('a[data-test-selector^=\"RC-meetingItem__link_race\"]')\n        race_card_urls = [link.attributes[\"href\"] for link in links]\n\n        async def fetch_single_html(url: str):\n            response = await self.make_request(self.http_client, \"GET\", url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(url) for url in race_card_urls]\n        html_contents = await asyncio.gather(*tasks)\n        return {\"date\": date, \"html_contents\": html_contents}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"html_contents\"):\n            return []\n\n        date = raw_data[\"date\"]\n        html_contents = raw_data[\"html_contents\"]\n        all_races: List[Race] = []\n\n        for html in html_contents:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first('a[data-test-selector=\"RC-course__name\"]')\n                if not venue_node:\n                    continue\n                venue_raw = venue_node.text(strip=True)\n                venue = normalize_venue_name(venue_raw)\n\n                race_time_node = parser.css_first('span[data-test-selector=\"RC-course__time\"]')\n                if not race_time_node:\n                    continue\n                race_time_str = race_time_node.text(strip=True)\n\n                race_datetime_str = f\"{date} {race_time_str}\"\n                start_time = datetime.strptime(race_datetime_str, \"%Y-%m-%d %H:%M\")\n\n                runners = self._parse_runners(parser)\n\n                if venue and runners:\n                    race_number = self._get_race_number(parser, start_time)\n                    race = Race(\n                        id=f\"rp_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=start_time,\n                        runners=runners,\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse RacingPost race from HTML content.\", exc_info=True)\n                continue\n        return all_races\n\n    def _get_race_number(self, parser: HTMLParser, start_time: datetime) -> int:\n        \"\"\"Derives the race number by finding the active time in the nav bar.\"\"\"\n        time_str_to_find = start_time.strftime(\"%H:%M\")\n        time_links = parser.css('a[data-test-selector=\"RC-raceTime\"]')\n        for i, link in enumerate(time_links):\n            if link.text(strip=True) == time_str_to_find:\n                return i + 1\n        return 1\n\n    def _parse_runners(self, parser: HTMLParser) -> list[Runner]:\n        \"\"\"Parses all runners from a single race card page.\"\"\"\n        runners = []\n        runner_nodes = parser.css('div[data-test-selector=\"RC-runnerCard\"]')\n        for node in runner_nodes:\n            if runner := self._parse_runner(node):\n                runners.append(runner)\n        return runners\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first('span[data-test-selector=\"RC-runnerNumber\"]')\n            name_node = node.css_first('a[data-test-selector=\"RC-runnerName\"]')\n            odds_node = node.css_first('span[data-test-selector=\"RC-runnerPrice\"]')\n\n            if not all([number_node, name_node, odds_node]):\n                return None\n\n            number_str = clean_text(number_node.text())\n            number = int(number_str) if number_str and number_str.isdigit() else 0\n            name = clean_text(name_node.text())\n            odds_str = clean_text(odds_node.text())\n            scratched = \"NR\" in odds_str.upper() or not odds_str\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError):\n            self.logger.warning(\"Could not parse RacingPost runner, skipping.\", exc_info=True)\n            return None\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "web_service/backend/adapters/tab_adapter.py": "# python_service/adapters/tab_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TabAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for tab.com.au.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"TAB\"\n    BASE_URL = \"https://www.tab.com.au\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/universal_adapter.py": "# python_service/adapters/universal_adapter.py\nimport json\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass UniversalAdapter(BaseAdapterV3):\n    \"\"\"\n    An adapter that executes logic from a declarative JSON definition file.\n    NOTE: This is a simplified proof-of-concept implementation.\n    \"\"\"\n\n    def __init__(self, config, definition_path: str):\n        with open(definition_path, \"r\") as f:\n            self.definition = json.load(f)\n\n        super().__init__(\n            source_name=self.definition[\"adapter_name\"],\n            base_url=self.definition[\"base_url\"],\n            config=config,\n        )\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Executes the fetch steps defined in the JSON definition.\"\"\"\n        self.logger.info(f\"Executing Universal Adapter PoC for {self.source_name}\")\n        response = await self.make_request(self.http_client, \"GET\", self.definition[\"start_url\"])\n        if not response:\n            return None\n\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        track_links = [self.base_url + a[\"href\"] for a in soup.select(self.definition[\"steps\"][0][\"selector\"])]\n\n        # In a full implementation, we would fetch and return each track page's content.\n        # For this PoC, we are not fetching the individual track links.\n        self.logger.warning(\"UniversalAdapter is a proof-of-concept and does not fully fetch all data.\")\n        return track_links\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a proof-of-concept and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/utils.py": "# python_service/adapters/utils.py\n# Compatibility shim to re-export parse_odds from the centralized location.\n\nfrom ..utils.odds import parse_odds\n\n__all__ = [\"parse_odds\"]\n",
    "web_service/backend/etl.py": "# python_service/etl.py\n# ETL pipeline for populating the historical data warehouse\n\nimport json\nimport logging\nimport os\nfrom datetime import date\n\nimport requests\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import text\nfrom sqlalchemy.exc import SQLAlchemyError\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass ScribesArchivesETL:\n    def __init__(self):\n        self.postgres_url = os.getenv(\"POSTGRES_URL\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.api_base_url = \"http://localhost:8000\"\n        self.engine = self._get_db_engine()\n\n    def _get_db_engine(self):\n        if not self.postgres_url:\n            logger.warning(\"POSTGRES_URL not set. ETL will be skipped.\")\n            return None\n        try:\n            return create_engine(self.postgres_url)\n        except Exception as e:\n            logger.error(f\"Failed to create database engine: {e}\", exc_info=True)\n            return None\n\n    def _fetch_race_data(self, target_date: date) -> list:\n        \"\"\"Fetches aggregated race data from the local API.\"\"\"\n        if not self.api_key:\n            raise ValueError(\"API_KEY not found in environment.\")\n\n        url = f\"{self.api_base_url}/api/races?race_date={target_date.isoformat()}\"\n        headers = {\"X-API-KEY\": self.api_key}\n        response = requests.get(url, headers=headers, timeout=120)\n        response.raise_for_status()\n        return response.json().get(\"races\", [])\n\n    def _validate_and_transform(self, race: dict) -> tuple:\n        \"\"\"Validates a race dictionary and transforms it for insertion.\"\"\"\n        if not all(k in race for k in [\"id\", \"venue\", \"race_number\", \"start_time\", \"runners\"]):\n            return (\n                None,\n                \"Missing core fields (id, venue, race_number, start_time, runners)\",\n            )\n\n        active_runners = [r for r in race.get(\"runners\", []) if not r.get(\"scratched\")]\n\n        transformed = {\n            \"race_id\": race[\"id\"],\n            \"venue\": race[\"venue\"],\n            \"race_number\": race[\"race_number\"],\n            \"start_time\": race[\"start_time\"],\n            \"source\": race.get(\"source\"),\n            \"qualification_score\": race.get(\"qualification_score\"),\n            \"field_size\": len(active_runners),\n        }\n        return transformed, None\n\n    def run(self, target_date: date):\n        if not self.engine:\n            return\n\n        logger.info(f\"Starting ETL process for {target_date.isoformat()}...\")\n        try:\n            races = self._fetch_race_data(target_date)\n        except (requests.RequestException, ValueError) as e:\n            logger.error(f\"Failed to fetch race data: {e}\", exc_info=True)\n            return\n\n        clean_records = []\n        quarantined_records = []\n\n        for race in races:\n            transformed, reason = self._validate_and_transform(race)\n            if transformed:\n                clean_records.append(transformed)\n            else:\n                quarantined_records.append(\n                    {\n                        \"race_id\": race.get(\"id\"),\n                        \"source\": race.get(\"source\"),\n                        \"payload\": json.dumps(race),\n                        \"reason\": reason,\n                    }\n                )\n\n        with self.engine.connect() as connection:\n            try:\n                with connection.begin():  # Transaction block\n                    if clean_records:\n                        # Using ON CONFLICT to prevent duplicates\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO historical_races (\n                                race_id, venue, race_number, start_time, source,\n                                qualification_score, field_size\n                            )\n                            VALUES (\n                                :race_id, :venue, :race_number, :start_time, :source,\n                                :qualification_score, :field_size\n                            )\n                            ON CONFLICT (race_id) DO NOTHING;\n                        \"\"\"\n                        )\n                        connection.execute(stmt, clean_records)\n                        logger.info(f\"Inserted/updated {len(clean_records)} records into historical_races.\")\n\n                    if quarantined_records:\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO quarantined_races (race_id, source, payload, reason)\n                            VALUES (:race_id, :source, :payload::jsonb, :reason);\n                        \"\"\"\n                        )\n                        connection.execute(stmt, quarantined_records)\n                        logger.warning(f\"Moved {len(quarantined_records)} records to quarantine.\")\n            except SQLAlchemyError as e:\n                logger.error(f\"Database transaction failed: {e}\", exc_info=True)\n\n        logger.info(\"ETL process finished.\")\n\n\ndef run_etl_for_yesterday():\n    from datetime import timedelta\n\n    yesterday = date.today() - timedelta(days=1)\n    etl = ScribesArchivesETL()\n    etl.run(yesterday)\n",
    "web_service/backend/fortuna_windows_service.py": "# fortuna_windows_service.py\n\nimport logging\nimport os\nimport sys\n\nimport servicemanager\nimport win32event\nimport win32service\nimport win32serviceutil\n\n# Ensure the script's directory is at the front of the path\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.insert(0, script_dir)\n\ntry:\n    from fortuna_service import FortunaBackgroundService\nexcept ImportError as e:\n    # Log a detailed error to the Windows Event Log if the import fails\n    servicemanager.LogErrorMsg(f\"FATAL: Could not import FortunaBackgroundService. Error: {e}\")\n    sys.exit(1)  # Exit with an error code\n\n\nclass FortunaWindowsService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaV8Service\"\n    _svc_display_name_ = \"Fortuna V8 Racing Analysis Service\"\n    _svc_description_ = \"Continuously fetches and analyzes horse racing data.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)\n        self.fortuna_service = FortunaBackgroundService()\n        # Configure logging to use the Windows Event Log\n        logging.basicConfig(\n            level=logging.INFO,\n            format=\"%(name)s - %(levelname)s - %(message)s\",\n            handlers=[servicemanager.LogHandler()],\n        )\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        self.fortuna_service.stop()\n        win32event.SetEvent(self.hWaitStop)\n        self.ReportServiceStatus(win32service.SERVICE_STOPPED)\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(\n            servicemanager.EVENTLOG_INFORMATION_TYPE,\n            servicemanager.PYS_SERVICE_STARTED,\n            (self._svc_name_, \"\"),\n        )\n        self.main()\n\n    def main(self):\n        self.fortuna_service.start()\n        win32event.WaitForSingleObject(self.hWaitStop, win32event.INFINITE)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaWindowsService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaWindowsService)\n",
    "web_service/backend/initialize_db.py": "# python_service/initialize_db.py\nfrom db.init import initialize_database\n\n\ndef main():\n    \"\"\"\n    This script exists solely to initialize the database.\n    It should be called before the main server process is started.\n    \"\"\"\n    print(\"Initializing database...\", flush=True)\n    initialize_database()\n    print(\"Database initialization complete.\", flush=True)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "web_service/backend/models_v3.py": "# python_service/models_v3.py\n# Defines the data structures for the V3 adapter architecture.\n\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import List\n\n\n@dataclass\nclass NormalizedRunner:\n    runner_id: str\n    name: str\n    saddle_cloth: str\n    odds_decimal: float\n\n\n@dataclass\nclass NormalizedRace:\n    race_key: str\n    track_key: str\n    start_time_iso: str\n    race_name: str\n    runners: List[NormalizedRunner] = field(default_factory=list)\n    source_ids: List[str] = field(default_factory=list)\n",
    "web_service/backend/user_friendly_errors.py": "# python_service/user_friendly_errors.py\n\n\"\"\"\nCentralized dictionary for mapping technical exceptions to user-friendly messages.\n\"\"\"\n\nERROR_MAP = {\n    \"AdapterHttpError\": {\n        \"message\": \"A data source is currently unavailable.\",\n        \"suggestion\": (\n            \"This is usually temporary. Please try again in a few minutes. \"\n            \"If the problem persists, the website may be down for maintenance.\"\n        ),\n    },\n    \"AdapterConfigError\": {\n        \"message\": \"A data adapter is misconfigured.\",\n        \"suggestion\": \"Please check that all required API keys and settings are present in your .env file.\",\n    },\n    \"default\": {\n        \"message\": \"An unexpected error occurred.\",\n        \"suggestion\": \"Please check the application logs for more details or contact support.\",\n    },\n}\n",
    "web_service/frontend/app/components/ManualOverridePanel.tsx": "// web_platform/frontend/src/components/ManualOverridePanel.tsx\nimport React, { useState } from 'react';\nimport { Race } from '../types/racing';\n\ninterface ManualOverridePanelProps {\n  adapterName: string;\n  attemptedUrl: string;\n  apiKey: string | null;\n  onParseSuccess: (adapterName: string, parsedRaces: Race[]) => void;\n}\n\nconst ManualOverridePanel: React.FC<ManualOverridePanelProps> = ({\n  adapterName,\n  attemptedUrl,\n  apiKey,\n  onParseSuccess,\n}) => {\n  const [showPanel, setShowPanel] = useState(true);\n  const [htmlContent, setHtmlContent] = useState('');\n  const [isSubmitting, setIsSubmitting] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  const handleSubmit = async () => {\n    if (!htmlContent.trim()) {\n      setError('HTML content cannot be empty.');\n      return;\n    }\n    if (!apiKey) {\n      setError('API key is not available. Cannot submit.');\n      return;\n    }\n\n    setIsSubmitting(true);\n    setError(null);\n\n    try {\n      const response = await fetch('/api/races/parse-manual', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'X-API-Key': apiKey,\n        },\n        body: JSON.stringify({\n          adapter_name: adapterName,\n          html_content: htmlContent,\n        }),\n      });\n\n      if (!response.ok) {\n        const errorData = await response.json();\n        throw new Error(errorData.detail || 'Failed to parse HTML.');\n      }\n\n      const parsedRaces: Race[] = await response.json();\n      onParseSuccess(adapterName, parsedRaces);\n      setShowPanel(false); // Hide panel on success\n\n    } catch (err) {\n      const errorMessage = err instanceof Error ? err.message : 'An unknown error occurred.';\n      setError(errorMessage);\n      console.error('Manual parse submission failed:', err);\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n\n  if (!showPanel) {\n    return null;\n  }\n\n  return (\n    <div className=\"bg-red-900 bg-opacity-50 border border-red-700 p-4 rounded-lg shadow-lg mb-4\">\n      <div className=\"flex justify-between items-center\">\n        <div>\n          <h3 className=\"font-bold text-red-300\">Data Fetch Failed: {adapterName}</h3>\n          <p className=\"text-sm text-red-400\">\n            The application failed to automatically retrieve data from:{' '}\n            <a href={attemptedUrl} target=\"_blank\" rel=\"noopener noreferrer\" className=\"underline hover:text-red-200\">\n              {attemptedUrl}\n            </a>\n          </p>\n        </div>\n        <button onClick={() => setShowPanel(false)} className=\"text-red-400 hover:text-red-200 text-2xl\">&times;</button>\n      </div>\n      <div className=\"mt-4\">\n        <p className=\"text-sm text-red-300 mb-2\">\n          <strong>To resolve this:</strong>\n          <ol className=\"list-decimal list-inside pl-4\">\n            <li>Click the link above to open the page in a new tab.</li>\n            <li>Right-click on the page and select \"View Page Source\".</li>\n            <li>Copy the entire HTML source code.</li>\n            <li>Paste the code into the text area below and click \"Submit Manual Data\".</li>\n          </ol>\n        </p>\n        <textarea\n          className=\"w-full h-24 p-2 bg-gray-900 border border-gray-700 rounded text-gray-300 font-mono text-xs\"\n          placeholder={`Paste HTML source for ${adapterName} here...`}\n          value={htmlContent}\n          onChange={(e) => setHtmlContent(e.target.value)}\n          disabled={isSubmitting}\n        />\n        {error && <p className=\"text-red-400 text-sm mt-2\">{error}</p>}\n        <div className=\"mt-2 flex gap-2\">\n          <button\n            onClick={handleSubmit}\n            className=\"px-3 py-1.5 bg-blue-600 text-white rounded hover:bg-blue-700 text-sm disabled:bg-blue-800 disabled:cursor-not-allowed\"\n            disabled={isSubmitting}\n          >\n            {isSubmitting ? 'Submitting...' : 'Submit Manual Data'}\n          </button>\n          <button\n            onClick={() => setShowPanel(false)}\n            className=\"px-3 py-1.5 bg-gray-700 text-white rounded hover:bg-gray-600 text-sm\"\n          >\n            Skip for Now\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default ManualOverridePanel;\n",
    "web_service/frontend/app/components/RaceCard.tsx": "// web_platform/frontend/src/components/RaceCard.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\nimport type { Race, Runner } from '../types/racing';\n\n// Local types removed, now importing from '../types/racing'\n\ninterface RaceCardProps {\n  race: Race;\n}\n\nconst Countdown: React.FC<{ startTime: string }> = ({ startTime }) => {\n  const [currentTime, setCurrentTime] = useState(new Date());\n\n  useEffect(() => {\n    const timer = setInterval(() => setCurrentTime(new Date()), 1000);\n    return () => clearInterval(timer);\n  }, []);\n\n  const getCountdown = (startTimeStr: string) => {\n    const postTime = new Date(startTimeStr);\n    const diff = postTime.getTime() - currentTime.getTime();\n\n    if (diff <= 0) return { text: \"RACE COMPLETE\", color: \"text-gray-500\" };\n\n    const minutes = Math.floor(diff / 60000);\n    const seconds = Math.floor((diff % 60000) / 1000).toString().padStart(2, '0');\n\n    let color = \"text-green-400\";\n    if (minutes < 2) color = \"text-red-500 font-bold animate-pulse\";\n    else if (minutes < 10) color = \"text-yellow-400\";\n\n    return { text: `${minutes}:${seconds} to post`, color };\n  };\n\n  const countdown = getCountdown(startTime);\n\n  return (\n    <span className={`font-mono text-sm ${countdown.color}`}>{countdown.text}</span>\n  );\n};\n\nexport const RaceCard: React.FC<RaceCardProps> = ({ race }) => {\n  const activeRunners = race.runners.filter(r => !r.scratched);\n  activeRunners.sort((a, b) => a.number - b.number);\n\n  const getUniqueSourcesCount = (runners: Runner[]): number => {\n    const sources = new Set();\n    runners.forEach(runner => {\n      if (runner.odds) {\n        Object.keys(runner.odds).forEach(source => sources.add(source));\n      }\n    });\n    return sources.size;\n  };\n\n  const getBestOdds = (runner: Runner): { odds: number, source: string } | null => {\n    if (!runner.odds) return null;\n  const validOdds = Object.values(runner.odds).filter(o => o.win !== null && o.win !== undefined && o.win < 999);\n    if (validOdds.length === 0) return null;\n  const best = validOdds.reduce((min, o) => (o.win ?? 999) < (min.win ?? 999) ? o : min);\n    return { odds: best.win!, source: best.source };\n  };\n\n  return (\n    <div className={`race-card-enhanced border rounded-lg p-4 bg-gray-800 shadow-lg hover:border-purple-500 transition-all ${race.qualification_score && race.qualification_score >= 80 ? 'card-premium' : 'border-gray-700'}`}>\n      {/* Header with Smart Status Indicators */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <h2 className=\"text-2xl font-bold text-white\">{race.venue}</h2>\n            <div className=\"flex gap-2 text-sm text-gray-400\">\n              <span>Race {race.race_number}</span>\n              <span>\u2022</span>\n              <Countdown startTime={race.start_time} />\n            </div>\n            {race.favorite && (\n              <div className=\"flex items-center gap-2 mt-2 text-sm text-yellow-400\">\n                <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-4 w-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n                  <path d=\"M9.049 2.927c.3-.921 1.603-.921 1.902 0l1.07 3.292a1 1 0 00.95.69h3.462c.969 0 1.371 1.24.588 1.81l-2.8 2.034a1 1 0 00-.364 1.118l1.07 3.292c.3.921-.755 1.688-1.54 1.118l-2.8-2.034a1 1 0 00-1.175 0l-2.8 2.034c-.784.57-1.838-.197-1.539-1.118l1.07-3.292a1 1 0 00-.364-1.118L2.98 8.72c-.783-.57-.38-1.81.588-1.81h3.461a1 1 0 00.951-.69l1.07-3.292z\" />\n                </svg>\n                <span className=\"font-semibold\">Favorite: {race.favorite.name}</span>\n              </div>\n            )}\n          </div>\n        </div>\n\n        {race.qualification_score && (\n          <div className={`px-4 py-2 rounded-full text-center ${\n            race.qualification_score >= 80 ? 'bg-red-500/20 text-red-400 border border-red-500/30' :\n            race.qualification_score >= 60 ? 'bg-yellow-500/20 text-yellow-400 border border-yellow-500/30' :\n            'bg-green-500/20 text-green-400 border border-green-500/30'\n          }`}>\n            <div className=\"font-bold text-lg\">{race.qualification_score.toFixed(0)}%</div>\n            <div className=\"text-xs\">Score</div>\n          </div>\n        )}\n      </div>\n\n      {/* Race Conditions Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Distance</div>\n          <div className=\"text-sm font-semibold text-white\">{race.distance || 'N/A'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Surface</div>\n          <div className=\"text-sm font-semibold text-white\">{race.surface || 'Dirt'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Field</div>\n          <div className=\"text-sm font-semibold text-white\">{activeRunners.length}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Sources</div>\n          <div className=\"text-sm font-semibold text-white\">{getUniqueSourcesCount(race.runners)}</div>\n        </div>\n      </div>\n\n      {/* Interactive Runner Rows */}\n      <div className=\"runners-table space-y-2\">\n        {activeRunners.map((runner, idx) => {\n          const bestOddsInfo = getBestOdds(runner);\n          return (\n            <div key={runner.number} className=\"runner-row group hover:bg-purple-500/10 transition-all rounded-md p-3\">\n              <div className=\"flex items-center justify-between\">\n                <div className=\"flex items-center gap-4 flex-1\">\n                  <div className={`w-10 h-10 rounded-full flex items-center justify-center font-bold transition-all group-hover:scale-110 text-gray-900 shadow-lg ${idx === 0 ? 'bg-gradient-to-br from-yellow-400 to-yellow-600 shadow-yellow-500/50' : idx === 1 ? 'bg-gradient-to-br from-gray-300 to-gray-500 shadow-gray-400/50' : idx === 2 ? 'bg-gradient-to-br from-orange-400 to-orange-600 shadow-orange-500/50' : 'bg-gray-700 text-gray-300'}`}>\n                    {runner.number}\n                  </div>\n                  <div className=\"flex flex-col\">\n                    <span className=\"font-bold text-white text-lg\">{runner.name}</span>\n                    <div className=\"flex gap-3 text-sm text-gray-400\">\n                      {runner.jockey && <span>J: {runner.jockey}</span>}\n                      {runner.trainer && <span>T: {runner.trainer}</span>}\n                    </div>\n                  </div>\n                </div>\n                {bestOddsInfo && (\n                  <div className=\"text-right\">\n                    <div className=\"text-2xl font-bold text-emerald-400\">{bestOddsInfo.odds.toFixed(2)}</div>\n                    <div className=\"text-xs text-gray-500\">via {bestOddsInfo.source}</div>\n                  </div>\n                )}\n              </div>\n            </div>\n          );\n        })}\n      </div>\n    </div>\n  );\n};",
    "web_service/frontend/app/components/ScoreBadge.tsx": "'use client';\nimport React from 'react';\n\nconst getScoreStyling = (score: number) => {\n  if (score >= 90) return { bg: 'bg-yellow-400/10', text: 'text-yellow-300', border: 'border-yellow-400' };\n  if (score >= 80) return { bg: 'bg-orange-500/10', text: 'text-orange-400', border: 'border-orange-500' };\n  return { bg: 'bg-sky-500/10', text: 'text-sky-400', border: 'border-sky-500' };\n};\n\nexport const ScoreBadge: React.FC<{ score: number }> = ({ score }) => {\n  const { bg, text } = getScoreStyling(score);\n  return (\n    <div className={`text-right ${text}`}>\n      <p className=\"text-3xl font-bold\">{score.toFixed(1)}</p>\n      <p className=\"text-xs font-medium tracking-wider uppercase\\\">Score</p>\n    </div>\n  );\n};",
    "web_service/frontend/app/components/StatusDetailModal.tsx": "// web_platform/frontend/src/components/StatusDetailModal.tsx\nimport React from 'react';\n\ninterface StatusDetailModalProps {\n  isOpen: boolean;\n  onClose: () => void;\n  status: {\n      title: string;\n      details: string | Record<string, any>;\n  };\n}\n\nexport const StatusDetailModal: React.FC<StatusDetailModalProps> = ({ isOpen, onClose, status }) => {\n  if (!isOpen) {\n    return null;\n  }\n\n  const { title, details } = status;\n  const isDetailsString = typeof details === 'string';\n\n  // Determine status color only if details is an object with a status property\n  const statusColor = !isDetailsString && (details.status === 'SUCCESS' || details.status === 'OK')\n    ? 'text-green-400'\n    : 'text-gray-300'; // Default color\n\n  return (\n    <div className=\"fixed inset-0 bg-black/60 flex items-center justify-center z-50\" onClick={onClose}>\n      <div className=\"bg-gray-800 border border-gray-700 rounded-lg shadow-xl p-6 max-w-lg w-full\" onClick={e => e.stopPropagation()}>\n        <div className=\"flex justify-between items-start mb-4\">\n          <h3 className=\"text-xl font-bold text-white\">{title}</h3>\n          <button onClick={onClose} className=\"text-gray-400 hover:text-white\">&times;</button>\n        </div>\n        <div className=\"space-y-2 text-sm max-h-96 overflow-y-auto pr-2\">\n            {isDetailsString ? (\n                <div className=\"text-gray-300 whitespace-pre-wrap bg-gray-900/50 p-4 rounded-md\">{details}</div>\n            ) : (\n                Object.entries(details).map(([key, value]) => (\n                    <div key={key} className=\"grid grid-cols-3 gap-4 border-b border-gray-700/50 py-2\">\n                    <span className=\"font-semibold text-gray-400 capitalize\">{key.replace(/_/g, ' ')}</span>\n                    <span className={`col-span-2 break-words ${key === 'status' ? statusColor : 'text-gray-300'}`}>\n                        {typeof value === 'object' ? JSON.stringify(value, null, 2) : String(value)}\n                    </span>\n                    </div>\n                ))\n            )}\n        </div>\n        <button\n          onClick={onClose}\n          className=\"bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded w-full mt-6\"\n        >\n          Close\n        </button>\n      </div>\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/TrifectaFactors.tsx": "// TrifectaFactors.tsx - FINAL, DYNAMIC VERSION\n'use client';\nimport React from 'react';\n\ninterface TrifectaFactorsProps {\n  factorsJson: string | null;\n}\n\nexport function TrifectaFactors({ factorsJson }: TrifectaFactorsProps) {\n  if (!factorsJson) {\n    return <div className=\"text-sm text-gray-500\">No analysis factors available.</div>;\n  }\n\n  try {\n    const factors = JSON.parse(factorsJson);\n    const positiveFactors = Object.entries(factors).filter(([key, value]: [string, any]) => value.ok);\n\n    if (positiveFactors.length === 0) {\n      return <div className=\"text-sm text-gray-500\">No positive factors identified.</div>;\n    }\n\n    return (\n      <div className=\"mt-2 text-xs\">\n        <h4 className=\"font-semibold mb-1\">Key Factors:</h4>\n        <ul className=\"list-disc list-inside space-y-1\">\n          {positiveFactors.map(([key, value]: [string, any]) => (\n            <li key={key} className=\"text-gray-700\">\n              <span className=\"font-medium text-green-600\">\u2713</span> {value.reason} ({value.points > 0 ? `+${value.points}` : value.points} pts)\n            </li>\n          ))}\n        </ul>\n      </div>\n    );\n  } catch (error) {\n    console.error(\"Failed to parse trifecta factors:\", error);\n    return <div className=\"text-sm text-red-500\">Error displaying analysis factors.</div>;\n  }\n}",
    "web_service/frontend/app/globals.css": "@tailwind base;\n@tailwind components;\n@tailwind utilities;",
    "web_service/frontend/postcss.config.js": "module.exports = {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n};",
    "web_service/frontend/public/workbox-4754cb34.js": "define([\"exports\"],function(t){\"use strict\";try{self[\"workbox:core:6.5.4\"]&&_()}catch(t){}const e=(t,...e)=>{let s=t;return e.length>0&&(s+=` :: ${JSON.stringify(e)}`),s};class s extends Error{constructor(t,s){super(e(t,s)),this.name=t,this.details=s}}try{self[\"workbox:routing:6.5.4\"]&&_()}catch(t){}const n=t=>t&&\"object\"==typeof t?t:{handle:t};class r{constructor(t,e,s=\"GET\"){this.handler=n(e),this.match=t,this.method=s}setCatchHandler(t){this.catchHandler=n(t)}}class i extends r{constructor(t,e,s){super(({url:e})=>{const s=t.exec(e.href);if(s&&(e.origin===location.origin||0===s.index))return s.slice(1)},e,s)}}class a{constructor(){this.t=new Map,this.i=new Map}get routes(){return this.t}addFetchListener(){self.addEventListener(\"fetch\",t=>{const{request:e}=t,s=this.handleRequest({request:e,event:t});s&&t.respondWith(s)})}addCacheListener(){self.addEventListener(\"message\",t=>{if(t.data&&\"CACHE_URLS\"===t.data.type){const{payload:e}=t.data,s=Promise.all(e.urlsToCache.map(e=>{\"string\"==typeof e&&(e=[e]);const s=new Request(...e);return this.handleRequest({request:s,event:t})}));t.waitUntil(s),t.ports&&t.ports[0]&&s.then(()=>t.ports[0].postMessage(!0))}})}handleRequest({request:t,event:e}){const s=new URL(t.url,location.href);if(!s.protocol.startsWith(\"http\"))return;const n=s.origin===location.origin,{params:r,route:i}=this.findMatchingRoute({event:e,request:t,sameOrigin:n,url:s});let a=i&&i.handler;const o=t.method;if(!a&&this.i.has(o)&&(a=this.i.get(o)),!a)return;let c;try{c=a.handle({url:s,request:t,event:e,params:r})}catch(t){c=Promise.reject(t)}const h=i&&i.catchHandler;return c instanceof Promise&&(this.o||h)&&(c=c.catch(async n=>{if(h)try{return await h.handle({url:s,request:t,event:e,params:r})}catch(t){t instanceof Error&&(n=t)}if(this.o)return this.o.handle({url:s,request:t,event:e});throw n})),c}findMatchingRoute({url:t,sameOrigin:e,request:s,event:n}){const r=this.t.get(s.method)||[];for(const i of r){let r;const a=i.match({url:t,sameOrigin:e,request:s,event:n});if(a)return r=a,(Array.isArray(r)&&0===r.length||a.constructor===Object&&0===Object.keys(a).length||\"boolean\"==typeof a)&&(r=void 0),{route:i,params:r}}return{}}setDefaultHandler(t,e=\"GET\"){this.i.set(e,n(t))}setCatchHandler(t){this.o=n(t)}registerRoute(t){this.t.has(t.method)||this.t.set(t.method,[]),this.t.get(t.method).push(t)}unregisterRoute(t){if(!this.t.has(t.method))throw new s(\"unregister-route-but-not-found-with-method\",{method:t.method});const e=this.t.get(t.method).indexOf(t);if(!(e>-1))throw new s(\"unregister-route-route-not-registered\");this.t.get(t.method).splice(e,1)}}let o;const c=()=>(o||(o=new a,o.addFetchListener(),o.addCacheListener()),o);function h(t,e,n){let a;if(\"string\"==typeof t){const s=new URL(t,location.href);a=new r(({url:t})=>t.href===s.href,e,n)}else if(t instanceof RegExp)a=new i(t,e,n);else if(\"function\"==typeof t)a=new r(t,e,n);else{if(!(t instanceof r))throw new s(\"unsupported-route-type\",{moduleName:\"workbox-routing\",funcName:\"registerRoute\",paramName:\"capture\"});a=t}return c().registerRoute(a),a}try{self[\"workbox:strategies:6.5.4\"]&&_()}catch(t){}const u={cacheWillUpdate:async({response:t})=>200===t.status||0===t.status?t:null},l={googleAnalytics:\"googleAnalytics\",precache:\"precache-v2\",prefix:\"workbox\",runtime:\"runtime\",suffix:\"undefined\"!=typeof registration?registration.scope:\"\"},f=t=>[l.prefix,t,l.suffix].filter(t=>t&&t.length>0).join(\"-\"),w=t=>t||f(l.precache),d=t=>t||f(l.runtime);function p(t,e){const s=new URL(t);for(const t of e)s.searchParams.delete(t);return s.href}class y{constructor(){this.promise=new Promise((t,e)=>{this.resolve=t,this.reject=e})}}const g=new Set;function m(t){return\"string\"==typeof t?new Request(t):t}class v{constructor(t,e){this.h={},Object.assign(this,e),this.event=e.event,this.u=t,this.l=new y,this.p=[],this.m=[...t.plugins],this.v=new Map;for(const t of this.m)this.v.set(t,{});this.event.waitUntil(this.l.promise)}async fetch(t){const{event:e}=this;let n=m(t);if(\"navigate\"===n.mode&&e instanceof FetchEvent&&e.preloadResponse){const t=await e.preloadResponse;if(t)return t}const r=this.hasCallback(\"fetchDidFail\")?n.clone():null;try{for(const t of this.iterateCallbacks(\"requestWillFetch\"))n=await t({request:n.clone(),event:e})}catch(t){if(t instanceof Error)throw new s(\"plugin-error-request-will-fetch\",{thrownErrorMessage:t.message})}const i=n.clone();try{let t;t=await fetch(n,\"navigate\"===n.mode?void 0:this.u.fetchOptions);for(const s of this.iterateCallbacks(\"fetchDidSucceed\"))t=await s({event:e,request:i,response:t});return t}catch(t){throw r&&await this.runCallbacks(\"fetchDidFail\",{error:t,event:e,originalRequest:r.clone(),request:i.clone()}),t}}async fetchAndCachePut(t){const e=await this.fetch(t),s=e.clone();return this.waitUntil(this.cachePut(t,s)),e}async cacheMatch(t){const e=m(t);let s;const{cacheName:n,matchOptions:r}=this.u,i=await this.getCacheKey(e,\"read\"),a=Object.assign(Object.assign({},r),{cacheName:n});s=await caches.match(i,a);for(const t of this.iterateCallbacks(\"cachedResponseWillBeUsed\"))s=await t({cacheName:n,matchOptions:r,cachedResponse:s,request:i,event:this.event})||void 0;return s}async cachePut(t,e){const n=m(t);var r;await(r=0,new Promise(t=>setTimeout(t,r)));const i=await this.getCacheKey(n,\"write\");if(!e)throw new s(\"cache-put-with-no-response\",{url:(a=i.url,new URL(String(a),location.href).href.replace(new RegExp(`^${location.origin}`),\"\"))});var a;const o=await this.R(e);if(!o)return!1;const{cacheName:c,matchOptions:h}=this.u,u=await self.caches.open(c),l=this.hasCallback(\"cacheDidUpdate\"),f=l?await async function(t,e,s,n){const r=p(e.url,s);if(e.url===r)return t.match(e,n);const i=Object.assign(Object.assign({},n),{ignoreSearch:!0}),a=await t.keys(e,i);for(const e of a)if(r===p(e.url,s))return t.match(e,n)}(u,i.clone(),[\"__WB_REVISION__\"],h):null;try{await u.put(i,l?o.clone():o)}catch(t){if(t instanceof Error)throw\"QuotaExceededError\"===t.name&&await async function(){for(const t of g)await t()}(),t}for(const t of this.iterateCallbacks(\"cacheDidUpdate\"))await t({cacheName:c,oldResponse:f,newResponse:o.clone(),request:i,event:this.event});return!0}async getCacheKey(t,e){const s=`${t.url} | ${e}`;if(!this.h[s]){let n=t;for(const t of this.iterateCallbacks(\"cacheKeyWillBeUsed\"))n=m(await t({mode:e,request:n,event:this.event,params:this.params}));this.h[s]=n}return this.h[s]}hasCallback(t){for(const e of this.u.plugins)if(t in e)return!0;return!1}async runCallbacks(t,e){for(const s of this.iterateCallbacks(t))await s(e)}*iterateCallbacks(t){for(const e of this.u.plugins)if(\"function\"==typeof e[t]){const s=this.v.get(e),n=n=>{const r=Object.assign(Object.assign({},n),{state:s});return e[t](r)};yield n}}waitUntil(t){return this.p.push(t),t}async doneWaiting(){let t;for(;t=this.p.shift();)await t}destroy(){this.l.resolve(null)}async R(t){let e=t,s=!1;for(const t of this.iterateCallbacks(\"cacheWillUpdate\"))if(e=await t({request:this.request,response:e,event:this.event})||void 0,s=!0,!e)break;return s||e&&200!==e.status&&(e=void 0),e}}class R{constructor(t={}){this.cacheName=d(t.cacheName),this.plugins=t.plugins||[],this.fetchOptions=t.fetchOptions,this.matchOptions=t.matchOptions}handle(t){const[e]=this.handleAll(t);return e}handleAll(t){t instanceof FetchEvent&&(t={event:t,request:t.request});const e=t.event,s=\"string\"==typeof t.request?new Request(t.request):t.request,n=\"params\"in t?t.params:void 0,r=new v(this,{event:e,request:s,params:n}),i=this.q(r,s,e);return[i,this.D(i,r,s,e)]}async q(t,e,n){let r;await t.runCallbacks(\"handlerWillStart\",{event:n,request:e});try{if(r=await this.U(e,t),!r||\"error\"===r.type)throw new s(\"no-response\",{url:e.url})}catch(s){if(s instanceof Error)for(const i of t.iterateCallbacks(\"handlerDidError\"))if(r=await i({error:s,event:n,request:e}),r)break;if(!r)throw s}for(const s of t.iterateCallbacks(\"handlerWillRespond\"))r=await s({event:n,request:e,response:r});return r}async D(t,e,s,n){let r,i;try{r=await t}catch(i){}try{await e.runCallbacks(\"handlerDidRespond\",{event:n,request:s,response:r}),await e.doneWaiting()}catch(t){t instanceof Error&&(i=t)}if(await e.runCallbacks(\"handlerDidComplete\",{event:n,request:s,response:r,error:i}),e.destroy(),i)throw i}}function b(t){t.then(()=>{})}function q(){return q=Object.assign?Object.assign.bind():function(t){for(var e=1;e<arguments.length;e++){var s=arguments[e];for(var n in s)({}).hasOwnProperty.call(s,n)&&(t[n]=s[n])}return t},q.apply(null,arguments)}let D,U;const x=new WeakMap,L=new WeakMap,I=new WeakMap,C=new WeakMap,E=new WeakMap;let N={get(t,e,s){if(t instanceof IDBTransaction){if(\"done\"===e)return L.get(t);if(\"objectStoreNames\"===e)return t.objectStoreNames||I.get(t);if(\"store\"===e)return s.objectStoreNames[1]?void 0:s.objectStore(s.objectStoreNames[0])}return k(t[e])},set:(t,e,s)=>(t[e]=s,!0),has:(t,e)=>t instanceof IDBTransaction&&(\"done\"===e||\"store\"===e)||e in t};function O(t){return t!==IDBDatabase.prototype.transaction||\"objectStoreNames\"in IDBTransaction.prototype?(U||(U=[IDBCursor.prototype.advance,IDBCursor.prototype.continue,IDBCursor.prototype.continuePrimaryKey])).includes(t)?function(...e){return t.apply(B(this),e),k(x.get(this))}:function(...e){return k(t.apply(B(this),e))}:function(e,...s){const n=t.call(B(this),e,...s);return I.set(n,e.sort?e.sort():[e]),k(n)}}function T(t){return\"function\"==typeof t?O(t):(t instanceof IDBTransaction&&function(t){if(L.has(t))return;const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"complete\",r),t.removeEventListener(\"error\",i),t.removeEventListener(\"abort\",i)},r=()=>{e(),n()},i=()=>{s(t.error||new DOMException(\"AbortError\",\"AbortError\")),n()};t.addEventListener(\"complete\",r),t.addEventListener(\"error\",i),t.addEventListener(\"abort\",i)});L.set(t,e)}(t),e=t,(D||(D=[IDBDatabase,IDBObjectStore,IDBIndex,IDBCursor,IDBTransaction])).some(t=>e instanceof t)?new Proxy(t,N):t);var e}function k(t){if(t instanceof IDBRequest)return function(t){const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"success\",r),t.removeEventListener(\"error\",i)},r=()=>{e(k(t.result)),n()},i=()=>{s(t.error),n()};t.addEventListener(\"success\",r),t.addEventListener(\"error\",i)});return e.then(e=>{e instanceof IDBCursor&&x.set(e,t)}).catch(()=>{}),E.set(e,t),e}(t);if(C.has(t))return C.get(t);const e=T(t);return e!==t&&(C.set(t,e),E.set(e,t)),e}const B=t=>E.get(t);const P=[\"get\",\"getKey\",\"getAll\",\"getAllKeys\",\"count\"],M=[\"put\",\"add\",\"delete\",\"clear\"],W=new Map;function j(t,e){if(!(t instanceof IDBDatabase)||e in t||\"string\"!=typeof e)return;if(W.get(e))return W.get(e);const s=e.replace(/FromIndex$/,\"\"),n=e!==s,r=M.includes(s);if(!(s in(n?IDBIndex:IDBObjectStore).prototype)||!r&&!P.includes(s))return;const i=async function(t,...e){const i=this.transaction(t,r?\"readwrite\":\"readonly\");let a=i.store;return n&&(a=a.index(e.shift())),(await Promise.all([a[s](...e),r&&i.done]))[0]};return W.set(e,i),i}N=(t=>q({},t,{get:(e,s,n)=>j(e,s)||t.get(e,s,n),has:(e,s)=>!!j(e,s)||t.has(e,s)}))(N);try{self[\"workbox:expiration:6.5.4\"]&&_()}catch(t){}const S=\"cache-entries\",K=t=>{const e=new URL(t,location.href);return e.hash=\"\",e.href};class A{constructor(t){this._=null,this.L=t}I(t){const e=t.createObjectStore(S,{keyPath:\"id\"});e.createIndex(\"cacheName\",\"cacheName\",{unique:!1}),e.createIndex(\"timestamp\",\"timestamp\",{unique:!1})}C(t){this.I(t),this.L&&function(t,{blocked:e}={}){const s=indexedDB.deleteDatabase(t);e&&s.addEventListener(\"blocked\",t=>e(t.oldVersion,t)),k(s).then(()=>{})}(this.L)}async setTimestamp(t,e){const s={url:t=K(t),timestamp:e,cacheName:this.L,id:this.N(t)},n=(await this.getDb()).transaction(S,\"readwrite\",{durability:\"relaxed\"});await n.store.put(s),await n.done}async getTimestamp(t){const e=await this.getDb(),s=await e.get(S,this.N(t));return null==s?void 0:s.timestamp}async expireEntries(t,e){const s=await this.getDb();let n=await s.transaction(S).store.index(\"timestamp\").openCursor(null,\"prev\");const r=[];let i=0;for(;n;){const s=n.value;s.cacheName===this.L&&(t&&s.timestamp<t||e&&i>=e?r.push(n.value):i++),n=await n.continue()}const a=[];for(const t of r)await s.delete(S,t.id),a.push(t.url);return a}N(t){return this.L+\"|\"+K(t)}async getDb(){return this._||(this._=await function(t,e,{blocked:s,upgrade:n,blocking:r,terminated:i}={}){const a=indexedDB.open(t,e),o=k(a);return n&&a.addEventListener(\"upgradeneeded\",t=>{n(k(a.result),t.oldVersion,t.newVersion,k(a.transaction),t)}),s&&a.addEventListener(\"blocked\",t=>s(t.oldVersion,t.newVersion,t)),o.then(t=>{i&&t.addEventListener(\"close\",()=>i()),r&&t.addEventListener(\"versionchange\",t=>r(t.oldVersion,t.newVersion,t))}).catch(()=>{}),o}(\"workbox-expiration\",1,{upgrade:this.C.bind(this)})),this._}}class F{constructor(t,e={}){this.O=!1,this.T=!1,this.k=e.maxEntries,this.B=e.maxAgeSeconds,this.P=e.matchOptions,this.L=t,this.M=new A(t)}async expireEntries(){if(this.O)return void(this.T=!0);this.O=!0;const t=this.B?Date.now()-1e3*this.B:0,e=await this.M.expireEntries(t,this.k),s=await self.caches.open(this.L);for(const t of e)await s.delete(t,this.P);this.O=!1,this.T&&(this.T=!1,b(this.expireEntries()))}async updateTimestamp(t){await this.M.setTimestamp(t,Date.now())}async isURLExpired(t){if(this.B){const e=await this.M.getTimestamp(t),s=Date.now()-1e3*this.B;return void 0===e||e<s}return!1}async delete(){this.T=!1,await this.M.expireEntries(1/0)}}try{self[\"workbox:range-requests:6.5.4\"]&&_()}catch(t){}async function H(t,e){try{if(206===e.status)return e;const n=t.headers.get(\"range\");if(!n)throw new s(\"no-range-header\");const r=function(t){const e=t.trim().toLowerCase();if(!e.startsWith(\"bytes=\"))throw new s(\"unit-must-be-bytes\",{normalizedRangeHeader:e});if(e.includes(\",\"))throw new s(\"single-range-only\",{normalizedRangeHeader:e});const n=/(\\d*)-(\\d*)/.exec(e);if(!n||!n[1]&&!n[2])throw new s(\"invalid-range-values\",{normalizedRangeHeader:e});return{start:\"\"===n[1]?void 0:Number(n[1]),end:\"\"===n[2]?void 0:Number(n[2])}}(n),i=await e.blob(),a=function(t,e,n){const r=t.size;if(n&&n>r||e&&e<0)throw new s(\"range-not-satisfiable\",{size:r,end:n,start:e});let i,a;return void 0!==e&&void 0!==n?(i=e,a=n+1):void 0!==e&&void 0===n?(i=e,a=r):void 0!==n&&void 0===e&&(i=r-n,a=r),{start:i,end:a}}(i,r.start,r.end),o=i.slice(a.start,a.end),c=o.size,h=new Response(o,{status:206,statusText:\"Partial Content\",headers:e.headers});return h.headers.set(\"Content-Length\",String(c)),h.headers.set(\"Content-Range\",`bytes ${a.start}-${a.end-1}/${i.size}`),h}catch(t){return new Response(\"\",{status:416,statusText:\"Range Not Satisfiable\"})}}function $(t,e){const s=e();return t.waitUntil(s),s}try{self[\"workbox:precaching:6.5.4\"]&&_()}catch(t){}function z(t){if(!t)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(\"string\"==typeof t){const e=new URL(t,location.href);return{cacheKey:e.href,url:e.href}}const{revision:e,url:n}=t;if(!n)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(!e){const t=new URL(n,location.href);return{cacheKey:t.href,url:t.href}}const r=new URL(n,location.href),i=new URL(n,location.href);return r.searchParams.set(\"__WB_REVISION__\",e),{cacheKey:r.href,url:i.href}}class G{constructor(){this.updatedURLs=[],this.notUpdatedURLs=[],this.handlerWillStart=async({request:t,state:e})=>{e&&(e.originalRequest=t)},this.cachedResponseWillBeUsed=async({event:t,state:e,cachedResponse:s})=>{if(\"install\"===t.type&&e&&e.originalRequest&&e.originalRequest instanceof Request){const t=e.originalRequest.url;s?this.notUpdatedURLs.push(t):this.updatedURLs.push(t)}return s}}}class V{constructor({precacheController:t}){this.cacheKeyWillBeUsed=async({request:t,params:e})=>{const s=(null==e?void 0:e.cacheKey)||this.W.getCacheKeyForURL(t.url);return s?new Request(s,{headers:t.headers}):t},this.W=t}}let J,Q;async function X(t,e){let n=null;if(t.url){n=new URL(t.url).origin}if(n!==self.location.origin)throw new s(\"cross-origin-copy-response\",{origin:n});const r=t.clone(),i={headers:new Headers(r.headers),status:r.status,statusText:r.statusText},a=e?e(i):i,o=function(){if(void 0===J){const t=new Response(\"\");if(\"body\"in t)try{new Response(t.body),J=!0}catch(t){J=!1}J=!1}return J}()?r.body:await r.blob();return new Response(o,a)}class Y extends R{constructor(t={}){t.cacheName=w(t.cacheName),super(t),this.j=!1!==t.fallbackToNetwork,this.plugins.push(Y.copyRedirectedCacheableResponsesPlugin)}async U(t,e){const s=await e.cacheMatch(t);return s||(e.event&&\"install\"===e.event.type?await this.S(t,e):await this.K(t,e))}async K(t,e){let n;const r=e.params||{};if(!this.j)throw new s(\"missing-precache-entry\",{cacheName:this.cacheName,url:t.url});{const s=r.integrity,i=t.integrity,a=!i||i===s;n=await e.fetch(new Request(t,{integrity:\"no-cors\"!==t.mode?i||s:void 0})),s&&a&&\"no-cors\"!==t.mode&&(this.A(),await e.cachePut(t,n.clone()))}return n}async S(t,e){this.A();const n=await e.fetch(t);if(!await e.cachePut(t,n.clone()))throw new s(\"bad-precaching-response\",{url:t.url,status:n.status});return n}A(){let t=null,e=0;for(const[s,n]of this.plugins.entries())n!==Y.copyRedirectedCacheableResponsesPlugin&&(n===Y.defaultPrecacheCacheabilityPlugin&&(t=s),n.cacheWillUpdate&&e++);0===e?this.plugins.push(Y.defaultPrecacheCacheabilityPlugin):e>1&&null!==t&&this.plugins.splice(t,1)}}Y.defaultPrecacheCacheabilityPlugin={cacheWillUpdate:async({response:t})=>!t||t.status>=400?null:t},Y.copyRedirectedCacheableResponsesPlugin={cacheWillUpdate:async({response:t})=>t.redirected?await X(t):t};class Z{constructor({cacheName:t,plugins:e=[],fallbackToNetwork:s=!0}={}){this.F=new Map,this.H=new Map,this.$=new Map,this.u=new Y({cacheName:w(t),plugins:[...e,new V({precacheController:this})],fallbackToNetwork:s}),this.install=this.install.bind(this),this.activate=this.activate.bind(this)}get strategy(){return this.u}precache(t){this.addToCacheList(t),this.G||(self.addEventListener(\"install\",this.install),self.addEventListener(\"activate\",this.activate),this.G=!0)}addToCacheList(t){const e=[];for(const n of t){\"string\"==typeof n?e.push(n):n&&void 0===n.revision&&e.push(n.url);const{cacheKey:t,url:r}=z(n),i=\"string\"!=typeof n&&n.revision?\"reload\":\"default\";if(this.F.has(r)&&this.F.get(r)!==t)throw new s(\"add-to-cache-list-conflicting-entries\",{firstEntry:this.F.get(r),secondEntry:t});if(\"string\"!=typeof n&&n.integrity){if(this.$.has(t)&&this.$.get(t)!==n.integrity)throw new s(\"add-to-cache-list-conflicting-integrities\",{url:r});this.$.set(t,n.integrity)}if(this.F.set(r,t),this.H.set(r,i),e.length>0){const t=`Workbox is precaching URLs without revision info: ${e.join(\", \")}\\nThis is generally NOT safe. Learn more at https://bit.ly/wb-precache`;console.warn(t)}}}install(t){return $(t,async()=>{const e=new G;this.strategy.plugins.push(e);for(const[e,s]of this.F){const n=this.$.get(s),r=this.H.get(e),i=new Request(e,{integrity:n,cache:r,credentials:\"same-origin\"});await Promise.all(this.strategy.handleAll({params:{cacheKey:s},request:i,event:t}))}const{updatedURLs:s,notUpdatedURLs:n}=e;return{updatedURLs:s,notUpdatedURLs:n}})}activate(t){return $(t,async()=>{const t=await self.caches.open(this.strategy.cacheName),e=await t.keys(),s=new Set(this.F.values()),n=[];for(const r of e)s.has(r.url)||(await t.delete(r),n.push(r.url));return{deletedURLs:n}})}getURLsToCacheKeys(){return this.F}getCachedURLs(){return[...this.F.keys()]}getCacheKeyForURL(t){const e=new URL(t,location.href);return this.F.get(e.href)}getIntegrityForCacheKey(t){return this.$.get(t)}async matchPrecache(t){const e=t instanceof Request?t.url:t,s=this.getCacheKeyForURL(e);if(s){return(await self.caches.open(this.strategy.cacheName)).match(s)}}createHandlerBoundToURL(t){const e=this.getCacheKeyForURL(t);if(!e)throw new s(\"non-precached-url\",{url:t});return s=>(s.request=new Request(t),s.params=Object.assign({cacheKey:e},s.params),this.strategy.handle(s))}}const tt=()=>(Q||(Q=new Z),Q);class et extends r{constructor(t,e){super(({request:s})=>{const n=t.getURLsToCacheKeys();for(const r of function*(t,{ignoreURLParametersMatching:e=[/^utm_/,/^fbclid$/],directoryIndex:s=\"index.html\",cleanURLs:n=!0,urlManipulation:r}={}){const i=new URL(t,location.href);i.hash=\"\",yield i.href;const a=function(t,e=[]){for(const s of[...t.searchParams.keys()])e.some(t=>t.test(s))&&t.searchParams.delete(s);return t}(i,e);if(yield a.href,s&&a.pathname.endsWith(\"/\")){const t=new URL(a.href);t.pathname+=s,yield t.href}if(n){const t=new URL(a.href);t.pathname+=\".html\",yield t.href}if(r){const t=r({url:i});for(const e of t)yield e.href}}(s.url,e)){const e=n.get(r);if(e){return{cacheKey:e,integrity:t.getIntegrityForCacheKey(e)}}}},t.strategy)}}t.CacheFirst=class extends R{async U(t,e){let n,r=await e.cacheMatch(t);if(!r)try{r=await e.fetchAndCachePut(t)}catch(t){t instanceof Error&&(n=t)}if(!r)throw new s(\"no-response\",{url:t.url,error:n});return r}},t.ExpirationPlugin=class{constructor(t={}){this.cachedResponseWillBeUsed=async({event:t,request:e,cacheName:s,cachedResponse:n})=>{if(!n)return null;const r=this.V(n),i=this.J(s);b(i.expireEntries());const a=i.updateTimestamp(e.url);if(t)try{t.waitUntil(a)}catch(t){}return r?n:null},this.cacheDidUpdate=async({cacheName:t,request:e})=>{const s=this.J(t);await s.updateTimestamp(e.url),await s.expireEntries()},this.X=t,this.B=t.maxAgeSeconds,this.Y=new Map,t.purgeOnQuotaError&&function(t){g.add(t)}(()=>this.deleteCacheAndMetadata())}J(t){if(t===d())throw new s(\"expire-custom-caches-only\");let e=this.Y.get(t);return e||(e=new F(t,this.X),this.Y.set(t,e)),e}V(t){if(!this.B)return!0;const e=this.Z(t);if(null===e)return!0;return e>=Date.now()-1e3*this.B}Z(t){if(!t.headers.has(\"date\"))return null;const e=t.headers.get(\"date\"),s=new Date(e).getTime();return isNaN(s)?null:s}async deleteCacheAndMetadata(){for(const[t,e]of this.Y)await self.caches.delete(t),await e.delete();this.Y=new Map}},t.NetworkFirst=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u),this.tt=t.networkTimeoutSeconds||0}async U(t,e){const n=[],r=[];let i;if(this.tt){const{id:s,promise:a}=this.et({request:t,logs:n,handler:e});i=s,r.push(a)}const a=this.st({timeoutId:i,request:t,logs:n,handler:e});r.push(a);const o=await e.waitUntil((async()=>await e.waitUntil(Promise.race(r))||await a)());if(!o)throw new s(\"no-response\",{url:t.url});return o}et({request:t,logs:e,handler:s}){let n;return{promise:new Promise(e=>{n=setTimeout(async()=>{e(await s.cacheMatch(t))},1e3*this.tt)}),id:n}}async st({timeoutId:t,request:e,logs:s,handler:n}){let r,i;try{i=await n.fetchAndCachePut(e)}catch(t){t instanceof Error&&(r=t)}return t&&clearTimeout(t),!r&&i||(i=await n.cacheMatch(e)),i}},t.RangeRequestsPlugin=class{constructor(){this.cachedResponseWillBeUsed=async({request:t,cachedResponse:e})=>e&&t.headers.has(\"range\")?await H(t,e):e}},t.StaleWhileRevalidate=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u)}async U(t,e){const n=e.fetchAndCachePut(t).catch(()=>{});e.waitUntil(n);let r,i=await e.cacheMatch(t);if(i);else try{i=await n}catch(t){t instanceof Error&&(r=t)}if(!i)throw new s(\"no-response\",{url:t.url,error:r});return i}},t.cleanupOutdatedCaches=function(){self.addEventListener(\"activate\",t=>{const e=w();t.waitUntil((async(t,e=\"-precache-\")=>{const s=(await self.caches.keys()).filter(s=>s.includes(e)&&s.includes(self.registration.scope)&&s!==t);return await Promise.all(s.map(t=>self.caches.delete(t))),s})(e).then(t=>{}))})},t.clientsClaim=function(){self.addEventListener(\"activate\",()=>self.clients.claim())},t.precacheAndRoute=function(t,e){!function(t){tt().precache(t)}(t),function(t){const e=tt();h(new et(e,t))}(e)},t.registerRoute=h});\n",
    "wix/WixUI_CustomProgress.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\">\n  <Fragment>\n    <UI>\n      <!-- Override the default InstallProgress dialog -->\n      <Dialog Id=\"InstallProgressDlg\" Width=\"370\" Height=\"270\" Title=\"Fortuna Faucet Installation\" Modeless=\"yes\">\n        <Control Id=\"Title\" Type=\"Title\" X=\"20\" Y=\"6\" Width=\"330\" Height=\"18\" Text=\"Installation Progress\" />\n        <Control Id=\"BannerBitmap\" Type=\"Bitmap\" X=\"0\" Y=\"0\" Width=\"370\" Height=\"44\" TabSkip=\"no\" Text=\"WixUI_Bmp_Banner\" />\n        <Control Id=\"Back\" Type=\"PushButton\" X=\"180\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Back\" Disabled=\"yes\" />\n        <Control Id=\"Next\" Type=\"PushButton\" X=\"236\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Next\" Disabled=\"yes\" />\n        <Control Id=\"Cancel\" Type=\"PushButton\" X=\"304\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"Cancel\" />\n\n        <Control Id=\"ActionText\" Type=\"Text\" X=\"70\" Y=\"80\" Width=\"280\" Height=\"20\" TabSkip=\"no\">\n          <Subscribe Event=\"ActionText\" Attribute=\"Text\" />\n        </Control>\n        <Control Id=\"Description\" Type=\"Text\" X=\"35\" Y=\"55\" Width=\"300\" Height=\"20\" Text=\"Please wait while the installer copies files.\" />\n\n        <!-- This is the new control to display the current filename -->\n        <Control Id=\"CurrentFileText\" Type=\"Text\" X=\"70\" Y=\"100\" Width=\"280\" Height=\"20\">\n            <Subscribe Event=\"SetProgress\" Attribute=\"Text\" />\n        </Control>\n\n        <Control Id=\"ProgressBar\" Type=\"ProgressBar\" X=\"35\" Y=\"120\" Width=\"300\" Height=\"10\" ProgressBlocks=\"yes\" Text=\"Progress\">\n          <Subscribe Event=\"SetProgress\" Attribute=\"Progress\" />\n        </Control>\n      </Dialog>\n\n      <!-- The Publish element must be a child of UI, not Dialog -->\n      <Publish Dialog=\"InstallProgressDlg\" Control=\"Cancel\" Event=\"SpawnDialog\" Value=\"CancelDlg\">1</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n"
}