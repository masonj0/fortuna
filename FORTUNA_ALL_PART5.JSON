{
    ".github/actions/run-smoke-test/action.yml": "name: 'Run Smoke Test (Socket Handover)'\ndescription: 'Launches an executable, waits for a socket to be bound, and performs a health check.'\ninputs:\n  exe-path:\n    description: 'Path to the executable to launch'\n    required: true\n  service-port:\n    description: 'Port to wait for on localhost'\n    required: true\n  health-endpoint:\n    description: 'Health endpoint to check (e.g., /health)'\n    required: false\n    default: '/health'\n  api-key:\n    description: 'API key for the service'\n    required: false\nruns:\n  using: 'composite'\n  steps:\n    - name: Run Python Smoke Test\n      shell: python\n      run: |\n        import os, sys, subprocess, socket, time, threading\n        from contextlib import closing\n\n        # --- CONFIGURATION ---\n        EXE_PATH = os.environ.get(\"INPUT_EXE-PATH\")\n        HOST = \"127.0.0.1\"\n        PORT = int(os.environ.get(\"INPUT_SERVICE-PORT\"))\n        HEALTH_ENDPOINT = os.environ.get(\"INPUT_HEALTH-ENDPOINT\", \"/health\")\n        API_KEY = os.environ.get(\"INPUT_API-KEY\", \"default-key\")\n        STARTUP_TIMEOUT = 90  # seconds\n        POLL_INTERVAL = 0.5   # seconds\n        STDOUT_LOG = \"service-logs/stdout.txt\"\n        STDERR_LOG = \"service-logs/stderr.txt\"\n        PID_FILE = \"service.pid\"\n\n        # --- UTILITY FUNCTIONS ---\n        def print_banner(message):\n            print(f\"\\\\n{'='*25} {message} {'='*25}\")\n\n        def check_socket(host, port):\n            with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:\n                return sock.connect_ex((host, port)) == 0\n\n        def tail_file(filename, lines=10):\n            try:\n                with open(filename, \"r\") as f:\n                    content = f.readlines()\n                return \"\".join(content[-lines:])\n            except FileNotFoundError:\n                return \"Log file not found.\"\n            except Exception as e:\n                return f\"Error reading log: {e}\"\n\n        # --- MAIN LOGIC ---\n        def main():\n            print_banner(\"SOCKET HANDOVER PROTOCOL INITIATED\")\n\n            # 1. Pre-flight check: Find a free port\n            print(f\"Checking if port {PORT} is available...\")\n            if check_socket(HOST, PORT):\n                print(f\"\u274c FATAL: Port {PORT} is already in use before starting the service.\")\n                sys.exit(1)\n            print(f\"\u2705 Port {PORT} is free.\")\n\n            # 2. Launch the service executable\n            print_banner(f\"LAUNCHING {os.path.basename(EXE_PATH)}\")\n            launch_env = os.environ.copy()\n            launch_env[\"FORTUNA_PORT\"] = str(PORT)\n            launch_env[\"API_KEY\"] = API_KEY\n            launch_env[\"FORTUNA_ENV\"] = \"smoke-test\"\n            launch_env[\"PYTHONUNBUFFERED\"] = \"1\"\n\n            if not os.path.exists(EXE_PATH):\n                print(f\"\u274c FATAL: Executable not found at {EXE_PATH}\")\n                sys.exit(1)\n\n            with open(STDOUT_LOG, \"wb\") as out_log, open(STDERR_LOG, \"wb\") as err_log:\n                process = subprocess.Popen([EXE_PATH], env=launch_env, stdout=out_log, stderr=err_log)\n\n            with open(PID_FILE, \"w\") as f:\n                f.write(str(process.pid))\n            print(f\"\ud83d\ude80 Service process started with PID: {process.pid}\")\n            print(f\"   - stdout -> {STDOUT_LOG}\")\n            print(f\"   - stderr -> {STDERR_LOG}\")\n\n            # 3. Wait for the socket to be bound\n            print_banner(f\"WAITING FOR SOCKET BIND ON {HOST}:{PORT}\")\n            start_time = time.time()\n            bound = False\n            while time.time() - start_time < STARTUP_TIMEOUT:\n                if process.poll() is not None:\n                    print(f\"\u274c FATAL: Process terminated unexpectedly with exit code {process.poll()}.\")\n                    break\n                if check_socket(HOST, PORT):\n                    print(f\"\u2705 Socket is now bound! (Took {time.time() - start_time:.2f}s)\")\n                    bound = True\n                    break\n                time.sleep(POLL_INTERVAL)\n                print(f\"   ... waiting ({time.time() - start_time:.1f}s)\", end=\"\\\\r\")\n\n            if not bound:\n                print(f\"\u274c FATAL: Timed out after {STARTUP_TIMEOUT}s waiting for port {PORT} to be bound.\")\n\n            # 4. Final Verification and Diagnostics\n            print_banner(\"FINAL DIAGNOSTICS\")\n            print(f\"STDOUT (Last 10 lines):\\\\n{tail_file(STDOUT_LOG)}\")\n            print(f\"STDERR (Last 10 lines):\\\\n{tail_file(STDERR_LOG)}\")\n\n            if process.poll() is not None:\n                print(\"\u274c Final state: PROCESS IS DEAD.\")\n                sys.exit(1)\n            else:\n                print(\"\u2705 Final state: PROCESS IS ALIVE.\")\n\n            if not bound:\n                print(\"\u274c Final state: SOCKET NOT BOUND.\")\n                sys.exit(1)\n            else:\n                print(\"\u2705 Final state: SOCKET IS BOUND.\")\n\n            print_banner(\"SOCKET HANDOVER SUCCESSFUL\")\n            sys.exit(0)\n\n        if __name__ == \"__main__\":\n            main()\n      env:\n        INPUT_EXE-PATH: ${{ inputs.exe-path }}\n        INPUT_SERVICE-PORT: ${{ inputs.service-port }}\n        INPUT_HEALTH-ENDPOINT: ${{ inputs.health-endpoint }}\n        INPUT_API-KEY: ${{ inputs.api-key }}",
    "PSEUDOCODE.MD": "# \ud83d\udc0e Fortuna Faucet - Complete Pseudocode Blueprint\n\n**Status:** Comprehensive System Specification (Revised & Corrected)\n**Version:** 2.2.0\n**Last Updated:** November 7, 2025\n\n---\n\n## TABLE OF CONTENTS\n\n1.  System Overview\n2.  Architecture Pillars\n3.  Backend Engine (Python) - Detailed\n4.  Frontend Interface (TypeScript/React) - Detailed\n5.  Electron Wrapper & Windows Integration - Detailed\n6.  Data Models & API Specification\n7.  Deployment & Automation (CI/CD)\n8.  End-to-End Workflows\n\n---\n\n## 1. SYSTEM OVERVIEW\n\n```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551         FORTUNA FAUCET - Racing Analysis Platform             \u2551\n\u2551  Unifying global horse/greyhound/harness racing intelligence   \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nMISSION:\n  \u2022 Acquire race data from 20+ global sources (APIs + web scraping).\n  \u2022 Normalize and deduplicate data into a canonical Race format.\n  \u2022 Apply analytical filters to surface high-value betting opportunities.\n  \u2022 Serve results via a secure, local REST API to an interactive dashboard.\n  \u2022 Operate as a professional, standalone, native Windows application.\n\nCORE TENETS:\n  \u2022 UI-First Experience: The user interface is always responsive, even during backend startup or restarts.\n  \u2022 Resilient Process Management: The backend executable's lifecycle is robustly managed, with timeouts and crash detection.\n  \u2022 Asynchronous Initialization: The backend server starts instantly, deferring heavy, blocking I/O to background threads.\n  \u2022 Secure by Design: Communication between the frontend and the privileged main process is secured via a context-aware preload script.\n  \u2022 Automated & Repeatable Builds: The entire application is built, tested, and packaged via a deterministic CI/CD pipeline.\n\nSTAKEHOLDERS:\n  \u2022 End User: Receives a professional MSI installer for a one-click, dependency-free launch.\n  \u2022 Developer: Works with clean, separated Python and TypeScript stacks, governed by this specification.\n```\n\n---\n\n## 2. ARCHITECTURE PILLARS\n\n### Pillar 1: Backend Engine (Python)\n\n```\nPYTHON_BACKEND:\n  \u251c\u2500 main.py\n  \u2502  \u2514\u2500 Entry point for PyInstaller executable; starts the Uvicorn server.\n  \u2502\n  \u251c\u2500 api.py\n  \u2502  \u2514\u2500 FastAPI application definition.\n  \u2502     \u251c\u2500 Lifespan Hook: Manages async startup/shutdown logic.\n  \u2502     \u251c\u2500 API Routes: /health, /api/status, /api/races, etc.\n  \u2502     \u2514\u2500 Dependency Injection: Provides engine and security dependencies.\n  \u2502\n  \u251c\u2500 engine.py\n  \u2502  \u2514\u2500 OddsEngine: Orchestrates all data fetching and processing.\n  \u2502\n  \u251c\u2500 adapters/\n  \u2502  \u251c\u2500 base_v3.py (Abstract Base Class for all data sources)\n  \u2502  \u2514\u2500 [20+ specific adapter implementations]\n  \u2502\n  \u251c\u2500 config.py\n  \u2502  \u2514\u2500 Pydantic settings management from .env file.\n  \u2502\n  \u2514\u2500 requirements.txt\n     \u2514\u2500 Clean, de-duplicated, and conflict-free list of all Python dependencies.\n```\n\n### Pillar 2: Frontend Interface (TypeScript/React)\n\n```\nFRONTEND:\n  \u251c\u2500 next.config.mjs\n  \u2502  \u2514\u2500 Next.js config with `output: 'export'` for 100% static generation.\n  \u2502\n  \u251c\u2500 app/page.tsx\n  \u2502  \u2514\u2500 Main application shell.\n  \u2502\n  \u251c\u2500 src/components/\n  \u2502  \u251c\u2500 LiveRaceDashboard.tsx (Main stateful component)\n  \u2502  \u2502  \u251c\u2500 Manages connection state ('connecting', 'online', 'error').\n  \u2502  \u2502  \u251c\u2500 Polls Electron main process for backend status via secure IPC.\n  \u2502  \u2502  \u2514\u2500 Fetches data from the local Python API when online.\n  \u2502  \u2502\n  \u2502  \u251c\u2500 RaceCard.tsx (Displays a single race)\n  \u2502  \u2514\u2500 StatusIndicator.tsx (Shows backend connection status)\n  \u2502\n  \u2514\u2500 src/types/\n     \u2514\u2500 racing.ts (TypeScript interfaces matching backend Pydantic models)\n```\n\n### Pillar 3: Electron Wrapper & Windows Integration\n\n```\nELECTRON_WRAPPER:\n  \u251c\u2500 main.js (Electron main process)\n  \u2502  \u251c\u2500 Creates the BrowserWindow and loads the static frontend.\n  \u2502  \u251c\u2500 Implements robust lifecycle management for the backend executable.\n  \u2502  \u251c\u2500 Provides secure IPC handlers for status checks and restarts.\n  \u2502  \u2514\u2500 Creates a system tray icon for background operation.\n  \u2502\n  \u251c\u2500 preload.js (Secure IPC Bridge)\n  \u2502  \u2514\u2500 Uses `contextBridge` to safely expose specific functions to the frontend.\n  \u2502\n  \u251c\u2500 package.json\n  \u2502  \u2514\u2500 Defines Node.js dependencies and build scripts.\n  \u2502\n  \u251c\u2500 electron-builder-config.yml\n  \u2502  \u2514\u2500 Defines the configuration for creating the final MSI installer.\n  \u2502\n  \u2514\u2500 .github/workflows/build-msi.yml\n     \u2514\u2500 GitHub Actions pipeline that automates the entire build, test, and package process.\n```\n\n---\n\n## 3. BACKEND ENGINE (PYTHON) - DETAILED\n\n### 3.1 Entry Point & Server Startup (`main.py`)\n\n```pseudocode\n// This is the script executed by fortuna-backend.exe\n\nPROCEDURE Main_Python_Entry_Point\n  // Guard required for PyInstaller and multiprocessing on Windows\n  IF this script is the main entry point:\n    CALL multiprocessing.freeze_support()\n\n    // Programmatically launch the FastAPI application using Uvicorn\n    // This call blocks and runs the server until the process is terminated\n    CALL uvicorn.run(\n      app=\"python_service.api:app\",\n      host=\"0.0.0.0\",\n      port=8000\n    )\nEND PROCEDURE\n```\n\n### 3.2 Asynchronous Application Lifecycle (`api.py`)\n\n```pseudocode\n// --- Lifespan Management (The key to a non-blocking startup) ---\nASYNC FUNCTION lifespan_manager(app: FastAPI):\n  // === ON STARTUP ===\n  LOG \"Uvicorn server is online. Starting lifespan initialization.\"\n\n  // 1. Perform immediate, non-blocking tasks\n  CONNECT to Redis cache\n\n  // 2. Defer slow, blocking tasks to a background thread\n  //    This allows the server to start accepting requests instantly.\n  SCHEDULE function \"initialize_heavy_resources(app)\" to run in a ThreadPoolExecutor\n\n  LOG \"Heavy resource initialization scheduled. Server is now responsive.\"\n\n  // 3. Yield control back to Uvicorn. The server is now live.\n  YIELD\n\n  // === ON SHUTDOWN ===\n  LOG \"Shutdown signal received.\"\n  AWAIT app.state.engine.close() // Gracefully close HTTP client connections\n  DISCONNECT from Redis\n  SHUTDOWN ThreadPoolExecutor\n\n// --- Heavy Initialization (Runs in Background) ---\nFUNCTION initialize_heavy_resources(app: FastAPI):\n  TRY\n    LOG \"Background initialization of OddsEngine has started.\"\n    settings <- get_settings_from_config()\n    engine <- create new OddsEngine(config=settings)\n    // This part is slow: it loads all ~25 adapters\n    app.state.engine <- engine\n    LOG \"Background initialization complete. OddsEngine is now available.\"\n  CATCH Exception as e:\n    LOG_CRITICAL \"Failed to initialize OddsEngine in the background.\", error=e\n    app.state.engine <- null // Ensure the app knows initialization failed\n```\n\n### 3.3 Engine Orchestration (`engine.py`)\n\n```pseudocode\nCLASS OddsEngine:\n  INIT(config):\n    self.config <- config\n    self.adapters <- [List of all adapter instances]\n    self.http_client <- httpx.AsyncClient(...)\n    self.semaphore <- asyncio.Semaphore(config.MAX_CONCURRENT_REQUESTS)\n\n    // Inject the shared, persistent HTTP client into each adapter\n    FOR adapter IN self.adapters:\n      adapter.http_client <- self.http_client\n\n  @cache_async_result(ttl_seconds=300)\n  ASYNC FUNCTION fetch_all_odds(date_str):\n    // Create a list of concurrent fetching tasks, wrapped in the semaphore\n    tasks <- [self._fetch_with_semaphore(adapter, date_str) FOR adapter in self.adapters]\n    results <- AWAIT asyncio.gather(*tasks, return_exceptions=True)\n\n    // Process results, separating successes from failures\n    all_races <- []\n    FOR result IN results:\n      IF result is a success:\n        all_races.extend(result.races)\n\n    // Deduplicate and merge races from different sources\n    deduped_races <- self._dedupe_races(all_races)\n\n    RETURN AggregatedResponse(races=deduped_races, source_statuses=...)\n```\n\n---\n\n## 4. FRONTEND INTERFACE (TYPESCRIPT/REACT) - DETAILED\n\n### 4.1 LiveRaceDashboard Component\n\n```pseudocode\nCOMPONENT LiveRaceDashboard (client-side):\n\n  STATE:\n    races: Race[] <- []\n    backendStatus: 'connecting' | 'online' | 'error' <- 'connecting'\n    lastLogs: string[] <- []\n\n  EFFECT on mount:\n    // Use the secure API exposed by preload.js\n    IF window.electronAPI exists:\n      // Set up a listener for status updates from the main process\n      window.electronAPI.onBackendStatus((update) => {\n        setBackendStatus(update.state)\n        setLastLogs(update.logs)\n      })\n\n    // Immediately request the current status\n    window.electronAPI.getBackendStatus().then((status) => {\n      setBackendStatus(status.state)\n      setLastLogs(status.logs)\n    })\n\n    // Set up a polling interval to keep status fresh\n    interval <- setInterval(() => {\n      window.electronAPI.getBackendStatus().then((status) => {\n        setBackendStatus(status.state)\n        setLastLogs(status.logs)\n      })\n    }, 3000) // Poll every 3 seconds\n\n    CLEANUP: clearInterval(interval)\n\n  EFFECT when backendStatus changes to 'online':\n    // Trigger data fetch only when the backend is confirmed to be running\n    fetchQualifiedRaces()\n\n  ASYNC FUNCTION fetchQualifiedRaces():\n    TRY:\n      // Make a standard HTTP call to the local Python server\n      response <- AWAIT fetch(\"http://127.0.0.1:8000/api/races/qualified/trifecta\")\n      IF NOT response.ok:\n        RAISE new Error(`API returned status ${response.status}`)\n\n      data <- AWAIT response.json()\n      setRaces(data.races)\n\n    CATCH e:\n      // If the API call fails, update the status\n      setBackendStatus('error')\n      setLastLogs([...lastLogs, `API Fetch Error: ${e.message}`])\n\n  FUNCTION RENDER:\n    <div className=\"dashboard\">\n      <StatusIndicator status={backendStatus} />\n      <RaceFilters />\n\n      IF backendStatus === 'error':\n        <ErrorDisplay logs={lastLogs} />\n      ELSE IF backendStatus === 'connecting':\n        <LoadingSkeleton />\n      ELSE IF races.length === 0:\n        <EmptyState message=\"No races matched your filters.\" />\n      ELSE:\n        <RaceGrid races={races} />\n    </div>\n```\n\n---\n\n## 5. ELECTRON WRAPPER & WINDOWS INTEGRATION - DETAILED\n\n### 5.1 Main Process (`main.js`) - With Robust Lifecycle Management\n\n```pseudocode\nCLASS FortunaDesktopApp:\n  INIT():\n    self.mainWindow <- null\n    self.backendState <- 'stopped'\n    self.backendLogs <- []\n    self.backendProcess <- null\n\n  FUNCTION createMainWindow():\n    // ... create BrowserWindow, load static frontend ...\n\n  FUNCTION startBackend():\n    IF self.backendProcess is not null:\n      self.backendProcess.kill()\n\n    self.backendState <- 'starting'\n    self.backendLogs <- ['Attempting to start backend...']\n    self.sendBackendStatusUpdate() // Notify UI\n\n    // Get path to the packaged executable\n    exePath <- path.join(process.resourcesPath, 'fortuna-backend', 'fortuna-backend.exe')\n\n    IF file at exePath does NOT exist:\n      self.backendState <- 'error'\n      self.backendLogs.push(`FATAL: Executable not found at ${exePath}`)\n      self.sendBackendStatusUpdate()\n      dialog.showErrorBox(\"Critical Error\", \"Backend is missing. Please reinstall.\")\n      RETURN\n\n    // Spawn the process\n    self.backendProcess <- spawn(exePath, [], { stdio: ['ignore', 'pipe', 'pipe'] })\n\n    // --- CRITICAL: Resiliency Logic ---\n    startupTimeout <- setTimeout(() => {\n      IF self.backendState === 'starting':\n        self.backendState <- 'error'\n        self.backendLogs.push('Error: Backend startup timed out after 30 seconds.')\n        self.backendProcess.kill()\n        self.sendBackendStatusUpdate()\n    }, 30000) // 30-second timeout\n\n    self.backendProcess.stdout.on('data', (data) => {\n      self.backendLogs.push(data.toString())\n      // A more robust check would be a successful health check poll\n      IF data.toString().includes(\"Uvicorn running\"):\n        self.backendState <- 'online'\n        clearTimeout(startupTimeout)\n        self.sendBackendStatusUpdate()\n    })\n\n    self.backendProcess.stderr.on('data', (data) => {\n      self.backendLogs.push(`[STDERR] ${data.toString()}`)\n    })\n\n    self.backendProcess.on('exit', (code) => {\n      clearTimeout(startupTimeout)\n      IF self.backendState is not 'error': // Avoid duplicate error messages\n        self.backendState <- 'error'\n        self.backendLogs.push(`Backend process exited unexpectedly with code: ${code}`)\n        self.sendBackendStatusUpdate()\n    })\n\n  FUNCTION sendBackendStatusUpdate():\n    // Send the latest status to the frontend renderer process\n    IF self.mainWindow is not null:\n      self.mainWindow.webContents.send('backend-status-update', {\n        state: self.backendState,\n        logs: self.backendLogs.slice(-20) // Send last 20 log lines\n      })\n\n// --- IPC Handlers (Securely Defined) ---\nipcMain.handle('get-backend-status', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN null\n\n  RETURN { state: self.backendState, logs: self.backendLogs.slice(-20) }\n})\n\nipcMain.on('restart-backend', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN\n\n  self.startBackend()\n})\n```\n\n### 5.2 Preload Script (`preload.js`)\n\n```pseudocode\n// Expose a limited, secure API to the frontend renderer process\ncontextBridge.exposeInMainWorld('electronAPI', {\n  getBackendStatus: () => ipcRenderer.invoke('get-backend-status'),\n  restartBackend: () => ipcRenderer.send('restart-backend'),\n  onBackendStatus: (callback) => ipcRenderer.on('backend-status-update', (_event, value) => callback(value))\n})\n```\n\n---\n\n## 6. DATA MODELS & API SPECIFICATION\n\n### 6.1 Core Data Models (Pydantic/TypeScript)\n\n```\nMODEL Race:\n  id: str (unique identifier, e.g., \"Betfair_USA_Aqueduct_2025-11-07_R1\")\n  venue: str\n  race_number: int\n  start_time: datetime\n  runners: List[Runner]\n  source: str\n\nMODEL Runner:\n  name: str\n  odds: Optional[float]\n```\n\n### 6.2 Primary API Endpoints\n\n```\nENDPOINT GET /health\n  Description: Simple health check, requires no authentication.\n  Response (200 OK): {\"status\": \"ok\"}\n\nENDPOINT GET /api/races/qualified/trifecta\n  Description: Fetches all race data, runs the Trifecta analyzer, and returns qualified races.\n  Headers:\n    - X-API-Key: (Required, not used in this local setup but good practice)\n  Query Params:\n    - max_field_size: int\n    - min_odds: float\n  Response (200 OK):\n    {\n      \"qualified_races\": List[Race],\n      \"analysis_metadata\": { ... }\n    }\n```\n\n---\n\n## 7. DEPLOYMENT & AUTOMATION (CI/CD)\n\n```pseudocode\nWORKFLOW Build_MSI_Installer_on_GitHub_Actions:\n  // Phase 1: Setup\n  SETUP Node.js and Python environments\n\n  // Phase 2: Build Frontend\n  RUN \"npm ci\" and \"npm run build\" in /web_platform/frontend\n  COPY static output to /electron/web-ui-build/out\n\n  // Phase 3: Build Backend\n  RUN \"pip install -r python_service/requirements.txt\"\n  // CRITICAL: Use PyInstaller with a spec file or CLI flags that include\n  // necessary hidden imports to prevent runtime crashes.\n  // e.g., --hidden-import=keyring.backends.fail.Keyring\n  EXECUTE PyInstaller to create fortuna-backend.exe\n  PLACE executable in /electron/resources/fortuna-backend\n\n  // Phase 4: Deep Integration Test\n  START fortuna-backend.exe in the background\n  POLL http://127.0.0.1:8000/health until it responds with 200 OK or times out\n  IF timeout or crash THEN FAIL the build\n\n  // Phase 5: Package\n  RUN \"npm ci\" in /electron\n  EXECUTE \"npx electron-builder\" to create the MSI installer\n\n  // Phase 6: Publish\n  UPLOAD MSI as a build artifact\n  IF build was triggered by a git tag THEN CREATE a new GitHub Release\n```\n\n---\n\n## 8. END-TO-END WORKFLOWS\n\n### 8.1 Production Startup Workflow (Resilient)\n\n```\nWORKFLOW user_launches_application:\n  STEP 1: User executes Fortuna Faucet.exe -> Electron main.js starts.\n  STEP 2: UI appears instantly. The main process creates the BrowserWindow and loads the static index.html. The UI shows a 'connecting' state.\n  STEP 3: Backend starts asynchronously. The main process calls the robust `startBackend()` function.\n  STEP 4: `startBackend()` spawns `fortuna-backend.exe` and starts a 30-second timeout.\n  STEP 5: The frontend UI polls for status every 3 seconds via the secure `window.electronAPI.getBackendStatus()`.\n  STEP 6: The backend `.exe` starts, its `lifespan` hook runs, and the Uvicorn server comes online within seconds.\n  STEP 7: The main process detects the \"Uvicorn running\" message (or a successful health poll) and updates its internal state to 'online'. The startup timeout is cleared.\n  STEP 8: On its next poll, the frontend receives the 'online' status.\n  STEP 9: The frontend's state changes, triggering the `fetchQualifiedRaces()` API call to `localhost:8000`.\n  STEP 10: Data is returned from the now fully-initialized backend and rendered in the UI.\n\n  FAILURE SCENARIO (Backend Crash):\n  STEP 6a: The backend `.exe` crashes on startup.\n  STEP 7a: The `on('exit')` handler in `main.js` fires. The state is set to 'error' with the exit code.\n  STEP 8a: On its next poll, the frontend receives the 'error' status and relevant logs.\n  STEP 9a: The UI renders an error message and a \"Restart Backend\" button.\n```\n\n---\n*This concludes the revised and definitive blueprint for the Fortuna Faucet application.*",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2)---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "electron/assets/.gitkeep": "# This directory is for application icons (e.g., icon.ico, tray-icon.png)",
    "electron/assets/license.rtf": "{\\rtf1\\ansi\\deff0\n{\\fonttbl{\\f0 Courier New;}}\n\\f0\\fs20\nFortuna Faucet License Agreement\\line\n\\line\nThis is a hobby project. It was cobbled together with a lot of caffeine and hope.\\line\n\\line\nThere are no warranties, guarantees, or promises that this will work.\\line\nFeel free to use it, break it, or share it. No copyrights are claimed.\\line\n\\line\nGood luck! You might need it.\n}",
    "electron/install-dependencies.js": "const { execSync } = require('child_process');\nconst path = require('path');\nconst fs = require('fs');\n\n// Path to the bundled Python executable (fortuna-backend.exe)\nconst PYTHON_EXE = path.join(process.resourcesPath, 'fortuna-backend.exe');\n// Path to the Python service directory (where alembic.ini is)\nconst PYTHON_SERVICE_DIR = path.join(process.resourcesPath, 'python_service');\n\nfunction runCommand(command, cwd) {\n    console.log(`Executing: ${command} in ${cwd}`);\n    try {\n        const output = execSync(command, { cwd: cwd, encoding: 'utf-8' });\n        console.log(output);\n    } catch (error) {\n        console.error(`Command failed: ${command}`);\n        console.error(error.stderr || error.stdout || error.message);\n        throw new Error(`Post-install setup failed: ${command}`);\n    }\n}\n\nfunction setupDatabase() {\n    console.log('--- Starting Database Setup (Alembic Migrations) ---');\n    // NOTE: The bundled EXE must be able to run a command like 'alembic' or a custom script\n    // that executes the migrations. Assuming the bundled EXE can run a module.\n    // A more robust solution is to bundle a dedicated migration script.\n\n    // Assuming the bundled EXE can execute a module that runs Alembic\n    const migrationCommand = `${PYTHON_EXE} -m python_service.database.run_migrations`;\n\n    // The migration script needs access to the database URL from the config.\n    // This is a placeholder, as the config loading is complex in a frozen app.\n    // For now, we assume the bundled EXE handles config loading.\n\n    runCommand(migrationCommand, PYTHON_SERVICE_DIR);\n    console.log('--- Database Setup Complete ---');\n}\n\n// This function is called by the Electron Builder installer hook\nmodule.exports = async function() {\n    try {\n        setupDatabase();\n    } catch (e) {\n        console.error('FATAL: Post-install setup failed.', e);\n        // In a real installer, you might log this and continue, or show a user error.\n    }\n};\n",
    "electron/secure-settings-manager.js": "// electron/secure-settings-manager.js\nconst { app } = require('electron');\nconst fs = require('fs');\nconst path = require('path');\n\nconst SETTINGS_FILE = path.join(app.getPath('userData'), 'settings.json');\n\nclass SecureSettingsManager {\n constructor() {\n this.settings = this.loadSettings();\n }\n\n loadSettings() {\n try {\n if (fs.existsSync(SETTINGS_FILE)) {\n const data = fs.readFileSync(SETTINGS_FILE, 'utf-8');\n return JSON.parse(data);\n }\n } catch (error) {\n console.error('Error loading settings:', error);\n }\n return {};\n }\n\n saveSettings() {\n try {\n fs.writeFileSync(SETTINGS_FILE, JSON.stringify(this.settings, null, 2));\n } catch (error) {\n console.error('Error saving settings:', error);\n }\n }\n\n getApiKey() {\n return this.settings.apiKey || null;\n }\n\n saveApiKey(apiKey) {\n this.settings.apiKey = apiKey;\n this.saveSettings();\n return { success: true };\n }\n\n getBetfairCredentials() {\n return this.settings.betfair || null;\n }\n\n saveBetfairCredentials(credentials) {\n this.settings.betfair = credentials;\n this.saveSettings();\n return { success: true };\n }\n}\n\nmodule.exports = new SecureSettingsManager();\n",
    "fortuna-backend-webservice.spec": "# -*- mode: python ; coding: utf-8 -*-\n\nimport os\nfrom pathlib import Path\nfrom textwrap import dedent\n\nfrom PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\nblock_cipher = None\nproject_root = Path(SPECPATH)\nversion_string = os.environ.get(\"FORTUNA_VERSION\", \"0.0.0\")\n\n\ndef ensure_path(rel_path: str) -> Path:\n    target = project_root / rel_path\n    if not target.exists():\n        raise SystemExit(f\"[spec] Required path missing: {target}\")\n    return target\n\n\ndef include_tree(rel_path: str, target: str, store: list):\n    absolute = ensure_path(rel_path)\n    store.append((str(absolute), target))\n    print(f\"[spec] Including {absolute} -> {target}\")\n\n\ndef build_version_file(version: str) -> str:\n    parts = [int(p) for p in version.split(\".\") if p.isdigit()]\n    while len(parts) < 4:\n        parts.append(0)\n    parts = parts[:4]\n    file_content = dedent(\n        f\"\"\"\n        VSVersionInfo(\n          ffi=FixedFileInfo(\n            filevers={tuple(parts)},\n            prodvers={tuple(parts)},\n            mask=0x3f,\n            flags=0x0,\n            OS=0x40004,\n            fileType=0x1,\n            subtype=0x0,\n            date=(0, 0)\n          ),\n          kids=[\n            StringFileInfo([\n              StringTable(\n                '040904B0',\n                [\n                  StringStruct('CompanyName', 'Fortuna Development Team'),\n                  StringStruct('FileDescription', 'Fortuna Backend Web Service'),\n                  StringStruct('FileVersion', '{version}'),\n                  StringStruct('InternalName', 'fortuna-backend'),\n                  StringStruct('ProductName', 'Fortuna Web Service'),\n                  StringStruct('ProductVersion', '{version}')\n                ]\n              )\n            ]),\n            VarFileInfo([VarStruct('Translation', [1033, 1200])])\n          ]\n        )\n        \"\"\"\n    ).strip()\n    version_dir = project_root / \"build\" / \"pyinstaller\"\n    version_dir.mkdir(parents=True, exist_ok=True)\n    version_file = version_dir / \"version-info.txt\"\n    version_file.write_text(file_content, encoding=\"utf-8\")\n    return str(version_file)\n\n\ndatas = []\nhiddenimports = set()\n\ninclude_tree(\"staging/ui\", \"ui\", datas)\ninclude_tree(\"python_service/adapters\", \"adapters\", datas)\ninclude_tree(\"python_service/data\", \"data\", datas)\ninclude_tree(\"python_service/json\", \"json\", datas)\n\ndatas += collect_data_files(\"uvicorn\", includes=[\"*.html\", \"*.json\"])\ndatas += collect_data_files(\"slowapi\", includes=[\"*.json\", \"*.yaml\"])\ndatas += collect_data_files(\"structlog\", includes=[\"*.json\"])\ndatas += collect_data_files(\"certifi\")\n\nhiddenimports.update(collect_submodules(\"python_service\"))\nhiddenimports.update(\n    [\n        \"uvicorn.logging\",\n        \"uvicorn.loops.auto\",\n        \"uvicorn.lifespan.on\",\n        \"uvicorn.protocols.http.h11_impl\",\n        \"uvicorn.protocols.http.httptools_impl\",\n        \"uvicorn.protocols.websockets.wsproto_impl\",\n        \"uvicorn.protocols.websockets.websockets_impl\",\n        \"fastapi.routing\",\n        \"fastapi.middleware.cors\",\n        \"fastapi.middleware.gzip\",\n        \"starlette.staticfiles\",\n        \"starlette.middleware.cors\",\n        \"anyio._backends._asyncio\",\n        \"httpcore\",\n        \"httpx\",\n        \"python_multipart\",\n        \"slowapi\",\n        \"structlog\",\n        \"tenacity\",\n        \"aiosqlite\",\n        \"selectolax\",\n        \"pydantic_core\",\n        \"pydantic_settings.sources\",\n    ]\n)\n\nanalysis = Analysis(\n    [\"python_service/main.py\"],\n    pathex=[str(project_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=sorted(hiddenimports),\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[\"tests\", \"pytest\", \"web_service\"],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\n\npyz = PYZ(analysis.pure, analysis.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz,\n    analysis.scripts,\n    analysis.binaries,\n    analysis.zipfiles,\n    analysis.datas,\n    [],\n    name=\"fortuna-backend\",\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=False,\n    upx_exclude=[],\n    runtime_tmpdir=None,\n    console=False,\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n    icon=None,\n    version=build_version_file(version_string),\n)\n",
    "python_service/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching horse racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairExchange\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for a given date.\"\"\"\n        await self._authenticate(self.http_client)\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            self.http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"7\"],  # Horse Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\", \"US\", \"FR\", \"ZA\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\"Failed to parse a Betfair market.\", exc_info=True, market=market)\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bf_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 1m Mdn Stks').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "python_service/adapters/betfair_auth_mixin.py": "# python_service/adapters/betfair_auth_mixin.py\n\nimport asyncio\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Optional\n\nimport httpx\nimport structlog\n\nfrom ..credentials_manager import SecureCredentialsManager\n\nlog = structlog.get_logger(__name__)\n\n\nclass BetfairAuthMixin:\n    \"\"\"Encapsulates Betfair authentication logic for reuse across adapters.\"\"\"\n\n    session_token: Optional[str] = None\n    token_expiry: Optional[datetime] = None\n    _auth_lock = asyncio.Lock()\n\n    async def _authenticate(self, http_client: httpx.AsyncClient):\n        \"\"\"\n        Authenticates with Betfair using credentials from the system's credential manager,\n        ensuring the session token is valid and refreshing it if necessary.\n        \"\"\"\n        async with self._auth_lock:\n            if self.session_token and self.token_expiry and self.token_expiry > (datetime.now() + timedelta(minutes=5)):\n                return\n\n            log.info(\"Attempting to authenticate with Betfair...\")\n            username, password = SecureCredentialsManager.get_betfair_credentials()\n\n            if not all([self.config.BETFAIR_APP_KEY, username, password]):\n                raise ValueError(\"Betfair credentials not fully configured in credential manager.\")\n\n            auth_url = \"https://identitysso.betfair.com/api/login\"\n            headers = {\n                \"X-Application\": self.config.BETFAIR_APP_KEY,\n                \"Content-Type\": \"application/x-www-form-urlencoded\",\n            }\n            payload = f\"username={username}&password={password}\"\n\n            response = await http_client.post(auth_url, headers=headers, content=payload, timeout=20)\n            response.raise_for_status()\n            data = response.json()\n\n            if data.get(\"status\") == \"SUCCESS\":\n                self.session_token = data.get(\"token\")\n                self.token_expiry = datetime.now() + timedelta(hours=3)\n                log.info(\"Betfair authentication successful.\")\n            else:\n                log.error(\"Betfair authentication failed\", error=data.get(\"error\"))\n                self.session_token = None  # Reset token to prevent using a stale one\n                return  # Return gracefully and let the adapter handle the lack of a token\n",
    "python_service/adapters/gbgb_api_adapter.py": "# python_service/adapters/gbgb_api_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass GbgbApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for the Greyhound Board of Great Britain API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"GBGB\"\n    BASE_URL = \"https://api.gbgb.org.uk/api/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches the raw meeting data from the GBGB API.\"\"\"\n        endpoint = f\"results/meeting/{date}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, meetings_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw meeting data into a list of Race objects.\"\"\"\n        if not meetings_data:\n            return []\n\n        all_races = []\n        for meeting in meetings_data:\n            track_name = meeting.get(\"trackName\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name):\n                        all_races.append(race)\n                except (KeyError, TypeError):\n                    self.logger.error(\n                        \"Error parsing GBGB race\",\n                        race_id=race_data.get(\"raceId\"),\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: Dict[str, Any], track_name: str) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race_data.get(\"raceId\")\n        race_number = race_data.get(\"raceNumber\")\n        race_time = race_data.get(\"raceTime\")\n\n        if not all([race_id, race_number, race_time]):\n            return None\n\n        return Race(\n            id=f\"gbgb_{race_id}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=datetime.fromisoformat(race_time.replace(\"Z\", \"+00:00\")),\n            runners=self._parse_runners(race_data.get(\"traps\", [])),\n            source=self.source_name,\n            race_name=race_data.get(\"raceTitle\"),\n            distance=f\"{race_data.get('raceDistance')}m\",\n        )\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                trap_number = runner_data.get(\"trapNumber\")\n                dog_name = runner_data.get(\"dogName\")\n                if not all([trap_number, dog_name]):\n                    continue\n\n                odds_data = {}\n                sp = runner_data.get(\"sp\")\n                if sp:\n                    win_odds = parse_odds_to_decimal(sp)\n                    if win_odds and win_odds < 999:\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=trap_number,\n                        name=dog_name,\n                        odds=odds_data,\n                    )\n                )\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Error parsing GBGB runner, skipping.\",\n                    runner_name=runner_data.get(\"dogName\"),\n                )\n                continue\n        return runners\n",
    "python_service/adapters/racing_and_sports_greyhound_adapter.py": "# python_service/adapters/racing_and_sports_greyhound_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports Greyhound API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSportsGreyhound\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"RACING_AND_SPORTS_TOKEN\") or not config.RACING_AND_SPORTS_TOKEN:\n            raise AdapterConfigError(self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw greyhound meetings data from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            self.http_client,\n            \"GET\",\n            \"v1/greyhound/meetings\",\n            headers=headers,\n            params=params,\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw meetings data into a list of Race objects.\"\"\"\n        all_races = []\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\"No 'meetings' in RacingAndSportsGreyhound response or invalid format.\")\n            return all_races\n\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed_race := self._parse_ras_race(meeting, race_summary):\n                        all_races.append(parsed_race)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse RacingAndSportsGreyhound race, skipping\",\n                        meeting=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return all_races\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"rasg_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=datetime.fromisoformat(start_time_str),\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/racingpost_adapter.py": "# python_service/adapters/racingpost_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingPostAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Racing Post racecards, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"RacingPost\"\n    BASE_URL = \"https://www.racingpost.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw HTML content for all races on a given date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch RacingPost index page\", url=index_url)\n            return None\n\n        index_parser = HTMLParser(index_response.text)\n        links = index_parser.css('a[data-test-selector^=\"RC-meetingItem__link_race\"]')\n        race_card_urls = [link.attributes[\"href\"] for link in links]\n\n        async def fetch_single_html(url: str):\n            response = await self.make_request(self.http_client, \"GET\", url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(url) for url in race_card_urls]\n        html_contents = await asyncio.gather(*tasks)\n        return {\"date\": date, \"html_contents\": html_contents}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"html_contents\"):\n            return []\n\n        date = raw_data[\"date\"]\n        html_contents = raw_data[\"html_contents\"]\n        all_races: List[Race] = []\n\n        for html in html_contents:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first('a[data-test-selector=\"RC-course__name\"]')\n                if not venue_node:\n                    continue\n                venue_raw = venue_node.text(strip=True)\n                venue = normalize_venue_name(venue_raw)\n\n                race_time_node = parser.css_first('span[data-test-selector=\"RC-course__time\"]')\n                if not race_time_node:\n                    continue\n                race_time_str = race_time_node.text(strip=True)\n\n                race_datetime_str = f\"{date} {race_time_str}\"\n                start_time = datetime.strptime(race_datetime_str, \"%Y-%m-%d %H:%M\")\n\n                runners = self._parse_runners(parser)\n\n                if venue and runners:\n                    race_number = self._get_race_number(parser, start_time)\n                    race = Race(\n                        id=f\"rp_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=start_time,\n                        runners=runners,\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse RacingPost race from HTML content.\", exc_info=True)\n                continue\n        return all_races\n\n    def _get_race_number(self, parser: HTMLParser, start_time: datetime) -> int:\n        \"\"\"Derives the race number by finding the active time in the nav bar.\"\"\"\n        time_str_to_find = start_time.strftime(\"%H:%M\")\n        time_links = parser.css('a[data-test-selector=\"RC-raceTime\"]')\n        for i, link in enumerate(time_links):\n            if link.text(strip=True) == time_str_to_find:\n                return i + 1\n        return 1\n\n    def _parse_runners(self, parser: HTMLParser) -> list[Runner]:\n        \"\"\"Parses all runners from a single race card page.\"\"\"\n        runners = []\n        runner_nodes = parser.css('div[data-test-selector=\"RC-runnerCard\"]')\n        for node in runner_nodes:\n            if runner := self._parse_runner(node):\n                runners.append(runner)\n        return runners\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first('span[data-test-selector=\"RC-runnerNumber\"]')\n            name_node = node.css_first('a[data-test-selector=\"RC-runnerName\"]')\n            odds_node = node.css_first('span[data-test-selector=\"RC-runnerPrice\"]')\n\n            if not all([number_node, name_node, odds_node]):\n                return None\n\n            number_str = clean_text(number_node.text())\n            number = int(number_str) if number_str and number_str.isdigit() else 0\n            name = clean_text(name_node.text())\n            odds_str = clean_text(odds_node.text())\n            scratched = \"NR\" in odds_str.upper() or not odds_str\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError):\n            self.logger.warning(\"Could not parse RacingPost runner, skipping.\", exc_info=True)\n            return None\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/sporting_life_adapter.py": "# python_service/adapters/sporting_life_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass SportingLifeAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for sportinglife.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"SportingLife\"\n    BASE_URL = \"https://www.sportinglife.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        Returns a dictionary containing the HTML content and the date.\n        \"\"\"\n        index_url = f\"/horse-racing/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch SportingLife index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        links = {a[\"href\"] for a in index_soup.select(\"a.hr-race-card-meeting__race-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to SportingLifeAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n\n                track_name_node = soup.select_one(\"a.hr-race-header-course-name__link\")\n                if not track_name_node:\n                    continue\n                track_name = clean_text(track_name_node.get_text())\n\n                race_time_node = soup.select_one(\"span.hr-race-header-time__time\")\n                if not race_time_node:\n                    continue\n                race_time_str = clean_text(race_time_node.get_text())\n\n                start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n\n                active_link = soup.select_one(\"a.hr-race-header-navigation-link--active\")\n                race_number = 1\n                if active_link:\n                    all_links = soup.select(\"a.hr-race-header-navigation-link\")\n                    try:\n                        race_number = all_links.index(active_link) + 1\n                    except ValueError:\n                        pass  # Keep default race number if active link not in all links\n\n                runners = [self._parse_runner(row) for row in soup.select(\"div.hr-racing-runner-card\")]\n\n                race = Race(\n                    id=f\"sl_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from SportingLife, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"a.hr-racing-runner-horse-name\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.get_text())\n\n            num_node = row.select_one(\"span.hr-racing-runner-saddle-cloth-no\")\n            if not num_node:\n                return None\n            num_str = clean_text(num_node.get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n\n            odds_node = row.select_one(\"span.hr-racing-runner-odds\")\n            odds_str = clean_text(odds_node.get_text()) if odds_node else \"\"\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {\n                    self.source_name: OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n                }\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on SportingLife, skipping runner.\")\n            return None\n",
    "python_service/adapters/tab_adapter.py": "# python_service/adapters/tab_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TabAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for tab.com.au.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"TAB\"\n    BASE_URL = \"https://www.tab.com.au\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/adapters/twinspires_adapter.py": "# python_service/adapters/twinspires_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TwinSpiresAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for twinspires.com.\n    This is a placeholder for a full implementation using the discovered JSON API.\n    \"\"\"\n\n    SOURCE_NAME = \"TwinSpires\"\n    BASE_URL = \"https://www.twinspires.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Reads HTML content from a local fixture file instead of making a live API call.\n        This is a temporary measure to allow development while the live API is blocking requests.\n        \"\"\"\n        # Read the local HTML fixture\n        try:\n            with open(\"tests/fixtures/twinspires_sample.html\", \"r\") as f:\n                html_content = f.read()\n        except FileNotFoundError:\n            self.logger.error(\"TwinSpires test fixture not found.\")\n            return None\n\n        # To maintain the data structure the parser expects, we will create a mock\n        # raw_data object that resembles the original API response, but includes\n        # the HTML content.\n        return {\n            \"html_content\": html_content,\n            \"mock_track_data\": {\"trackId\": \"cd\", \"trackName\": \"Churchill Downs\", \"raceType\": \"Thoroughbred\"},\n            \"mock_race_card\": {\"raceNumber\": 5, \"postTime\": \"2025-10-26T16:30:00Z\"},\n        }\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Parses race and runner data from the mock raw_data object, which now\n        includes the HTML content from the local fixture.\n        \"\"\"\n        if not raw_data or \"html_content\" not in raw_data:\n            return []\n\n        self.logger.info(\"Parsing TwinSpires data from local fixture.\")\n\n        html_content = raw_data[\"html_content\"]\n        track = raw_data[\"mock_track_data\"]\n        race_card = raw_data[\"mock_race_card\"]\n\n        # Parse the runners from the HTML content\n        runners = self._parse_runners_from_html(html_content)\n\n        try:\n            start_time = datetime.fromisoformat(race_card.get(\"postTime\").replace(\"Z\", \"+00:00\"))\n\n            race = Race(\n                id=f\"ts_{track.get('trackId')}_{race_card.get('raceNumber')}\",\n                venue=track.get(\"trackName\"),\n                race_number=race_card.get(\"raceNumber\"),\n                start_time=start_time,\n                discipline=track.get(\"raceType\", \"Unknown\"),\n                runners=runners,\n                source=self.SOURCE_NAME,\n            )\n            return [race]\n        except Exception as e:\n            self.logger.warning(\n                \"Failed to parse race card from mock data.\",\n                error=e,\n                exc_info=True,\n            )\n            return []\n\n    def _parse_runners_from_html(self, html_content: str) -> List[Runner]:\n        \"\"\"Parses runner data from a race card's HTML content.\"\"\"\n        runners = []\n        soup = BeautifulSoup(html_content, \"html.parser\")\n        runner_elements = soup.select(\"li.runner\")\n\n        for element in runner_elements:\n            try:\n                scratched = \"scratched\" in element.get(\"class\", [])\n\n                number_tag = element.select_one(\"span.runner-number\")\n                name_tag = element.select_one(\"span.runner-name\")\n                odds_tag = element.select_one(\"span.runner-odds\")\n\n                if not all([number_tag, name_tag, odds_tag]):\n                    continue\n\n                number = int(number_tag.text.strip())\n                name = name_tag.text.strip()\n                odds_str = odds_tag.text.strip()\n\n                odds = {}\n                if not scratched and odds_str not in [\"SCR\", \"\"]:\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    if win_odds:\n                        odds[self.SOURCE_NAME] = OddsData(\n                            win=win_odds,\n                            source=self.SOURCE_NAME,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=number,\n                        name=name,\n                        scratched=scratched,\n                        odds=odds,\n                    )\n                )\n            except (ValueError, TypeError) as e:\n                self.logger.warning(\"Failed to parse a runner, skipping.\", error=e, exc_info=True)\n                continue\n\n        return runners\n\n    async def _get_races_async(self, date: str) -> List[Race]:\n        raw_data = await self._fetch_data(date)\n        return self._parse_races(raw_data)\n\n    def get_races(self, date: str) -> List[Race]:\n        \"\"\"\n        Orchestrates the fetching and parsing of race data for a given date.\n        This method will be called by the FortunaEngine.\n        \"\"\"\n        self.logger.info(f\"Getting races for {date} from {self.SOURCE_NAME}\")\n        # This is a synchronous wrapper for the async orchestrator\n        # It's a temporary measure to allow me to see the API response.\n        import asyncio\n\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        races = loop.run_until_complete(self._get_races_async(date))\n        return races\n",
    "python_service/adapters/utils.py": "# python_service/adapters/utils.py\n# Compatibility shim to re-export parse_odds from the centralized location.\n\nfrom ..utils.odds import parse_odds\n\n__all__ = [\"parse_odds\"]\n",
    "python_service/api.py": "# python_service/api.py\n\nimport asyncio\nimport os\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom contextlib import asynccontextmanager\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import List\nfrom typing import Optional\n\nimport aiosqlite\nimport structlog\nfrom fastapi import Depends\nfrom fastapi import FastAPI\nfrom fastapi import HTTPException\nfrom fastapi import Query\nfrom fastapi import Request\nfrom fastapi import WebSocket\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom slowapi import Limiter\nfrom slowapi import _rate_limit_exceeded_handler\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi.middleware import SlowAPIMiddleware\nfrom slowapi.util import get_remote_address\nfrom starlette.websockets import WebSocketDisconnect\n\n# --- PyInstaller Explicit Imports ---\nfrom .analyzer import AnalyzerEngine\nfrom .cache_manager import cache_manager\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .engine import OddsEngine\nfrom .health import router as health_router\nfrom .logging_config import configure_logging\nfrom .manual_override_manager import ManualOverrideManager\nfrom .middleware.error_handler import UserFriendlyException\nfrom .middleware.error_handler import user_friendly_exception_handler\nfrom .middleware.error_handler import validation_exception_handler\nfrom .models import AggregatedResponse\nfrom .models import ManualParseRequest\nfrom .models import QualifiedRacesResponse\nfrom .models import Race\nfrom .models import TipsheetRace\nfrom .security import verify_api_key\n\n# ------------------------------------\n\nlog = structlog.get_logger()\n\n# Create a fixed thread pool for blocking calls at the module level\nexecutor = ThreadPoolExecutor(max_workers=1)\n\n\ndef _initialize_heavy_resources_sync(app: FastAPI):\n    \"\"\"\n    This synchronous function contains the blocking I/O and CPU-intensive\n    initialization of the OddsEngine and its ~25 adapters. By isolating it,\n    we can run it in a background thread without stalling the main Uvicorn event loop.\n    \"\"\"\n    log.info(\"Background initialization of heavy resources started.\")\n    try:\n        settings = get_settings()\n\n        # Initialize WebSocket connection manager\n        connection_manager = ConnectionManager()\n\n        # Initialize manual override manager\n        manual_override_manager = ManualOverrideManager()\n\n        # Initialize engine with manual override and WebSocket support\n        engine = OddsEngine(\n            config=settings,\n            manual_override_manager=manual_override_manager,\n            connection_manager=connection_manager,\n        )\n\n        # Store the initialized components on the app state\n        app.state.engine = engine\n        app.state.analyzer_engine = AnalyzerEngine()\n        app.state.manual_override_manager = manual_override_manager\n        app.state.connection_manager = connection_manager\n        log.info(\"Background initialization of heavy resources completed successfully.\")\n    except Exception:\n        log.critical(\"CRITICAL: Background initialization failed.\", exc_info=True)\n        # In a real-world scenario, you might want a more robust way\n        # to signal this failure to the main application.\n        app.state.engine = None\n\n\nclass ConnectionManager:\n    \"\"\"Manages active WebSocket connections.\"\"\"\n\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        log.info(\"WebSocket ConnectionManager initialized.\")\n\n    async def connect(self, websocket: WebSocket):\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        log.info(\"New WebSocket connection established.\")\n\n    def disconnect(self, websocket: WebSocket):\n        self.active_connections.remove(websocket)\n        log.info(\"WebSocket connection closed.\")\n\n    async def broadcast(self, message: dict):\n        \"\"\"Broadcasts a message to all connected clients.\"\"\"\n        if not self.active_connections:\n            return\n\n        log.info(\n            \"Broadcasting message to connected clients\",\n            client_count=len(self.active_connections),\n        )\n        for connection in self.active_connections:\n            try:\n                await connection.send_json(message)\n            except Exception:\n                log.error(\"Error sending message to a WebSocket client.\", exc_info=True)\n\n\n# Lifespan context manager\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    configure_logging()\n    log.info(\"Uvicorn is online, starting lifespan hook.\")\n\n    # 1. Perform lightweight, non-blocking startup tasks\n    settings = get_settings()\n    await cache_manager.connect(settings.REDIS_URL)\n    log.info(\"Fast, non-blocking startup tasks complete (Redis connected).\")\n\n    # 2. Schedule the heavy, synchronous initialization to run in a background thread\n    loop = asyncio.get_event_loop()\n    loop.run_in_executor(executor, _initialize_heavy_resources_sync, app)\n    log.info(\"Heavy resource initialization has been scheduled in a background thread.\")\n\n    # 3. Wait for the engine to be initialized before yielding control.\n    start_time = time.time()\n    while not hasattr(app.state, \"engine\") or app.state.engine is None:\n        if time.time() - start_time > 30:  # 30-second timeout\n            raise RuntimeError(\"Engine initialization timed out.\")\n        await asyncio.sleep(0.1)\n\n    log.info(\"Engine is initialized. Server is ready to accept requests.\")\n    yield\n\n    # --- Shutdown Sequence ---\n    log.info(\"Server shutdown sequence initiated.\")\n    if hasattr(app.state, \"engine\") and app.state.engine:\n        log.info(\"Closing HTTP client resources.\")\n        await app.state.engine.close()\n\n    await cache_manager.disconnect()\n    executor.shutdown(wait=False)\n    log.info(\"Server shutdown sequence complete.\")\n\n\nlimiter = Limiter(key_func=get_remote_address)\napp = FastAPI(\n    title=\"Fortuna Faucet API\",\n    version=\"2.1\",\n    lifespan=lifespan,\n    docs_url=\"/api/docs\",\n    redoc_url=\"/api/redoc\",\n    openapi_url=\"/api/openapi.json\",\n)\n\napp.add_middleware(SlowAPIMiddleware)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\napp.add_exception_handler(RequestValidationError, validation_exception_handler)\napp.add_exception_handler(UserFriendlyException, user_friendly_exception_handler)\napp.include_router(health_router)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\", \"http://localhost:3001\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\"],\n    allow_headers=[\"*\"],\n)\n\n# --- Robust Pathing for Frozen Executables ---\ndef resource_path(relative_path: str) -> str:\n    \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\n    if getattr(sys, 'frozen', False):\n        # PyInstaller creates a temp folder and stores path in _MEIPASS\n        base_path = sys._MEIPASS\n    else:\n        # In development, the base path is the project root.\n        # This assumes the script is run from the project root.\n        base_path = os.path.abspath(\".\")\n    return os.path.join(base_path, relative_path)\n\n# --- Conditional UI Serving for Web Service Mode ---\nif os.environ.get(\"FORTUNA_MODE\") == \"webservice\":\n    import sys\n    from fastapi.staticfiles import StaticFiles\n    from starlette.responses import FileResponse\n    from starlette.middleware.base import BaseHTTPMiddleware\n\n    log.info(\"Application running in 'webservice' mode, configuring static file serving.\")\n\n    # Use the robust resource_path function to find the 'ui' directory.\n    # The spec file bundles 'staging/ui' into the 'ui' folder in the executable's root.\n    static_dir_key = \"ui\" if getattr(sys, 'frozen', False) else \"staging/ui\"\n    static_files_dir = resource_path(static_dir_key)\n    log.info(\"Resolved static files directory\", path=static_files_dir)\n\n    if not os.path.exists(static_files_dir):\n        log.error(\"Static files directory not found! UI will not be served.\", path=static_files_dir)\n    else:\n        class SpaMiddleware(BaseHTTPMiddleware):\n            async def dispatch(self, request, call_next):\n                response = await call_next(request)\n                if response.status_code == 404 and not request.url.path.startswith('/api'):\n                    index_path = os.path.join(static_files_dir, \"index.html\")\n                    if os.path.exists(index_path):\n                        return FileResponse(index_path)\n                return response\n\n        app.add_middleware(SpaMiddleware)\n\n        app.mount(\"/\", StaticFiles(directory=static_files_dir), name=\"static\")\n\ndef get_engine(request: Request) -> OddsEngine:\n    return request.app.state.engine\n\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"ok\", \"timestamp\": datetime.now().isoformat()}\n\n\n@app.get(\"/api/adapters/status\")\n@limiter.limit(\"60/minute\")\nasync def get_all_adapter_statuses(\n    request: Request,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        return engine.get_all_adapter_statuses()\n    except Exception:\n        log.error(\"Error in /api/adapters/status\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@app.get(\"/api/races/qualified/{analyzer_name}\", response_model=QualifiedRacesResponse)\n@limiter.limit(\"120/minute\")\nasync def get_qualified_races(\n    analyzer_name: str,\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n    max_field_size: int = Query(10, ge=3, le=20),\n    min_favorite_odds: float = Query(2.5, ge=1.0, le=100.0),\n    min_second_favorite_odds: float = Query(4.0, ge=1.0, le=100.0),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        aggregated_data = await engine.fetch_all_odds(date_str)\n        races = [Race(**r) for r in aggregated_data.get(\"races\", [])]\n        analyzer_engine = request.app.state.analyzer_engine\n        custom_params = {\n            \"max_field_size\": max_field_size,\n            \"min_favorite_odds\": min_favorite_odds,\n            \"min_second_favorite_odds\": min_second_favorite_odds,\n        }\n        analyzer = analyzer_engine.get_analyzer(analyzer_name, **custom_params)\n        result = analyzer.qualify_races(races)\n        return QualifiedRacesResponse(**result)\n    except ValueError as e:\n        log.warning(\"Requested analyzer not found\", analyzer_name=analyzer_name)\n        raise HTTPException(status_code=404, detail=str(e))\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(\"Error in /api/races/qualified\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\n@app.get(\"/api/races/filter-suggestions\")\nasync def get_filter_suggestions(engine: OddsEngine = Depends(get_engine)):\n    try:\n        date_str = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n        aggregated = await engine.fetch_all_odds(date_str)\n        if not aggregated or not aggregated.get(\"races\"):\n            return {\"suggestions\": {}}\n        field_sizes = [len(r[\"runners\"]) for r in aggregated[\"races\"]]\n        favorite_odds, second_favorite_odds = [], []\n        for race_data in aggregated[\"races\"]:\n            race = Race(**race_data)\n            runners = race.runners\n            if len(runners) >= 2:\n                odds_list = []\n                for runner in runners:\n                    if not runner.scratched and runner.odds:\n                        best_odd = min(\n                            (o.win for o in runner.odds.values() if o.win is not None),\n                            default=None,\n                        )\n                        if best_odd is not None:\n                            odds_list.append(float(best_odd))\n                if len(odds_list) >= 2:\n                    odds_list.sort()\n                    favorite_odds.append(odds_list[0])\n                    second_favorite_odds.append(odds_list[1])\n        return {\n            \"suggestions\": {\n                \"max_field_size\": {\"recommended\": (int(sum(field_sizes) / len(field_sizes)) if field_sizes else 10)},\n                \"min_favorite_odds\": {\"recommended\": 2.5},\n                \"min_second_favorite_odds\": {\"recommended\": 4.0},\n            }\n        }\n    except Exception:\n        log.error(\"Error generating filter suggestions\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Failed to generate suggestions\")\n\n\n@app.get(\"/api/races/source/{source_name}\", response_model=AggregatedResponse)\n@limiter.limit(\"60/minute\")\nasync def get_races_by_source(\n    source_name: str,\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        return await engine.fetch_all_odds(date_str, source=source_name)\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(f\"Error in /api/races/source/{source_name}\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\n@app.get(\"/api/races\", response_model=AggregatedResponse)\n@limiter.limit(\"30/minute\")\nasync def get_races(\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    source: Optional[str] = None,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        return await engine.fetch_all_odds(date_str, source)\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(\"Error in /api/races\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\nDB_PATH = \"fortuna.db\"\n\n\ndef get_current_date() -> date:\n    return datetime.now().date()\n\n\n@app.get(\"/api/tipsheet\", response_model=List[TipsheetRace])\n@limiter.limit(\"30/minute\")\nasync def get_tipsheet_endpoint(request: Request, date: date = Depends(get_current_date)):\n    results = []\n    try:\n        async with aiosqlite.connect(DB_PATH) as db:\n            db.row_factory = aiosqlite.Row\n            query = \"SELECT * FROM tipsheet WHERE date(post_time) = ? ORDER BY post_time ASC\"\n            async with db.execute(query, (date.isoformat(),)) as cursor:\n                async for row in cursor:\n                    results.append(dict(row))\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return results\n\n\n# API Models\nclass ManualDataSubmission(BaseModel):\n    request_id: str\n    content: str\n    content_type: str = \"html\"\n\n\n# New endpoints\n@app.get(\"/api/manual-overrides/pending\")\n@limiter.limit(\"60/minute\")\nasync def get_pending_overrides(\n    request: Request,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Get all pending manual override requests\"\"\"\n    pending = manager.get_pending_requests()\n    return {\"pending_requests\": [req.model_dump() for req in pending]}\n\n\n@app.post(\"/api/manual-overrides/submit\")\n@limiter.limit(\"30/minute\")\nasync def submit_manual_data(\n    request: Request,\n    submission: ManualDataSubmission,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Submit manually-provided data for a failed fetch\"\"\"\n    success = manager.submit_manual_data(\n        request_id=submission.request_id,\n        raw_content=submission.content,\n        content_type=submission.content_type,\n    )\n\n    if success:\n        return {\"status\": \"success\", \"message\": \"Manual data submitted\"}\n    else:\n        raise HTTPException(status_code=404, detail=\"Request not found\")\n\n\n@app.post(\"/api/manual-overrides/skip/{request_id}\")\n@limiter.limit(\"60/minute\")\nasync def skip_manual_override(\n    request: Request,\n    request_id: str,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Skip a manual override request\"\"\"\n    success = manager.skip_request(request_id)\n\n    if success:\n        return {\"status\": \"success\", \"message\": \"Request skipped\"}\n    else:\n        raise HTTPException(status_code=404, detail=\"Request not found\")\n\n\n@app.post(\"/api/manual-overrides/cleanup\")\n@limiter.limit(\"60/minute\")\nasync def cleanup_old_overrides(\n    request: Request,\n    max_age_hours: int = 24,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Clean up old manual override requests\"\"\"\n    manager.clear_old_requests(max_age_hours)\n    return {\"status\": \"success\", \"message\": \"Old requests cleaned\"}\n\n\n@app.websocket(\"/ws/live-updates\")\nasync def websocket_endpoint(websocket: WebSocket, api_key: str = Query(...)):\n    \"\"\"WebSocket endpoint for live race updates.\"\"\"\n    try:\n        # Use the existing API key verification logic\n        # This is a synchronous call, which is fine for auth at the start.\n        # In a real-world scenario with high connection rates, you might\n        # want to make this check asynchronous if it involved I/O.\n        verify_api_key(api_key)\n    except HTTPException as e:\n        log.warning(\"WebSocket connection rejected due to invalid API key.\")\n        await websocket.close(code=4001, reason=f\"Authentication failed: {e.detail}\")\n        return\n\n    manager = websocket.app.state.connection_manager\n    await manager.connect(websocket)\n    try:\n        # Keep the connection alive, listening for messages (if any)\n        while True:\n            # You could implement logic here to handle incoming messages if needed\n            # For now, it's just a broadcast-only connection\n            await websocket.receive_text()\n    except WebSocketDisconnect:\n        manager.disconnect(websocket)\n        log.info(\"Client disconnected from WebSocket.\")\n\n\n@app.post(\"/api/races/parse-manual\", response_model=List[Race])\n@limiter.limit(\"30/minute\")\nasync def parse_manual_html(\n    request: Request,\n    parse_request: ManualParseRequest,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    \"\"\"\n    Manually parses a block of HTML using a specified adapter.\n    \"\"\"\n    try:\n        adapter = engine.get_adapter(parse_request.adapter_name)\n        if not adapter:\n            raise HTTPException(\n                status_code=404,\n                detail=f\"Adapter '{parse_request.adapter_name}' not found.\",\n            )\n\n        # The _parse_races method is synchronous, so we run it in a thread\n        # to avoid blocking the asyncio event loop.\n        loop = asyncio.get_event_loop()\n        parsed_races_data = await loop.run_in_executor(executor, adapter._parse_races, parse_request.html_content)\n\n        # Validate the parsed data with the Race model\n        validated_races = [Race(**race_data) for race_data in parsed_races_data]\n        return validated_races\n\n    except Exception as e:\n        log.error(\"Error during manual parsing\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n",
    "python_service/credentials_manager.py": "# python_service/credentials_manager.py\ntry:\n    import keyring\n\n    # This check is crucial for cross-platform compatibility\n    import keyring.backends.windows\n\n    IS_WINDOWS = True\nexcept ImportError:\n    keyring = None\n    IS_WINDOWS = False\n\n\nclass SecureCredentialsManager:\n    \"\"\"Manages secrets in the system's native credential store.\"\"\"\n\n    SERVICE_NAME = \"Fortuna\"\n\n    @staticmethod\n    def save_credential(account: str, secret: str) -> bool:\n        \"\"\"Saves a secret for a given account (e.g., 'api_key', 'betfair_username').\"\"\"\n        if not IS_WINDOWS:\n            print(\"Credential storage is only supported on Windows.\")\n            return False\n        try:\n            keyring.set_password(SecureCredentialsManager.SERVICE_NAME, account, secret)\n            return True\n        except Exception as e:\n            print(f\"\u274c Failed to save credential for {account}: {e}\")\n            return False\n\n    @staticmethod\n    def get_credential(account: str) -> str:\n        \"\"\"Retrieves a secret for a given account.\"\"\"\n        if not IS_WINDOWS:\n            return None\n        try:\n            return keyring.get_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception as e:\n            print(f\"\u274c Failed to retrieve credential for {account}: {e}\")\n            return None\n\n    @staticmethod\n    def get_betfair_credentials() -> tuple[str, str]:\n        \"\"\"Convenience method to retrieve both Betfair username and password.\"\"\"\n        username = SecureCredentialsManager.get_credential(\"betfair_username\")\n        password = SecureCredentialsManager.get_credential(\"betfair_password\")\n        return username, password\n\n    @staticmethod\n    def delete_credential(account: str):\n        \"\"\"Deletes a specific credential.\"\"\"\n        if not IS_WINDOWS:\n            return\n        try:\n            keyring.delete_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception:\n            pass\n",
    "python_service/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "python_service/health_check.py": "import socket\nimport sys\n\n\ndef is_port_available(port=8000):\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex((\"127.0.0.1\", port))\n        sock.close()\n        return result != 0\n    except Exception:\n        return False\n\n\nif __name__ == \"__main__\":\n    if not is_port_available(8000):\n        print(\"ERROR: Port 8000 already in use. Kill existing process or use different port.\")\n        sys.exit(1)\n    print(\"Port 8000 available \u2713\")\n",
    "python_service/logging_config.py": "# python_service/logging_config.py\nimport logging\nimport sys\n\nimport structlog\n\n\ndef configure_logging(log_level: str = \"INFO\"):\n    \"\"\"Configures structlog for structured, JSON-formatted logging.\"\"\"\n    logging.basicConfig(\n        level=log_level,\n        format=\"%(message)s\",\n        stream=sys.stdout,\n    )\n\n    # Keep the processor chain simple for maximum reliability in bundled executables.\n    # More complex processors like StackInfoRenderer can cause issues in\n    # constrained environments.\n    structlog.configure(\n        processors=[\n            structlog.stdlib.filter_by_level,\n            structlog.stdlib.add_log_level,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n        cache_logger_on_first_use=True,\n    )\n",
    "python_service/models.py": "# python_service/models.py\n\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Annotated\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom pydantic import BaseModel\nfrom pydantic import ConfigDict\nfrom pydantic import Field\nfrom pydantic import WrapSerializer\n\n\ndef decimal_serializer(value: Decimal, handler: Callable[[Decimal], Any]) -> Any:\n    \"\"\"Custom serializer for Decimal to float conversion.\"\"\"\n    return float(value)\n\n\nJsonDecimal = Annotated[Decimal, WrapSerializer(decimal_serializer, when_used=\"json\")]\n\n\n# --- Configuration for Aliases (BUG #4 Fix) ---\nclass FortunaBaseModel(BaseModel):\n    model_config = ConfigDict(\n        populate_by_name=True,\n        arbitrary_types_allowed=True,\n    )\n\n\n# --- Core Data Models ---\nclass OddsData(FortunaBaseModel):\n    win: Optional[JsonDecimal] = None\n    place: Optional[JsonDecimal] = None\n    show: Optional[JsonDecimal] = None\n    source: str\n    last_updated: datetime\n\n\nclass Runner(FortunaBaseModel):\n    id: Optional[str] = None\n    name: str\n    number: Optional[int] = Field(None, alias=\"saddleClothNumber\")\n    scratched: bool = False\n    odds: Dict[str, OddsData] = {}\n    jockey: Optional[str] = None\n    trainer: Optional[str] = None\n\n\nclass Race(FortunaBaseModel):\n    id: str\n    venue: str\n    race_number: int = Field(..., alias=\"raceNumber\")\n    start_time: datetime = Field(..., alias=\"startTime\")\n    runners: List[Runner]\n    source: str\n    field_size: Optional[int] = None\n    qualification_score: Optional[float] = Field(None, alias=\"qualificationScore\")\n    favorite: Optional[Runner] = None\n    race_name: Optional[str] = None\n    distance: Optional[str] = None\n    is_error_placeholder: bool = Field(False, alias=\"isErrorPlaceholder\")\n    error_message: Optional[str] = Field(None, alias=\"errorMessage\")\n\n\nclass SourceInfo(FortunaBaseModel):\n    name: str\n    status: str\n    races_fetched: int = Field(..., alias=\"racesFetched\")\n    fetch_duration: float = Field(..., alias=\"fetchDuration\")\n    error_message: Optional[str] = Field(None, alias=\"errorMessage\")\n    attempted_url: Optional[str] = Field(None, alias=\"attemptedUrl\")\n\n\nclass AdapterError(FortunaBaseModel):\n    adapter_name: str = Field(..., alias=\"adapterName\")\n    error_message: str = Field(..., alias=\"errorMessage\")\n    attempted_url: Optional[str] = Field(None, alias=\"attemptedUrl\")\n\n\nclass AggregatedResponse(FortunaBaseModel):\n    races: List[Race]\n    errors: List[AdapterError]\n    source_info: List[SourceInfo] = Field(..., alias=\"sourceInfo\")\n\n\nclass QualifiedRacesResponse(FortunaBaseModel):\n    criteria: Dict[str, Any]\n    races: List[Race]\n\n\nclass TipsheetRace(FortunaBaseModel):\n    race_id: str = Field(..., alias=\"raceId\")\n    track_name: str = Field(..., alias=\"trackName\")\n    race_number: int = Field(..., alias=\"raceNumber\")\n    post_time: str = Field(..., alias=\"postTime\")\n    score: float\n    factors: Any  # JSON string stored as Any\n\n\nclass ManualParseRequest(FortunaBaseModel):\n    adapter_name: str\n    html_content: str = Field(..., max_length=5_000_000)  # ~5MB limit\n",
    "python_service/tests/test_manual_override.py": "# python_service/tests/test_manual_override.py\nimport pytest\n\nfrom python_service.manual_override_manager import ManualOverrideManager\n\n\n@pytest.fixture\ndef manager():\n    # The manager is now in-memory and doesn't need a path\n    return ManualOverrideManager()\n\n\ndef test_register_and_retrieve(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n    content = \"<html>Manual content</html>\"\n    content_type = \"text/html\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    success = manager.submit_manual_data(\n        request_id=request_id,\n        raw_content=content,\n        content_type=content_type,\n    )\n\n    assert success\n\n    # Verify that the data can be retrieved correctly\n    retrieved_data = manager.get_manual_data(adapter_name=adapter, url=url)\n    assert retrieved_data is not None\n    retrieved_content, retrieved_type = retrieved_data\n    assert retrieved_content == content\n    assert retrieved_type == content_type\n\n    # Verify that data is consumed after retrieval\n    assert manager.get_manual_data(adapter_name=adapter, url=url) is None\n",
    "python_service/utils/text.py": "# python_service/utils/text.py\n# Centralized text and name normalization utilities\nimport re\nfrom typing import Optional\n\n\ndef clean_text(text: Optional[str]) -> Optional[str]:\n    \"\"\"Strips leading/trailing whitespace and collapses internal whitespace.\"\"\"\n    if not text:\n        return None\n    return \" \".join(text.strip().split())\n\n\ndef normalize_venue_name(name: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Normalizes a UK or Irish racecourse name to a standard format.\n    Handles common abbreviations and variations.\n    \"\"\"\n    if not name:\n        return None\n\n    # Use a temporary variable for matching, but return the properly cased name\n    cleaned_name_upper = clean_text(name).upper()\n\n    VENUE_MAP = {\n        \"ASCOT\": \"Ascot\",\n        \"AYR\": \"Ayr\",\n        \"BANGOR-ON-DEE\": \"Bangor-on-Dee\",\n        \"CATTERICK BRIDGE\": \"Catterick\",\n        \"CHELMSFORD CITY\": \"Chelmsford\",\n        \"EPSOM DOWNS\": \"Epsom\",\n        \"FONTWELL\": \"Fontwell Park\",\n        \"HAYDOCK\": \"Haydock Park\",\n        \"KEMPTON\": \"Kempton Park\",\n        \"LINGFIELD\": \"Lingfield Park\",\n        \"NEWMARKET (ROWLEY)\": \"Newmarket\",\n        \"NEWMARKET (JULY)\": \"Newmarket\",\n        \"SANDOWN\": \"Sandown Park\",\n        \"STRATFORD\": \"Stratford-on-Avon\",\n        \"YARMOUTH\": \"Great Yarmouth\",\n        \"CURRAGH\": \"Curragh\",\n        \"DOWN ROYAL\": \"Down Royal\",\n    }\n\n    # Check primary map first\n    if cleaned_name_upper in VENUE_MAP:\n        return VENUE_MAP[cleaned_name_upper]\n\n    # Handle cases where the key is the desired output but needs to be mapped from a variation\n    # e.g. CHELMSFORD maps to Chelmsford\n    # Title case the cleaned name for a sensible default\n    title_cased_name = clean_text(name).title()\n    if title_cased_name in VENUE_MAP.values():\n        return title_cased_name\n\n    # Return the title-cased cleaned name as a fallback\n    return title_cased_name\n\n\ndef normalize_course_name(name: str) -> str:\n    if not name:\n        return \"\"\n    name = name.lower().strip()\n    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s-]+\", \"_\", name)\n    return name\n",
    "requirements-dev.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=requirements-dev.txt requirements-dev.in\n#\naltair==5.5.0\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\nanyio==4.11.0\n    # via httpx\nattrs==25.4.0\n    # via\n    #   jsonschema\n    #   referencing\nblack==25.11.0\n    # via -r requirements-dev.in\nblinker==1.9.0\n    # via streamlit\nboolean-py==5.0\n    # via license-expression\ncachecontrol[filecache]==0.14.3\n    # via\n    #   cachecontrol\n    #   pip-audit\ncachetools==6.2.1\n    # via streamlit\ncertifi==2023.7.22\n    # via\n    #   httpcore\n    #   httpx\n    #   requests\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.0\n    # via\n    #   black\n    #   streamlit\ncyclonedx-python-lib==9.1.0\n    # via pip-audit\ndefusedxml==0.7.1\n    # via py-serializable\ndistro==1.9.0\n    # via tabula-py\nfakeredis[lua]==2.23.0\n    # via -r requirements-dev.in\nfilelock==3.20.0\n    # via cachecontrol\ngitdb==4.0.12\n    # via gitpython\ngitpython==3.1.45\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\ngreenlet==3.2.4\n    # via playwright\nh11==0.16.0\n    # via httpcore\nhttpcore==1.0.9\n    # via httpx\nhttpx==0.28.1\n    # via respx\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njinja2==3.1.6\n    # via\n    #   altair\n    #   pydeck\njsonschema==4.25.1\n    # via altair\njsonschema-specifications==2025.9.1\n    # via jsonschema\nlicense-expression==30.4.4\n    # via cyclonedx-python-lib\nlupa==2.6\n    # via fakeredis\nmarkdown-it-py==4.0.0\n    # via rich\nmarkupsafe==3.0.3\n    # via jinja2\nmdurl==0.1.2\n    # via markdown-it-py\nmsgpack==1.1.2\n    # via cachecontrol\nmypy-extensions==1.1.0\n    # via black\nnarwhals==2.9.0\n    # via altair\nnumpy==2.3.4\n    # via\n    #   pandas\n    #   pydeck\n    #   streamlit\n    #   tabula-py\npackageurl-python==0.17.5\n    # via cyclonedx-python-lib\npackaging==25.0\n    # via\n    #   altair\n    #   black\n    #   pip-audit\n    #   pip-requirements-parser\n    #   pytest\n    #   streamlit\npandas==2.3.3\n    # via\n    #   streamlit\n    #   tabula-py\npathspec==0.12.1\n    # via black\npillow==11.3.0\n    # via streamlit\npip-api==0.0.34\n    # via pip-audit\npip-audit==2.9.0\n    # via -r requirements-dev.in\npip-requirements-parser==32.0.1\n    # via pip-audit\nplatformdirs==4.5.0\n    # via\n    #   black\n    #   pip-audit\nplaywright==1.55.0\n    # via -r requirements-dev.in\npluggy==1.6.0\n    # via pytest\nprotobuf==6.33.0\n    # via streamlit\npy-serializable==2.1.0\n    # via cyclonedx-python-lib\npyarrow==21.0.0\n    # via streamlit\npydeck==0.9.1\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\npyee==13.0.0\n    # via playwright\npygments==2.19.2\n    # via\n    #   pytest\n    #   rich\npyparsing==3.2.5\n    # via pip-requirements-parser\npytest==8.4.2\n    # via\n    #   -r requirements-dev.in\n    #   pytest-asyncio\npytest-asyncio==1.2.0\n    # via -r requirements-dev.in\npython-dateutil==2.9.0.post0\n    # via pandas\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==7.0.1\n    # via fakeredis\nreferencing==0.37.0\n    # via\n    #   jsonschema\n    #   jsonschema-specifications\nrequests==2.32.5\n    # via\n    #   cachecontrol\n    #   pip-audit\n    #   streamlit\nrespx==0.22.0\n    # via -r requirements-dev.in\nrich==14.2.0\n    # via pip-audit\nrpds-py==0.28.0\n    # via\n    #   jsonschema\n    #   referencing\nsix==1.17.0\n    # via python-dateutil\nsmmap==5.0.2\n    # via gitdb\nsniffio==1.3.1\n    # via anyio\nsortedcontainers==2.4.0\n    # via\n    #   cyclonedx-python-lib\n    #   fakeredis\nstreamlit==1.50.0\n    # via -r requirements-dev.in\ntabula-py==2.10.0\n    # via -r requirements-dev.in\ntenacity==8.2.3\n    # via streamlit\ntoml==0.10.2\n    # via\n    #   pip-audit\n    #   streamlit\ntornado==6.5.2\n    # via streamlit\ntyping-extensions==4.15.0\n    # via\n    #   altair\n    #   anyio\n    #   pyee\n    #   pytest-asyncio\n    #   referencing\n    #   streamlit\ntzdata==2025.2\n    # via pandas\nurllib3==2.5.0\n    # via requests\nwatchdog==6.0.0\n    # via streamlit\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools\n",
    "scripts/fortuna-quick-start.ps1": "# ====================================================================\n# Fortuna Faucet - Quick Start Script (No Installation Required)\n# ====================================================================\n# This script runs Fortuna directly from source without any MSI\n# Useful for development and testing before packaging\n# ====================================================================\n\nparam(\n    [switch]$SkipChecks,\n    [switch]$NoFrontend\n)\n\n$ErrorActionPreference = 'Stop'\n$OriginalLocation = Get-Location\n\n# ============= CONFIGURATION =============\n$PROJECT_ROOT = Split-Path -Parent $MyInvocation.MyCommand.Path\n$VENV_PATH = Join-Path $PROJECT_ROOT \".venv\"\n$PYTHON_EXE = Join-Path $VENV_PATH \"Scripts\\python.exe\"\n$BACKEND_DIR = Join-Path $PROJECT_ROOT \"python_service\"\n$FRONTEND_DIR = Join-Path $PROJECT_ROOT \"web_platform\\frontend\"\n$BACKEND_PORT = 8000\n$FRONTEND_PORT = 3000\n\n# ============= HELPER FUNCTIONS =============\n\nfunction Write-Status {\n    param([string]$Message, [string]$Status = \"INFO\")\n    $Color = switch ($Status) {\n        \"OK\"      { \"Green\" }\n        \"ERROR\"   { \"Red\" }\n        \"WARNING\" { \"Yellow\" }\n        default   { \"Cyan\" }\n    }\n    Write-Host \"[$Status] $Message\" -ForegroundColor $Color\n}\n\nfunction Test-CommandExists {\n    param([string]$Command)\n    try {\n        Get-Command $Command -ErrorAction Stop | Out-Null\n        return $true\n    } catch {\n        return $false\n    }\n}\n\nfunction Test-PortAvailable {\n    param([int]$Port)\n    try {\n        $Listener = [System.Net.Sockets.TcpListener]::new([System.Net.IPAddress]::Any, $Port)\n        $Listener.Start()\n        $Listener.Stop()\n        return $true\n    } catch {\n        return $false\n    }\n}\n\nfunction Stop-ProcessOnPort {\n    param([int]$Port)\n    $Connection = Get-NetTCPConnection -LocalPort $Port -ErrorAction SilentlyContinue\n    if ($Connection) {\n        $ProcessId = $Connection.OwningProcess\n        Write-Status \"Killing process $ProcessId on port $Port\" \"WARNING\"\n        Stop-Process -Id $ProcessId -Force -ErrorAction SilentlyContinue\n        Start-Sleep -Seconds 2\n    }\n}\n\nfunction Wait-ForBackend {\n    param([int]$MaxAttempts = 30)\n\n    Write-Status \"Waiting for backend to start (http://127.0.0.1:$BACKEND_PORT/health)...\"\n\n    for ($i = 1; $i -le $MaxAttempts; $i++) {\n        try {\n            $Response = Invoke-WebRequest -Uri \"http://127.0.0.1:$BACKEND_PORT/health\" -UseBasicParsing -TimeoutSec 2\n            if ($Response.StatusCode -eq 200) {\n                Write-Status \"Backend is healthy!\" \"OK\"\n                return $true\n            }\n        } catch {\n            Write-Host \".\" -NoNewline\n            Start-Sleep -Seconds 1\n        }\n    }\n\n    Write-Status \"Backend failed to start after $MaxAttempts seconds\" \"ERROR\"\n    return $false\n}\n\n# ============= PREFLIGHT CHECKS =============\n\nWrite-Host \"`n========================================\" -ForegroundColor Cyan\nWrite-Host \" Fortuna Faucet - Quick Start\" -ForegroundColor Cyan\nWrite-Host \"========================================`n\" -ForegroundColor Cyan\n\nif (-not $SkipChecks) {\n    Write-Status \"Running preflight checks...\"\n\n    # Check Python\n    if (-not (Test-Path $PYTHON_EXE)) {\n        Write-Status \"Python virtual environment not found at $VENV_PATH\" \"ERROR\"\n        Write-Status \"Please run setup script first or create venv manually\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"Python venv found\" \"OK\"\n\n    # Check Node.js\n    if (-not (Test-CommandExists \"node\")) {\n        Write-Status \"Node.js not found in PATH\" \"ERROR\"\n        Write-Status \"Install from: https://nodejs.org/\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"Node.js found: $(node --version)\" \"OK\"\n\n    # Check npm\n    if (-not (Test-CommandExists \"npm\")) {\n        Write-Status \"npm not found\" \"ERROR\"\n        exit 1\n    }\n    Write-Status \"npm found: $(npm --version)\" \"OK\"\n\n    # Check if ports are available\n    if (-not (Test-PortAvailable $BACKEND_PORT)) {\n        Write-Status \"Port $BACKEND_PORT is already in use\" \"WARNING\"\n        Stop-ProcessOnPort $BACKEND_PORT\n    }\n\n    if (-not $NoFrontend -and -not (Test-PortAvailable $FRONTEND_PORT)) {\n        Write-Status \"Port $FRONTEND_PORT is already in use\" \"WARNING\"\n        Stop-ProcessOnPort $FRONTEND_PORT\n    }\n\n    # Check Python dependencies\n    Write-Status \"Checking Python dependencies...\"\n    $PipList = & $PYTHON_EXE -m pip list\n    if ($PipList -notmatch \"fastapi\") {\n        Write-Status \"Python dependencies not installed\" \"WARNING\"\n        Write-Status \"Installing dependencies...\"\n        & $PYTHON_EXE -m pip install -r (Join-Path $BACKEND_DIR \"requirements.txt\")\n    } else {\n        Write-Status \"Python dependencies OK\" \"OK\"\n    }\n\n    # Check Node dependencies\n    if (-not $NoFrontend) {\n        Write-Status \"Checking Node.js dependencies...\"\n        $NodeModules = Join-Path $FRONTEND_DIR \"node_modules\"\n        if (-not (Test-Path $NodeModules)) {\n            Write-Status \"Node.js dependencies not installed\" \"WARNING\"\n            Write-Status \"Installing dependencies...\"\n            Push-Location $FRONTEND_DIR\n            npm install\n            Pop-Location\n        } else {\n            Write-Status \"Node.js dependencies OK\" \"OK\"\n        }\n    }\n\n    Write-Host \"\"\n}\n\n# ============= LAUNCH BACKEND =============\n\nWrite-Status \"Starting backend server...\"\n\n$BackendJob = Start-Job -ScriptBlock {\n    param($PythonExe, $BackendDir)\n    Set-Location $BackendDir\n    & $PythonExe -m uvicorn api:app --host 127.0.0.1 --port 8000 --reload\n} -ArgumentList $PYTHON_EXE, $BACKEND_DIR\n\nWrite-Status \"Backend job started (ID: $($BackendJob.Id))\"\n\n# Wait for backend to be healthy\nif (-not (Wait-ForBackend)) {\n    Write-Status \"Backend startup failed. Checking logs...\" \"ERROR\"\n    Receive-Job $BackendJob\n    Stop-Job $BackendJob\n    Remove-Job $BackendJob\n    exit 1\n}\n\n# ============= LAUNCH FRONTEND =============\n\nif (-not $NoFrontend) {\n    Write-Status \"Starting frontend dev server...\"\n\n    $FrontendJob = Start-Job -ScriptBlock {\n        param($FrontendDir)\n        Set-Location $FrontendDir\n        npm run dev\n    } -ArgumentList $FRONTEND_DIR\n\n    Write-Status \"Frontend job started (ID: $($FrontendJob.Id))\"\n\n    # Wait a bit for frontend to start\n    Start-Sleep -Seconds 5\n\n    Write-Status \"Opening browser...\" \"OK\"\n    Start-Process \"http://localhost:$FRONTEND_PORT\"\n}\n\n# ============= MONITORING =============\n\nWrite-Host \"`n========================================\" -ForegroundColor Green\nWrite-Host \" Fortuna is now running!\" -ForegroundColor Green\nWrite-Host \"========================================\" -ForegroundColor Green\nWrite-Host \"\"\nWrite-Status \"Backend:  http://127.0.0.1:$BACKEND_PORT\" \"OK\"\nif (-not $NoFrontend) {\n    Write-Status \"Frontend: http://127.0.0.1:$FRONTEND_PORT\" \"OK\"\n}\nWrite-Host \"\"\nWrite-Host \"Press Ctrl+C to stop all services\" -ForegroundColor Yellow\nWrite-Host \"\"\n\ntry {\n    while ($true) {\n        Start-Sleep -Seconds 2\n\n        # Check if jobs are still running\n        if ($BackendJob.State -eq \"Failed\" -or $BackendJob.State -eq \"Stopped\") {\n            Write-Status \"Backend has stopped unexpectedly!\" \"ERROR\"\n            Receive-Job $BackendJob\n            break\n        }\n\n        if (-not $NoFrontend -and ($FrontendJob.State -eq \"Failed\" -or $FrontendJob.State -eq \"Stopped\")) {\n            Write-Status \"Frontend has stopped unexpectedly!\" \"ERROR\"\n            Receive-Job $FrontendJob\n            break\n        }\n    }\n} finally {\n    # ============= CLEANUP =============\n    Write-Host \"`n`nShutting down...\" -ForegroundColor Yellow\n\n    if ($BackendJob) {\n        Write-Status \"Stopping backend...\"\n        Stop-Job $BackendJob -ErrorAction SilentlyContinue\n        Remove-Job $BackendJob -Force -ErrorAction SilentlyContinue\n    }\n\n    if ($FrontendJob) {\n        Write-Status \"Stopping frontend...\"\n        Stop-Job $FrontendJob -ErrorAction SilentlyContinue\n        Remove-Job $FrontendJob -Force -ErrorAction SilentlyContinue\n    }\n\n    # Kill any remaining processes on the ports\n    Stop-ProcessOnPort $BACKEND_PORT\n    if (-not $NoFrontend) {\n        Stop-ProcessOnPort $FRONTEND_PORT\n    }\n\n    Set-Location $OriginalLocation\n    Write-Status \"Cleanup complete\" \"OK\"\n}\n\n# ============= USAGE EXAMPLES =============\n<#\n.SYNOPSIS\nQuick start script for Fortuna Faucet (no installation required)\n\n.DESCRIPTION\nLaunches the backend and frontend servers directly from source code\nUseful for development and testing before creating an MSI installer\n\n.PARAMETER SkipChecks\nSkip all preflight dependency checks (faster startup)\n\n.PARAMETER NoFrontend\nOnly start the backend API server (no UI)\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1\nStarts both backend and frontend with full checks\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1 -NoFrontend\nStarts only the backend API (useful for API testing)\n\n.EXAMPLE\n.\\fortuna-quick-start.ps1 -SkipChecks\nFast startup (assumes all dependencies are already installed)\n#>",
    "scripts/get_api_key.py": "# scripts/get_api_key.py\nimport os\nimport sys\n\n# This is a workaround to ensure the script can find the python_service module,\n# especially when run from the packaged Electron app.\n# It assumes this script is in `resources/app/scripts` and the service is in `resources/app/python_service`.\ntry:\n    # Get the directory of the current script.\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    # Go up one level to the `app` directory and add `python_service` to the path.\n    project_root = os.path.dirname(script_dir)\n    sys.path.append(project_root)\n    from python_service.credentials_manager import SecureCredentialsManager\nexcept ImportError as e:\n    # If the import fails, write the error to stderr and exit.\n    # This helps in debugging path issues in the production environment.\n    print(\n        f\"Error: Failed to import SecureCredentialsManager. Details: {e}\",\n        file=sys.stderr,\n    )\n    sys.exit(1)\n\n\ndef retrieve_and_print_key():\n    \"\"\"\n    Retrieves the API key using the SecureCredentialsManager and prints it to stdout.\n    If the key is not found, it prints an empty string.\n    If an error occurs, it prints the error to stderr.\n    \"\"\"\n    try:\n        api_key = SecureCredentialsManager.get_api_key()\n        if api_key:\n            print(api_key, end=\"\")  # Print the key directly to stdout\n        else:\n            print(\"\", end=\"\")  # Print empty string if no key is found\n    except Exception as e:\n        print(f\"An error occurred while retrieving the API key: {e}\", file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    retrieve_and_print_key()\n",
    "web_platform/frontend/next.config.mjs": "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  output: 'export',  // Critical for static HTML export\n  distDir: 'out',\n  trailingSlash: true,\n  images: {\n    unoptimized: true  // Required for static export\n  },\n  async rewrites() {\n    return [\n      {\n        source: '/api/:path*',\n        destination: 'http://127.0.0.1:8000/api/:path*',\n      },\n    ]\n  },\n};\n\nexport default nextConfig;\n",
    "web_platform/frontend/src/components/ErrorDisplay.tsx": "// web_platform/frontend/src/components/ErrorDisplay.tsx\n'use client';\n\nimport React from 'react';\n\ninterface ErrorInfo {\n  message: string;\n  suggestion: string;\n  details?: string;\n}\n\ninterface ErrorDisplayProps {\n  error: ErrorInfo;\n}\n\nexport const ErrorDisplay: React.FC<ErrorDisplayProps> = ({ error }) => {\n  return (\n    <div className=\"bg-red-900/20 border border-red-500/30 text-white rounded-lg p-6 max-w-2xl mx-auto my-8\">\n      <div className=\"flex items-center mb-4\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-8 w-8 text-red-400 mr-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n          <path fillRule=\"evenodd\" d=\"M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z\" clipRule=\"evenodd\" />\n        </svg>\n        <h2 className=\"text-2xl font-bold text-red-400\">An Error Occurred</h2>\n      </div>\n      <p className=\"text-lg text-slate-300 mb-2\">{error.message}</p>\n      <p className=\"text-slate-400 mb-6\">{error.suggestion}</p>\n      {error.details && (\n        <details className=\"bg-slate-800/50 rounded-lg p-4\">\n          <summary className=\"cursor-pointer text-sm text-slate-500 hover:text-white\">\n            Technical Details\n          </summary>\n          <pre className=\"text-xs text-slate-400 mt-2 p-2 bg-black/30 rounded overflow-x-auto\">\n            <code>{error.details}</code>\n          </pre>\n        </details>\n      )}\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/LiveRaceDashboard.tsx": "// web_platform/frontend/src/components/LiveRaceDashboard.tsx\n'use client';\n\nimport React, { useState, useEffect, useCallback } from 'react';\nimport { useQuery, useQueryClient } from '@tanstack/react-query';\nimport { RaceFilters } from './RaceFilters';\nimport { RaceCard } from './RaceCard';\nimport { RaceCardSkeleton } from './RaceCardSkeleton';\nimport { EmptyState } from './EmptyState';\nimport { ErrorDisplay } from './ErrorDisplay';\nimport { Race, SourceInfo, AdapterError, AggregatedRacesResponse } from '../types/racing';\nimport { useWebSocket } from '../hooks/useWebSocket';\nimport { StatusDetailModal } from './StatusDetailModal';\nimport ManualOverridePanel from './ManualOverridePanel';\nimport { LiveModeToggle } from './LiveModeToggle';\nimport { AdapterStatusPanel } from './AdapterStatusPanel';\n\n// Type for the backend process status received from Electron main\ntype BackendState = 'starting' | 'running' | 'error' | 'stopped';\ninterface BackendStatus {\n  state: BackendState;\n  logs: string[];\n}\n\ninterface RaceFilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nconst fetchAdapterStatuses = async (apiKey: string | null, port: number | null): Promise<SourceInfo[]> => {\n  if (!apiKey || !port) {\n    throw new Error('API key or port not available.');\n  }\n  const response = await fetch(`http://localhost:${port}/api/adapters/status`, {\n    headers: { 'X-API-Key': apiKey, 'Content-Type': 'application/json' },\n  });\n  if (!response.ok) {\n    const errorData = await response.json();\n    throw new Error(JSON.stringify(errorData));\n  }\n  return response.json();\n};\n\nconst fetchQualifiedRaces = async (apiKey: string | null, port: number | null, params: RaceFilterParams): Promise<AggregatedRacesResponse> => {\n  if (!apiKey || !port) {\n    throw new Error('API key or port not available');\n  }\n  const url = new URL(`http://localhost:${port}/api/races`);\n\n  const response = await fetch(url.toString(), {\n    headers: { 'X-API-Key': apiKey },\n  });\n\n  if (!response.ok) {\n    const errorData = await response.json();\n    throw new Error(JSON.stringify(errorData));\n  }\n\n  return response.json();\n};\n\n\nconst BackendErrorPanel = ({ logs, onRestart }: { logs: string[]; onRestart: () => void }) => (\n  <div className=\"bg-slate-800 p-6 rounded-lg border border-red-500/50 text-white\">\n    <h2 className=\"text-2xl font-bold text-red-400 mb-4\">Backend Service Error</h2>\n    <p className=\"text-slate-400 mb-4\">The backend data service failed to start or has crashed. Below are the most recent diagnostic messages.</p>\n    <div className=\"bg-black p-4 rounded-md font-mono text-sm text-slate-300 h-64 overflow-y-auto mb-4\">\n      {logs.map((log, index) => (\n        <p key={index} className=\"whitespace-pre-wrap\">{`> ${log}`}</p>\n      ))}\n    </div>\n    <button\n      onClick={onRestart}\n      className=\"w-full px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 transition-colors\"\n    >\n      Restart Backend Service\n    </button>\n  </div>\n);\n\n// New Sub-Component to display an error from a specific adapter\nconst ErrorCard = ({ source, message }: { source: string; message: string }) => (\n  <div className=\"bg-slate-800 rounded-lg p-4 border border-red-500/50 flex flex-col justify-between\">\n    <div>\n      <h3 className=\"font-bold text-red-400 text-lg\">{source} Failed</h3>\n      <p className=\"text-slate-400 text-sm mt-2\">{message}</p>\n    </div>\n    <div className=\"mt-4 text-xs text-slate-500\">\n      <p>This adapter failed to fetch data. This is not a critical error; other adapters may provide the necessary data.</p>\n    </div>\n  </div>\n);\n\n// New Sub-Component to render the grid of races or error cards\nconst RaceGrid = ({ races }: { races: Race[] }) => (\n  <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-4\">\n    {races.map(race =>\n      race.isErrorPlaceholder ? (\n        <ErrorCard key={race.id} source={race.venue} message={race.errorMessage || 'An unknown error occurred.'} />\n      ) : (\n        <RaceCard key={race.id} race={race} />\n      )\n    )}\n  </div>\n);\n\nconst useBackendStatus = () => {\n  const [backendStatus, setBackendStatus] = useState<BackendStatus>({ state: 'starting', logs: [] });\n\n  useEffect(() => {\n    let isMounted = true;\n\n    const getInitialStatus = async () => {\n      if (window.electronAPI?.getBackendStatus) {\n        try {\n          const initialStatus = await window.electronAPI.getBackendStatus();\n          if (isMounted) setBackendStatus(initialStatus);\n        } catch (error) {\n          console.error(\"Failed to get initial backend status:\", error);\n          if (isMounted) setBackendStatus({ state: 'error', logs: ['Failed to query backend status from main process.'] });\n        }\n      } else {\n          setBackendStatus({ state: 'running', logs: ['In a web-only environment, backend is assumed to be running.'] });\n      }\n    };\n\n    if (window.electronAPI?.onBackendStatusUpdate) {\n      const unsubscribe = window.electronAPI.onBackendStatusUpdate((status: BackendStatus) => {\n        if (isMounted) setBackendStatus(status);\n      });\n      getInitialStatus();\n      return () => {\n        isMounted = false;\n        if (typeof unsubscribe === 'function') {\n          unsubscribe();\n        }\n      };\n    } else {\n        getInitialStatus();\n    }\n  }, []);\n\n  return backendStatus;\n};\n\nexport const LiveRaceDashboard = React.memo(() => {\n  const [races, setRaces] = useState<Race[]>([]);\n  const [adapterErrors, setAdapterErrors] = useState<AdapterError[]>([]);\n  const backendStatus = useBackendStatus();\n  const [apiKey, setApiKey] = useState<string | null>(null);\n  const [apiPort, setApiPort] = useState<number | null>(null);\n  const queryClient = useQueryClient();\n\n  // Get API key and port on component mount\n  useEffect(() => {\n    const fetchApiConfig = async () => {\n      try {\n        // Use a single check for electronAPI\n        const isElectron = typeof window.electronAPI !== 'undefined';\n\n        const key = isElectron\n          ? await window.electronAPI.getApiKey()\n          : null;\n\n        if (key) {\n          setApiKey(key);\n        } else {\n          console.error('API key could not be retrieved.');\n          // Fallback to a default or test key if necessary for web-only mode\n          setApiKey(\"a_secure_test_api_key_that_is_long_enough\");\n        }\n\n        const port = isElectron\n          ? await window.electronAPI.getApiPort()\n          : 8000; // Default port for web-only development\n\n        if (port) {\n          setApiPort(port);\n        } else {\n          console.error('API port could not be retrieved, defaulting to 8000.');\n          setApiPort(8000);\n        }\n\n      } catch (error) {\n        console.error('Error fetching API config:', error);\n        // Provide fallbacks in case of an error during retrieval\n        setApiKey(\"a_secure_test_api_key_that_is_long_enough\");\n        setApiPort(8000);\n      }\n    };\n    fetchApiConfig();\n  }, []);\n\n  const [params, setParams] = useState<RaceFilterParams>({\n    maxFieldSize: 10,\n    minFavoriteOdds: 2.5,\n    minSecondFavoriteOdds: 4.0,\n  });\n\n  const {\n    data,\n    status: connectionStatus,\n    error: errorDetails,\n    refetch,\n  } = useQuery({\n    queryKey: ['aggregatedRaces', apiKey, apiPort], // Updated query key\n    queryFn: () => fetchQualifiedRaces(apiKey, apiPort, params),\n    enabled: backendStatus.state === 'running' && !!apiKey && !!apiPort,\n    refetchOnWindowFocus: true,\n  });\n\n  // Update state when data is successfully fetched\n  useEffect(() => {\n    if (data) {\n      setRaces(data.races || []);\n      setAdapterErrors(data.errors || []);\n      setLastUpdate(new Date());\n    }\n  }, [data]);\n\n  const { data: liveData, isConnected: isLiveConnected } = useWebSocket<AggregatedRacesResponse>(\n    '/ws/live-updates',\n    { apiKey, port: apiPort }\n  );\n\n  // Effect to update state when new live data arrives\n  useEffect(() => {\n    if (liveData) {\n      console.log('Received live data update:', liveData);\n      // Update the query cache and local state with the new data\n      queryClient.setQueryData(['aggregatedRaces', apiKey], liveData);\n      setRaces(liveData.races || []);\n      setAdapterErrors(liveData.errors || []);\n      setLastUpdate(new Date());\n    }\n  }, [liveData, queryClient, apiKey]);\n\n  const [lastUpdate, setLastUpdate] = useState<Date | null>(null);\n  const [isModalOpen, setIsModalOpen] = useState(false);\n\n\n  const handleParamsChange = useCallback((newParams: RaceFilterParams) => {\n    setParams(newParams);\n  }, []);\n\n  const handleParseSuccess = (adapterName: string, parsedRaces: Race[]) => {\n    queryClient.setQueryData(['qualifiedRaces', apiKey, params], (oldData: { races: Race[], source_info: SourceInfo[] } | undefined) => {\n      if (!oldData) return { races: parsedRaces, source_info: [] };\n\n      // 1. Remove the placeholder error card for this adapter\n      const otherRaces = oldData.races.filter(race => race.source !== adapterName);\n\n      // 2. Merge the new races in\n      const updatedRaces = [...otherRaces, ...parsedRaces].sort(\n        (a, b) => new Date(a.start_time).getTime() - new Date(b.start_time).getTime()\n      );\n\n      // 3. Update source_info to remove the failed source\n      const updatedSourceInfo = oldData.source_info.filter(s => s.name !== adapterName);\n\n      return { races: updatedRaces, source_info: updatedSourceInfo };\n    });\n  };\n\n  const renderContent = () => {\n    // Priority 1: Backend process has failed.\n    if (backendStatus.state === 'error') {\n      return <BackendErrorPanel logs={backendStatus.logs} onRestart={() => window.electronAPI.restartBackend()} />;\n    }\n\n    if (backendStatus.state === 'stopped') {\n        return <EmptyState\n            title=\"Backend Service Stopped\"\n            message=\"The backend data service is not running. Please start it to see live race data.\"\n            actionButton={<button onClick={() => window.electronAPI.restartBackend()} className=\"mt-4 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700\">Start Backend Service</button>}\n        />;\n    }\n\n    // Priority 2: Backend is starting or initial fetch is happening.\n    const isLoading = backendStatus.state === 'starting' || (connectionStatus === 'pending' && !data);\n    if (isLoading) {\n        return (\n            <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-4\">\n                {[...Array(8)].map((_, i) => <RaceCardSkeleton key={i} />)}\n            </div>\n        );\n    }\n\n    // Priority 3: API connection is offline.\n    if (connectionStatus === 'error') {\n      try {\n        const errorInfo = JSON.parse((errorDetails as Error).message);\n        return <ErrorDisplay error={errorInfo.error} />;\n      } catch (e) {\n        return <EmptyState\n            title=\"API Connection Offline\"\n            message={(errorDetails as Error)?.message || \"The backend is running, but the dashboard could not connect to its API.\"}\n            actionButton={<button onClick={() => refetch()} className=\"mt-4 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700\">Retry Connection</button>}\n        />;\n      }\n    }\n\n    // Priority 4: No races found after a successful fetch.\n    if (!races || races.length === 0) {\n      return <EmptyState\n          title=\"No Races Found\"\n          message=\"No races matched the specified criteria for the selected date. Please try different filters.\"\n      />;\n    }\n\n    // Priority 5: Display the races (and any error placeholders).\n    return <RaceGrid races={races} />;\n  };\n\n  const getStatusIndicator = () => {\n    if (backendStatus.state === 'error') {\n      return { color: 'bg-red-500', text: 'Backend Error' };\n    }\n    if (backendStatus.state === 'stopped') {\n        return { color: 'bg-gray-500', text: 'Stopped' };\n    }\n    if (backendStatus.state === 'starting') {\n      return { color: 'bg-yellow-500', text: 'Backend Starting...' };\n    }\n    if (isLiveConnected) {\n      return { color: 'bg-cyan-500', text: 'Live' };\n    }\n    return { color: 'bg-yellow-500', text: 'Connecting...' };\n  };\n\n  const { color: statusColor, text: statusText } = getStatusIndicator();\n\n  return (\n    <>\n      <div className=\"space-y-6\">\n        <div className=\"flex justify-between items-start\">\n            <div className=\"text-left space-y-2\">\n                <h1 className=\"text-4xl font-bold text-white\">\ud83c\udfc7 Fortuna Faucet</h1>\n                <p className=\"text-slate-400\">\n                Last updated: {lastUpdate ? lastUpdate.toLocaleTimeString() : 'N/A'}\n                </p>\n            </div>\n            <div className=\"flex items-center gap-4\">\n                <button\n                    onClick={() => (connectionStatus === 'error' || backendStatus.state === 'error') && setIsModalOpen(true)}\n                    className={`flex items-center gap-2 px-3 py-1.5 rounded-full text-sm font-medium text-white ${statusColor} ${(connectionStatus === 'error' || backendStatus.state === 'error') ? 'cursor-pointer hover:opacity-80' : 'cursor-default'}`}\n                    data-testid=\"status-indicator\"\n                >\n                    <span className={`w-2.5 h-2.5 rounded-full bg-white ${isLiveConnected ? 'animate-pulse' : ''}`}></span>\n                    {statusText}\n                </button>\n            </div>\n        </div>\n\n        <RaceFilters onParamsChange={handleParamsChange} isLoading={connectionStatus === 'pending'} refetch={refetch} />\n\n        {adapterErrors.map(error => (\n          <ManualOverridePanel\n            key={error.adapterName}\n            adapterName={error.adapterName}\n            attemptedUrl={error.attemptedUrl || 'URL not available'}\n            apiKey={apiKey}\n            onParseSuccess={handleParseSuccess}\n          />\n        ))}\n\n        {renderContent()}\n      </div>\n\n      <StatusDetailModal\n        isOpen={isModalOpen}\n        onClose={() => setIsModalOpen(false)}\n        status={{ title: 'Connection Error', details: (errorDetails as Error)?.message || 'No specific error message was provided.' }}\n      />\n    </>\n  );\n});\n",
    "web_platform/frontend/src/components/RaceFilters.tsx": "// web_platform/frontend/src/components/RaceFilters.tsx\n'use client';\n\nimport { useState, useCallback } from 'react';\nimport { Settings, RotateCcw } from 'lucide-react';\n\ninterface FilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nexport interface RaceFiltersProps {\n  onParamsChange: (params: FilterParams) => void;\n  isLoading: boolean;\n  refetch: () => void;\n}\n\nconst DEFAULT_PARAMS: FilterParams = {\n  maxFieldSize: 10,\n  minFavoriteOdds: 2.5,\n  minSecondFavoriteOdds: 4.0,\n};\n\nexport function RaceFilters({ onParamsChange, isLoading, refetch }: RaceFiltersProps) {\n  const [params, setParams] = useState<FilterParams>(DEFAULT_PARAMS);\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // Handle individual parameter changes\n  const handleChange = useCallback((key: keyof FilterParams, value: number) => {\n    setParams(prev => {\n      const updated = { ...prev, [key]: value };\n      onParamsChange(updated);\n      return updated;\n    });\n    // Debounce the refetch call\n    const timer = setTimeout(() => {\n      refetch();\n    }, 500);\n    return () => clearTimeout(timer);\n  }, [onParamsChange, refetch]);\n\n  // Reset to defaults\n  const handleReset = useCallback(() => {\n    setParams(DEFAULT_PARAMS);\n    onParamsChange(DEFAULT_PARAMS);\n    refetch();\n  }, [onParamsChange, refetch]);\n\n  return (\n    <div className=\"bg-gradient-to-r from-slate-800 to-slate-900 rounded-lg p-4 mb-6 border border-slate-700\">\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-2\">\n          <Settings className=\"w-5 h-5 text-amber-500\" />\n          <h3 className=\"text-lg font-semibold text-white\">Race Filters</h3>\n        </div>\n        <button\n          onClick={() => setIsExpanded(!isExpanded)}\n          className=\"text-sm text-slate-400 hover:text-slate-200 transition\"\n        >\n          {isExpanded ? 'Hide' : 'Show'}\n        </button>\n      </div>\n\n      {isExpanded && (\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 pt-4 border-t border-slate-700\">\n          {/* Max Field Size */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Max Field Size\n              <span className=\"text-amber-500 ml-2\">{params.maxFieldSize}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2\"\n              max=\"20\"\n              value={params.maxFieldSize}\n              onChange={(e) => handleChange('maxFieldSize', parseInt(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Filters races with larger fields</p>\n          </div>\n\n          {/* Min Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"1.5\"\n              max=\"5\"\n              step=\"0.1\"\n              value={params.minFavoriteOdds}\n              onChange={(e) => handleChange('minFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = pickier favorites</p>\n          </div>\n\n          {/* Min Second Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min 2nd Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minSecondFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2.0\"\n              max=\"8\"\n              step=\"0.1\"\n              value={params.minSecondFavoriteOdds}\n              onChange={(e) => handleChange('minSecondFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = better odds separation</p>\n          </div>\n\n          {/* Reset Button */}\n          <div className=\"md:col-span-3 flex justify-end pt-4 border-t border-slate-700\">\n            <button\n              onClick={handleReset}\n              disabled={isLoading}\n              className=\"inline-flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-600 text-slate-200 rounded text-sm font-medium transition disabled:opacity-50\"\n            >\n              <RotateCcw className=\"w-4 h-4\" />\n              Reset to Defaults\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/components/ScoreBadge.tsx": "'use client';\nimport React from 'react';\n\nconst getScoreStyling = (score: number) => {\n  if (score >= 90) return { bg: 'bg-yellow-400/10', text: 'text-yellow-300', border: 'border-yellow-400' };\n  if (score >= 80) return { bg: 'bg-orange-500/10', text: 'text-orange-400', border: 'border-orange-500' };\n  return { bg: 'bg-sky-500/10', text: 'text-sky-400', border: 'border-sky-500' };\n};\n\nexport const ScoreBadge: React.FC<{ score: number }> = ({ score }) => {\n  const { bg, text } = getScoreStyling(score);\n  return (\n    <div className={`text-right ${text}`}>\n      <p className=\"text-3xl font-bold\">{score.toFixed(1)}</p>\n      <p className=\"text-xs font-medium tracking-wider uppercase\\\">Score</p>\n    </div>\n  );\n};",
    "web_platform/frontend/src/lib/queryClient.ts": "// web_platform/frontend/src/lib/queryClient.ts\nimport { QueryClient } from '@tanstack/react-query';\n\nexport const queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      retry: 3,\n      staleTime: 1000 * 60 * 5, // 5 minutes\n    },\n  },\n});\n",
    "web_platform/frontend/src/types/electron.d.ts": "// web_platform/frontend/src/types/electron.d.ts\n\n/**\n * This declaration file extends the global Window interface to include the\n * 'electronAPI' object exposed by the preload script. This provides\n * TypeScript with type information for the functions we're using for IPC.\n */\nexport {};\n\ndeclare global {\n  interface Window {\n    electronAPI?: {\n      /**\n       * Asynchronously fetches the secure API key from the main process.\n       * @returns {Promise<string|null>} A promise that resolves with the API key or null if not found.\n       */\n      getApiKey: () => Promise<string | null>;\n      /**\n       * Registers a callback for backend status updates from the main process.\n       * @param callback The function to execute. Receives an object with state and logs.\n       * @returns A function to unsubscribe the listener.\n       */\n      onBackendStatusUpdate: (callback: (status: { state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }) => void) => () => void;\n\n      /**\n       * Sends a command to the main process to restart the backend executable.\n       */\n      restartBackend: () => void;\n\n      /**\n       * Asynchronously fetches the current backend status from the main process.\n       * @returns {Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>}\n       */\n      getBackendStatus: () => Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>;\n      generateApiKey: () => Promise<string>;\n      saveApiKey: (apiKey: string) => Promise<{ success: boolean }>;\n      saveBetfairCredentials: (credentials: { appKey: string; username: string; password: string }) => Promise<{ success: boolean }>;\n      getApiPort: () => Promise<number | null>;\n    };\n  }\n}\n",
    "web_platform/frontend/tailwind.config.ts": "import type { Config } from 'tailwindcss'\n\nconst config: Config = {\n  darkMode: 'media',\n  content: [\n    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/components/**/*.{js,ts,jsx,tsx,mdx}',\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\nexport default config",
    "web_service/backend/adapters/brisnet_adapter.py": "# python_service/adapters/brisnet_adapter.py\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom dateutil.parser import parse\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass BrisnetAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for brisnet.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Brisnet\"\n    BASE_URL = \"https://www.brisnet.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"Fetches the raw HTML from the Brisnet race page.\"\"\"\n        # Note: Brisnet URL structure seems to require a track code, e.g., 'CD' for Churchill Downs.\n        # This implementation will need to be improved to dynamically handle different tracks.\n        # For now, it is hardcoded to Churchill Downs as a placeholder.\n        url = f\"/race/{date}/CD\"\n        response = await self.make_request(self.http_client, \"GET\", url)\n        return {\"html\": response.text, \"date\": date} if response and response.text else None\n\n    def _parse_races(self, raw_data: Optional[dict]) -> List[Race]:\n        \"\"\"Parses the raw HTML into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"html\"):\n            return []\n\n        html = raw_data[\"html\"]\n        race_date = raw_data[\"date\"]\n        soup = BeautifulSoup(html, \"html.parser\")\n\n        venue_text_node = soup.select_one(\"header h1\")\n        if not venue_text_node:\n            self.logger.warning(\"Could not find venue name on Brisnet page.\")\n            return []\n\n        venue_text = venue_text_node.text\n        venue = normalize_venue_name(venue_text.split(\" - \")[0])\n\n        races = []\n        for race_section in soup.select(\"section.race\"):\n            try:\n                race_number_str = race_section.get(\"data-racenumber\")\n                if not race_number_str or not race_number_str.isdigit():\n                    continue\n                race_number = int(race_number_str)\n\n                post_time_node = race_section.select_one(\".race-title span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text.replace(\"Post Time: \", \"\").strip()\n                start_time = parse(f\"{race_date} {post_time_str}\")\n\n                runners = []\n                for row in race_section.select(\"tbody tr\"):\n                    if \"scratched\" in row.get(\"class\", []):\n                        continue\n\n                    cells = row.find_all(\"td\")\n                    if len(cells) < 3:\n                        continue\n\n                    number_text = cells[0].text.strip()\n                    if not number_text.isdigit():\n                        continue\n                    number = int(number_text)\n\n                    name = cells[1].text.strip()\n                    odds_str = cells[2].text.strip()\n\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    odds = {}\n                    if win_odds:\n                        odds[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                    runners.append(Runner(number=number, name=name, odds=odds))\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"brisnet_{venue.replace(' ', '').lower()}_{race_date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                    field_size=len(runners),\n                )\n                races.append(race)\n            except (ValueError, IndexError, TypeError):\n                self.logger.warning(\"Failed to parse a race on Brisnet, skipping.\", exc_info=True)\n                continue\n\n        return races\n",
    "web_service/backend/adapters/equibase_adapter.py": "# python_service/adapters/equibase_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass EquibaseAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Equibase race entries, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Equibase\"\n    BASE_URL = \"https://www.equibase.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        d = datetime.strptime(date, \"%Y-%m-%d\").date()\n        index_url = f\"/entries/Entries.cfm?ELEC_DATE={d.month}/{d.day}/{d.year}&STYLE=EQB\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Equibase index page\", url=index_url)\n            return None\n\n        parser = HTMLParser(index_response.text)\n        track_links = [\n            link.attributes[\"href\"]\n            for link in parser.css(\"div.track-information a\")\n            if \"race=\" not in link.attributes.get(\"href\", \"\")\n        ]\n\n        async def get_race_links_from_track(track_url: str):\n            response = await self.make_request(self.http_client, \"GET\", track_url, headers=self._get_headers())\n            if not response:\n                return []\n            parser = HTMLParser(response.text)\n            return [link.attributes[\"href\"] for link in parser.css(\"a.program-race-link\")]\n\n        tasks = [get_race_links_from_track(link) for link in track_links]\n        results = await asyncio.gather(*tasks)\n        race_links = [f\"{self.base_url}{link}\" for sublist in results for link in sublist]\n\n        async def fetch_single_html(race_url: str):\n            response = await self.make_request(self.http_client, \"GET\", race_url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        date = raw_data[\"date\"]\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first(\"div.track-information strong\")\n                if not venue_node:\n                    continue\n                venue = clean_text(venue_node.text())\n\n                race_number_node = parser.css_first(\"div.race-information strong\")\n                if not race_number_node:\n                    continue\n                race_number_text = race_number_node.text().replace(\"Race\", \"\").strip()\n                if not race_number_text.isdigit():\n                    continue\n                race_number = int(race_number_text)\n\n                post_time_node = parser.css_first(\"p.post-time span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text().strip()\n                start_time = self._parse_post_time(date, post_time_str)\n\n                runners = []\n                runner_nodes = parser.css(\"table.entries-table tbody tr\")\n                for node in runner_nodes:\n                    if runner := self._parse_runner(node):\n                        runners.append(runner)\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"eqb_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse Equibase race page.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first(\"td:nth-child(1)\")\n            if not number_node or not number_node.text(strip=True).isdigit():\n                return None\n            number = int(number_node.text(strip=True))\n\n            name_node = node.css_first(\"td:nth-child(3)\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            odds_node = node.css_first(\"td:nth-child(10)\")\n            odds_str = clean_text(odds_node.text()) if odds_node else \"\"\n\n            scratched = \"scratched\" in node.attributes.get(\"class\", \"\").lower()\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError, IndexError):\n            self.logger.warning(\"Could not parse Equibase runner, skipping.\", exc_info=True)\n            return None\n\n    def _parse_post_time(self, date_str: str, time_str: str) -> datetime:\n        \"\"\"Parses a time string like 'Post Time: 12:30 PM ET' into a datetime object.\"\"\"\n        time_part = time_str.split(\" \")[-2] + \" \" + time_str.split(\" \")[-1]\n        dt_str = f\"{date_str} {time_part}\"\n        return datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "web_service/backend/adapters/punters_adapter.py": "# python_service/adapters/punters_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass PuntersAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for punters.com.au.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"Punters\"\n    BASE_URL = \"https://www.punters.com.au\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/racingtv_adapter.py": "# python_service/adapters/racingtv_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingTVAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping data from racingtv.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"RacingTV\"\n    BASE_URL = \"https://www.racingtv.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/tvg_adapter.py": "# python_service/adapters/tvg_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..core.exceptions import AdapterParsingError\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TVGAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US racing data from the TVG API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"TVG\"\n    BASE_URL = \"https://api.tvg.com/v2/races/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"TVG_API_KEY\") or not config.TVG_API_KEY:\n            raise AdapterConfigError(self.source_name, \"TVG_API_KEY is not configured.\")\n        self.tvg_api_key = config.TVG_API_KEY\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches all race details for a given date by first getting tracks.\"\"\"\n        headers = {\"X-Api-Key\": self.tvg_api_key}\n        summary_url = f\"summary?date={date}&country=USA\"\n\n        tracks_response = await self.make_request(self.http_client, \"GET\", summary_url, headers=headers)\n        if not tracks_response:\n            return None\n        tracks_data = tracks_response.json()\n\n        race_detail_tasks = []\n        for track in tracks_data.get(\"tracks\", []):\n            track_id = track.get(\"id\")\n            for race in track.get(\"races\", []):\n                race_id = race.get(\"id\")\n                if track_id and race_id:\n                    details_url = f\"{track_id}/{race_id}\"\n                    race_detail_tasks.append(self.make_request(self.http_client, \"GET\", details_url, headers=headers))\n\n        race_detail_responses = await asyncio.gather(*race_detail_tasks, return_exceptions=True)\n\n        # Filter out exceptions and return only successful responses\n        return [resp.json() for resp in race_detail_responses if resp and not isinstance(resp, Exception)]\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of detailed race JSON objects into Race models.\"\"\"\n        races = []\n        if not isinstance(raw_data, list):\n            self.logger.warning(\"raw_data is not a list, cannot parse TVG races.\")\n            return races\n\n        for race_detail in raw_data:\n            try:\n                if race := self._parse_race(race_detail):\n                    races.append(race)\n            except AdapterParsingError:\n                self.logger.warning(\n                    \"Failed to parse TVG race detail, skipping.\",\n                    race_detail=race_detail,\n                    exc_info=True,\n                )\n        return races\n\n    def _parse_race(self, race_detail: dict) -> Optional[Race]:\n        \"\"\"Parses a single detailed race JSON object into a Race model.\"\"\"\n        track = race_detail.get(\"track\")\n        race_info = race_detail.get(\"race\")\n\n        if not track or not race_info:\n            raise AdapterParsingError(self.source_name, \"Missing track or race info in race detail.\")\n\n        runners = []\n        for runner_data in race_detail.get(\"runners\", []):\n            if runner_data.get(\"scratched\"):\n                continue\n\n            odds = runner_data.get(\"odds\", {})\n            current_odds = odds.get(\"currentPrice\", {})\n            odds_str = current_odds.get(\"fractional\") or odds.get(\"morningLinePrice\", {}).get(\"fractional\")\n\n            try:\n                number = int(runner_data.get(\"programNumber\", \"0\").replace(\"A\", \"\"))\n            except (ValueError, TypeError):\n                self.logger.warning(f\"Could not parse program number: {runner_data.get('programNumber')}\")\n                continue\n\n            odds_data = {}\n            if odds_str:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds_data[self.source_name] = OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n\n            runners.append(\n                Runner(\n                    number=number,\n                    name=clean_text(runner_data.get(\"name\")),\n                    odds=odds_data,\n                    scratched=False,\n                )\n            )\n\n        if not runners:\n            raise AdapterParsingError(self.source_name, \"No non-scratched runners found.\")\n\n        post_time = race_info.get(\"postTime\")\n        if not post_time:\n            raise AdapterParsingError(self.source_name, \"Missing post time.\")\n\n        try:\n            start_time = datetime.fromisoformat(post_time.replace(\"Z\", \"+00:00\"))\n        except (ValueError, TypeError, AttributeError) as e:\n            raise AdapterParsingError(\n                self.source_name,\n                f\"Could not parse post time: {post_time}\",\n            ) from e\n\n        return Race(\n            id=f\"tvg_{track.get('code', 'UNK')}_{race_info.get('date', 'NODATE')}_{race_info.get('number', 0)}\",\n            venue=track.get(\"name\"),\n            race_number=race_info.get(\"number\"),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/engine.py": "# python_service/engine.py\n\nimport asyncio\nimport json\nfrom copy import deepcopy\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Tuple\n\nimport httpx\nimport redis\nimport redis.asyncio as redis_async\nimport structlog\nfrom pydantic import ValidationError\n\nfrom .adapters.at_the_races_adapter import AtTheRacesAdapter\nfrom .adapters.base_adapter_v3 import BaseAdapterV3\nfrom .adapters.betfair_adapter import BetfairAdapter\n\n# from .adapters.betfair_datascientist_adapter import BetfairDataScientistAdapter\nfrom .adapters.betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .adapters.brisnet_adapter import BrisnetAdapter\nfrom .adapters.equibase_adapter import EquibaseAdapter\nfrom .adapters.fanduel_adapter import FanDuelAdapter\nfrom .adapters.gbgb_api_adapter import GbgbApiAdapter\nfrom .adapters.greyhound_adapter import GreyhoundAdapter\nfrom .adapters.harness_adapter import HarnessAdapter\nfrom .adapters.horseracingnation_adapter import HorseRacingNationAdapter\nfrom .adapters.nyrabets_adapter import NYRABetsAdapter\nfrom .adapters.oddschecker_adapter import OddscheckerAdapter\nfrom .adapters.pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .adapters.punters_adapter import PuntersAdapter\nfrom .adapters.racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .adapters.racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .adapters.racingpost_adapter import RacingPostAdapter\nfrom .adapters.racingtv_adapter import RacingTVAdapter\nfrom .adapters.sporting_life_adapter import SportingLifeAdapter\nfrom .adapters.tab_adapter import TabAdapter\nfrom .adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom .adapters.timeform_adapter import TimeformAdapter\nfrom .adapters.tvg_adapter import TVGAdapter\nfrom .adapters.twinspires_adapter import TwinSpiresAdapter\nfrom .adapters.xpressbet_adapter import XpressbetAdapter\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .manual_override_manager import ManualOverrideManager\nfrom .models import AggregatedResponse\nfrom .models import Race\n\nlog = structlog.get_logger(__name__)\n\n\nclass OddsEngine:\n    def __init__(\n        self,\n        config=None,\n        manual_override_manager: ManualOverrideManager = None,\n        connection_manager=None,\n    ):\n        # THE FIX: Import the cache_manager singleton here to ensure tests can\n        # patch and reload it *before* the engine is initialized.\n        from .cache_manager import cache_manager\n\n        self.logger = structlog.get_logger(__name__)\n        self.logger.info(\"Initializing FortunaEngine...\")\n        self.connection_manager = connection_manager\n        self.cache_manager = cache_manager\n\n        try:\n            try:\n                self.config = config or get_settings()\n                self.logger.info(\"Configuration loaded.\")\n            except ValidationError as e:\n                self.logger.warning(\n                    \"Could not load settings, possibly in test environment.\",\n                    error=str(e),\n                )\n                # Create a default/mock config or re-raise if not in a test context\n                from .config import Settings\n\n                self.config = Settings(API_KEY=\"a_secure_test_api_key_that_is_long_enough\")\n\n            # Redis is now handled entirely by the CacheManager.\n\n            self.logger.info(\"Initializing adapters...\")\n            self.adapters: List[BaseAdapterV3] = []\n            adapter_classes = [\n                AtTheRacesAdapter,\n                BetfairAdapter,\n                BetfairGreyhoundAdapter,\n                BrisnetAdapter,\n                EquibaseAdapter,\n                FanDuelAdapter,\n                GbgbApiAdapter,\n                GreyhoundAdapter,\n                HarnessAdapter,\n                HorseRacingNationAdapter,\n                NYRABetsAdapter,\n                OddscheckerAdapter,\n                PuntersAdapter,\n                RacingAndSportsAdapter,\n                RacingAndSportsGreyhoundAdapter,\n                RacingPostAdapter,\n                RacingTVAdapter,\n                SportingLifeAdapter,\n                TabAdapter,\n                TheRacingApiAdapter,\n                TimeformAdapter,\n                TwinSpiresAdapter,\n                TVGAdapter,\n                XpressbetAdapter,\n                PointsBetGreyhoundAdapter,\n            ]\n\n            for adapter_cls in adapter_classes:\n                try:\n                    self.logger.info(f\"Attempting to initialize adapter: {adapter_cls.__name__}\")\n                    adapter_instance = adapter_cls(config=self.config)\n                    self.logger.info(f\"Successfully initialized adapter: {adapter_cls.__name__}\")\n                    if manual_override_manager and getattr(adapter_instance, \"supports_manual_override\", False):\n                        adapter_instance.enable_manual_override(manual_override_manager)\n                    self.adapters.append(adapter_instance)\n                except AdapterConfigError as e:\n                    self.logger.warning(\n                        \"Skipping adapter due to configuration error\",\n                        adapter=adapter_cls.__name__,\n                        error=str(e),\n                    )\n                except Exception:\n                    self.logger.error(\n                        f\"An unexpected error occurred while initializing {adapter_cls.__name__}\",\n                        exc_info=True,\n                    )\n\n            # Special case for BetfairDataScientistAdapter with extra args - DISABLED\n            # try:\n            #     bds_adapter = BetfairDataScientistAdapter(\n            #         model_name=\"ThoroughbredModel\",\n            #         url=\"https://betfair-data-supplier-prod.herokuapp.com/api/widgets/kvs-ratings/datasets\",\n            #         config=self.config,\n            #     )\n            #     if manual_override_manager and getattr(bds_adapter, \"supports_manual_override\", False):\n            #         bds_adapter.enable_manual_override(manual_override_manager)\n            #     self.adapters.append(bds_adapter)\n            # except Exception:\n            #     self.logger.warning(\n            #         \"Failed to initialize adapter: BetfairDataScientistAdapter\",\n            #         exc_info=True,\n            #     )\n\n            self.logger.info(f\"{len(self.adapters)} adapters initialized successfully.\")\n\n            self.logger.info(\"Initializing HTTP client...\")\n            self.http_limits = httpx.Limits(\n                max_connections=self.config.HTTP_POOL_CONNECTIONS,\n                max_keepalive_connections=self.config.HTTP_MAX_KEEPALIVE,\n            )\n            self.http_client = httpx.AsyncClient(limits=self.http_limits, http2=True)\n            self.logger.info(\"HTTP client initialized.\")\n\n            # Assign the shared client to each adapter\n            for adapter in self.adapters:\n                adapter.http_client = self.http_client\n\n            # Initialize semaphore for concurrency limiting\n            self.semaphore = asyncio.Semaphore(self.config.MAX_CONCURRENT_REQUESTS)\n            self.logger.info(\n                \"Concurrency semaphore initialized\",\n                limit=self.config.MAX_CONCURRENT_REQUESTS,\n            )\n\n            self.logger.info(\"FortunaEngine initialization complete.\")\n\n        except Exception:\n            self.logger.critical(\"CRITICAL FAILURE during FortunaEngine initialization.\", exc_info=True)\n            raise\n\n    async def close(self):\n        await self.http_client.aclose()\n\n    def get_all_adapter_statuses(self) -> List[Dict[str, Any]]:\n        return [adapter.get_status() for adapter in self.adapters]\n\n    async def get_from_cache(self, key):\n        return await self.cache_manager.get(key)\n\n    async def set_in_cache(self, key, value, ttl=300):\n        # THE FIX: The keyword argument is 'ttl_seconds', not 'ttl'.\n        await self.cache_manager.set(key, value, ttl_seconds=ttl)\n\n    async def _fetch_with_semaphore(self, adapter: BaseAdapterV3, date: str):\n        \"\"\"Acquires the semaphore before fetching data from an adapter.\"\"\"\n        async with self.semaphore:\n            return await self._time_adapter_fetch(adapter, date)\n\n    async def _time_adapter_fetch(self, adapter: BaseAdapterV3, date: str) -> Tuple[str, Dict[str, Any], float]:\n        \"\"\"\n        Wraps a V3 adapter's fetch call for safe, non-blocking execution,\n        and returns a consistent payload with timing information.\n        \"\"\"\n        start_time = datetime.now()\n        races: List[Race] = []\n        error_message = None\n        is_success = False\n        attempted_url = None\n\n        try:\n            race_data_list = await adapter.get_races(date)\n            races = [Race(**race_data) for race_data in race_data_list]\n            is_success = True\n        except AdapterHttpError as e:\n            self.logger.error(\n                \"HTTP failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                status_code=e.status_code,\n                url=e.url,\n                exc_info=False,\n            )\n            error_message = f\"HTTP Error {e.status_code} for {e.url}\"\n            attempted_url = e.url\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n        except Exception as e:\n            self.logger.error(\n                \"Critical failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                error=str(e),\n                exc_info=True,\n            )\n            error_message = str(e)\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n\n        duration = (datetime.now() - start_time).total_seconds()\n\n        payload = {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": adapter.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": duration,\n                \"attempted_url\": attempted_url,\n            },\n        }\n        return (adapter.source_name, payload, duration)\n\n    def _race_key(self, race: Race) -> str:\n        return f\"{race.venue.lower().strip()}|{race.race_number}|{race.start_time.strftime('%H:%M')}\"\n\n    def _dedupe_races(self, races: List[Race]) -> List[Race]:\n        \"\"\"Deduplicates races and reconciles odds from different sources.\"\"\"\n        races_copy = deepcopy(races)\n        race_map: Dict[str, Race] = {}\n        for race in races_copy:\n            key = self._race_key(race)\n            if key not in race_map:\n                race_map[key] = race\n            else:\n                existing_race = race_map[key]\n                runner_map = {r.number: r for r in existing_race.runners}\n                for new_runner in race.runners:\n                    if new_runner.number in runner_map:\n                        existing_runner = runner_map[new_runner.number]\n                        existing_runner.odds.update(new_runner.odds)\n                    else:\n                        existing_race.runners.append(new_runner)\n                existing_race.source += f\", {race.source}\"\n\n        return list(race_map.values())\n\n    async def _broadcast_update(self, data: Dict[str, Any]):\n        \"\"\"Helper to broadcast data if the connection manager is available.\"\"\"\n        if self.connection_manager:\n            await self.connection_manager.broadcast(data)\n\n    async def fetch_all_odds(self, date: str, source_filter: str = None) -> Dict[str, Any]:\n        \"\"\"\n        Fetches and aggregates race data from all configured adapters.\n        The result of this method is cached and broadcasted via WebSocket.\n        \"\"\"\n        # Construct a cache key\n        cache_key = f\"fortuna_engine_races:{date}:{source_filter or 'all'}\"\n        cached_data = await self.get_from_cache(cache_key)\n        if cached_data:\n            log.info(\"Cache hit for fetch_all_odds\", key=cache_key)\n            return json.loads(cached_data)\n\n        log.info(\"Cache miss for fetch_all_odds\", key=cache_key)\n        target_adapters = self.adapters\n        if source_filter:\n            log.info(\"Applying source filter\", source=source_filter)\n            target_adapters = [a for a in self.adapters if a.source_name.lower() == source_filter.lower()]\n\n        tasks = [self._fetch_with_semaphore(adapter, date) for adapter in target_adapters]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        source_infos = []\n        all_races = []\n        errors = []\n\n        for i, result in enumerate(results):\n            adapter = target_adapters[i]\n            if isinstance(result, Exception):\n                log.error(\"Adapter fetch task failed with an unhandled exception\", adapter=adapter.source_name, error=result)\n                errors.append({\n                    \"adapter_name\": adapter.source_name,\n                    \"error_message\": f\"Unhandled exception: {str(result)}\",\n                    \"attempted_url\": \"Unknown\"\n                })\n                source_infos.append({\n                    \"name\": adapter.source_name,\n                    \"status\": \"FAILED\",\n                    \"error_message\": f\"Unhandled exception: {str(result)}\",\n                })\n            else:\n                _adapter_name, adapter_result, _duration = result\n                source_info = adapter_result.get(\"source_info\", {})\n                source_infos.append(source_info)\n                if source_info.get(\"status\") == \"SUCCESS\":\n                    all_races.extend(adapter_result.get(\"races\", []))\n                else:\n                    errors.append({\n                        \"adapter_name\": adapter.source_name,\n                        \"error_message\": source_info.get(\"error_message\", \"Unknown error\"),\n                        \"attempted_url\": source_info.get(\"attempted_url\")\n                    })\n\n        deduped_races = self._dedupe_races(all_races)\n\n        response_obj = AggregatedResponse(\n            date=datetime.strptime(date, \"%Y-%m-%d\").date(),\n            races=deduped_races,\n            errors=errors,\n            source_info=source_infos,\n            metadata={\n                \"fetch_time\": datetime.now(),\n                \"sources_queried\": [a.source_name for a in target_adapters],\n                \"sources_successful\": len([s for s in source_infos if s[\"status\"] == \"SUCCESS\"]),\n                \"total_races\": len(deduped_races),\n                \"total_errors\": len(errors),\n            },\n        )\n\n        response_data = response_obj.model_dump(by_alias=True)\n\n        # Set the result in the cache\n        await self.set_in_cache(cache_key, json.dumps(response_data, default=str), ttl=300)\n        await self._broadcast_update(response_data)\n        return response_data\n",
    "web_service/backend/requirements.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=python_service/requirements.txt python_service/requirements.in\n#\naiosqlite==0.21.0\n    # via -r python_service/requirements.in\naltgraph==0.17.4\n    # via pyinstaller\nannotated-doc==0.0.4\n    # via fastapi\nannotated-types==0.7.0\n    # via pydantic\nanyio==4.11.0\n    # via\n    #   httpx\n    #   starlette\nbeautifulsoup4==4.14.2\n    # via -r python_service/requirements.in\nblack==25.11.0\n    # via -r python_service/requirements.in\nbuild==1.3.0\n    # via pip-tools\ncertifi==2025.10.5\n    # via\n    #   -r python_service/requirements.in\n    #   httpcore\n    #   httpx\n    #   requests\ncffi==2.0.0\n    # via cryptography\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.0\n    # via\n    #   black\n    #   pip-tools\n    #   uvicorn\ncryptography==46.0.3\n    # via\n    #   -r python_service/requirements.in\n    #   secretstorage\ndeprecated==1.3.1\n    # via limits\nfastapi==0.121.1\n    # via -r python_service/requirements.in\ngreenlet==3.2.4\n    # via sqlalchemy\nh11==0.16.0\n    # via\n    #   httpcore\n    #   uvicorn\nh2==4.3.0\n    # via httpx\nhpack==4.1.0\n    # via h2\nhttpcore==1.0.9\n    # via httpx\nhttpx[http2]==0.28.1\n    # via -r python_service/requirements.in\nhyperframe==6.1.0\n    # via h2\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njaraco-classes==3.4.0\n    # via keyring\njaraco-context==6.0.1\n    # via keyring\njaraco-functools==4.3.0\n    # via keyring\njeepney==0.9.0\n    # via\n    #   keyring\n    #   secretstorage\nkeyring==25.6.0\n    # via -r python_service/requirements.in\nlimits==5.6.0\n    # via slowapi\nmore-itertools==10.8.0\n    # via\n    #   jaraco-classes\n    #   jaraco-functools\nmypy-extensions==1.1.0\n    # via black\nnumpy==2.3.4\n    # via\n    #   -r python_service/requirements.in\n    #   pandas\n    #   scipy\npackaging==25.0\n    # via\n    #   black\n    #   build\n    #   limits\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\n    #   pytest\npandas==2.3.3\n    # via -r python_service/requirements.in\npathspec==0.12.1\n    # via black\npip-tools==7.5.1\n    # via -r python_service/requirements.in\nplatformdirs==4.5.0\n    # via black\npluggy==1.6.0\n    # via pytest\npsutil==7.1.3\n    # via -r python_service/requirements.in\npsycopg2-binary==2.9.11\n    # via -r python_service/requirements.in\npycparser==2.23\n    # via cffi\npydantic==2.12.4\n    # via\n    #   fastapi\n    #   pydantic-settings\npydantic-core==2.41.5\n    # via pydantic\npydantic-settings==2.12.0\n    # via -r python_service/requirements.in\npygments==2.19.2\n    # via pytest\npyinstaller==6.6.0\n    # via -r python_service/requirements.in\npyinstaller-hooks-contrib==2025.9\n    # via pyinstaller\npyproject-hooks==1.2.0\n    # via\n    #   build\n    #   pip-tools\npytest==9.0.0\n    # via\n    #   -r python_service/requirements.in\n    #   pytest-asyncio\npytest-asyncio==1.3.0\n    # via -r python_service/requirements.in\npython-dateutil==2.9.0.post0\n    # via pandas\npython-dotenv==1.2.1\n    # via pydantic-settings\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==7.0.1\n    # via -r python_service/requirements.in\nrequests==2.32.5\n    # via -r python_service/requirements.in\nscipy==1.16.3\n    # via -r python_service/requirements.in\nsecretstorage==3.4.1\n    # via keyring\nselectolax==0.4.0\n    # via -r python_service/requirements.in\nsix==1.17.0\n    # via python-dateutil\nslowapi==0.1.9\n    # via -r python_service/requirements.in\nsniffio==1.3.1\n    # via anyio\nsoupsieve==2.8\n    # via beautifulsoup4\nsqlalchemy==2.0.44\n    # via -r python_service/requirements.in\nstarlette==0.49.3\n    # via fastapi\nstructlog==25.5.0\n    # via -r python_service/requirements.in\ntenacity==8.5.0\n    # via -r python_service/requirements.in\ntyping-extensions==4.15.0\n    # via\n    #   aiosqlite\n    #   anyio\n    #   beautifulsoup4\n    #   fastapi\n    #   limits\n    #   pydantic\n    #   pydantic-core\n    #   pytest-asyncio\n    #   sqlalchemy\n    #   starlette\n    #   typing-inspection\ntyping-inspection==0.4.2\n    # via\n    #   pydantic\n    #   pydantic-settings\ntzdata==2025.2\n    # via pandas\nurllib3==2.5.0\n    # via\n    #   -r python_service/requirements.in\n    #   requests\nuvicorn==0.30.1\n    # via -r python_service/requirements.in\nwheel==0.45.1\n    # via\n    #   -r python_service/requirements.in\n    #   pip-tools\nwrapt==2.0.1\n    # via deprecated\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools\n",
    "web_service/backend/requirements_minimal.txt": "httpx==0.25.0\nstructlog==23.2.0\npydantic==2.5.0\nuvicorn==0.24.0\nfastapi==0.104.1\ntenacity==8.2.3\n",
    "web_service/backend/user_friendly_errors.py": "# python_service/user_friendly_errors.py\n\n\"\"\"\nCentralized dictionary for mapping technical exceptions to user-friendly messages.\n\"\"\"\n\nERROR_MAP = {\n    \"AdapterHttpError\": {\n        \"message\": \"A data source is currently unavailable.\",\n        \"suggestion\": (\n            \"This is usually temporary. Please try again in a few minutes. \"\n            \"If the problem persists, the website may be down for maintenance.\"\n        ),\n    },\n    \"AdapterConfigError\": {\n        \"message\": \"A data adapter is misconfigured.\",\n        \"suggestion\": \"Please check that all required API keys and settings are present in your .env file.\",\n    },\n    \"default\": {\n        \"message\": \"An unexpected error occurred.\",\n        \"suggestion\": \"Please check the application logs for more details or contact support.\",\n    },\n}\n",
    "web_service/frontend/app/components/EmptyState.tsx": "// web_platform/frontend/src/components/EmptyState.tsx\nimport React from 'react';\n\ninterface EmptyStateProps {\n  title: string;\n  message: string;\n  actionButton?: React.ReactNode;\n}\n\nexport const EmptyState: React.FC<EmptyStateProps> = ({ title, message, actionButton }) => {\n  return (\n    <div className=\"text-center p-8 bg-gray-800/50 border border-gray-700 rounded-lg mt-8\">\n      <svg\n        className=\"mx-auto h-12 w-12 text-gray-500\"\n        fill=\"none\"\n        viewBox=\"0 0 24 24\"\n        stroke=\"currentColor\"\n        aria-hidden=\"true\"\n      >\n        <path\n          vectorEffect=\"non-scaling-stroke\"\n          strokeLinecap=\"round\"\n          strokeLinejoin=\"round\"\n          strokeWidth={2}\n          d=\"M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z\"\n        />\n      </svg>\n      <h3 className=\"mt-2 text-xl font-semibold text-white\">{title}</h3>\n      <p className=\"mt-1 text-md text-gray-400\">\n        {message}\n      </p>\n      {actionButton && <div className=\"mt-6\">{actionButton}</div>}\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/RaceCardSkeleton.tsx": "// web_platform/frontend/src/components/RaceCardSkeleton.tsx\nimport React from 'react';\n\nexport const RaceCardSkeleton: React.FC = () => {\n  return (\n    <div className=\"race-card-skeleton border border-gray-700 rounded-lg p-4 bg-gray-800 shadow-lg animate-pulse\">\n      {/* Skeleton Header */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <div className=\"h-7 w-28 bg-gray-700 rounded-md\"></div>\n            <div className=\"h-4 w-40 bg-gray-700 rounded-md mt-2\"></div>\n          </div>\n        </div>\n        <div className=\"h-16 w-16 bg-gray-700 rounded-full\"></div>\n      </div>\n\n      {/* Skeleton Info Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"h-3 w-12 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-8 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-12 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-8 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-10 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-6 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-10 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-6 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n      </div>\n\n      {/* Skeleton Runner Rows */}\n      <div className=\"space-y-2\">\n        {[...Array(3)].map((_, i) => (\n          <div key={i} className=\"runner-row rounded-md p-3\">\n            <div className=\"flex items-center justify-between\">\n              <div className=\"flex items-center gap-4 flex-1\">\n                <div className=\"w-10 h-10 rounded-full bg-gray-700\"></div>\n                <div className=\"flex flex-col space-y-2\">\n                  <div className=\"h-5 w-32 bg-gray-700 rounded-md\"></div>\n                  <div className=\"h-4 w-40 bg-gray-700 rounded-md\"></div>\n                </div>\n              </div>\n              <div className=\"text-right\">\n                <div className=\"h-6 w-16 bg-gray-700 rounded-md\"></div>\n                <div className=\"h-3 w-12 bg-gray-700 rounded-md mt-2\"></div>\n              </div>\n            </div>\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/SettingsPage.tsx": "// src/components/SettingsPage.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\n\nexport function SettingsPage() {\n  const [apiKey, setApiKey] = useState('');\n  const [betfairAppKey, setBetfairAppKey] = useState('');\n  const [betfairUsername, setBetfairUsername] = useState('');\n  const [betfairPassword, setBetfairPassword] = useState('');\n\n  useEffect(() => {\n    // Fetch the current API key when the component mounts\n    const fetchApiKey = async () => {\n      if (window.electronAPI?.getApiKey) {\n        const key = await window.electronAPI.getApiKey();\n        if (key) {\n          setApiKey(key);\n        }\n      }\n    };\n    fetchApiKey();\n  }, []);\n\n  const handleGenerateApiKey = async () => {\n    if (window.electronAPI?.generateApiKey) {\n      const newKey = await window.electronAPI.generateApiKey();\n      setApiKey(newKey);\n    }\n  };\n\n  const handleSaveSettings = async () => {\n    if (window.electronAPI?.saveApiKey && window.electronAPI?.saveBetfairCredentials) {\n      await window.electronAPI.saveApiKey(apiKey);\n      await window.electronAPI.saveBetfairCredentials({\n        appKey: betfairAppKey,\n        username: betfairUsername,\n        password: betfairPassword,\n      });\n      alert('Settings saved successfully!');\n    }\n  };\n\n  return (\n    <div className=\"bg-slate-800 p-8 rounded-lg border border-slate-700 text-white max-w-2xl mx-auto\">\n      <h2 className=\"text-3xl font-bold text-white mb-6\">Application Settings</h2>\n\n      <div className=\"space-y-8\">\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">API Key</h3>\n          <p className=\"text-sm text-slate-400 mb-3\">This key is required for the dashboard to communicate with the backend service.</p>\n          <div className=\"flex items-center space-x-2\">\n            <input\n              type=\"text\"\n              readOnly\n              value={apiKey}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 font-mono text-sm\"\n            />\n            <button\n              onClick={handleGenerateApiKey}\n              className=\"px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded transition-colors font-semibold\"\n            >\n              Generate New Key\n            </button>\n          </div>\n        </div>\n\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">Betfair Credentials (Optional)</h3>\n           <p className=\"text-sm text-slate-400 mb-3\">Required for adapters that use the Betfair Exchange API.</p>\n          <div className=\"space-y-3\">\n            <input\n              type=\"password\"\n              placeholder=\"App Key\"\n              value={betfairAppKey}\n              onChange={(e) => setBetfairAppKey(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"text\"\n              placeholder=\"Username\"\n              value={betfairUsername}\n              onChange={(e) => setBetfairUsername(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"password\"\n              placeholder=\"Password\"\n              value={betfairPassword}\n              onChange={(e) => setBetfairPassword(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n          </div>\n        </div>\n\n        <div className=\"flex justify-end pt-6 border-t border-slate-700\">\n          <button\n            onClick={handleSaveSettings}\n            className=\"px-8 py-3 bg-green-600 hover:bg-green-700 rounded font-bold text-lg transition-colors\"\n          >\n            Save All Settings\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
    "web_service/frontend/app/components/TrifectaFactors.tsx": "// TrifectaFactors.tsx - FINAL, DYNAMIC VERSION\n'use client';\nimport React from 'react';\n\ninterface TrifectaFactorsProps {\n  factorsJson: string | null;\n}\n\nexport function TrifectaFactors({ factorsJson }: TrifectaFactorsProps) {\n  if (!factorsJson) {\n    return <div className=\"text-sm text-gray-500\">No analysis factors available.</div>;\n  }\n\n  try {\n    const factors = JSON.parse(factorsJson);\n    const positiveFactors = Object.entries(factors).filter(([key, value]: [string, any]) => value.ok);\n\n    if (positiveFactors.length === 0) {\n      return <div className=\"text-sm text-gray-500\">No positive factors identified.</div>;\n    }\n\n    return (\n      <div className=\"mt-2 text-xs\">\n        <h4 className=\"font-semibold mb-1\">Key Factors:</h4>\n        <ul className=\"list-disc list-inside space-y-1\">\n          {positiveFactors.map(([key, value]: [string, any]) => (\n            <li key={key} className=\"text-gray-700\">\n              <span className=\"font-medium text-green-600\">\u2713</span> {value.reason} ({value.points > 0 ? `+${value.points}` : value.points} pts)\n            </li>\n          ))}\n        </ul>\n      </div>\n    );\n  } catch (error) {\n    console.error(\"Failed to parse trifecta factors:\", error);\n    return <div className=\"text-sm text-red-500\">Error displaying analysis factors.</div>;\n  }\n}",
    "web_service/frontend/app/layout.tsx": "// web_platform/frontend/app/layout.tsx\nimport './globals.css';\nimport type { Metadata } from 'next';\nimport { Inter } from 'next/font/google';\nimport Providers from './Providers';\n\nconst inter = Inter({ subsets: ['latin'] });\n\nexport const metadata: Metadata = {\n  title: 'Fortuna',\n  description: 'Real-time horse racing analysis.',\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={`${inter.className} bg-white text-gray-900 dark:bg-gray-900 dark:text-gray-100`}>\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}",
    "web_service/frontend/app/types/electron.d.ts": "// web_platform/frontend/src/types/electron.d.ts\n\n/**\n * This declaration file extends the global Window interface to include the\n * 'electronAPI' object exposed by the preload script. This provides\n * TypeScript with type information for the functions we're using for IPC.\n */\nexport {};\n\ndeclare global {\n  interface Window {\n    electronAPI?: {\n      /**\n       * Asynchronously fetches the secure API key from the main process.\n       * @returns {Promise<string|null>} A promise that resolves with the API key or null if not found.\n       */\n      getApiKey: () => Promise<string | null>;\n      /**\n       * Registers a callback for backend status updates from the main process.\n       * @param callback The function to execute. Receives an object with state and logs.\n       * @returns A function to unsubscribe the listener.\n       */\n      onBackendStatusUpdate: (callback: (status: { state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }) => void) => () => void;\n\n      /**\n       * Sends a command to the main process to restart the backend executable.\n       */\n      restartBackend: () => void;\n\n      /**\n       * Asynchronously fetches the current backend status from the main process.\n       * @returns {Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>}\n       */\n      getBackendStatus: () => Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>;\n      generateApiKey: () => Promise<string>;\n      saveApiKey: (apiKey: string) => Promise<{ success: boolean }>;\n      saveBetfairCredentials: (credentials: { appKey: string; username: string; password: string }) => Promise<{ success: boolean }>;\n      getApiPort: () => Promise<number | null>;\n    };\n  }\n}\n",
    "web_service/frontend/next.config.mjs": "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  output: 'export',  // Critical for static HTML export\n  distDir: 'out',\n  trailingSlash: true,\n  images: {\n    unoptimized: true  // Required for static export\n  },\n  async rewrites() {\n    return [\n      {\n        source: '/api/:path*',\n        destination: 'http://127.0.0.1:8000/api/:path*',\n      },\n    ]\n  },\n};\n\nexport default nextConfig;\n",
    "web_service/frontend/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"lib\": [\n      \"dom\",\n      \"dom.iterable\",\n      \"esnext\"\n    ],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": false,\n    \"noEmit\": true,\n    \"incremental\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ]\n  },\n  \"include\": [\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\",\n    \"out/types/**/*.ts\"\n  ],\n  \"exclude\": [\n    \"node_modules\"\n  ]\n}\n"
}