{
    ".github/workflows/build-web-service-msi.yml": "name: Build Fortuna Faucet MSI (WiX v4) - \ud83c\udfc6 PRODUCTION\n\non:\n  push:\n    branches: [main]\n    tags:\n      - 'v*'\n  workflow_dispatch:\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n  PYTHONUTF8: \"1\"\n\njobs:\n  # ============================================================================\n  # JOB 1: BUILD FRONTEND\n  # ============================================================================\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend'\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'web_platform/frontend/package-lock.json'\n      - name: Frontend - Install & Build\n        shell: pwsh\n        run: |\n          cd web_platform/frontend\n          npm ci\n          npm run build\n      - name: Verify Frontend Build\n        shell: pwsh\n        run: |\n          $outDir = 'web_platform/frontend/out'\n          if (-not (Test-Path $outDir)) { throw \"\u274c FATAL: Build output directory 'out' not created\" }\n          $fileCount = (Get-ChildItem -Path $outDir -Recurse -File | Measure-Object).Count\n          if ($fileCount -eq 0) { throw \"\u274c FATAL: Build output directory is empty\" }\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: frontend-build\n          path: web_platform/frontend/out\n          retention-days: 1\n\n  # ============================================================================\n  # JOB 2: BUILD BACKEND (Bundles Frontend inside EXE)\n  # ============================================================================\n  build-backend:\n    name: '\ud83d\udc0d Build Backend'\n    needs: [build-frontend]\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'python_service/requirements.txt'\n      - name: Create Staging Directory for UI\n        shell: pwsh\n        run: New-Item -ItemType Directory -Path \"staging/ui\" -Force | Out-Null\n      - name: Download Frontend Artifact\n        uses: actions/download-artifact@v4\n        with:\n          name: frontend-build\n          path: staging/ui\n      - name: Install Python Dependencies\n        shell: pwsh\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r python_service/requirements-dev.txt\n      - name: Create Missing Directories\n        shell: pwsh\n        run: |\n          New-Item -ItemType Directory -Path \"python_service/data\" -Force | Out-Null\n          New-Item -ItemType Directory -Path \"python_service/json\" -Force | Out-Null\n      - name: Backend - Build with PyInstaller\n        shell: pwsh\n        run: pyinstaller fortuna-backend-webservice.spec --noconfirm\n      - name: Upload Backend Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: backend-executable\n          path: dist/fortuna-backend.exe\n          retention-days: 1\n\n  # ============================================================================\n  # JOB 2B: SMOKE TEST BACKEND\n  # ============================================================================\n  smoke-test-backend:\n    name: '\ud83d\udd25 Smoke Test Backend'\n    needs: [build-backend]\n    runs-on: windows-latest\n    env:\n      FORTUNA_MODE: webservice\n    steps:\n      - name: Download Backend Executable\n        uses: actions/download-artifact@v4\n        with:\n          name: backend-executable\n          path: ./dist\n      - name: Run Backend and Test\n        shell: pwsh\n        run: |\n          $stdOutLog = \"backend-out.log\"\n          $stdErrLog = \"backend-err.log\"\n          Start-Process -FilePath \"./dist/fortuna-backend.exe\" -RedirectStandardOutput $stdOutLog -RedirectStandardError $stdErrLog\n          Write-Host \"Waiting for backend...\"\n          Start-Sleep -Seconds 10\n          try {\n              $response = Invoke-WebRequest -Uri \"http://127.0.0.1:8000/\" -UseBasicParsing -TimeoutSec 2\n              if ($response.StatusCode -eq 200) { Write-Host \"\u2705 Health check passed!\" -ForegroundColor Green }\n          } catch {\n              if (Test-Path $stdOutLog) { Get-Content $stdOutLog -Tail 20 }\n              if (Test-Path $stdErrLog) { Get-Content $stdErrLog -Tail 20 }\n              throw \"\u274c Backend health check failed.\"\n          }\n          Stop-Process -Name \"fortuna-backend\" -Force -ErrorAction SilentlyContinue\n\n  # ============================================================================\n  # JOB 3: PACKAGE SERVICE MSI\n  # ============================================================================\n  package-msi-service:\n    name: '\ud83d\udcbf Package Service MSI'\n    needs: [smoke-test-backend]\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n      - name: Download Backend Executable\n        uses: actions/download-artifact@v4\n        with:\n          name: backend-executable\n          path: ./dist\n      - name: Stage Artifacts\n        id: stage_files\n        shell: pwsh\n        run: |\n          $staging = \"build_wix/staging\"\n          New-Item -ItemType Directory -Path $staging -Force | Out-Null\n          Move-Item -Path \"./dist/fortuna-backend.exe\" -Destination \"$staging/fortuna-backend.exe\" -Force\n          $msiName = \"Fortuna-WebService-${{ github.ref_name }}.msi\".Replace('/', '-')\n          if ($msiName -match \"main\") { $msiName = \"Fortuna-WebService-Nightly.msi\" }\n          echo \"msi_name=$msiName\" >> $env:GITHUB_OUTPUT\n      - name: Setup .NET 8 SDK\n        uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: '8.0.x'\n      \n      # CRITICAL FIX: Remove conflicting WXS file to prevent duplicate symbol errors\n      - name: Remove Conflicting WXS File\n        shell: pwsh\n        run: |\n          if (Test-Path \"build_wix/Product_WithoutService.wxs\") {\n            Remove-Item \"build_wix/Product_WithoutService.wxs\" -Force\n            Write-Host \"\u2705 Removed conflicting Product_WithoutService.wxs\" -ForegroundColor Green\n          }\n\n      - name: Generate WiX Project File\n        working-directory: build_wix\n        shell: pwsh\n        run: |\n          $msiOutputName = \"${{ steps.stage_files.outputs.msi_name }}\".Replace('.msi', '')\n          $wixProjContent = @\"\n          <Project Sdk=\"WixToolset.Sdk/4.0.5\">\n            <PropertyGroup>\n              <OutputName>$msiOutputName</OutputName>\n              <OutputType>Package</OutputType>\n              <DefineConstants>SourceDir=staging</DefineConstants>\n              <Platforms>x64</Platforms>\n              <EnableDefaultCompileItems>false</EnableDefaultCompileItems>\n            </PropertyGroup>\n            <ItemGroup>\n              <PackageReference Include=\"WixToolset.Util.wixext\" Version=\"4.0.5\" />\n              <PackageReference Include=\"WixToolset.Firewall.wixext\" Version=\"4.0.5\" />\n              <PackageReference Include=\"WixToolset.UI.wixext\" Version=\"4.0.5\" />\n            </ItemGroup>\n            <ItemGroup>\n              <Compile Include=\"Product_WithService.wxs\" />\n            </ItemGroup>\n          </Project>\n          \"@\n          Set-Content -Path \"Fortuna.wixproj\" -Value $wixProjContent -Encoding UTF8\n      \n      - name: Build MSI\n        working-directory: build_wix\n        shell: pwsh\n        run: |\n          dotnet build Fortuna.wixproj -c Release -p:Platform=x64\n          $msiPath = \"bin/x64/Release/${{ steps.stage_files.outputs.msi_name }}\"\n          if (-not (Test-Path $msiPath)) { throw \"\u274c Service MSI was not created.\" }\n          New-Item -ItemType Directory -Path \"dist\" -Force | Out-Null\n          Copy-Item -Path $msiPath -Destination \"dist/\" -Force\n      - name: Upload MSI Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: fortuna-installer-service\n          path: build_wix/dist/*.msi\n          retention-days: 1\n\n  # ============================================================================\n  # JOB 4: CREATE GITHUB RELEASE\n  # ============================================================================\n  create-release:\n    name: '\ud83d\ude80 Create GitHub Release'\n    needs: [package-msi-service]\n    runs-on: ubuntu-latest\n    if: startsWith(github.ref, 'refs/tags/')\n    steps:\n      - name: Download All MSI Artifacts\n        uses: actions/download-artifact@v4\n        with:\n          path: installers/\n      - name: Create Release\n        uses: softprops/action-gh-release@v1\n        with:\n          files: installers/*/*.msi\n          body: |\n            \ud83c\udfc6 **Fortuna Faucet Production Release**\n            Native Windows Service Installer.\n          draft: false\n          prerelease: false\n",
    ".gitignore": "# Byte-compiled / optimized files\n__pycache__/\n*.pyc\n!*.spec\n\n# Distribution / packaging\nbuild/\ndist/\n*.egg-info/\n\n# Unit test / coverage reports\n.pytest_cache/\n.coverage\n\n# Environments\n.venv/\nvenv/\nenv/\n\n# IDE settings\n.vscode/\n.idea/\n\n# Database files\n*.db\n*.sqlite\n*.sqlite3\n\n# Node.js\nnode_modules/\n/ui/node_modules/\n/ui/build/\nweb_platform/frontend/.next/\n\n# Environment files\n.env\n.env.*\n# Allow specific env templates\n!.env.example\n!/web_platform/frontend/.env.local\n\n# Log files\n*.log\n*.log*\n\n\n# Security\n.key\n\n# Review artifacts\nReviewableJSON/\n\n# Image files\n*.png\n",
    "JSON_BACKUP_MANIFEST.md": "# Checkmate Ultimate Solo: JSON Backup Manifest (Total Recall Edition)\n\n**Purpose:** To provide a single, complete, and verified list of direct links to the JSON backups of all CORE and Operational files. This is the definitive entry point for external AI code review.\n\n---\n\n## 1.0 CORE Architecture (JSON Backups)\n\n### Python Backend\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/api.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/engine.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/models.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/__init__.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/base.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/utils.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/betfair_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/pointsbet_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/racing_and_sports_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/tvg_adapter.py.json\n\n### TypeScript Frontend\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/package.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/package-lock.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/next.config.mjs.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/tailwind.config.ts.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/tsconfig.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/page.tsx.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/layout.tsx.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/globals.css.json\n\n---\n\n## 2.0 Operational & Tooling (JSON Backups)\n\n### Project Tooling\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/.gitignore.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/convert_to_json.py.json\n\n### Environment & Setup\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/setup_windows.bat.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/.env.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/requirements.txt.json\n\n### Strategic Blueprints\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/README.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/ARCHITECTURAL_MANDATE.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/HISTORY.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/STATUS.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/WISDOM.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/PROJECT_MANIFEST.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/ROADMAP_APPENDICES.md.json",
    "MANIFEST_PART2_FRONTEND.json": "[\n    \"electron/assets/.gitkeep\",\n    \"electron/assets/banner.bmp\",\n    \"electron/assets/dialog.bmp\",\n    \"electron/assets/icon.ico\",\n    \"electron/assets/license.rtf\",\n    \"electron/electron-builder-config.yml\",\n    \"electron/install-dependencies.js\",\n    \"electron/install-validator.js\",\n    \"electron/main.js\",\n    \"electron/package-lock.json\",\n    \"electron/package.json\",\n    \"electron/preload.js\",\n    \"electron/resources/.gitkeep\",\n    \"electron/secure-settings-manager.js\",\n    \"web_platform/api_gateway/package-lock.json\",\n    \"web_platform/api_gateway/package.json\",\n    \"web_platform/api_gateway/src/server.ts\",\n    \"web_platform/api_gateway/src/services/DatabaseService.ts\",\n    \"web_platform/api_gateway/tsconfig.json\",\n    \"web_platform/frontend/.gitignore\",\n    \"web_platform/frontend/app/Providers.tsx\",\n    \"web_platform/frontend/app/globals.css\",\n    \"web_platform/frontend/app/layout.tsx\",\n    \"web_platform/frontend/app/page.tsx\",\n    \"web_platform/frontend/next-env.d.ts\",\n    \"web_platform/frontend/next.config.mjs\",\n    \"web_platform/frontend/out/app-build-manifest.json\",\n    \"web_platform/frontend/out/build-manifest.json\",\n    \"web_platform/frontend/out/cache/webpack/client-development/0.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/client-development/1.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/client-development/2.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/client-development/index.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/client-development/index.pack.gz.old\",\n    \"web_platform/frontend/out/cache/webpack/server-development/0.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/server-development/1.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/server-development/index.pack.gz\",\n    \"web_platform/frontend/out/package.json\",\n    \"web_platform/frontend/out/react-loadable-manifest.json\",\n    \"web_platform/frontend/out/server/app-paths-manifest.json\",\n    \"web_platform/frontend/out/server/app/_not-found/page.js\",\n    \"web_platform/frontend/out/server/app/_not-found/page_client-reference-manifest.js\",\n    \"web_platform/frontend/out/server/app/page.js\",\n    \"web_platform/frontend/out/server/app/page_client-reference-manifest.js\",\n    \"web_platform/frontend/out/server/interception-route-rewrite-manifest.js\",\n    \"web_platform/frontend/out/server/middleware-build-manifest.js\",\n    \"web_platform/frontend/out/server/middleware-manifest.json\",\n    \"web_platform/frontend/out/server/middleware-react-loadable-manifest.js\",\n    \"web_platform/frontend/out/server/next-font-manifest.js\",\n    \"web_platform/frontend/out/server/next-font-manifest.json\",\n    \"web_platform/frontend/out/server/pages-manifest.json\",\n    \"web_platform/frontend/out/server/server-reference-manifest.js\",\n    \"web_platform/frontend/out/server/server-reference-manifest.json\",\n    \"web_platform/frontend/out/server/vendor-chunks/@swc.js\",\n    \"web_platform/frontend/out/server/vendor-chunks/@tanstack.js\",\n    \"web_platform/frontend/out/server/vendor-chunks/next.js\",\n    \"web_platform/frontend/out/server/webpack-runtime.js\",\n    \"web_platform/frontend/out/static/chunks/_app-pages-browser_src_components_LiveRaceDashboard_tsx.js\",\n    \"web_platform/frontend/out/static/chunks/app/_not-found/page.js\",\n    \"web_platform/frontend/out/static/chunks/app/layout.js\",\n    \"web_platform/frontend/out/static/chunks/app/page.js\",\n    \"web_platform/frontend/out/static/chunks/polyfills.js\",\n    \"web_platform/frontend/out/static/chunks/webpack.js\",\n    \"web_platform/frontend/out/static/development/_buildManifest.js\",\n    \"web_platform/frontend/out/static/development/_ssgManifest.js\",\n    \"web_platform/frontend/out/static/webpack/01fdca362d2484da.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/0b14ffdc6b7405b0.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/0c13911c36654704.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/0cc62c0d69337015.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/1102717a44ab94bf.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/1d062a4e4b35d832.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/21491417ca7217a4.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/2ee876d7437031ad.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/30465abebefde3c5.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/37b04dca5a231885.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/3e580a3b3e254396.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/3e8a0401ffd42d5d.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/3f1c3fdd4110bb04.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/3f1f3ff31d98afe7.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/430150897770bc5d.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/4de2e9c6b8f4c203.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/5443d0dc225d24d3.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/55da9d621eb1b5ad.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/6e7923fa5dbd9424.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/6ec70d586d2284c9.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/72955ddbc10a2b90.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/790eca55bdffbf91.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/794677064701dbe2.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/7d88d39af9b94529.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/825e6c5a6d51fb53.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8308a84cca948fdc.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/833937b119865b49.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/84482d1ccb0e3e71.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/845040b3ab1bf0c4.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/84a4c7fac1ec51da.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8855e7e0a16aba28.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8b27cec4e9c67e4e.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8c89b2b88bafc3c8.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8eb67309205ed244.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8ebd0c1b7991f533.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/92aeba9d00e54170.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/93cbed664bd2d989.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/97e0b85b30bf4436.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/99a83d4470cbbbc3.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.01fdca362d2484da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.0c13911c36654704.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.0cc62c0d69337015.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.1102717a44ab94bf.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.1d062a4e4b35d832.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.21491417ca7217a4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.2ee876d7437031ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.30465abebefde3c5.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.37b04dca5a231885.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.3e580a3b3e254396.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.3e8a0401ffd42d5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.3f1c3fdd4110bb04.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.3f1f3ff31d98afe7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.4de2e9c6b8f4c203.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.5443d0dc225d24d3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.55da9d621eb1b5ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.6e7923fa5dbd9424.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.6ec70d586d2284c9.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.72955ddbc10a2b90.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.790eca55bdffbf91.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.794677064701dbe2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.7d88d39af9b94529.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.825e6c5a6d51fb53.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.8308a84cca948fdc.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.845040b3ab1bf0c4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.84a4c7fac1ec51da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.8855e7e0a16aba28.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.8c89b2b88bafc3c8.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.92aeba9d00e54170.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.93cbed664bd2d989.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.99a83d4470cbbbc3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.a45cc08a37f050d1.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.af91db5e83d57611.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.c2062fb2e060f992.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.c679324551e5c1b6.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.c841923556cf90df.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.c930a8ef74aeb182.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.d1dc2849d77d7161.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.d534dd4e05712657.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.d6265b1d3d3abb87.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.e17cee7bf39d45a2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.ed79f245a27328f3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.f24862a0b3194137.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.f35d73514d14d52e.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.f9c203cbadc07384.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.fe5ad14e23c61cde.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/a45cc08a37f050d1.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/af91db5e83d57611.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/app/layout.01fdca362d2484da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.0b14ffdc6b7405b0.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.0c13911c36654704.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.0cc62c0d69337015.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.1102717a44ab94bf.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.1d062a4e4b35d832.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.21491417ca7217a4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.2ee876d7437031ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.30465abebefde3c5.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.37b04dca5a231885.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.3e580a3b3e254396.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.3e8a0401ffd42d5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.3f1c3fdd4110bb04.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.3f1f3ff31d98afe7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.430150897770bc5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.4de2e9c6b8f4c203.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.5443d0dc225d24d3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.55da9d621eb1b5ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.6e7923fa5dbd9424.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.6ec70d586d2284c9.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.72955ddbc10a2b90.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.790eca55bdffbf91.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.794677064701dbe2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.7d88d39af9b94529.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.825e6c5a6d51fb53.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8308a84cca948fdc.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.833937b119865b49.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.84482d1ccb0e3e71.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.845040b3ab1bf0c4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.84a4c7fac1ec51da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8855e7e0a16aba28.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8c89b2b88bafc3c8.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8eb67309205ed244.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8ebd0c1b7991f533.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.92aeba9d00e54170.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.93cbed664bd2d989.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.97e0b85b30bf4436.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.99a83d4470cbbbc3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.a45cc08a37f050d1.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.af91db5e83d57611.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.b0b37d6009df81e0.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c2062fb2e060f992.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c679324551e5c1b6.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c69a370f1cf00177.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c841923556cf90df.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c89b36212a277c3f.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c930a8ef74aeb182.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.d1dc2849d77d7161.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.d534dd4e05712657.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.d6265b1d3d3abb87.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.d9f9b1d577c226e7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.e17cee7bf39d45a2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.ed79f245a27328f3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.f24862a0b3194137.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.f35d73514d14d52e.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.f9c203cbadc07384.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.fe5ad14e23c61cde.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/b0b37d6009df81e0.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c2062fb2e060f992.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c679324551e5c1b6.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c69a370f1cf00177.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c841923556cf90df.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c89b36212a277c3f.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c930a8ef74aeb182.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/d1dc2849d77d7161.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/d534dd4e05712657.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/d6265b1d3d3abb87.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/d9f9b1d577c226e7.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/e17cee7bf39d45a2.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/ed79f245a27328f3.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/f24862a0b3194137.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/f35d73514d14d52e.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/f9c203cbadc07384.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/fe5ad14e23c61cde.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/webpack.01fdca362d2484da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.0b14ffdc6b7405b0.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.0c13911c36654704.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.0cc62c0d69337015.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.1102717a44ab94bf.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.1d062a4e4b35d832.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.21491417ca7217a4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.2ee876d7437031ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.30465abebefde3c5.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.37b04dca5a231885.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.3e580a3b3e254396.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.3e8a0401ffd42d5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.3f1c3fdd4110bb04.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.3f1f3ff31d98afe7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.430150897770bc5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.4de2e9c6b8f4c203.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.5443d0dc225d24d3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.55da9d621eb1b5ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.6e7923fa5dbd9424.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.6ec70d586d2284c9.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.72955ddbc10a2b90.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.790eca55bdffbf91.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.794677064701dbe2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.7d88d39af9b94529.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.825e6c5a6d51fb53.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8308a84cca948fdc.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.833937b119865b49.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.84482d1ccb0e3e71.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.845040b3ab1bf0c4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.84a4c7fac1ec51da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8855e7e0a16aba28.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8b27cec4e9c67e4e.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8c89b2b88bafc3c8.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8eb67309205ed244.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8ebd0c1b7991f533.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.92aeba9d00e54170.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.93cbed664bd2d989.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.97e0b85b30bf4436.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.99a83d4470cbbbc3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.a45cc08a37f050d1.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.af91db5e83d57611.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.b0b37d6009df81e0.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c2062fb2e060f992.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c679324551e5c1b6.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c69a370f1cf00177.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c841923556cf90df.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c89b36212a277c3f.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c930a8ef74aeb182.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.d1dc2849d77d7161.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.d534dd4e05712657.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.d6265b1d3d3abb87.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.d9f9b1d577c226e7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.e17cee7bf39d45a2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.ed79f245a27328f3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.f24862a0b3194137.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.f35d73514d14d52e.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.f9c203cbadc07384.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.fe5ad14e23c61cde.hot-update.js\",\n    \"web_platform/frontend/out/trace\",\n    \"web_platform/frontend/out/types/app/layout.ts\",\n    \"web_platform/frontend/out/types/app/page.ts\",\n    \"web_platform/frontend/out/types/package.json\",\n    \"web_platform/frontend/package-lock.json\",\n    \"web_platform/frontend/package.json\",\n    \"web_platform/frontend/postcss.config.js\",\n    \"web_platform/frontend/public/manifest.json\",\n    \"web_platform/frontend/public/sw.js\",\n    \"web_platform/frontend/public/workbox-4754cb34.js\",\n    \"web_platform/frontend/src/components/AdapterStatusPanel.tsx\",\n    \"web_platform/frontend/src/components/EmptyState.tsx\",\n    \"web_platform/frontend/src/components/LiveModeToggle.tsx\",\n    \"web_platform/frontend/src/components/LiveRaceDashboard.tsx\",\n    \"web_platform/frontend/src/components/LiveRaceDashboardNoSSR.tsx\",\n    \"web_platform/frontend/src/components/ManualOverridePanel.tsx\",\n    \"web_platform/frontend/src/components/RaceCard.tsx\",\n    \"web_platform/frontend/src/components/RaceCardSkeleton.tsx\",\n    \"web_platform/frontend/src/components/RaceFilters.tsx\",\n    \"web_platform/frontend/src/components/ScoreBadge.tsx\",\n    \"web_platform/frontend/src/components/SettingsPage.tsx\",\n    \"web_platform/frontend/src/components/StatusDetailModal.tsx\",\n    \"web_platform/frontend/src/components/Tabs.tsx\",\n    \"web_platform/frontend/src/components/TrifectaFactors.tsx\",\n    \"web_platform/frontend/src/hooks/useRealTimeRaces.ts\",\n    \"web_platform/frontend/src/hooks/useWebSocket.ts\",\n    \"web_platform/frontend/src/lib/queryClient.ts\",\n    \"web_platform/frontend/src/types/electron.d.ts\",\n    \"web_platform/frontend/src/types/racing.ts\",\n    \"web_platform/frontend/src/utils/exportManager.ts\",\n    \"web_platform/frontend/tailwind.config.ts\",\n    \"web_platform/frontend/tsconfig.json\"\n]",
    "MANIFEST_PART4_ROOT.json": "[\n    \".env.example\",\n    \".github/dependabot.yml\",\n    \".github/workflows/build-msi.yml\",\n    \".github/workflows/codeql.yml\",\n    \".gitignore\",\n    \"AGENTS.md\",\n    \"ARCHITECTURAL_MANDATE.md\",\n    \"ARCHIVE_PROJECT.py\",\n    \"FORTUNA_ALL_PART5.JSON\",\n    \"HISTORY.md\",\n    \"JSON_BACKUP_MANIFEST.md\",\n    \"MANIFEST_SCRIPTS.json\",\n    \"PSEUDOCODE.MD\",\n    \"README.md\",\n    \"README_WINDOWS.md\",\n    \"REBRANDING_AUDIT.md\",\n    \"ROADMAP_APPENDICES.md\",\n    \"STATUS.md\",\n    \"USER_GUIDE.MD\",\n    \"USER_GUIDE.md\",\n    \"VERSION.txt\",\n    \"WISDOM.md\",\n    \"assets/sounds/.gitkeep\",\n    \"audit-ignore.txt\",\n    \"build_wix/Product.wxs\",\n    \"build_wix/build_msi.py\",\n    \"check_port.py\",\n    \"config.ini\",\n    \"configure_startup.py\",\n    \"create_fortuna_json.py\",\n    \"fortuna-backend.spec\",\n    \"fortuna-backend.spec.template\",\n    \"fortuna_app.py\",\n    \"fortuna_monitor.py\",\n    \"frontend.log\",\n    \"jules-scratch/verification/launch.png\",\n    \"jules-scratch/verification/verification.png\",\n    \"jules-scratch/verification/verify_error_handling.py\",\n    \"jules-scratch/verification/verify_frontend.py\",\n    \"jules-scratch/verification/verify_launch.py\",\n    \"jules-scratch/verification/verify_page.py\",\n    \"manual_override_tool.py\",\n    \"package-lock.json\",\n    \"package.json\",\n    \"playwright_test.js\",\n    \"pyproject.toml\",\n    \"pytest.ini\",\n    \"requirements-dev.in\",\n    \"requirements-dev.txt\",\n    \"requirements.txt\",\n    \"scripts/audit_rebranding.py\",\n    \"scripts/convert_to_json.py\",\n    \"scripts/fortuna-quick-start.ps1\",\n    \"scripts/get_api_key.py\",\n    \"scripts/install_fortuna_gui.bat\",\n    \"scripts/install_fortuna_silent.bat\",\n    \"scripts/prepare_minimal_build.py\",\n    \"scripts/repair_fortuna.bat\",\n    \"scripts/uninstall_fortuna.bat\",\n    \"setup.py\",\n    \"test-results/.last-run.json\",\n    \"verification.png\",\n    \"verify_dashboard.py\",\n    \"windows_service.py\",\n    \"wix/WixUI_CustomInstallDir.wxs\",\n    \"wix/WixUI_CustomProgress.wxs\",\n    \"wix/product.wxs\"\n]",
    "PSEUDOCODE.MD": "# \ud83d\udc0e Fortuna Faucet - Complete Pseudocode Blueprint\n\n**Status:** Comprehensive System Specification (Revised & Corrected)\n**Version:** 2.2.0\n**Last Updated:** November 7, 2025\n\n---\n\n## TABLE OF CONTENTS\n\n1.  System Overview\n2.  Architecture Pillars\n3.  Backend Engine (Python) - Detailed\n4.  Frontend Interface (TypeScript/React) - Detailed\n5.  Electron Wrapper & Windows Integration - Detailed\n6.  Data Models & API Specification\n7.  Deployment & Automation (CI/CD)\n8.  End-to-End Workflows\n\n---\n\n## 1. SYSTEM OVERVIEW\n\n```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551         FORTUNA FAUCET - Racing Analysis Platform             \u2551\n\u2551  Unifying global horse/greyhound/harness racing intelligence   \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nMISSION:\n  \u2022 Acquire race data from 20+ global sources (APIs + web scraping).\n  \u2022 Normalize and deduplicate data into a canonical Race format.\n  \u2022 Apply analytical filters to surface high-value betting opportunities.\n  \u2022 Serve results via a secure, local REST API to an interactive dashboard.\n  \u2022 Operate as a professional, standalone, native Windows application.\n\nCORE TENETS:\n  \u2022 UI-First Experience: The user interface is always responsive, even during backend startup or restarts.\n  \u2022 Resilient Process Management: The backend executable's lifecycle is robustly managed, with timeouts and crash detection.\n  \u2022 Asynchronous Initialization: The backend server starts instantly, deferring heavy, blocking I/O to background threads.\n  \u2022 Secure by Design: Communication between the frontend and the privileged main process is secured via a context-aware preload script.\n  \u2022 Automated & Repeatable Builds: The entire application is built, tested, and packaged via a deterministic CI/CD pipeline.\n\nSTAKEHOLDERS:\n  \u2022 End User: Receives a professional MSI installer for a one-click, dependency-free launch.\n  \u2022 Developer: Works with clean, separated Python and TypeScript stacks, governed by this specification.\n```\n\n---\n\n## 2. ARCHITECTURE PILLARS\n\n### Pillar 1: Backend Engine (Python)\n\n```\nPYTHON_BACKEND:\n  \u251c\u2500 main.py\n  \u2502  \u2514\u2500 Entry point for PyInstaller executable; starts the Uvicorn server.\n  \u2502\n  \u251c\u2500 api.py\n  \u2502  \u2514\u2500 FastAPI application definition.\n  \u2502     \u251c\u2500 Lifespan Hook: Manages async startup/shutdown logic.\n  \u2502     \u251c\u2500 API Routes: /health, /api/status, /api/races, etc.\n  \u2502     \u2514\u2500 Dependency Injection: Provides engine and security dependencies.\n  \u2502\n  \u251c\u2500 engine.py\n  \u2502  \u2514\u2500 OddsEngine: Orchestrates all data fetching and processing.\n  \u2502\n  \u251c\u2500 adapters/\n  \u2502  \u251c\u2500 base_v3.py (Abstract Base Class for all data sources)\n  \u2502  \u2514\u2500 [20+ specific adapter implementations]\n  \u2502\n  \u251c\u2500 config.py\n  \u2502  \u2514\u2500 Pydantic settings management from .env file.\n  \u2502\n  \u2514\u2500 requirements.txt\n     \u2514\u2500 Clean, de-duplicated, and conflict-free list of all Python dependencies.\n```\n\n### Pillar 2: Frontend Interface (TypeScript/React)\n\n```\nFRONTEND:\n  \u251c\u2500 next.config.mjs\n  \u2502  \u2514\u2500 Next.js config with `output: 'export'` for 100% static generation.\n  \u2502\n  \u251c\u2500 app/page.tsx\n  \u2502  \u2514\u2500 Main application shell.\n  \u2502\n  \u251c\u2500 src/components/\n  \u2502  \u251c\u2500 LiveRaceDashboard.tsx (Main stateful component)\n  \u2502  \u2502  \u251c\u2500 Manages connection state ('connecting', 'online', 'error').\n  \u2502  \u2502  \u251c\u2500 Polls Electron main process for backend status via secure IPC.\n  \u2502  \u2502  \u2514\u2500 Fetches data from the local Python API when online.\n  \u2502  \u2502\n  \u2502  \u251c\u2500 RaceCard.tsx (Displays a single race)\n  \u2502  \u2514\u2500 StatusIndicator.tsx (Shows backend connection status)\n  \u2502\n  \u2514\u2500 src/types/\n     \u2514\u2500 racing.ts (TypeScript interfaces matching backend Pydantic models)\n```\n\n### Pillar 3: Electron Wrapper & Windows Integration\n\n```\nELECTRON_WRAPPER:\n  \u251c\u2500 main.js (Electron main process)\n  \u2502  \u251c\u2500 Creates the BrowserWindow and loads the static frontend.\n  \u2502  \u251c\u2500 Implements robust lifecycle management for the backend executable.\n  \u2502  \u251c\u2500 Provides secure IPC handlers for status checks and restarts.\n  \u2502  \u2514\u2500 Creates a system tray icon for background operation.\n  \u2502\n  \u251c\u2500 preload.js (Secure IPC Bridge)\n  \u2502  \u2514\u2500 Uses `contextBridge` to safely expose specific functions to the frontend.\n  \u2502\n  \u251c\u2500 package.json\n  \u2502  \u2514\u2500 Defines Node.js dependencies and build scripts.\n  \u2502\n  \u251c\u2500 electron-builder-config.yml\n  \u2502  \u2514\u2500 Defines the configuration for creating the final MSI installer.\n  \u2502\n  \u2514\u2500 .github/workflows/build-msi.yml\n     \u2514\u2500 GitHub Actions pipeline that automates the entire build, test, and package process.\n```\n\n---\n\n## 3. BACKEND ENGINE (PYTHON) - DETAILED\n\n### 3.1 Entry Point & Server Startup (`main.py`)\n\n```pseudocode\n// This is the script executed by fortuna-backend.exe\n\nPROCEDURE Main_Python_Entry_Point\n  // Guard required for PyInstaller and multiprocessing on Windows\n  IF this script is the main entry point:\n    CALL multiprocessing.freeze_support()\n\n    // Programmatically launch the FastAPI application using Uvicorn\n    // This call blocks and runs the server until the process is terminated\n    CALL uvicorn.run(\n      app=\"python_service.api:app\",\n      host=\"0.0.0.0\",\n      port=8000\n    )\nEND PROCEDURE\n```\n\n### 3.2 Asynchronous Application Lifecycle (`api.py`)\n\n```pseudocode\n// --- Lifespan Management (The key to a non-blocking startup) ---\nASYNC FUNCTION lifespan_manager(app: FastAPI):\n  // === ON STARTUP ===\n  LOG \"Uvicorn server is online. Starting lifespan initialization.\"\n\n  // 1. Perform immediate, non-blocking tasks\n  CONNECT to Redis cache\n\n  // 2. Defer slow, blocking tasks to a background thread\n  //    This allows the server to start accepting requests instantly.\n  SCHEDULE function \"initialize_heavy_resources(app)\" to run in a ThreadPoolExecutor\n\n  LOG \"Heavy resource initialization scheduled. Server is now responsive.\"\n\n  // 3. Yield control back to Uvicorn. The server is now live.\n  YIELD\n\n  // === ON SHUTDOWN ===\n  LOG \"Shutdown signal received.\"\n  AWAIT app.state.engine.close() // Gracefully close HTTP client connections\n  DISCONNECT from Redis\n  SHUTDOWN ThreadPoolExecutor\n\n// --- Heavy Initialization (Runs in Background) ---\nFUNCTION initialize_heavy_resources(app: FastAPI):\n  TRY\n    LOG \"Background initialization of OddsEngine has started.\"\n    settings <- get_settings_from_config()\n    engine <- create new OddsEngine(config=settings)\n    // This part is slow: it loads all ~25 adapters\n    app.state.engine <- engine\n    LOG \"Background initialization complete. OddsEngine is now available.\"\n  CATCH Exception as e:\n    LOG_CRITICAL \"Failed to initialize OddsEngine in the background.\", error=e\n    app.state.engine <- null // Ensure the app knows initialization failed\n```\n\n### 3.3 Engine Orchestration (`engine.py`)\n\n```pseudocode\nCLASS OddsEngine:\n  INIT(config):\n    self.config <- config\n    self.adapters <- [List of all adapter instances]\n    self.http_client <- httpx.AsyncClient(...)\n    self.semaphore <- asyncio.Semaphore(config.MAX_CONCURRENT_REQUESTS)\n\n    // Inject the shared, persistent HTTP client into each adapter\n    FOR adapter IN self.adapters:\n      adapter.http_client <- self.http_client\n\n  @cache_async_result(ttl_seconds=300)\n  ASYNC FUNCTION fetch_all_odds(date_str):\n    // Create a list of concurrent fetching tasks, wrapped in the semaphore\n    tasks <- [self._fetch_with_semaphore(adapter, date_str) FOR adapter in self.adapters]\n    results <- AWAIT asyncio.gather(*tasks, return_exceptions=True)\n\n    // Process results, separating successes from failures\n    all_races <- []\n    FOR result IN results:\n      IF result is a success:\n        all_races.extend(result.races)\n\n    // Deduplicate and merge races from different sources\n    deduped_races <- self._dedupe_races(all_races)\n\n    RETURN AggregatedResponse(races=deduped_races, source_statuses=...)\n```\n\n---\n\n## 4. FRONTEND INTERFACE (TYPESCRIPT/REACT) - DETAILED\n\n### 4.1 LiveRaceDashboard Component\n\n```pseudocode\nCOMPONENT LiveRaceDashboard (client-side):\n\n  STATE:\n    races: Race[] <- []\n    backendStatus: 'connecting' | 'online' | 'error' <- 'connecting'\n    lastLogs: string[] <- []\n\n  EFFECT on mount:\n    // Use the secure API exposed by preload.js\n    IF window.electronAPI exists:\n      // Set up a listener for status updates from the main process\n      window.electronAPI.onBackendStatus((update) => {\n        setBackendStatus(update.state)\n        setLastLogs(update.logs)\n      })\n\n    // Immediately request the current status\n    window.electronAPI.getBackendStatus().then((status) => {\n      setBackendStatus(status.state)\n      setLastLogs(status.logs)\n    })\n\n    // Set up a polling interval to keep status fresh\n    interval <- setInterval(() => {\n      window.electronAPI.getBackendStatus().then((status) => {\n        setBackendStatus(status.state)\n        setLastLogs(status.logs)\n      })\n    }, 3000) // Poll every 3 seconds\n\n    CLEANUP: clearInterval(interval)\n\n  EFFECT when backendStatus changes to 'online':\n    // Trigger data fetch only when the backend is confirmed to be running\n    fetchQualifiedRaces()\n\n  ASYNC FUNCTION fetchQualifiedRaces():\n    TRY:\n      // Make a standard HTTP call to the local Python server\n      response <- AWAIT fetch(\"http://127.0.0.1:8000/api/races/qualified/trifecta\")\n      IF NOT response.ok:\n        RAISE new Error(`API returned status ${response.status}`)\n\n      data <- AWAIT response.json()\n      setRaces(data.races)\n\n    CATCH e:\n      // If the API call fails, update the status\n      setBackendStatus('error')\n      setLastLogs([...lastLogs, `API Fetch Error: ${e.message}`])\n\n  FUNCTION RENDER:\n    <div className=\"dashboard\">\n      <StatusIndicator status={backendStatus} />\n      <RaceFilters />\n\n      IF backendStatus === 'error':\n        <ErrorDisplay logs={lastLogs} />\n      ELSE IF backendStatus === 'connecting':\n        <LoadingSkeleton />\n      ELSE IF races.length === 0:\n        <EmptyState message=\"No races matched your filters.\" />\n      ELSE:\n        <RaceGrid races={races} />\n    </div>\n```\n\n---\n\n## 5. ELECTRON WRAPPER & WINDOWS INTEGRATION - DETAILED\n\n### 5.1 Main Process (`main.js`) - With Robust Lifecycle Management\n\n```pseudocode\nCLASS FortunaDesktopApp:\n  INIT():\n    self.mainWindow <- null\n    self.backendState <- 'stopped'\n    self.backendLogs <- []\n    self.backendProcess <- null\n\n  FUNCTION createMainWindow():\n    // ... create BrowserWindow, load static frontend ...\n\n  FUNCTION startBackend():\n    IF self.backendProcess is not null:\n      self.backendProcess.kill()\n\n    self.backendState <- 'starting'\n    self.backendLogs <- ['Attempting to start backend...']\n    self.sendBackendStatusUpdate() // Notify UI\n\n    // Get path to the packaged executable\n    exePath <- path.join(process.resourcesPath, 'fortuna-backend', 'fortuna-backend.exe')\n\n    IF file at exePath does NOT exist:\n      self.backendState <- 'error'\n      self.backendLogs.push(`FATAL: Executable not found at ${exePath}`)\n      self.sendBackendStatusUpdate()\n      dialog.showErrorBox(\"Critical Error\", \"Backend is missing. Please reinstall.\")\n      RETURN\n\n    // Spawn the process\n    self.backendProcess <- spawn(exePath, [], { stdio: ['ignore', 'pipe', 'pipe'] })\n\n    // --- CRITICAL: Resiliency Logic ---\n    startupTimeout <- setTimeout(() => {\n      IF self.backendState === 'starting':\n        self.backendState <- 'error'\n        self.backendLogs.push('Error: Backend startup timed out after 30 seconds.')\n        self.backendProcess.kill()\n        self.sendBackendStatusUpdate()\n    }, 30000) // 30-second timeout\n\n    self.backendProcess.stdout.on('data', (data) => {\n      self.backendLogs.push(data.toString())\n      // A more robust check would be a successful health check poll\n      IF data.toString().includes(\"Uvicorn running\"):\n        self.backendState <- 'online'\n        clearTimeout(startupTimeout)\n        self.sendBackendStatusUpdate()\n    })\n\n    self.backendProcess.stderr.on('data', (data) => {\n      self.backendLogs.push(`[STDERR] ${data.toString()}`)\n    })\n\n    self.backendProcess.on('exit', (code) => {\n      clearTimeout(startupTimeout)\n      IF self.backendState is not 'error': // Avoid duplicate error messages\n        self.backendState <- 'error'\n        self.backendLogs.push(`Backend process exited unexpectedly with code: ${code}`)\n        self.sendBackendStatusUpdate()\n    })\n\n  FUNCTION sendBackendStatusUpdate():\n    // Send the latest status to the frontend renderer process\n    IF self.mainWindow is not null:\n      self.mainWindow.webContents.send('backend-status-update', {\n        state: self.backendState,\n        logs: self.backendLogs.slice(-20) // Send last 20 log lines\n      })\n\n// --- IPC Handlers (Securely Defined) ---\nipcMain.handle('get-backend-status', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN null\n\n  RETURN { state: self.backendState, logs: self.backendLogs.slice(-20) }\n})\n\nipcMain.on('restart-backend', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN\n\n  self.startBackend()\n})\n```\n\n### 5.2 Preload Script (`preload.js`)\n\n```pseudocode\n// Expose a limited, secure API to the frontend renderer process\ncontextBridge.exposeInMainWorld('electronAPI', {\n  getBackendStatus: () => ipcRenderer.invoke('get-backend-status'),\n  restartBackend: () => ipcRenderer.send('restart-backend'),\n  onBackendStatus: (callback) => ipcRenderer.on('backend-status-update', (_event, value) => callback(value))\n})\n```\n\n---\n\n## 6. DATA MODELS & API SPECIFICATION\n\n### 6.1 Core Data Models (Pydantic/TypeScript)\n\n```\nMODEL Race:\n  id: str (unique identifier, e.g., \"Betfair_USA_Aqueduct_2025-11-07_R1\")\n  venue: str\n  race_number: int\n  start_time: datetime\n  runners: List[Runner]\n  source: str\n\nMODEL Runner:\n  name: str\n  odds: Optional[float]\n```\n\n### 6.2 Primary API Endpoints\n\n```\nENDPOINT GET /health\n  Description: Simple health check, requires no authentication.\n  Response (200 OK): {\"status\": \"ok\"}\n\nENDPOINT GET /api/races/qualified/trifecta\n  Description: Fetches all race data, runs the Trifecta analyzer, and returns qualified races.\n  Headers:\n    - X-API-Key: (Required, not used in this local setup but good practice)\n  Query Params:\n    - max_field_size: int\n    - min_odds: float\n  Response (200 OK):\n    {\n      \"qualified_races\": List[Race],\n      \"analysis_metadata\": { ... }\n    }\n```\n\n---\n\n## 7. DEPLOYMENT & AUTOMATION (CI/CD)\n\n```pseudocode\nWORKFLOW Build_MSI_Installer_on_GitHub_Actions:\n  // Phase 1: Setup\n  SETUP Node.js and Python environments\n\n  // Phase 2: Build Frontend\n  RUN \"npm ci\" and \"npm run build\" in /web_platform/frontend\n  COPY static output to /electron/web-ui-build/out\n\n  // Phase 3: Build Backend\n  RUN \"pip install -r python_service/requirements.txt\"\n  // CRITICAL: Use PyInstaller with a spec file or CLI flags that include\n  // necessary hidden imports to prevent runtime crashes.\n  // e.g., --hidden-import=keyring.backends.fail.Keyring\n  EXECUTE PyInstaller to create fortuna-backend.exe\n  PLACE executable in /electron/resources/fortuna-backend\n\n  // Phase 4: Deep Integration Test\n  START fortuna-backend.exe in the background\n  POLL http://127.0.0.1:8000/health until it responds with 200 OK or times out\n  IF timeout or crash THEN FAIL the build\n\n  // Phase 5: Package\n  RUN \"npm ci\" in /electron\n  EXECUTE \"npx electron-builder\" to create the MSI installer\n\n  // Phase 6: Publish\n  UPLOAD MSI as a build artifact\n  IF build was triggered by a git tag THEN CREATE a new GitHub Release\n```\n\n---\n\n## 8. END-TO-END WORKFLOWS\n\n### 8.1 Production Startup Workflow (Resilient)\n\n```\nWORKFLOW user_launches_application:\n  STEP 1: User executes Fortuna Faucet.exe -> Electron main.js starts.\n  STEP 2: UI appears instantly. The main process creates the BrowserWindow and loads the static index.html. The UI shows a 'connecting' state.\n  STEP 3: Backend starts asynchronously. The main process calls the robust `startBackend()` function.\n  STEP 4: `startBackend()` spawns `fortuna-backend.exe` and starts a 30-second timeout.\n  STEP 5: The frontend UI polls for status every 3 seconds via the secure `window.electronAPI.getBackendStatus()`.\n  STEP 6: The backend `.exe` starts, its `lifespan` hook runs, and the Uvicorn server comes online within seconds.\n  STEP 7: The main process detects the \"Uvicorn running\" message (or a successful health poll) and updates its internal state to 'online'. The startup timeout is cleared.\n  STEP 8: On its next poll, the frontend receives the 'online' status.\n  STEP 9: The frontend's state changes, triggering the `fetchQualifiedRaces()` API call to `localhost:8000`.\n  STEP 10: Data is returned from the now fully-initialized backend and rendered in the UI.\n\n  FAILURE SCENARIO (Backend Crash):\n  STEP 6a: The backend `.exe` crashes on startup.\n  STEP 7a: The `on('exit')` handler in `main.js` fires. The state is set to 'error' with the exit code.\n  STEP 8a: On its next poll, the frontend receives the 'error' status and relevant logs.\n  STEP 9a: The UI renders an error message and a \"Restart Backend\" button.\n```\n\n---\n*This concludes the revised and definitive blueprint for the Fortuna Faucet application.*",
    "README_WINDOWS.md": "# \ud83d\udc34 Fortuna Faucet - User Guide for Windows\n\nWelcome to Fortuna Faucet! This guide provides simple, step-by-step instructions to get you up and running.\n\n## Installation\n\nInstalling the application is a straightforward process using our official installer.\n\n1.  **Download the Installer:**\n    *   Go to the [**Latest Release Page**](https://github.com/masonj0/fortuna/releases/latest) on GitHub.\n    *   Download the file ending in `.msi` (e.g., `JBMason's 1st App-X.X.X.msi`).\n\n2.  **Run the Installer:**\n    *   Double-click the downloaded `.msi` file to launch the setup wizard.\n    *   Follow the on-screen instructions to complete the installation.\n\n## What to Expect After Installation\n\nOnce the setup is complete, you will find a new folder in your Start Menu named **\"JBMason's 1st App\"**.\n\n*   **Launching the App:** Inside this folder, click on the **\"JBMason's 1st App\"** shortcut to start the application.\n*   **How it Works:** The shortcut launches the main application window (the dashboard). The backend data engine starts automatically in the background and will close when you exit the application.\n\nThat's it! All previous installation methods are now obsolete. Enjoy using the application!\n",
    "USER_GUIDE.md": "# \ud83c\udfaf Fortuna Faucet: Complete User Guide for Windows Hobbyists\n\n## What Is This Amazing Software?\n\n**Fortuna Faucet** is a professional-grade horse racing analysis platform that:\n- \ud83d\udcca Aggregates data from **20+ global racing sources** simultaneously\n- \ud83e\udd16 Uses AI-powered analysis to find value betting opportunities\n- \ud83d\udcc8 Provides live odds monitoring via Betfair Exchange\n- \ud83c\udf10 Features a beautiful web dashboard for real-time insights\n- \ud83d\udd04 Runs automatically in the background like a professional service\n\nThink of it as your personal racing intelligence agency!\n\n---\n\n## \ud83d\ude80 Quick Start (15 Minutes to Racing!)\n\n### Step 1: One-Click Installation\n1. Extract all files to `C:\\FortunaFaucet` (or your preferred location)\n2. **Right-click** `INSTALL_FORTUNA.bat` \u2192 **Run as Administrator**\n3. Wait 3-5 minutes while it automatically installs:\n   - Python 3.11 (if needed)\n   - Node.js (if needed)\n   - All required packages\n\n### Step 2: Quick Configuration\n1. **Double-click** `setup_wizard.py` in your folder\n2. Follow the friendly prompts to configure:\n   - Your private API key (auto-generated)\n   - Betfair credentials (optional, for live odds)\n3. The wizard creates your `.env` file automatically!\n\n### Step 3: Launch!\n- **Double-click** the \"Launch Fortuna\" shortcut on your desktop\n- Wait 10 seconds for services to start\n- Your dashboard opens automatically in your browser! \ud83c\udf89\n\n---\n\n## \ud83c\udfae Using Your New Command Center\n\n### The Dashboard (http://localhost:3000)\nYour racing command center features:\n\n**\ud83d\udcca Statistics Panel** (Top of screen)\n- **Qualified Races**: How many races meet your criteria\n- **Premium Targets**: High-score opportunities (80%+)\n- **Next Race**: Countdown to the next qualifying race\n- **Avg Field Size**: Average number of horses\n\n**\ud83c\udf9b\ufe0f Smart Filters** (Middle section)\nCustomize what you see:\n- **Min Score Slider**: Only show races above X% match\n- **Max Field Size**: Filter by number of runners (8, 10, 12, or Any)\n- **Sort By**: Order by score, time, or track name\n\n**\ud83c\udfc7 Race Cards** (Main display)\nEach card shows:\n- Track name and race number\n- Qualification score (color-coded!)\n- Race conditions (distance, surface)\n- Top 3 contenders with best odds\n- Data source count\n\n### Color Coding System\n- \ud83d\udd34 **Red (80%+)**: Premium betting opportunity!\n- \ud83d\udfe1 **Yellow (60-79%)**: Good value potential\n- \ud83d\udfe2 **Green (<60%)**: Meets minimum criteria\n\n---\n\n## \ud83d\udd27 Advanced Features\n\n### Live Odds Monitoring\nOnce you've added Betfair credentials:\n1. The system automatically tracks races approaching post time\n2. Updates odds every 30 seconds for races within 5 minutes\n3. Highlights dramatic odds movements\n\n### Desktop Monitor Tool\nRun `fortuna_monitor.py` for a real-time status window:\n- Shows all data source health\n- Performance graphs (with matplotlib)\n- Success rates and fetch durations\n- Quick \"Refresh Now\" button\n\n### Auto-Start on Windows Boot\nRun `SCHEDULE_FORTUNA.bat` (as Administrator):\n- Fortuna starts when you log into Windows\n- Daily 3 AM restart for fresh data\n- Runs silently in the background\n\n---\n\n## \ud83c\udfaf Understanding the \"Trifecta Analyzer\"\n\nThis is the brain! It scores races on three factors:\n\n### Factor 1: Field Size (smaller is better)\n- **Why**: Fewer horses = easier to predict\n- **Default**: Maximum 10 runners\n\n### Factor 2: Favorite's Odds (higher is better)\n- **Why**: If the favorite is 2.5+, the race is wide open\n- **Default**: Minimum 2.5\n\n### Factor 3: Second Favorite's Odds (higher is better)\n- **Why**: Confirms multiple horses are competitive\n- **Default**: Minimum 4.0\n\n**The Score**: Combines all three into a 0-100% match rating!\n\n---\n\n## \ud83d\udcda System Architecture (Simplified)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \ud83c\udf10 Next.js Dashboard (Port 3000)    \u2502\n\u2502     Your beautiful web interface        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 API Calls\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   \ud83d\udc0d Python FastAPI Backend (Port 8000) \u2502\n\u2502   - OddsEngine: Fetches from 20+ sources\u2502\n\u2502   - TrifectaAnalyzer: Scores races      \u2502\n\u2502   - LiveOddsMonitor: Betfair tracking   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 Async Requests\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \ud83d\udd0c Adapter Fleet (20+ sources)      \u2502\n\u2502  TVG \u2022 Betfair \u2022 TimeForm \u2022 GBGB       \u2502\n\u2502  RacingAndSports \u2022 USTA \u2022 And more!     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n---\n\n## \ud83d\udd10 Security Notes\n\n### API Keys\n- **Your local API_KEY**: Only for communication between YOUR backend and frontend\n- Never shared online, never exposed\n- Auto-generated during setup\n\n### External API Keys (Optional)\nAdd these to `.env` for more data sources:\n```\nTVG_API_KEY=\"your_tvg_key\"\nRACING_AND_SPORTS_TOKEN=\"your_ras_token\"\nTHE_RACING_API_KEY=\"your_theracingapi_key\"\n```\n\nGet keys from:\n- TVG: https://www.tvg.com/promos/developer-api\n- Racing and Sports: https://www.racingandsports.com/data-api/\n- The Racing API: https://www.theracingapi.com/\n\n---\n\n## \ud83d\udee0\ufe0f Troubleshooting\n\n### \"Backend Offline\" Error\n```batch\n# Stop everything cleanly\nSTOP_FORTUNA.bat\n\n# Wait 10 seconds, then restart\nLAUNCH_FORTUNA.bat\n```\n\n### Dashboard Loads But No Data\n1. Open `http://localhost:8000/health` in browser\n2. Should show: `{\"status\": \"OK\"}`\n3. If not, check Python backend window for errors\n\n### \"Port Already In Use\" Error\nSomeone else is using port 8000 or 3000:\n```batch\n# Windows: Kill processes on those ports\nnetstat -ano | findstr :8000\ntaskkill /PID [number] /F\n\nnetstat -ano | findstr :3000\ntaskkill /PID [number] /F\n```\n\n### Reset Everything\n```batch\n# Nuclear option: Clean slate\nSTOP_FORTUNA.bat\ndel .env\nsetup_wizard.py\nINSTALL_FORTUNA.bat\n```\n\n---\n\n## \ud83d\udcd6 File Structure Explained\n\n### Critical Files (Don't Delete!)\n- `.env` - Your configuration (API keys, settings)\n- `requirements.txt` - Python packages list\n- `package.json` - Node.js packages list\n\n### Convenience Scripts\n- `LAUNCH_FORTUNA.bat` - Start everything\n- `STOP_FORTUNA.bat` - Stop everything\n- `RESTART_FORTUNA.bat` - Clean restart\n- `setup_wizard.py` - Interactive config tool\n\n### Python Backend (`python_service/`)\n- `api.py` - Web server (FastAPI)\n- `engine.py` - Master data orchestrator\n- `analyzer.py` - Race scoring logic\n- `models.py` - Data structure definitions\n- `adapters/` - Individual data source plugins\n\n### Frontend (`web_platform/frontend/`)\n- `src/app/page.tsx` - Main dashboard\n- `src/components/RaceCard.tsx` - Individual race display\n- `.env.local` - Frontend API key\n\n---\n\n## \ud83c\udf93 Customization Ideas\n\n### Change Analyzer Thresholds\nEdit `python_service/analyzer.py`:\n```python\nclass TrifectaAnalyzer(BaseAnalyzer):\n    def __init__(self,\n                 max_field_size: int = 8,      # \u2190 Change this\n                 min_favorite_odds: float = 3.0, # \u2190 Or this\n                 min_second_favorite_odds: float = 5.0): # \u2190 Or this\n```\n\n### Add New Data Sources\n1. Copy `python_service/adapters/template_adapter.py`\n2. Rename and implement the `fetch_races()` method\n3. Register in `python_service/adapters/__init__.py`\n4. Add to `python_service/engine.py` adapter list\n\n### Customize Dashboard Colors\nEdit `web_platform/frontend/tailwind.config.ts`:\n```typescript\ntheme: {\n  extend: {\n    colors: {\n      'fortuna-primary': '#your-hex-color',\n    }\n  }\n}\n```\n\n---\n\n## \ud83d\udca1 Pro Tips\n\n### Tip 1: Use Windows Task Scheduler\nRun `SCHEDULE_FORTUNA.bat` for:\n- Auto-start on login\n- Daily 3 AM maintenance restart\n\n### Tip 2: Monitor Multiple Days\nThe analyzer works for \"today\" by default, but you can query any date:\n```\nhttp://localhost:8000/api/races/qualified/trifecta?race_date=2025-10-25\n```\n\n### Tip 3: Export Data\nThe API returns pure JSON. Use tools like:\n- **Postman** for testing\n- **PowerShell** for scripting:\n```powershell\nInvoke-RestMethod -Uri \"http://localhost:8000/api/races/qualified/trifecta\" `\n  -Headers @{\"X-API-Key\"=\"your_key\"} | ConvertTo-Json -Depth 10\n```\n\n### Tip 4: Mobile Access\nIf you want to check from your phone on the same WiFi:\n1. Find your PC's IP: `ipconfig` in Command Prompt\n2. Open firewall port 3000\n3. Access from phone: `http://192.168.1.X:3000`\n\n---\n\n## \ud83c\udf89 You're Ready!\n\nThis is a **professional-grade** system that you now control. It was built with years of racing analytics experience and modern software practices.\n\n### What You Can Do Now:\n\u2705 Track races from 20+ global sources\n\u2705 Identify value opportunities with AI scoring\n\u2705 Monitor live odds movements\n\u2705 Run 24/7 as a background service\n\u2705 Customize thresholds and filters\n\u2705 Expand with new data sources\n\n**Welcome to the world of algorithmic racing analysis!** \ud83c\udfc7\ud83d\ude80\n\n---\n\n## \ud83d\udcde Additional Resources\n\n### Project Documentation\n- `HISTORY.md` - Project evolution story\n- `ARCHITECTURAL_MANDATE.md` - System design principles\n- `WISDOM.md` - Developer best practices\n- `ROADMAP_APPENDICES.md` - Future expansion ideas\n\n### Useful Commands\n```batch\n# View all active Python processes\ntasklist | findstr python\n\n# Check if ports are available\nnetstat -ano | findstr :8000\nnetstat -ano | findstr :3000\n\n# Update Python packages\n.venv\\Scripts\\activate\npip install --upgrade -r requirements.txt\n```\n\n### Need Help?\n1. Check `fortuna_restart.log` for error history\n2. Run `fortuna_monitor.py` to see real-time system status\n3. Verify `.env` file has all required keys\n\nHappy Racing! \ud83c\udfb0\ud83c\udfc6",
    "VERSION.txt": "1.0",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2)---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "build_wix/Product_WithService.wxs": "<Wix xmlns=\"http://wixtoolset.org/schemas/v4/wxs\"\n     xmlns:util=\"http://wixtoolset.org/schemas/v4/wxs/util\"\n     xmlns:firewall=\"http://wixtoolset.org/schemas/v4/wxs/firewall\"\n     xmlns:ui=\"http://wixtoolset.org/schemas/v4/wxs/ui\">\n\n  <Package Name=\"Fortuna Faucet Web Service\"\n           Manufacturer=\"Fortuna Development Team\"\n           Version=\"1.0.0.0\"\n           UpgradeCode=\"d8ba82a4-1215-4c83-9369-5254165563e4\"\n           Scope=\"perMachine\">\n\n    <MajorUpgrade DowngradeErrorMessage=\"A newer version is already installed.\" />\n    <MediaTemplate EmbedCab=\"yes\" />\n\n    <Feature Id=\"MainApplication\" Title=\"Main Application\" Level=\"1\">\n      <ComponentGroupRef Id=\"ServiceComponents\" />\n      <ComponentGroupRef Id=\"ShortcutsComponentGroup\" />\n    </Feature>\n\n    <StandardDirectory Id=\"ProgramFiles64Folder\">\n      <Directory Id=\"INSTALLFOLDER\" Name=\"Fortuna\">\n        <Directory Id=\"DataFolder\" Name=\"data\" />\n        <Directory Id=\"LogsFolder\" Name=\"logs\" />\n\n        <Component Id=\"FortunaBackendService\" Guid=\"a1b1a73a-4424-4221-897b-0331984639e2\">\n          <File Id=\"FortunaBackendExe\"\n                Source=\"$(var.SourceDir)/fortuna-backend.exe\"\n                KeyPath=\"yes\" />\n\n          <Environment Id=\"FortunaDataDir\" Name=\"FORTUNA_DATA_DIR\" Value=\"[DataFolder]\" Action=\"set\" System=\"yes\" />\n          <Environment Id=\"FortunaLogDir\" Name=\"FORTUNA_LOG_DIR\" Value=\"[LogsFolder]\" Action=\"set\" System=\"yes\" />\n          <Environment Id=\"FortunaMode\" Name=\"FORTUNA_MODE\" Value=\"webservice\" Action=\"set\" System=\"yes\" />\n\n          <ServiceInstall Id=\"InstallFortunaService\"\n                          Name=\"FortunaBackendService\"\n                          DisplayName=\"Fortuna Faucet Backend\"\n                          Description=\"Handles data aggregation for Fortuna Faucet.\"\n                          Start=\"auto\"\n                          Type=\"ownProcess\"\n                          ErrorControl=\"normal\"\n                          Account=\"LocalService\" />\n\n          <ServiceControl Id=\"StartFortunaService\"\n                          Name=\"FortunaBackendService\"\n                          Start=\"install\"\n                          Stop=\"both\"\n                          Remove=\"uninstall\"\n                          Wait=\"yes\" />\n\n          <firewall:FirewallException Id=\"FWException\"\n                                      Name=\"Fortuna Faucet\"\n                                      Port=\"8000\"\n                                      Protocol=\"tcp\"\n                                      Scope=\"any\" />\n\n          <CreateFolder Directory=\"DataFolder\">\n            <util:PermissionEx User=\"LocalService\" GenericAll=\"yes\" />\n          </CreateFolder>\n          <CreateFolder Directory=\"LogsFolder\">\n            <util:PermissionEx User=\"LocalService\" GenericAll=\"yes\" />\n          </CreateFolder>\n        </Component>\n      </Directory>\n    </StandardDirectory>\n\n    <StandardDirectory Id=\"ProgramMenuFolder\">\n      <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Service\" />\n    </StandardDirectory>\n\n    <ComponentGroup Id=\"ServiceComponents\">\n      <ComponentRef Id=\"FortunaBackendService\" />\n    </ComponentGroup>\n\n    <ComponentGroup Id=\"ShortcutsComponentGroup\" Directory=\"ApplicationProgramsFolder\">\n      <Component Id=\"ApplicationShortcuts\" Guid=\"0fe34ea7-c144-465a-8ab7-7eef33ccfd5c\">\n        <util:InternetShortcut Id=\"DashboardShortcut\" Name=\"Fortuna Faucet Dashboard\" Target=\"http://localhost:8000\" />\n        <Shortcut Id=\"UninstallShortcut\" Name=\"Uninstall Fortuna Service\" Description=\"Remove this application\" Target=\"[System64Folder]msiexec.exe\" Arguments=\"/x [ProductCode]\" />\n        <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\" />\n        <RegistryValue Root=\"HKCU\" Key=\"Software\\Fortuna Faucet Service\" Name=\"Installed\" Type=\"integer\" Value=\"1\" KeyPath=\"yes\" />\n      </Component>\n    </ComponentGroup>\n\n    <!-- MODERN WIX V4 UI SYNTAX -->\n    <ui:WixUI Id=\"WixUI_InstallDir\" InstallDirectory=\"INSTALLFOLDER\" />\n\n  </Package>\n</Wix>\n",
    "build_wix/Product_WithoutService.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://wixtoolset.org/schemas/v4/wxs\"\n     xmlns:util=\"http://wixtoolset.org/schemas/v4/wxs/util\">\n\n  <Package Name=\"Fortuna Faucet - Standalone\"\n           Manufacturer=\"Fortuna Development Team\"\n           Version=\"1.0.0.0\"\n           UpgradeCode=\"28085bda-8ed9-48de-8d12-08d9cc77fb76\"\n           Scope=\"perMachine\">\n\n    <MajorUpgrade DowngradeErrorMessage=\"A newer version is already installed.\" />\n    <MediaTemplate EmbedCab=\"yes\" />\n\n    <!-- Features -->\n    <Feature Id=\"MainApplication\" Title=\"Main Application\" Level=\"1\">\n      <ComponentGroupRef Id=\"StandaloneComponents\" />\n      <ComponentGroupRef Id=\"ShortcutsComponentGroup\"/>\n    </Feature>\n\n    <!-- Directory Structure -->\n    <StandardDirectory Id=\"ProgramFiles64Folder\">\n      <Directory Id=\"INSTALLFOLDER\" Name=\"Fortuna Standalone\">\n        <Component Id=\"FortunaBackendStandalone\" Guid=\"04e85c16-b8de-4ca6-b540-dbf5f178ba3e\">\n          <File Id=\"FortunaBackendExe\"\n                Source=\"$(var.SourceDir)/fortuna-backend.exe\"\n                KeyPath=\"yes\" />\n        </Component>\n      </Directory>\n    </StandardDirectory>\n\n    <StandardDirectory Id=\"ProgramMenuFolder\">\n        <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Standalone\"/>\n    </StandardDirectory>\n\n    <!-- Component Groups -->\n    <ComponentGroup Id=\"StandaloneComponents\">\n      <ComponentRef Id=\"FortunaBackendStandalone\" />\n    </ComponentGroup>\n\n    <ComponentGroup Id=\"ShortcutsComponentGroup\" Directory=\"ApplicationProgramsFolder\">\n      <Component Id=\"ApplicationShortcuts\" Guid=\"f4bd5c40-1d9f-4428-9413-8fbcf6ecdc4e\">\n          <util:InternetShortcut Id=\"DashboardShortcut\" Name=\"Fortuna Faucet Dashboard\" Target=\"http://localhost:8000\"/>\n          <Shortcut Id=\"UninstallShortcut\" Name=\"Uninstall Fortuna Faucet Standalone\" Description=\"Remove this application\" Target=\"[System64Folder]msiexec.exe\" Arguments=\"/x [ProductCode]\" />\n          <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\"/>\n          <RegistryValue Root=\"HKCU\" Key=\"Software\\Fortuna Faucet Standalone\" Name=\"Installed\" Type=\"integer\" Value=\"1\" KeyPath=\"yes\"/>\n      </Component>\n    </ComponentGroup>\n\n    <!-- UI -->\n    <Property Id=\"WIXUI_INSTALLDIR\" Value=\"INSTALLFOLDER\" />\n    <UI>\n      <UIRef Id=\"WixUI_InstallDir\" />\n    </UI>\n\n  </Package>\n</Wix>\n",
    "configure_startup.py": "# configure_startup.py\nimport sys\nimport winreg\nfrom pathlib import Path\n\n\nclass StartupManager:\n    \"\"\"Manage Windows startup registry entries for the current user.\"\"\"\n\n    REGISTRY_PATH = r\"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n    APP_NAME = \"FortunaFaucetTray\"\n\n    @classmethod\n    def is_enabled(cls) -> bool:\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_READ)\n            winreg.QueryValueEx(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            return True\n        except FileNotFoundError:\n            return False\n\n    @classmethod\n    def enable(cls):\n        launcher_path = Path(__file__).parent / \"launcher.ps1\"\n        cmd = f'powershell.exe -WindowStyle Hidden -File \"{launcher_path}\"'\n\n        key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n        winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, cmd)\n        winreg.CloseKey(key)\n        print(\"Startup enabled.\")\n\n    @classmethod\n    def disable(cls):\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n            winreg.DeleteValue(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            print(\"Startup disabled.\")\n        except FileNotFoundError:\n            print(\"Already disabled.\")\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"enable\":\n            StartupManager.enable()\n        elif sys.argv[1] == \"disable\":\n            StartupManager.disable()\n        elif sys.argv[1] == \"status\":\n            print(f\"Startup is currently {'enabled' if StartupManager.is_enabled() else 'disabled'}\")\n    else:\n        print(\"Usage: python configure_startup.py [enable|disable|status]\")\n",
    "electron/electron-builder-config.yml": "appId: com.fortuna.faucet\nproductName: \"Fortuna Faucet\"\ndirectories:\n  buildResources: \"assets\"\n  output: \"dist\"\nfiles:\n  - \"main.js\"\n  - \"preload.js\"\n  - \"package.json\"\n  - \"secure-settings-manager.js\"\n  - \"web-ui-build/out/**/*\"\n  - \"assets/**/*\"\nextraResources:\n  - from: \"resources/fortuna-backend.exe\"\n    to: \"fortuna-backend.exe\"\nwin:\n  target: \"msi\"\n  icon: \"assets/icon.ico\"\nmsi:\n  oneClick: false\n  perMachine: true\n  runAfterFinish: true\n  createDesktopShortcut: true\n  createStartMenuShortcut: true\n  shortcutName: \"Fortuna Faucet\"\n",
    "fortuna-backend-electron.spec": "# -*- mode: python ; coding: utf-8 -*-\n\nblock_cipher = None\n\na = Analysis(\n    ['python_service/main.py'],\n    pathex=[],\n    binaries=[],\n    datas=[\n        ('python_service/data', 'data'),\n        ('python_service/json', 'json'),\n        ('python_service/adapters', 'adapters'),\n    ],\n    hiddenimports=[\n        'uvicorn.logging',\n        'uvicorn.loops',\n        'uvicorn.loops.auto',\n        'uvicorn.protocols',\n        'uvicorn.protocols.http',\n        'uvicorn.protocols.http.auto',\n        'uvicorn.protocols.websockets',\n        'uvicorn.protocols.websockets.auto',\n        'uvicorn.lifespan',\n        'uvicorn.lifespan.on',\n        'numpy',\n        'pandas',\n    ],\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz,\n    a.scripts,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    [],\n    name='fortuna-backend',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    runtime_tmpdir=None,\n    console=True,\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\n",
    "fortuna_app.py": "import os\nimport socket\nimport subprocess\nimport sys\nimport threading\nimport time\nimport tkinter as tk\nfrom pathlib import Path\nfrom tkinter import messagebox\nfrom tkinter import scrolledtext\nfrom tkinter import ttk\n\nimport psutil\nimport requests\n\n\n# --- Control Panel Tab (from former launcher_gui.py) ---\nclass ControlPanelTab(tk.Frame):\n    def __init__(self, parent, master_app):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self.master_app = master_app\n        self.backend_proc = None\n        self.frontend_proc = None\n        self.backend_unresponsive_count = 0\n        self.frontend_unresponsive_count = 0\n        self.first_launch = not (Path(os.environ[\"USERPROFILE\"]) / \"Desktop\" / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\").exists()\n        self._create_ui()\n        self.monitor_thread = threading.Thread(target=self.monitor_services, daemon=True)\n        self.monitor_thread.start()\n\n    def log_output(self, message):\n        self.log_text.config(state=tk.NORMAL)\n        self.log_text.insert(tk.END, f\"[{time.strftime('%H:%M:%S')}] {message}\\n\")\n        self.log_text.config(state=tk.DISABLED)\n        self.log_text.see(tk.END)\n\n    def smart_start(self):\n        \"\"\"On first launch, run verification, create shortcuts, and then start.\"\"\"\n        if messagebox.askokcancel(\n            \"First-Time Setup\",\n            \"Welcome to Fortuna Faucet!\\n\\nThis first launch will verify your system and create a desktop shortcut for easy access. Proceed?\",\n        ):\n            # Steal and run the logic from the System Tools Tab\n            self.master_app.notebook.select(self.master_app.system_tools_tab)\n            self.master_app.system_tools_tab.run_verification()\n            self.master_app.system_tools_tab.run_create_shortcuts()\n\n            # Once done, revert to a normal start button\n            messagebox.showinfo(\"Setup Complete\", \"Setup is complete! The main services will now start.\")\n            self.launch_btn.config(text=\"\u25b6 START FORTUNA\", bg=\"#00ff88\", command=self.launch_services)\n            self.launch_services()\n\n    def _create_ui(self):\n        title = tk.Label(\n            self,\n            text=\"\ud83d\udc34 System Control Panel\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        )\n        title.pack(pady=20)\n\n        status_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        status_frame.pack(fill=tk.X, padx=40, pady=10)\n\n        tk.Label(\n            status_frame,\n            text=\"Backend Service (API)\",\n            font=(\"Segoe UI\", 10),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        self.backend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg=\"#0f3460\", highlightthickness=0)\n        self.backend_status_canvas.pack(fill=tk.X, pady=(0, 10))\n        self.backend_indicator = self.backend_status_canvas.create_oval(15, 10, 35, 30, fill=\"#ff4444\", outline=\"\")\n        self.backend_text = self.backend_status_canvas.create_text(\n            55, 20, text=\"Stopped\", fill=\"#ffffff\", anchor=\"w\", font=(\"Segoe UI\", 9)\n        )\n\n        tk.Label(\n            status_frame,\n            text=\"Frontend Dashboard (UI)\",\n            font=(\"Segoe UI\", 10),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        self.frontend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg=\"#0f3460\", highlightthickness=0)\n        self.frontend_status_canvas.pack(fill=tk.X)\n        self.frontend_indicator = self.frontend_status_canvas.create_oval(15, 10, 35, 30, fill=\"#ff4444\", outline=\"\")\n        self.frontend_text = self.frontend_status_canvas.create_text(\n            55, 20, text=\"Stopped\", fill=\"#ffffff\", anchor=\"w\", font=(\"Segoe UI\", 9)\n        )\n\n        button_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        button_frame.pack(fill=tk.X, padx=40, pady=20)\n\n        self.launch_btn = tk.Button(\n            button_frame,\n            text=\"\u25b6 START FORTUNA\",\n            font=(\"Segoe UI\", 14, \"bold\"),\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            height=2,\n            relief=tk.FLAT,\n        )\n        if self.first_launch:\n            self.launch_btn.config(\n                text=\"\u25b6 FIRST-TIME START & SETUP\",\n                bg=\"#ff9900\",\n                command=self.smart_start,\n            )\n        else:\n            self.launch_btn.config(command=self.launch_services)\n        self.launch_btn.pack(fill=tk.X, pady=(0, 10))\n\n        self.stop_btn = tk.Button(\n            button_frame,\n            text=\"\u23f9 STOP SERVICES\",\n            font=(\"Segoe UI\", 12),\n            bg=\"#ff4444\",\n            fg=\"#ffffff\",\n            command=self.stop_services,\n            state=tk.DISABLED,\n            height=1,\n            relief=tk.FLAT,\n        )\n        self.stop_btn.pack(fill=tk.X)\n\n        self.log_text = scrolledtext.ScrolledText(self, height=5, bg=\"#000000\", fg=\"#00ff88\", state=tk.DISABLED)\n        self.log_text.pack(pady=10, padx=40, fill=tk.X)\n\n    def check_ports(self, ports=[8000, 3000]):\n        unavailable_ports = []\n        for port in ports:\n            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n                if s.connect_ex((\"127.0.0.1\", port)) == 0:\n                    unavailable_ports.append(port)\n        return unavailable_ports\n\n    def launch_services(self):\n        unavailable = self.check_ports()\n        if unavailable:\n            messagebox.showerror(\n                \"Port Conflict\",\n                f\"Cannot launch. Port(s) {', '.join(map(str, unavailable))} are already in use by another application.\",\n            )\n            return\n\n        self.launch_btn.config(state=tk.DISABLED)\n        self.update_status(\"backend\", \"starting\", \"Launching...\")\n        self.update_status(\"frontend\", \"starting\", \"Launching...\")\n\n        try:\n            venv_python = Path(\".venv/Scripts/python.exe\")\n            self.backend_proc = subprocess.Popen(\n                [\n                    str(venv_python),\n                    \"-m\",\n                    \"uvicorn\",\n                    \"python_service.api:app\",\n                    \"--host\",\n                    \"127.0.0.1\",\n                    \"--port\",\n                    \"8000\",\n                ],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                cwd=Path(__file__).parent,\n                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n            )\n        except Exception as e:\n            self.update_status(\"backend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        try:\n            self.frontend_proc = subprocess.Popen(\n                [\"npm\", \"run\", \"dev\"],\n                shell=True,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                cwd=\"web_platform/frontend\",\n                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n            )\n        except Exception as e:\n            self.update_status(\"frontend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        self.stop_btn.config(state=tk.NORMAL)\n\n    def stop_services(self):\n        self.stop_btn.config(state=tk.DISABLED)\n        for proc_name in [\"backend\", \"frontend\"]:\n            proc = getattr(self, f\"{proc_name}_proc\")\n            if proc and proc.poll() is None:\n                try:\n                    parent = psutil.Process(proc.pid)\n                    for child in parent.children(recursive=True):\n                        child.kill()\n                    parent.kill()\n                except psutil.NoSuchProcess:\n                    pass\n            setattr(self, f\"{proc_name}_proc\", None)\n        self.launch_btn.config(state=tk.NORMAL)\n\n    def restart_service(self, service_name: str):\n        \"\"\"Gracefully stop and restart a single failed service.\"\"\"\n        proc_attr = f\"{service_name}_proc\"\n        proc = getattr(self, proc_attr)\n\n        # Stop the specific process\n        if proc and proc.poll() is None:\n            try:\n                parent = psutil.Process(proc.pid)\n                for child in parent.children(recursive=True):\n                    child.kill()\n                parent.kill()\n            except psutil.NoSuchProcess:\n                pass\n        setattr(self, proc_attr, None)\n\n        # Wait a moment\n        time.sleep(2)\n\n        # Relaunch the specific process\n        self.update_status(service_name, \"starting\", \"Attempting auto-restart...\")\n        try:\n            if service_name == \"backend\":\n                venv_python = Path(\".venv/Scripts/python.exe\")\n                new_proc = subprocess.Popen(\n                    [\n                        str(venv_python),\n                        \"-m\",\n                        \"uvicorn\",\n                        \"python_service.api:app\",\n                        \"--host\",\n                        \"127.0.0.1\",\n                        \"--port\",\n                        \"8000\",\n                    ],\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                    cwd=Path(__file__).parent.parent,\n                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n                )\n            else:  # frontend\n                new_proc = subprocess.Popen(\n                    [\"npm\", \"run\", \"dev\"],\n                    shell=True,\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                    cwd=\"web_platform/frontend\",\n                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n                )\n            setattr(self, proc_attr, new_proc)\n        except Exception as e:\n            self.update_status(service_name, \"error\", f\"Auto-restart failed: {e}\")\n\n    def monitor_services(self):\n        while True:\n            # --- Backend Monitoring ---\n            if self.backend_proc and self.backend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:8000/health\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"backend\", \"ok\", \"Healthy (200 OK)\")\n                        self.backend_unresponsive_count = 0  # Reset counter on success\n                    else:\n                        self.update_status(\"backend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"backend\", \"unresponsive\", \"Unresponsive\")\n                    self.backend_unresponsive_count += 1\n                    if self.backend_unresponsive_count >= 3:  # If unresponsive for 3 cycles (15s)\n                        self.log_output(\"Backend unresponsive. Attempting automatic restart...\")\n                        self.restart_service(\"backend\")\n                        self.backend_unresponsive_count = 0  # Reset after attempt\n            else:\n                self.update_status(\"backend\", \"stopped\", \"Stopped\")\n\n            # --- Frontend Monitoring ---\n            if self.frontend_proc and self.frontend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:3000\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"frontend\", \"ok\", \"Healthy (200 OK)\")\n                        self.frontend_unresponsive_count = 0\n                    else:\n                        self.update_status(\"frontend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"frontend\", \"unresponsive\", \"Unresponsive\")\n                    self.frontend_unresponsive_count += 1\n                    if self.frontend_unresponsive_count >= 3:\n                        self.log_output(\"Frontend unresponsive. Attempting automatic restart...\")\n                        self.restart_service(\"frontend\")\n                        self.frontend_unresponsive_count = 0\n            else:\n                self.update_status(\"frontend\", \"stopped\", \"Stopped\")\n            time.sleep(5)\n\n    def update_status(self, service: str, status: str, message: str):\n        colors = {\n            \"ok\": \"#00ff88\",\n            \"unresponsive\": \"#ffcc00\",\n            \"error\": \"#ff4444\",\n            \"stopped\": \"#ff4444\",\n            \"starting\": \"#0f6cbd\",\n        }\n        canvas = getattr(self, f\"{service}_status_canvas\")\n        indicator = getattr(self, f\"{service}_indicator\")\n        text = getattr(self, f\"{service}_text\")\n\n        canvas.itemconfig(indicator, fill=colors.get(status, \"#404060\"))\n        canvas.itemconfig(text, text=message)\n\n\n# --- Setup Wizard Tab (from former setup_wizard_gui.py) ---\nclass SetupWizardTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self.current_step = 0\n        self.settings = {}\n        self._create_widgets()\n        self.show_step(0)\n\n    def _create_widgets(self):\n        header = tk.Label(\n            self,\n            text=\"\ud83d\udd27 First-Time Setup & Configuration\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        header.pack(pady=20)\n        self.step_label = tk.Label(\n            self,\n            text=\"Step 1 of 4: Generate API Key\",\n            font=(\"Segoe UI\", 11),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        self.step_label.pack(pady=10)\n        self.content_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        self.content_frame.pack(fill=tk.BOTH, expand=True, padx=30, pady=20)\n        button_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        button_frame.pack(fill=tk.X, padx=30, pady=20)\n        self.prev_btn = tk.Button(\n            button_frame,\n            text=\"< Back\",\n            command=self.previous_step,\n            state=tk.DISABLED,\n            bg=\"#404060\",\n            fg=\"#ffffff\",\n            padx=20,\n        )\n        self.prev_btn.pack(side=tk.LEFT)\n        self.next_btn = tk.Button(\n            button_frame,\n            text=\"Next >\",\n            command=self.next_step,\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            font=(\"Segoe UI\", 11, \"bold\"),\n            padx=20,\n        )\n        self.next_btn.pack(side=tk.RIGHT)\n\n    def show_step(self, step_index):\n        self._clear_content()\n        self.current_step = step_index\n        if step_index == 0:\n            self._show_step_1()\n        elif step_index == 1:\n            self._show_step_2()\n        elif step_index == 2:\n            self._show_step_3()\n        elif step_index == 3:\n            self._show_step_4()\n        self.update_buttons()\n\n    def _show_step_1(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83d\udd10 Secure API Key\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        tk.Label(\n            self.content_frame,\n            text=\"A secure API key will be generated and stored.\",\n            wraplength=600,\n            justify=tk.LEFT,\n            bg=\"#1a1a2e\",\n            fg=\"#cccccc\",\n        ).pack(anchor=\"w\", pady=10)\n        # ... Add API key generation logic and display ...\n\n    def _show_step_2(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83c\udfc7 Betfair Exchange (Optional)\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        # ... Add Betfair configuration form ...\n\n    def _show_step_3(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\u2713 Verifying Setup\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(anchor=\"w\")\n        # ... Add verification checks logic ...\n\n    def _show_step_4(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83c\udf89 Setup Complete!\",\n            font=(\"Segoe UI\", 14, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(pady=20)\n        self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n\n    def next_step(self):\n        if self.current_step < 3:\n            self.show_step(self.current_step + 1)\n\n    def previous_step(self):\n        if self.current_step > 0:\n            self.show_step(self.current_step - 1)\n\n    def finish_setup(self):\n        messagebox.showinfo(\"Setup Complete\", \"Your configuration has been saved.\")\n\n    def _clear_content(self):\n        for widget in self.content_frame.winfo_children():\n            widget.destroy()\n\n    def update_buttons(self):\n        self.prev_btn.config(state=tk.NORMAL if self.current_step > 0 else tk.DISABLED)\n        if self.current_step == 3:\n            self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n        else:\n            self.next_btn.config(text=\"Next >\", command=self.next_step)\n\n\n# --- System Tools Tab ---\nclass SystemToolsTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self._create_ui()\n\n    def _create_ui(self):\n        title = tk.Label(\n            self,\n            text=\"\u2699\ufe0f System Tools\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        title.pack(pady=20)\n        tk.Button(\n            self,\n            text=\"Create Desktop Shortcuts\",\n            command=self.run_create_shortcuts,\n            font=(\"Segoe UI\", 12),\n        ).pack(pady=10, padx=40, fill=tk.X)\n        tk.Button(\n            self,\n            text=\"Verify Installation\",\n            command=self.run_verification,\n            font=(\"Segoe UI\", 12),\n        ).pack(pady=10, padx=40, fill=tk.X)\n        self.output_box = scrolledtext.ScrolledText(self, height=10, bg=\"#0f3460\", fg=\"#ffffff\", state=tk.DISABLED)\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n    def log_output(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n\n    def run_create_shortcuts(self):\n        self.log_output(\"--- Creating Desktop Shortcut ---\")\n        try:\n            from win32com.client import Dispatch\n\n            desktop = Path(os.environ[\"USERPROFILE\"]) / \"Desktop\"\n            app_path = Path(__file__).resolve()\n            shortcut_path = desktop / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\"\n\n            if shortcut_path.exists():\n                self.log_output(\"\ud83d\udfe1 Shortcut already exists. Overwriting.\")\n\n            shell = Dispatch(\"WScript.Shell\")\n            shortcut = shell.CreateShortCut(str(shortcut_path))\n            shortcut.TargetPath = sys.executable\n            shortcut.Arguments = f'\"{app_path}\"'\n            shortcut.WorkingDirectory = str(app_path.parent)\n\n            ico_path = app_path.parent / \"fortuna.ico\"\n            if ico_path.exists():\n                shortcut.IconLocation = str(ico_path)\n            else:\n                self.log_output(\"\ud83d\udfe1 Icon file not found, using default.\")\n\n            shortcut.save()\n            self.log_output(\"\u2705 Success: Shortcut created on Desktop.\")\n        except ImportError:\n            self.log_output(\"\u274c ERROR: 'pywin32' is not installed. Cannot create shortcuts.\")\n            self.log_output(\"  Please run: pip install pywin32\")\n        except Exception as e:\n            self.log_output(f\"\u274c ERROR: An unexpected error occurred: {e}\")\n\n    def run_verification(self):\n        self.log_output(\"\\n--- Verifying System Setup ---\")\n        verifications = [\n            (\"Python 3.11+\", lambda: sys.version_info >= (3, 11)),\n            (\n                \"Python Virtual Env (.venv)\",\n                lambda: Path(\".venv\").exists() and Path(\".venv/Scripts/python.exe\").exists(),\n            ),\n            (\n                \"Node.js (npm)\",\n                lambda: subprocess.run(\"npm -v\", shell=True, capture_output=True).returncode == 0,\n            ),\n            (\n                \"Frontend Dependencies (node_modules)\",\n                lambda: Path(\"web_platform/frontend/node_modules\").exists(),\n            ),\n        ]\n\n        all_ok = True\n        for name, check in verifications:\n            result = check()\n            self.log_output(f\"- {name}: {'\u2705 OK' if result else '\u274c FAILED'}\")\n            if not result:\n                all_ok = False\n\n        if all_ok:\n            self.log_output(\"\\n\u2705 All checks passed. System is ready.\")\n        else:\n            self.log_output(\"\\n\u274c Some checks failed. Please review the log.\")\n\n\n# --- Main Application Window ---\nclass FortunaApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"\ud83d\udc34 Fortuna Faucet\")\n        self.geometry(\"700x550\")\n        self.configure(bg=\"#1a1a2e\")\n\n        style = ttk.Style()\n        style.theme_use(\"clam\")\n        style.configure(\"TNotebook\", background=\"#1a1a2e\", borderwidth=0)\n        style.configure(\"TNotebook.Tab\", background=\"#404060\", foreground=\"#ffffff\", padding=[10, 5])\n        style.map(\"TNotebook.Tab\", background=[(\"selected\", \"#0f6cbd\")])\n\n        self.notebook = ttk.Notebook(self)\n\n        self.control_panel_tab = ControlPanelTab(self.notebook, self)\n        self.setup_wizard_tab = SetupWizardTab(self.notebook)\n        self.system_tools_tab = SystemToolsTab(self.notebook)\n\n        self.notebook.add(self.control_panel_tab, text=\"Control Panel\")\n        self.notebook.add(self.setup_wizard_tab, text=\"Setup & Config\")\n        self.notebook.add(self.system_tools_tab, text=\"System Tools\")\n\n        self.notebook.pack(expand=True, fill=\"both\", padx=10, pady=10)\n\n    def on_closing(self):\n        if self.control_panel_tab.backend_proc or self.control_panel_tab.frontend_proc:\n            if messagebox.askokcancel(\"Quit\", \"Services are still running. Do you want to stop them and exit?\"):\n                self.control_panel_tab.stop_services()\n                self.destroy()\n        else:\n            self.destroy()\n\n\n# --- NEW: Self-Setup UI and Logic ---\nclass SetupApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - First-Time Setup\")\n        self.geometry(\"700x500\")\n        self.configure(bg=\"#1a1a2e\")\n\n        self.protocol(\"WM_DELETE_WINDOW\", self.quit)\n\n        header_font = tk.font.Font(family=\"Segoe UI\", size=16, weight=\"bold\")\n        body_font = tk.font.Font(family=\"Segoe UI\", size=10)\n        button_font = tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\")\n\n        tk.Label(\n            self,\n            text=\"\ud83d\udce6 Welcome to Fortuna Faucet\",\n            font=header_font,\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(pady=(20, 10))\n        tk.Label(\n            self,\n            text=\"The necessary dependencies are not installed. Click 'Start Installation' to begin.\",\n            font=body_font,\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(pady=(0, 20))\n\n        self.install_button = tk.Button(\n            self,\n            text=\"\u25b6\ufe0f Start Installation\",\n            font=button_font,\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            command=self.start_installation,\n            relief=tk.FLAT,\n            padx=20,\n            pady=10,\n        )\n        self.install_button.pack(pady=10)\n\n        self.output_box = scrolledtext.ScrolledText(\n            self,\n            height=15,\n            bg=\"#0f3460\",\n            fg=\"#cccccc\",\n            state=tk.DISABLED,\n            relief=tk.FLAT,\n            bd=0,\n            padx=10,\n            pady=10,\n        )\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n        self.status_label = tk.Label(self, text=\"Waiting to start...\", font=body_font, bg=\"#1a1a2e\", fg=\"#ffffff\")\n        self.status_label.pack(pady=10)\n\n    def log(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n        self.update_idletasks()\n\n    def start_installation(self):\n        self.install_button.config(state=tk.DISABLED, text=\"Installation in progress...\")\n        self.log(\"--- Starting installation ---\")\n        self.status_label.config(text=\"Installing... Please be patient, this may take several minutes.\")\n        threading.Thread(target=self.run_install_commands, daemon=True).start()\n\n    def run_command(self, command):\n        process = subprocess.Popen(\n            command,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n            encoding=\"utf-8\",\n            errors=\"replace\",\n            shell=True,\n        )\n        for line in iter(process.stdout.readline, \"\"):\n            self.log(line.strip())\n        process.wait()\n        return process.returncode\n\n    def run_install_commands(self):\n        commands = [\n            (\n                \"1/3: Creating Python virtual environment...\",\n                f\"{sys.executable} -m venv .venv\",\n            ),\n            (\n                \"2/3: Installing Python dependencies...\",\n                '\"' + str(Path(\".venv/Scripts/python.exe\")) + '\" -m pip install -r requirements.txt',\n            ),\n            (\n                \"3/3: Installing Node.js dependencies...\",\n                \"npm install --prefix web_platform/frontend\",\n            ),\n        ]\n\n        for i, (msg, cmd) in enumerate(commands):\n            self.log(f\"\\\\n--- STEP {msg} ---\")\n            return_code = self.run_command(cmd)\n            if return_code != 0:\n                self.log(f\"\\\\n--- ERROR: Step {i + 1} failed with code {return_code}. ---\")\n                self.status_label.config(\n                    text=\"Installation Failed. Please see log for details.\",\n                    fg=\"#ff4444\",\n                )\n                self.install_button.config(state=tk.NORMAL, text=\"Retry Installation\")\n                return\n\n        self.log(\"\\\\n--- \u2705 INSTALLATION COMPLETE! ---\")\n        self.status_label.config(text=\"Setup successful! You can now launch the application.\", fg=\"#00ff88\")\n        self.install_button.destroy()\n        launch_button = tk.Button(\n            self,\n            text=\"\ud83d\ude80 Launch Fortuna\",\n            font=tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\"),\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            command=self.launch_app,\n            relief=tk.FLAT,\n            padx=20,\n            pady=10,\n        )\n        launch_button.pack(pady=10)\n\n    def launch_app(self):\n        self.destroy()\n        # Relaunch the script to start the main app\n        subprocess.Popen([sys.executable, __file__])\n\n\n# --- NEW: Main Execution Block ---\nif __name__ == \"__main__\":\n    VENV_PATH = Path(__file__).parent / \".venv\"\n    if not VENV_PATH.exists() or not (VENV_PATH / \"Scripts\" / \"python.exe\").exists():\n        # If the virtual environment doesn't exist, run the setup wizard.\n        setup_app = SetupApp()\n        setup_app.mainloop()\n    else:\n        # Otherwise, run the main application.\n        app = FortunaApp()\n        app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n        app.mainloop()\n",
    "jules-scratch/verification/verify_frontend.py": "from playwright.sync_api import sync_playwright\n\n\ndef run():\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=True)\n        page = browser.new_page()\n        page.goto(\"http://localhost:3000\")\n        page.screenshot(path=\"jules-scratch/verification/verification.png\")\n        browser.close()\n\n\nif __name__ == \"__main__\":\n    run()\n",
    "jules-scratch/verification/verify_websockets.py": "from playwright.sync_api import sync_playwright, expect\nimport time\n\ndef run(playwright):\n    browser = playwright.chromium.launch(headless=True)\n    page = browser.new_page()\n\n    # Mock the Electron API and the WebSocket connection\n    page.add_init_script(\"\"\"\n        window.electronAPI = {\n            getApiKey: () => Promise.resolve('test-api-key'),\n            getBackendStatus: () => Promise.resolve({ state: 'running', logs: [] }),\n            onBackendStatusUpdate: (callback) => {\n                // Do nothing, assume it's always running\n                return () => {}; // Return an unsubscribe function\n            }\n        };\n\n        const mockSocket = {\n            listeners: {},\n            on(event, callback) {\n                this.listeners[event] = callback;\n            },\n            close() {},\n            readyState: 0, // Initially connecting\n            send() {},\n        };\n        window.mockSocket = mockSocket;\n        window.WebSocket = function(url) {\n            console.log('Mock WebSocket created for:', url);\n            setTimeout(() => {\n                mockSocket.readyState = 1; // OPEN\n                if(mockSocket.listeners.open) {\n                    mockSocket.listeners.open();\n                }\n            }, 100);\n            return mockSocket;\n        };\n    \"\"\")\n\n    # Intercept the API call and return a mock response\n    page.route(\"**/api/adapters/status\", lambda route: route.fulfill(\n        status=200,\n        json=[]\n    ))\n\n    page.goto(\"http://localhost:3000\")\n\n    # Wait for the status indicator to be visible\n    page.wait_for_selector('[data-testid=\"status-indicator\"]')\n\n    # Check that the status indicator eventually shows \"Live\"\n    expect(page.locator('[data-testid=\"status-indicator\"]')).to_have_text(\"Live\", timeout=5000)\n\n    # Simulate a WebSocket message with race data\n    page.evaluate(\"\"\"\n        window.mockSocket.listeners.message({\n            data: JSON.stringify({\n                races: [{\n                    id: 'test-race-1',\n                    venue: 'Test Park',\n                    raceNumber: 1,\n                    isErrorPlaceholder: false,\n                    startTime: new Date().toISOString(),\n                    runners: [{\n                        number: 1,\n                        name: 'Test Horse',\n                        odds: { 'TestSource': { win: 5.0, source: 'TestSource', last_updated: new Date().toISOString() } }\n                    }]\n                }],\n                source_info: [{\n                    name: 'TestSource',\n                    status: 'SUCCESS',\n                    races_fetched: 1,\n                    fetch_duration: 0.1\n                }]\n            })\n        });\n    \"\"\")\n\n    # Check that the UI has updated with the new data\n    expect(page.get_by_text(\"Test Park\")).to_be_visible()\n    expect(page.get_by_text(\"Test Horse\")).to_be_visible()\n\n    page.screenshot(path=\"jules-scratch/verification/websockets.png\")\n    browser.close()\n\nwith sync_playwright() as playwright:\n    run(playwright)\n",
    "pg_schemas/historical_races.sql": "-- Schema for the main historical races data warehouse table\nCREATE TABLE IF NOT EXISTS historical_races (\n    race_id VARCHAR(255) PRIMARY KEY,\n    venue VARCHAR(100) NOT NULL,\n    race_number INTEGER NOT NULL,\n    start_time TIMESTAMP WITH TIME ZONE NOT NULL,\n    source VARCHAR(50),\n    qualification_score NUMERIC(5, 2),\n    field_size INTEGER,\n    extracted_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n);\n",
    "playwright_test.js": "const { chromium } = require('playwright');\nconst { test, expect } = require('@playwright/test');\n\n(async () => {\n  const browser = await chromium.launch();\n  const page = await browser.newPage();\n\n  // Navigate to the dashboard\n  await page.goto('http://localhost:3001');\n\n  // Wait for the initial loading to complete.\n  // We expect the skeleton loaders to disappear.\n  await expect(page.locator('div:has-text(\"Loading races...\")')).toHaveCount(0, { timeout: 15000 });\n\n  // Check for the manual override panel\n  const overridePanel = page.locator('div:has-text(\"Fetch Failed: AtTheRaces\")');\n  await expect(overridePanel).toBeVisible({ timeout: 10000 });\n\n  // Check for the text area with the correct URL\n  // The date is a placeholder, as it can change. The important part is the base URL.\n  const textArea = overridePanel.locator('textarea');\n  await expect(textArea).toHaveAttribute('value', /https:\\/\\/www\\.attheraces\\.com\\/racecards\\/\\d{4}-\\d{2}-\\d{2}/);\n\n\n  // Take a screenshot for visual confirmation\n  await page.screenshot({ path: 'manual-override-panel.png' });\n\n  await browser.close();\n})();\n",
    "python_service/adapters/__init__.py": "# python_service/adapters/__init__.py\n# TEMPORARY FIX: Comment out the problematic adapter\n\nfrom .at_the_races_adapter import AtTheRacesAdapter\nfrom .betfair_adapter import BetfairAdapter\nfrom .betfair_greyhound_adapter import BetfairGreyhoundAdapter\n\n# from .betfair_datascientist_adapter import BetfairDataScientistAdapter  # DISABLED: PyInstaller NumPy issue\nfrom .gbgb_api_adapter import GbgbApiAdapter\nfrom .greyhound_adapter import GreyhoundAdapter\nfrom .harness_adapter import HarnessAdapter\nfrom .pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .sporting_life_adapter import SportingLifeAdapter\nfrom .the_racing_api_adapter import TheRacingApiAdapter\nfrom .timeform_adapter import TimeformAdapter\nfrom .tvg_adapter import TVGAdapter\n\n__all__ = [\n    \"GbgbApiAdapter\",\n    \"TVGAdapter\",\n    \"BetfairAdapter\",\n    \"BetfairGreyhoundAdapter\",\n    \"RacingAndSportsGreyhoundAdapter\",\n    \"AtTheRacesAdapter\",\n    \"PointsBetGreyhoundAdapter\",\n    \"RacingAndSportsAdapter\",\n    \"SportingLifeAdapter\",\n    \"TimeformAdapter\",\n    \"HarnessAdapter\",\n    \"GreyhoundAdapter\",\n    \"TheRacingApiAdapter\",\n    # \"BetfairDataScientistAdapter\",  # DISABLED\n]\n",
    "python_service/adapters/base_adapter_v3.py": "# python_service/adapters/base_v3.py\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom typing import Any\nfrom typing import AsyncGenerator\nfrom typing import List\n\nimport httpx\nimport structlog\nfrom tenacity import RetryError\nfrom tenacity import retry\nfrom tenacity import stop_after_attempt\nfrom tenacity import wait_exponential\n\nfrom ..core.exceptions import AdapterHttpError\nfrom ..manual_override_manager import ManualOverrideManager\nfrom ..models import Race\n\n\nclass BaseAdapterV3(ABC):\n    \"\"\"\n    Abstract base class for all V3 data adapters.\n    Enforces a standardized fetch/parse pattern and includes robust request handling.\n    \"\"\"\n\n    def __init__(self, source_name: str, base_url: str, config=None, timeout: int = 20):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.config = config\n        self.timeout = timeout\n        self.logger = structlog.get_logger(adapter_name=self.source_name)\n        self.http_client: httpx.AsyncClient = None  # Injected by the engine\n        self.manual_override_manager: ManualOverrideManager = None\n        self.supports_manual_override = True  # Can be overridden by subclasses\n\n    def enable_manual_override(self, manager: ManualOverrideManager):\n        \"\"\"Injects the manual override manager into the adapter.\"\"\"\n        self.manual_override_manager = manager\n\n    @abstractmethod\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw data (e.g., HTML, JSON) for the given date.\n        This is the only method that should perform network operations.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        Parses the raw data retrieved by _fetch_data into a list of Race objects.\n        This method should be a pure function with no side effects.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        Orchestrates the fetch-then-parse pipeline for the adapter.\n        This public method should not be overridden by subclasses.\n        \"\"\"\n        raw_data = None\n\n        if self.manual_override_manager:\n            # This is not a full URL, but a representative key for the fetch operation\n            # Subclasses might need to override get_races to provide a more specific URL if needed\n            lookup_key = f\"{self.base_url}/racecards/{date}\"\n            manual_data = self.manual_override_manager.get_manual_data(self.source_name, lookup_key)\n            if manual_data:\n                self.logger.info(\"Using manually submitted data for request\", url=lookup_key)\n                # Reconstruct a dictionary similar to what _fetch_data would return\n                # This may need adjustment based on adapter specifics\n                raw_data = {\"pages\": [manual_data[0]], \"date\": date}\n\n        if raw_data is None:\n            try:\n                raw_data = await self._fetch_data(date)\n            except AdapterHttpError as e:\n                if self.manual_override_manager and self.supports_manual_override:\n                    self.manual_override_manager.register_failure(self.source_name, e.url)\n                raise  # Reraise the exception to be handled by the OddsEngine\n\n        if raw_data is not None:\n            parsed_races = self._parse_races(raw_data)\n            for race in parsed_races:\n                yield race\n\n    @retry(\n        wait=wait_exponential(multiplier=1, min=2, max=10),\n        stop=stop_after_attempt(3),\n        reraise=True,  # Reraise the final exception to be caught by get_races\n    )\n    async def make_request(self, http_client: httpx.AsyncClient, method: str, url: str, **kwargs) -> httpx.Response:\n        \"\"\"\n        Makes a resilient HTTP request with built-in retry logic using tenacity.\n        \"\"\"\n        # Ensure the URL is correctly formed, whether it's relative or absolute\n        full_url = url if url.startswith(\"http\") else f\"{self.base_url.rstrip('/')}/{url.lstrip('/')}\"\n\n        try:\n            self.logger.info(\"Making request\", method=method.upper(), url=full_url)\n            response = await http_client.request(method, full_url, timeout=self.timeout, **kwargs)\n            response.raise_for_status()  # Raise an exception for 4xx/5xx responses\n            return response\n        except httpx.HTTPStatusError as e:\n            self.logger.error(\n                \"HTTP Status Error during request\",\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            )\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            ) from e\n        except (httpx.RequestError, RetryError) as e:\n            self.logger.error(\"Request Error or Retry Error\", error=str(e))\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=503,  # Service Unavailable\n                url=full_url,\n            ) from e\n\n    def get_status(self) -> dict:\n        \"\"\"\n        Returns a dictionary representing the adapter's current status.\n        Subclasses can extend this to include more specific health checks.\n        \"\"\"\n        return {\n            \"adapter_name\": self.source_name,\n            \"status\": \"OK\",  # Basic status; can be enhanced in subclasses\n        }\n",
    "python_service/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching horse racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairExchange\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for a given date.\"\"\"\n        await self._authenticate(self.http_client)\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            self.http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"7\"],  # Horse Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\", \"US\", \"FR\", \"ZA\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\"Failed to parse a Betfair market.\", exc_info=True, market=market)\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bf_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 1m Mdn Stks').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "python_service/adapters/betfair_auth_mixin.py": "# python_service/adapters/betfair_auth_mixin.py\n\nimport asyncio\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Optional\n\nimport httpx\nimport structlog\n\nfrom ..credentials_manager import SecureCredentialsManager\n\nlog = structlog.get_logger(__name__)\n\n\nclass BetfairAuthMixin:\n    \"\"\"Encapsulates Betfair authentication logic for reuse across adapters.\"\"\"\n\n    session_token: Optional[str] = None\n    token_expiry: Optional[datetime] = None\n    _auth_lock = asyncio.Lock()\n\n    async def _authenticate(self, http_client: httpx.AsyncClient):\n        \"\"\"\n        Authenticates with Betfair using credentials from the system's credential manager,\n        ensuring the session token is valid and refreshing it if necessary.\n        \"\"\"\n        async with self._auth_lock:\n            if self.session_token and self.token_expiry and self.token_expiry > (datetime.now() + timedelta(minutes=5)):\n                return\n\n            log.info(\"Attempting to authenticate with Betfair...\")\n            username, password = SecureCredentialsManager.get_betfair_credentials()\n\n            if not all([self.config.BETFAIR_APP_KEY, username, password]):\n                raise ValueError(\"Betfair credentials not fully configured in credential manager.\")\n\n            auth_url = \"https://identitysso.betfair.com/api/login\"\n            headers = {\n                \"X-Application\": self.config.BETFAIR_APP_KEY,\n                \"Content-Type\": \"application/x-www-form-urlencoded\",\n            }\n            payload = f\"username={username}&password={password}\"\n\n            response = await http_client.post(auth_url, headers=headers, content=payload, timeout=20)\n            response.raise_for_status()\n            data = response.json()\n\n            if data.get(\"status\") == \"SUCCESS\":\n                self.session_token = data.get(\"token\")\n                self.token_expiry = datetime.now() + timedelta(hours=3)\n                log.info(\"Betfair authentication successful.\")\n            else:\n                log.error(\"Betfair authentication failed\", error=data.get(\"error\"))\n                self.session_token = None  # Reset token to prevent using a stale one\n                return  # Return gracefully and let the adapter handle the lack of a token\n",
    "python_service/adapters/equibase_adapter.py": "# python_service/adapters/equibase_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass EquibaseAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Equibase race entries, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Equibase\"\n    BASE_URL = \"https://www.equibase.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        d = datetime.strptime(date, \"%Y-%m-%d\").date()\n        index_url = f\"/entries/Entries.cfm?ELEC_DATE={d.month}/{d.day}/{d.year}&STYLE=EQB\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Equibase index page\", url=index_url)\n            return None\n\n        parser = HTMLParser(index_response.text)\n        track_links = [\n            link.attributes[\"href\"]\n            for link in parser.css(\"div.track-information a\")\n            if \"race=\" not in link.attributes.get(\"href\", \"\")\n        ]\n\n        async def get_race_links_from_track(track_url: str):\n            response = await self.make_request(self.http_client, \"GET\", track_url, headers=self._get_headers())\n            if not response:\n                return []\n            parser = HTMLParser(response.text)\n            return [link.attributes[\"href\"] for link in parser.css(\"a.program-race-link\")]\n\n        tasks = [get_race_links_from_track(link) for link in track_links]\n        results = await asyncio.gather(*tasks)\n        race_links = [f\"{self.base_url}{link}\" for sublist in results for link in sublist]\n\n        async def fetch_single_html(race_url: str):\n            response = await self.make_request(self.http_client, \"GET\", race_url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        date = raw_data[\"date\"]\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first(\"div.track-information strong\")\n                if not venue_node:\n                    continue\n                venue = clean_text(venue_node.text())\n\n                race_number_node = parser.css_first(\"div.race-information strong\")\n                if not race_number_node:\n                    continue\n                race_number_text = race_number_node.text().replace(\"Race\", \"\").strip()\n                if not race_number_text.isdigit():\n                    continue\n                race_number = int(race_number_text)\n\n                post_time_node = parser.css_first(\"p.post-time span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text().strip()\n                start_time = self._parse_post_time(date, post_time_str)\n\n                runners = []\n                runner_nodes = parser.css(\"table.entries-table tbody tr\")\n                for node in runner_nodes:\n                    if runner := self._parse_runner(node):\n                        runners.append(runner)\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"eqb_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse Equibase race page.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first(\"td:nth-child(1)\")\n            if not number_node or not number_node.text(strip=True).isdigit():\n                return None\n            number = int(number_node.text(strip=True))\n\n            name_node = node.css_first(\"td:nth-child(3)\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            odds_node = node.css_first(\"td:nth-child(10)\")\n            odds_str = clean_text(odds_node.text()) if odds_node else \"\"\n\n            scratched = \"scratched\" in node.attributes.get(\"class\", \"\").lower()\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError, IndexError):\n            self.logger.warning(\"Could not parse Equibase runner, skipping.\", exc_info=True)\n            return None\n\n    def _parse_post_time(self, date_str: str, time_str: str) -> datetime:\n        \"\"\"Parses a time string like 'Post Time: 12:30 PM ET' into a datetime object.\"\"\"\n        time_part = time_str.split(\" \")[-2] + \" \" + time_str.split(\" \")[-1]\n        dt_str = f\"{date_str} {time_part}\"\n        return datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/horseracingnation_adapter.py": "# python_service/adapters/horseracingnation_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass HorseRacingNationAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for horseracingnation.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"HorseRacingNation\"\n    BASE_URL = \"https://www.horseracingnation.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/adapters/oddschecker_adapter.py": "# python_service/adapters/oddschecker_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass OddscheckerAdapter(BaseAdapterV3):\n    \"\"\"Adapter for scraping horse racing odds from Oddschecker, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"Oddschecker\"\n    BASE_URL = \"https://www.oddschecker.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date. This involves a multi-level fetch.\n        \"\"\"\n        # Note: Oddschecker doesn't seem to support historical dates well in its main nav,\n        # but we build the URL as if it does for future compatibility.\n        index_url = f\"/horse-racing/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Oddschecker index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        # Find all links to individual race pages\n        race_links = {a[\"href\"] for a in index_soup.select(\"a.race-time-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings from different races into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to OddscheckerAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n                race = self._parse_race_page(soup, race_date)\n                if race:\n                    all_races.append(race)\n            except (AttributeError, IndexError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from Oddschecker, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_race_page(self, soup: BeautifulSoup, race_date) -> Optional[Race]:\n        track_name_node = soup.select_one(\"h1.meeting-name\")\n        if not track_name_node:\n            return None\n        track_name = track_name_node.get_text(strip=True)\n\n        race_time_node = soup.select_one(\"span.race-time\")\n        if not race_time_node:\n            return None\n        race_time_str = race_time_node.get_text(strip=True)\n\n        # Heuristic to find race number from navigation\n        active_link = soup.select_one(\"a.race-time-link.active\")\n        race_number = 1\n        if active_link:\n            all_links = soup.select(\"a.race-time-link\")\n            try:\n                race_number = all_links.index(active_link) + 1\n            except ValueError:\n                pass  # Keep default race number if active link not in all links\n\n        start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n        runners = [runner for row in soup.select(\"tr.race-card-row\") if (runner := self._parse_runner_row(row))]\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"oc_{track_name.lower().replace(' ', '')}_{start_time.strftime('%Y%m%d')}_r{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _parse_runner_row(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"span.selection-name\")\n            if not name_node:\n                return None\n            name = name_node.get_text(strip=True)\n\n            odds_node = row.select_one(\"span.bet-button-odds-desktop, span.best-price\")\n            if not odds_node:\n                return None\n            odds_str = odds_node.get_text(strip=True)\n\n            number_node = row.select_one(\"td.runner-number\")\n            if not number_node or not number_node.get_text(strip=True).isdigit():\n                return None\n            number = int(number_node.get_text(strip=True))\n\n            if not name or not odds_str:\n                return None\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_dict = {}\n            if win_odds and win_odds < 999:\n                odds_dict[self.source_name] = OddsData(\n                    win=win_odds, source=self.source_name, last_updated=datetime.now()\n                )\n\n            return Runner(number=number, name=name, odds=odds_dict)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on Oddschecker, skipping runner.\")\n            return None\n",
    "python_service/adapters/punters_adapter.py": "# python_service/adapters/punters_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass PuntersAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for punters.com.au.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"Punters\"\n    BASE_URL = \"https://www.punters.com.au\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/api.py": "# python_service/api.py\n\nimport asyncio\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom contextlib import asynccontextmanager\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import List\nfrom typing import Optional\n\nimport aiosqlite\nimport structlog\nfrom fastapi import Depends\nfrom fastapi import FastAPI\nfrom fastapi import HTTPException\nfrom fastapi import Query\nfrom fastapi import Request\nfrom fastapi import WebSocket\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom slowapi import Limiter\nfrom slowapi import _rate_limit_exceeded_handler\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi.middleware import SlowAPIMiddleware\nfrom slowapi.util import get_remote_address\nfrom starlette.websockets import WebSocketDisconnect\n\n# --- PyInstaller Explicit Imports ---\nfrom .analyzer import AnalyzerEngine\nfrom .cache_manager import cache_manager\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .engine import OddsEngine\nfrom .health import router as health_router\nfrom .logging_config import configure_logging\nfrom .manual_override_manager import ManualOverrideManager\nfrom .middleware.error_handler import UserFriendlyException\nfrom .middleware.error_handler import user_friendly_exception_handler\nfrom .middleware.error_handler import validation_exception_handler\nfrom .models import AggregatedResponse\nfrom .models import ManualParseRequest\nfrom .models import QualifiedRacesResponse\nfrom .models import Race\nfrom .models import TipsheetRace\nfrom .security import verify_api_key\n\n# ------------------------------------\n\nlog = structlog.get_logger()\n\n# Create a fixed thread pool for blocking calls at the module level\nexecutor = ThreadPoolExecutor(max_workers=1)\n\n\ndef _initialize_heavy_resources_sync(app: FastAPI):\n    \"\"\"\n    This synchronous function contains the blocking I/O and CPU-intensive\n    initialization of the OddsEngine and its ~25 adapters. By isolating it,\n    we can run it in a background thread without stalling the main Uvicorn event loop.\n    \"\"\"\n    log.info(\"Background initialization of heavy resources started.\")\n    try:\n        settings = get_settings()\n\n        # Initialize WebSocket connection manager\n        connection_manager = ConnectionManager()\n\n        # Initialize manual override manager\n        manual_override_manager = ManualOverrideManager()\n\n        # Initialize engine with manual override and WebSocket support\n        engine = OddsEngine(\n            config=settings,\n            manual_override_manager=manual_override_manager,\n            connection_manager=connection_manager,\n        )\n\n        # Store the initialized components on the app state\n        app.state.engine = engine\n        app.state.analyzer_engine = AnalyzerEngine()\n        app.state.manual_override_manager = manual_override_manager\n        app.state.connection_manager = connection_manager\n        log.info(\"Background initialization of heavy resources completed successfully.\")\n    except Exception:\n        log.critical(\"CRITICAL: Background initialization failed.\", exc_info=True)\n        # In a real-world scenario, you might want a more robust way\n        # to signal this failure to the main application.\n        app.state.engine = None\n\n\nclass ConnectionManager:\n    \"\"\"Manages active WebSocket connections.\"\"\"\n\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        log.info(\"WebSocket ConnectionManager initialized.\")\n\n    async def connect(self, websocket: WebSocket):\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        log.info(\"New WebSocket connection established.\")\n\n    def disconnect(self, websocket: WebSocket):\n        self.active_connections.remove(websocket)\n        log.info(\"WebSocket connection closed.\")\n\n    async def broadcast(self, message: dict):\n        \"\"\"Broadcasts a message to all connected clients.\"\"\"\n        if not self.active_connections:\n            return\n\n        log.info(\n            \"Broadcasting message to connected clients\",\n            client_count=len(self.active_connections),\n        )\n        for connection in self.active_connections:\n            try:\n                await connection.send_json(message)\n            except Exception:\n                log.error(\"Error sending message to a WebSocket client.\", exc_info=True)\n\n\n# Lifespan context manager\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    configure_logging()\n    log.info(\"Uvicorn is online, starting lifespan hook.\")\n\n    # 1. Perform lightweight, non-blocking startup tasks\n    settings = get_settings()\n    await cache_manager.connect(settings.REDIS_URL)\n    log.info(\"Fast, non-blocking startup tasks complete (Redis connected).\")\n\n    # 2. Schedule the heavy, synchronous initialization to run in a background thread\n    loop = asyncio.get_event_loop()\n    loop.run_in_executor(executor, _initialize_heavy_resources_sync, app)\n    log.info(\"Heavy resource initialization has been scheduled in a background thread.\")\n\n    # 3. Wait for the engine to be initialized before yielding control.\n    start_time = time.time()\n    while not hasattr(app.state, \"engine\") or app.state.engine is None:\n        if time.time() - start_time > 30:  # 30-second timeout\n            raise RuntimeError(\"Engine initialization timed out.\")\n        await asyncio.sleep(0.1)\n\n    log.info(\"Engine is initialized. Server is ready to accept requests.\")\n    yield\n\n    # --- Shutdown Sequence ---\n    log.info(\"Server shutdown sequence initiated.\")\n    if hasattr(app.state, \"engine\") and app.state.engine:\n        log.info(\"Closing HTTP client resources.\")\n        await app.state.engine.close()\n\n    await cache_manager.disconnect()\n    executor.shutdown(wait=False)\n    log.info(\"Server shutdown sequence complete.\")\n\n\nlimiter = Limiter(key_func=get_remote_address)\napp = FastAPI(\n    title=\"Fortuna Faucet API\",\n    version=\"2.1\",\n    lifespan=lifespan,\n    docs_url=\"/api/docs\",\n    redoc_url=\"/api/redoc\",\n    openapi_url=\"/api/openapi.json\",\n)\n\napp.add_middleware(SlowAPIMiddleware)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\napp.add_exception_handler(RequestValidationError, validation_exception_handler)\napp.add_exception_handler(UserFriendlyException, user_friendly_exception_handler)\napp.include_router(health_router)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\", \"http://localhost:3001\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\"],\n    allow_headers=[\"*\"],\n)\n\n\ndef get_engine(request: Request) -> OddsEngine:\n    return request.app.state.engine\n\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"ok\", \"timestamp\": datetime.now().isoformat()}\n\n\n@app.get(\"/api/adapters/status\")\n@limiter.limit(\"60/minute\")\nasync def get_all_adapter_statuses(\n    request: Request,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        return engine.get_all_adapter_statuses()\n    except Exception:\n        log.error(\"Error in /api/adapters/status\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@app.get(\"/api/races/qualified/{analyzer_name}\", response_model=QualifiedRacesResponse)\n@limiter.limit(\"120/minute\")\nasync def get_qualified_races(\n    analyzer_name: str,\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n    max_field_size: int = Query(10, ge=3, le=20),\n    min_favorite_odds: float = Query(2.5, ge=1.0, le=100.0),\n    min_second_favorite_odds: float = Query(4.0, ge=1.0, le=100.0),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        aggregated_data = await engine.fetch_all_odds(date_str)\n        races = [Race(**r) for r in aggregated_data.get(\"races\", [])]\n        analyzer_engine = request.app.state.analyzer_engine\n        custom_params = {\n            \"max_field_size\": max_field_size,\n            \"min_favorite_odds\": min_favorite_odds,\n            \"min_second_favorite_odds\": min_second_favorite_odds,\n        }\n        analyzer = analyzer_engine.get_analyzer(analyzer_name, **custom_params)\n        result = analyzer.qualify_races(races)\n        return QualifiedRacesResponse(**result)\n    except ValueError as e:\n        log.warning(\"Requested analyzer not found\", analyzer_name=analyzer_name)\n        raise HTTPException(status_code=404, detail=str(e))\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(\"Error in /api/races/qualified\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\n@app.get(\"/api/races/filter-suggestions\")\nasync def get_filter_suggestions(engine: OddsEngine = Depends(get_engine)):\n    try:\n        date_str = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n        aggregated = await engine.fetch_all_odds(date_str)\n        if not aggregated or not aggregated.get(\"races\"):\n            return {\"suggestions\": {}}\n        field_sizes = [len(r[\"runners\"]) for r in aggregated[\"races\"]]\n        favorite_odds, second_favorite_odds = [], []\n        for race_data in aggregated[\"races\"]:\n            race = Race(**race_data)\n            runners = race.runners\n            if len(runners) >= 2:\n                odds_list = []\n                for runner in runners:\n                    if not runner.scratched and runner.odds:\n                        best_odd = min(\n                            (o.win for o in runner.odds.values() if o.win is not None),\n                            default=None,\n                        )\n                        if best_odd is not None:\n                            odds_list.append(float(best_odd))\n                if len(odds_list) >= 2:\n                    odds_list.sort()\n                    favorite_odds.append(odds_list[0])\n                    second_favorite_odds.append(odds_list[1])\n        return {\n            \"suggestions\": {\n                \"max_field_size\": {\"recommended\": (int(sum(field_sizes) / len(field_sizes)) if field_sizes else 10)},\n                \"min_favorite_odds\": {\"recommended\": 2.5},\n                \"min_second_favorite_odds\": {\"recommended\": 4.0},\n            }\n        }\n    except Exception:\n        log.error(\"Error generating filter suggestions\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Failed to generate suggestions\")\n\n\n@app.get(\"/api/races/source/{source_name}\", response_model=AggregatedResponse)\n@limiter.limit(\"60/minute\")\nasync def get_races_by_source(\n    source_name: str,\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        return await engine.fetch_all_odds(date_str, source=source_name)\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(f\"Error in /api/races/source/{source_name}\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\n@app.get(\"/api/races\", response_model=AggregatedResponse)\n@limiter.limit(\"30/minute\")\nasync def get_races(\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    source: Optional[str] = None,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        return await engine.fetch_all_odds(date_str, source)\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(\"Error in /api/races\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\nDB_PATH = \"fortuna.db\"\n\n\ndef get_current_date() -> date:\n    return datetime.now().date()\n\n\n@app.get(\"/api/tipsheet\", response_model=List[TipsheetRace])\n@limiter.limit(\"30/minute\")\nasync def get_tipsheet_endpoint(request: Request, date: date = Depends(get_current_date)):\n    results = []\n    try:\n        async with aiosqlite.connect(DB_PATH) as db:\n            db.row_factory = aiosqlite.Row\n            query = \"SELECT * FROM tipsheet WHERE date(post_time) = ? ORDER BY post_time ASC\"\n            async with db.execute(query, (date.isoformat(),)) as cursor:\n                async for row in cursor:\n                    results.append(dict(row))\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return results\n\n\n# API Models\nclass ManualDataSubmission(BaseModel):\n    request_id: str\n    content: str\n    content_type: str = \"html\"\n\n\n# New endpoints\n@app.get(\"/api/manual-overrides/pending\")\n@limiter.limit(\"60/minute\")\nasync def get_pending_overrides(\n    request: Request,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Get all pending manual override requests\"\"\"\n    pending = manager.get_pending_requests()\n    return {\"pending_requests\": [req.model_dump() for req in pending]}\n\n\n@app.post(\"/api/manual-overrides/submit\")\n@limiter.limit(\"30/minute\")\nasync def submit_manual_data(\n    request: Request,\n    submission: ManualDataSubmission,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Submit manually-provided data for a failed fetch\"\"\"\n    success = manager.submit_manual_data(\n        request_id=submission.request_id,\n        raw_content=submission.content,\n        content_type=submission.content_type,\n    )\n\n    if success:\n        return {\"status\": \"success\", \"message\": \"Manual data submitted\"}\n    else:\n        raise HTTPException(status_code=404, detail=\"Request not found\")\n\n\n@app.post(\"/api/manual-overrides/skip/{request_id}\")\n@limiter.limit(\"60/minute\")\nasync def skip_manual_override(\n    request: Request,\n    request_id: str,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Skip a manual override request\"\"\"\n    success = manager.skip_request(request_id)\n\n    if success:\n        return {\"status\": \"success\", \"message\": \"Request skipped\"}\n    else:\n        raise HTTPException(status_code=404, detail=\"Request not found\")\n\n\n@app.post(\"/api/manual-overrides/cleanup\")\n@limiter.limit(\"60/minute\")\nasync def cleanup_old_overrides(\n    request: Request,\n    max_age_hours: int = 24,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Clean up old manual override requests\"\"\"\n    manager.clear_old_requests(max_age_hours)\n    return {\"status\": \"success\", \"message\": \"Old requests cleaned\"}\n\n\n@app.websocket(\"/ws/live-updates\")\nasync def websocket_endpoint(websocket: WebSocket, api_key: str = Query(...)):\n    \"\"\"WebSocket endpoint for live race updates.\"\"\"\n    try:\n        # Use the existing API key verification logic\n        # This is a synchronous call, which is fine for auth at the start.\n        # In a real-world scenario with high connection rates, you might\n        # want to make this check asynchronous if it involved I/O.\n        verify_api_key(api_key)\n    except HTTPException as e:\n        log.warning(\"WebSocket connection rejected due to invalid API key.\")\n        await websocket.close(code=4001, reason=f\"Authentication failed: {e.detail}\")\n        return\n\n    manager = websocket.app.state.connection_manager\n    await manager.connect(websocket)\n    try:\n        # Keep the connection alive, listening for messages (if any)\n        while True:\n            # You could implement logic here to handle incoming messages if needed\n            # For now, it's just a broadcast-only connection\n            await websocket.receive_text()\n    except WebSocketDisconnect:\n        manager.disconnect(websocket)\n        log.info(\"Client disconnected from WebSocket.\")\n\n\n@app.post(\"/api/races/parse-manual\", response_model=List[Race])\n@limiter.limit(\"30/minute\")\nasync def parse_manual_html(\n    request: Request,\n    parse_request: ManualParseRequest,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    \"\"\"\n    Manually parses a block of HTML using a specified adapter.\n    \"\"\"\n    try:\n        adapter = engine.get_adapter(parse_request.adapter_name)\n        if not adapter:\n            raise HTTPException(\n                status_code=404,\n                detail=f\"Adapter '{parse_request.adapter_name}' not found.\",\n            )\n\n        # The _parse_races method is synchronous, so we run it in a thread\n        # to avoid blocking the asyncio event loop.\n        loop = asyncio.get_event_loop()\n        parsed_races_data = await loop.run_in_executor(executor, adapter._parse_races, parse_request.html_content)\n\n        # Validate the parsed data with the Race model\n        validated_races = [Race(**race_data) for race_data in parsed_races_data]\n        return validated_races\n\n    except Exception as e:\n        log.error(\"Error during manual parsing\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n",
    "python_service/credentials_manager.py": "# python_service/credentials_manager.py\ntry:\n    import keyring\n\n    # This check is crucial for cross-platform compatibility\n    import keyring.backends.windows\n\n    IS_WINDOWS = True\nexcept ImportError:\n    keyring = None\n    IS_WINDOWS = False\n\n\nclass SecureCredentialsManager:\n    \"\"\"Manages secrets in the system's native credential store.\"\"\"\n\n    SERVICE_NAME = \"Fortuna\"\n\n    @staticmethod\n    def save_credential(account: str, secret: str) -> bool:\n        \"\"\"Saves a secret for a given account (e.g., 'api_key', 'betfair_username').\"\"\"\n        if not IS_WINDOWS:\n            print(\"Credential storage is only supported on Windows.\")\n            return False\n        try:\n            keyring.set_password(SecureCredentialsManager.SERVICE_NAME, account, secret)\n            return True\n        except Exception as e:\n            print(f\"\u274c Failed to save credential for {account}: {e}\")\n            return False\n\n    @staticmethod\n    def get_credential(account: str) -> str:\n        \"\"\"Retrieves a secret for a given account.\"\"\"\n        if not IS_WINDOWS:\n            return None\n        try:\n            return keyring.get_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception as e:\n            print(f\"\u274c Failed to retrieve credential for {account}: {e}\")\n            return None\n\n    @staticmethod\n    def get_betfair_credentials() -> tuple[str, str]:\n        \"\"\"Convenience method to retrieve both Betfair username and password.\"\"\"\n        username = SecureCredentialsManager.get_credential(\"betfair_username\")\n        password = SecureCredentialsManager.get_credential(\"betfair_password\")\n        return username, password\n\n    @staticmethod\n    def delete_credential(account: str):\n        \"\"\"Deletes a specific credential.\"\"\"\n        if not IS_WINDOWS:\n            return\n        try:\n            keyring.delete_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception:\n            pass\n",
    "python_service/engine.py": "# python_service/engine.py\n\nimport asyncio\nimport json\nfrom copy import deepcopy\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Tuple\n\nimport httpx\nimport redis\nimport redis.asyncio as redis_async\nimport structlog\nfrom pydantic import ValidationError\n\nfrom .adapters.at_the_races_adapter import AtTheRacesAdapter\nfrom .adapters.base_adapter_v3 import BaseAdapterV3\nfrom .adapters.betfair_adapter import BetfairAdapter\n\n# from .adapters.betfair_datascientist_adapter import BetfairDataScientistAdapter\nfrom .adapters.betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .adapters.brisnet_adapter import BrisnetAdapter\nfrom .adapters.drf_adapter import DRFAdapter\nfrom .adapters.equibase_adapter import EquibaseAdapter\nfrom .adapters.fanduel_adapter import FanDuelAdapter\nfrom .adapters.gbgb_api_adapter import GbgbApiAdapter\nfrom .adapters.greyhound_adapter import GreyhoundAdapter\nfrom .adapters.harness_adapter import HarnessAdapter\nfrom .adapters.horseracingnation_adapter import HorseRacingNationAdapter\nfrom .adapters.nyrabets_adapter import NYRABetsAdapter\nfrom .adapters.oddschecker_adapter import OddscheckerAdapter\nfrom .adapters.pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .adapters.punters_adapter import PuntersAdapter\nfrom .adapters.racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .adapters.racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .adapters.racingpost_adapter import RacingPostAdapter\nfrom .adapters.racingtv_adapter import RacingTVAdapter\nfrom .adapters.sporting_life_adapter import SportingLifeAdapter\nfrom .adapters.tab_adapter import TabAdapter\nfrom .adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom .adapters.timeform_adapter import TimeformAdapter\nfrom .adapters.tvg_adapter import TVGAdapter\nfrom .adapters.twinspires_adapter import TwinSpiresAdapter\nfrom .adapters.xpressbet_adapter import XpressbetAdapter\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .manual_override_manager import ManualOverrideManager\nfrom .models import AggregatedResponse\nfrom .models import Race\n\nlog = structlog.get_logger(__name__)\n\n\nclass OddsEngine:\n    def __init__(\n        self,\n        config=None,\n        manual_override_manager: ManualOverrideManager = None,\n        connection_manager=None,\n    ):\n        # THE FIX: Import the cache_manager singleton here to ensure tests can\n        # patch and reload it *before* the engine is initialized.\n        from .cache_manager import cache_manager\n\n        self.logger = structlog.get_logger(__name__)\n        self.logger.info(\"Initializing FortunaEngine...\")\n        self.connection_manager = connection_manager\n        self.cache_manager = cache_manager\n\n        try:\n            try:\n                self.config = config or get_settings()\n                self.logger.info(\"Configuration loaded.\")\n            except ValidationError as e:\n                self.logger.warning(\n                    \"Could not load settings, possibly in test environment.\",\n                    error=str(e),\n                )\n                # Create a default/mock config or re-raise if not in a test context\n                from .config import Settings\n\n                self.config = Settings(API_KEY=\"a_secure_test_api_key_that_is_long_enough\")\n\n            # Redis is now handled entirely by the CacheManager.\n\n            self.logger.info(\"Initializing adapters...\")\n            self.adapters: List[BaseAdapterV3] = []\n            adapter_classes = [\n                AtTheRacesAdapter,\n                BetfairAdapter,\n                BetfairGreyhoundAdapter,\n                BrisnetAdapter,\n                DRFAdapter,\n                EquibaseAdapter,\n                FanDuelAdapter,\n                GbgbApiAdapter,\n                GreyhoundAdapter,\n                HarnessAdapter,\n                HorseRacingNationAdapter,\n                NYRABetsAdapter,\n                OddscheckerAdapter,\n                PuntersAdapter,\n                RacingAndSportsAdapter,\n                RacingAndSportsGreyhoundAdapter,\n                RacingPostAdapter,\n                RacingTVAdapter,\n                SportingLifeAdapter,\n                TabAdapter,\n                TheRacingApiAdapter,\n                TimeformAdapter,\n                TwinSpiresAdapter,\n                TVGAdapter,\n                XpressbetAdapter,\n                PointsBetGreyhoundAdapter,\n            ]\n\n            for adapter_cls in adapter_classes:\n                try:\n                    adapter_instance = adapter_cls(config=self.config)\n                    if manual_override_manager and getattr(adapter_instance, \"supports_manual_override\", False):\n                        adapter_instance.enable_manual_override(manual_override_manager)\n                    self.adapters.append(adapter_instance)\n                except AdapterConfigError as e:\n                    self.logger.warning(\n                        \"Skipping adapter due to configuration error\",\n                        adapter=adapter_cls.__name__,\n                        error=str(e),\n                    )\n                except Exception:\n                    self.logger.error(\n                        f\"An unexpected error occurred while initializing {adapter_cls.__name__}\",\n                        exc_info=True,\n                    )\n\n            # Special case for BetfairDataScientistAdapter with extra args - DISABLED\n            # try:\n            #     bds_adapter = BetfairDataScientistAdapter(\n            #         model_name=\"ThoroughbredModel\",\n            #         url=\"https://betfair-data-supplier-prod.herokuapp.com/api/widgets/kvs-ratings/datasets\",\n            #         config=self.config,\n            #     )\n            #     if manual_override_manager and getattr(bds_adapter, \"supports_manual_override\", False):\n            #         bds_adapter.enable_manual_override(manual_override_manager)\n            #     self.adapters.append(bds_adapter)\n            # except Exception:\n            #     self.logger.warning(\n            #         \"Failed to initialize adapter: BetfairDataScientistAdapter\",\n            #         exc_info=True,\n            #     )\n\n            self.logger.info(f\"{len(self.adapters)} adapters initialized successfully.\")\n\n            self.logger.info(\"Initializing HTTP client...\")\n            self.http_limits = httpx.Limits(\n                max_connections=self.config.HTTP_POOL_CONNECTIONS,\n                max_keepalive_connections=self.config.HTTP_MAX_KEEPALIVE,\n            )\n            self.http_client = httpx.AsyncClient(limits=self.http_limits, http2=True)\n            self.logger.info(\"HTTP client initialized.\")\n\n            # Assign the shared client to each adapter\n            for adapter in self.adapters:\n                adapter.http_client = self.http_client\n\n            # Initialize semaphore for concurrency limiting\n            self.semaphore = asyncio.Semaphore(self.config.MAX_CONCURRENT_REQUESTS)\n            self.logger.info(\n                \"Concurrency semaphore initialized\",\n                limit=self.config.MAX_CONCURRENT_REQUESTS,\n            )\n\n            self.logger.info(\"FortunaEngine initialization complete.\")\n\n        except Exception:\n            self.logger.critical(\"CRITICAL FAILURE during FortunaEngine initialization.\", exc_info=True)\n            raise\n\n    async def close(self):\n        await self.http_client.aclose()\n\n    def get_all_adapter_statuses(self) -> List[Dict[str, Any]]:\n        return [adapter.get_status() for adapter in self.adapters]\n\n    async def get_from_cache(self, key):\n        return await self.cache_manager.get(key)\n\n    async def set_in_cache(self, key, value, ttl=300):\n        # THE FIX: The keyword argument is 'ttl_seconds', not 'ttl'.\n        await self.cache_manager.set(key, value, ttl_seconds=ttl)\n\n    async def _fetch_with_semaphore(self, adapter: BaseAdapterV3, date: str):\n        \"\"\"Acquires the semaphore before fetching data from an adapter.\"\"\"\n        async with self.semaphore:\n            return await self._time_adapter_fetch(adapter, date)\n\n    async def _time_adapter_fetch(self, adapter: BaseAdapterV3, date: str) -> Tuple[str, Dict[str, Any], float]:\n        \"\"\"\n        Wraps a V3 adapter's fetch call for safe, non-blocking execution,\n        and returns a consistent payload with timing information.\n        \"\"\"\n        start_time = datetime.now()\n        races: List[Race] = []\n        error_message = None\n        is_success = False\n        attempted_url = None\n\n        try:\n            race_data_list = await adapter.get_races(date)\n            races = [Race(**race_data) for race_data in race_data_list]\n            is_success = True\n        except AdapterHttpError as e:\n            self.logger.error(\n                \"HTTP failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                status_code=e.status_code,\n                url=e.url,\n                exc_info=False,\n            )\n            error_message = f\"HTTP Error {e.status_code} for {e.url}\"\n            attempted_url = e.url\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n        except Exception as e:\n            self.logger.error(\n                \"Critical failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                error=str(e),\n                exc_info=True,\n            )\n            error_message = str(e)\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n\n        duration = (datetime.now() - start_time).total_seconds()\n\n        payload = {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": adapter.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": duration,\n                \"attempted_url\": attempted_url,\n            },\n        }\n        return (adapter.source_name, payload, duration)\n\n    def _race_key(self, race: Race) -> str:\n        return f\"{race.venue.lower().strip()}|{race.race_number}|{race.start_time.strftime('%H:%M')}\"\n\n    def _dedupe_races(self, races: List[Race]) -> List[Race]:\n        \"\"\"Deduplicates races and reconciles odds from different sources.\"\"\"\n        races_copy = deepcopy(races)\n        race_map: Dict[str, Race] = {}\n        for race in races_copy:\n            key = self._race_key(race)\n            if key not in race_map:\n                race_map[key] = race\n            else:\n                existing_race = race_map[key]\n                runner_map = {r.number: r for r in existing_race.runners}\n                for new_runner in race.runners:\n                    if new_runner.number in runner_map:\n                        existing_runner = runner_map[new_runner.number]\n                        existing_runner.odds.update(new_runner.odds)\n                    else:\n                        existing_race.runners.append(new_runner)\n                existing_race.source += f\", {race.source}\"\n\n        return list(race_map.values())\n\n    async def _broadcast_update(self, data: Dict[str, Any]):\n        \"\"\"Helper to broadcast data if the connection manager is available.\"\"\"\n        if self.connection_manager:\n            await self.connection_manager.broadcast(data)\n\n    async def fetch_all_odds(self, date: str, source_filter: str = None) -> Dict[str, Any]:\n        \"\"\"\n        Fetches and aggregates race data from all configured adapters.\n        The result of this method is cached and broadcasted via WebSocket.\n        \"\"\"\n        # Construct a cache key\n        cache_key = f\"fortuna_engine_races:{date}:{source_filter or 'all'}\"\n        cached_data = await self.get_from_cache(cache_key)\n        if cached_data:\n            log.info(\"Cache hit for fetch_all_odds\", key=cache_key)\n            return json.loads(cached_data)\n\n        log.info(\"Cache miss for fetch_all_odds\", key=cache_key)\n        target_adapters = self.adapters\n        if source_filter:\n            log.info(\"Applying source filter\", source=source_filter)\n            target_adapters = [a for a in self.adapters if a.source_name.lower() == source_filter.lower()]\n\n        tasks = [self._fetch_with_semaphore(adapter, date) for adapter in target_adapters]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        source_infos = []\n        all_races = []\n\n        for result in results:\n            if isinstance(result, Exception):\n                log.error(\"Adapter fetch task failed\", error=result, exc_info=False)\n                continue\n\n            _adapter_name, adapter_result, _duration = result\n            source_info = adapter_result.get(\"source_info\", {})\n            source_infos.append(source_info)\n            if source_info.get(\"status\") == \"SUCCESS\":\n                all_races.extend(adapter_result.get(\"races\", []))\n\n        deduped_races = self._dedupe_races(all_races)\n\n        response_obj = AggregatedResponse(\n            date=datetime.strptime(date, \"%Y-%m-%d\").date(),\n            races=deduped_races,\n            source_info=source_infos,\n            metadata={\n                \"fetch_time\": datetime.now(),\n                \"sources_queried\": [a.source_name for a in target_adapters],\n                \"sources_successful\": len([s for s in source_infos if s[\"status\"] == \"SUCCESS\"]),\n                \"total_races\": len(deduped_races),\n            },\n        )\n\n        response_data = response_obj.model_dump(by_alias=True)\n\n        # Set the result in the cache\n        await self.set_in_cache(cache_key, json.dumps(response_data, default=str), ttl=300)\n        await self._broadcast_update(response_data)\n        return response_data\n",
    "python_service/etl.py": "# python_service/etl.py\n# ETL pipeline for populating the historical data warehouse\n\nimport json\nimport logging\nimport os\nfrom datetime import date\n\nimport requests\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import text\nfrom sqlalchemy.exc import SQLAlchemyError\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass ScribesArchivesETL:\n    def __init__(self):\n        self.postgres_url = os.getenv(\"POSTGRES_URL\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.api_base_url = \"http://localhost:8000\"\n        self.engine = self._get_db_engine()\n\n    def _get_db_engine(self):\n        if not self.postgres_url:\n            logger.warning(\"POSTGRES_URL not set. ETL will be skipped.\")\n            return None\n        try:\n            return create_engine(self.postgres_url)\n        except Exception as e:\n            logger.error(f\"Failed to create database engine: {e}\", exc_info=True)\n            return None\n\n    def _fetch_race_data(self, target_date: date) -> list:\n        \"\"\"Fetches aggregated race data from the local API.\"\"\"\n        if not self.api_key:\n            raise ValueError(\"API_KEY not found in environment.\")\n\n        url = f\"{self.api_base_url}/api/races?race_date={target_date.isoformat()}\"\n        headers = {\"X-API-KEY\": self.api_key}\n        response = requests.get(url, headers=headers, timeout=120)\n        response.raise_for_status()\n        return response.json().get(\"races\", [])\n\n    def _validate_and_transform(self, race: dict) -> tuple:\n        \"\"\"Validates a race dictionary and transforms it for insertion.\"\"\"\n        if not all(k in race for k in [\"id\", \"venue\", \"race_number\", \"start_time\", \"runners\"]):\n            return (\n                None,\n                \"Missing core fields (id, venue, race_number, start_time, runners)\",\n            )\n\n        active_runners = [r for r in race.get(\"runners\", []) if not r.get(\"scratched\")]\n\n        transformed = {\n            \"race_id\": race[\"id\"],\n            \"venue\": race[\"venue\"],\n            \"race_number\": race[\"race_number\"],\n            \"start_time\": race[\"start_time\"],\n            \"source\": race.get(\"source\"),\n            \"qualification_score\": race.get(\"qualification_score\"),\n            \"field_size\": len(active_runners),\n        }\n        return transformed, None\n\n    def run(self, target_date: date):\n        if not self.engine:\n            return\n\n        logger.info(f\"Starting ETL process for {target_date.isoformat()}...\")\n        try:\n            races = self._fetch_race_data(target_date)\n        except (requests.RequestException, ValueError) as e:\n            logger.error(f\"Failed to fetch race data: {e}\", exc_info=True)\n            return\n\n        clean_records = []\n        quarantined_records = []\n\n        for race in races:\n            transformed, reason = self._validate_and_transform(race)\n            if transformed:\n                clean_records.append(transformed)\n            else:\n                quarantined_records.append(\n                    {\n                        \"race_id\": race.get(\"id\"),\n                        \"source\": race.get(\"source\"),\n                        \"payload\": json.dumps(race),\n                        \"reason\": reason,\n                    }\n                )\n\n        with self.engine.connect() as connection:\n            try:\n                with connection.begin():  # Transaction block\n                    if clean_records:\n                        # Using ON CONFLICT to prevent duplicates\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO historical_races (\n                                race_id, venue, race_number, start_time, source,\n                                qualification_score, field_size\n                            )\n                            VALUES (\n                                :race_id, :venue, :race_number, :start_time, :source,\n                                :qualification_score, :field_size\n                            )\n                            ON CONFLICT (race_id) DO NOTHING;\n                        \"\"\"\n                        )\n                        connection.execute(stmt, clean_records)\n                        logger.info(f\"Inserted/updated {len(clean_records)} records into historical_races.\")\n\n                    if quarantined_records:\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO quarantined_races (race_id, source, payload, reason)\n                            VALUES (:race_id, :source, :payload::jsonb, :reason);\n                        \"\"\"\n                        )\n                        connection.execute(stmt, quarantined_records)\n                        logger.warning(f\"Moved {len(quarantined_records)} records to quarantine.\")\n            except SQLAlchemyError as e:\n                logger.error(f\"Database transaction failed: {e}\", exc_info=True)\n\n        logger.info(\"ETL process finished.\")\n\n\ndef run_etl_for_yesterday():\n    from datetime import timedelta\n\n    yesterday = date.today() - timedelta(days=1)\n    etl = ScribesArchivesETL()\n    etl.run(yesterday)\n",
    "python_service/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "python_service/health.py": "# python_service/health.py\nfrom datetime import datetime\nfrom typing import Dict\nfrom typing import List\n\nimport psutil\nimport structlog\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\nlog = structlog.get_logger(__name__)\n\n\nclass HealthMonitor:\n    def __init__(self):\n        self.adapter_health: Dict[str, Dict] = {}\n        self.system_metrics: List[Dict] = []\n        self.max_metrics_history = 100\n\n    def record_adapter_response(self, adapter_name: str, success: bool, duration: float):\n        if adapter_name not in self.adapter_health:\n            self.adapter_health[adapter_name] = {\n                \"total_requests\": 0,\n                \"successful_requests\": 0,\n                \"failed_requests\": 0,\n                \"avg_response_time\": 0.0,\n                \"last_success\": None,\n                \"last_failure\": None,\n            }\n\n        health = self.adapter_health[adapter_name]\n        health[\"total_requests\"] += 1\n\n        if success:\n            health[\"successful_requests\"] += 1\n            health[\"last_success\"] = datetime.now().isoformat()\n        else:\n            health[\"failed_requests\"] += 1\n            health[\"last_failure\"] = datetime.now().isoformat()\n\n        health[\"avg_response_time\"] = (\n            health[\"avg_response_time\"] * (health[\"total_requests\"] - 1) + duration\n        ) / health[\"total_requests\"]\n\n    def get_system_metrics(self) -> Dict:\n        cpu_percent = psutil.cpu_percent(interval=1)\n        memory = psutil.virtual_memory()\n        disk = psutil.disk_usage(\"/\")\n\n        metrics = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"cpu_percent\": cpu_percent,\n            \"memory_percent\": memory.percent,\n            \"memory_available_gb\": round(memory.available / (1024**3), 2),\n            \"disk_percent\": disk.percent,\n            \"disk_free_gb\": round(disk.free / (1024**3), 2),\n        }\n\n        self.system_metrics.append(metrics)\n        if len(self.system_metrics) > self.max_metrics_history:\n            self.system_metrics.pop(0)\n\n        return metrics\n\n    def get_health_report(self) -> Dict:\n        system_metrics = self.get_system_metrics()\n        return {\n            \"status\": \"healthy\" if self.is_system_healthy() else \"degraded\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"system\": system_metrics,\n            \"adapters\": self.adapter_health,\n            \"metrics_history\": self.system_metrics[-10:],\n        }\n\n    def is_system_healthy(self) -> bool:\n        if not self.system_metrics:\n            return True\n        latest = self.system_metrics[-1]\n        return latest[\"cpu_percent\"] < 80 and latest[\"memory_percent\"] < 85 and latest[\"disk_percent\"] < 90\n\n\n# Global instance for the application to use\nhealth_monitor = HealthMonitor()\n\n\n@router.get(\"/health/detailed\", tags=[\"Health\"])\nasync def get_detailed_health():\n    \"\"\"Provides a comprehensive health check of the system.\"\"\"\n    return health_monitor.get_health_report()\n\n\n@router.get(\"/health\", tags=[\"Health\"])\nasync def get_basic_health():\n    \"\"\"Provides a basic health check for load balancers and uptime monitoring.\"\"\"\n    return {\"status\": \"ok\", \"timestamp\": datetime.now().isoformat()}\n",
    "python_service/health_check.py": "import socket\nimport sys\n\n\ndef is_port_available(port=8000):\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex((\"127.0.0.1\", port))\n        sock.close()\n        return result != 0\n    except Exception:\n        return False\n\n\nif __name__ == \"__main__\":\n    if not is_port_available(8000):\n        print(\"ERROR: Port 8000 already in use. Kill existing process or use different port.\")\n        sys.exit(1)\n    print(\"Port 8000 available \u2713\")\n",
    "python_service/initialize_db.py": "# python_service/initialize_db.py\nfrom db.init import initialize_database\n\n\ndef main():\n    \"\"\"\n    This script exists solely to initialize the database.\n    It should be called before the main server process is started.\n    \"\"\"\n    print(\"Initializing database...\", flush=True)\n    initialize_database()\n    print(\"Database initialization complete.\", flush=True)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "python_service/models_v3.py": "# python_service/models_v3.py\n# Defines the data structures for the V3 adapter architecture.\n\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import List\n\n\n@dataclass\nclass NormalizedRunner:\n    runner_id: str\n    name: str\n    saddle_cloth: str\n    odds_decimal: float\n\n\n@dataclass\nclass NormalizedRace:\n    race_key: str\n    track_key: str\n    start_time_iso: str\n    race_name: str\n    runners: List[NormalizedRunner] = field(default_factory=list)\n    source_ids: List[str] = field(default_factory=list)\n",
    "python_service/requirements.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=python_service/requirements.txt python_service/requirements.in\n#\naiosqlite==0.21.0\n    # via -r python_service/requirements.in\naltgraph==0.17.4\n    # via pyinstaller\nannotated-doc==0.0.4\n    # via fastapi\nannotated-types==0.7.0\n    # via pydantic\nanyio==4.11.0\n    # via\n    #   httpx\n    #   starlette\nbeautifulsoup4==4.14.2\n    # via -r python_service/requirements.in\nblack==25.11.0\n    # via -r python_service/requirements.in\nbuild==1.3.0\n    # via pip-tools\ncertifi==2025.10.5\n    # via\n    #   -r python_service/requirements.in\n    #   httpcore\n    #   httpx\n    #   requests\ncffi==2.0.0\n    # via cryptography\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.0\n    # via\n    #   black\n    #   pip-tools\n    #   uvicorn\ncryptography==46.0.3\n    # via\n    #   -r python_service/requirements.in\n    #   secretstorage\ndeprecated==1.3.1\n    # via limits\nfastapi==0.121.1\n    # via -r python_service/requirements.in\ngreenlet==3.2.4\n    # via sqlalchemy\nh11==0.16.0\n    # via\n    #   httpcore\n    #   uvicorn\nh2==4.3.0\n    # via httpx\nhpack==4.1.0\n    # via h2\nhttpcore==1.0.9\n    # via httpx\nhttpx[http2]==0.28.1\n    # via -r python_service/requirements.in\nhyperframe==6.1.0\n    # via h2\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njaraco-classes==3.4.0\n    # via keyring\njaraco-context==6.0.1\n    # via keyring\njaraco-functools==4.3.0\n    # via keyring\njeepney==0.9.0\n    # via\n    #   keyring\n    #   secretstorage\nkeyring==25.6.0\n    # via -r python_service/requirements.in\nlimits==5.6.0\n    # via slowapi\nmore-itertools==10.8.0\n    # via\n    #   jaraco-classes\n    #   jaraco-functools\nmypy-extensions==1.1.0\n    # via black\nnumpy==2.3.4\n    # via\n    #   -r python_service/requirements.in\n    #   pandas\n    #   scipy\npackaging==25.0\n    # via\n    #   black\n    #   build\n    #   limits\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\n    #   pytest\npandas==2.3.3\n    # via -r python_service/requirements.in\npathspec==0.12.1\n    # via black\npip-tools==7.5.1\n    # via -r python_service/requirements.in\nplatformdirs==4.5.0\n    # via black\npluggy==1.6.0\n    # via pytest\npsutil==7.1.3\n    # via -r python_service/requirements.in\npsycopg2-binary==2.9.11\n    # via -r python_service/requirements.in\npycparser==2.23\n    # via cffi\npydantic==2.12.4\n    # via\n    #   fastapi\n    #   pydantic-settings\npydantic-core==2.41.5\n    # via pydantic\npydantic-settings==2.12.0\n    # via -r python_service/requirements.in\npygments==2.19.2\n    # via pytest\npyinstaller==6.6.0\n    # via -r python_service/requirements.in\npyinstaller-hooks-contrib==2025.9\n    # via pyinstaller\npyproject-hooks==1.2.0\n    # via\n    #   build\n    #   pip-tools\npytest==9.0.0\n    # via\n    #   -r python_service/requirements.in\n    #   pytest-asyncio\npytest-asyncio==1.3.0\n    # via -r python_service/requirements.in\npython-dateutil==2.9.0.post0\n    # via pandas\npython-dotenv==1.2.1\n    # via pydantic-settings\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==7.0.1\n    # via -r python_service/requirements.in\nrequests==2.32.5\n    # via -r python_service/requirements.in\nscipy==1.16.3\n    # via -r python_service/requirements.in\nsecretstorage==3.4.1\n    # via keyring\nselectolax==0.4.0\n    # via -r python_service/requirements.in\nsix==1.17.0\n    # via python-dateutil\nslowapi==0.1.9\n    # via -r python_service/requirements.in\nsniffio==1.3.1\n    # via anyio\nsoupsieve==2.8\n    # via beautifulsoup4\nsqlalchemy==2.0.44\n    # via -r python_service/requirements.in\nstarlette==0.49.3\n    # via fastapi\nstructlog==25.5.0\n    # via -r python_service/requirements.in\ntenacity==8.5.0\n    # via -r python_service/requirements.in\ntyping-extensions==4.15.0\n    # via\n    #   aiosqlite\n    #   anyio\n    #   beautifulsoup4\n    #   fastapi\n    #   limits\n    #   pydantic\n    #   pydantic-core\n    #   pytest-asyncio\n    #   sqlalchemy\n    #   starlette\n    #   typing-inspection\ntyping-inspection==0.4.2\n    # via\n    #   pydantic\n    #   pydantic-settings\ntzdata==2025.2\n    # via pandas\nurllib3==2.5.0\n    # via\n    #   -r python_service/requirements.in\n    #   requests\nuvicorn==0.30.1\n    # via -r python_service/requirements.in\nwheel==0.45.1\n    # via\n    #   -r python_service/requirements.in\n    #   pip-tools\nwrapt==2.0.1\n    # via deprecated\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools\n",
    "python_service/run_api.py": "# python_service/run_api.py\n\nimport uvicorn\n\n\ndef main():\n    # This entry point is for the packaged application\n    uvicorn.run(\"python_service.api:app\", host=\"127.0.0.1\", port=8000, reload=False)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "python_service/security.py": "# python_service/security.py\n\nimport secrets\n\nfrom fastapi import Depends\nfrom fastapi import HTTPException\nfrom fastapi import Security\nfrom fastapi import status\nfrom fastapi.security import APIKeyHeader\n\nfrom .config import Settings\nfrom .config import get_settings\n\nAPI_KEY_NAME = \"X-API-Key\"\napi_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)\n\n\nasync def verify_api_key(key: str = Security(api_key_header), settings: Settings = Depends(get_settings)):\n    \"\"\"\n    Verifies the provided API key against the one in settings using a\n    timing-attack resistant comparison.\n    \"\"\"\n    if secrets.compare_digest(key, settings.API_KEY):\n        return True\n    else:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Invalid or missing API Key\")\n",
    "python_service/user_friendly_errors.py": "# python_service/user_friendly_errors.py\n\n\"\"\"\nCentralized dictionary for mapping technical exceptions to user-friendly messages.\n\"\"\"\n\nERROR_MAP = {\n    \"AdapterHttpError\": {\n        \"message\": \"A data source is currently unavailable.\",\n        \"suggestion\": (\n            \"This is usually temporary. Please try again in a few minutes. \"\n            \"If the problem persists, the website may be down for maintenance.\"\n        ),\n    },\n    \"AdapterConfigError\": {\n        \"message\": \"A data adapter is misconfigured.\",\n        \"suggestion\": \"Please check that all required API keys and settings are present in your .env file.\",\n    },\n    \"default\": {\n        \"message\": \"An unexpected error occurred.\",\n        \"suggestion\": \"Please check the application logs for more details or contact support.\",\n    },\n}\n",
    "python_service/utils/odds.py": "# Centralized odds parsing utility, created by Operation: The A+ Trifecta\nfrom decimal import Decimal\nfrom decimal import InvalidOperation\nfrom typing import Optional\nfrom typing import Union\n\n\ndef parse_odds_to_decimal(odds: Union[str, int, float, None]) -> Optional[Decimal]:\n    \"\"\"\n    Parse various odds formats to Decimal for precise financial calculations.\n    Handles fractional, decimal, and special cases ('EVS', 'SP', etc.).\n    Returns None for unparseable or invalid values.\n    \"\"\"\n    if odds is None:\n        return None\n\n    if isinstance(odds, (int, float)):\n        return Decimal(str(odds))\n\n    odds_str = str(odds).strip().upper()\n\n    SPECIAL_CASES = {\n        \"EVS\": Decimal(\"2.0\"),\n        \"EVENS\": Decimal(\"2.0\"),\n        \"SP\": None,\n        \"SCRATCHED\": None,\n        \"SCR\": None,\n        \"\": None,\n    }\n\n    if odds_str in SPECIAL_CASES:\n        return SPECIAL_CASES[odds_str]\n\n    if \"/\" in odds_str:\n        try:\n            parts = odds_str.split(\"/\")\n            if len(parts) != 2:\n                return None\n            num, den = map(Decimal, parts)\n            if den <= 0:\n                return None\n            return Decimal(\"1.0\") + (num / den)\n        except (ValueError, InvalidOperation):\n            return None\n\n    try:\n        return Decimal(odds_str)\n    except (ValueError, InvalidOperation):\n        return None\n",
    "python_service/utils/text.py": "# python_service/utils/text.py\n# Centralized text and name normalization utilities\nimport re\nfrom typing import Optional\n\n\ndef clean_text(text: Optional[str]) -> Optional[str]:\n    \"\"\"Strips leading/trailing whitespace and collapses internal whitespace.\"\"\"\n    if not text:\n        return None\n    return \" \".join(text.strip().split())\n\n\ndef normalize_venue_name(name: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Normalizes a UK or Irish racecourse name to a standard format.\n    Handles common abbreviations and variations.\n    \"\"\"\n    if not name:\n        return None\n\n    # Use a temporary variable for matching, but return the properly cased name\n    cleaned_name_upper = clean_text(name).upper()\n\n    VENUE_MAP = {\n        \"ASCOT\": \"Ascot\",\n        \"AYR\": \"Ayr\",\n        \"BANGOR-ON-DEE\": \"Bangor-on-Dee\",\n        \"CATTERICK BRIDGE\": \"Catterick\",\n        \"CHELMSFORD CITY\": \"Chelmsford\",\n        \"EPSOM DOWNS\": \"Epsom\",\n        \"FONTWELL\": \"Fontwell Park\",\n        \"HAYDOCK\": \"Haydock Park\",\n        \"KEMPTON\": \"Kempton Park\",\n        \"LINGFIELD\": \"Lingfield Park\",\n        \"NEWMARKET (ROWLEY)\": \"Newmarket\",\n        \"NEWMARKET (JULY)\": \"Newmarket\",\n        \"SANDOWN\": \"Sandown Park\",\n        \"STRATFORD\": \"Stratford-on-Avon\",\n        \"YARMOUTH\": \"Great Yarmouth\",\n        \"CURRAGH\": \"Curragh\",\n        \"DOWN ROYAL\": \"Down Royal\",\n    }\n\n    # Check primary map first\n    if cleaned_name_upper in VENUE_MAP:\n        return VENUE_MAP[cleaned_name_upper]\n\n    # Handle cases where the key is the desired output but needs to be mapped from a variation\n    # e.g. CHELMSFORD maps to Chelmsford\n    # Title case the cleaned name for a sensible default\n    title_cased_name = clean_text(name).title()\n    if title_cased_name in VENUE_MAP.values():\n        return title_cased_name\n\n    # Return the title-cased cleaned name as a fallback\n    return title_cased_name\n\n\ndef normalize_course_name(name: str) -> str:\n    if not name:\n        return \"\"\n    name = name.lower().strip()\n    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s-]+\", \"_\", name)\n    return name\n",
    "requirements.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=requirements.txt python_service/requirements.in\n#\naiosqlite==0.21.0\n    # via -r python_service/requirements.in\naltgraph==0.17.4\n    # via pyinstaller\nannotated-types==0.7.0\n    # via pydantic\nanyio==3.7.1\n    # via\n    #   fastapi\n    #   httpx\n    #   starlette\nbeautifulsoup4==4.12.2\n    # via -r python_service/requirements.in\nblack==25.11.0\n    # via -r python_service/requirements.in\nbuild==1.3.0\n    # via pip-tools\ncertifi==2025.11.12\n    # via\n    #   -r python_service/requirements.in\n    #   httpcore\n    #   httpx\n    #   requests\ncffi==2.0.0\n    # via cryptography\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.1\n    # via\n    #   black\n    #   pip-tools\n    #   uvicorn\ncryptography==46.0.3\n    # via\n    #   -r python_service/requirements.in\n    #   secretstorage\ndeprecated==1.3.1\n    # via limits\nfastapi==0.104.1\n    # via -r python_service/requirements.in\ngreenlet==3.2.4\n    # via sqlalchemy\nh11==0.16.0\n    # via\n    #   httpcore\n    #   uvicorn\nh2==4.3.0\n    # via httpx\nhpack==4.1.0\n    # via h2\nhttpcore==1.0.9\n    # via httpx\nhttpx[http2]==0.27.0\n    # via -r python_service/requirements.in\nhyperframe==6.1.0\n    # via h2\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njaraco-classes==3.4.0\n    # via keyring\njaraco-context==6.0.1\n    # via keyring\njaraco-functools==4.3.0\n    # via keyring\njeepney==0.9.0\n    # via\n    #   keyring\n    #   secretstorage\nkeyring==25.6.0\n    # via -r python_service/requirements.in\nlimits==5.6.0\n    # via slowapi\nmore-itertools==10.8.0\n    # via\n    #   jaraco-classes\n    #   jaraco-functools\nmypy-extensions==1.1.0\n    # via black\nnumpy==1.26.4\n    # via\n    #   -r python_service/requirements.in\n    #   pandas\n    #   scipy\npackaging==25.0\n    # via\n    #   black\n    #   build\n    #   limits\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\n    #   pytest\npandas==2.1.3\n    # via -r python_service/requirements.in\npathspec==0.12.1\n    # via black\npip-tools==7.5.2\n    # via -r python_service/requirements.in\nplatformdirs==4.5.0\n    # via black\npluggy==1.6.0\n    # via pytest\npsutil==7.1.1\n    # via -r python_service/requirements.in\npsycopg2-binary==2.9.9\n    # via -r python_service/requirements.in\npycparser==2.23\n    # via cffi\npydantic==2.5.2\n    # via\n    #   fastapi\n    #   pydantic-settings\npydantic-core==2.14.5\n    # via pydantic\npydantic-settings==2.1.0\n    # via -r python_service/requirements.in\npyinstaller==6.6.0\n    # via -r python_service/requirements.in\npyinstaller-hooks-contrib==2025.9\n    # via pyinstaller\npyproject-hooks==1.2.0\n    # via\n    #   build\n    #   pip-tools\npytest==8.3.2\n    # via\n    #   -r python_service/requirements.in\n    #   pytest-asyncio\npytest-asyncio==1.2.0\n    # via -r python_service/requirements.in\npython-dateutil==2.9.0.post0\n    # via pandas\npython-dotenv==1.0.0\n    # via pydantic-settings\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==5.0.1\n    # via -r python_service/requirements.in\nrequests==2.32.5\n    # via -r python_service/requirements.in\nscipy==1.16.3\n    # via -r python_service/requirements.in\nsecretstorage==3.4.1\n    # via keyring\nselectolax==0.4.0\n    # via -r python_service/requirements.in\nsix==1.17.0\n    # via python-dateutil\nslowapi==0.1.9\n    # via -r python_service/requirements.in\nsniffio==1.3.1\n    # via\n    #   anyio\n    #   httpx\nsoupsieve==2.8\n    # via beautifulsoup4\nsqlalchemy==2.0.23\n    # via -r python_service/requirements.in\nstarlette==0.27.0\n    # via fastapi\nstructlog==24.1.0\n    # via -r python_service/requirements.in\ntenacity==9.1.2\n    # via -r python_service/requirements.in\ntyping-extensions==4.15.0\n    # via\n    #   aiosqlite\n    #   fastapi\n    #   limits\n    #   pydantic\n    #   pydantic-core\n    #   pytest-asyncio\n    #   sqlalchemy\ntzdata==2025.2\n    # via pandas\nurllib3==2.5.0\n    # via\n    #   -r python_service/requirements.in\n    #   requests\nuvicorn==0.30.1\n    # via -r python_service/requirements.in\nwheel==0.45.1\n    # via\n    #   -r python_service/requirements.in\n    #   pip-tools\nwrapt==2.0.1\n    # via deprecated\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools\n",
    "scripts/audit_rebranding.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Rebranding Audit Script\n# ==============================================================================\n# This script performs a comprehensive, read-only audit of the project to\n# identify all files containing legacy branding terms.\n# ==============================================================================\n\nimport os\n\n# --- CONFIGURATION ---\nTARGET_TERMS = [\"checkmate\", \"solo\"]\nEXCLUDED_DIRS = [\n    \".git\",\n    \".venv\",\n    \"node_modules\",\n    \"build\",\n    \"dist\",\n    \"__pycache__\",\n    \"ReviewableJSON\",\n]\nEXCLUDED_FILES = [\"audit_rebranding.py\", \"REBRANDING_AUDIT.md\"]\nOUTPUT_FILE = \"REBRANDING_AUDIT.md\"\n# -------------------\n\n\ndef search_file_for_terms(file_path, terms):\n    \"\"\"Searches a single file for a list of terms, case-insensitively.\"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            content = f.read().lower()\n            for term in terms:\n                if term in content:\n                    return True\n    except Exception as e:\n        print(f\"[WARNING] Could not read file {file_path}: {e}\")\n    return False\n\n\ndef main():\n    \"\"\"Main orchestrator for the audit.\"\"\"\n    print(\"--- Starting Rebranding Audit ---\")\n    affected_files = []\n    for root, dirs, files in os.walk(\".\", topdown=True):\n        # Exclude specified directories\n        dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS]\n\n        for filename in files:\n            if filename in EXCLUDED_FILES:\n                continue\n\n            file_path = os.path.join(root, filename)\n\n            # Check filename itself\n            if any(term in filename.lower() for term in TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in filename: {file_path}\")\n                continue  # No need to search content if filename matches\n\n            # Check file content\n            if search_file_for_terms(file_path, TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in content: {file_path}\")\n\n    print(f\"\\n--- Audit Complete. Found {len(affected_files)} affected files. ---\")\n\n    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"# Fortuna Faucet: Rebranding Audit Report\\n\\n\")\n        f.write(\"This report lists all files containing legacy branding terms (`checkmate`, `solo`).\\n\\n---\\n\\n\")\n        if affected_files:\n            for file_path in sorted(affected_files):\n                f.write(f\"- `{file_path.replace(os.sep, '/')}`\\n\")\n        else:\n            f.write(\"No files with legacy branding were found.\\n\")\n\n    print(f\"[SUCCESS] Report written to {OUTPUT_FILE}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/install_fortuna_gui.bat": "@echo off\nREM Interactive MSI installation with standard Windows UI\n\ntitle Fortuna Faucet Installation Wizard\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Administrator privileges required\n    echo Please right-click this file and select \"Run as Administrator\"\n    pause\n    exit /b 1\n)\n\nREM Assumes the MSI is in the 'dist' subfolder relative to the project root\nmsiexec.exe /i \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" /L*v \"%TEMP%\\fortuna_install.log\"\n\nif %errorlevel% equ 0 (\n    echo Installation completed successfully!\n    echo Access dashboard at: http://localhost:3000\n) else (\n    echo Installation failed. Log: %TEMP%\\fortuna_install.log\n)\npause",
    "tests/adapters/test_twinspires_adapter.py": "# tests/adapters/test_twinspires_adapter.py\nimport pytest\nfrom python_service.adapters.twinspires_adapter import TwinSpiresAdapter\nfrom python_service.models import Race\n\n# A mock settings object to satisfy the adapter's config dependency\nclass MockSettings:\n    pass\n\n@pytest.fixture\ndef adapter():\n    return TwinSpiresAdapter(config=MockSettings())\n\n@pytest.mark.asyncio\nasync def test_get_races_from_fixture(adapter):\n    \"\"\"\n    Test that the adapter can correctly parse a local HTML fixture.\n    This test validates the end-to-end parsing logic, including runner data,\n    using the offline implementation.\n    \"\"\"\n    # Call the method under test, which is now wired to read from the fixture\n    races = await adapter._get_races_async(date=\"2025-11-12\")\n\n    # Assertions\n    assert isinstance(races, list)\n    assert len(races) == 1\n\n    # Check the race for correct parsing\n    race = races[0]\n    assert race.venue == \"Churchill Downs\"\n    assert race.race_number == 5\n\n    # Check that runners were parsed correctly\n    assert len(race.runners) == 4\n\n    # Verify a specific runner's details\n    runner_1 = next((r for r in race.runners if r.number == 1), None)\n    assert runner_1 is not None\n    assert runner_1.name == \"Braveheart\"\n    assert not runner_1.scratched\n    assert runner_1.odds[\"TwinSpires\"].win == 3.5\n\n    # Verify a scratched runner\n    runner_3 = next((r for r in race.runners if r.number == 3), None)\n    assert runner_3 is not None\n    assert runner_3.name == \"Steady Eddy\"\n    assert runner_3.scratched\n    assert not runner_3.odds\n",
    "tests/analyzers/test_trifecta_analyzer.py": "# Dedicated test suite for the TrifectaAnalyzer, resurrected and expanded.\nfrom datetime import datetime\n\nimport pytest\n\nfrom python_service.analyzer import TrifectaAnalyzer\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\n\n@pytest.fixture\ndef analyzer():\n    return TrifectaAnalyzer()\n\n\n@pytest.fixture\ndef runners():\n    return []\n\n\n@pytest.fixture\ndef create_race(runners):\n    return Race(\n        id=\"test-race\",\n        venue=\"TEST\",\n        race_number=1,\n        start_time=datetime.now(),\n        runners=runners,\n        source=\"test\",\n    )\n\n\ndef test_analyzer_name(analyzer):\n    assert analyzer.name == \"trifecta_analyzer\"\n\n\n# Test cases resurrected from legacy scorer and logic tests\ndef test_qualifies_with_exactly_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is True\n\n\ndef test_qualifies_with_more_than_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds4 = {\"TestOdds\": OddsData(win=Decimal(\"6.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=False),\n        Runner(number=4, name=\"D\", odds=odds4, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is True\n\n\n# New test cases for edge-case hardening\ndef test_rejects_with_fewer_than_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is False\n\n\ndef test_rejects_if_scratched_runners_reduce_field_below_three(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=True),  # Scratched\n    ]\n    assert analyzer.is_race_qualified(create_race) is False\n\n\ndef test_handles_empty_runner_list(analyzer, create_race):\n    race = create_race\n    race.runners = []\n    assert analyzer.is_race_qualified(race) is False\n\n\ndef test_handles_none_race_object(analyzer):\n    assert analyzer.is_race_qualified(None) is False\n",
    "tests/conftest.py": "# tests/conftest.py\nfrom contextlib import asynccontextmanager\nfrom unittest.mock import Mock\nfrom unittest.mock import patch\n\nimport fakeredis.aioredis\nimport httpx\nimport pytest\nimport pytest_asyncio\nfrom fastapi import FastAPI\nfrom fastapi.testclient import TestClient\n\nfrom python_service.api import app\nfrom python_service.api import get_settings\nfrom python_service.config import Settings\nfrom python_service.engine import OddsEngine\nfrom python_service.manual_override_manager import ManualOverrideManager\n\n\ndef get_test_settings():\n    \"\"\"\n    Returns a comprehensive, test-specific Settings object that satisfies all\n    adapter configuration requirements. This prevents AdapterConfigErrors during\n    app startup in a test environment.\n    \"\"\"\n    return Settings(\n        API_KEY=\"a_secure_test_api_key_that_is_long_enough\",\n        THE_RACING_API_KEY=\"test_racing_api_key\",\n        BETFAIR_APP_KEY=\"test_betfair_key\",\n        TVG_API_KEY=\"test_tvg_key\",\n        RACING_AND_SPORTS_TOKEN=\"test_ras_token\",\n        GREYHOUND_API_URL=\"https://api.example.com/greyhound\",\n    )\n\n\n@pytest.fixture(scope=\"function\")\ndef client():\n    \"\"\"\n    A TestClient instance for testing the FastAPI app.\n    This fixture handles the setup and teardown of dependency overrides\n    and a custom, synchronous lifespan for tests.\n    \"\"\"\n\n    @asynccontextmanager\n    async def test_lifespan(app_for_lifespan: FastAPI):\n        \"\"\"A synchronous, test-friendly version of the app's lifespan.\"\"\"\n        settings = get_test_settings()\n        # No background thread needed for tests. Initialize directly.\n        app_for_lifespan.state.engine = OddsEngine(config=settings)\n        app_for_lifespan.state.manual_override_manager = ManualOverrideManager()\n        yield\n        # No shutdown tasks needed for test client\n\n    # Temporarily replace the real lifespan with our test version\n    original_lifespan = app.router.lifespan_context\n    app.router.lifespan_context = test_lifespan\n\n    # Override settings dependency\n    original_get_settings = app.dependency_overrides.get(get_settings)\n    app.dependency_overrides[get_settings] = get_test_settings\n\n    # This patch is critical. It replaces the real Redis connection with a fake one.\n    with patch(\n        \"redis.from_url\", new_callable=lambda: fakeredis.aioredis.FakeRedis.from_url\n    ), patch(\n        \"python_service.credentials_manager.SecureCredentialsManager.get_betfair_credentials\",\n        return_value=(\"test_user\", \"test_pass\"),\n    ):\n        # Create a client that will run our test_lifespan on startup\n        with TestClient(app) as test_client:\n            yield test_client\n\n    # Clean up overrides and restore the original lifespan\n    app.router.lifespan_context = original_lifespan\n    if original_get_settings:\n        app.dependency_overrides[get_settings] = original_get_settings\n    else:\n        app.dependency_overrides.clear()\n\n\n@pytest_asyncio.fixture\nasync def clear_cache():\n    \"\"\"A fixture to ensure the cache is cleared before a test.\"\"\"\n    from python_service.cache_manager import cache_manager\n\n    if cache_manager.is_configured and cache_manager.redis_client:\n        await cache_manager.redis_client.flushdb()\n    cache_manager.memory_cache.clear()\n\n\n@pytest.fixture\ndef mock_httpx_client():\n    \"\"\"Mocks the httpx.AsyncClient for testing adapters.\"\"\"\n    return Mock(spec=httpx.AsyncClient)\n",
    "tests/fixtures/at_the_races_greyhounds.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <title>Racecard</title>\n</head>\n<body>\n    <link rel=\"canonical\" href=\"/racecard/GB/Monmore/2025-10-29/1817/1\" />\n    <h1 class=\"heading-racecard-title\">Monmore | 18:17</h1>\n    <div class=\"table-default__row--card-runner\">\n        <div class=\"table-default__cell\">\n            <span class=\"runner-number__no\">1</span>\n            <div class=\"runner-cloth-name\">\n                <span class=\"runner-cloth-name__name\">Crossfield Larry</span>\n            </div>\n            <button class=\"bet-selector__odds\">5/2</button>\n        </div>\n    </div>\n    <div class=\"table-default__row--card-runner\">\n        <div class=\"table-default__cell\">\n            <span class=\"runner-number__no\">2</span>\n            <div class=\"runner-cloth-name\">\n                <span class=\"runner-cloth-name__name\">Stouke A Star</span>\n            </div>\n            <button class=\"bet-selector__odds\">11/4</button>\n        </div>\n    </div>\n</body>\n</html>\n",
    "tests/test_api.py": "# tests/test_api.py\nfrom datetime import date\nfrom datetime import datetime\nfrom unittest.mock import AsyncMock\nfrom unittest.mock import patch\n\nimport aiosqlite\nimport pytest\n\n# --- Fixtures ---\nfrom python_service.models import AggregatedResponse\n\n# The client fixture is now correctly sourced from conftest.py,\n# which handles the settings override globally.\n\n# --- API Tests ---\n\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine.fetch_all_odds\", new_callable=AsyncMock)\nasync def test_get_races_endpoint_success(mock_fetch_all_odds, client):\n    \"\"\"\n    SPEC: The /api/races endpoint should return data with a valid API key.\n    \"\"\"\n    # ARRANGE\n    today = date.today()\n    mock_response = AggregatedResponse(\n        date=today,\n        races=[],\n        sources=[],\n        metadata={},\n        # This was the missing field causing the validation error\n        source_info=[],\n    )\n    mock_fetch_all_odds.return_value = mock_response.model_dump()\n    headers = {\"X-API-Key\": \"a_secure_test_api_key_that_is_long_enough\"}\n\n    # ACT\n    response = client.get(f\"/api/races?race_date={today.isoformat()}\", headers=headers)\n\n    # ASSERT\n    assert response.status_code == 200\n    mock_fetch_all_odds.assert_awaited_once()\n\n\n@pytest.mark.asyncio\nasync def test_get_tipsheet_endpoint_success(tmp_path, client):\n    \"\"\"\n    SPEC: The /api/tipsheet endpoint should return a list of tipsheet races from the database.\n    \"\"\"\n    db_path = tmp_path / \"test.db\"\n    post_time = datetime.now()\n\n    with patch(\"python_service.api.DB_PATH\", db_path):\n        async with aiosqlite.connect(db_path) as db:\n            await db.execute(\n                \"\"\"\n                CREATE TABLE tipsheet (\n                    race_id TEXT PRIMARY KEY,\n                    track_name TEXT,\n                    race_number INTEGER,\n                    post_time TEXT,\n                    score REAL,\n                    factors TEXT\n                )\n            \"\"\"\n            )\n            await db.execute(\n                \"INSERT INTO tipsheet VALUES (?, ?, ?, ?, ?, ?)\",\n                (\"test_race_1\", \"Test Park\", 1, post_time.isoformat(), 85.5, \"{}\"),\n            )\n            await db.commit()\n\n        # ACT\n        response = client.get(f\"/api/tipsheet?date={post_time.date().isoformat()}\")\n\n        # ASSERT\n        assert response.status_code == 200\n        response_data = response.json()\n        assert len(response_data) == 1\n        # The database returns snake_case, but the Pydantic model is camelCase\n        assert response_data[0][\"raceId\"] == \"test_race_1\"\n        assert response_data[0][\"score\"] == 85.5\n\n\ndef test_health_check_unauthenticated(client):\n    \"\"\"Ensures the /health endpoint is accessible without an API key.\"\"\"\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    json_response = response.json()\n    assert json_response[\"status\"] == \"ok\"\n    assert \"timestamp\" in json_response\n\n\ndef test_api_key_authentication_failure(client):\n    \"\"\"Ensures that endpoints are protected and fail with an invalid API key.\"\"\"\n    response = client.get(\"/api/races/qualified/trifecta\", headers={\"X-API-KEY\": \"invalid_key\"})\n    assert response.status_code == 403\n    assert \"Invalid or missing API Key\" in response.json()[\"detail\"]\n\n\ndef test_api_key_authentication_missing(client):\n    \"\"\"Ensures that endpoints are protected and fail with a missing API key.\"\"\"\n    response = client.get(\"/api/races/qualified/trifecta\")\n    assert response.status_code == 403\n    assert \"Not authenticated\" in response.json()[\"detail\"]\n",
    "tests/test_msi_installation.ps1": "param([string]$MsiPath = \".\\dist\\Fortuna-Faucet-2.1.0-x64.msi\")\n\nWrite-Host \"Testing MSI Installation...\" -ForegroundColor Cyan\n\n# Test 1: File integrity\nWrite-Host \"\u2022 Verifying MSI structure...\"\nif (Test-Path $MsiPath) {\n    Write-Host \"\u2713 MSI file exists\"\n} else {\n    Write-Error \"MSI file not found\"\n    exit 1\n}\n\n# Test 2: Installation\nWrite-Host \"\u2022 Testing interactive installation...\"\n& msiexec.exe /i $MsiPath /l*v \"test_install.log\"\n\n# Test 3: Verify installation\nWrite-Host \"\u2022 Verifying files were installed...\"\n$programFiles = \"$env:PROGRAMFILES\\Fortuna Faucet\"\nif (Test-Path $programFiles) {\n    Write-Host \"\u2713 Installation successful\"\n} else {\n    Write-Error \"Installation failed\"\n    exit 1\n}\n\n# Test 4: Registry entries\nWrite-Host \"\u2022 Checking registry entries...\"\n$regPath = \"HKLM:\\Software\\Fortuna Faucet\"\nif (Test-Path $regPath) {\n    Write-Host \"\u2713 Registry entries found\"\n} else {\n    Write-Error \"Registry entries missing\"\n    exit 1\n}",
    "tests/test_silent_deployment.ps1": "Write-Host \"Testing silent deployment...\" -ForegroundColor Cyan\n\n& msiexec.exe /i \"Fortuna-Faucet-2.1.0-x64.msi\" `\n    /qn /l*v \"silent_test.log\" `\n    ALLUSERS=1 INSTALLSCOPE=perMachine\n\nif ($LASTEXITCODE -eq 0) {\n    Write-Host \"\u2713 Silent deployment successful\"\n} else {\n    Write-Host \"\u2717 Silent deployment failed\"\n    Write-Host \"Log: silent_test.log\"\n    exit 1\n}",
    "web_platform/api_gateway/src/services/DatabaseService.ts": "import sqlite3 from 'sqlite3';\nimport { open, Database } from 'sqlite';\nimport path from 'path';\n\nexport class DatabaseService {\n  private db: Database | null = null;\n\n  private async getDb(): Promise<Database> {\n    if (!this.db) {\n      const dbPath = process.env.FORTUNA_DB_PATH || path.join(process.cwd(), '../../../../shared_database/races.db');\n      this.db = await open({\n        filename: dbPath,\n        driver: sqlite3.Database\n      });\n    }\n    return this.db;\n  }\n\n  async getQualifiedRaces(): Promise<any[]> {\n    const db = await this.getDb();\n    return db.all(`SELECT * FROM qualified_races`);\n  }\n}\n",
    "web_platform/frontend/app/globals.css": "@tailwind base;\n@tailwind components;\n@tailwind utilities;",
    "web_platform/frontend/app/layout.tsx": "// web_platform/frontend/app/layout.tsx\nimport './globals.css';\nimport type { Metadata } from 'next';\nimport { Inter } from 'next/font/google';\nimport Providers from './Providers';\n\nconst inter = Inter({ subsets: ['latin'] });\n\nexport const metadata: Metadata = {\n  title: 'Fortuna',\n  description: 'Real-time horse racing analysis.',\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={`${inter.className} bg-white text-gray-900 dark:bg-gray-900 dark:text-gray-100`}>\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}",
    "web_platform/frontend/app/page.tsx": "'use client';\nimport dynamic from 'next/dynamic';\nimport React from 'react';\nimport { Tabs } from '../src/components/Tabs';\nimport { SettingsPage } from '../src/components/SettingsPage';\n\nconst LiveRaceDashboard = dynamic(\n  () => import('../src/components/LiveRaceDashboard').then((mod) => mod.LiveRaceDashboard),\n  {\n    ssr: false,\n    loading: () => <p className=\"text-center text-xl mt-8\">Loading Dashboard...</p>\n  }\n);\n\nexport default function Home() {\n  const tabs = [\n    {\n      label: 'Dashboard',\n      content: <LiveRaceDashboard />,\n    },\n    {\n      label: 'Settings',\n      content: <SettingsPage />,\n    },\n  ];\n\n  return (\n    <main className=\"min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 p-8\">\n      <div className=\"max-w-7xl mx-auto space-y-8\">\n        <h1 className=\"text-4xl font-bold text-white\">Fortuna Faucet</h1>\n        <Tabs tabs={tabs} />\n      </div>\n    </main>\n  );\n}\n",
    "web_platform/frontend/next-env.d.ts": "/// <reference types=\"next\" />\n/// <reference types=\"next/image-types/global\" />\n\n// NOTE: This file should not be edited\n// see https://nextjs.org/docs/app/building-your-application/configuring/typescript for more information.\n",
    "web_platform/frontend/public/manifest.json": "{\n  \"name\": \"Fortuna Faucet Command Deck\",\n  \"short_name\": \"Fortuna\",\n  \"description\": \"Real-time racing analysis.\",\n  \"start_url\": \"/\",\n  \"display\": \"standalone\",\n  \"background_color\": \"#1a202c\",\n  \"theme_color\": \"#1a202c\",\n  \"icons\": [\n    {\n      \"src\": \"/icons/icon-192x192.png\",\n      \"sizes\": \"192x192\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/icon-512x512.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\"\n    }\n  ]\n}\n",
    "web_platform/frontend/public/sw.js": "if(!self.define){let e,s={};const a=(a,n)=>(a=new URL(a+\".js\",n).href,s[a]||new Promise(s=>{if(\"document\"in self){const e=document.createElement(\"script\");e.src=a,e.onload=s,document.head.appendChild(e)}else e=a,importScripts(a),s()}).then(()=>{let e=s[a];if(!e)throw new Error(`Module ${a} didn\u2019t register its module`);return e}));self.define=(n,t)=>{const i=e||(\"document\"in self?document.currentScript.src:\"\")||location.href;if(s[i])return;let c={};const r=e=>a(e,i),o={module:{uri:i},exports:c,require:r};s[i]=Promise.all(n.map(e=>o[e]||r(e))).then(e=>(t(...e),c))}}define([\"./workbox-4754cb34\"],function(e){\"use strict\";importScripts(),self.skipWaiting(),e.clientsClaim(),e.precacheAndRoute([{url:\"/_next/app-build-manifest.json\",revision:\"b6130f23369e5df052a4061c412f24fa\"},{url:\"/_next/static/YkCCvmjhdkIswKuIgvFNH/_buildManifest.js\",revision:\"c155cce658e53418dec34664328b51ac\"},{url:\"/_next/static/YkCCvmjhdkIswKuIgvFNH/_ssgManifest.js\",revision:\"b6652df95db52feb4daf4eca35380933\"},{url:\"/_next/static/chunks/117-6326cd814d964913.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/816-7254031126ac0a96.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/928.d7f641058b89a54a.js\",revision:\"d7f641058b89a54a\"},{url:\"/_next/static/chunks/app/_not-found/page-e7dc36cd5a340c38.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/app/layout-605479d07717f01e.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/app/page-a2c385e93bfc2dac.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/fd9d1056-af804af0be509bea.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/framework-f66176bb897dc684.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/main-8563e00d234bd632.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/main-app-e0b3e4e952d25145.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/pages/_app-72b849fbd24ac258.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/pages/_error-7ba65e1336b92748.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/polyfills-42372ed130431b0a.js\",revision:\"846118c33b2c0e922d7b3a7676f81f6f\"},{url:\"/_next/static/chunks/webpack-d92cdde7bb2319ca.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/css/a55e4893d0564dbf.css\",revision:\"a55e4893d0564dbf\"},{url:\"/_next/static/media/19cfc7226ec3afaa-s.woff2\",revision:\"9dda5cfc9a46f256d0e131bb535e46f8\"},{url:\"/_next/static/media/21350d82a1f187e9-s.woff2\",revision:\"4e2553027f1d60eff32898367dd4d541\"},{url:\"/_next/static/media/8e9860b6e62d6359-s.woff2\",revision:\"01ba6c2a184b8cba08b0d57167664d75\"},{url:\"/_next/static/media/ba9851c3c22cd980-s.woff2\",revision:\"9e494903d6b0ffec1a1e14d34427d44d\"},{url:\"/_next/static/media/c5fe6dc8356a8c31-s.woff2\",revision:\"027a89e9ab733a145db70f09b8a18b42\"},{url:\"/_next/static/media/df0a9ae256c0569c-s.woff2\",revision:\"d54db44de5ccb18886ece2fda72bdfe0\"},{url:\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",revision:\"65850a373e258f1c897a2b3d75eb74de\"},{url:\"/manifest.json\",revision:\"23bffdb04aba9b85948642cffa772eae\"}],{ignoreURLParametersMatching:[]}),e.cleanupOutdatedCaches(),e.registerRoute(\"/\",new e.NetworkFirst({cacheName:\"start-url\",plugins:[{cacheWillUpdate:async({request:e,response:s,event:a,state:n})=>s&&\"opaqueredirect\"===s.type?new Response(s.body,{status:200,statusText:\"OK\",headers:s.headers}):s}]}),\"GET\"),e.registerRoute(/^https:\\/\\/fonts\\.(?:gstatic)\\.com\\/.*/i,new e.CacheFirst({cacheName:\"google-fonts-webfonts\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:31536e3})]}),\"GET\"),e.registerRoute(/^https:\\/\\/fonts\\.(?:googleapis)\\.com\\/.*/i,new e.StaleWhileRevalidate({cacheName:\"google-fonts-stylesheets\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:604800})]}),\"GET\"),e.registerRoute(/\\.(?:eot|otf|ttc|ttf|woff|woff2|font.css)$/i,new e.StaleWhileRevalidate({cacheName:\"static-font-assets\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:604800})]}),\"GET\"),e.registerRoute(/\\.(?:jpg|jpeg|gif|png|svg|ico|webp)$/i,new e.StaleWhileRevalidate({cacheName:\"static-image-assets\",plugins:[new e.ExpirationPlugin({maxEntries:64,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\/_next\\/image\\?url=.+$/i,new e.StaleWhileRevalidate({cacheName:\"next-image\",plugins:[new e.ExpirationPlugin({maxEntries:64,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:mp3|wav|ogg)$/i,new e.CacheFirst({cacheName:\"static-audio-assets\",plugins:[new e.RangeRequestsPlugin,new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:mp4)$/i,new e.CacheFirst({cacheName:\"static-video-assets\",plugins:[new e.RangeRequestsPlugin,new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:js)$/i,new e.StaleWhileRevalidate({cacheName:\"static-js-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:css|less)$/i,new e.StaleWhileRevalidate({cacheName:\"static-style-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\/_next\\/data\\/.+\\/.+\\.json$/i,new e.StaleWhileRevalidate({cacheName:\"next-data\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:json|xml|csv)$/i,new e.NetworkFirst({cacheName:\"static-data-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>{if(!(self.origin===e.origin))return!1;const s=e.pathname;return!s.startsWith(\"/api/auth/\")&&!!s.startsWith(\"/api/\")},new e.NetworkFirst({cacheName:\"apis\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:16,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>{if(!(self.origin===e.origin))return!1;return!e.pathname.startsWith(\"/api/\")},new e.NetworkFirst({cacheName:\"others\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>!(self.origin===e.origin),new e.NetworkFirst({cacheName:\"cross-origin\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:3600})]}),\"GET\")});\n",
    "web_platform/frontend/public/workbox-4754cb34.js": "define([\"exports\"],function(t){\"use strict\";try{self[\"workbox:core:6.5.4\"]&&_()}catch(t){}const e=(t,...e)=>{let s=t;return e.length>0&&(s+=` :: ${JSON.stringify(e)}`),s};class s extends Error{constructor(t,s){super(e(t,s)),this.name=t,this.details=s}}try{self[\"workbox:routing:6.5.4\"]&&_()}catch(t){}const n=t=>t&&\"object\"==typeof t?t:{handle:t};class r{constructor(t,e,s=\"GET\"){this.handler=n(e),this.match=t,this.method=s}setCatchHandler(t){this.catchHandler=n(t)}}class i extends r{constructor(t,e,s){super(({url:e})=>{const s=t.exec(e.href);if(s&&(e.origin===location.origin||0===s.index))return s.slice(1)},e,s)}}class a{constructor(){this.t=new Map,this.i=new Map}get routes(){return this.t}addFetchListener(){self.addEventListener(\"fetch\",t=>{const{request:e}=t,s=this.handleRequest({request:e,event:t});s&&t.respondWith(s)})}addCacheListener(){self.addEventListener(\"message\",t=>{if(t.data&&\"CACHE_URLS\"===t.data.type){const{payload:e}=t.data,s=Promise.all(e.urlsToCache.map(e=>{\"string\"==typeof e&&(e=[e]);const s=new Request(...e);return this.handleRequest({request:s,event:t})}));t.waitUntil(s),t.ports&&t.ports[0]&&s.then(()=>t.ports[0].postMessage(!0))}})}handleRequest({request:t,event:e}){const s=new URL(t.url,location.href);if(!s.protocol.startsWith(\"http\"))return;const n=s.origin===location.origin,{params:r,route:i}=this.findMatchingRoute({event:e,request:t,sameOrigin:n,url:s});let a=i&&i.handler;const o=t.method;if(!a&&this.i.has(o)&&(a=this.i.get(o)),!a)return;let c;try{c=a.handle({url:s,request:t,event:e,params:r})}catch(t){c=Promise.reject(t)}const h=i&&i.catchHandler;return c instanceof Promise&&(this.o||h)&&(c=c.catch(async n=>{if(h)try{return await h.handle({url:s,request:t,event:e,params:r})}catch(t){t instanceof Error&&(n=t)}if(this.o)return this.o.handle({url:s,request:t,event:e});throw n})),c}findMatchingRoute({url:t,sameOrigin:e,request:s,event:n}){const r=this.t.get(s.method)||[];for(const i of r){let r;const a=i.match({url:t,sameOrigin:e,request:s,event:n});if(a)return r=a,(Array.isArray(r)&&0===r.length||a.constructor===Object&&0===Object.keys(a).length||\"boolean\"==typeof a)&&(r=void 0),{route:i,params:r}}return{}}setDefaultHandler(t,e=\"GET\"){this.i.set(e,n(t))}setCatchHandler(t){this.o=n(t)}registerRoute(t){this.t.has(t.method)||this.t.set(t.method,[]),this.t.get(t.method).push(t)}unregisterRoute(t){if(!this.t.has(t.method))throw new s(\"unregister-route-but-not-found-with-method\",{method:t.method});const e=this.t.get(t.method).indexOf(t);if(!(e>-1))throw new s(\"unregister-route-route-not-registered\");this.t.get(t.method).splice(e,1)}}let o;const c=()=>(o||(o=new a,o.addFetchListener(),o.addCacheListener()),o);function h(t,e,n){let a;if(\"string\"==typeof t){const s=new URL(t,location.href);a=new r(({url:t})=>t.href===s.href,e,n)}else if(t instanceof RegExp)a=new i(t,e,n);else if(\"function\"==typeof t)a=new r(t,e,n);else{if(!(t instanceof r))throw new s(\"unsupported-route-type\",{moduleName:\"workbox-routing\",funcName:\"registerRoute\",paramName:\"capture\"});a=t}return c().registerRoute(a),a}try{self[\"workbox:strategies:6.5.4\"]&&_()}catch(t){}const u={cacheWillUpdate:async({response:t})=>200===t.status||0===t.status?t:null},l={googleAnalytics:\"googleAnalytics\",precache:\"precache-v2\",prefix:\"workbox\",runtime:\"runtime\",suffix:\"undefined\"!=typeof registration?registration.scope:\"\"},f=t=>[l.prefix,t,l.suffix].filter(t=>t&&t.length>0).join(\"-\"),w=t=>t||f(l.precache),d=t=>t||f(l.runtime);function p(t,e){const s=new URL(t);for(const t of e)s.searchParams.delete(t);return s.href}class y{constructor(){this.promise=new Promise((t,e)=>{this.resolve=t,this.reject=e})}}const g=new Set;function m(t){return\"string\"==typeof t?new Request(t):t}class v{constructor(t,e){this.h={},Object.assign(this,e),this.event=e.event,this.u=t,this.l=new y,this.p=[],this.m=[...t.plugins],this.v=new Map;for(const t of this.m)this.v.set(t,{});this.event.waitUntil(this.l.promise)}async fetch(t){const{event:e}=this;let n=m(t);if(\"navigate\"===n.mode&&e instanceof FetchEvent&&e.preloadResponse){const t=await e.preloadResponse;if(t)return t}const r=this.hasCallback(\"fetchDidFail\")?n.clone():null;try{for(const t of this.iterateCallbacks(\"requestWillFetch\"))n=await t({request:n.clone(),event:e})}catch(t){if(t instanceof Error)throw new s(\"plugin-error-request-will-fetch\",{thrownErrorMessage:t.message})}const i=n.clone();try{let t;t=await fetch(n,\"navigate\"===n.mode?void 0:this.u.fetchOptions);for(const s of this.iterateCallbacks(\"fetchDidSucceed\"))t=await s({event:e,request:i,response:t});return t}catch(t){throw r&&await this.runCallbacks(\"fetchDidFail\",{error:t,event:e,originalRequest:r.clone(),request:i.clone()}),t}}async fetchAndCachePut(t){const e=await this.fetch(t),s=e.clone();return this.waitUntil(this.cachePut(t,s)),e}async cacheMatch(t){const e=m(t);let s;const{cacheName:n,matchOptions:r}=this.u,i=await this.getCacheKey(e,\"read\"),a=Object.assign(Object.assign({},r),{cacheName:n});s=await caches.match(i,a);for(const t of this.iterateCallbacks(\"cachedResponseWillBeUsed\"))s=await t({cacheName:n,matchOptions:r,cachedResponse:s,request:i,event:this.event})||void 0;return s}async cachePut(t,e){const n=m(t);var r;await(r=0,new Promise(t=>setTimeout(t,r)));const i=await this.getCacheKey(n,\"write\");if(!e)throw new s(\"cache-put-with-no-response\",{url:(a=i.url,new URL(String(a),location.href).href.replace(new RegExp(`^${location.origin}`),\"\"))});var a;const o=await this.R(e);if(!o)return!1;const{cacheName:c,matchOptions:h}=this.u,u=await self.caches.open(c),l=this.hasCallback(\"cacheDidUpdate\"),f=l?await async function(t,e,s,n){const r=p(e.url,s);if(e.url===r)return t.match(e,n);const i=Object.assign(Object.assign({},n),{ignoreSearch:!0}),a=await t.keys(e,i);for(const e of a)if(r===p(e.url,s))return t.match(e,n)}(u,i.clone(),[\"__WB_REVISION__\"],h):null;try{await u.put(i,l?o.clone():o)}catch(t){if(t instanceof Error)throw\"QuotaExceededError\"===t.name&&await async function(){for(const t of g)await t()}(),t}for(const t of this.iterateCallbacks(\"cacheDidUpdate\"))await t({cacheName:c,oldResponse:f,newResponse:o.clone(),request:i,event:this.event});return!0}async getCacheKey(t,e){const s=`${t.url} | ${e}`;if(!this.h[s]){let n=t;for(const t of this.iterateCallbacks(\"cacheKeyWillBeUsed\"))n=m(await t({mode:e,request:n,event:this.event,params:this.params}));this.h[s]=n}return this.h[s]}hasCallback(t){for(const e of this.u.plugins)if(t in e)return!0;return!1}async runCallbacks(t,e){for(const s of this.iterateCallbacks(t))await s(e)}*iterateCallbacks(t){for(const e of this.u.plugins)if(\"function\"==typeof e[t]){const s=this.v.get(e),n=n=>{const r=Object.assign(Object.assign({},n),{state:s});return e[t](r)};yield n}}waitUntil(t){return this.p.push(t),t}async doneWaiting(){let t;for(;t=this.p.shift();)await t}destroy(){this.l.resolve(null)}async R(t){let e=t,s=!1;for(const t of this.iterateCallbacks(\"cacheWillUpdate\"))if(e=await t({request:this.request,response:e,event:this.event})||void 0,s=!0,!e)break;return s||e&&200!==e.status&&(e=void 0),e}}class R{constructor(t={}){this.cacheName=d(t.cacheName),this.plugins=t.plugins||[],this.fetchOptions=t.fetchOptions,this.matchOptions=t.matchOptions}handle(t){const[e]=this.handleAll(t);return e}handleAll(t){t instanceof FetchEvent&&(t={event:t,request:t.request});const e=t.event,s=\"string\"==typeof t.request?new Request(t.request):t.request,n=\"params\"in t?t.params:void 0,r=new v(this,{event:e,request:s,params:n}),i=this.q(r,s,e);return[i,this.D(i,r,s,e)]}async q(t,e,n){let r;await t.runCallbacks(\"handlerWillStart\",{event:n,request:e});try{if(r=await this.U(e,t),!r||\"error\"===r.type)throw new s(\"no-response\",{url:e.url})}catch(s){if(s instanceof Error)for(const i of t.iterateCallbacks(\"handlerDidError\"))if(r=await i({error:s,event:n,request:e}),r)break;if(!r)throw s}for(const s of t.iterateCallbacks(\"handlerWillRespond\"))r=await s({event:n,request:e,response:r});return r}async D(t,e,s,n){let r,i;try{r=await t}catch(i){}try{await e.runCallbacks(\"handlerDidRespond\",{event:n,request:s,response:r}),await e.doneWaiting()}catch(t){t instanceof Error&&(i=t)}if(await e.runCallbacks(\"handlerDidComplete\",{event:n,request:s,response:r,error:i}),e.destroy(),i)throw i}}function b(t){t.then(()=>{})}function q(){return q=Object.assign?Object.assign.bind():function(t){for(var e=1;e<arguments.length;e++){var s=arguments[e];for(var n in s)({}).hasOwnProperty.call(s,n)&&(t[n]=s[n])}return t},q.apply(null,arguments)}let D,U;const x=new WeakMap,L=new WeakMap,I=new WeakMap,C=new WeakMap,E=new WeakMap;let N={get(t,e,s){if(t instanceof IDBTransaction){if(\"done\"===e)return L.get(t);if(\"objectStoreNames\"===e)return t.objectStoreNames||I.get(t);if(\"store\"===e)return s.objectStoreNames[1]?void 0:s.objectStore(s.objectStoreNames[0])}return k(t[e])},set:(t,e,s)=>(t[e]=s,!0),has:(t,e)=>t instanceof IDBTransaction&&(\"done\"===e||\"store\"===e)||e in t};function O(t){return t!==IDBDatabase.prototype.transaction||\"objectStoreNames\"in IDBTransaction.prototype?(U||(U=[IDBCursor.prototype.advance,IDBCursor.prototype.continue,IDBCursor.prototype.continuePrimaryKey])).includes(t)?function(...e){return t.apply(B(this),e),k(x.get(this))}:function(...e){return k(t.apply(B(this),e))}:function(e,...s){const n=t.call(B(this),e,...s);return I.set(n,e.sort?e.sort():[e]),k(n)}}function T(t){return\"function\"==typeof t?O(t):(t instanceof IDBTransaction&&function(t){if(L.has(t))return;const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"complete\",r),t.removeEventListener(\"error\",i),t.removeEventListener(\"abort\",i)},r=()=>{e(),n()},i=()=>{s(t.error||new DOMException(\"AbortError\",\"AbortError\")),n()};t.addEventListener(\"complete\",r),t.addEventListener(\"error\",i),t.addEventListener(\"abort\",i)});L.set(t,e)}(t),e=t,(D||(D=[IDBDatabase,IDBObjectStore,IDBIndex,IDBCursor,IDBTransaction])).some(t=>e instanceof t)?new Proxy(t,N):t);var e}function k(t){if(t instanceof IDBRequest)return function(t){const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"success\",r),t.removeEventListener(\"error\",i)},r=()=>{e(k(t.result)),n()},i=()=>{s(t.error),n()};t.addEventListener(\"success\",r),t.addEventListener(\"error\",i)});return e.then(e=>{e instanceof IDBCursor&&x.set(e,t)}).catch(()=>{}),E.set(e,t),e}(t);if(C.has(t))return C.get(t);const e=T(t);return e!==t&&(C.set(t,e),E.set(e,t)),e}const B=t=>E.get(t);const P=[\"get\",\"getKey\",\"getAll\",\"getAllKeys\",\"count\"],M=[\"put\",\"add\",\"delete\",\"clear\"],W=new Map;function j(t,e){if(!(t instanceof IDBDatabase)||e in t||\"string\"!=typeof e)return;if(W.get(e))return W.get(e);const s=e.replace(/FromIndex$/,\"\"),n=e!==s,r=M.includes(s);if(!(s in(n?IDBIndex:IDBObjectStore).prototype)||!r&&!P.includes(s))return;const i=async function(t,...e){const i=this.transaction(t,r?\"readwrite\":\"readonly\");let a=i.store;return n&&(a=a.index(e.shift())),(await Promise.all([a[s](...e),r&&i.done]))[0]};return W.set(e,i),i}N=(t=>q({},t,{get:(e,s,n)=>j(e,s)||t.get(e,s,n),has:(e,s)=>!!j(e,s)||t.has(e,s)}))(N);try{self[\"workbox:expiration:6.5.4\"]&&_()}catch(t){}const S=\"cache-entries\",K=t=>{const e=new URL(t,location.href);return e.hash=\"\",e.href};class A{constructor(t){this._=null,this.L=t}I(t){const e=t.createObjectStore(S,{keyPath:\"id\"});e.createIndex(\"cacheName\",\"cacheName\",{unique:!1}),e.createIndex(\"timestamp\",\"timestamp\",{unique:!1})}C(t){this.I(t),this.L&&function(t,{blocked:e}={}){const s=indexedDB.deleteDatabase(t);e&&s.addEventListener(\"blocked\",t=>e(t.oldVersion,t)),k(s).then(()=>{})}(this.L)}async setTimestamp(t,e){const s={url:t=K(t),timestamp:e,cacheName:this.L,id:this.N(t)},n=(await this.getDb()).transaction(S,\"readwrite\",{durability:\"relaxed\"});await n.store.put(s),await n.done}async getTimestamp(t){const e=await this.getDb(),s=await e.get(S,this.N(t));return null==s?void 0:s.timestamp}async expireEntries(t,e){const s=await this.getDb();let n=await s.transaction(S).store.index(\"timestamp\").openCursor(null,\"prev\");const r=[];let i=0;for(;n;){const s=n.value;s.cacheName===this.L&&(t&&s.timestamp<t||e&&i>=e?r.push(n.value):i++),n=await n.continue()}const a=[];for(const t of r)await s.delete(S,t.id),a.push(t.url);return a}N(t){return this.L+\"|\"+K(t)}async getDb(){return this._||(this._=await function(t,e,{blocked:s,upgrade:n,blocking:r,terminated:i}={}){const a=indexedDB.open(t,e),o=k(a);return n&&a.addEventListener(\"upgradeneeded\",t=>{n(k(a.result),t.oldVersion,t.newVersion,k(a.transaction),t)}),s&&a.addEventListener(\"blocked\",t=>s(t.oldVersion,t.newVersion,t)),o.then(t=>{i&&t.addEventListener(\"close\",()=>i()),r&&t.addEventListener(\"versionchange\",t=>r(t.oldVersion,t.newVersion,t))}).catch(()=>{}),o}(\"workbox-expiration\",1,{upgrade:this.C.bind(this)})),this._}}class F{constructor(t,e={}){this.O=!1,this.T=!1,this.k=e.maxEntries,this.B=e.maxAgeSeconds,this.P=e.matchOptions,this.L=t,this.M=new A(t)}async expireEntries(){if(this.O)return void(this.T=!0);this.O=!0;const t=this.B?Date.now()-1e3*this.B:0,e=await this.M.expireEntries(t,this.k),s=await self.caches.open(this.L);for(const t of e)await s.delete(t,this.P);this.O=!1,this.T&&(this.T=!1,b(this.expireEntries()))}async updateTimestamp(t){await this.M.setTimestamp(t,Date.now())}async isURLExpired(t){if(this.B){const e=await this.M.getTimestamp(t),s=Date.now()-1e3*this.B;return void 0===e||e<s}return!1}async delete(){this.T=!1,await this.M.expireEntries(1/0)}}try{self[\"workbox:range-requests:6.5.4\"]&&_()}catch(t){}async function H(t,e){try{if(206===e.status)return e;const n=t.headers.get(\"range\");if(!n)throw new s(\"no-range-header\");const r=function(t){const e=t.trim().toLowerCase();if(!e.startsWith(\"bytes=\"))throw new s(\"unit-must-be-bytes\",{normalizedRangeHeader:e});if(e.includes(\",\"))throw new s(\"single-range-only\",{normalizedRangeHeader:e});const n=/(\\d*)-(\\d*)/.exec(e);if(!n||!n[1]&&!n[2])throw new s(\"invalid-range-values\",{normalizedRangeHeader:e});return{start:\"\"===n[1]?void 0:Number(n[1]),end:\"\"===n[2]?void 0:Number(n[2])}}(n),i=await e.blob(),a=function(t,e,n){const r=t.size;if(n&&n>r||e&&e<0)throw new s(\"range-not-satisfiable\",{size:r,end:n,start:e});let i,a;return void 0!==e&&void 0!==n?(i=e,a=n+1):void 0!==e&&void 0===n?(i=e,a=r):void 0!==n&&void 0===e&&(i=r-n,a=r),{start:i,end:a}}(i,r.start,r.end),o=i.slice(a.start,a.end),c=o.size,h=new Response(o,{status:206,statusText:\"Partial Content\",headers:e.headers});return h.headers.set(\"Content-Length\",String(c)),h.headers.set(\"Content-Range\",`bytes ${a.start}-${a.end-1}/${i.size}`),h}catch(t){return new Response(\"\",{status:416,statusText:\"Range Not Satisfiable\"})}}function $(t,e){const s=e();return t.waitUntil(s),s}try{self[\"workbox:precaching:6.5.4\"]&&_()}catch(t){}function z(t){if(!t)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(\"string\"==typeof t){const e=new URL(t,location.href);return{cacheKey:e.href,url:e.href}}const{revision:e,url:n}=t;if(!n)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(!e){const t=new URL(n,location.href);return{cacheKey:t.href,url:t.href}}const r=new URL(n,location.href),i=new URL(n,location.href);return r.searchParams.set(\"__WB_REVISION__\",e),{cacheKey:r.href,url:i.href}}class G{constructor(){this.updatedURLs=[],this.notUpdatedURLs=[],this.handlerWillStart=async({request:t,state:e})=>{e&&(e.originalRequest=t)},this.cachedResponseWillBeUsed=async({event:t,state:e,cachedResponse:s})=>{if(\"install\"===t.type&&e&&e.originalRequest&&e.originalRequest instanceof Request){const t=e.originalRequest.url;s?this.notUpdatedURLs.push(t):this.updatedURLs.push(t)}return s}}}class V{constructor({precacheController:t}){this.cacheKeyWillBeUsed=async({request:t,params:e})=>{const s=(null==e?void 0:e.cacheKey)||this.W.getCacheKeyForURL(t.url);return s?new Request(s,{headers:t.headers}):t},this.W=t}}let J,Q;async function X(t,e){let n=null;if(t.url){n=new URL(t.url).origin}if(n!==self.location.origin)throw new s(\"cross-origin-copy-response\",{origin:n});const r=t.clone(),i={headers:new Headers(r.headers),status:r.status,statusText:r.statusText},a=e?e(i):i,o=function(){if(void 0===J){const t=new Response(\"\");if(\"body\"in t)try{new Response(t.body),J=!0}catch(t){J=!1}J=!1}return J}()?r.body:await r.blob();return new Response(o,a)}class Y extends R{constructor(t={}){t.cacheName=w(t.cacheName),super(t),this.j=!1!==t.fallbackToNetwork,this.plugins.push(Y.copyRedirectedCacheableResponsesPlugin)}async U(t,e){const s=await e.cacheMatch(t);return s||(e.event&&\"install\"===e.event.type?await this.S(t,e):await this.K(t,e))}async K(t,e){let n;const r=e.params||{};if(!this.j)throw new s(\"missing-precache-entry\",{cacheName:this.cacheName,url:t.url});{const s=r.integrity,i=t.integrity,a=!i||i===s;n=await e.fetch(new Request(t,{integrity:\"no-cors\"!==t.mode?i||s:void 0})),s&&a&&\"no-cors\"!==t.mode&&(this.A(),await e.cachePut(t,n.clone()))}return n}async S(t,e){this.A();const n=await e.fetch(t);if(!await e.cachePut(t,n.clone()))throw new s(\"bad-precaching-response\",{url:t.url,status:n.status});return n}A(){let t=null,e=0;for(const[s,n]of this.plugins.entries())n!==Y.copyRedirectedCacheableResponsesPlugin&&(n===Y.defaultPrecacheCacheabilityPlugin&&(t=s),n.cacheWillUpdate&&e++);0===e?this.plugins.push(Y.defaultPrecacheCacheabilityPlugin):e>1&&null!==t&&this.plugins.splice(t,1)}}Y.defaultPrecacheCacheabilityPlugin={cacheWillUpdate:async({response:t})=>!t||t.status>=400?null:t},Y.copyRedirectedCacheableResponsesPlugin={cacheWillUpdate:async({response:t})=>t.redirected?await X(t):t};class Z{constructor({cacheName:t,plugins:e=[],fallbackToNetwork:s=!0}={}){this.F=new Map,this.H=new Map,this.$=new Map,this.u=new Y({cacheName:w(t),plugins:[...e,new V({precacheController:this})],fallbackToNetwork:s}),this.install=this.install.bind(this),this.activate=this.activate.bind(this)}get strategy(){return this.u}precache(t){this.addToCacheList(t),this.G||(self.addEventListener(\"install\",this.install),self.addEventListener(\"activate\",this.activate),this.G=!0)}addToCacheList(t){const e=[];for(const n of t){\"string\"==typeof n?e.push(n):n&&void 0===n.revision&&e.push(n.url);const{cacheKey:t,url:r}=z(n),i=\"string\"!=typeof n&&n.revision?\"reload\":\"default\";if(this.F.has(r)&&this.F.get(r)!==t)throw new s(\"add-to-cache-list-conflicting-entries\",{firstEntry:this.F.get(r),secondEntry:t});if(\"string\"!=typeof n&&n.integrity){if(this.$.has(t)&&this.$.get(t)!==n.integrity)throw new s(\"add-to-cache-list-conflicting-integrities\",{url:r});this.$.set(t,n.integrity)}if(this.F.set(r,t),this.H.set(r,i),e.length>0){const t=`Workbox is precaching URLs without revision info: ${e.join(\", \")}\\nThis is generally NOT safe. Learn more at https://bit.ly/wb-precache`;console.warn(t)}}}install(t){return $(t,async()=>{const e=new G;this.strategy.plugins.push(e);for(const[e,s]of this.F){const n=this.$.get(s),r=this.H.get(e),i=new Request(e,{integrity:n,cache:r,credentials:\"same-origin\"});await Promise.all(this.strategy.handleAll({params:{cacheKey:s},request:i,event:t}))}const{updatedURLs:s,notUpdatedURLs:n}=e;return{updatedURLs:s,notUpdatedURLs:n}})}activate(t){return $(t,async()=>{const t=await self.caches.open(this.strategy.cacheName),e=await t.keys(),s=new Set(this.F.values()),n=[];for(const r of e)s.has(r.url)||(await t.delete(r),n.push(r.url));return{deletedURLs:n}})}getURLsToCacheKeys(){return this.F}getCachedURLs(){return[...this.F.keys()]}getCacheKeyForURL(t){const e=new URL(t,location.href);return this.F.get(e.href)}getIntegrityForCacheKey(t){return this.$.get(t)}async matchPrecache(t){const e=t instanceof Request?t.url:t,s=this.getCacheKeyForURL(e);if(s){return(await self.caches.open(this.strategy.cacheName)).match(s)}}createHandlerBoundToURL(t){const e=this.getCacheKeyForURL(t);if(!e)throw new s(\"non-precached-url\",{url:t});return s=>(s.request=new Request(t),s.params=Object.assign({cacheKey:e},s.params),this.strategy.handle(s))}}const tt=()=>(Q||(Q=new Z),Q);class et extends r{constructor(t,e){super(({request:s})=>{const n=t.getURLsToCacheKeys();for(const r of function*(t,{ignoreURLParametersMatching:e=[/^utm_/,/^fbclid$/],directoryIndex:s=\"index.html\",cleanURLs:n=!0,urlManipulation:r}={}){const i=new URL(t,location.href);i.hash=\"\",yield i.href;const a=function(t,e=[]){for(const s of[...t.searchParams.keys()])e.some(t=>t.test(s))&&t.searchParams.delete(s);return t}(i,e);if(yield a.href,s&&a.pathname.endsWith(\"/\")){const t=new URL(a.href);t.pathname+=s,yield t.href}if(n){const t=new URL(a.href);t.pathname+=\".html\",yield t.href}if(r){const t=r({url:i});for(const e of t)yield e.href}}(s.url,e)){const e=n.get(r);if(e){return{cacheKey:e,integrity:t.getIntegrityForCacheKey(e)}}}},t.strategy)}}t.CacheFirst=class extends R{async U(t,e){let n,r=await e.cacheMatch(t);if(!r)try{r=await e.fetchAndCachePut(t)}catch(t){t instanceof Error&&(n=t)}if(!r)throw new s(\"no-response\",{url:t.url,error:n});return r}},t.ExpirationPlugin=class{constructor(t={}){this.cachedResponseWillBeUsed=async({event:t,request:e,cacheName:s,cachedResponse:n})=>{if(!n)return null;const r=this.V(n),i=this.J(s);b(i.expireEntries());const a=i.updateTimestamp(e.url);if(t)try{t.waitUntil(a)}catch(t){}return r?n:null},this.cacheDidUpdate=async({cacheName:t,request:e})=>{const s=this.J(t);await s.updateTimestamp(e.url),await s.expireEntries()},this.X=t,this.B=t.maxAgeSeconds,this.Y=new Map,t.purgeOnQuotaError&&function(t){g.add(t)}(()=>this.deleteCacheAndMetadata())}J(t){if(t===d())throw new s(\"expire-custom-caches-only\");let e=this.Y.get(t);return e||(e=new F(t,this.X),this.Y.set(t,e)),e}V(t){if(!this.B)return!0;const e=this.Z(t);if(null===e)return!0;return e>=Date.now()-1e3*this.B}Z(t){if(!t.headers.has(\"date\"))return null;const e=t.headers.get(\"date\"),s=new Date(e).getTime();return isNaN(s)?null:s}async deleteCacheAndMetadata(){for(const[t,e]of this.Y)await self.caches.delete(t),await e.delete();this.Y=new Map}},t.NetworkFirst=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u),this.tt=t.networkTimeoutSeconds||0}async U(t,e){const n=[],r=[];let i;if(this.tt){const{id:s,promise:a}=this.et({request:t,logs:n,handler:e});i=s,r.push(a)}const a=this.st({timeoutId:i,request:t,logs:n,handler:e});r.push(a);const o=await e.waitUntil((async()=>await e.waitUntil(Promise.race(r))||await a)());if(!o)throw new s(\"no-response\",{url:t.url});return o}et({request:t,logs:e,handler:s}){let n;return{promise:new Promise(e=>{n=setTimeout(async()=>{e(await s.cacheMatch(t))},1e3*this.tt)}),id:n}}async st({timeoutId:t,request:e,logs:s,handler:n}){let r,i;try{i=await n.fetchAndCachePut(e)}catch(t){t instanceof Error&&(r=t)}return t&&clearTimeout(t),!r&&i||(i=await n.cacheMatch(e)),i}},t.RangeRequestsPlugin=class{constructor(){this.cachedResponseWillBeUsed=async({request:t,cachedResponse:e})=>e&&t.headers.has(\"range\")?await H(t,e):e}},t.StaleWhileRevalidate=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u)}async U(t,e){const n=e.fetchAndCachePut(t).catch(()=>{});e.waitUntil(n);let r,i=await e.cacheMatch(t);if(i);else try{i=await n}catch(t){t instanceof Error&&(r=t)}if(!i)throw new s(\"no-response\",{url:t.url,error:r});return i}},t.cleanupOutdatedCaches=function(){self.addEventListener(\"activate\",t=>{const e=w();t.waitUntil((async(t,e=\"-precache-\")=>{const s=(await self.caches.keys()).filter(s=>s.includes(e)&&s.includes(self.registration.scope)&&s!==t);return await Promise.all(s.map(t=>self.caches.delete(t))),s})(e).then(t=>{}))})},t.clientsClaim=function(){self.addEventListener(\"activate\",()=>self.clients.claim())},t.precacheAndRoute=function(t,e){!function(t){tt().precache(t)}(t),function(t){const e=tt();h(new et(e,t))}(e)},t.registerRoute=h});\n",
    "web_platform/frontend/src/components/AdapterStatusPanel.tsx": "// web_platform/frontend/src/components/AdapterStatusPanel.tsx\n'use client';\n\nimport React from 'react';\nimport { SourceInfo } from '../types/racing';\n\ninterface AdapterStatusPanelProps {\n  adapter: SourceInfo;\n  onFetchRaces: (sourceName: string) => void;\n}\n\nexport const AdapterStatusPanel: React.FC<AdapterStatusPanelProps> = ({ adapter, onFetchRaces }) => {\n  const isConfigured = adapter.status !== 'CONFIG_ERROR';\n\n  return (\n    <div className={`p-4 rounded-lg border ${isConfigured ? 'bg-slate-800 border-slate-700' : 'bg-yellow-900/20 border-yellow-700/50'}`}>\n      <div className=\"flex justify-between items-center\">\n        <h3 className=\"font-bold text-lg text-white\">{adapter.name}</h3>\n        <span className={`px-2 py-0.5 rounded-full text-xs font-medium ${isConfigured ? 'bg-green-500/20 text-green-300' : 'bg-yellow-500/20 text-yellow-300'}`}>\n          {isConfigured ? 'Ready' : 'Not Configured'}\n        </span>\n      </div>\n      <div className=\"mt-4 flex gap-2\">\n        <button\n          onClick={() => onFetchRaces(adapter.name)}\n          disabled={!isConfigured}\n          className=\"flex-1 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 disabled:bg-slate-700 disabled:text-slate-400 disabled:cursor-not-allowed\"\n        >\n          Automatic Load\n        </button>\n        <button\n          disabled\n          className=\"flex-1 px-4 py-2 bg-slate-700 text-slate-400 rounded cursor-not-allowed\"\n        >\n          Manual Entry (Coming Soon)\n        </button>\n      </div>\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/ErrorDisplay.tsx": "// web_platform/frontend/src/components/ErrorDisplay.tsx\n'use client';\n\nimport React from 'react';\n\ninterface ErrorInfo {\n  message: string;\n  suggestion: string;\n  details?: string;\n}\n\ninterface ErrorDisplayProps {\n  error: ErrorInfo;\n}\n\nexport const ErrorDisplay: React.FC<ErrorDisplayProps> = ({ error }) => {\n  return (\n    <div className=\"bg-red-900/20 border border-red-500/30 text-white rounded-lg p-6 max-w-2xl mx-auto my-8\">\n      <div className=\"flex items-center mb-4\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-8 w-8 text-red-400 mr-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n          <path fillRule=\"evenodd\" d=\"M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z\" clipRule=\"evenodd\" />\n        </svg>\n        <h2 className=\"text-2xl font-bold text-red-400\">An Error Occurred</h2>\n      </div>\n      <p className=\"text-lg text-slate-300 mb-2\">{error.message}</p>\n      <p className=\"text-slate-400 mb-6\">{error.suggestion}</p>\n      {error.details && (\n        <details className=\"bg-slate-800/50 rounded-lg p-4\">\n          <summary className=\"cursor-pointer text-sm text-slate-500 hover:text-white\">\n            Technical Details\n          </summary>\n          <pre className=\"text-xs text-slate-400 mt-2 p-2 bg-black/30 rounded overflow-x-auto\">\n            <code>{error.details}</code>\n          </pre>\n        </details>\n      )}\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/ManualOverridePanel.tsx": "// web_platform/frontend/src/components/ManualOverridePanel.tsx\nimport React, { useState } from 'react';\nimport { Race } from '../types/racing';\n\ninterface ManualOverridePanelProps {\n  adapterName: string;\n  attemptedUrl: string;\n  apiKey: string | null;\n  onParseSuccess: (adapterName: string, parsedRaces: Race[]) => void;\n}\n\nconst ManualOverridePanel: React.FC<ManualOverridePanelProps> = ({\n  adapterName,\n  attemptedUrl,\n  apiKey,\n  onParseSuccess,\n}) => {\n  const [showPanel, setShowPanel] = useState(true);\n  const [htmlContent, setHtmlContent] = useState('');\n  const [isSubmitting, setIsSubmitting] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  const handleSubmit = async () => {\n    if (!htmlContent.trim()) {\n      setError('HTML content cannot be empty.');\n      return;\n    }\n    if (!apiKey) {\n      setError('API key is not available. Cannot submit.');\n      return;\n    }\n\n    setIsSubmitting(true);\n    setError(null);\n\n    try {\n      const response = await fetch('/api/races/parse-manual', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'X-API-Key': apiKey,\n        },\n        body: JSON.stringify({\n          adapter_name: adapterName,\n          html_content: htmlContent,\n        }),\n      });\n\n      if (!response.ok) {\n        const errorData = await response.json();\n        throw new Error(errorData.detail || 'Failed to parse HTML.');\n      }\n\n      const parsedRaces: Race[] = await response.json();\n      onParseSuccess(adapterName, parsedRaces);\n      setShowPanel(false); // Hide panel on success\n\n    } catch (err) {\n      const errorMessage = err instanceof Error ? err.message : 'An unknown error occurred.';\n      setError(errorMessage);\n      console.error('Manual parse submission failed:', err);\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n\n  if (!showPanel) {\n    return null;\n  }\n\n  return (\n    <div className=\"bg-red-900 bg-opacity-50 border border-red-700 p-4 rounded-lg shadow-lg mb-4\">\n      <div className=\"flex justify-between items-center\">\n        <div>\n          <h3 className=\"font-bold text-red-300\">Data Fetch Failed: {adapterName}</h3>\n          <p className=\"text-sm text-red-400\">\n            The application failed to automatically retrieve data from:{' '}\n            <a href={attemptedUrl} target=\"_blank\" rel=\"noopener noreferrer\" className=\"underline hover:text-red-200\">\n              {attemptedUrl}\n            </a>\n          </p>\n        </div>\n        <button onClick={() => setShowPanel(false)} className=\"text-red-400 hover:text-red-200 text-2xl\">&times;</button>\n      </div>\n      <div className=\"mt-4\">\n        <p className=\"text-sm text-red-300 mb-2\">\n          <strong>To resolve this:</strong>\n          <ol className=\"list-decimal list-inside pl-4\">\n            <li>Click the link above to open the page in a new tab.</li>\n            <li>Right-click on the page and select \"View Page Source\".</li>\n            <li>Copy the entire HTML source code.</li>\n            <li>Paste the code into the text area below and click \"Submit Manual Data\".</li>\n          </ol>\n        </p>\n        <textarea\n          className=\"w-full h-24 p-2 bg-gray-900 border border-gray-700 rounded text-gray-300 font-mono text-xs\"\n          placeholder={`Paste HTML source for ${adapterName} here...`}\n          value={htmlContent}\n          onChange={(e) => setHtmlContent(e.target.value)}\n          disabled={isSubmitting}\n        />\n        {error && <p className=\"text-red-400 text-sm mt-2\">{error}</p>}\n        <div className=\"mt-2 flex gap-2\">\n          <button\n            onClick={handleSubmit}\n            className=\"px-3 py-1.5 bg-blue-600 text-white rounded hover:bg-blue-700 text-sm disabled:bg-blue-800 disabled:cursor-not-allowed\"\n            disabled={isSubmitting}\n          >\n            {isSubmitting ? 'Submitting...' : 'Submit Manual Data'}\n          </button>\n          <button\n            onClick={() => setShowPanel(false)}\n            className=\"px-3 py-1.5 bg-gray-700 text-white rounded hover:bg-gray-600 text-sm\"\n          >\n            Skip for Now\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default ManualOverridePanel;\n",
    "web_platform/frontend/src/components/RaceCardSkeleton.tsx": "// web_platform/frontend/src/components/RaceCardSkeleton.tsx\nimport React from 'react';\n\nexport const RaceCardSkeleton: React.FC = () => {\n  return (\n    <div className=\"race-card-skeleton border border-gray-700 rounded-lg p-4 bg-gray-800 shadow-lg animate-pulse\">\n      {/* Skeleton Header */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <div className=\"h-7 w-28 bg-gray-700 rounded-md\"></div>\n            <div className=\"h-4 w-40 bg-gray-700 rounded-md mt-2\"></div>\n          </div>\n        </div>\n        <div className=\"h-16 w-16 bg-gray-700 rounded-full\"></div>\n      </div>\n\n      {/* Skeleton Info Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"h-3 w-12 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-8 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-12 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-8 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-10 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-6 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-10 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-6 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n      </div>\n\n      {/* Skeleton Runner Rows */}\n      <div className=\"space-y-2\">\n        {[...Array(3)].map((_, i) => (\n          <div key={i} className=\"runner-row rounded-md p-3\">\n            <div className=\"flex items-center justify-between\">\n              <div className=\"flex items-center gap-4 flex-1\">\n                <div className=\"w-10 h-10 rounded-full bg-gray-700\"></div>\n                <div className=\"flex flex-col space-y-2\">\n                  <div className=\"h-5 w-32 bg-gray-700 rounded-md\"></div>\n                  <div className=\"h-4 w-40 bg-gray-700 rounded-md\"></div>\n                </div>\n              </div>\n              <div className=\"text-right\">\n                <div className=\"h-6 w-16 bg-gray-700 rounded-md\"></div>\n                <div className=\"h-3 w-12 bg-gray-700 rounded-md mt-2\"></div>\n              </div>\n            </div>\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/RaceFilters.tsx": "// web_platform/frontend/src/components/RaceFilters.tsx\n'use client';\n\nimport { useState, useCallback } from 'react';\nimport { Settings, RotateCcw } from 'lucide-react';\n\ninterface FilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nexport interface RaceFiltersProps {\n  onParamsChange: (params: FilterParams) => void;\n  isLoading: boolean;\n  refetch: () => void;\n}\n\nconst DEFAULT_PARAMS: FilterParams = {\n  maxFieldSize: 10,\n  minFavoriteOdds: 2.5,\n  minSecondFavoriteOdds: 4.0,\n};\n\nexport function RaceFilters({ onParamsChange, isLoading, refetch }: RaceFiltersProps) {\n  const [params, setParams] = useState<FilterParams>(DEFAULT_PARAMS);\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // Handle individual parameter changes\n  const handleChange = useCallback((key: keyof FilterParams, value: number) => {\n    setParams(prev => {\n      const updated = { ...prev, [key]: value };\n      onParamsChange(updated);\n      return updated;\n    });\n    // Debounce the refetch call\n    const timer = setTimeout(() => {\n      refetch();\n    }, 500);\n    return () => clearTimeout(timer);\n  }, [onParamsChange, refetch]);\n\n  // Reset to defaults\n  const handleReset = useCallback(() => {\n    setParams(DEFAULT_PARAMS);\n    onParamsChange(DEFAULT_PARAMS);\n    refetch();\n  }, [onParamsChange, refetch]);\n\n  return (\n    <div className=\"bg-gradient-to-r from-slate-800 to-slate-900 rounded-lg p-4 mb-6 border border-slate-700\">\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-2\">\n          <Settings className=\"w-5 h-5 text-amber-500\" />\n          <h3 className=\"text-lg font-semibold text-white\">Race Filters</h3>\n        </div>\n        <button\n          onClick={() => setIsExpanded(!isExpanded)}\n          className=\"text-sm text-slate-400 hover:text-slate-200 transition\"\n        >\n          {isExpanded ? 'Hide' : 'Show'}\n        </button>\n      </div>\n\n      {isExpanded && (\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 pt-4 border-t border-slate-700\">\n          {/* Max Field Size */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Max Field Size\n              <span className=\"text-amber-500 ml-2\">{params.maxFieldSize}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2\"\n              max=\"20\"\n              value={params.maxFieldSize}\n              onChange={(e) => handleChange('maxFieldSize', parseInt(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Filters races with larger fields</p>\n          </div>\n\n          {/* Min Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"1.5\"\n              max=\"5\"\n              step=\"0.1\"\n              value={params.minFavoriteOdds}\n              onChange={(e) => handleChange('minFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = pickier favorites</p>\n          </div>\n\n          {/* Min Second Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min 2nd Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minSecondFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2.0\"\n              max=\"8\"\n              step=\"0.1\"\n              value={params.minSecondFavoriteOdds}\n              onChange={(e) => handleChange('minSecondFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = better odds separation</p>\n          </div>\n\n          {/* Reset Button */}\n          <div className=\"md:col-span-3 flex justify-end pt-4 border-t border-slate-700\">\n            <button\n              onClick={handleReset}\n              disabled={isLoading}\n              className=\"inline-flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-600 text-slate-200 rounded text-sm font-medium transition disabled:opacity-50\"\n            >\n              <RotateCcw className=\"w-4 h-4\" />\n              Reset to Defaults\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/components/SettingsPage.tsx": "// src/components/SettingsPage.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\n\nexport function SettingsPage() {\n  const [apiKey, setApiKey] = useState('');\n  const [betfairAppKey, setBetfairAppKey] = useState('');\n  const [betfairUsername, setBetfairUsername] = useState('');\n  const [betfairPassword, setBetfairPassword] = useState('');\n\n  useEffect(() => {\n    // Fetch the current API key when the component mounts\n    const fetchApiKey = async () => {\n      if (window.electronAPI?.getApiKey) {\n        const key = await window.electronAPI.getApiKey();\n        if (key) {\n          setApiKey(key);\n        }\n      }\n    };\n    fetchApiKey();\n  }, []);\n\n  const handleGenerateApiKey = async () => {\n    if (window.electronAPI?.generateApiKey) {\n      const newKey = await window.electronAPI.generateApiKey();\n      setApiKey(newKey);\n    }\n  };\n\n  const handleSaveSettings = async () => {\n    if (window.electronAPI?.saveApiKey && window.electronAPI?.saveBetfairCredentials) {\n      await window.electronAPI.saveApiKey(apiKey);\n      await window.electronAPI.saveBetfairCredentials({\n        appKey: betfairAppKey,\n        username: betfairUsername,\n        password: betfairPassword,\n      });\n      alert('Settings saved successfully!');\n    }\n  };\n\n  return (\n    <div className=\"bg-slate-800 p-8 rounded-lg border border-slate-700 text-white max-w-2xl mx-auto\">\n      <h2 className=\"text-3xl font-bold text-white mb-6\">Application Settings</h2>\n\n      <div className=\"space-y-8\">\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">API Key</h3>\n          <p className=\"text-sm text-slate-400 mb-3\">This key is required for the dashboard to communicate with the backend service.</p>\n          <div className=\"flex items-center space-x-2\">\n            <input\n              type=\"text\"\n              readOnly\n              value={apiKey}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 font-mono text-sm\"\n            />\n            <button\n              onClick={handleGenerateApiKey}\n              className=\"px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded transition-colors font-semibold\"\n            >\n              Generate New Key\n            </button>\n          </div>\n        </div>\n\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">Betfair Credentials (Optional)</h3>\n           <p className=\"text-sm text-slate-400 mb-3\">Required for adapters that use the Betfair Exchange API.</p>\n          <div className=\"space-y-3\">\n            <input\n              type=\"password\"\n              placeholder=\"App Key\"\n              value={betfairAppKey}\n              onChange={(e) => setBetfairAppKey(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"text\"\n              placeholder=\"Username\"\n              value={betfairUsername}\n              onChange={(e) => setBetfairUsername(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"password\"\n              placeholder=\"Password\"\n              value={betfairPassword}\n              onChange={(e) => setBetfairPassword(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n          </div>\n        </div>\n\n        <div className=\"flex justify-end pt-6 border-t border-slate-700\">\n          <button\n            onClick={handleSaveSettings}\n            className=\"px-8 py-3 bg-green-600 hover:bg-green-700 rounded font-bold text-lg transition-colors\"\n          >\n            Save All Settings\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/components/Tabs.tsx": "// src/components/Tabs.tsx\n'use client';\n\nimport React, { useState } from 'react';\n\ntype Tab = {\n  label: string;\n  content: React.ReactNode;\n};\n\ntype TabsProps = {\n  tabs: Tab[];\n};\n\nexport function Tabs({ tabs }: TabsProps) {\n  const [activeTab, setActiveTab] = useState(0);\n\n  return (\n    <div>\n      <div className=\"border-b border-slate-700\">\n        <nav className=\"-mb-px flex space-x-8\" aria-label=\"Tabs\">\n          {tabs.map((tab, index) => (\n            <button\n              key={tab.label}\n              onClick={() => setActiveTab(index)}\n              className={`${\n                activeTab === index\n                  ? 'border-blue-500 text-blue-400'\n                  : 'border-transparent text-slate-400 hover:text-slate-200 hover:border-slate-500'\n              } whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm transition-colors focus:outline-none`}\n            >\n              {tab.label}\n            </button>\n          ))}\n        </nav>\n      </div>\n      <div className=\"mt-8\">{tabs[activeTab].content}</div>\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/hooks/useWebSocket.ts": "// web_platform/frontend/src/hooks/useWebSocket.ts\n'use client';\n\nimport { useState, useEffect, useRef } from 'react';\n\ninterface WebSocketOptions {\n  apiKey: string | null;\n}\n\nexport const useWebSocket = <T>(url: string, options: WebSocketOptions) => {\n  const [data, setData] = useState<T | null>(null);\n  const [isConnected, setIsConnected] = useState(false);\n  const webSocketRef = useRef<WebSocket | null>(null);\n\n  useEffect(() => {\n    if (!url || !options.apiKey) {\n      if (webSocketRef.current) {\n        webSocketRef.current.close();\n      }\n      return;\n    }\n\n    const wsUrl = new URL(url, window.location.href);\n    wsUrl.protocol = wsUrl.protocol.replace('http', 'ws');\n    wsUrl.searchParams.append('api_key', options.apiKey);\n\n    const ws = new WebSocket(wsUrl.toString());\n    webSocketRef.current = ws;\n\n    ws.onopen = () => {\n      console.log('WebSocket connection established.');\n      setIsConnected(true);\n    };\n\n    ws.onmessage = (event) => {\n      try {\n        const messageData = JSON.parse(event.data);\n        setData(messageData);\n      } catch (error) {\n        console.error('Error parsing WebSocket message:', error);\n      }\n    };\n\n    ws.onerror = (error) => {\n      console.error('WebSocket error:', error);\n    };\n\n    ws.onclose = (event) => {\n      console.log(`WebSocket connection closed: ${event.code} ${event.reason}`);\n      setIsConnected(false);\n      webSocketRef.current = null;\n    };\n\n    return () => {\n      if (ws.readyState === WebSocket.OPEN) {\n        ws.close();\n      }\n    };\n  }, [url, options.apiKey]);\n\n  return { data, isConnected };\n};\n",
    "web_platform/frontend/src/types/electron.d.ts": "// web_platform/frontend/src/types/electron.d.ts\n\n/**\n * This declaration file extends the global Window interface to include the\n * 'electronAPI' object exposed by the preload script. This provides\n * TypeScript with type information for the functions we're using for IPC.\n */\nexport {};\n\ndeclare global {\n  interface Window {\n    electronAPI?: {\n      /**\n       * Asynchronously fetches the secure API key from the main process.\n       * @returns {Promise<string|null>} A promise that resolves with the API key or null if not found.\n       */\n      getApiKey: () => Promise<string | null>;\n      /**\n       * Registers a callback for backend status updates from the main process.\n       * @param callback The function to execute. Receives an object with state and logs.\n       * @returns A function to unsubscribe the listener.\n       */\n      onBackendStatusUpdate: (callback: (status: { state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }) => void) => () => void;\n\n      /**\n       * Sends a command to the main process to restart the backend executable.\n       */\n      restartBackend: () => void;\n\n      /**\n       * Asynchronously fetches the current backend status from the main process.\n       * @returns {Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>}\n       */\n      getBackendStatus: () => Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>;\n      generateApiKey: () => Promise<string>;\n      saveApiKey: (apiKey: string) => Promise<{ success: boolean }>;\n      saveBetfairCredentials: (credentials: { appKey: string; username: string; password: string }) => Promise<{ success: boolean }>;\n    };\n  }\n}\n",
    "web_platform/frontend/tailwind.config.ts": "import type { Config } from 'tailwindcss'\n\nconst config: Config = {\n  darkMode: 'media',\n  content: [\n    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/components/**/*.{js,ts,jsx,tsx,mdx}',\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\nexport default config"
}