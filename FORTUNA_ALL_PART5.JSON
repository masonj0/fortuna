{
    ".github/actions/run-asgi-diagnostics/action.yml": "name: 'Run ASGI Import Killer Diagnostics'\ndescription: 'Runs a multi-phase diagnostic to verify Python ASGI application imports.'\n\ninputs:\n  python-version:\n    description: 'The version of Python to use.'\n    required: true\n  backend-dir:\n    description: 'The directory of the backend service to test.'\n    required: true\n  backend-module-path:\n    description: 'The Python module path for the backend service (e.g., web_service.backend).'\n    required: true\n\nruns:\n  using: \"composite\"\n  steps:\n      - name: \u2699\ufe0f Setup Python (EXACT VERSION)\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ inputs.python-version }}\n\n      - name: \ud83d\udccb Capture Python Info\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          Write-Host \"Python executable: $(which python)\" -ForegroundColor Cyan\n          python --version\n          python -m site\n          python -c \"import sys; print('Prefix:', sys.prefix); print('Base prefix:', sys.base_prefix)\"\n\n      - name: \ud83d\udce5 Install Requirements (Exactly as Backend Build)\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel --quiet\n\n          Write-Host \"Installing requirements.txt...\" -ForegroundColor Cyan\n          pip install -r (Join-Path \"${{ inputs.backend-dir }}\" \"requirements.txt\") -v 2>&1 | Tee-Object \"install-requirements.log\"\n\n          if (Test-Path (Join-Path \"${{ inputs.backend-dir }}\" \"requirements-dev.txt\")) {\n            Write-Host \"Installing requirements-dev.txt...\" -ForegroundColor Cyan\n            pip install -r (Join-Path \"${{ inputs.backend-dir }}\" \"requirements-dev.txt\") -v 2>&1 | Tee-Object -Append \"install-requirements.log\"\n          }\n\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c pip install failed\" -ForegroundColor Red\n            exit 1\n          }\n\n          Write-Host \"\u2705 All dependencies installed\" -ForegroundColor Green\n\n      - name: \ud83d\udce6 Capture Installed Packages\n        shell: pwsh\n        run: |\n          pip list | Tee-Object \"installed-packages.txt\"\n          pip freeze | Tee-Object \"pip-freeze.txt\"\n\n      - name: \ud83d\udc0d Set PYTHONPATH\n        shell: pwsh\n        run: |\n          echo \"PYTHONPATH=${{ github.workspace }}\" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append\n          Write-Host \"PYTHONPATH set to ${{ github.workspace }}\"\n\n      - name: \ud83e\uddea PHASE 1 System Imports\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 1 SYSTEM-LEVEL IMPORTS\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('os', 'filesystem'), ('sys', 'system'), ('json', 'serialization'),\",\n            \"    ('asyncio', 'async I/O'), ('pathlib', 'paths'), ('typing', 'type hints'),\",\n            \"    ('importlib', 'import utilities')\",\n            ']',\n            'failed = []',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:20} [{desc}]\")',\n            '    except ImportError as e:',\n            '        print(f\"\u274c {mod_name:20} ImportError: {e}\")',\n            '        failed.append(mod_name)',\n            'if failed:',\n            '    print(f\"\\n\u274c {len(failed)} system imports failed\")',\n            '    sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 1 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 2 Web Framework Core\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'import traceback',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 2 WEB FRAMEWORK CORE\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('fastapi', 'web framework'),\",\n            \"    ('uvicorn', 'ASGI server'),\",\n            \"    ('starlette', 'ASGI toolkit'),\",\n            \"    ('starlette.applications', 'ASGI app'),\",\n            \"    ('starlette.routing', 'routing'),\",\n            ']',\n            'failed = []',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except ImportError as e:',\n            '        print(f\"\u274c {mod_name:30} ImportError: {e}\")',\n            '        failed.append((mod_name, str(e)))',\n            '    except Exception as e:',\n            '        print(f\"\u26a0\ufe0f  {mod_name:30} {type(e).__name__}: {e}\")',\n            'if failed:',\n            '    print(f\"\\n\u274c {len(failed)} core framework imports failed\")',\n            '    for mod, err in failed:',\n            '        print(f\"  - {mod}\")',\n            '    sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 2 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 3 Pydantic & Data Validation\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 3 PYDANTIC & DATA VALIDATION\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('pydantic', 'validation'),\",\n            \"    ('pydantic_core', 'core'),\",\n            \"    ('pydantic_settings', 'settings'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")',\n            '        sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 3 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 4 Async/IO Utilities\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 4 ASYNC/IO UTILITIES\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('anyio', 'async compat'),\",\n            \"    ('httpcore', 'HTTP core'),\",\n            \"    ('httpx', 'HTTP client'),\",\n            \"    ('aiosqlite', 'async DB'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")',\n            '        sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 4 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 5 Optional Dependencies (non-critical)\n        shell: pwsh\n        continue-on-error: true\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 5 OPTIONAL DEPENDENCIES (non-critical)\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('slowapi', 'rate limiting'),\",\n            \"    ('structlog', 'logging'),\",\n            \"    ('tenacity', 'retries'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u26a0\ufe0f  {mod_name:30} not critical: {type(e).__name__}\")',\n            'print(f\"\\n\u2705 Phase 5 complete (warnings OK)\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n\n      - name: \ud83e\uddea PHASE 6 Application Directory Structure\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n\n          $script = @(\n            'import os',\n            'from pathlib import Path',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 6 APPLICATION DIRECTORY STRUCTURE\")',\n            'print(\"=\"*80)',\n            'cwd = Path.cwd()',\n            'backend_dir = cwd / \"${{ inputs.backend-dir }}\"',\n            'print(f\"\\nCurrent directory: {cwd}\")',\n            'print(f\"\\nBackend directory exists: {backend_dir.exists()}\")',\n            'if backend_dir.exists():',\n            '    print(f\"  Contents:\")',\n            '    for item in backend_dir.iterdir():',\n            '        print(f\"    - {item.name}\")',\n            '    main_py = backend_dir / \"main.py\"',\n            '    api_py = backend_dir / \"api.py\"',\n            '    print(f''\\n  main.py: {main_py.stat().st_size if main_py.exists() else \"N/A\"} bytes'')',\n            '    print(f''  api.py: {api_py.stat().st_size if api_py.exists() else \"N/A\"} bytes'')'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n\n      - name: \ud83e\uddea PHASE 7 CRITICAL - Application Module Imports\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'import traceback',\n            'import importlib',\n            'from pathlib import Path',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 7 APPLICATION MODULE IMPORTS (CRITICAL)\")',\n            'print(\"=\"*80)',\n            'backend_module_path = \"${{ inputs.backend-module-path }}\"',\n            'print(f\"\\n[Step 1] Dynamically importing module: {backend_module_path}\")',\n            'try:',\n            '    backend_module = importlib.import_module(backend_module_path)',\n            '    print(f\"\u2705 {backend_module_path} imported successfully\")',\n            'except Exception as e:',\n            '    print(f\"\u274c FATAL: {backend_module_path} import failed\")',\n            '    print(f\"   Error: {type(e).__name__}: {e}\")',\n            '    traceback.print_exc()',\n            '    sys.exit(1)',\n            'print(''\\\\n[Step 2] Retrieving \"app\" object from the API submodule...'')',\n            'api_module_path = f\"{backend_module_path}.api\"',\n            'try:',\n            '    api_module = importlib.import_module(api_module_path)',\n            '    app = getattr(api_module, \"app\")',\n            '    print(f\"\u2705 app object retrieved from {api_module_path}\")',\n            '    print(f\"   Type: {type(app)}\")',\n            '    print(f\"   Class: {app.__class__.__name__}\")',\n            '    print(f\"   Module: {app.__class__.__module__}\")',\n            'except (ImportError, AttributeError) as e:',\n            '    print(f\"\u274c FATAL: Could not get app object from {api_module_path}\")',\n            '    print(f\"   Error: {type(e).__name__}: {e}\")',\n            '    traceback.print_exc()',\n            '    sys.exit(1)',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"\u2705 ALL APPLICATION IMPORTS SUCCESSFUL\")',\n            'print(\"=\"*80)',\n            'print(\"\\nThe ASGI app is fully importable.\")',\n            'print(\"Uvicorn should be able to load it successfully.\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c APPLICATION IMPORT TEST FAILED\" -ForegroundColor Red\n            exit 1\n          }\n\n      - name: \ud83d\udccb Generate ASGI Diagnostic Report\n        if: always()\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $report = @()\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report += \"\u2551              ASGI IMPORT KILLER - DIAGNOSTIC REPORT                        \u2551\"\n          $report += \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\"\n          $report += \"\"\n          $report += \"Timestamp: $(Get-Date -Format 'o')\"\n          $report += \"Python: $(python --version)\"\n          $report += \"\"\n          $report += \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\"\n          $result = if ($LASTEXITCODE -eq 0) { 'PASS \u2705' } else { 'FAIL \u274c' }\n          $report += \"\u2502 RESULT: $result \u2502\"\n          $report += \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\"\n          $report += \"\"\n          $report += \"If this passed:\"\n          $report += \"  \u2705 All required dependencies are installed\"\n          $report += \"  \u2705 python_service.main is importable\"\n          $report += \"  \u2705 FastAPI app is accessible\"\n          $report += \"  \u2705 The executable should work\"\n          $report += \"  \u2705 Uvicorn WILL be able to load the app\"\n          $report += \"\"\n          $report += \"If this failed:\"\n          $report += \"  \u274c See error output above for the exact problem\"\n          $report += \"  \u274c Fix the import error in your code\"\n          $report += \"  \u274c Common issues:\"\n          $report += \"     - Missing dependency in requirements.txt\"\n          $report += \"     - Syntax error in api.py or main.py\"\n          $report += \"     - Circular import in api.py\"\n          $report += \"     - api.py imports a module that fails\"\n          $report += \"\"\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report | Tee-Object \"asgi-diagnostic-report.txt\"\n\n      - name: \ud83d\udce4 Upload Diagnostic Artifacts\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: asgi-import-diagnostics-${{ github.run_id }}\n          path: |\n            install-requirements.log\n            installed-packages.txt\n            pip-freeze.txt\n            asgi-diagnostic-report.txt\n          retention-days: 30\n          if-no-files-found: warn\n",
    ".github/workflows/build-monolith-final.yml": "name: Build Monolith (Final)\n\non:\n  push:\n    branches: [ main ]\n  workflow_dispatch:\n\njobs:\n  build:\n    name: 'Build Fortuna Monolith'\n    runs-on: windows-latest\n\n    steps:\n      - name: \ud83d\udce5 Checkout\n        uses: actions/checkout@v4\n\n      # ========== FRONTEND ==========\n      - name: \ud83c\udfa8 Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n\n      - name: \ud83e\uddf9 Clean Previous Builds\n        working-directory: ./web_service/frontend\n        shell: pwsh\n        run: |\n          Remove-Item -Path \"public\" -Recurse -Force -ErrorAction SilentlyContinue\n          Remove-Item -Path \".next\" -Recurse -Force -ErrorAction SilentlyContinue\n          Write-Host \"\u2705 Cleaned\"\n\n      - name: \ud83d\udccb Check Next.js Config\n        working-directory: ./web_service/frontend\n        shell: pwsh\n        run: |\n          Write-Host \"Checking package.json...\"\n          if (Test-Path \"package.json\") {\n            $pkg = Get-Content package.json | ConvertFrom-Json\n            Write-Host \"  name: $($pkg.name)\"\n            Write-Host \"  build: $($pkg.scripts.build)\"\n          } else {\n            Write-Error \"package.json not found!\"\n            exit 1\n          }\n\n      - name: \ud83c\udfd7\ufe0f Build Frontend\n        working-directory: ./web_service/frontend\n        shell: pwsh\n        run: |\n          Write-Host \"=== BUILDING FRONTEND ===\" -ForegroundColor Cyan\n\n          # Create/verify next.config.js\n          $configLines = @(\n            \"/** @type {import('next').NextConfig} */\",\n            \"const nextConfig = {\",\n            \"  output: 'export',\",\n            \"  distDir: 'build',\",\n            \"  images: { unoptimized: true },\",\n            \"  trailingSlash: true,\",\n            \"}\",\n            \"module.exports = nextConfig\"\n          )\n          $configContent = $configLines -join [System.Environment]::NewLine\n          Set-Content -Path \"next.config.js\" -Value $configContent -Encoding UTF8\n          Write-Host \"\u2705 next.config.js set for 'build' directory output\"\n\n          Write-Host \"Installing dependencies...\"\n          npm install --legacy-peer-deps\n          if ($LASTEXITCODE -ne 0) {\n            Write-Error \"npm install failed\"\n            exit 1\n          }\n\n          Write-Host \"Building...\"\n          npm run build\n          if ($LASTEXITCODE -ne 0) {\n            Write-Error \"npm run build failed\"\n            exit 1\n          }\n\n          Write-Host \"Moving build artifacts to 'public'...\"\n          New-Item -ItemType Directory -Force -Path \"public\" | Out-Null\n          Move-Item -Path \"build/*\" -Destination \"public\" -Force\n          if ($LASTEXITCODE -ne 0) {\n            Write-Error \"Failed to move build artifacts\"\n            exit 1\n          }\n          Write-Host \"\u2705 Artifacts moved.\"\n\n          # Verify output\n          Write-Host \"`nVerifying output...\"\n          if (-not (Test-Path \"public\")) {\n            Write-Host \"\u274c 'public' directory not found!\" -ForegroundColor Red\n            Write-Host \"Contents of current dir:\"\n            Get-ChildItem | Format-Table Name\n            exit 1\n          }\n\n          if (-not (Test-Path \"public/index.html\")) {\n            Write-Host \"\u274c public/index.html not found!\" -ForegroundColor Red\n            Write-Host \"Contents of 'public':\"\n            Get-ChildItem -Path \"public\" -Recurse | Format-Table Name\n            exit 1\n          }\n\n          $count = (Get-ChildItem -Path \"public\" -Recurse -File).Count\n          Write-Host \"\u2705 Frontend built: $count files\" -ForegroundColor Green\n\n      # ========== BACKEND ==========\n      - name: \ud83d\udc0d Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n          cache-dependency-path: 'web_service/backend/requirements.txt'\n\n      - name: \ud83d\udce6 Install Python Dependencies\n        shell: pwsh\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install pyinstaller==6.6.0\n          pip install pywin32 # CRITICAL: Provides the 'win32timezone' hidden import\n          pip install -r web_service/backend/requirements.txt\n\n      - name: \ud83d\udcc2 Create Data Directories\n        shell: pwsh\n        run: |\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/data\" | Out-Null\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/json\" | Out-Null\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/logs\" | Out-Null\n\n      # ========== BUILD ==========\n      - name: \ud83d\udd28 Build with PyInstaller\n        shell: pwsh\n        run: |\n          Write-Host \"=== BUILDING MONOLITH ===\" -ForegroundColor Cyan\n\n          # Final verification\n          if (-not (Test-Path \"web_service/frontend/public/index.html\")) {\n            Write-Error \"\u274c Frontend not ready!\"\n            Write-Host \"Frontend path check:\"\n            Test-Path \"web_service/frontend/public\"\n            Test-Path \"web_service/frontend/public/index.html\"\n            exit 1\n          }\n\n          Write-Host \"\u2705 Frontend verified\"\n          Write-Host \"Running PyInstaller...\"\n\n          pyinstaller --noconfirm --clean fortuna-desktop.spec 2>&1 | Tee-Object -FilePath \"build.log\"\n\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"Last 100 lines of build.log:\" -ForegroundColor Red\n            Get-Content \"build.log\" -Tail 100\n            exit 1\n          }\n\n          $exe = \"dist/Fortuna-Desktop/Fortuna-Desktop.exe\"\n          if (Test-Path $exe) {\n            $mb = (Get-Item $exe).Length / 1MB\n            Write-Host \"\u2705 BUILD SUCCESS: $([math]::Round($mb, 2)) MB\" -ForegroundColor Green\n          } else {\n            Write-Error \"EXE not created!\"\n            exit 1\n          }\n\n      # ========== PACKAGE & UPLOAD ==========\n      - name: \ud83d\udce6 Package Artifact for Distribution\n        shell: pwsh\n        run: |\n          $distDir = \"dist/Fortuna-Desktop\"\n          Write-Host \"=== PACKAGING ARTIFACT ===\" -ForegroundColor Cyan\n\n          # Create README.txt\n          $readmeLines = @(\n            'Fortuna Desktop - User Guide',\n            '',\n            '**HOW TO RUN**',\n            '1. Double-click \"Fortuna-Desktop.exe\".',\n            '2. The application window will open and the dashboard will load.',\n            '',\n            '**WHAT TO EXPECT**',\n            '- To stop the application, simply close the window.'\n          )\n          $readmeLines | Out-File -FilePath \"$distDir/README.txt\" -Encoding utf8\n          Write-Host \"\u2705 Created README.txt\"\n\n          # Create ZIP archive\n          $zipFileName = \"Fortuna-Desktop-Windows-${{ github.run_number }}.zip\"\n          Compress-Archive -Path \"$distDir/*\" -DestinationPath $zipFileName -Force\n          Write-Host \"\u2705 Created $zipFileName\" -ForegroundColor Green\n\n      - name: \ud83d\udce4 Upload Packaged Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: Fortuna-Desktop-Windows-${{ github.run_number }}\n          path: Fortuna-Desktop-Windows-${{ github.run_number }}.zip\n          if-no-files-found: error\n\n      # ========== TEST ==========\n      - name: Install VC++ Redistributable\n        shell: pwsh\n        run: |\n          # Download and install VC++ Runtime\n          $url = \"https://aka.ms/vs/17/release/vc_redist.x64.exe\"\n          Invoke-WebRequest -Uri $url -OutFile vc_redist.x64.exe\n          .\\vc_redist.x64.exe /install /quiet /norestart\n          Start-Sleep -Seconds 5\n          Get-Command vc_redist.x64.exe -ErrorAction SilentlyContinue\n\n      - name: \ud83e\uddea Smoke Test\n        shell: pwsh\n        timeout-minutes: 5\n        run: |\n          Write-Host \"=== SMOKE TEST ===\" -ForegroundColor Cyan\n          $exe = \"dist/Fortuna-Desktop/Fortuna-Desktop.exe\"\n          \n          # 1. Launch App\n          Write-Host \"\ud83d\ude80 Launching $exe...\"\n          $process = Start-Process -FilePath $exe -PassThru\n          $pid = $process.Id\n          Write-Host \"   PID: $pid\"\n          \n          # 2. Wait & Check Health\n          $url = \"http://127.0.0.1:8000/api/health\"\n          $maxRetries = 20\n          $success = $false\n          \n          for ($i=1; $i -le $maxRetries; $i++) {\n            if ($process.HasExited) {\n              Write-Error \"\u274c Process crashed immediately! Exit Code: $($process.ExitCode)\"\n              break\n            }\n            try {\n              $resp = Invoke-WebRequest -Uri $url -UseBasicParsing -TimeoutSec 2\n              if ($resp.StatusCode -eq 200) {\n                Write-Host \"\u2705 Backend is HEALTHY!\" -ForegroundColor Green\n                $success = $true\n                break\n              }\n            } catch {\n              Write-Host \"   Ping failed ($i/$maxRetries)...\"\n              Start-Sleep -Seconds 2\n            }\n          }\n          \n          # 3. Cleanup\n          if (-not $process.HasExited) {\n            Stop-Process -Id $pid -Force\n          }\n          \n          # 4. Diagnostics (If Failed)\n          if (-not $success) {\n            Write-Host \"\u274c SMOKE TEST FAILED\" -ForegroundColor Red\n            \n            # Check for the log file created by run_desktop_app.py\n            $logPath = \"$env:TEMP\\fortuna-desktop.log\"\n            if (Test-Path $logPath) {\n              Write-Host \"--- APPLICATION LOG ($logPath) ---\" -ForegroundColor Yellow\n              Get-Content $logPath\n              Write-Host \"----------------------------------\"\n            } else {\n              Write-Host \"\u26a0\ufe0f No application log found at $logPath\"\n            }\n            exit 1\n          }\n          Write-Host \"\u2705 Test Complete.\"\n\n      - name: \ud83d\udccb Upload Build Log\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: build-log-${{ github.run_number }}\n          path: build.log\n          if-no-files-found: ignore\n",
    ".python-version": "3.10\n",
    "JSON_BACKUP_MANIFEST.md": "# Checkmate Ultimate Solo: JSON Backup Manifest (Total Recall Edition)\n\n**Purpose:** To provide a single, complete, and verified list of direct links to the JSON backups of all CORE and Operational files. This is the definitive entry point for external AI code review.\n\n---\n\n## 1.0 CORE Architecture (JSON Backups)\n\n### Python Backend\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/api.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/engine.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/models.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/__init__.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/base.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/utils.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/betfair_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/pointsbet_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/racing_and_sports_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/tvg_adapter.py.json\n\n### TypeScript Frontend\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/package.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/package-lock.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/next.config.mjs.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/tailwind.config.ts.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/tsconfig.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/page.tsx.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/layout.tsx.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/globals.css.json\n\n---\n\n## 2.0 Operational & Tooling (JSON Backups)\n\n### Project Tooling\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/.gitignore.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/convert_to_json.py.json\n\n### Environment & Setup\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/setup_windows.bat.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/.env.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/requirements.txt.json\n\n### Strategic Blueprints\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/README.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/ARCHITECTURAL_MANDATE.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/HISTORY.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/STATUS.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/WISDOM.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/PROJECT_MANIFEST.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/ROADMAP_APPENDICES.md.json",
    "README_WINDOWS.md": "# \ud83d\udc34 Fortuna Faucet - User Guide for Windows\n\nWelcome to Fortuna Faucet! This guide provides simple, step-by-step instructions to get you up and running.\n\n## Installation\n\nInstalling the application is a straightforward process using our official installer.\n\n1.  **Download the Installer:**\n    *   Go to the [**Latest Release Page**](https://github.com/masonj0/fortuna/releases/latest) on GitHub.\n    *   Download the file ending in `.msi` (e.g., `JBMason's 1st App-X.X.X.msi`).\n\n2.  **Run the Installer:**\n    *   Double-click the downloaded `.msi` file to launch the setup wizard.\n    *   Follow the on-screen instructions to complete the installation.\n\n## What to Expect After Installation\n\nOnce the setup is complete, you will find a new folder in your Start Menu named **\"JBMason's 1st App\"**.\n\n*   **Launching the App:** Inside this folder, click on the **\"JBMason's 1st App\"** shortcut to start the application.\n*   **How it Works:** The shortcut launches the main application window (the dashboard). The backend data engine starts automatically in the background and will close when you exit the application.\n\nThat's it! All previous installation methods are now obsolete. Enjoy using the application!\n",
    "USER_GUIDE.MD": "# Fortuna Faucet - User Guide\n\nThis document provides instructions for users of the Fortuna Faucet application.\n\n## Installation\n\n1.  Download the `Fortuna-Faucet-Installer.msi` file from the latest release.\n2.  Run the installer and follow the on-screen instructions.\n3.  The application will be installed to `C:\\Program Files\\Fortuna Faucet` by default.\n\n## Usage\n\n1.  Launch the application from the Start Menu or desktop shortcut.\n2.  The main window will display the live race dashboard.\n3.  Use the settings page to configure your preferences.\n",
    "debug_installer.ps1": "# 1. Get the location of this script\n$currentDir = $PSScriptRoot\n\n# 2. Find all .msi files in this folder\n$msiFiles = Get-ChildItem -Path $currentDir -Filter \"*.msi\"\n\n# 3. Validate we found exactly one MSI\nif ($msiFiles.Count -eq 0) {\n    Write-Host \"\u274c Error: No MSI files found in $currentDir\" -ForegroundColor Red\n    Read-Host \"Press Enter to exit...\"\n    Exit\n}\nif ($msiFiles.Count -gt 1) {\n    Write-Host \"\u274c Error: Multiple MSI files found. I don't know which one to run:\" -ForegroundColor Red\n    $msiFiles | ForEach-Object { Write-Host \" - $($_.Name)\" }\n    Read-Host \"Press Enter to exit...\"\n    Exit\n}\n\n# 4. Set up file paths\n$targetMsi = $msiFiles[0].FullName\n$logFile = Join-Path -Path $currentDir -ChildPath \"install_debug.log\"\n\nWrite-Host \"------------------------------------------------\" -ForegroundColor Cyan\nWrite-Host \"\ud83d\ude80 Target Found: $($msiFiles[0].Name)\" -ForegroundColor Green\nWrite-Host \"\ud83d\udcdd Log File:     $logFile\" -ForegroundColor Yellow\nWrite-Host \"------------------------------------------------\" -ForegroundColor Cyan\n\n# 5. Run MSIEXEC\n# /i   = Install\n# /L*v = Log all information (Verbose)\ntry {\n    Start-Process -FilePath \"msiexec.exe\" -ArgumentList \"/i `\"$targetMsi`\" /L*v `\"$logFile`\"\" -Wait\n    Write-Host \"\u2705 Installer finished.\" -ForegroundColor Green\n}\ncatch {\n    Write-Host \"\u274c Failed to launch msiexec.\" -ForegroundColor Red\n    Write-Error $_\n}\n\n# 6. Pause so you can read the output\nRead-Host \"Press Enter to close this window...\"\n",
    "e2e/jules-smoke-test.py": "import asyncio\nfrom playwright.async_api import async_playwright, expect\n\nasync def main():\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        page = await browser.new_page()\n        try:\n            await page.goto(\"http://127.0.0.1:8000\")\n            await expect(page.get_by_test_id(\"main-heading\")).to_be_visible()\n        finally:\n            await page.screenshot(path=\"playwright-screenshot.png\")\n            await browser.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
    "electron/resources/.gitkeep": "",
    "file_version_info.txt": "# UTF-8\n#\n# For more details about fixed file info 'ffi' see:\\\n# http://msdn.microsoft.com/en-us/library/ms646997.aspx\nVSVersionInfo(\n  ffi=FixedFileInfo(\n    # filevers and prodvers should be always a tuple with four items: (1, 2, 3, 4)\n    # Set not needed items to zero 0.\n    filevers=(1, 0, 0, 0),\n    prodvers=(1, 0, 0, 0),\n    # Contains a bitmask that specifies the valid bits 'flags'r\n    mask=0x3f,\n    # Contains a bitmask that specifies the Boolean attributes of the file.\n    flags=0x0,\n    # The operating system for which this file was designed.\n    # 0x4 - NT and there is no need to change it.\n    OS=0x40004,\n    # The general type of file.\n    # 0x1 - application\n    fileType=0x1,\n    # The function of the file.\n    # 0x0 - the function is not defined for this fileType\n    subtype=0x0,\n    # Creation date and time stamp.\n    date=(0, 0)\n    ),\n  kids=[\n    StringFileInfo(\n      [\n      StringTable(\n        '000004b0',\n        [StringStruct('CompanyName', 'Fortuna Technologies'),\n        StringStruct('FileDescription', 'Fortuna Faucet - Racing Analysis Engine'),\n        StringStruct('FileVersion', '1.0.0.0'),\n        StringStruct('InternalName', 'Fortuna-WebService'),\n        StringStruct('LegalCopyright', '\u00a9 2026 Fortuna Technologies. All rights reserved.'),\n        StringStruct('OriginalFilename', 'Fortuna-WebService.exe'),\n        StringStruct('ProductName', 'Fortuna Faucet'),\n        StringStruct('ProductVersion', '1.0.0.0')])\n      ]),\n    VarFileInfo([VarStruct('Translation', [1033, 1200])])\n  ]\n)",
    "fortuna-backend-hooks/hook-tenacity.py": "\"\"\"\nPyInstaller hook for tenacity.\n\nTenacity uses dynamic imports for async support and retry strategies that\nPyInstaller cannot automatically detect. This hook ensures all tenacity\nsubmodules are collected into the bundle.\n\nThis is especially critical for tenacity 8.2.3+ which includes async retry support.\n\"\"\"\n\nfrom PyInstaller.utils.hooks import collect_submodules\n\n# Collect all tenacity submodules recursively\nhiddenimports = collect_submodules('tenacity')\n\n# Explicitly add critical submodules that might be missed\n# These are the modules tenacity dynamically imports for retry strategies and async support\ncritical_submodules = [\n    'tenacity.retry',\n    'tenacity.stop',\n    'tenacity.wait',\n    'tenacity.retry_if_result',\n    'tenacity.retry_if_exception',\n    'tenacity.before_sleep',\n    'tenacity.after',\n    'tenacity.before',\n    'tenacity.retry_error',\n    'tenacity.compat',\n    'tenacity.future',\n    'tenacity.asyncio',  # Critical for async retry support\n]\n\n# Merge and deduplicate\nhiddenimports = list(set(hiddenimports + critical_submodules))\n",
    "fortuna-desktop-tinyfield.spec": "# fortuna-desktop.spec\n# This spec file is for creating a windowed, GUI-based application\n# using pywebview. It is based on fortuna-monolith.spec.\n\nfrom PyInstaller.utils.hooks import collect_submodules\nfrom pathlib import Path\nimport sys\nimport os\n\nblock_cipher = None\n\n# ===== GET PROJECT ROOT =====\nspec_path = Path(SPECPATH) if 'SPECPATH' in dir() else Path(os.path.dirname(os.path.abspath(__file__)))\nproject_root = spec_path.parent if spec_path.name == 'fortuna-desktop-tinyfield.spec' else spec_path\n\n# ===== FRONTEND VALIDATION =====\nfrontend_out = project_root / 'web_service' / 'frontend' / 'public'\nif not frontend_out.exists() or not (frontend_out / 'index.html').exists():\n    print(\"[ERROR] FATAL: Frontend 'public' directory with index.html not found!\")\n    sys.exit(1)\n\n# ===== BACKEND VALIDATION =====\nbackend_root = project_root / 'web_service' / 'backend'\nmain_script = project_root / 'run_desktop_app.py'\nif not main_script.exists():\n    print(f\"[ERROR] FATAL: Main script not found at {main_script}!\")\n    sys.exit(1)\n\n# ===== DATA FILES =====\ndatas = [\n    (str(frontend_out), 'public')\n]\n\n# ===== HIDDEN IMPORTS =====\nhiddenimports = list(set(\n    collect_submodules('web_service.backend') +\n    [\n        'uvicorn', 'uvicorn.logging', 'uvicorn.loops', 'uvicorn.loops.auto',\n        'uvicorn.protocols', 'uvicorn.protocols.http', 'uvicorn.protocols.http.auto',\n        'uvicorn.protocols.http.h11_impl', 'uvicorn.lifespan', 'uvicorn.lifespan.on',\n        'fastapi', 'starlette', 'pydantic', 'anyio', 'structlog', 'tenacity',\n        'sqlalchemy', 'greenlet', 'win32timezone'\n    ]\n))\n\n# ===== ANALYSIS =====\na = Analysis(\n    [str(main_script)],\n    pathex=[str(project_root), str(backend_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    cipher=block_cipher,\n    noarchive=False,\n)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\n# ===== BUILD EXECUTABLE (WINDOWED) =====\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.zipfiles, a.datas, [],\n    name='Fortuna-Desktop-TinyField',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    runtime_tmpdir=None,\n    console=False,  # This creates a windowed application\n    disable_windowed_traceback=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n    icon=None # Consider adding an icon here later\n)\n\ncoll = COLLECT(\n    exe, a.binaries, a.zipfiles, a.datas,\n    strip=False,\n    upx=True,\n    name='Fortuna-Desktop-TinyField'\n)\n",
    "podman-compose.yml": "version: '3.8'\n\nservices:\n  fortuna:\n    build: .\n    container_name: fortuna-faucet\n    ports:\n      - \"8000:8000\"\n    environment:\n      - PYTHONUNBUFFERED=1\n      - FORTUNA_MODE=podman\n    volumes:\n      - ./web_service/backend/data:/app/web_service/backend/data\n      - ./web_service/backend/logs:/app/web_service/backend/logs\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 5s\n",
    "pyproject.toml": "[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"paddock-parser-ng\"\nversion = \"0.1.0\"\ndescription = \"A toolkit to identify the best racecards for betting.\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\n\n[project.scripts]\npaddock_parser_ui = \"paddock_parser.entry_points:run_terminal_ui\"\npaddock_parser_dashboard = \"paddock_parser.entry_points:run_dashboard\"\npaddock_parser_predict = \"paddock_parser.entry_points:run_prediction_engine\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n\n# Configuration for the Ruff linter\n[tool.ruff]\n# Allow lines to be up to 120 characters long.\nline-length = 120\n\n[tool.ruff.lint]\n# Enable Pyflakes (F), pycodestyle (E, W), and isort (I) rules.\nselect = [\"E\", \"F\", \"W\", \"I\"]\nignore = []\n\n[tool.ruff.lint.isort]\n# Sort imports within their sections alphabetically.\nforce-single-line = true\n",
    "run_desktop_app.py": "import sys\nimport os\nimport threading\nimport logging\nimport traceback\nfrom pathlib import Path\n\n# --- 1. SETUP LOGGING (CRITICAL FOR DEBUGGING) ---\ndef setup_logging():\n    # Log to %TEMP% so we can retrieve it if the app crashes\n    log_dir = Path(os.environ.get(\"TEMP\", \".\"))\n    log_file = log_dir / \"fortuna-desktop.log\"\n    \n    logging.basicConfig(\n        filename=log_file,\n        level=logging.DEBUG,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        filemode='w'\n    )\n    \n    # Also print to console for dev mode\n    console = logging.StreamHandler()\n    console.setLevel(logging.DEBUG)\n    logging.getLogger('').addHandler(console)\n    return logging.getLogger(__name__)\n\nlogger = setup_logging()\n\n# --- 2. ROBUST IMPORTS ---\ntry:\n    import uvicorn\n    import webview\n    from fastapi import FastAPI\n    from fastapi.staticfiles import StaticFiles\n    from fastapi.middleware.cors import CORSMiddleware\nexcept Exception as e:\n    logger.critical(f\"Failed to import core dependencies: {e}\\n{traceback.format_exc()}\")\n    sys.exit(1)\n\n# --- 3. DEFINE APP ---\ndef create_app():\n    app = FastAPI()\n    app.add_middleware(CORSMiddleware, allow_origins=[\"*\"], allow_methods=[\"*\"], allow_headers=[\"*\"])\n\n    # Health Check (Used by CI Smoke Test)\n    @app.get(\"/api/health\")\n    def health():\n        return {\"status\": \"ok\", \"mode\": \"desktop\"}\n\n    # Try to load real backend\n    try:\n        # Lazy import to prevent crash if backend deps are missing\n        from web_service.backend.api import router as api_router\n        app.include_router(api_router, prefix=\"/api\")\n        logger.info(\"Loaded Backend API\")\n    except Exception as e:\n        logger.warning(f\"Could not load Backend API: {e}\")\n        @app.get(\"/api/error\")\n        def api_error(): return {\"error\": str(e)}\n\n    return app\n\n# --- 4. ASSET PATHS ---\ndef get_asset_path():\n    # PyInstaller unpacks data to _MEIPASS\n    if hasattr(sys, '_MEIPASS'):\n        return Path(sys._MEIPASS) / 'public'\n    # Dev mode path\n    return Path(__file__).parent / 'web_service' / 'frontend' / 'public'\n\n# --- 5. SERVER THREAD ---\ndef start_server(app, port):\n    try:\n        # Mount Frontend\n        static_dir = get_asset_path()\n        if static_dir.exists():\n            app.mount(\"/\", StaticFiles(directory=str(static_dir), html=True), name=\"static\")\n            logger.info(f\"Serving frontend from {static_dir}\")\n        else:\n            logger.error(f\"Frontend not found at {static_dir}\")\n\n        logger.info(f\"Starting Uvicorn on port {port}\")\n        uvicorn.run(app, host=\"127.0.0.1\", port=port, log_level=\"info\")\n    except Exception as e:\n        logger.critical(f\"Server crashed: {e}\\n{traceback.format_exc()}\")\n\nif __name__ == '__main__':\n    try:\n        if sys.platform == 'win32':\n            import multiprocessing\n            multiprocessing.freeze_support()\n\n        port = 8000\n        app = create_app()\n        \n        # Start Backend Thread\n        t = threading.Thread(target=start_server, args=(app, port), daemon=True)\n        t.start()\n\n        # Start GUI\n        logger.info(\"Launching WebView...\")\n        webview.create_window(\"Fortuna Faucet\", f\"http://127.0.0.1:{port}\", width=1280, height=800)\n        webview.start()\n        logger.info(\"App closed normally.\")\n\n    except Exception as e:\n        logger.critical(f\"Fatal Crash: {e}\\n{traceback.format_exc()}\")\n        sys.exit(1)",
    "scripts/audit_rebranding.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Rebranding Audit Script\n# ==============================================================================\n# This script performs a comprehensive, read-only audit of the project to\n# identify all files containing legacy branding terms.\n# ==============================================================================\n\nimport os\n\n# --- CONFIGURATION ---\nTARGET_TERMS = [\"checkmate\", \"solo\"]\nEXCLUDED_DIRS = [\n    \".git\",\n    \".venv\",\n    \"node_modules\",\n    \"build\",\n    \"dist\",\n    \"__pycache__\",\n    \"ReviewableJSON\",\n]\nEXCLUDED_FILES = [\"audit_rebranding.py\", \"REBRANDING_AUDIT.md\"]\nOUTPUT_FILE = \"REBRANDING_AUDIT.md\"\n# -------------------\n\n\ndef search_file_for_terms(file_path, terms):\n    \"\"\"Searches a single file for a list of terms, case-insensitively.\"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            content = f.read().lower()\n            for term in terms:\n                if term in content:\n                    return True\n    except Exception as e:\n        print(f\"[WARNING] Could not read file {file_path}: {e}\")\n    return False\n\n\ndef main():\n    \"\"\"Main orchestrator for the audit.\"\"\"\n    print(\"--- Starting Rebranding Audit ---\")\n    affected_files = []\n    for root, dirs, files in os.walk(\".\", topdown=True):\n        # Exclude specified directories\n        dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS]\n\n        for filename in files:\n            if filename in EXCLUDED_FILES:\n                continue\n\n            file_path = os.path.join(root, filename)\n\n            # Check filename itself\n            if any(term in filename.lower() for term in TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in filename: {file_path}\")\n                continue  # No need to search content if filename matches\n\n            # Check file content\n            if search_file_for_terms(file_path, TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in content: {file_path}\")\n\n    print(f\"\\n--- Audit Complete. Found {len(affected_files)} affected files. ---\")\n\n    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"# Fortuna Faucet: Rebranding Audit Report\\n\\n\")\n        f.write(\"This report lists all files containing legacy branding terms (`checkmate`, `solo`).\\n\\n---\\n\\n\")\n        if affected_files:\n            for file_path in sorted(affected_files):\n                f.write(f\"- `{file_path.replace(os.sep, '/')}`\\n\")\n        else:\n            f.write(\"No files with legacy branding were found.\\n\")\n\n    print(f\"[SUCCESS] Report written to {OUTPUT_FILE}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/fortuna-quick-start.ps1": "<#\n.SYNOPSIS\n    Fortuna Supreme Developer Bootstrapper (v2.0)\n    Aligns with CI/CD 'Champion' workflows for robust local development.\n\n.DESCRIPTION\n    - Auto-detects and kills blocking processes on ports 8000/3000\n    - Validates Python/Node environments\n    - Installs dependencies using fast caching strategies (npm ci)\n    - Launches Backend (FastAPI) and Frontend (Next.js) in parallel\n\n.PARAMETER Clean\n    Removes build artifacts and caches (.next, __pycache__, etc.) before starting.\n\n.PARAMETER Production\n    Builds the frontend for production instead of running in dev mode.\n\n.PARAMETER NoFrontend\n    Launches only the backend API.\n#>\n\nparam(\n    [switch]$SkipChecks,\n    [switch]$NoFrontend,\n    [switch]$Production,\n    [switch]$Clean,\n    [switch]$Help,\n    [string]$PythonExecutable\n)\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Configuration ---\n$PROJECT_ROOT = Resolve-Path \"$PSScriptRoot\\..\"\n$BACKEND_DIR  = Join-Path $PROJECT_ROOT \"web_service\\backend\"\n$FRONTEND_DIR = Join-Path $PROJECT_ROOT \"web_service\\frontend\"\n$PYTHON_CMD   = if ($PythonExecutable) { $PythonExecutable } else { \"py -3.11\" }\n\n# --- Helper Functions ---\nfunction Show-Step($msg) { Write-Host \"`n\ud83d\udd35 $msg\" -ForegroundColor Cyan }\nfunction Show-Success($msg) { Write-Host \"   \u2705 $msg\" -ForegroundColor Green }\nfunction Show-Warn($msg) { Write-Host \"   \u26a0\ufe0f  $msg\" -ForegroundColor Yellow }\nfunction Show-Fail($msg) { Write-Host \"   \u274c $msg\" -ForegroundColor Red; exit 1 }\n\nfunction Clear-BuildCache {\n    Show-Step \"Cleaning build caches (-Clean active)...\"\n    $paths = @(\n        (Join-Path $FRONTEND_DIR \".next\"),\n        (Join-Path $FRONTEND_DIR \"node_modules\\.cache\"),\n        (Join-Path $BACKEND_DIR \"__pycache__\"),\n        (Join-Path $BACKEND_DIR \"*.spec\")\n    )\n    foreach ($p in $paths) {\n        if (Test-Path $p) {\n            Remove-Item -Path $p -Recurse -Force -ErrorAction SilentlyContinue\n            Write-Host \"   Deleted: $p\" -ForegroundColor Gray\n        }\n    }\n    Show-Success \"Cache cleared.\"\n}\n\nfunction Check-Port($port, $name) {\n    $process = Get-NetTCPConnection -LocalPort $port -State Listen -ErrorAction SilentlyContinue | Select-Object -ExpandProperty OwningProcess -Unique\n    if ($process) {\n        Show-Warn \"Port $port ($name) is blocked by PID $process. Killing it...\"\n        Stop-Process -Id $process -Force\n        Show-Success \"Port $port freed.\"\n    }\n}\n\n# --- Main Execution ---\n\nWrite-Host \"`n\ud83d\ude80 FORTUNA SUPREME BOOTSTRAPPER\" -ForegroundColor Magenta\nWrite-Host \"=================================\" -ForegroundColor Gray\n\nif ($Help) { Get-Help $PSCommandPath -Detailed; exit }\nif ($Clean) { Clear-BuildCache }\n\n# 1. Pre-flight Checks\nif (-not $SkipChecks) {\n    Show-Step \"System Health Check\"\n    Check-Port 8000 \"Backend API\"\n    Check-Port 3000 \"Frontend UI\"\n}\n\n# 2. Backend Setup\nShow-Step \"Preparing Backend (Python)...\"\nif (-not (Test-Path $BACKEND_DIR)) { Show-Fail \"Backend directory not found at: $BACKEND_DIR\" }\n\n# Check for Python\ntry {\n    & $PYTHON_CMD --version\n    Show-Success \"Python executable found.\"\n} catch {\n    Show-Fail \"Python not found in PATH or specified executable is invalid.\"\n}\n\n# Upgrade Pip & Wheel\nWrite-Host \"   Upgrading pip/wheel...\" -NoNewline\n& $PYTHON_CMD -m pip install --upgrade pip wheel --quiet\nWrite-Host \" Done.\" -ForegroundColor Green\n\n# Verify Critical Imports\nWrite-Host \"   Verifying dependencies...\" -NoNewline\n$testImport = & $PYTHON_CMD -c \"import fastapi, uvicorn, structlog; print('OK')\" 2>$null\nif ($testImport -match \"OK\") {\n    Write-Host \" OK (Skipping install)\" -ForegroundColor Green\n} else {\n    Write-Host \" Missing.\" -ForegroundColor Yellow\n    Show-Warn \"Installing requirements from requirements.txt...\"\n    Push-Location $BACKEND_DIR\n    & $PYTHON_CMD -m pip install -r requirements.txt\n    Pop-Location\n}\n\n# 3. Frontend Setup\nif (-not $NoFrontend) {\n    Show-Step \"Preparing Frontend (Node.js)...\"\n    if (-not (Test-Path $FRONTEND_DIR)) { Show-Fail \"Frontend directory not found at: $FRONTEND_DIR\" }\n\n    Push-Location $FRONTEND_DIR\n\n    # Smart Install (npm ci vs install)\n    if (Test-Path \"node_modules\") {\n        Show-Success \"Node modules present.\"\n    } else {\n        Show-Warn \"Installing dependencies (npm ci)...\"\n        npm ci --silent\n    }\n\n    # Production Build Logic\n    if ($Production) {\n        Show-Step \"Building for Production...\"\n        npm run build\n        Show-Success \"Production build complete.\"\n    }\n\n    Pop-Location\n}\n\n# 4. Launch Sequence\nShow-Step \"Launching Services...\"\n\n# In CI, we need to use Start-Job to get process output and add a wait\n# loop to ensure the service is ready before tests run.\nif ($env:CI) {\n    Show-Warn \"CI environment detected. Using Start-Job for backend...\"\n    $job = Start-Job -ScriptBlock {\n        # This script block runs in a separate process\n        param($path, $cmd)\n        Set-Location $path\n        & $cmd -m uvicorn main:app --port 8000 --host 0.0.0.0\n    } -ArgumentList $BACKEND_DIR, $PYTHON_CMD\n\n    Show-Success \"Backend job started (Job ID: $($job.Id))\"\n\n    # Wait for the backend to become healthy (up to 30 seconds)\n    $healthCheckUrl = \"http://localhost:8000/health\"\n    Write-Host \"   Pinging backend health endpoint ($healthCheckUrl)...\" -NoNewline\n    $timeout = 30\n    $start = Get-Date\n    $healthy = $false\n    while ((Get-Date) -lt $start.AddSeconds($timeout)) {\n        try {\n            $response = Invoke-WebRequest -Uri $healthCheckUrl -UseBasicParsing -TimeoutSec 2\n            if ($response.StatusCode -eq 200) {\n                Write-Host \" OK\" -ForegroundColor Green\n                Show-Success \"Backend is healthy and responding.\"\n                $healthy = $true\n                break\n            }\n        } catch {\n            # Catch exceptions for connection refused, etc.\n        }\n        Start-Sleep -Seconds 1\n        Write-Host \".\" -NoNewline\n    }\n\n    if (-not $healthy) {\n        Write-Host \" FAILED\" -ForegroundColor Red\n        Show-Fail \"Backend did not start within the $timeout-second timeout.\"\n        Receive-Job $job # Display any output from the failed job\n        Stop-Job $job\n        exit 1\n    }\n\n} else {\n    # -- LOCAL DEVELOPMENT (Existing Logic) --\n    $backendScript = \"cd `\"$BACKEND_DIR`\"; & $PYTHON_CMD -m uvicorn main:app --reload --port 8000\"\n    Start-Process pwsh -ArgumentList \"-NoExit\", \"-Command\", $backendScript -WindowStyle Normal\n    Show-Success \"Backend launched on Port 8000\"\n}\n\n# Launch Frontend (No changes needed here for now)\nif (-not $NoFrontend) {\n    if ($env:CI) {\n        # In CI, we would typically build and serve statically, but for this\n        # script's purpose, we'll assume the backend handles the UI\n        Show-Warn \"Frontend launch skipped in CI mode for this script.\"\n    } else {\n        $cmd = if ($Production) { \"start\" } else { \"dev\" }\n        $frontendScript = \"cd `\"$FRONTEND_DIR`\"; npm run $cmd\"\n        Start-Process pwsh -ArgumentList \"-NoExit\", \"-Command\", $frontendScript -WindowStyle Normal\n        Show-Success \"Frontend launched on Port 3000 ($cmd mode)\"\n    }\n}\n\n# Keep script running if interactive, otherwise exit for CI\nif ($env:CI) {\n    Write-Host \"`n\u2728 CI run complete. Exiting.\" -ForegroundColor Cyan\n} else {\n    Write-Host \"`n\u2728 Fortuna is running! Press Ctrl+C in the popup windows to stop.\" -ForegroundColor Cyan\n}\n",
    "scripts/get_api_key.py": "# scripts/get_api_key.py\nimport os\nimport sys\n\n# This is a workaround to ensure the script can find the python_service module,\n# especially when run from the packaged Electron app.\n# It assumes this script is in `resources/app/scripts` and the service is in `resources/app/python_service`.\ntry:\n    # Get the directory of the current script.\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    # Go up one level to the `app` directory and add `python_service` to the path.\n    project_root = os.path.dirname(script_dir)\n    sys.path.append(project_root)\n    from python_service.credentials_manager import SecureCredentialsManager\nexcept ImportError as e:\n    # If the import fails, write the error to stderr and exit.\n    # This helps in debugging path issues in the production environment.\n    print(\n        f\"Error: Failed to import SecureCredentialsManager. Details: {e}\",\n        file=sys.stderr,\n    )\n    sys.exit(1)\n\n\ndef retrieve_and_print_key():\n    \"\"\"\n    Retrieves the API key using the SecureCredentialsManager and prints it to stdout.\n    If the key is not found, it prints an empty string.\n    If an error occurs, it prints the error to stderr.\n    \"\"\"\n    try:\n        api_key = SecureCredentialsManager.get_api_key()\n        if api_key:\n            print(api_key, end=\"\")  # Print the key directly to stdout\n        else:\n            print(\"\", end=\"\")  # Print empty string if no key is found\n    except Exception as e:\n        print(f\"An error occurred while retrieving the API key: {e}\", file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    retrieve_and_print_key()\n",
    "scripts/realtime-race-monitor.ps1": "<#\n.SYNOPSIS\n    Fortuna Real-Time Race Monitor (v1.0)\n    Builds, launches, and queries the backend service to provide live racecard comparisons.\n#>\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Configuration ---\n$PYTHON_VERSION = \"3.11\"\n$BACKEND_DIR    = \"web_service/backend\"\n$SPEC_FILE      = \"fortuna-unified.spec\"\n$SERVICE_PORT   = 8102\n$API_KEY        = \"a_secure_test_api_key_that_is_long_enough\" # Mock key for local execution\n\n# --- Helper Functions ---\nfunction Show-Step($msg) { Write-Host \"`n\ud83d\ude80 $msg\" -ForegroundColor Cyan }\nfunction Show-Success($msg) { Write-Host \"   \u2705 $msg\" -ForegroundColor Green }\nfunction Show-Warn($msg) { Write-Host \"   \u26a0\ufe0f  $msg\" -ForegroundColor Yellow }\nfunction Show-Fail($msg) { Write-Host \"   \u274c $msg\" -ForegroundColor Red; exit 1 }\n\n# --- Main Execution ---\ntry {\n    # 1. Environment Setup & Dependency Installation\n    Show-Step \"Preparing environment...\"\n    try {\n        $pyVer = & python --version 2>&1\n        if ($pyVer -notmatch $PYTHON_VERSION) {\n            Show-Warn \"Python version mismatch. Expected $($PYTHON_VERSION), found $($pyVer).\"\n        }\n        Show-Success \"Found Python: $pyVer\"\n    } catch {\n        Show-Fail \"Python not found. Please ensure Python $($PYTHON_VERSION) is in your PATH.\"\n    }\n\n    Show-Step \"Installing dependencies...\"\n    try {\n        python -m pip install --upgrade pip --quiet\n        pip install -r \"$($BACKEND_DIR)/requirements.txt\"\n        pip install pyinstaller==6.6.0\n        Show-Success \"All Python dependencies are installed.\"\n    } catch {\n        Show-Fail \"Failed to install dependencies. Check logs for details.\"\n    }\n\n\n    # 2. Build the Backend Executable\n    Show-Step \"Building backend executable with PyInstaller...\"\n\n    # Clean previous builds\n    if (Test-Path \"dist\") { Remove-Item -Recurse -Force \"dist\" }\n    if (Test-Path \"build\") { Remove-Item -Recurse -Force \"build\" }\n\n    # PyInstaller requires these directories to exist at build time\n    New-Item -ItemType Directory -Path \"$($BACKEND_DIR)/data\", \"$($BACKEND_DIR)/json\", \"$($BACKEND_DIR)/logs\" -Force | Out-Null\n\n    try {\n        pyinstaller --noconfirm --clean $SPEC_FILE\n        Show-Success \"Backend executable built successfully.\"\n    } catch {\n        Show-Fail \"PyInstaller build failed. See output for details.\"\n    }\n\n    # 3. Launch the Backend Service\n    Show-Step \"Launching backend service...\"\n    $exePath = Resolve-Path \"dist/fortuna-webservice/fortuna-webservice.exe\"\n    if (-not (Test-Path $exePath)) {\n        Show-Fail \"Could not find the built executable at $($exePath).\"\n    }\n\n    # The executable needs its runtime directories in its own folder\n    $exeDir = Split-Path $exePath -Parent\n    New-Item -ItemType Directory -Path \"$($exeDir)/data\", \"$($exeDir)/json\", \"$($exeDir)/logs\" -Force | Out-Null\n    Show-Success \"Created runtime directories in $($exeDir).\"\n\n    # Start the process in the background\n    $process = Start-Process -FilePath $exePath -WindowStyle Hidden -PassThru\n    $Global:BackendProcessId = $process.Id # Store PID for cleanup\n    Show-Success \"Backend service is starting in the background (PID: $($Global:BackendProcessId)).\"\n\n\n    # 4. Health Check & API Query\n    Show-Step \"Waiting for service to become healthy...\"\n    $healthUrl = \"http://localhost:$($SERVICE_PORT)/health\"\n    $maxRetries = 20\n    $retryDelay = 3 # seconds\n\n    for ($i = 0; $i -lt $maxRetries; $i++) {\n        try {\n            $response = Invoke-WebRequest -Uri $healthUrl -UseBasicParsing\n            if ($response.StatusCode -eq 200) {\n                Show-Success \"Service is healthy and responding.\"\n                break\n            }\n        } catch {\n            Write-Host \"   ... waiting ($($i+1)/$($maxRetries))\"\n            Start-Sleep -Seconds $retryDelay\n        }\n        if ($i -eq $maxRetries - 1) {\n            Show-Fail \"Service failed to start within the timeout period.\"\n        }\n    }\n\n    Show-Step \"Querying API for live race data...\"\n    $racesUrl = \"http://localhost:$($SERVICE_PORT)/api/races\"\n    $headers = @{ \"X-API-Key\" = $API_KEY }\n    try {\n        $apiResponse = Invoke-RestMethod -Uri $racesUrl -Headers $headers -Method Get\n        Show-Success \"Successfully fetched data for $($apiResponse.races.Count) races.\"\n    } catch {\n        Show-Fail \"Failed to query the API. Error: $($_.Exception.Message)\"\n    }\n\n\n    # 5. Process and Format Data\n    Show-Step \"Formatting race comparison...\"\n    $now = [datetime]::UtcNow\n    $upcomingRaces = $apiResponse.races | Where-Object { [datetime]$_.startTime -gt $now } | Sort-Object startTime | Select-Object -First 3\n\n    $output = @()\n    $output += \"--- Fortuna Real-Time Race Monitor ---\"\n    $output += \"Generated: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss UTC')\"\n    $output += \"========================================\"\n\n    foreach ($race in $upcomingRaces) {\n        $raceTime = [datetime]$race.startTime\n        $timeToPost = New-TimeSpan -Start $now -End $raceTime\n        $output += \"\"\n        $output += \"$($race.venue) - Race $($race.race_number) ($($raceTime.ToLocalTime().ToString('h:mm tt')))\"\n        $output += \"Starts in: $($timeToPost.Minutes)m $($timeToPost.Seconds)s\"\n        $output += \"----------------------------------------\"\n        $output += \"{0,-25} {1,-15} {2,-15}\" -f \"Runner\", \"Best Odds\", \"Source\"\n        $output += \"{0,-25} {1,-15} {2,-15}\" -f \"-----\", \"---------\", \"------\"\n\n        foreach ($runner in $race.runners) {\n            $bestOdds = $null\n            $bestSource = \"N/A\"\n            if ($runner.odds) {\n                $oddsValues = $runner.odds.psobject.Properties | ForEach-Object { $_.Value }\n                if($oddsValues) {\n                    $best = $oddsValues | Sort-Object win -Descending | Select-Object -First 1\n                    if($best -and $best.win){\n                        $bestOdds = $best.win\n                        $bestSource = $best.source\n                    }\n                }\n            }\n            $output += \"{0,-25} {1,-15} {2,-15}\" -f $runner.name, $bestOdds, $bestSource\n        }\n    }\n\n    $output += \"========================================\"\n\n    # Display the formatted output in the console\n    $output | Out-Host\n\n} finally {\n    # 6. Cleanup\n    Show-Step \"Cleaning up...\"\n    if ($Global:BackendProcessId) {\n        try {\n            Stop-Process -Id $Global:BackendProcessId -Force\n            Show-Success \"Backend service (PID: $($Global:BackendProcessId)) stopped.\"\n        } catch {\n            Show-Warn \"Could not stop backend service (PID: $($Global:BackendProcessId)). It may have already exited.\"\n        }\n    } else {\n        Show-Success \"No backend process to stop.\"\n    }\n}\n",
    "tests/adapters/test_greyhound_adapter.py": "from datetime import date\nfrom datetime import datetime\nfrom unittest.mock import AsyncMock\n\nimport pytest\n\nfrom python_service.adapters.greyhound_adapter import GreyhoundAdapter\nfrom tests.conftest import get_test_settings\n\n\n@pytest.fixture\ndef test_settings():\n    \"\"\"Provides a valid Settings object for testing.\"\"\"\n    return get_test_settings()\n\n\n@pytest.mark.asyncio\nasync def test_get_races_parses_correctly(test_settings):\n    \"\"\"\n    Tests that the GreyhoundAdapter correctly parses a valid API response via get_races.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n\n    mock_api_response = {\n        \"cards\": [\n            {\n                \"track_name\": \"Test Track\",\n                \"races\": [\n                    {\n                        \"race_id\": \"test_race_123\",\n                        \"race_number\": 1,\n                        \"start_time\": int(datetime.now().timestamp()),\n                        \"runners\": [\n                            {\n                                \"dog_name\": \"Rapid Rover\",\n                                \"trap_number\": 1,\n                                \"odds\": {\"win\": \"2.5\"},\n                            },\n                            {\n                                \"dog_name\": \"Swift Sprint\",\n                                \"trap_number\": 2,\n                                \"scratched\": True,\n                            },\n                            {\n                                \"dog_name\": \"Lazy Larry\",\n                                \"trap_number\": 3,\n                                \"odds\": {\"win\": \"10.0\"},\n                            },\n                        ],\n                    }\n                ],\n            }\n        ]\n    }\n    adapter._fetch_data = AsyncMock(return_value=mock_api_response)\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert len(races) == 1\n    race = races[0]\n    assert race.id == \"greyhound_test_race_123\"\n    assert race.venue == \"Test Track\"\n    assert len(race.runners) == 2  # One was scratched\n\n    runner1 = race.runners[0]\n    assert runner1.name == \"Rapid Rover\"\n    assert runner1.number == 1\n    assert runner1.odds[\"Greyhound Racing\"].win == 2.5\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_empty_response(test_settings):\n    \"\"\"\n    Tests that the GreyhoundAdapter handles an empty API response gracefully.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(return_value={\"cards\": []})\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert races == []\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_fetch_failure(test_settings):\n    \"\"\"\n    Tests that get_races returns an empty list when _fetch_data returns None.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(return_value=None)\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert races == []\n",
    "tests/analyzers/test_trifecta_analyzer.py": "# Dedicated test suite for the TrifectaAnalyzer, resurrected and expanded.\nfrom datetime import datetime\n\nimport pytest\n\nfrom python_service.analyzer import TrifectaAnalyzer\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\n\n@pytest.fixture\ndef analyzer():\n    return TrifectaAnalyzer()\n\n\n@pytest.fixture\ndef runners():\n    return []\n\n\n@pytest.fixture\ndef create_race(runners):\n    return Race(\n        id=\"test-race\",\n        venue=\"TEST\",\n        race_number=1,\n        start_time=datetime.now(),\n        runners=runners,\n        source=\"test\",\n    )\n\n\ndef test_analyzer_name(analyzer):\n    assert analyzer.name == \"trifecta_analyzer\"\n\n\n# Test cases resurrected from legacy scorer and logic tests\ndef test_qualifies_with_exactly_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is True\n\n\ndef test_qualifies_with_more_than_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds4 = {\"TestOdds\": OddsData(win=Decimal(\"6.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=False),\n        Runner(number=4, name=\"D\", odds=odds4, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is True\n\n\n# New test cases for edge-case hardening\ndef test_rejects_with_fewer_than_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is False\n\n\ndef test_rejects_if_scratched_runners_reduce_field_below_three(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=True),  # Scratched\n    ]\n    assert analyzer.is_race_qualified(create_race) is False\n\n\ndef test_handles_empty_runner_list(analyzer, create_race):\n    race = create_race\n    race.runners = []\n    assert analyzer.is_race_qualified(race) is False\n\n\ndef test_handles_none_race_object(analyzer):\n    assert analyzer.is_race_qualified(None) is False\n",
    "tests/fixtures/twinspires_sample.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <title>Race Results - Twinspires</title>\n</head>\n<body>\n    <div id=\"race-card\">\n        <h1>Race 5 - Churchill Downs - 2025-10-26</h1>\n        <div class=\"race-details\">\n            <span class=\"post-time\">Post Time: 04:30 PM</span>\n            <span class=\"distance\">1 Mile</span>\n            <span class=\"surface\">Dirt</span>\n        </div>\n        <ul class=\"runners-list\">\n            <li class=\"runner\">\n                <span class=\"runner-number\">1</span>\n                <span class=\"runner-name\">Braveheart</span>\n                <span class=\"runner-odds\">5/2</span>\n            </li>\n            <li class=\"runner\">\n                <span class=\"runner-number\">2</span>\n                <span class=\"runner-name\">Speedster</span>\n                <span class=\"runner-odds\">10/1</span>\n            </li>\n            <li class=\"runner scratched\">\n                <span class=\"runner-number\">3</span>\n                <span class=\"runner-name\">Steady Eddy</span>\n                <span class=\"runner-odds\">SCR</span>\n            </li>\n             <li class=\"runner\">\n                <span class=\"runner-number\">4</span>\n                <span class=\"runner-name\">Gallant Gus</span>\n                <span class=\"runner-odds\">3/1</span>\n            </li>\n        </ul>\n    </div>\n</body>\n</html>\n",
    "tests/test_engine.py": "import pytest\nfrom unittest.mock import AsyncMock, MagicMock, patch\nfrom datetime import datetime, date\nfrom decimal import Decimal\nfrom tests.conftest import create_mock_race, get_test_settings\n\n# Import your actual classes\nfrom python_service.engine import OddsEngine\nfrom python_service.adapters.base_adapter_v3 import BaseAdapterV3\n\n@pytest.mark.asyncio\nasync def test_engine_initialization():\n    \"\"\"Test that the engine loads config correctly.\"\"\"\n    engine = OddsEngine(config=get_test_settings())\n    assert engine.config.API_KEY == \"test-override-key-123\"\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine._time_adapter_fetch\")\nasync def test_fetch_all_odds_success(mock_fetch, clear_cache):\n    \"\"\"Test happy path: fetching odds from a single adapter.\"\"\"\n    # ARRANGE\n    settings = get_test_settings()\n    settings.CACHE_ENABLED = False\n    engine = OddsEngine(config=settings)\n\n    today = datetime.now()\n    mock_race = create_mock_race(\n        \"MockSource\", \"Churchill Downs\", 1, today,\n        [{\"number\": 1, \"name\": \"Secretariat\", \"odds\": \"1.5\"}]\n    )\n\n    # This is the new way to mock the data\n    mock_fetch.return_value = (\"MockSource\", {\"races\": [mock_race], \"source_info\": {\"name\": \"MockSource\", \"status\": \"SUCCESS\", \"races_fetched\": 1, \"fetch_duration\": 0.1}}, 0.1)\n\n    # We still need to give the engine an adapter to iterate over\n    mock_adapter = MagicMock(spec=BaseAdapterV3)\n    mock_adapter.source_name = \"MockSource\"\n    engine.adapters = [mock_adapter]\n\n    # ACT\n    result = await engine.fetch_all_odds(date.today().strftime(\"%Y-%m-%d\"))\n\n    # ASSERT\n    assert len(result[\"races\"]) == 1\n    assert result[\"races\"][0][\"venue\"] == \"Churchill Downs\"\n    assert result[\"races\"][0][\"runners\"][0][\"name\"] == \"Secretariat\"\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine._time_adapter_fetch\")\nasync def test_fetch_all_odds_resilience(mock_fetch, clear_cache):\n    \"\"\"Test that one failing adapter does not crash the whole engine.\"\"\"\n    # ARRANGE\n    settings = get_test_settings()\n    settings.CACHE_ENABLED = False\n    engine = OddsEngine(config=settings)\n\n    # Mock successful adapter data\n    good_race = create_mock_race(\"GoodSource\", \"Track A\", 1, datetime.now(), [])\n    good_payload = (\"GoodSource\", {\"races\": [good_race], \"source_info\": {\"name\": \"GoodSource\", \"status\": \"SUCCESS\", \"races_fetched\": 1, \"fetch_duration\": 0.1}}, 0.1)\n\n    # Mock failed adapter data\n    bad_payload = (\"BadSource\", {\"races\": [], \"source_info\": {\"name\": \"BadSource\", \"status\": \"FAILED\", \"error_message\": \"API Down\", \"races_fetched\": 0, \"fetch_duration\": 0.1}}, 0.1)\n\n    mock_fetch.side_effect = [good_payload, bad_payload]\n\n    # We still need to give the engine adapters to iterate over\n    good_adapter = MagicMock(spec=BaseAdapterV3); good_adapter.source_name = \"GoodSource\"\n    bad_adapter = MagicMock(spec=BaseAdapterV3); bad_adapter.source_name = \"BadSource\"\n    engine.adapters = [good_adapter, bad_adapter]\n\n    # ACT\n    result = await engine.fetch_all_odds(\"2025-12-08\")\n\n    # ASSERT\n    assert len(result[\"races\"]) == 1, \"Should return data from the good adapter\"\n    assert result[\"races\"][0][\"source\"] == \"GoodSource\"\n\n    # Verify error logging in sourceInfo\n    bad_info = next((s for s in result[\"sourceInfo\"] if s[\"name\"] == \"BadSource\"), None)\n    assert bad_info is not None\n    assert bad_info[\"status\"] == \"FAILED\"\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine._time_adapter_fetch\")\nasync def test_race_aggregation_and_deduplication(mock_fetch, clear_cache):\n    \"\"\"Test merging identical races from different sources.\"\"\"\n    settings = get_test_settings()\n    settings.CACHE_ENABLED = False\n    engine = OddsEngine(config=settings)\n    now = datetime.now()\n\n    # Same race, different sources, slightly different odds\n    race_a = create_mock_race(\"SourceA\", \"Ascot\", 1, now, [{\"number\": 1, \"name\": \"Horse X\", \"odds\": \"2.0\"}])\n    race_b = create_mock_race(\"SourceB\", \"Ascot\", 1, now, [{\"number\": 1, \"name\": \"Horse X\", \"odds\": \"2.2\"}])\n\n    payload_a = (\"SourceA\", {\"races\": [race_a], \"source_info\": {\"name\": \"SourceA\", \"status\": \"SUCCESS\", \"races_fetched\": 1, \"fetch_duration\": 0.1}}, 0.1)\n    payload_b = (\"SourceB\", {\"races\": [race_b], \"source_info\": {\"name\": \"SourceB\", \"status\": \"SUCCESS\", \"races_fetched\": 1, \"fetch_duration\": 0.1}}, 0.1)\n    mock_fetch.side_effect = [payload_a, payload_b]\n\n    adapter_a = MagicMock(spec=BaseAdapterV3); adapter_a.source_name = \"SourceA\"\n    adapter_b = MagicMock(spec=BaseAdapterV3); adapter_b.source_name = \"SourceB\"\n    engine.adapters = [adapter_a, adapter_b]\n\n\n    # ACT\n    result = await engine.fetch_all_odds(\"2025-12-08\")\n\n    # ASSERT\n    assert len(result[\"races\"]) == 1, \"Should deduplicate into a single race object\"\n    merged_race = result[\"races\"][0]\n    runner = merged_race[\"runners\"][0]\n\n    # Check that odds from both sources are present\n    # Note: This assertion depends on how your engine merges odds.\n    # If it merges into a dict, this passes. If it overwrites, adjust accordingly.\n    odds_keys = runner[\"odds\"].keys()\n    assert \"SourceA\" in odds_keys\n    assert \"SourceB\" in odds_keys",
    "tests/test_msi_installation.ps1": "param([string]$MsiPath = \".\\dist\\Fortuna-Faucet-2.1.0-x64.msi\")\n\nWrite-Host \"Testing MSI Installation...\" -ForegroundColor Cyan\n\n# Test 1: File integrity\nWrite-Host \"\u2022 Verifying MSI structure...\"\nif (Test-Path $MsiPath) {\n    Write-Host \"\u2713 MSI file exists\"\n} else {\n    Write-Error \"MSI file not found\"\n    exit 1\n}\n\n# Test 2: Installation\nWrite-Host \"\u2022 Testing interactive installation...\"\n& msiexec.exe /i $MsiPath /l*v \"test_install.log\"\n\n# Test 3: Verify installation\nWrite-Host \"\u2022 Verifying files were installed...\"\n$programFiles = \"$env:PROGRAMFILES\\Fortuna Faucet\"\nif (Test-Path $programFiles) {\n    Write-Host \"\u2713 Installation successful\"\n} else {\n    Write-Error \"Installation failed\"\n    exit 1\n}\n\n# Test 4: Registry entries\nWrite-Host \"\u2022 Checking registry entries...\"\n$regPath = \"HKLM:\\Software\\Fortuna Faucet\"\nif (Test-Path $regPath) {\n    Write-Host \"\u2713 Registry entries found\"\n} else {\n    Write-Error \"Registry entries missing\"\n    exit 1\n}",
    "tests/utils.py": "# tests/utils.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Dict\nfrom typing import List\n\nfrom python_service.models import OddsData\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\n\ndef create_mock_race(\n    source: str,\n    track_name: str,\n    race_number: int,\n    start_time: datetime,\n    runners_data: List[Dict],\n) -> dict:\n    \"\"\"\n    Creates a dictionary representing a race, suitable for Pydantic model validation.\n    This is a test utility to generate consistent race data.\n    \"\"\"\n    runners = []\n    for i, runner_info in enumerate(runners_data):\n        odds_data = {}\n        if \"odds\" in runner_info:\n            odds_value = Decimal(str(runner_info[\"odds\"]))\n            odds_data[source] = OddsData(win=odds_value, source=source, last_updated=datetime.now())\n\n        runners.append(\n            Runner(\n                number=runner_info.get(\"number\", i + 1),\n                name=runner_info.get(\"name\", f\"Runner {i + 1}\"),\n                odds=odds_data,\n                scratched=runner_info.get(\"scratched\", False),\n            ).model_dump()\n        )\n\n    # Use Pydantic model to create and then dump the data to ensure it's valid\n    race = Race(\n        id=f\"test_{track_name}_{race_number}\",\n        venue=track_name,\n        race_number=race_number,\n        start_time=start_time,\n        runners=runners,\n        source=source,\n    )\n    return race.model_dump()\n",
    "web_service/backend/__init__.py": "# This file makes this directory a package.\n",
    "web_service/backend/adapters/base_adapter_v3.py": "# python_service/adapters/base_v3.py\nfrom __future__ import annotations\n\nimport asyncio\nimport hashlib\nimport json\nimport random\nimport time\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any, TypeVar\n\nimport httpx\nimport structlog\nfrom tenacity import (\n    RetryError,\n    retry,\n    retry_if_exception_type,\n    stop_after_attempt,\n    wait_exponential,\n)\n\nfrom ..core.exceptions import AdapterHttpError, AdapterParsingError\nfrom ..manual_override_manager import ManualOverrideManager\nfrom ..models import Race\nfrom ..validators import DataValidationPipeline\n\nT = TypeVar(\"T\")\n\n\nclass CircuitState(Enum):\n    \"\"\"Circuit breaker states.\"\"\"\n    CLOSED = \"closed\"      # Normal operation\n    OPEN = \"open\"          # Failing, reject requests\n    HALF_OPEN = \"half_open\"  # Testing if service recovered\n\n\n@dataclass\nclass CircuitBreaker:\n    \"\"\"Thread-safe circuit breaker implementation.\"\"\"\n    failure_threshold: int = 5\n    recovery_timeout: float = 60.0\n    half_open_max_calls: int = 3\n\n    _failure_count: int = field(default=0, repr=False)\n    _last_failure_time: float = field(default=0.0, repr=False)\n    _state: CircuitState = field(default=CircuitState.CLOSED, repr=False)\n    _half_open_calls: int = field(default=0, repr=False)\n    _lock: asyncio.Lock = field(default_factory=asyncio.Lock, init=False, repr=False)\n\n    @property\n    def state(self) -> CircuitState:\n        \"\"\"Returns current state without mutation. Use check_state() for transitions.\"\"\"\n        return self._state\n\n    async def check_and_transition_state(self) -> CircuitState:\n        \"\"\"Check state and handle OPEN -> HALF_OPEN transition atomically.\"\"\"\n        async with self._lock:\n            if self._state == CircuitState.OPEN:\n                if time.monotonic() - self._last_failure_time >= self.recovery_timeout:\n                    self._state = CircuitState.HALF_OPEN\n                    self._half_open_calls = 0\n            return self._state\n\n    async def record_success(self) -> None:\n        \"\"\"Record a successful call.\"\"\"\n        async with self._lock:\n            self._failure_count = 0\n            if self._state == CircuitState.HALF_OPEN:\n                self._half_open_calls += 1\n                if self._half_open_calls >= self.half_open_max_calls:\n                    self._state = CircuitState.CLOSED\n\n    async def record_failure(self) -> None:\n        \"\"\"Record a failed call.\"\"\"\n        async with self._lock:\n            self._failure_count += 1\n            self._last_failure_time = time.monotonic()\n\n            if self._failure_count >= self.failure_threshold:\n                self._state = CircuitState.OPEN\n            elif self._state == CircuitState.HALF_OPEN:\n                self._state = CircuitState.OPEN\n\n    async def allow_request(self) -> bool:\n        \"\"\"Check if a request should be allowed.\"\"\"\n        state = await self.check_and_transition_state()\n        return state in (CircuitState.CLOSED, CircuitState.HALF_OPEN)\n\n\n@dataclass\nclass RateLimiter:\n    \"\"\"Token bucket rate limiter.\"\"\"\n    requests_per_second: float = 10.0\n    burst_size: int = 20\n\n    _tokens: float = field(default=0.0, init=False, repr=False)\n    _last_update: float = field(default=0.0, init=False, repr=False)\n    _lock: asyncio.Lock = field(default_factory=asyncio.Lock, init=False, repr=False)\n\n    def __post_init__(self) -> None:\n        self._tokens = float(self.burst_size)\n        self._last_update = time.monotonic()\n\n    async def acquire(self) -> None:\n        \"\"\"Acquire a token, waiting if necessary.\"\"\"\n        async with self._lock:\n            now = time.monotonic()\n            elapsed = now - self._last_update\n            self._tokens = min(self.burst_size, self._tokens + elapsed * self.requests_per_second)\n            self._last_update = now\n\n            if self._tokens < 1:\n                wait_time = (1 - self._tokens) / self.requests_per_second\n                await asyncio.sleep(wait_time)\n                self._tokens = 0\n            else:\n                self._tokens -= 1\n\n\n@dataclass\nclass CacheEntry:\n    \"\"\"Cache entry with TTL.\"\"\"\n    data: Any\n    created_at: float\n    ttl: float\n\n    @property\n    def is_expired(self) -> bool:\n        return time.monotonic() - self.created_at > self.ttl\n\n\nclass ResponseCache:\n    \"\"\"Simple in-memory response cache.\"\"\"\n\n    def __init__(self, default_ttl: float = 300.0, max_entries: int = 1000):\n        self.default_ttl = default_ttl\n        self.max_entries = max_entries\n        self._cache: dict[str, CacheEntry] = {}\n        self._lock = asyncio.Lock()\n\n    @staticmethod\n    def _make_key(method: str, url: str, **kwargs) -> str:\n        \"\"\"Generate a stable cache key from request parameters.\"\"\"\n        # Filter out non-hashable or irrelevant kwargs\n        cacheable_kwargs = {\n            k: v for k, v in kwargs.items()\n            if k not in ('headers', 'timeout', 'follow_redirects')\n            and isinstance(v, (str, int, float, bool, tuple, type(None)))\n        }\n        key_data = f\"{method}:{url}:{json.dumps(cacheable_kwargs, sort_keys=True, default=str)}\"\n        return hashlib.sha256(key_data.encode()).hexdigest()[:32]\n\n    async def get(self, method: str, url: str, **kwargs) -> Any | None:\n        \"\"\"Get a cached response if available and not expired.\"\"\"\n        key = self._make_key(method, url, **kwargs)\n\n        async with self._lock:\n            entry = self._cache.get(key)\n            if entry and not entry.is_expired:\n                return entry.data\n            elif entry:\n                del self._cache[key]\n        return None\n\n    async def set(self, method: str, url: str, data: Any, ttl: float | None = None, **kwargs) -> None:\n        \"\"\"Cache a response.\"\"\"\n        key = self._make_key(method, url, **kwargs)\n\n        async with self._lock:\n            # Evict old entries if cache is full\n            if len(self._cache) >= self.max_entries:\n                expired_keys = [k for k, v in self._cache.items() if v.is_expired]\n                for k in expired_keys:\n                    del self._cache[k]\n\n                # If still full, remove oldest entries\n                if len(self._cache) >= self.max_entries:\n                    oldest = sorted(self._cache.items(), key=lambda x: x[1].created_at)\n                    for k, _ in oldest[:len(self._cache) // 4]:\n                        del self._cache[k]\n\n            self._cache[key] = CacheEntry(\n                data=data,\n                created_at=time.monotonic(),\n                ttl=ttl or self.default_ttl\n            )\n\n    async def clear(self) -> None:\n        \"\"\"Clear all cached entries.\"\"\"\n        async with self._lock:\n            self._cache.clear()\n\n\n@dataclass\nclass AdapterMetrics:\n    \"\"\"Thread-safe metrics for adapter health monitoring.\"\"\"\n    _lock: asyncio.Lock = field(default_factory=asyncio.Lock, init=False, repr=False)\n    _total_requests: int = field(default=0, repr=False)\n    _successful_requests: int = field(default=0, repr=False)\n    _failed_requests: int = field(default=0, repr=False)\n    _total_latency_ms: float = field(default=0.0, repr=False)\n    _last_success: float | None = field(default=None, repr=False)\n    _last_failure: float | None = field(default=None, repr=False)\n    _last_error: str | None = field(default=None, repr=False)\n\n    @property\n    def total_requests(self) -> int:\n        return self._total_requests\n\n    @property\n    def success_rate(self) -> float:\n        if self._total_requests == 0:\n            return 1.0\n        return self._successful_requests / self._total_requests\n\n    @property\n    def avg_latency_ms(self) -> float:\n        if self._successful_requests == 0:\n            return 0.0\n        return self._total_latency_ms / self._successful_requests\n\n    async def record_success(self, latency_ms: float) -> None:\n        async with self._lock:\n            self._total_requests += 1\n            self._successful_requests += 1\n            self._total_latency_ms += latency_ms\n            self._last_success = time.time()\n\n    async def record_failure(self, error: str) -> None:\n        async with self._lock:\n            self._total_requests += 1\n            self._failed_requests += 1\n            self._last_failure = time.time()\n            self._last_error = error\n\n    def snapshot(self) -> dict[str, Any]:\n        \"\"\"Return a point-in-time snapshot of metrics.\"\"\"\n        return {\n            \"total_requests\": self._total_requests,\n            \"successful_requests\": self._successful_requests,\n            \"failed_requests\": self._failed_requests,\n            \"success_rate\": self.success_rate,\n            \"avg_latency_ms\": self.avg_latency_ms,\n            \"last_success\": self._last_success,\n            \"last_failure\": self._last_failure,\n            \"last_error\": self._last_error,\n        }\n\n\nclass BaseAdapterV3(ABC):\n    \"\"\"\n    Abstract base class for all V3 data adapters.\n\n    Features:\n    - Standardized fetch/parse pattern\n    - Retry logic with exponential backoff\n    - Circuit breaker for fault tolerance\n    - Rate limiting\n    - Response caching\n    - Comprehensive metrics\n    \"\"\"\n\n    # List of common User-Agent strings for rotation\n    USER_AGENTS = [\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0\",\n        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n    ]\n\n    @property\n    def DEFAULT_USER_AGENT(self) -> str:\n        \"\"\"Return a randomly selected User-Agent.\"\"\"\n        return random.choice(self.USER_AGENTS)\n\n    def __init__(\n        self,\n        source_name: str,\n        base_url: str,\n        config: Any = None,\n        timeout: int = 20,\n        enable_cache: bool = True,\n        cache_ttl: float = 300.0,\n        rate_limit: float = 10.0,\n    ):\n        self.source_name = source_name\n        self.base_url = base_url.rstrip(\"/\")\n        self.config = config\n        self.timeout = timeout\n\n        self.logger = structlog.get_logger(adapter_name=self.source_name)\n        self.http_client: httpx.AsyncClient = httpx.AsyncClient(timeout=self.timeout)\n        self.manual_override_manager: ManualOverrideManager | None = None\n        self.supports_manual_override = True\n\n        # Resilience components\n        self.circuit_breaker = CircuitBreaker()\n        self.rate_limiter = RateLimiter(requests_per_second=rate_limit)\n        self.cache = ResponseCache(default_ttl=cache_ttl) if enable_cache else None\n        self.metrics = AdapterMetrics()\n\n    async def __aenter__(self) -> \"BaseAdapterV3\":\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:\n        \"\"\"Async context manager exit with cleanup.\"\"\"\n        await self.close()\n\n    async def close(self) -> None:\n        \"\"\"Clean up resources.\"\"\"\n        if self.http_client:\n            await self.http_client.aclose()\n            self.http_client = None\n        if self.cache:\n            await self.cache.clear()\n        self.logger.debug(\"Adapter resources cleaned up\")\n\n    def enable_manual_override(self, manager: ManualOverrideManager) -> None:\n        \"\"\"Injects the manual override manager into the adapter.\"\"\"\n        self.manual_override_manager = manager\n\n    @abstractmethod\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw data (e.g., HTML, JSON) for the given date.\n        This is the only method that should perform network operations.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _parse_races(self, raw_data: Any) -> list[Race]:\n        \"\"\"\n        Parses the raw data retrieved by _fetch_data into a list of Race objects.\n        This method should be a pure function with no side effects.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_races(self, date: str) -> list[Race]:\n        \"\"\"\n        Orchestrates the fetch-then-parse pipeline for the adapter.\n        This public method should not be overridden by subclasses.\n        \"\"\"\n        raw_data = None\n\n        # Check for manual override data first\n        if self.manual_override_manager:\n            lookup_key = f\"{self.base_url}/racecards/{date}\"\n            manual_data = self.manual_override_manager.get_manual_data(self.source_name, lookup_key)\n            if manual_data:\n                self.logger.info(\"Using manually submitted data\", url=lookup_key)\n                raw_data = {\"pages\": [manual_data[0]], \"date\": date}\n\n        # Fetch from source if no manual data\n        if raw_data is None:\n            try:\n                raw_data = await self._fetch_data(date)\n            except AdapterHttpError as e:\n                if self.manual_override_manager and self.supports_manual_override:\n                    self.manual_override_manager.register_failure(self.source_name, e.url)\n                raise\n\n        # Parse the data\n        if raw_data is not None:\n            return self._validate_and_parse_races(raw_data)\n\n        return []\n\n    def _validate_and_parse_races(self, raw_data: Any) -> list[Race]:\n        is_valid, reason = DataValidationPipeline.validate_raw_response(self.source_name, raw_data)\n        if not is_valid:\n            raise AdapterParsingError(self.source_name, f\"Raw response validation failed: {reason}\")\n\n        try:\n            parsed_races = self._parse_races(raw_data)\n        except Exception as e:\n            self.logger.error(\"Failed to parse race data\", error=str(e))\n            raise AdapterParsingError(self.source_name, \"Parsing logic failed.\") from e\n\n        validated_races, warnings = DataValidationPipeline.validate_parsed_races(parsed_races)\n\n        if warnings:\n            self.logger.warning(\"Validation warnings during parsing\", warnings=warnings)\n\n        return validated_races\n\n    async def make_request(\n        self,\n        method: str,\n        url: str,\n        use_cache: bool = True,\n        cache_ttl: float | None = None,\n        **kwargs,\n    ) -> httpx.Response:\n        \"\"\"\n        Makes a resilient HTTP request with circuit breaker, rate limiting, caching, and retries.\n        \"\"\"\n        full_url = url if url.startswith(\"http\") else f\"{self.base_url}/{url.lstrip('/')}\"\n\n        # Check cache first for GET requests\n        if use_cache and self.cache and method.upper() == \"GET\":\n            cached = await self.cache.get(method, full_url, **kwargs)\n            if cached is not None:\n                self.logger.debug(\"Cache hit\", url=full_url)\n                return cached\n\n        @retry(\n            retry=retry_if_exception_type((httpx.RequestError, httpx.HTTPStatusError)),\n            wait=wait_exponential(multiplier=1, min=2, max=10),\n            stop=stop_after_attempt(3),\n            reraise=True,\n        )\n        async def _attempt_request():\n            # Check circuit breaker before each attempt\n            if not await self.circuit_breaker.allow_request():\n                self.logger.warning(\"Circuit breaker open, rejecting request\", url=full_url)\n                raise AdapterHttpError(\n                    adapter_name=self.source_name,\n                    status_code=503,\n                    url=full_url,\n                    message=\"Circuit breaker is open\",\n                )\n\n            # Apply rate limiting and a small random delay\n            await self.rate_limiter.acquire()\n            await asyncio.sleep(random.uniform(0.5, 2.5))\n\n            headers = {\n                \"User-Agent\": self.DEFAULT_USER_AGENT,\n                \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n                \"Accept-Language\": \"en-US,en;q=0.9\",\n                \"Referer\": \"https://www.google.com/\",\n                \"DNT\": \"1\",\n                \"Upgrade-Insecure-Requests\": \"1\",\n                **kwargs.get(\"headers\", {}),\n            }\n\n            start_time = time.monotonic()\n            try:\n                self.logger.info(\"Making request attempt\", method=method.upper(), url=full_url)\n                response = await self.http_client.request(\n                    method, full_url, timeout=self.timeout, **kwargs\n                )\n                response.raise_for_status()\n\n                latency_ms = (time.monotonic() - start_time) * 1000\n                await self.metrics.record_success(latency_ms)\n                await self.circuit_breaker.record_success()\n\n                return response\n            except httpx.HTTPStatusError as e:\n                await self.metrics.record_failure(f\"HTTP {e.response.status_code}\")\n                await self.circuit_breaker.record_failure()\n                raise  # Re-raise to trigger tenacity retry\n            except httpx.RequestError as e:\n                await self.metrics.record_failure(str(e))\n                await self.circuit_breaker.record_failure()\n                raise  # Re-raise to trigger tenacity retry\n\n        try:\n            response = await _attempt_request()\n\n            # Cache successful GET responses\n            if use_cache and self.cache and method.upper() == \"GET\":\n                await self.cache.set(method, full_url, response, ttl=cache_ttl, **kwargs)\n\n            return response\n        except (RetryError, httpx.HTTPStatusError) as e:\n            final_exception = e.last_attempt.exception() if isinstance(e, RetryError) else e\n            self.logger.error(\"Request failed after multiple retries\", error=str(final_exception))\n\n            if isinstance(final_exception, httpx.HTTPStatusError):\n                raise AdapterHttpError(\n                    adapter_name=self.source_name,\n                    status_code=final_exception.response.status_code,\n                    url=str(final_exception.request.url),\n                    message=f\"HTTP {final_exception.response.status_code}: {final_exception.response.reason_phrase}\",\n                    response_body=final_exception.response.text[:500] if final_exception.response.text else None,\n                    request_method=method.upper(),\n                ) from final_exception\n            else:\n                raise AdapterHttpError(\n                    adapter_name=self.source_name, status_code=503, url=full_url\n                ) from final_exception\n\n    async def health_check(self) -> dict[str, Any]:\n        \"\"\"\n        Performs a health check on the adapter.\n        Subclasses can override to add custom checks.\n        \"\"\"\n        return {\n            \"adapter_name\": self.source_name,\n            \"base_url\": self.base_url,\n            \"circuit_breaker_state\": self.circuit_breaker.state.value,\n            \"metrics\": self.metrics.snapshot(),\n        }\n\n    def get_status(self) -> dict[str, Any]:\n        \"\"\"\n        Returns a dictionary representing the adapter's current status.\n        \"\"\"\n        status = \"OK\"\n        if self.circuit_breaker.state == CircuitState.OPEN:\n            status = \"CIRCUIT_OPEN\"\n        elif self.metrics.success_rate < 0.5:\n            status = \"DEGRADED\"\n\n        return {\n            \"adapter_name\": self.source_name,\n            \"status\": status,\n            \"circuit_state\": self.circuit_breaker.state.value,\n            \"success_rate\": round(self.metrics.success_rate, 3),\n        }\n\n    async def reset(self) -> None:\n        \"\"\"Reset adapter state (cache, circuit breaker, metrics).\"\"\"\n        if self.cache:\n            await self.cache.clear()\n        self.circuit_breaker = CircuitBreaker()\n        self.metrics = AdapterMetrics()\n        self.logger.info(\"Adapter state reset\")\n",
    "web_service/backend/adapters/betfair_auth_mixin.py": "# python_service/adapters/betfair_auth_mixin.py\n\nimport asyncio\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Optional\n\nimport httpx\nimport structlog\n\nfrom ..credentials_manager import SecureCredentialsManager\n\nlog = structlog.get_logger(__name__)\n\n\nclass BetfairAuthMixin:\n    \"\"\"Encapsulates Betfair authentication logic for reuse across adapters.\"\"\"\n\n    session_token: Optional[str] = None\n    token_expiry: Optional[datetime] = None\n    _auth_lock = asyncio.Lock()\n\n    async def _authenticate(self, http_client: httpx.AsyncClient):\n        \"\"\"\n        Authenticates with Betfair using credentials from the system's credential manager,\n        ensuring the session token is valid and refreshing it if necessary.\n        \"\"\"\n        async with self._auth_lock:\n            if self.session_token and self.token_expiry and self.token_expiry > (datetime.now() + timedelta(minutes=5)):\n                return\n\n            log.info(\"Attempting to authenticate with Betfair...\")\n            username, password = SecureCredentialsManager.get_betfair_credentials()\n\n            if not all([self.config.BETFAIR_APP_KEY, username, password]):\n                raise ValueError(\"Betfair credentials not fully configured in credential manager.\")\n\n            auth_url = \"https://identitysso.betfair.com/api/login\"\n            headers = {\n                \"X-Application\": self.config.BETFAIR_APP_KEY,\n                \"Content-Type\": \"application/x-www-form-urlencoded\",\n            }\n            payload = f\"username={username}&password={password}\"\n\n            response = await http_client.post(auth_url, headers=headers, content=payload, timeout=20)\n            response.raise_for_status()\n            data = response.json()\n\n            if data.get(\"status\") == \"SUCCESS\":\n                self.session_token = data.get(\"token\")\n                self.token_expiry = datetime.now() + timedelta(hours=3)\n                log.info(\"Betfair authentication successful.\")\n            else:\n                log.error(\"Betfair authentication failed\", error=data.get(\"error\"))\n                self.session_token = None  # Reset token to prevent using a stale one\n                return  # Return gracefully and let the adapter handle the lack of a token\n",
    "web_service/backend/adapters/fanduel_adapter.py": "# python_service/adapters/fanduel_adapter.py\n\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass FanDuelAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for FanDuel's private API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"FanDuel\"\n    BASE_URL = \"https://sb-api.nj.sportsbook.fanduel.com/api/\"\n\n    def __init__(self, config=None, session=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config, session=session)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw market data from the FanDuel API.\"\"\"\n        # Note: FanDuel's API is not date-centric. Event discovery would be needed for a robust implementation.\n        # This uses a hardcoded eventId as a placeholder.\n        event_id = \"38183.3\"\n        self.logger.info(f\"Fetching races from FanDuel for event_id: {event_id}\")\n        endpoint = f\"markets?_ak=Fh2e68s832c41d4b&eventId={event_id}\"\n        response = await self.make_request(\"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw API response into a list of Race objects.\"\"\"\n        if not raw_data or \"marketGroups\" not in raw_data:\n            self.logger.warning(\"FanDuel response missing 'marketGroups' key\")\n            return []\n\n        races = []\n        for group in raw_data.get(\"marketGroups\", []):\n            if group.get(\"marketGroupName\") == \"Win\":\n                for market in group.get(\"markets\", []):\n                    try:\n                        if race := self._parse_single_race(market):\n                            races.append(race)\n                    except Exception:\n                        self.logger.error(\n                            \"Failed to parse a FanDuel market\",\n                            market=market,\n                            exc_info=True,\n                        )\n        return races\n\n    def _parse_single_race(self, market: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single market from the API response into a Race object.\"\"\"\n        market_name = market.get(\"marketName\", \"\")\n        if not market_name.startswith(\"Race\"):\n            return None\n\n        parts = market_name.split(\" - \")\n        if len(parts) < 2:\n            self.logger.warning(f\"Could not parse race and track from FanDuel market name: {market_name}\")\n            return None\n\n        race_number_str = parts[0].replace(\"Race \", \"\").strip()\n        if not race_number_str.isdigit():\n            return None\n        race_number = int(race_number_str)\n\n        track_name = parts[1]\n\n        # Placeholder for start_time - FanDuel's market API doesn't provide it directly\n        start_time = datetime.now(timezone.utc) + timedelta(hours=race_number)\n\n        runners = []\n        for runner_data in market.get(\"runners\", []):\n            try:\n                runner_name = runner_data.get(\"runnerName\")\n                win_runner_odds = runner_data.get(\"winRunnerOdds\", {})\n                current_price = win_runner_odds.get(\"currentPrice\")\n\n                if not runner_name or not current_price:\n                    continue\n\n                numerator, denominator = map(int, current_price.split(\"/\"))\n                decimal_odds = Decimal(numerator) / Decimal(denominator) + 1\n\n                odds = OddsData(\n                    win=decimal_odds,\n                    source=self.source_name,\n                    last_updated=datetime.now(timezone.utc),\n                )\n\n                name_parts = runner_name.split(\".\", 1)\n                if len(name_parts) < 2:\n                    continue\n                program_number_str = name_parts[0].strip()\n                horse_name = name_parts[1].strip()\n\n                runners.append(\n                    Runner(\n                        name=horse_name,\n                        number=(int(program_number_str) if program_number_str.isdigit() else 0),\n                        odds={self.source_name: odds},\n                    )\n                )\n            except (ValueError, ZeroDivisionError, IndexError, TypeError):\n                self.logger.warning(\n                    \"Could not parse FanDuel runner\",\n                    runner_data=runner_data,\n                    exc_info=True,\n                )\n                continue\n\n        if not runners:\n            return None\n\n        race_id = f\"FD-{track_name.replace(' ', '')[:5].upper()}-{start_time.strftime('%Y%m%d')}-R{race_number}\"\n\n        return Race(\n            id=race_id,\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/nyrabets_adapter.py": "# python_service/adapters/nyrabets_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass NYRABetsAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for nyrabets.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"NYRABets\"\n    BASE_URL = \"https://nyrabets.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/racing_and_sports_greyhound_adapter.py": "# python_service/adapters/racing_and_sports_greyhound_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports Greyhound API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSportsGreyhound\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"RACING_AND_SPORTS_TOKEN\") or not config.RACING_AND_SPORTS_TOKEN:\n            raise AdapterConfigError(self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw greyhound meetings data from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            self.http_client,\n            \"GET\",\n            \"v1/greyhound/meetings\",\n            headers=headers,\n            params=params,\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw meetings data into a list of Race objects.\"\"\"\n        all_races = []\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\"No 'meetings' in RacingAndSportsGreyhound response or invalid format.\")\n            return all_races\n\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed_race := self._parse_ras_race(meeting, race_summary):\n                        all_races.append(parsed_race)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse RacingAndSportsGreyhound race, skipping\",\n                        meeting=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return all_races\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"rasg_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=datetime.fromisoformat(start_time_str),\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/template_adapter.py": "# python_service/adapters/template_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TemplateAdapter(BaseAdapterV3):\n    \"\"\"\n    A template for creating new adapters, based on the BaseAdapterV3 pattern.\n    This adapter is a non-functional stub.\n    \"\"\"\n\n    SOURCE_NAME = \"[IMPLEMENT ME] Example Source\"\n    BASE_URL = \"https://api.example.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        # self.api_key = config.EXAMPLE_API_KEY # Uncomment if needed\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/universal_adapter.py": "# python_service/adapters/universal_adapter.py\nimport json\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass UniversalAdapter(BaseAdapterV3):\n    \"\"\"\n    An adapter that executes logic from a declarative JSON definition file.\n    NOTE: This is a simplified proof-of-concept implementation.\n    \"\"\"\n\n    def __init__(self, config, definition_path: str):\n        with open(definition_path, \"r\") as f:\n            self.definition = json.load(f)\n\n        super().__init__(\n            source_name=self.definition[\"adapter_name\"],\n            base_url=self.definition[\"base_url\"],\n            config=config,\n        )\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Executes the fetch steps defined in the JSON definition.\"\"\"\n        self.logger.info(f\"Executing Universal Adapter PoC for {self.source_name}\")\n        response = await self.make_request(self.http_client, \"GET\", self.definition[\"start_url\"])\n        if not response:\n            return None\n\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        track_links = [self.base_url + a[\"href\"] for a in soup.select(self.definition[\"steps\"][0][\"selector\"])]\n\n        # In a full implementation, we would fetch and return each track page's content.\n        # For this PoC, we are not fetching the individual track links.\n        self.logger.warning(\"UniversalAdapter is a proof-of-concept and does not fully fetch all data.\")\n        return track_links\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a proof-of-concept and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/cache_manager.py": "# python_service/cache_manager.py\nimport asyncio\nimport hashlib\nimport json\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom functools import wraps\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Optional\n\nimport structlog\n\ntry:\n    import redis\n\n    REDIS_AVAILABLE = True\nexcept ImportError:\n    REDIS_AVAILABLE = False\n\nlog = structlog.get_logger(__name__)\n\n\nclass CacheManager:\n    def __init__(self):\n        self.redis_client = None\n        self.memory_cache = {}\n        self.is_configured = False\n        log.info(\"CacheManager initialized (not connected).\")\n\n    async def connect(self, redis_url: str):\n        if self.is_configured or not REDIS_AVAILABLE or not redis_url:\n            return\n\n        try:\n            log.info(\"Attempting to connect to Redis...\", url=redis_url)\n            # Use the async version of the client\n            self.redis_client = redis.asyncio.from_url(redis_url, decode_responses=True)\n            await self.redis_client.ping()  # Verify connection asynchronously\n            self.is_configured = True\n            log.info(\"Redis cache connected successfully.\")\n        except (redis.exceptions.ConnectionError, asyncio.TimeoutError) as e:\n            log.warning(\n                \"Failed to connect to Redis. Falling back to in-memory cache.\",\n                error=str(e),\n            )\n            self.redis_client = None\n            self.is_configured = False\n\n    async def disconnect(self):\n        if self.redis_client:\n            await self.redis_client.close()\n            log.info(\"Redis connection closed.\")\n\n    def _generate_key(self, prefix: str, *args, **kwargs) -> str:\n        key_data = f\"{prefix}:{args}:{sorted(kwargs.items())}\"\n        return hashlib.md5(key_data.encode()).hexdigest()\n\n    async def get(self, key: str) -> Any | None:\n        if self.redis_client:\n            try:\n                value = await self.redis_client.get(key)\n                return json.loads(value) if value else None\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis GET failed, falling back to memory cache.\", error=e)\n\n        entry = self.memory_cache.get(key)\n        if entry and entry.get(\"expires_at\", datetime.min) > datetime.now():\n            return entry.get(\"value\")\n        return None\n\n    async def set(self, key: str, value: Any, ttl_seconds: int = 300):\n        try:\n            serialized = json.dumps(value, default=str)\n        except (TypeError, ValueError) as e:\n            log.error(\"Failed to serialize value for caching.\", value=value, error=str(e))\n            return\n\n        if self.redis_client:\n            try:\n                await self.redis_client.setex(key, ttl_seconds, serialized)\n                return\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis SET failed, falling back to memory cache.\", error=e)\n\n        self.memory_cache[key] = {\n            \"value\": value,\n            \"expires_at\": datetime.now() + timedelta(seconds=ttl_seconds),\n        }\n\n\n# --- Singleton Instance & Decorator ---\ncache_manager = CacheManager()\n\n\ndef cache_async_result(ttl_seconds: int = 300, key_prefix: str = \"cache\"):\n    def decorator(func: Callable):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            instance_args = args[1:] if args and hasattr(args[0], func.__name__) else args\n            cache_key = cache_manager._generate_key(f\"{key_prefix}:{func.__name__}\", *instance_args, **kwargs)\n\n            cached_result = await cache_manager.get(cache_key)\n            if cached_result is not None:\n                log.debug(\"Cache hit\", function=func.__name__)\n                return cached_result\n\n            log.debug(\"Cache miss\", function=func.__name__)\n            result = await func(*args, **kwargs)\n\n            try:\n                await cache_manager.set(cache_key, result, ttl_seconds)\n            except Exception as e:\n                log.error(\"Failed to store result in cache.\", error=str(e), key=cache_key)\n\n            return result\n\n        return wrapper\n\n    return decorator\n\n\nclass StaleDataCache:\n    \"\"\"In-memory cache for storing the last known good data for a given date.\"\"\"\n\n    def __init__(self, max_age_hours: int = 24):\n        self._cache: dict[str, dict] = {}\n        self.max_age = timedelta(hours=max_age_hours)\n        self.logger = structlog.get_logger(cache_type=\"StaleDataCache\")\n\n    async def get(self, date_key: str) -> Optional[dict]:\n        \"\"\"\n        Retrieves stale data if it exists and is within the max_age.\n        Returns a dictionary with the data and its age, or None.\n        \"\"\"\n        entry = self._cache.get(date_key)\n        if not entry:\n            self.logger.debug(\"Cache miss\", key=date_key)\n            return None\n\n        now = datetime.utcnow()\n        timestamp = entry[\"timestamp\"]\n        age = now - timestamp\n\n        if age > self.max_age:\n            self.logger.warning(\"Cache entry expired\", key=date_key, age_hours=age.total_seconds() / 3600)\n            del self._cache[date_key]\n            return None\n\n        age_hours = age.total_seconds() / 3600\n        self.logger.info(\"Cache hit\", key=date_key, age_hours=round(age_hours, 2))\n        return {\"data\": entry[\"data\"], \"age_hours\": age_hours}\n\n    async def set(self, date_key: str, data: Any):\n        \"\"\"\n        Stores the latest successful data fetch for a given date.\n        \"\"\"\n        self.logger.info(\"Updating stale cache\", key=date_key)\n        self._cache[date_key] = {\n            \"timestamp\": datetime.utcnow(),\n            \"data\": data,\n        }\n",
    "web_service/backend/credentials_manager.py": "# python_service/credentials_manager.py\ntry:\n    import keyring\n\n    # This check is crucial for cross-platform compatibility\n    import keyring.backends.windows\n\n    IS_WINDOWS = True\nexcept ImportError:\n    keyring = None\n    IS_WINDOWS = False\n\n\nclass SecureCredentialsManager:\n    \"\"\"Manages secrets in the system's native credential store.\"\"\"\n\n    SERVICE_NAME = \"Fortuna\"\n\n    @staticmethod\n    def save_credential(account: str, secret: str) -> bool:\n        \"\"\"Saves a secret for a given account (e.g., 'api_key', 'betfair_username').\"\"\"\n        if not IS_WINDOWS:\n            print(\"Credential storage is only supported on Windows.\")\n            return False\n        try:\n            keyring.set_password(SecureCredentialsManager.SERVICE_NAME, account, secret)\n            return True\n        except Exception as e:\n            print(f\"\u274c Failed to save credential for {account}: {e}\")\n            return False\n\n    @staticmethod\n    def get_credential(account: str) -> str:\n        \"\"\"Retrieves a secret for a given account.\"\"\"\n        if not IS_WINDOWS:\n            return None\n        try:\n            return keyring.get_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception as e:\n            print(f\"\u274c Failed to retrieve credential for {account}: {e}\")\n            return None\n\n    @staticmethod\n    def get_betfair_credentials() -> tuple[str, str]:\n        \"\"\"Convenience method to retrieve both Betfair username and password.\"\"\"\n        username = SecureCredentialsManager.get_credential(\"betfair_username\")\n        password = SecureCredentialsManager.get_credential(\"betfair_password\")\n        return username, password\n\n    @staticmethod\n    def delete_credential(account: str):\n        \"\"\"Deletes a specific credential.\"\"\"\n        if not IS_WINDOWS:\n            return\n        try:\n            keyring.delete_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception:\n            pass\n",
    "web_service/backend/engine.py": "# python_service/engine.py\n\nimport asyncio\nimport json\nfrom copy import deepcopy\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\n\nimport httpx\nimport redis\nimport redis.asyncio as redis_async\nimport structlog\nfrom pydantic import ValidationError\n\nfrom .adapters.at_the_races_adapter import AtTheRacesAdapter\nfrom .adapters.base_adapter_v3 import BaseAdapterV3\nfrom .adapters.betfair_adapter import BetfairAdapter\n\n# from .adapters.betfair_datascientist_adapter import BetfairDataScientistAdapter\nfrom .adapters.betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .adapters.brisnet_adapter import BrisnetAdapter\nfrom .adapters.equibase_adapter import EquibaseAdapter\nfrom .adapters.fanduel_adapter import FanDuelAdapter\nfrom .adapters.gbgb_api_adapter import GbgbApiAdapter\nfrom .adapters.greyhound_adapter import GreyhoundAdapter\nfrom .adapters.harness_adapter import HarnessAdapter\nfrom .adapters.horseracingnation_adapter import HorseRacingNationAdapter\nfrom .adapters.nyrabets_adapter import NYRABetsAdapter\nfrom .adapters.oddschecker_adapter import OddscheckerAdapter\nfrom .adapters.pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .adapters.punters_adapter import PuntersAdapter\nfrom .adapters.racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .adapters.racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .adapters.racingpost_adapter import RacingPostAdapter\nfrom .adapters.racingtv_adapter import RacingTVAdapter\nfrom .adapters.sporting_life_adapter import SportingLifeAdapter\nfrom .adapters.tab_adapter import TabAdapter\nfrom .adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom .adapters.timeform_adapter import TimeformAdapter\nfrom .adapters.tvg_adapter import TVGAdapter\nfrom .adapters.twinspires_adapter import TwinSpiresAdapter\nfrom .adapters.xpressbet_adapter import XpressbetAdapter\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .adapter_manager import AdapterHealthMonitor, AdapterHealth, AdapterStatus\nfrom .cache_manager import StaleDataCache\nfrom .manual_override_manager import ManualOverrideManager\nfrom .models import AggregatedResponse\nfrom .models import Race\n\nlog = structlog.get_logger(__name__)\n\n\nclass OddsEngine:\n    def __init__(\n        self,\n        config=None,\n        manual_override_manager: ManualOverrideManager = None,\n        connection_manager=None,\n        exclude_adapters: Optional[List[str]] = None,\n    ):\n        # THE FIX: Import the cache_manager singleton here to ensure tests can\n        # patch and reload it *before* the engine is initialized.\n        from .cache_manager import cache_manager\n\n        self.logger = structlog.get_logger(__name__)\n        self.logger.info(\"Initializing FortunaEngine...\")\n        self.connection_manager = connection_manager\n        self.cache_manager = cache_manager\n        self.health_monitor = AdapterHealthMonitor()\n        self.stale_data_cache = StaleDataCache(max_age_hours=24)\n        self.exclude_adapters = set(exclude_adapters) if exclude_adapters else set()\n\n        try:\n            try:\n                self.config = config or get_settings()\n                self.logger.info(\"Configuration loaded.\")\n            except ValidationError as e:\n                self.logger.warning(\n                    \"Could not load settings, possibly in test environment.\",\n                    error=str(e),\n                )\n                # Create a default/mock config or re-raise if not in a test context\n                from .config import Settings\n\n                self.config = Settings(API_KEY=\"a_secure_test_api_key_that_is_long_enough\")\n\n            # Redis is now handled entirely by the CacheManager.\n\n            self.logger.info(\"Initializing adapters...\")\n            self.adapters: Dict[str, BaseAdapterV3] = {}\n            adapter_classes = [\n                AtTheRacesAdapter,\n                BetfairAdapter,\n                BetfairGreyhoundAdapter,\n                BrisnetAdapter,\n                EquibaseAdapter,\n                FanDuelAdapter,\n                GbgbApiAdapter,\n                GreyhoundAdapter,\n                HarnessAdapter,\n                HorseRacingNationAdapter,\n                NYRABetsAdapter,\n                OddscheckerAdapter,\n                PuntersAdapter,\n                RacingAndSportsAdapter,\n                RacingAndSportsGreyhoundAdapter,\n                RacingPostAdapter,\n                RacingTVAdapter,\n                SportingLifeAdapter,\n                TabAdapter,\n                TheRacingApiAdapter,\n                TimeformAdapter,\n                TwinSpiresAdapter,\n                TVGAdapter,\n                XpressbetAdapter,\n                PointsBetGreyhoundAdapter,\n            ]\n\n            for adapter_cls in adapter_classes:\n                adapter_name = adapter_cls.__name__\n                if adapter_name in self.exclude_adapters:\n                    self.logger.info(f\"Intentionally skipping adapter: {adapter_name}\")\n                    continue\n                try:\n                    self.logger.info(f\"Attempting to initialize adapter: {adapter_name}\")\n                    adapter_instance = adapter_cls(config=self.config)\n                    self.logger.info(f\"Successfully initialized adapter: {adapter_name}\")\n                    if manual_override_manager and getattr(adapter_instance, \"supports_manual_override\", False):\n                        adapter_instance.enable_manual_override(manual_override_manager)\n                    self.adapters[adapter_instance.source_name] = adapter_instance\n                except AdapterConfigError as e:\n                    self.logger.warning(\n                        \"Skipping adapter due to configuration error\",\n                        adapter=adapter_name,\n                        error=str(e),\n                    )\n                except Exception:\n                    self.logger.error(\n                        f\"An unexpected error occurred while initializing {adapter_name}\",\n                        exc_info=True,\n                    )\n\n            for adapter_instance in self.adapters.values():\n                self.health_monitor.statuses[adapter_instance.source_name] = AdapterStatus(\n                    name=adapter_instance.source_name,\n                    health=AdapterHealth.HEALTHY,\n                    success_rate_24h=1.0,\n                    last_success=None,\n                    consecutive_failures=0,\n                    avg_response_time_ms=0,\n                    last_error=None,\n                )\n            # Special case for BetfairDataScientistAdapter with extra args - DISABLED\n            # try:\n            #     bds_adapter = BetfairDataScientistAdapter(\n            #         model_name=\"ThoroughbredModel\",\n            #         url=\"https://betfair-data-supplier-prod.herokuapp.com/api/widgets/kvs-ratings/datasets\",\n            #         config=self.config,\n            #     )\n            #     if manual_override_manager and getattr(bds_adapter, \"supports_manual_override\", False):\n            #         bds_adapter.enable_manual_override(manual_override_manager)\n            #     self.adapters.append(bds_adapter)\n            # except Exception:\n            #     self.logger.warning(\n            #         \"Failed to initialize adapter: BetfairDataScientistAdapter\",\n            #         exc_info=True,\n            #     )\n\n            self.logger.info(f\"{len(self.adapters)} adapters initialized successfully.\")\n\n            self.logger.info(\"Initializing HTTP client...\")\n            self.http_limits = httpx.Limits(\n                max_connections=self.config.HTTP_POOL_CONNECTIONS,\n                max_keepalive_connections=self.config.HTTP_MAX_KEEPALIVE,\n            )\n            self.http_client = httpx.AsyncClient(limits=self.http_limits, http2=True)\n            self.logger.info(\"HTTP client initialized.\")\n\n            # Assign the shared client to each adapter\n            for adapter in self.adapters.values():\n                adapter.http_client = self.http_client\n\n            # Initialize semaphore for concurrency limiting\n            self.semaphore = asyncio.Semaphore(self.config.MAX_CONCURRENT_REQUESTS)\n            self.logger.info(\n                \"Concurrency semaphore initialized\",\n                limit=self.config.MAX_CONCURRENT_REQUESTS,\n            )\n\n            self.logger.info(\"FortunaEngine initialization complete.\")\n\n        except Exception:\n            self.logger.critical(\"CRITICAL FAILURE during FortunaEngine initialization.\", exc_info=True)\n            raise\n\n    async def close(self):\n        await self.http_client.aclose()\n\n    def get_all_adapter_statuses(self) -> List[Dict[str, Any]]:\n        return [adapter.get_status() for adapter in self.adapters.values()]\n\n    async def get_from_cache(self, key):\n        return await self.cache_manager.get(key)\n\n    async def set_in_cache(self, key, value, ttl=300):\n        # THE FIX: The keyword argument is 'ttl_seconds', not 'ttl'.\n        await self.cache_manager.set(key, value, ttl_seconds=ttl)\n\n    async def _fetch_with_semaphore(self, adapter: BaseAdapterV3, date: str):\n        \"\"\"Acquires the semaphore before fetching data from an adapter.\"\"\"\n        async with self.semaphore:\n            return await self._time_adapter_fetch(adapter, date)\n\n    async def _time_adapter_fetch(self, adapter: BaseAdapterV3, date: str) -> Tuple[str, Dict[str, Any], float]:\n        \"\"\"\n        Wraps a V3 adapter's fetch call for safe, non-blocking execution,\n        and returns a consistent payload with timing information.\n        \"\"\"\n        start_time = datetime.now()\n        races: List[Race] = []\n        error_message = None\n        is_success = False\n        attempted_url = None\n\n        try:\n            race_data_list = await adapter.get_races(date)\n            processed_races = []\n            for race_data in race_data_list:\n                if isinstance(race_data, Race):\n                    processed_races.append(race_data)\n                else:\n                    processed_races.append(Race(**race_data))\n            races = processed_races\n            is_success = True\n        except AdapterHttpError as e:\n            self.logger.error(\n                \"HTTP failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                status_code=e.status_code,\n                url=e.url,\n                exc_info=False,\n            )\n            error_message = f\"HTTP Error {e.status_code} for {e.url}\"\n            attempted_url = e.url\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n        except Exception as e:\n            self.logger.error(\n                \"Critical failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                error=str(e),\n                exc_info=True,\n            )\n            error_message = str(e)\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n\n        duration = (datetime.now() - start_time).total_seconds()\n\n        # Update health monitor\n        await self.health_monitor.update_adapter_status(\n            adapter_name=adapter.source_name,\n            success=is_success,\n            latency_ms=duration * 1000,\n            error=error_message,\n        )\n\n        payload = {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": adapter.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": duration,\n                \"attempted_url\": attempted_url,\n            },\n        }\n        return (adapter.source_name, payload, duration)\n\n    def _race_key(self, race: Race) -> str:\n        return f\"{race.venue.lower().strip()}|{race.race_number}|{race.start_time.strftime('%H:%M')}\"\n\n    def _dedupe_races(self, races: List[Race]) -> List[Race]:\n        \"\"\"Deduplicates races and reconciles odds from different sources.\"\"\"\n        races_copy = deepcopy(races)\n        race_map: Dict[str, Race] = {}\n        for race in races_copy:\n            key = self._race_key(race)\n            if key not in race_map:\n                race_map[key] = race\n            else:\n                existing_race = race_map[key]\n                runner_map = {r.number: r for r in existing_race.runners}\n                for new_runner in race.runners:\n                    if new_runner.number in runner_map:\n                        existing_runner = runner_map[new_runner.number]\n                        existing_runner.odds.update(new_runner.odds)\n                    else:\n                        existing_race.runners.append(new_runner)\n                existing_race.source += f\", {race.source}\"\n\n        return list(race_map.values())\n\n    def _calculate_coverage(self, results: List[Dict[str, Any]]) -> float:\n        # Stub implementation\n        return 0.0\n\n    def _merge_adapter_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:\n        source_infos = []\n        all_races = []\n        errors = []\n\n        for adapter_result in results:\n            source_info = adapter_result.get(\"source_info\", {})\n            source_infos.append(source_info)\n            if source_info.get(\"status\") == \"SUCCESS\":\n                all_races.extend(adapter_result.get(\"races\", []))\n            else:\n                errors.append({\n                    \"adapter_name\": source_info.get(\"name\"),\n                    \"error_message\": source_info.get(\"error_message\", \"Unknown error\"),\n                    \"attempted_url\": source_info.get(\"attempted_url\")\n                })\n\n        deduped_races = self._dedupe_races(all_races)\n\n        return {\n            \"races\": deduped_races,\n            \"errors\": errors,\n            \"source_info\": source_infos\n        }\n\n    async def _broadcast_update(self, data: Dict[str, Any]):\n        \"\"\"Helper to broadcast data if the connection manager is available.\"\"\"\n        if self.connection_manager:\n            await self.connection_manager.broadcast(data)\n\n    async def fetch_all_odds(self, date: str, source_filter: str = None, min_required_adapters: int = 2) -> Dict[str, Any]:\n        if date is None:\n            date = datetime.now().strftime(\"%Y-%m-%d\")\n\n        # Re-introduce live caching\n        cache_key = f\"fortuna_engine_races:{date}:{source_filter or 'all'}\"\n        cached_data = await self.get_from_cache(cache_key)\n        if cached_data:\n            log.info(\"Cache hit for fetch_all_odds\", key=cache_key)\n            return json.loads(cached_data)\n\n        all_payloads = []\n        attempted_adapters = []\n        all_adapter_names = list(self.adapters.keys())\n        if source_filter:\n            all_adapter_names = [name for name in all_adapter_names if name.lower() == source_filter.lower()]\n\n        ordered_adapter_names = self.health_monitor.get_ordered_adapters(all_adapter_names)\n\n        # Tier 1: Healthy\n        healthy_names = [name for name in ordered_adapter_names if self.health_monitor.statuses[name].health == AdapterHealth.HEALTHY]\n        if healthy_names:\n            tasks = [self._fetch_with_semaphore(self.adapters[name], date) for name in healthy_names]\n            attempted_adapters.extend(healthy_names)\n            results = await asyncio.gather(*tasks, return_exceptions=True)\n            for res in results:\n                if not isinstance(res, Exception):\n                    _adapter_name, payload, _duration = res\n                    all_payloads.append(payload)\n\n        successful_count = len([p for p in all_payloads if p['source_info']['status'] == 'SUCCESS'])\n\n        # Tier 2: Degraded\n        if successful_count < min_required_adapters:\n            degraded_names = [name for name in ordered_adapter_names if self.health_monitor.statuses[name].health == AdapterHealth.DEGRADED]\n            if degraded_names:\n                tasks = [self._fetch_with_semaphore(self.adapters[name], date) for name in degraded_names]\n                attempted_adapters.extend(degraded_names)\n                results = await asyncio.gather(*tasks, return_exceptions=True)\n                for res in results:\n                    if not isinstance(res, Exception):\n                        _adapter_name, payload, _duration = res\n                        all_payloads.append(payload)\n\n        # Tier 3: Stale cache fallback\n        if not any(p['source_info']['status'] == 'SUCCESS' for p in all_payloads):\n            log.warning(\"All live adapters failed, attempting to use stale cache.\")\n            stale_data = await self.stale_data_cache.get(date)\n            if stale_data:\n                log.info(\"Using stale data from cache.\", cache_age_hours=stale_data['age_hours'])\n                stale_results = stale_data['data']\n                stale_results['metadata']['data_freshness'] = 'stale'\n                stale_results['warnings'] = [\"Using cached data from a previous run as all live sources failed.\"]\n                return stale_results\n\n        if not all_payloads:\n            log.error(\"All adapter fetches failed and no stale data available.\")\n            return {\"races\": [], \"errors\": [{\"adapter_name\": \"all\", \"error_message\": \"All adapters failed and no stale data available.\"}], \"source_info\": [], \"metadata\": {}}\n\n        merged_results = self._merge_adapter_results(all_payloads)\n        successful_count = len([s for s in merged_results[\"source_info\"] if s[\"status\"] == \"SUCCESS\"])\n\n        try:\n            parsed_date = datetime.strptime(date, \"%Y-%m-%d\").date()\n        except (ValueError, TypeError):\n            parsed_date = datetime.now().date()\n\n        response_obj = AggregatedResponse(\n            date=parsed_date,\n            races=merged_results[\"races\"],\n            errors=merged_results[\"errors\"],\n            source_info=merged_results[\"source_info\"],\n            metadata={\n                \"fetch_time\": datetime.now(),\n                \"sources_queried\": attempted_adapters,\n                \"sources_successful\": successful_count,\n                \"total_races\": len(merged_results[\"races\"]),\n                \"total_errors\": len(merged_results[\"errors\"]),\n                'coverage': self._calculate_coverage(all_payloads),\n                'data_freshness': 'live'\n            },\n        )\n        response_data = response_obj.model_dump(by_alias=True)\n\n        # Cache successful live results\n        if successful_count > 0:\n            await self.stale_data_cache.set(date, response_data)\n            await self.set_in_cache(cache_key, json.dumps(response_data, default=str), ttl=300)\n\n        await self._broadcast_update(response_data)\n        return response_data\n",
    "web_service/backend/fortuna_windows_service.py": "# fortuna_windows_service.py\n\nimport logging\nimport os\nimport sys\n\nimport servicemanager\nimport win32event\nimport win32service\nimport win32serviceutil\n\n# Ensure the script's directory is at the front of the path\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.insert(0, script_dir)\n\ntry:\n    from fortuna_service import FortunaBackgroundService\nexcept ImportError as e:\n    # Log a detailed error to the Windows Event Log if the import fails\n    servicemanager.LogErrorMsg(f\"FATAL: Could not import FortunaBackgroundService. Error: {e}\")\n    sys.exit(1)  # Exit with an error code\n\n\nclass FortunaWindowsService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaV8Service\"\n    _svc_display_name_ = \"Fortuna V8 Racing Analysis Service\"\n    _svc_description_ = \"Continuously fetches and analyzes horse racing data.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)\n        self.fortuna_service = FortunaBackgroundService()\n        # Configure logging to use the Windows Event Log\n        logging.basicConfig(\n            level=logging.INFO,\n            format=\"%(name)s - %(levelname)s - %(message)s\",\n            handlers=[servicemanager.LogHandler()],\n        )\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        self.fortuna_service.stop()\n        win32event.SetEvent(self.hWaitStop)\n        self.ReportServiceStatus(win32service.SERVICE_STOPPED)\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(\n            servicemanager.EVENTLOG_INFORMATION_TYPE,\n            servicemanager.PYS_SERVICE_STARTED,\n            (self._svc_name_, \"\"),\n        )\n        self.main()\n\n    def main(self):\n        self.fortuna_service.start()\n        win32event.WaitForSingleObject(self.hWaitStop, win32event.INFINITE)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaWindowsService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaWindowsService)\n",
    "web_service/backend/main.py": "import sys\nfrom pathlib import Path\nimport uvicorn\nimport logging\nimport traceback\n\n# CRITICAL: Set up paths and logging for PyInstaller\nif getattr(sys, 'frozen', False):\n    # Running as compiled executable\n    PROJECT_ROOT = Path(sys.executable).parent\n    LOG_FILE = PROJECT_ROOT / 'fortuna-monolith.log'\n    # Redirect stdout and stderr to the log file to capture all output\n    sys.stdout = open(LOG_FILE, 'w', encoding='utf-8')\n    sys.stderr = sys.stdout\nelse:\n    # Running as script\n    PROJECT_ROOT = Path(__file__).parent.parent.parent\n    LOG_FILE = PROJECT_ROOT / 'fortuna-monolith-dev.log'\n\n# Configure logging to write to the log file and original stdout\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(LOG_FILE),\n        logging.StreamHandler(sys.__stdout__)\n    ]\n)\nlog = logging.getLogger(__name__)\n\n# Add project root to path\nif str(PROJECT_ROOT) not in sys.path:\n    sys.path.insert(0, str(PROJECT_ROOT))\nlog.info(f\"PROJECT_ROOT added to sys.path: {PROJECT_ROOT}\")\nlog.info(f\"Full sys.path: {sys.path}\")\n\n# Now that the path is set, we can import our application modules\nfrom web_service.backend.api import app\nfrom web_service.backend.config import get_settings\nfrom web_service.backend.port_check import check_port_and_exit_if_in_use\n\n\ndef main():\n    \"\"\"Main entry point for Fortuna Monolith.\"\"\"\n    try:\n        log.info(\"=\"*70)\n        log.info(\"\ud83d\ude80 Fortuna Monolith Initializing...\")\n        log.info(f\"Python Executable: {sys.executable}\")\n        log.info(f\"Working Directory: {Path.cwd()}\")\n        log.info(\"=\"*70)\n\n        settings = get_settings()\n\n        log.info(f\"Checking port {settings.FORTUNA_PORT} on host {settings.UVICORN_HOST}\")\n        check_port_and_exit_if_in_use(settings.FORTUNA_PORT, settings.UVICORN_HOST)\n        log.info(f\"Port {settings.FORTUNA_PORT} is available.\")\n\n        log.info(f\"Host: {settings.UVICORN_HOST}\")\n        log.info(f\"Port: {settings.FORTUNA_PORT}\")\n        log.info(f\"Mode: {'Frozen (Executable)' if getattr(sys, 'frozen', False) else 'Development'}\")\n        log.info(f\"Log file: {LOG_FILE}\")\n\n        log.info(\"Starting Uvicorn server...\")\n        uvicorn.run(\n            app,\n            host=settings.UVICORN_HOST,\n            port=settings.FORTUNA_PORT,\n            log_level=\"info\",\n            access_log=True,\n        )\n        log.info(\"Uvicorn server stopped gracefully.\")\n\n    except Exception as e:\n        log.critical(\"--- !!! A FATAL ERROR OCCURRED DURING STARTUP !!! ---\")\n        log.critical(traceback.format_exc())\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    # Multiprocessing support for PyInstaller\n    from multiprocessing import freeze_support\n    freeze_support()\n    main()\n",
    "web_service/backend/models_v3.py": "# python_service/models_v3.py\n# Defines the data structures for the V3 adapter architecture.\n\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import List\n\n\n@dataclass\nclass NormalizedRunner:\n    runner_id: str\n    name: str\n    saddle_cloth: str\n    odds_decimal: float\n\n\n@dataclass\nclass NormalizedRace:\n    race_key: str\n    track_key: str\n    start_time_iso: str\n    race_name: str\n    runners: List[NormalizedRunner] = field(default_factory=list)\n    source_ids: List[str] = field(default_factory=list)\n",
    "web_service/backend/requirements-dev.txt": "#\n# Development & Build-Time Dependencies\n# This file should be used for setting up a development or CI/CD environment.\n#\n\n-r requirements.txt\n\n# --- Build Tools ---\npip-tools\n\n# --- Testing Tools ---\npytest\npytest-asyncio\nfakeredis\nrespx\n\n# --- Linting & Auditing ---\nblack\nruff\npip-audit\nsetuptools<81\n",
    "web_service/backend/tests/__init__.py": "",
    "web_service/backend/utils/text.py": "# python_service/utils/text.py\n# Centralized text and name normalization utilities\nimport re\nfrom typing import Optional\n\n\ndef clean_text(text: Optional[str]) -> Optional[str]:\n    \"\"\"Strips leading/trailing whitespace and collapses internal whitespace.\"\"\"\n    if not text:\n        return None\n    return \" \".join(text.strip().split())\n\n\ndef normalize_venue_name(name: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Normalizes a UK or Irish racecourse name to a standard format.\n    Handles common abbreviations and variations.\n    \"\"\"\n    if not name:\n        return None\n\n    # Use a temporary variable for matching, but return the properly cased name\n    cleaned_name_upper = clean_text(name).upper()\n\n    VENUE_MAP = {\n        \"ASCOT\": \"Ascot\",\n        \"AYR\": \"Ayr\",\n        \"BANGOR-ON-DEE\": \"Bangor-on-Dee\",\n        \"CATTERICK BRIDGE\": \"Catterick\",\n        \"CHELMSFORD CITY\": \"Chelmsford\",\n        \"EPSOM DOWNS\": \"Epsom\",\n        \"FONTWELL\": \"Fontwell Park\",\n        \"HAYDOCK\": \"Haydock Park\",\n        \"KEMPTON\": \"Kempton Park\",\n        \"LINGFIELD\": \"Lingfield Park\",\n        \"NEWMARKET (ROWLEY)\": \"Newmarket\",\n        \"NEWMARKET (JULY)\": \"Newmarket\",\n        \"SANDOWN\": \"Sandown Park\",\n        \"STRATFORD\": \"Stratford-on-Avon\",\n        \"YARMOUTH\": \"Great Yarmouth\",\n        \"CURRAGH\": \"Curragh\",\n        \"DOWN ROYAL\": \"Down Royal\",\n    }\n\n    # Check primary map first\n    if cleaned_name_upper in VENUE_MAP:\n        return VENUE_MAP[cleaned_name_upper]\n\n    # Handle cases where the key is the desired output but needs to be mapped from a variation\n    # e.g. CHELMSFORD maps to Chelmsford\n    # Title case the cleaned name for a sensible default\n    title_cased_name = clean_text(name).title()\n    if title_cased_name in VENUE_MAP.values():\n        return title_cased_name\n\n    # Return the title-cased cleaned name as a fallback\n    return title_cased_name\n\n\ndef normalize_course_name(name: str) -> str:\n    if not name:\n        return \"\"\n    name = name.lower().strip()\n    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s-]+\", \"_\", name)\n    return name\n",
    "web_service/frontend/app/components/AdapterStatusPanel.tsx": "// web_platform/frontend/src/components/AdapterStatusPanel.tsx\n'use client';\n\nimport React from 'react';\nimport { SourceInfo } from '../types/racing';\n\ninterface AdapterStatusPanelProps {\n  adapter: SourceInfo;\n  onFetchRaces: (sourceName: string) => void;\n}\n\nexport const AdapterStatusPanel: React.FC<AdapterStatusPanelProps> = ({ adapter, onFetchRaces }) => {\n  const isConfigured = adapter.status !== 'CONFIG_ERROR';\n\n  return (\n    <div className={`p-4 rounded-lg border ${isConfigured ? 'bg-slate-800 border-slate-700' : 'bg-yellow-900/20 border-yellow-700/50'}`}>\n      <div className=\"flex justify-between items-center\">\n        <h3 className=\"font-bold text-lg text-white\">{adapter.name}</h3>\n        <span className={`px-2 py-0.5 rounded-full text-xs font-medium ${isConfigured ? 'bg-green-500/20 text-green-300' : 'bg-yellow-500/20 text-yellow-300'}`}>\n          {isConfigured ? 'Ready' : 'Not Configured'}\n        </span>\n      </div>\n      <div className=\"mt-4 flex gap-2\">\n        <button\n          onClick={() => onFetchRaces(adapter.name)}\n          disabled={!isConfigured}\n          className=\"flex-1 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 disabled:bg-slate-700 disabled:text-slate-400 disabled:cursor-not-allowed\"\n        >\n          Automatic Load\n        </button>\n        <button\n          disabled\n          className=\"flex-1 px-4 py-2 bg-slate-700 text-slate-400 rounded cursor-not-allowed\"\n        >\n          Manual Entry (Coming Soon)\n        </button>\n      </div>\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/LiveRaceDashboard.tsx": "// web_platform/frontend/src/components/LiveRaceDashboard.tsx\n'use client';\n\nimport React, { useState, useEffect, useCallback } from 'react';\nimport { useQuery, useQueryClient } from '@tanstack/react-query';\nimport { RaceFilters } from './RaceFilters';\nimport { RaceCard } from './RaceCard';\nimport { RaceCardSkeleton } from './RaceCardSkeleton';\nimport { EmptyState } from './EmptyState';\nimport { ErrorDisplay } from './ErrorDisplay';\nimport { Race, SourceInfo, AdapterError, AggregatedRacesResponse } from '../types/racing';\nimport { useWebSocket } from '../hooks/useWebSocket';\nimport { StatusDetailModal } from './StatusDetailModal';\nimport ManualOverridePanel from './ManualOverridePanel';\nimport { LiveModeToggle } from './LiveModeToggle';\nimport { AdapterStatusPanel } from './AdapterStatusPanel';\n\n// Type for the backend process status received from Electron main\ntype BackendState = 'starting' | 'running' | 'error' | 'stopped';\ninterface BackendStatus {\n  state: BackendState;\n  logs: string[];\n}\n\ninterface RaceFilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nconst fetchAdapterStatuses = async (apiKey: string | null): Promise<SourceInfo[]> => {\n  if (!apiKey) {\n    throw new Error('API key not available.');\n  }\n  const response = await fetch(`/api/adapters/status`, {\n    headers: { 'X-API-Key': apiKey, 'Content-Type': 'application/json' },\n  });\n  if (!response.ok) {\n    const errorData = await response.json();\n    throw new Error(JSON.stringify(errorData));\n  }\n  return response.json();\n};\n\nconst fetchQualifiedRaces = async (apiKey: string | null, params: RaceFilterParams): Promise<AggregatedRacesResponse> => {\n  if (!apiKey) {\n    throw new Error('API key not available');\n  }\n  // In web service mode, API calls are relative to the current origin.\n  const response = await fetch(`/api/races`, {\n    headers: { 'X-API-Key': apiKey },\n  });\n\n  if (!response.ok) {\n    const errorData = await response.json();\n    throw new Error(JSON.stringify(errorData));\n  }\n\n  return response.json();\n};\n\n\nconst BackendErrorPanel = ({ logs }: { logs: string[] }) => (\n  <div className=\"bg-slate-800 p-6 rounded-lg border border-red-500/50 text-white\">\n    <h2 className=\"text-2xl font-bold text-red-400 mb-4\">Backend Service Error</h2>\n    <p className=\"text-slate-400 mb-4\">The backend data service failed to start or has crashed. Below are the most recent diagnostic messages.</p>\n    <div className=\"bg-black p-4 rounded-md font-mono text-sm text-slate-300 h-64 overflow-y-auto mb-4\">\n      {logs.map((log, index) => (\n        <p key={index} className=\"whitespace-pre-wrap\">{`> ${log}`}</p>\n      ))}\n    </div>\n    <p className=\"text-sm text-slate-500 text-center mt-4\">Please check the server logs for more information.</p>\n  </div>\n);\n\n// New Sub-Component to display an error from a specific adapter\nconst ErrorCard = ({ source, message }: { source: string; message: string }) => (\n  <div className=\"bg-slate-800 rounded-lg p-4 border border-red-500/50 flex flex-col justify-between\">\n    <div>\n      <h3 className=\"font-bold text-red-400 text-lg\">{source} Failed</h3>\n      <p className=\"text-slate-400 text-sm mt-2\">{message}</p>\n    </div>\n    <div className=\"mt-4 text-xs text-slate-500\">\n      <p>This adapter failed to fetch data. This is not a critical error; other adapters may provide the necessary data.</p>\n    </div>\n  </div>\n);\n\n// New Sub-Component to render the grid of races or error cards\nconst RaceGrid = ({ races }: { races: Race[] }) => (\n  <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-4\">\n    {races.map(race =>\n      race.isErrorPlaceholder ? (\n        <ErrorCard key={race.id} source={race.venue} message={race.errorMessage || 'An unknown error occurred.'} />\n      ) : (\n        <RaceCard key={race.id} race={race} />\n      )\n    )}\n  </div>\n);\n\n// In a pure web service, the frontend cannot know the backend's process status.\n// We assume it's always running if the frontend is served.\nconst useBackendStatus = (): BackendStatus => {\n  return { state: 'running', logs: ['Running in web service mode. Backend status is assumed to be active.'] };\n};\n\nexport const LiveRaceDashboard = React.memo(() => {\n  const [races, setRaces] = useState<Race[]>([]);\n  const [adapterErrors, setAdapterErrors] = useState<AdapterError[]>([]);\n  const backendStatus = useBackendStatus();\n  // In a web service, the API key might be hardcoded, come from a meta tag, or an auth flow.\n  // For this version, we'll rely on the backend not requiring one from the same origin or use a known key.\n  const [apiKey, setApiKey] = useState<string | null>(\"a_secure_test_api_key_that_is_long_enough\");\n  const queryClient = useQueryClient();\n\n  const [params, setParams] = useState<RaceFilterParams>({\n    maxFieldSize: 10,\n    minFavoriteOdds: 2.5,\n    minSecondFavoriteOdds: 4.0,\n  });\n\n  const {\n    data,\n    status: connectionStatus,\n    error: errorDetails,\n    refetch,\n  } = useQuery({\n    queryKey: ['aggregatedRaces', apiKey],\n    queryFn: () => fetchQualifiedRaces(apiKey, params),\n    enabled: backendStatus.state === 'running' && !!apiKey,\n    refetchOnWindowFocus: true,\n  });\n\n  // Update state when data is successfully fetched\n  useEffect(() => {\n    if (data) {\n      setRaces(data.races || []);\n      setAdapterErrors(data.errors || []);\n      setLastUpdate(new Date());\n    }\n  }, [data]);\n\n  const { data: liveData, isConnected: isLiveConnected } = useWebSocket<AggregatedRacesResponse>(\n    '/ws/live-updates',\n    { apiKey } // Port is not needed for same-origin WebSockets\n  );\n\n  // Effect to update state when new live data arrives\n  useEffect(() => {\n    if (liveData) {\n      console.log('Received live data update:', liveData);\n      // Update the query cache and local state with the new data\n      queryClient.setQueryData(['aggregatedRaces', apiKey], liveData);\n      setRaces(liveData.races || []);\n      setAdapterErrors(liveData.errors || []);\n      setLastUpdate(new Date());\n    }\n  }, [liveData, queryClient, apiKey]);\n\n  const [lastUpdate, setLastUpdate] = useState<Date | null>(null);\n  const [isModalOpen, setIsModalOpen] = useState(false);\n\n\n  const handleParamsChange = useCallback((newParams: RaceFilterParams) => {\n    setParams(newParams);\n  }, []);\n\n  const handleParseSuccess = (adapterName: string, parsedRaces: Race[]) => {\n    queryClient.setQueryData(['qualifiedRaces', apiKey, params], (oldData: { races: Race[], source_info: SourceInfo[] } | undefined) => {\n      if (!oldData) return { races: parsedRaces, source_info: [] };\n\n      // 1. Remove the placeholder error card for this adapter\n      const otherRaces = oldData.races.filter(race => race.source !== adapterName);\n\n      // 2. Merge the new races in\n      const updatedRaces = [...otherRaces, ...parsedRaces].sort(\n        (a, b) => new Date(a.start_time).getTime() - new Date(b.start_time).getTime()\n      );\n\n      // 3. Update source_info to remove the failed source\n      const updatedSourceInfo = oldData.source_info.filter(s => s.name !== adapterName);\n\n      return { races: updatedRaces, source_info: updatedSourceInfo };\n    });\n  };\n\n  const renderContent = () => {\n    // Priority 1: Backend process has failed.\n    if (backendStatus.state === 'error') {\n      return <BackendErrorPanel logs={backendStatus.logs} />;\n    }\n\n    if (backendStatus.state === 'stopped') {\n        return <EmptyState\n            title=\"Backend Service Stopped\"\n            message=\"The backend data service is not running. Please start it to see live race data.\"\n        />;\n    }\n\n    // Priority 2: Backend is starting or initial fetch is happening.\n    const isLoading = backendStatus.state === 'starting' || (connectionStatus === 'pending' && !data);\n    if (isLoading) {\n        return (\n            <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-4\">\n                {[...Array(8)].map((_, i) => <RaceCardSkeleton key={i} />)}\n            </div>\n        );\n    }\n\n    // Priority 3: API connection is offline.\n    if (connectionStatus === 'error') {\n      try {\n        const errorInfo = JSON.parse((errorDetails as Error).message);\n        return <ErrorDisplay error={errorInfo.error} />;\n      } catch (e) {\n        return <EmptyState\n            title=\"API Connection Offline\"\n            message={(errorDetails as Error)?.message || \"The backend is running, but the dashboard could not connect to its API.\"}\n            actionButton={<button onClick={() => refetch()} className=\"mt-4 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700\">Retry Connection</button>}\n        />;\n      }\n    }\n\n    // Priority 4: No races found after a successful fetch.\n    if (!races || races.length === 0) {\n      return <EmptyState\n          title=\"No Races Found\"\n          message=\"No races matched the specified criteria for the selected date. Please try different filters.\"\n      />;\n    }\n\n    // Priority 5: Display the races (and any error placeholders).\n    return <RaceGrid races={races} />;\n  };\n\n  const getStatusIndicator = () => {\n    if (backendStatus.state === 'error') {\n      return { color: 'bg-red-500', text: 'Backend Error' };\n    }\n    if (backendStatus.state === 'stopped') {\n        return { color: 'bg-gray-500', text: 'Stopped' };\n    }\n    if (backendStatus.state === 'starting') {\n      return { color: 'bg-yellow-500', text: 'Backend Starting...' };\n    }\n    if (isLiveConnected) {\n      return { color: 'bg-cyan-500', text: 'Live' };\n    }\n    return { color: 'bg-yellow-500', text: 'Connecting...' };\n  };\n\n  const { color: statusColor, text: statusText } = getStatusIndicator();\n\n  return (\n    <>\n      <div className=\"space-y-6\">\n        <div className=\"flex justify-between items-start\">\n            <div className=\"text-left space-y-2\">\n                <h1 className=\"text-4xl font-bold text-white\">\ud83c\udfc7 Fortuna Faucet</h1>\n                <p className=\"text-slate-400\">\n                Last updated: {lastUpdate ? lastUpdate.toLocaleTimeString() : 'N/A'}\n                </p>\n            </div>\n            <div className=\"flex items-center gap-4\">\n                <button\n                    onClick={() => (connectionStatus === 'error' || backendStatus.state === 'error') && setIsModalOpen(true)}\n                    className={`flex items-center gap-2 px-3 py-1.5 rounded-full text-sm font-medium text-white ${statusColor} ${(connectionStatus === 'error' || backendStatus.state === 'error') ? 'cursor-pointer hover:opacity-80' : 'cursor-default'}`}\n                    data-testid=\"status-indicator\"\n                >\n                    <span className={`w-2.5 h-2.5 rounded-full bg-white ${isLiveConnected ? 'animate-pulse' : ''}`}></span>\n                    {statusText}\n                </button>\n            </div>\n        </div>\n\n        <RaceFilters onParamsChange={handleParamsChange} isLoading={connectionStatus === 'pending'} refetch={refetch} />\n\n        {adapterErrors.map(error => (\n          <ManualOverridePanel\n            key={error.adapterName}\n            adapterName={error.adapterName}\n            attemptedUrl={error.attemptedUrl || 'URL not available'}\n            apiKey={apiKey}\n            onParseSuccess={handleParseSuccess}\n          />\n        ))}\n\n        {renderContent()}\n      </div>\n\n      <StatusDetailModal\n        isOpen={isModalOpen}\n        onClose={() => setIsModalOpen(false)}\n        status={{ title: 'Connection Error', details: (errorDetails as Error)?.message || 'No specific error message was provided.' }}\n      />\n    </>\n  );\n});\n",
    "web_service/frontend/app/components/ManualOverridePanel.tsx": "// web_platform/frontend/src/components/ManualOverridePanel.tsx\nimport React, { useState } from 'react';\nimport { Race } from '../types/racing';\n\ninterface ManualOverridePanelProps {\n  adapterName: string;\n  attemptedUrl: string;\n  apiKey: string | null;\n  onParseSuccess: (adapterName: string, parsedRaces: Race[]) => void;\n}\n\nconst ManualOverridePanel: React.FC<ManualOverridePanelProps> = ({\n  adapterName,\n  attemptedUrl,\n  apiKey,\n  onParseSuccess,\n}) => {\n  const [showPanel, setShowPanel] = useState(true);\n  const [htmlContent, setHtmlContent] = useState('');\n  const [isSubmitting, setIsSubmitting] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  const handleSubmit = async () => {\n    if (!htmlContent.trim()) {\n      setError('HTML content cannot be empty.');\n      return;\n    }\n    if (!apiKey) {\n      setError('API key is not available. Cannot submit.');\n      return;\n    }\n\n    setIsSubmitting(true);\n    setError(null);\n\n    try {\n      const response = await fetch('/api/races/parse-manual', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'X-API-Key': apiKey,\n        },\n        body: JSON.stringify({\n          adapter_name: adapterName,\n          html_content: htmlContent,\n        }),\n      });\n\n      if (!response.ok) {\n        const errorData = await response.json();\n        throw new Error(errorData.detail || 'Failed to parse HTML.');\n      }\n\n      const parsedRaces: Race[] = await response.json();\n      onParseSuccess(adapterName, parsedRaces);\n      setShowPanel(false); // Hide panel on success\n\n    } catch (err) {\n      const errorMessage = err instanceof Error ? err.message : 'An unknown error occurred.';\n      setError(errorMessage);\n      console.error('Manual parse submission failed:', err);\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n\n  if (!showPanel) {\n    return null;\n  }\n\n  return (\n    <div className=\"bg-red-900 bg-opacity-50 border border-red-700 p-4 rounded-lg shadow-lg mb-4\">\n      <div className=\"flex justify-between items-center\">\n        <div>\n          <h3 className=\"font-bold text-red-300\">Data Fetch Failed: {adapterName}</h3>\n          <p className=\"text-sm text-red-400\">\n            The application failed to automatically retrieve data from:{' '}\n            <a href={attemptedUrl} target=\"_blank\" rel=\"noopener noreferrer\" className=\"underline hover:text-red-200\">\n              {attemptedUrl}\n            </a>\n          </p>\n        </div>\n        <button onClick={() => setShowPanel(false)} className=\"text-red-400 hover:text-red-200 text-2xl\">&times;</button>\n      </div>\n      <div className=\"mt-4\">\n        <p className=\"text-sm text-red-300 mb-2\">\n          <strong>To resolve this:</strong>\n          <ol className=\"list-decimal list-inside pl-4\">\n            <li>Click the link above to open the page in a new tab.</li>\n            <li>Right-click on the page and select \"View Page Source\".</li>\n            <li>Copy the entire HTML source code.</li>\n            <li>Paste the code into the text area below and click \"Submit Manual Data\".</li>\n          </ol>\n        </p>\n        <textarea\n          className=\"w-full h-24 p-2 bg-gray-900 border border-gray-700 rounded text-gray-300 font-mono text-xs\"\n          placeholder={`Paste HTML source for ${adapterName} here...`}\n          value={htmlContent}\n          onChange={(e) => setHtmlContent(e.target.value)}\n          disabled={isSubmitting}\n        />\n        {error && <p className=\"text-red-400 text-sm mt-2\">{error}</p>}\n        <div className=\"mt-2 flex gap-2\">\n          <button\n            onClick={handleSubmit}\n            className=\"px-3 py-1.5 bg-blue-600 text-white rounded hover:bg-blue-700 text-sm disabled:bg-blue-800 disabled:cursor-not-allowed\"\n            disabled={isSubmitting}\n          >\n            {isSubmitting ? 'Submitting...' : 'Submit Manual Data'}\n          </button>\n          <button\n            onClick={() => setShowPanel(false)}\n            className=\"px-3 py-1.5 bg-gray-700 text-white rounded hover:bg-gray-600 text-sm\"\n          >\n            Skip for Now\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default ManualOverridePanel;\n",
    "web_service/frontend/app/components/SettingsPage.tsx": "// src/components/SettingsPage.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\n\nexport function SettingsPage() {\n  const [apiKey, setApiKey] = useState('');\n  const [betfairAppKey, setBetfairAppKey] = useState('');\n  const [betfairUsername, setBetfairUsername] = useState('');\n  const [betfairPassword, setBetfairPassword] = useState('');\n\n  useEffect(() => {\n    // Fetch the current API key when the component mounts\n    const fetchApiKey = async () => {\n      if (window.electronAPI?.getApiKey) {\n        const key = await window.electronAPI.getApiKey();\n        if (key) {\n          setApiKey(key);\n        }\n      }\n    };\n    fetchApiKey();\n  }, []);\n\n  const handleGenerateApiKey = async () => {\n    if (window.electronAPI?.generateApiKey) {\n      const newKey = await window.electronAPI.generateApiKey();\n      setApiKey(newKey);\n    }\n  };\n\n  const handleSaveSettings = async () => {\n    if (window.electronAPI?.saveApiKey && window.electronAPI?.saveBetfairCredentials) {\n      await window.electronAPI.saveApiKey(apiKey);\n      await window.electronAPI.saveBetfairCredentials({\n        appKey: betfairAppKey,\n        username: betfairUsername,\n        password: betfairPassword,\n      });\n      alert('Settings saved successfully!');\n    }\n  };\n\n  return (\n    <div className=\"bg-slate-800 p-8 rounded-lg border border-slate-700 text-white max-w-2xl mx-auto\">\n      <h2 className=\"text-3xl font-bold text-white mb-6\">Application Settings</h2>\n\n      <div className=\"space-y-8\">\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">API Key</h3>\n          <p className=\"text-sm text-slate-400 mb-3\">This key is required for the dashboard to communicate with the backend service.</p>\n          <div className=\"flex items-center space-x-2\">\n            <input\n              type=\"text\"\n              readOnly\n              value={apiKey}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 font-mono text-sm\"\n            />\n            <button\n              onClick={handleGenerateApiKey}\n              className=\"px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded transition-colors font-semibold\"\n            >\n              Generate New Key\n            </button>\n          </div>\n        </div>\n\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">Betfair Credentials (Optional)</h3>\n           <p className=\"text-sm text-slate-400 mb-3\">Required for adapters that use the Betfair Exchange API.</p>\n          <div className=\"space-y-3\">\n            <input\n              type=\"password\"\n              placeholder=\"App Key\"\n              value={betfairAppKey}\n              onChange={(e) => setBetfairAppKey(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"text\"\n              placeholder=\"Username\"\n              value={betfairUsername}\n              onChange={(e) => setBetfairUsername(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"password\"\n              placeholder=\"Password\"\n              value={betfairPassword}\n              onChange={(e) => setBetfairPassword(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n          </div>\n        </div>\n\n        <div className=\"flex justify-end pt-6 border-t border-slate-700\">\n          <button\n            onClick={handleSaveSettings}\n            className=\"px-8 py-3 bg-green-600 hover:bg-green-700 rounded font-bold text-lg transition-colors\"\n          >\n            Save All Settings\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
    "web_service/frontend/app/hooks/useRealTimeRaces.ts": "import { useState, useEffect } from 'react';\nimport { io, Socket } from 'socket.io-client';\nimport { Race } from '../types/racing';\n\nconst API_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8080';\n\nexport function useRealTimeRaces() {\n  const [races, setRaces] = useState<Race[]>([]);\n  const [isConnected, setIsConnected] = useState(false);\n\n  useEffect(() => {\n    const socket: Socket = io(API_URL);\n\n    socket.on('connect', () => setIsConnected(true));\n    socket.on('disconnect', () => setIsConnected(false));\n\n    socket.on('races_update', (data: { races: Race[] }) => {\n      if (data && Array.isArray(data.races)) {\n        setRaces(data.races);\n      }\n    });\n\n    // Cleanup on component unmount\n    return () => {\n      socket.disconnect();\n    };\n  }, []);\n\n  return { races, isConnected };\n}",
    "web_service/frontend/app/types/electron.d.ts": "// web_platform/frontend/src/types/electron.d.ts\n\n/**\n * This declaration file extends the global Window interface to include the\n * 'electronAPI' object exposed by the preload script. This provides\n * TypeScript with type information for the functions we're using for IPC.\n */\nexport {};\n\ndeclare global {\n  interface Window {\n    electronAPI?: {\n      /**\n       * Asynchronously fetches the secure API key from the main process.\n       * @returns {Promise<string|null>} A promise that resolves with the API key or null if not found.\n       */\n      getApiKey: () => Promise<string | null>;\n      /**\n       * Registers a callback for backend status updates from the main process.\n       * @param callback The function to execute. Receives an object with state and logs.\n       * @returns A function to unsubscribe the listener.\n       */\n      onBackendStatusUpdate: (callback: (status: { state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }) => void) => () => void;\n\n      /**\n       * Sends a command to the main process to restart the backend executable.\n       */\n      restartBackend: () => void;\n\n      /**\n       * Asynchronously fetches the current backend status from the main process.\n       * @returns {Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>}\n       */\n      getBackendStatus: () => Promise<{ state: 'starting' | 'running' | 'error' | 'stopped'; logs: string[] }>;\n      generateApiKey: () => Promise<string>;\n      saveApiKey: (apiKey: string) => Promise<{ success: boolean }>;\n      saveBetfairCredentials: (credentials: { appKey: string; username: string; password: string }) => Promise<{ success: boolean }>;\n      getApiPort: () => Promise<number | null>;\n    };\n  }\n}\n",
    "web_service/frontend/postcss.config.js": "module.exports = {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n};",
    "wix/product.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:util=\"http://schemas.microsoft.com/wix/UtilExtension\">\n\n  <Product\n    Id=\"*\"\n    Name=\"Fortuna Faucet - Racing Analysis Engine\"\n    Language=\"1033\"\n    Version=\"$(var.Version)\"\n    Manufacturer=\"Mason J0 Studios\"\n    UpgradeCode=\"12345678-1234-1234-1234-123456789012\">\n\n    <Package\n      InstallerVersion=\"200\"\n      Compressed=\"yes\"\n      InstallScope=\"perMachine\"\n      Platform=\"x64\"\n      Description=\"Horse racing analysis platform\"\n      Comments=\"Professional-grade installer\"/>\n\n    <Media Id=\"1\" Cabinet=\"fortuna.cab\" EmbedCab=\"yes\"/>\n\n    <!-- Directory Structure -->\n    <Directory Id=\"TARGETDIR\" Name=\"SourceDir\">\n      <Directory Id=\"ProgramFiles64Folder\">\n        <Directory Id=\"INSTALLFOLDER\" Name=\"Fortuna Faucet\">\n        </Directory>\n      </Directory>\n      <Directory Id=\"ProgramMenuFolder\">\n        <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Faucet\"/>\n      </Directory>\n    </Directory>\n\n    <!-- Environment Variable -->\n    <ComponentGroup Id=\"EnvironmentComponentGroup\" Directory=\"INSTALLFOLDER\">\n      <Component Id=\"FortunaPortEnvironmentVar\" Guid=\"*\">\n        <Environment Id=\"FortunaPort\" Name=\"FORTUNA_PORT\" Value=\"8000\" Permanent=\"no\" Action=\"set\" System=\"yes\" />\n        <RegistryValue Root=\"HKLM\" Key=\"Software\\Fortuna Faucet\" Name=\"Path\" Type=\"string\" Value=\"[INSTALLFOLDER]\" KeyPath=\"yes\" />\n      </Component>\n    </ComponentGroup>\n\n    <!-- Features -->\n    <!-- Service Installation -->\n    <ComponentGroup Id=\"ServiceComponentGroup\" Directory=\"INSTALLFOLDER\">\n        <Component Id=\"FortunaBackendService\" Guid=\"*\">\n            <File Id=\"fortuna-backend.exe\" Source=\"$(var.BackendPath)\" KeyPath=\"yes\" />\n            <ServiceInstall\n                Id=\"FortunaServiceInstall\"\n                Type=\"ownProcess\"\n                Name=\"Fortuna\"\n                DisplayName=\"Fortuna Faucet Backend\"\n                Description=\"Data aggregation and analysis engine for horse racing.\"\n                Start=\"auto\"\n                Account=\"LocalSystem\"\n                ErrorControl=\"normal\" />\n            <ServiceControl Id=\"StartFortunaService\" Start=\"install\" Stop=\"uninstall\" Remove=\"uninstall\" Name=\"Fortuna\" Wait=\"no\" />\n        </Component>\n    </ComponentGroup>\n\n    <Feature Id=\"ProductFeature\" Title=\"Fortuna Faucet\" Level=\"1\">\n        <ComponentGroupRef Id=\"BackendFileGroup\"/>\n        <ComponentGroupRef Id=\"FrontendFileGroup\"/>\n        <ComponentGroupRef Id=\"ShortcutsComponentGroup\"/>\n        <ComponentGroupRef Id=\"EnvironmentComponentGroup\"/>\n        <ComponentGroupRef Id=\"ServiceComponentGroup\"/>\n    </Feature>\n\n    <!-- Shortcuts -->\n    <ComponentGroup Id=\"ShortcutsComponentGroup\" Directory=\"ApplicationProgramsFolder\">\n      <Component Id=\"ApplicationShortcuts\" Guid=\"*\">\n          <util:InternetShortcut Id=\"DashboardShortcut\" Name=\"Fortuna Faucet Dashboard\" Target=\"http://localhost:3000\"/>\n          <Shortcut Id=\"UninstallShortcut\" Name=\"Uninstall Fortuna Faucet\" Description=\"Remove this application\" Target=\"[SystemFolder]msiexec.exe\" Arguments=\"/x [ProductCode]\" Advertise=\"no\"/>\n          <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\"/>\n          <RegistryValue Root=\"HKCU\" Key=\"Software\\Fortuna Faucet\" Name=\"Installed\" Type=\"integer\" Value=\"1\" KeyPath=\"yes\"/>\n      </Component>\n    </ComponentGroup>\n\n    <!-- UI -->\n    <UI>\n      <UIRef Id=\"WixUI_CustomInstallDir\" />\n    </UI>\n    <UIRef Id=\"WixUI_Common\" />\n    <Property Id=\"WIXUI_INSTALLDIR\" Value=\"INSTALLFOLDER\" />\n    <WixVariable Id=\"WixUILicenseRtf\" Value=\"electron\\assets\\license.rtf\"/>\n    <WixVariable Id=\"WixUIBannerBmp\" Value=\"electron\\assets\\banner.bmp\"/>\n    <WixVariable Id=\"WixUIDialogBmp\" Value=\"electron\\assets\\dialog.bmp\"/>\n\n    <Condition Message=\"Windows 7 or later (64-bit) is required\">\n      <![CDATA[Installed OR (VersionNT64 >= 601)]]>\n    </Condition>\n\n  </Product>\n</Wix>\n"
}