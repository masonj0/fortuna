{
    ".github/workflows/build-web-service-msi.yml": "name: Build Fortuna Faucet Web Service Installer\n\non:\n  push:\n    branches: [main]\n    tags:\n      - 'v*'\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.12'\n\njobs:\n  # ============================================================================\n  # STAGE 0: VALIDATION & ENVIRONMENT SETUP\n  # ============================================================================\n  validate-environment:\n    name: '\ud83d\udd0d Validate Environment & Dependencies'\n    timeout-minutes: 5\n    runs-on: windows-latest\n    outputs:\n      node-cache-hit: ${{ steps.node-cache.outputs.cache-hit }}\n      python-cache-hit: ${{ steps.python-cache.outputs.cache-hit }}\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4.1.7\n\n      - name: Validate Critical Files Exist\n        shell: pwsh\n        run: |\n          $criticalFiles = @(\n            'web_platform/frontend/package.json',\n            'web_platform/frontend/package-lock.json',\n            'python_service/requirements.txt',\n            'python_service/requirements-dev.txt',\n            'python_service/main.py',\n            'fortuna-backend-webservice.spec',\n            'build_wix/Product_WithService.wxs',\n            'build_wix/harvest.wixproj'\n          )\n          \n          $missing = @()\n          foreach ($file in $criticalFiles) {\n            if (-not (Test-Path $file)) {\n              $missing += $file\n            }\n          }\n          \n          if ($missing.Count -gt 0) {\n            Write-Host \"\u274c FATAL: Missing critical files:\" -ForegroundColor Red\n            $missing | ForEach-Object { Write-Host \"  - $_\" -ForegroundColor Red }\n            exit 1\n          }\n          Write-Host \"\u2705 All critical files present\" -ForegroundColor Green\n\n      - name: Validate Directory Structure\n        shell: pwsh\n        run: |\n          $requiredDirs = @(\n            'web_platform/frontend',\n            'python_service',\n            'build_wix'\n          )\n          \n          foreach ($dir in $requiredDirs) {\n            if (-not (Test-Path $dir -PathType Container)) {\n              Write-Host \"\u274c FATAL: Missing directory: $dir\" -ForegroundColor Red\n              exit 1\n            }\n          }\n          Write-Host \"\u2705 All required directories present\" -ForegroundColor Green\n\n      - name: Check Cache Status\n        id: node-cache\n        shell: pwsh\n        run: |\n          if (Test-Path 'web_platform/frontend/node_modules') {\n            Write-Host \"node-cache-hit=true\" >> $env:GITHUB_OUTPUT\n          } else {\n            Write-Host \"node-cache-hit=false\" >> $env:GITHUB_OUTPUT\n          }\n\n      - name: Check Python Cache Status\n        id: python-cache\n        shell: pwsh\n        run: |\n          if (Test-Path 'python_service/venv') {\n            Write-Host \"python-cache-hit=true\" >> $env:GITHUB_OUTPUT\n          } else {\n            Write-Host \"python-cache-hit=false\" >> $env:GITHUB_OUTPUT\n          }\n\n  # ============================================================================\n  # STAGE 1: FRONTEND BUILD\n  # ============================================================================\n  build-frontend:\n    name: '\ud83d\udce6 Build Frontend'\n    timeout-minutes: 15\n    needs: [validate-environment]\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4.1.7\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4.0.3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: 'web_platform/frontend/package-lock.json'\n\n      - name: Frontend - Install Dependencies\n        shell: pwsh\n        run: |\n          cd web_platform/frontend\n          Write-Host \"Installing dependencies...\" -ForegroundColor Cyan\n          npm ci --verbose\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c npm ci failed with exit code: $LASTEXITCODE\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 Dependencies installed\" -ForegroundColor Green\n\n      - name: Frontend - Security Audit\n        shell: pwsh\n        continue-on-error: true\n        run: |\n          cd web_platform/frontend\n          Write-Host \"Running npm audit...\" -ForegroundColor Cyan\n          npm audit --audit-level=moderate\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u26a0\ufe0f npm audit found issues (non-blocking)\" -ForegroundColor Yellow\n          }\n\n      - name: Frontend - Lint (if configured)\n        shell: pwsh\n        continue-on-error: true\n        run: |\n          cd web_platform/frontend\n          if (Select-String -Path 'package.json' -Pattern '\"lint\"' -Quiet) {\n            Write-Host \"Running lint...\" -ForegroundColor Cyan\n            npm run lint\n          } else {\n            Write-Host \"\u26a0\ufe0f No lint script found\" -ForegroundColor Yellow\n          }\n\n      - name: Frontend - Build\n        shell: pwsh\n        run: |\n          cd web_platform/frontend\n          Write-Host \"Building frontend...\" -ForegroundColor Cyan\n          npm run build\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c npm run build failed with exit code: $LASTEXITCODE\" -ForegroundColor Red\n            exit 1\n          }\n          \n          if (-not (Test-Path 'out')) {\n            Write-Host \"\u274c FATAL: Build output directory 'out' not created\" -ForegroundColor Red\n            exit 1\n          }\n          \n          $fileCount = (Get-ChildItem -Path 'out' -Recurse -File | Measure-Object).Count\n          if ($fileCount -eq 0) {\n            Write-Host \"\u274c FATAL: Build output directory is empty\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 Frontend build complete ($fileCount files)\" -ForegroundColor Green\n\n      - name: Verify Frontend Build Output\n        shell: pwsh\n        run: |\n          $outDir = 'web_platform/frontend/out'\n          Write-Host \"Frontend build contents:\" -ForegroundColor Cyan\n          Get-ChildItem -Path $outDir -Recurse | Select-Object -First 20 | ForEach-Object {\n            Write-Host \"  $($_.FullName.Replace($outDir, '').TrimStart('\\'))\"\n          }\n\n      - name: Upload Frontend Artifact\n        uses: actions/upload-artifact@v4.3.4\n        with:\n          name: frontend-build-output-${{ github.sha }}\n          path: web_platform/frontend/out\n          retention-days: 1\n          if-no-files-found: error\n\n      - name: Verify Frontend Artifact Upload\n        shell: pwsh\n        run: |\n          Write-Host \"\u2705 Frontend artifact uploaded successfully\" -ForegroundColor Green\n\n  # ============================================================================\n  # STAGE 2: BACKEND BUILD\n  # ============================================================================\n  build-backend:\n    name: '\ud83d\udc0d Build Backend'\n    timeout-minutes: 25\n    needs: [build-frontend]\n    runs-on: windows-latest\n    env:\n      PYTHONUTF8: \"1\"\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4.1.7\n\n      - name: Setup Python\n        uses: actions/setup-python@v5.1.1\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'python_service/requirements.txt'\n\n      - name: Verify Python Installation\n        shell: pwsh\n        run: |\n          python --version\n          pip --version\n          Write-Host \"\u2705 Python environment verified\" -ForegroundColor Green\n\n      - name: Create Required Directories\n        shell: pwsh\n        run: |\n          $requiredDirs = @(\n            'python_service/adapters',\n            'python_service/data',\n            'python_service/json',\n            'staging/ui'\n          )\n          \n          foreach ($dir in $requiredDirs) {\n            if (-not (Test-Path $dir)) {\n              New-Item -ItemType Directory -Path $dir -Force | Out-Null\n              Write-Host \"\u2705 Created: $dir\" -ForegroundColor Green\n            }\n          }\n\n      - name: Download Frontend Artifact\n        uses: actions/download-artifact@v4.1.8\n        with:\n          name: frontend-build-output-${{ github.sha }}\n          path: ./temp-frontend\n\n      - name: Verify Frontend Artifact Downloaded\n        shell: pwsh\n        run: |\n          if (-not (Test-Path 'temp-frontend')) {\n            Write-Host \"\u274c FATAL: Frontend artifact not downloaded\" -ForegroundColor Red\n            exit 1\n          }\n          $fileCount = (Get-ChildItem -Path 'temp-frontend' -Recurse -File | Measure-Object).Count\n          if ($fileCount -eq 0) {\n            Write-Host \"\u274c FATAL: Downloaded frontend artifact is empty\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 Frontend artifact verified ($fileCount files)\" -ForegroundColor Green\n\n      - name: Stage Frontend for PyInstaller\n        shell: pwsh\n        run: |\n          $sourceDir = 'temp-frontend'\n          $destinationDir = 'staging/ui'\n          \n          Write-Host \"Staging frontend from $sourceDir to $destinationDir\" -ForegroundColor Cyan\n          \n          if (Test-Path $destinationDir) {\n            Remove-Item -Recurse -Force $destinationDir\n          }\n          New-Item -ItemType Directory -Path $destinationDir -Force | Out-Null\n          \n          Copy-Item -Path \"$sourceDir/*\" -Destination $destinationDir -Recurse -Force\n          \n          $stagedFileCount = (Get-ChildItem -Path $destinationDir -Recurse -File | Measure-Object).Count\n          if ($stagedFileCount -eq 0) {\n            Write-Host \"\u274c FATAL: Staging failed - destination is empty\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 Frontend staged successfully ($stagedFileCount files)\" -ForegroundColor Green\n\n      - name: Verify Critical Python Files\n        shell: pwsh\n        run: |\n          $criticalFiles = @(\n            'python_service/main.py',\n            'fortuna-backend-webservice.spec'\n          )\n          \n          foreach ($file in $criticalFiles) {\n            if (-not (Test-Path $file)) {\n              Write-Host \"\u274c FATAL: Missing critical file: $file\" -ForegroundColor Red\n              exit 1\n            }\n          }\n          Write-Host \"\u2705 All critical Python files present\" -ForegroundColor Green\n\n      - name: Install Python Dependencies\n        shell: pwsh\n        run: |\n          Write-Host \"Installing Python dependencies...\" -ForegroundColor Cyan\n          python -m pip install --upgrade pip setuptools wheel\n          \n          pip install -r python_service/requirements.txt\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c FATAL: pip install failed\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 Python dependencies installed\" -ForegroundColor Green\n\n      - name: Install Development Dependencies\n        shell: pwsh\n        run: |\n          Write-Host \"Installing dev dependencies...\" -ForegroundColor Cyan\n          pip install -r python_service/requirements-dev.txt\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c FATAL: pip install dev failed\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 Dev dependencies installed\" -ForegroundColor Green\n\n      - name: Backend - Security Audit\n        shell: pwsh\n        continue-on-error: true\n        run: |\n          Write-Host \"Running pip-audit...\" -ForegroundColor Cyan\n          pip install pip-audit\n          pip-audit -r python_service/requirements.txt --local\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u26a0\ufe0f pip-audit found issues (non-blocking)\" -ForegroundColor Yellow\n          }\n\n      - name: Verify PyInstaller Spec\n        shell: pwsh\n        run: |\n          $specFile = 'fortuna-backend-webservice.spec'\n          $specContent = Get-Content $specFile -Raw\n          \n          if ($specContent -notmatch 'Analysis|PyInstaller') {\n            Write-Host \"\u274c FATAL: PyInstaller spec file appears invalid\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 PyInstaller spec file validated\" -ForegroundColor Green\n\n      - name: Backend - Build with PyInstaller\n        shell: pwsh\n        run: |\n          Write-Host \"Building backend with PyInstaller...\" -ForegroundColor Cyan\n          pyinstaller fortuna-backend-webservice.spec --noconfirm\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c FATAL: PyInstaller build failed\" -ForegroundColor Red\n            exit 1\n          }\n          \n          if (-not (Test-Path 'dist/fortuna-backend.exe')) {\n            Write-Host \"\u274c FATAL: PyInstaller did not produce fortuna-backend.exe\" -ForegroundColor Red\n            Get-ChildItem -Path 'dist' -Recurse | ForEach-Object { Write-Host \"  Found: $_\" }\n            exit 1\n          }\n          \n          $exeSize = (Get-Item 'dist/fortuna-backend.exe').Length / 1MB\n          Write-Host \"\u2705 Backend executable created (${exeSize:.1f} MB)\" -ForegroundColor Green\n\n      - name: Verify Backend Executable\n        shell: pwsh\n        run: |\n          $exe = 'dist/fortuna-backend.exe'\n          \n          if (-not (Test-Path $exe)) {\n            Write-Host \"\u274c FATAL: Executable not found at $exe\" -ForegroundColor Red\n            exit 1\n          }\n          \n          $fileInfo = Get-Item $exe\n          if ($fileInfo.Length -lt 10MB) {\n            Write-Host \"\u26a0\ufe0f WARNING: Executable is suspiciously small ($(${fileInfo.Length} / 1MB) MB)\" -ForegroundColor Yellow\n          }\n          \n          Write-Host \"\u2705 Backend executable verified\" -ForegroundColor Green\n          Write-Host \"  Size: $($fileInfo.Length / 1MB) MB\" -ForegroundColor Green\n          Write-Host \"  Modified: $($fileInfo.LastWriteTime)\" -ForegroundColor Green\n\n      - name: Upload Backend Artifact\n        uses: actions/upload-artifact@v4.3.4\n        with:\n          name: backend-executable-${{ github.sha }}\n          path: dist/fortuna-backend.exe\n          retention-days: 1\n          if-no-files-found: error\n\n      - name: Verify Backend Artifact Upload\n        shell: pwsh\n        run: |\n          Write-Host \"\u2705 Backend artifact uploaded successfully\" -ForegroundColor Green\n\n  # ============================================================================\n  # STAGE 3: SMOKE TESTS\n  # ============================================================================\n  smoke-test-backend:\n    name: '\ud83e\uddea Smoke Test Backend Executable'\n    timeout-minutes: 15\n    needs: [build-backend]\n    runs-on: windows-latest\n    steps:\n      - name: Download Backend Executable\n        uses: actions/download-artifact@v4.1.8\n        with:\n          name: backend-executable-${{ github.sha }}\n          path: ./backend-dist\n\n      - name: Verify Executable Downloaded\n        shell: pwsh\n        run: |\n          if (-not (Test-Path 'backend-dist/fortuna-backend.exe')) {\n            Write-Host \"\u274c FATAL: Backend executable not found\" -ForegroundColor Red\n            exit 1\n          }\n          Write-Host \"\u2705 Backend executable verified\" -ForegroundColor Green\n\n      - name: Run Smoke Test - Backend Health\n        shell: pwsh\n        timeout-minutes: 5\n        env:\n          API_KEY: \"a_secure_test_api_key_that_is_long_enough_for_smoke_test_12345\"\n        run: |\n          $exe = './backend-dist/fortuna-backend.exe'\n          $logDir = 'logs'\n          $stdOutPath = Join-Path $logDir 'backend-out.txt'\n          $stdErrPath = Join-Path $logDir 'backend-err.txt'\n          \n          if (-not (Test-Path $logDir)) {\n            New-Item -ItemType Directory -Path $logDir -Force | Out-Null\n          }\n          \n          Write-Host \"Starting backend process...\" -ForegroundColor Cyan\n          $process = Start-Process -FilePath $exe `\n            -PassThru `\n            -NoNewWindow `\n            -RedirectStandardOutput $stdOutPath `\n            -RedirectStandardError $stdErrPath `\n            -ErrorAction Stop\n          \n          Write-Host \"Backend process started (PID: $($process.Id))\" -ForegroundColor Green\n          \n          $serverReady = $false\n          $maxAttempts = 40\n          $attemptCount = 0\n          \n          try {\n            for ($i = 1; $i -le $maxAttempts; $i++) {\n              $attemptCount = $i\n              \n              if ($process.HasExited) {\n                Write-Host \"\u274c Backend process exited unexpectedly (Exit Code: $($process.ExitCode))\" -ForegroundColor Red\n                break\n              }\n              \n              try {\n                Write-Host \"Attempt $i/$maxAttempts: Checking /health endpoint...\" -ForegroundColor Gray\n                $response = Invoke-WebRequest `\n                  -Uri 'http://127.0.0.1:8000/health' `\n                  -TimeoutSec 2 `\n                  -UseBasicParsing `\n                  -ErrorAction SilentlyContinue\n                \n                if ($response.StatusCode -eq 200) {\n                  Write-Host \"\u2705 Health endpoint responded\" -ForegroundColor Green\n                  \n                  Write-Host \"Checking /api/races endpoint...\" -ForegroundColor Gray\n                  $headers = @{ 'X-API-Key' = $env:API_KEY }\n                  $apiResponse = Invoke-WebRequest `\n                    -Uri 'http://127.0.0.1:8000/api/races' `\n                    -Headers $headers `\n                    -TimeoutSec 2 `\n                    -UseBasicParsing `\n                    -ErrorAction SilentlyContinue\n                  \n                  if ($apiResponse.StatusCode -eq 200 -or $apiResponse.StatusCode -eq 400 -or $apiResponse.StatusCode -eq 401) {\n                    Write-Host \"\u2705 API endpoint responded (Status: $($apiResponse.StatusCode))\" -ForegroundColor Green\n                    $serverReady = $true\n                    break\n                  }\n                }\n              } catch {\n                Write-Host \"  (waiting...)\" -ForegroundColor Gray\n              }\n              \n              Start-Sleep -Seconds 1.5\n            }\n          } finally {\n            Write-Host \"Stopping backend process...\" -ForegroundColor Cyan\n            Stop-Process -Id $process.Id -Force -ErrorAction SilentlyContinue\n            Start-Sleep -Milliseconds 500\n          }\n          \n          if (-not $serverReady) {\n            Write-Host \"\u274c SMOKE TEST FAILED: Backend did not become healthy\" -ForegroundColor Red\n            Write-Host \"Attempts: $attemptCount/$maxAttempts\" -ForegroundColor Red\n            \n            if (Test-Path $stdOutPath) {\n              Write-Host \"`n--- STDOUT (last 30 lines) ---\" -ForegroundColor Yellow\n              Get-Content $stdOutPath -Tail 30 | Write-Host\n            }\n            if (Test-Path $stdErrPath) {\n              Write-Host \"`n--- STDERR (last 30 lines) ---\" -ForegroundColor Yellow\n              Get-Content $stdErrPath -Tail 30 | Write-Host\n            }\n            exit 1\n          }\n          \n          Write-Host \"`n\u2705 SMOKE TEST PASSED on attempt $attemptCount\" -ForegroundColor Green\n\n      - name: Upload Smoke Test Logs\n        if: always()\n        uses: actions/upload-artifact@v4.3.4\n        with:\n          name: smoke-test-logs-${{ github.sha }}\n          path: logs/\n          retention-days: 3\n\n  # ============================================================================\n  # STAGE 4: PACKAGING / WiX INSTALLER\n  # ============================================================================\n  build-wix-installer:\n    name: '\ud83d\udd25 Build WiX Installer (v4)'\n    timeout-minutes: 20\n    needs: [smoke-test-backend, build-frontend]\n    runs-on: windows-latest\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4.1.7\n\n      - name: Create Staging Directory\n        shell: pwsh\n        run: |\n          $stagingDir = 'build_wix/staging'\n          if (Test-Path $stagingDir) {\n            Remove-Item -Recurse -Force $stagingDir\n          }\n          New-Item -ItemType Directory -Path \"$stagingDir/ui\" -Force | Out-Null\n          Write-Host \"\u2705 Staging directory prepared\" -ForegroundColor Green\n\n      - name: Download Frontend Artifact\n        uses: actions/download-artifact@v4.1.8\n        with:\n          name: frontend-build-output-${{ github.sha }}\n          path: ./artifacts/frontend\n\n      - name: Download Backend Artifact\n        uses: actions/download-artifact@v4.1.8\n        with:\n          name: backend-executable-${{ github.sha }}\n          path: ./artifacts/backend\n\n      - name: Verify Downloaded Artifacts\n        shell: pwsh\n        run: |\n          $frontendPath = './artifacts/frontend'\n          $backendPath = './artifacts/backend/fortuna-backend.exe'\n          \n          if (-not (Test-Path $frontendPath)) {\n            Write-Host \"\u274c FATAL: Frontend artifact not found\" -ForegroundColor Red\n            exit 1\n          }\n          \n          if (-not (Test-Path $backendPath)) {\n            Write-Host \"\u274c FATAL: Backend executable not found\" -ForegroundColor Red\n            exit 1\n          }\n          \n          $frontendFiles = (Get-ChildItem -Path $frontendPath -Recurse -File | Measure-Object).Count\n          $backendSize = (Get-Item $backendPath).Length / 1MB\n          \n          Write-Host \"\u2705 Artifacts verified:\" -ForegroundColor Green\n          Write-Host \"  Frontend: $frontendFiles files\" -ForegroundColor Green\n          Write-Host \"  Backend: ${backendSize:.1f} MB\" -ForegroundColor Green\n\n      - name: Stage Artifacts for WiX\n        shell: pwsh\n        run: |\n          $wixStaging = 'build_wix/staging'\n          $uiDir = \"$wixStaging/ui\"\n          \n          Write-Host \"Copying backend executable...\" -ForegroundColor Cyan\n          Copy-Item -Path './artifacts/backend/fortuna-backend.exe' `\n            -Destination \"$wixStaging/fortuna-backend.exe\" -Force\n          \n          Write-Host \"Copying frontend files...\" -ForegroundColor Cyan\n          Copy-Item -Path './artifacts/frontend/*' `\n            -Destination $uiDir -Recurse -Force\n          \n          $backendExists = Test-Path \"$wixStaging/fortuna-backend.exe\"\n          $frontendCount = (Get-ChildItem -Path $uiDir -Recurse -File | Measure-Object).Count\n          \n          if (-not $backendExists) {\n            Write-Host \"\u274c FATAL: Backend not staged correctly\" -ForegroundColor Red\n            exit 1\n          }\n          \n          if ($frontendCount -eq 0) {\n            Write-Host \"\u274c FATAL: Frontend staging failed (0 files)\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 All artifacts staged successfully\" -ForegroundColor Green\n          Write-Host \"  Backend: staged\" -ForegroundColor Green\n          Write-Host \"  Frontend: $frontendCount files\" -ForegroundColor Green\n\n      - name: Setup .NET for WiX v4\n        uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: '6.0.x'\n\n      - name: Verify .NET Installation\n        shell: pwsh\n        run: |\n          dotnet --version\n          Write-Host \"\u2705 .NET SDK verified\" -ForegroundColor Green\n\n      - name: Install WiX v4 Toolset\n        shell: pwsh\n        run: |\n          Write-Host \"Installing WiX toolset...\" -ForegroundColor Cyan\n          dotnet tool install --global wix\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c FATAL: WiX installation failed\" -ForegroundColor Red\n            exit 1\n          }\n          \n          wix --version\n          Write-Host \"\u2705 WiX toolset installed\" -ForegroundColor Green\n\n      - name: Add WiX Extensions\n        shell: pwsh\n        run: |\n          Write-Host \"Adding WiX extensions...\" -ForegroundColor Cyan\n          wix extension add WixToolset.Util.wixext\n          wix extension add WixToolset.Firewall.wixext\n          Write-Host \"\u2705 Extensions installed\" -ForegroundColor Green\n\n      - name: Verify WiX Configuration Files\n        shell: pwsh\n        run: |\n          $files = @(\n            'build_wix/Product_WithService.wxs',\n            'build_wix/harvest.wixproj'\n          )\n          \n          foreach ($file in $files) {\n            if (-not (Test-Path $file)) {\n              Write-Host \"\u274c FATAL: Missing $file\" -ForegroundColor Red\n              exit 1\n            }\n          }\n          Write-Host \"\u2705 WiX configuration files verified\" -ForegroundColor Green\n\n      - name: Run WiX Heat (Frontend Harvesting)\n        shell: pwsh\n        run: |\n          Write-Host \"Harvesting frontend directory...\" -ForegroundColor Cyan\n          $stagingDir = \"build_wix/staging\"\n          $uiDir = \"$stagingDir/ui\"\n          \n          if (-not (Test-Path $uiDir)) {\n            Write-Host \"\u274c FATAL: UI staging directory not found\" -ForegroundColor Red\n            exit 1\n          }\n          \n          $fileCount = (Get-ChildItem -Path $uiDir -Recurse -File | Measure-Object).Count\n          if ($fileCount -eq 0) {\n            Write-Host \"\u274c FATAL: No files in UI directory to harvest\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"Files to harvest: $fileCount\" -ForegroundColor Green\n          \n          dotnet msbuild build_wix/harvest.wixproj -restore -t:GenerateFrontendWxs -v:minimal\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c FATAL: Heat harvest failed\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 Frontend harvest complete\" -ForegroundColor Green\n\n      - name: Validate Generated Frontend Components\n        shell: pwsh\n        run: |\n          $filePath = 'build_wix/frontend_components.wxs'\n          \n          if (-not (Test-Path $filePath)) {\n            Write-Host \"\u274c FATAL: frontend_components.wxs not generated\" -ForegroundColor Red\n            exit 1\n          }\n          \n          $content = Get-Content $filePath -Raw\n          \n          if ($content -notmatch '<ComponentGroup Id=\"FrontendComponents\">') {\n            Write-Host \"\u274c FATAL: Missing FrontendComponents ComponentGroup\" -ForegroundColor Red\n            exit 1\n          }\n          \n          $fileCount = ([regex]::Matches($content, '<File')).Count\n          if ($fileCount -eq 0) {\n            Write-Host \"\u274c FATAL: No files in generated WXS\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 Generated WXS validated\" -ForegroundColor Green\n          Write-Host \"  Files: $fileCount\" -ForegroundColor Green\n\n      - name: Build MSI with WiX\n        shell: pwsh\n        run: |\n          $sourceDir = \"$PWD/build_wix/staging\"\n          $uiDir = \"$sourceDir/ui\"\n          $outputDir = 'dist'\n          $msiName = 'Fortuna-Full-App-Service-v4.msi'\n          \n          if (-not (Test-Path $outputDir)) {\n            New-Item -ItemType Directory -Path $outputDir -Force | Out-Null\n          }\n          \n          Write-Host \"Building MSI...\" -ForegroundColor Cyan\n          Write-Host \"  Source: $sourceDir\" -ForegroundColor Gray\n          Write-Host \"  Output: $outputDir/$msiName\" -ForegroundColor Gray\n          \n          wix build `\n            build_wix/Product_WithService.wxs `\n            build_wix/frontend_components.wxs `\n            -ext WixToolset.Util.wixext `\n            -ext WixToolset.Firewall.wixext `\n            -d \"SourceDir=$sourceDir\" `\n            -d \"FrontendSourceDir=$uiDir\" `\n            -o \"$outputDir/$msiName\"\n          \n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c FATAL: MSI build failed\" -ForegroundColor Red\n            exit 1\n          }\n          \n          if (-not (Test-Path \"$outputDir/$msiName\")) {\n            Write-Host \"\u274c FATAL: MSI not created at expected location\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"\u2705 MSI created successfully\" -ForegroundColor Green\n\n      - name: Verify MSI\n        shell: pwsh\n        run: |\n          $msiPath = 'dist/Fortuna-Full-App-Service-v4.msi'\n          \n          if (-not (Test-Path $msiPath)) {\n            Write-Host \"\u274c FATAL: MSI file not found\" -ForegroundColor Red\n            exit 1\n          }\n          \n          $msiSize = (Get-Item $msiPath).Length / 1MB\n          \n          if ($msiSize -lt 5) {\n            Write-Host \"\u26a0\ufe0f WARNING: MSI is suspiciously small (${msiSize:.1f} MB)\" -ForegroundColor Yellow\n          }\n          \n          Write-Host \"\u2705 MSI verified\" -ForegroundColor Green\n          Write-Host \"  Size: ${msiSize:.1f} MB\" -ForegroundColor Green\n          Write-Host \"  Path: $msiPath\" -ForegroundColor Green\n\n      - name: Upload WiX MSI Artifact\n        uses: actions/upload-artifact@v4.3.4\n        with:\n          name: fortuna-wix-installer-windows-v4\n          path: dist/Fortuna-Full-App-Service-v4.msi\n          retention-days: 7\n          if-no-files-found: error\n\n      - name: Create Release Summary\n        shell: pwsh\n        run: |\n          $msiPath = 'dist/Fortuna-Full-App-Service-v4.msi'\n          $msiSize = (Get-Item $msiPath).Length / 1MB\n          $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n          \n          Write-Host \"`n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\" -ForegroundColor Green\n          Write-Host \"\u2551          BUILD COMPLETE - SUCCESS              \u2551\" -ForegroundColor Green\n          Write-Host \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\" -ForegroundColor Green\n          Write-Host \"`nBuild Summary:\" -ForegroundColor Cyan\n          Write-Host \"  Timestamp: $timestamp\" -ForegroundColor Green\n          Write-Host \"  Commit: ${{ github.sha }}\" -ForegroundColor Green\n          Write-Host \"  Branch: ${{ github.ref }}\" -ForegroundColor Green\n          Write-Host \"`nArtifacts Generated:\" -ForegroundColor Cyan\n          Write-Host \"  \u2705 Frontend Build\" -ForegroundColor Green\n          Write-Host \"  \u2705 Backend Executable\" -ForegroundColor Green\n          Write-Host \"  \u2705 Smoke Tests Passed\" -ForegroundColor Green\n          Write-Host \"  \u2705 WiX MSI Installer\" -ForegroundColor Green\n          Write-Host \"`nInstaller Details:\" -ForegroundColor Cyan\n          Write-Host \"  File: Fortuna-Full-App-Service-v4.msi\" -ForegroundColor Green\n          Write-Host \"  Size: ${msiSize:.1f} MB\" -ForegroundColor Green\n          Write-Host \"  Location: dist/\" -ForegroundColor Green\n\n  # ============================================================================\n  # FINAL STAGE: BUILD STATUS & NOTIFICATIONS\n  # ============================================================================\n  build-status:\n    name: '\u2705 Build Status Summary'\n    timeout-minutes: 5\n    needs: [build-wix-installer]\n    runs-on: windows-latest\n    if: always()\n    steps:\n      - name: Check Overall Build Status\n        shell: pwsh\n        run: |\n          $needsContext = '${{ needs }}'\n          Write-Host \"Build Pipeline Summary:\" -ForegroundColor Cyan\n          Write-Host \"  Validate Environment: ${{ needs.validate-environment.result }}\" -ForegroundColor Green\n          Write-Host \"  Build Frontend: ${{ needs.build-frontend.result }}\" -ForegroundColor Green\n          Write-Host \"  Build Backend: ${{ needs.build-backend.result }}\" -ForegroundColor Green\n          Write-Host \"  Smoke Tests: ${{ needs.smoke-test-backend.result }}\" -ForegroundColor Green\n          Write-Host \"  Build Installer: ${{ needs.build-wix-installer.result }}\" -ForegroundColor Green\n          \n          if ('${{ needs.build-wix-installer.result }}' -ne 'success') {\n            Write-Host \"`n\u274c Build pipeline failed!\" -ForegroundColor Red\n            exit 1\n          }\n          \n          Write-Host \"`n\u2705 All stages completed successfully!\" -ForegroundColor Green\n\n      - name: Generate Build Report\n        if: success()\n        shell: pwsh\n        run: |\n          Write-Host \"`n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\" -ForegroundColor Green\n          Write-Host \"\u2551    FORTUNA FAUCET BUILD PIPELINE SUCCESSFUL    \u2551\" -ForegroundColor Green\n          Write-Host \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\" -ForegroundColor Green\n          Write-Host \"`n\u2705 All stages passed:\" -ForegroundColor Green\n          Write-Host \"  1. Environment validation\" -ForegroundColor Green\n          Write-Host \"  2. Frontend build with security audit\" -ForegroundColor Green\n          Write-Host \"  3. Backend build with PyInstaller\" -ForegroundColor Green\n          Write-Host \"  4. Backend smoke tests (health + API)\" -ForegroundColor Green\n          Write-Host \"  5. WiX installer packaging\" -ForegroundColor Green\n          Write-Host \"`nArtifacts Ready for Release:\" -ForegroundColor Cyan\n          Write-Host \"  \ud83d\udce6 Fortuna-Full-App-Service-v4.msi\" -ForegroundColor Green\n          Write-Host \"`nNext Steps:\" -ForegroundColor Cyan\n          Write-Host \"  1. Download MSI from artifacts\" -ForegroundColor Yellow\n          Write-Host \"  2. Test on target system\" -ForegroundColor Yellow\n          Write-Host \"  3. Create GitHub release\" -ForegroundColor Yellow\n          Write-Host \"  4. Publish to distribution channels\" -ForegroundColor Yellow\n\n      - name: Failure Report\n        if: failure()\n        shell: pwsh\n        run: |\n          Write-Host \"`n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\" -ForegroundColor Red\n          Write-Host \"\u2551           BUILD PIPELINE FAILED                \u2551\" -ForegroundColor Red\n          Write-Host \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\" -ForegroundColor Red\n          Write-Host \"`nFailed Jobs:\" -ForegroundColor Red\n          Write-Host \"  Validate Environment: ${{ needs.validate-environment.result }}\" -ForegroundColor $(if('${{ needs.validate-environment.result }}' -eq 'failure'){'Red'}else{'Green'})\n          Write-Host \"  Build Frontend: ${{ needs.build-frontend.result }}\" -ForegroundColor $(if('${{ needs.build-frontend.result }}' -eq 'failure'){'Red'}else{'Green'})\n          Write-Host \"  Build Backend: ${{ needs.build-backend.result }}\" -ForegroundColor $(if('${{ needs.build-backend.result }}' -eq 'failure'){'Red'}else{'Green'})\n          Write-Host \"  Smoke Tests: ${{ needs.smoke-test-backend.result }}\" -ForegroundColor $(if('${{ needs.smoke-test-backend.result }}' -eq 'failure'){'Red'}else{'Green'})\n          Write-Host \"  Build Installer: ${{ needs.build-wix-installer.result }}\" -ForegroundColor $(if('${{ needs.build-wix-installer.result }}' -eq 'failure'){'Red'}else{'Green'})\n          Write-Host \"`nDebugging:\" -ForegroundColor Yellow\n          Write-Host \"  1. Check job logs for specific errors\" -ForegroundColor Yellow\n          Write-Host \"  2. Review artifact uploads\" -ForegroundColor Yellow\n          Write-Host \"  3. Verify environment setup\" -ForegroundColor Yellow\n",
    ".github/workflows/codeql.yml": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may plcace this file in any folder within the .github/workflows folder.\n# GitHub will find and execute it.\n#\n# To learn more about the language matrix, please visit https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#changing-the-languages-that-are-analyzed\n\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ main ]\n  schedule:\n    - cron: '22 5 * * 1'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'python', 'javascript' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v3\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries are pulled from a suite stored in GitHub.\n        # See https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v3\n\n    # \u2139\ufe0f Command-line programs to run using the OS shell.\n    # \ud83d\udcda See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines.\n    #   and modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #     echo \"Run, Build Application using script\"\n    #     ./build.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v3\n      with:\n        category: \"/language:${{matrix.language}}\"\n",
    "ARCHITECTURAL_MANDATE.md": "# Fortuna Faucet - Architectural Mandate (v3.0)\n\nThis document codifies the architectural laws and philosophical principles that govern the Fortuna Faucet kingdom. Adherence to this mandate is non-negotiable for all development.\n\n---\n\n## The Prime Directive: A Professional, Resilient System\n\nThe ultimate goal of this project is to be a professional-grade, A+ intelligence engine. This is achieved through three core pillars:\n\n1.  **Rigid Standardization:** Code should be consistent and predictable. Shared logic must be centralized. Common patterns must be enforced, not merely suggested.\n2.  **Resilience Engineering:** The system must be self-healing and gracefully handle the failure of its individual components. We do not simply handle errors; we build a system that anticipates and survives them.\n3.  **Developer Clarity:** The codebase must be easy to understand, maintain, and extend. Code should be self-documenting, and its intent should be obvious.\n\n---\n\n## The Law of the Adapters: The `BaseAdapterV3` Pattern\n\nAll new data adapters **MUST** inherit from the `BaseAdapterV3` abstract base class. This is the cornerstone of our standardization and resilience strategy.\n\nThe `BaseAdapterV3` enforces a strict separation of concerns:\n\n1.  **`_fetch_data(self, date)` -> `Any`:** This method's **only** responsibility is to perform network operations and retrieve raw data (e.g., HTML, JSON). It should contain no parsing logic.\n2.  **`_parse_races(self, raw_data)` -> `list[Race]`:** This method's **only** responsibility is to parse the raw data provided by `_fetch_data` into a list of `Race` objects. It must be a pure function with no side effects or network calls.\n\nThe public-facing `get_races()` method is provided by the base class and **MUST NOT** be overridden. It orchestrates the fetch-then-parse pipeline, ensuring that all adapters behave identically from the engine's perspective.\n\nThis pattern guarantees that every adapter in our fleet is consistent, predictable, and easy to test.\n\n---\n\n## The Law of the Engine: Orchestrate, Don't Participate\n\nThe `OddsEngine` is the central orchestrator. Its responsibilities are:\n\n-   To manage the fleet of active adapters.\n-   To execute all adapter fetches in parallel.\n-   To gracefully handle the failure of any individual adapter without halting the entire process.\n-   To perform the deduplication and merging of race data from multiple sources.\n-   To manage the caching layer (Redis).\n\nThe engine should remain agnostic to the internal workings of any specific adapter. It interacts only with the standardized interface provided by `BaseAdapterV3`.\n\n---\n\n## The Law of the Core Texts: Maintain the Truth\n\nThe project's core documentation is not optional. It is the living memory and strategic guide of the kingdom.\n\n-   **`ROADMAP_APPENDICES.MD`:** The Grand Strategy must be kept current. Completed objectives must be marked as such.\n-   **`HISTORY.MD`:** Significant architectural shifts and completed campaigns must be chronicled.\n-   **`PSEUDOCODE.MD`:** The architectural blueprint must be updated to reflect major changes to the system's design.\n-   **Manifests (`MANIFEST*.md`):** All new files must be added to the appropriate manifest to ensure the integrity of the archival system.\n\n\n---\n\n## The Final Law: The Law of the True Scribe\n\n**Effective Date:** 2025-10-15\n\n**Verdict:** The system of manually maintained manifest files (`MANIFEST.md`, `MANIFEST2.md`, `MANIFEST3.md`) is hereby declared a catastrophic failure and is **permanently deprecated**.\n\n**The New Law:** The one and only method for generating the project's `FORTUNA_ALL` archives is the `ARCHIVE_PROJECT.py` script. This 'True Scribe' is the single, automated source of truth. It programmatically scans and categorizes the entire kingdom, ensuring a perfect, complete, and uncorrupted archive is generated every time.\n\nAll previous archival scripts (`create_fortuna_json.py`, `MANAGE_MANIFESTS.py`) are not to be used under any circumstances.",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `fortuna`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n\n---\n\n## The Age of Perfection (The Great Simplification)\n\nThe Penta-Hybrid architecture, while a triumph of technical integration, proved to be a strategic dead end. Its complexity became a fortress, making rapid iteration and onboarding of new intelligence (both human and AI) prohibitively expensive. The kingdom was powerful but brittle.\n\nA new doctrine was forged: **Simplicity is the ultimate sophistication.**\n\nThe decision was made to execute \"The Great Simplification.\" The multi-language backend (Python, Rust, Go) was decommissioned. The kingdom was reforged upon a new, elegant, and vastly more powerful two-pillar system:\n\n1.  **A Unified Python Backend:** A single, asynchronous Python service, built on FastAPI, would serve as the kingdom's engine.\n2.  **A Modern TypeScript Frontend:** A dedicated Next.js application would serve as the kingdom's command deck.\n\nThis act of creative destruction liberated the project, enabling a new era of unprecedented velocity.\n\n---\n\n## The Three-Pillar Doctrine\n\nWith the new two-pillar foundation in place, the backend itself was perfected into a three-pillar intelligence engine, a concept that defines the modern era of the Fortuna Faucet:\n\n*   **Pillar 1: The Future (The Planner):** The resilient `OddsEngine` and its fleet of adapters, responsible for finding the day's strategic opportunities.\n*   **Pillar 2: The Past (The Archive):** The perfected `ChartScraper` and `ResultsParser`, responsible for building our historical data warehouse from the ground truth of Equibase PDFs.\n*   **Pillar 3: The Present (The Finisher):** The weaponized `LiveOddsMonitor`, armed with the API-driven `BetfairAdapter`, designed to conquer the final moments of toteboard volatility.\n\nThese three pillars, orchestrated by the fully autonomous `fortuna_watchman.py`, represented the pinnacle of the project's original vision. The kingdom was, for a time, considered \"perfected.\"\n\n---\n\n## The Windows Ascension (The Impossible Dream)\n\nThe perfected kingdom was powerful, but it was still a tool for developers. The final, grandest vision was to transform it into a true, professional-grade application for its sole operator. This campaign, known as \"The Impossible Dream,\" was to forge the **Fortuna Faucet - Windows Native Edition.**\n\nThis era saw the rapid creation of a new, third layer of the kingdom, built upon the foundation of the previous work:\n\n*   **The Electron Shell:** The Next.js frontend was wrapped in an Electron container, transforming it from a website into a true, installable desktop application with its own window, icon, and system tray integration.\n*   **The Engine Room:** The Python backend was re-architected to run as a persistent, background **Windows Service**, making it a true, always-on component of the operating system, independent of the UI.\n*   **The Native GUI:** A dedicated Tkinter-based \"Observatory\" was forged\u2014a standalone GUI mission control for monitoring the health and performance of the background service.\n*   **The One-Click Kingdom:** A complete suite of professional tooling (including installation scripts, a setup wizard, and launchers) was created to provide a seamless, zero-friction installation and management experience.\n\nThis ascension represents the current state of the art, transforming a powerful engine into a polished, autonomous, and user-focused product.\n\n\n---\n\n## The Era of the Windows Kingdom (October 2025)\n\nWith the core engine stabilized and the command deck providing a clear view of the data, the project's focus shifted from pure data acquisition to the operator's experience. This era marked a profound transformation, elevating the project from a collection of powerful but disparate scripts into a cohesive, professional-grade, and resilient native Windows application.\n\nThis campaign, guided by a new \"Grand Strategy\" blueprint, was executed with rapid precision, resulting in a complete overhaul of the user-facing toolkit:\n\n-   **A Bulletproof Foundation:** The installation and launch scripts were re-architected from the ground up. They became intelligent and self-healing, featuring pre-flight system checks, automated port conflict resolution, active health-check loops, and automated repair utilities.\n-   **A Professional Toolkit:** The operator was empowered with a suite of new tools, including an interactive setup wizard, a real-time CLI status monitor, and a full-fledged graphical \"Data Management Console\" for monitoring, filtering, and analyzing data.\n-   **A Unified Command Console (`SERVICE_MANAGER.bat`):** Unify all individual scripts under a single, user-friendly, menu-driven service manager, providing a 'single pane of glass' for all common operations.\n\nThis era solidified the kingdom's foundations, making it not just powerful, but stable, reliable, and a pleasure to operate. The Faucet was no longer just an engine; it was a complete, professional-grade machine.\n\n---\n\n## The Gauntlet of CI/CD (Late October 2025)\n\nWith a professional-grade application in hand, the final frontier was professional-grade *delivery*. This campaign focused on automating the creation of the MSI installer through a continuous integration pipeline, a process that proved to be a formidable challenge.\n\nThe kingdom's engineers faced a relentless series of cryptic build errors from the WiX Toolset, a hostile environment that tested their resolve. Through a series of rapid, iterative fixes\u2014addressing everything from component GUIDs and 64-bit architecture mismatches to obscure linker errors and frontend dependency warnings\u2014they systematically conquered each obstacle.\n\nThis trial by fire culminated in a triumphant success: a fully automated GitHub Actions workflow that reliably compiles, links, and delivers a polished, distributable MSI installer. This victory transformed the project's delivery model from a manual, error-prone process into a repeatable, one-click release pipeline, marking the true completion of the \"Windows Ascension.\"\n\n---\n\n## The Great Unbundling (Late October 2025)\n\nThe CI/CD pipeline was technically successful, but it revealed a deeper, philosophical flaw in the architecture. The installer, while automated, was a fragile monolith. It attempted to bundle raw source code (Python, JavaScript) and orchestrate their setup on the user's machine using post-install scripts. This approach was fraught with peril, vulnerable to failures from network issues, corporate firewalls, and unpredictable machine states.\n\nA final, decisive architectural mandate was issued, informed by the wisdom of external AI consultants: **The application must be delivered, not assembled.**\n\nThis mandate triggered \"The Great Unbundling,\" a swift and transformative refactoring of the entire delivery pipeline:\n\n*   **The Backend Forged:** The Python backend was no longer treated as source code to be installed, but as a product to be delivered. **PyInstaller** was used to forge the entire FastAPI service\u2014interpreter and all dependencies\u2014into a single, standalone `.exe`.\n*   **The Frontend Solidified:** The Next.js frontend was no longer a service to be run, but a static asset to be displayed. The `npm run build` process was configured to produce a clean, static HTML/CSS/JS export.\n*   **The Installer Perfected:** With the application components now self-contained, the MSI installer's role was radically simplified. All complex post-install scripting was eliminated. The WiX toolset was now used for its core competency: reliably copying pre-compiled, robust artifacts to the user's machine.\n\nThis final act of architectural purification created the \"Three-Executable Architecture\" (the backend executable, the Electron wrapper, and the MSI installer itself), achieving true portability and eliminating an entire class of deployment failures. The Windows Ascension was not just complete; it was perfected.",
    "MANIFEST_PART1_BACKEND.json": "[\n    \"python_service/__init__.py\",\n    \"python_service/adapters/__init__.py\",\n    \"python_service/adapters/at_the_races_adapter.py\",\n    \"python_service/adapters/base_adapter_v3.py\",\n    \"python_service/adapters/betfair_adapter.py\",\n    \"python_service/adapters/betfair_auth_mixin.py\",\n    \"python_service/adapters/betfair_datascientist_adapter.py\",\n    \"python_service/adapters/betfair_greyhound_adapter.py\",\n    \"python_service/adapters/brisnet_adapter.py\",\n    \"python_service/adapters/drf_adapter.py\",\n    \"python_service/adapters/equibase_adapter.py\",\n    \"python_service/adapters/fanduel_adapter.py\",\n    \"python_service/adapters/gbgb_api_adapter.py\",\n    \"python_service/adapters/greyhound_adapter.py\",\n    \"python_service/adapters/harness_adapter.py\",\n    \"python_service/adapters/horseracingnation_adapter.py\",\n    \"python_service/adapters/nyrabets_adapter.py\",\n    \"python_service/adapters/oddschecker_adapter.py\",\n    \"python_service/adapters/pointsbet_greyhound_adapter.py\",\n    \"python_service/adapters/punters_adapter.py\",\n    \"python_service/adapters/racing_and_sports_adapter.py\",\n    \"python_service/adapters/racing_and_sports_greyhound_adapter.py\",\n    \"python_service/adapters/racingpost_adapter.py\",\n    \"python_service/adapters/racingtv_adapter.py\",\n    \"python_service/adapters/sporting_life_adapter.py\",\n    \"python_service/adapters/tab_adapter.py\",\n    \"python_service/adapters/template_adapter.py\",\n    \"python_service/adapters/the_racing_api_adapter.py\",\n    \"python_service/adapters/timeform_adapter.py\",\n    \"python_service/adapters/tvg_adapter.py\",\n    \"python_service/adapters/twinspires_adapter.py\",\n    \"python_service/adapters/universal_adapter.py\",\n    \"python_service/adapters/utils.py\",\n    \"python_service/adapters/xpressbet_adapter.py\",\n    \"python_service/analyzer.py\",\n    \"python_service/api.py\",\n    \"python_service/cache_manager.py\",\n    \"python_service/config.py\",\n    \"python_service/core/__init__.py\",\n    \"python_service/core/errors.py\",\n    \"python_service/core/exceptions.py\",\n    \"python_service/credentials_manager.py\",\n    \"python_service/db/init.py\",\n    \"python_service/engine.py\",\n    \"python_service/etl.py\",\n    \"python_service/fortuna_service.py\",\n    \"python_service/fortuna_watchman.py\",\n    \"python_service/fortuna_windows_service.py\",\n    \"python_service/health.py\",\n    \"python_service/health_check.py\",\n    \"python_service/initialize_db.py\",\n    \"python_service/logging_config.py\",\n    \"python_service/main.py\",\n    \"python_service/manual_override_manager.py\",\n    \"python_service/middleware/__init__.py\",\n    \"python_service/middleware/error_handler.py\",\n    \"python_service/models.py\",\n    \"python_service/models_v3.py\",\n    \"python_service/notifications.py\",\n    \"python_service/requirements-dev.txt\",\n    \"python_service/requirements.in\",\n    \"python_service/requirements.txt\",\n    \"python_service/requirements_minimal.txt\",\n    \"python_service/run_api.py\",\n    \"python_service/security.py\",\n    \"python_service/tests/test_manual_override.py\",\n    \"python_service/user_friendly_errors.py\",\n    \"python_service/utils/__init__.py\",\n    \"python_service/utils/odds.py\",\n    \"python_service/utils/text.py\"\n]",
    "MANIFEST_PART2_FRONTEND.json": "[\n    \"electron/assets/.gitkeep\",\n    \"electron/assets/banner.bmp\",\n    \"electron/assets/dialog.bmp\",\n    \"electron/assets/icon.ico\",\n    \"electron/assets/license.rtf\",\n    \"electron/electron-builder-config.yml\",\n    \"electron/install-dependencies.js\",\n    \"electron/install-validator.js\",\n    \"electron/main.js\",\n    \"electron/package-lock.json\",\n    \"electron/package.json\",\n    \"electron/preload.js\",\n    \"electron/resources/.gitkeep\",\n    \"electron/secure-settings-manager.js\",\n    \"web_platform/api_gateway/package-lock.json\",\n    \"web_platform/api_gateway/package.json\",\n    \"web_platform/api_gateway/src/server.ts\",\n    \"web_platform/api_gateway/src/services/DatabaseService.ts\",\n    \"web_platform/api_gateway/tsconfig.json\",\n    \"web_platform/frontend/.gitignore\",\n    \"web_platform/frontend/app/Providers.tsx\",\n    \"web_platform/frontend/app/globals.css\",\n    \"web_platform/frontend/app/layout.tsx\",\n    \"web_platform/frontend/app/page.tsx\",\n    \"web_platform/frontend/next-env.d.ts\",\n    \"web_platform/frontend/next.config.mjs\",\n    \"web_platform/frontend/out/app-build-manifest.json\",\n    \"web_platform/frontend/out/build-manifest.json\",\n    \"web_platform/frontend/out/cache/webpack/client-development/0.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/client-development/1.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/client-development/2.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/client-development/index.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/client-development/index.pack.gz.old\",\n    \"web_platform/frontend/out/cache/webpack/server-development/0.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/server-development/1.pack.gz\",\n    \"web_platform/frontend/out/cache/webpack/server-development/index.pack.gz\",\n    \"web_platform/frontend/out/package.json\",\n    \"web_platform/frontend/out/react-loadable-manifest.json\",\n    \"web_platform/frontend/out/server/app-paths-manifest.json\",\n    \"web_platform/frontend/out/server/app/_not-found/page.js\",\n    \"web_platform/frontend/out/server/app/_not-found/page_client-reference-manifest.js\",\n    \"web_platform/frontend/out/server/app/page.js\",\n    \"web_platform/frontend/out/server/app/page_client-reference-manifest.js\",\n    \"web_platform/frontend/out/server/interception-route-rewrite-manifest.js\",\n    \"web_platform/frontend/out/server/middleware-build-manifest.js\",\n    \"web_platform/frontend/out/server/middleware-manifest.json\",\n    \"web_platform/frontend/out/server/middleware-react-loadable-manifest.js\",\n    \"web_platform/frontend/out/server/next-font-manifest.js\",\n    \"web_platform/frontend/out/server/next-font-manifest.json\",\n    \"web_platform/frontend/out/server/pages-manifest.json\",\n    \"web_platform/frontend/out/server/server-reference-manifest.js\",\n    \"web_platform/frontend/out/server/server-reference-manifest.json\",\n    \"web_platform/frontend/out/server/vendor-chunks/@swc.js\",\n    \"web_platform/frontend/out/server/vendor-chunks/@tanstack.js\",\n    \"web_platform/frontend/out/server/vendor-chunks/next.js\",\n    \"web_platform/frontend/out/server/webpack-runtime.js\",\n    \"web_platform/frontend/out/static/chunks/_app-pages-browser_src_components_LiveRaceDashboard_tsx.js\",\n    \"web_platform/frontend/out/static/chunks/app/_not-found/page.js\",\n    \"web_platform/frontend/out/static/chunks/app/layout.js\",\n    \"web_platform/frontend/out/static/chunks/app/page.js\",\n    \"web_platform/frontend/out/static/chunks/polyfills.js\",\n    \"web_platform/frontend/out/static/chunks/webpack.js\",\n    \"web_platform/frontend/out/static/development/_buildManifest.js\",\n    \"web_platform/frontend/out/static/development/_ssgManifest.js\",\n    \"web_platform/frontend/out/static/webpack/01fdca362d2484da.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/0b14ffdc6b7405b0.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/0c13911c36654704.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/0cc62c0d69337015.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/1102717a44ab94bf.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/1d062a4e4b35d832.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/21491417ca7217a4.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/2ee876d7437031ad.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/30465abebefde3c5.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/37b04dca5a231885.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/3e580a3b3e254396.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/3e8a0401ffd42d5d.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/3f1c3fdd4110bb04.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/3f1f3ff31d98afe7.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/430150897770bc5d.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/4de2e9c6b8f4c203.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/5443d0dc225d24d3.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/55da9d621eb1b5ad.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/6e7923fa5dbd9424.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/6ec70d586d2284c9.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/72955ddbc10a2b90.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/790eca55bdffbf91.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/794677064701dbe2.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/7d88d39af9b94529.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/825e6c5a6d51fb53.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8308a84cca948fdc.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/833937b119865b49.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/84482d1ccb0e3e71.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/845040b3ab1bf0c4.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/84a4c7fac1ec51da.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8855e7e0a16aba28.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8b27cec4e9c67e4e.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8c89b2b88bafc3c8.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8eb67309205ed244.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/8ebd0c1b7991f533.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/92aeba9d00e54170.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/93cbed664bd2d989.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/97e0b85b30bf4436.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/99a83d4470cbbbc3.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.01fdca362d2484da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.0c13911c36654704.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.0cc62c0d69337015.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.1102717a44ab94bf.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.1d062a4e4b35d832.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.21491417ca7217a4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.2ee876d7437031ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.30465abebefde3c5.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.37b04dca5a231885.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.3e580a3b3e254396.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.3e8a0401ffd42d5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.3f1c3fdd4110bb04.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.3f1f3ff31d98afe7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.4de2e9c6b8f4c203.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.5443d0dc225d24d3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.55da9d621eb1b5ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.6e7923fa5dbd9424.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.6ec70d586d2284c9.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.72955ddbc10a2b90.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.790eca55bdffbf91.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.794677064701dbe2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.7d88d39af9b94529.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.825e6c5a6d51fb53.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.8308a84cca948fdc.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.845040b3ab1bf0c4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.84a4c7fac1ec51da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.8855e7e0a16aba28.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.8c89b2b88bafc3c8.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.92aeba9d00e54170.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.93cbed664bd2d989.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.99a83d4470cbbbc3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.a45cc08a37f050d1.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.af91db5e83d57611.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.c2062fb2e060f992.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.c679324551e5c1b6.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.c841923556cf90df.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.c930a8ef74aeb182.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.d1dc2849d77d7161.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.d534dd4e05712657.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.d6265b1d3d3abb87.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.e17cee7bf39d45a2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.ed79f245a27328f3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.f24862a0b3194137.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.f35d73514d14d52e.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.f9c203cbadc07384.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/_app-pages-browser_src_components_LiveRaceDashboard_tsx.fe5ad14e23c61cde.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/a45cc08a37f050d1.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/af91db5e83d57611.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/app/layout.01fdca362d2484da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.0b14ffdc6b7405b0.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.0c13911c36654704.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.0cc62c0d69337015.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.1102717a44ab94bf.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.1d062a4e4b35d832.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.21491417ca7217a4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.2ee876d7437031ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.30465abebefde3c5.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.37b04dca5a231885.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.3e580a3b3e254396.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.3e8a0401ffd42d5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.3f1c3fdd4110bb04.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.3f1f3ff31d98afe7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.430150897770bc5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.4de2e9c6b8f4c203.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.5443d0dc225d24d3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.55da9d621eb1b5ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.6e7923fa5dbd9424.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.6ec70d586d2284c9.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.72955ddbc10a2b90.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.790eca55bdffbf91.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.794677064701dbe2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.7d88d39af9b94529.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.825e6c5a6d51fb53.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8308a84cca948fdc.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.833937b119865b49.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.84482d1ccb0e3e71.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.845040b3ab1bf0c4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.84a4c7fac1ec51da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8855e7e0a16aba28.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8c89b2b88bafc3c8.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8eb67309205ed244.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.8ebd0c1b7991f533.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.92aeba9d00e54170.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.93cbed664bd2d989.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.97e0b85b30bf4436.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.99a83d4470cbbbc3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.a45cc08a37f050d1.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.af91db5e83d57611.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.b0b37d6009df81e0.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c2062fb2e060f992.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c679324551e5c1b6.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c69a370f1cf00177.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c841923556cf90df.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c89b36212a277c3f.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.c930a8ef74aeb182.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.d1dc2849d77d7161.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.d534dd4e05712657.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.d6265b1d3d3abb87.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.d9f9b1d577c226e7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.e17cee7bf39d45a2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.ed79f245a27328f3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.f24862a0b3194137.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.f35d73514d14d52e.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.f9c203cbadc07384.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/app/layout.fe5ad14e23c61cde.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/b0b37d6009df81e0.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c2062fb2e060f992.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c679324551e5c1b6.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c69a370f1cf00177.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c841923556cf90df.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c89b36212a277c3f.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/c930a8ef74aeb182.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/d1dc2849d77d7161.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/d534dd4e05712657.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/d6265b1d3d3abb87.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/d9f9b1d577c226e7.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/e17cee7bf39d45a2.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/ed79f245a27328f3.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/f24862a0b3194137.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/f35d73514d14d52e.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/f9c203cbadc07384.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/fe5ad14e23c61cde.webpack.hot-update.json\",\n    \"web_platform/frontend/out/static/webpack/webpack.01fdca362d2484da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.0b14ffdc6b7405b0.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.0c13911c36654704.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.0cc62c0d69337015.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.1102717a44ab94bf.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.1d062a4e4b35d832.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.21491417ca7217a4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.2ee876d7437031ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.30465abebefde3c5.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.37b04dca5a231885.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.3e580a3b3e254396.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.3e8a0401ffd42d5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.3f1c3fdd4110bb04.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.3f1f3ff31d98afe7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.430150897770bc5d.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.4de2e9c6b8f4c203.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.5443d0dc225d24d3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.55da9d621eb1b5ad.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.6e7923fa5dbd9424.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.6ec70d586d2284c9.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.72955ddbc10a2b90.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.790eca55bdffbf91.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.794677064701dbe2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.7d88d39af9b94529.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.825e6c5a6d51fb53.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8308a84cca948fdc.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.833937b119865b49.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.84482d1ccb0e3e71.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.845040b3ab1bf0c4.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.84a4c7fac1ec51da.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8855e7e0a16aba28.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8b27cec4e9c67e4e.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8c89b2b88bafc3c8.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8eb67309205ed244.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.8ebd0c1b7991f533.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.92aeba9d00e54170.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.93cbed664bd2d989.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.97e0b85b30bf4436.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.99a83d4470cbbbc3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.a45cc08a37f050d1.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.af91db5e83d57611.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.b0b37d6009df81e0.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c2062fb2e060f992.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c679324551e5c1b6.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c69a370f1cf00177.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c841923556cf90df.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c89b36212a277c3f.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.c930a8ef74aeb182.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.d1dc2849d77d7161.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.d534dd4e05712657.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.d6265b1d3d3abb87.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.d9f9b1d577c226e7.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.e17cee7bf39d45a2.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.ed79f245a27328f3.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.f24862a0b3194137.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.f35d73514d14d52e.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.f9c203cbadc07384.hot-update.js\",\n    \"web_platform/frontend/out/static/webpack/webpack.fe5ad14e23c61cde.hot-update.js\",\n    \"web_platform/frontend/out/trace\",\n    \"web_platform/frontend/out/types/app/layout.ts\",\n    \"web_platform/frontend/out/types/app/page.ts\",\n    \"web_platform/frontend/out/types/package.json\",\n    \"web_platform/frontend/package-lock.json\",\n    \"web_platform/frontend/package.json\",\n    \"web_platform/frontend/postcss.config.js\",\n    \"web_platform/frontend/public/manifest.json\",\n    \"web_platform/frontend/public/sw.js\",\n    \"web_platform/frontend/public/workbox-4754cb34.js\",\n    \"web_platform/frontend/src/components/AdapterStatusPanel.tsx\",\n    \"web_platform/frontend/src/components/EmptyState.tsx\",\n    \"web_platform/frontend/src/components/LiveModeToggle.tsx\",\n    \"web_platform/frontend/src/components/LiveRaceDashboard.tsx\",\n    \"web_platform/frontend/src/components/LiveRaceDashboardNoSSR.tsx\",\n    \"web_platform/frontend/src/components/ManualOverridePanel.tsx\",\n    \"web_platform/frontend/src/components/RaceCard.tsx\",\n    \"web_platform/frontend/src/components/RaceCardSkeleton.tsx\",\n    \"web_platform/frontend/src/components/RaceFilters.tsx\",\n    \"web_platform/frontend/src/components/ScoreBadge.tsx\",\n    \"web_platform/frontend/src/components/SettingsPage.tsx\",\n    \"web_platform/frontend/src/components/StatusDetailModal.tsx\",\n    \"web_platform/frontend/src/components/Tabs.tsx\",\n    \"web_platform/frontend/src/components/TrifectaFactors.tsx\",\n    \"web_platform/frontend/src/hooks/useRealTimeRaces.ts\",\n    \"web_platform/frontend/src/hooks/useWebSocket.ts\",\n    \"web_platform/frontend/src/lib/queryClient.ts\",\n    \"web_platform/frontend/src/types/electron.d.ts\",\n    \"web_platform/frontend/src/types/racing.ts\",\n    \"web_platform/frontend/src/utils/exportManager.ts\",\n    \"web_platform/frontend/tailwind.config.ts\",\n    \"web_platform/frontend/tsconfig.json\"\n]",
    "MANIFEST_PART3_SUPPORT.json": "[\n    \"pg_schemas/historical_races.sql\",\n    \"pg_schemas/quarantine_races.sql\",\n    \"pg_schemas/quarantined_races.sql\",\n    \"tests/__init__.py\",\n    \"tests/adapters/test_gbgb_api_adapter.py\",\n    \"tests/adapters/test_greyhound_adapter.py\",\n    \"tests/adapters/test_racingtv_adapter.py\",\n    \"tests/adapters/test_the_racing_api_adapter.py\",\n    \"tests/adapters/test_timeform_adapter_modernized.py\",\n    \"tests/adapters/test_twinspires_adapter.py\",\n    \"tests/analyzers/test_trifecta_analyzer.py\",\n    \"tests/conftest.py\",\n    \"tests/fixtures/at_the_races_greyhound_sample.html\",\n    \"tests/fixtures/at_the_races_greyhounds.html\",\n    \"tests/fixtures/timeform_legacy_sample.html\",\n    \"tests/fixtures/timeform_modern_sample.html\",\n    \"tests/fixtures/twinspires_sample.html\",\n    \"tests/test_analyzer.py\",\n    \"tests/test_api.py\",\n    \"tests/test_api/test_endpoints.py\",\n    \"tests/test_engine.py\",\n    \"tests/test_engine/test_orchestration.py\",\n    \"tests/test_manual_override.py\",\n    \"tests/test_models.py\",\n    \"tests/test_models/test_validation.py\",\n    \"tests/test_msi_installation.ps1\",\n    \"tests/test_silent_deployment.ps1\",\n    \"tests/test_uninstall.ps1\",\n    \"tests/utils.py\",\n    \"tests/utils/test_odds.py\"\n]",
    "STATUS.md": "# Project Status: Foundation Rebuilt, Hardening in Progress\n\n**Date:** 2025-10-03\n\n## Current State\n\n*   **Architecture:** The backend has been successfully rebuilt into a superior, asynchronous FastAPI application, as defined by 'Operation: Grand Synthesis'. The new foundation is stable, tested, and features a resilient `BaseAdapter` pattern.\n\n*   **Status:** The foundational refactoring is complete. The first two data adapters (`Betfair`, `TVG`) have been implemented on the new architecture. We are now in a new phase of development: **'Phase 2: Hardening & Expansion.'**\n\n*   **Documentation:** All core strategic documents and manifests have been synchronized with the new technical reality.\n\n*   **Next Steps:** Our immediate priority is to act on the verified intelligence from our Oracle (Jules1003). The next missions will focus on implementing critical API security features (rate limiting, authentication) and continuing the build-out of our adapter fleet.",
    "USER_GUIDE.MD": "# Fortuna Faucet - User Guide\n\nThis document provides instructions for users of the Fortuna Faucet application.\n\n## Installation\n\n1.  Download the `Fortuna-Faucet-Installer.msi` file from the latest release.\n2.  Run the installer and follow the on-screen instructions.\n3.  The application will be installed to `C:\\Program Files\\Fortuna Faucet` by default.\n\n## Usage\n\n1.  Launch the application from the Start Menu or desktop shortcut.\n2.  The main window will display the live race dashboard.\n3.  Use the settings page to configure your preferences.\n",
    "USER_GUIDE.md": "# \ud83c\udfaf Fortuna Faucet: Complete User Guide for Windows Hobbyists\n\n## What Is This Amazing Software?\n\n**Fortuna Faucet** is a professional-grade horse racing analysis platform that:\n- \ud83d\udcca Aggregates data from **20+ global racing sources** simultaneously\n- \ud83e\udd16 Uses AI-powered analysis to find value betting opportunities\n- \ud83d\udcc8 Provides live odds monitoring via Betfair Exchange\n- \ud83c\udf10 Features a beautiful web dashboard for real-time insights\n- \ud83d\udd04 Runs automatically in the background like a professional service\n\nThink of it as your personal racing intelligence agency!\n\n---\n\n## \ud83d\ude80 Quick Start (15 Minutes to Racing!)\n\n### Step 1: One-Click Installation\n1. Extract all files to `C:\\FortunaFaucet` (or your preferred location)\n2. **Right-click** `INSTALL_FORTUNA.bat` \u2192 **Run as Administrator**\n3. Wait 3-5 minutes while it automatically installs:\n   - Python 3.11 (if needed)\n   - Node.js (if needed)\n   - All required packages\n\n### Step 2: Quick Configuration\n1. **Double-click** `setup_wizard.py` in your folder\n2. Follow the friendly prompts to configure:\n   - Your private API key (auto-generated)\n   - Betfair credentials (optional, for live odds)\n3. The wizard creates your `.env` file automatically!\n\n### Step 3: Launch!\n- **Double-click** the \"Launch Fortuna\" shortcut on your desktop\n- Wait 10 seconds for services to start\n- Your dashboard opens automatically in your browser! \ud83c\udf89\n\n---\n\n## \ud83c\udfae Using Your New Command Center\n\n### The Dashboard (http://localhost:3000)\nYour racing command center features:\n\n**\ud83d\udcca Statistics Panel** (Top of screen)\n- **Qualified Races**: How many races meet your criteria\n- **Premium Targets**: High-score opportunities (80%+)\n- **Next Race**: Countdown to the next qualifying race\n- **Avg Field Size**: Average number of horses\n\n**\ud83c\udf9b\ufe0f Smart Filters** (Middle section)\nCustomize what you see:\n- **Min Score Slider**: Only show races above X% match\n- **Max Field Size**: Filter by number of runners (8, 10, 12, or Any)\n- **Sort By**: Order by score, time, or track name\n\n**\ud83c\udfc7 Race Cards** (Main display)\nEach card shows:\n- Track name and race number\n- Qualification score (color-coded!)\n- Race conditions (distance, surface)\n- Top 3 contenders with best odds\n- Data source count\n\n### Color Coding System\n- \ud83d\udd34 **Red (80%+)**: Premium betting opportunity!\n- \ud83d\udfe1 **Yellow (60-79%)**: Good value potential\n- \ud83d\udfe2 **Green (<60%)**: Meets minimum criteria\n\n---\n\n## \ud83d\udd27 Advanced Features\n\n### Live Odds Monitoring\nOnce you've added Betfair credentials:\n1. The system automatically tracks races approaching post time\n2. Updates odds every 30 seconds for races within 5 minutes\n3. Highlights dramatic odds movements\n\n### Desktop Monitor Tool\nRun `fortuna_monitor.py` for a real-time status window:\n- Shows all data source health\n- Performance graphs (with matplotlib)\n- Success rates and fetch durations\n- Quick \"Refresh Now\" button\n\n### Auto-Start on Windows Boot\nRun `SCHEDULE_FORTUNA.bat` (as Administrator):\n- Fortuna starts when you log into Windows\n- Daily 3 AM restart for fresh data\n- Runs silently in the background\n\n---\n\n## \ud83c\udfaf Understanding the \"Trifecta Analyzer\"\n\nThis is the brain! It scores races on three factors:\n\n### Factor 1: Field Size (smaller is better)\n- **Why**: Fewer horses = easier to predict\n- **Default**: Maximum 10 runners\n\n### Factor 2: Favorite's Odds (higher is better)\n- **Why**: If the favorite is 2.5+, the race is wide open\n- **Default**: Minimum 2.5\n\n### Factor 3: Second Favorite's Odds (higher is better)\n- **Why**: Confirms multiple horses are competitive\n- **Default**: Minimum 4.0\n\n**The Score**: Combines all three into a 0-100% match rating!\n\n---\n\n## \ud83d\udcda System Architecture (Simplified)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \ud83c\udf10 Next.js Dashboard (Port 3000)    \u2502\n\u2502     Your beautiful web interface        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 API Calls\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   \ud83d\udc0d Python FastAPI Backend (Port 8000) \u2502\n\u2502   - OddsEngine: Fetches from 20+ sources\u2502\n\u2502   - TrifectaAnalyzer: Scores races      \u2502\n\u2502   - LiveOddsMonitor: Betfair tracking   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 Async Requests\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \ud83d\udd0c Adapter Fleet (20+ sources)      \u2502\n\u2502  TVG \u2022 Betfair \u2022 TimeForm \u2022 GBGB       \u2502\n\u2502  RacingAndSports \u2022 USTA \u2022 And more!     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n---\n\n## \ud83d\udd10 Security Notes\n\n### API Keys\n- **Your local API_KEY**: Only for communication between YOUR backend and frontend\n- Never shared online, never exposed\n- Auto-generated during setup\n\n### External API Keys (Optional)\nAdd these to `.env` for more data sources:\n```\nTVG_API_KEY=\"your_tvg_key\"\nRACING_AND_SPORTS_TOKEN=\"your_ras_token\"\nTHE_RACING_API_KEY=\"your_theracingapi_key\"\n```\n\nGet keys from:\n- TVG: https://www.tvg.com/promos/developer-api\n- Racing and Sports: https://www.racingandsports.com/data-api/\n- The Racing API: https://www.theracingapi.com/\n\n---\n\n## \ud83d\udee0\ufe0f Troubleshooting\n\n### \"Backend Offline\" Error\n```batch\n# Stop everything cleanly\nSTOP_FORTUNA.bat\n\n# Wait 10 seconds, then restart\nLAUNCH_FORTUNA.bat\n```\n\n### Dashboard Loads But No Data\n1. Open `http://localhost:8000/health` in browser\n2. Should show: `{\"status\": \"OK\"}`\n3. If not, check Python backend window for errors\n\n### \"Port Already In Use\" Error\nSomeone else is using port 8000 or 3000:\n```batch\n# Windows: Kill processes on those ports\nnetstat -ano | findstr :8000\ntaskkill /PID [number] /F\n\nnetstat -ano | findstr :3000\ntaskkill /PID [number] /F\n```\n\n### Reset Everything\n```batch\n# Nuclear option: Clean slate\nSTOP_FORTUNA.bat\ndel .env\nsetup_wizard.py\nINSTALL_FORTUNA.bat\n```\n\n---\n\n## \ud83d\udcd6 File Structure Explained\n\n### Critical Files (Don't Delete!)\n- `.env` - Your configuration (API keys, settings)\n- `requirements.txt` - Python packages list\n- `package.json` - Node.js packages list\n\n### Convenience Scripts\n- `LAUNCH_FORTUNA.bat` - Start everything\n- `STOP_FORTUNA.bat` - Stop everything\n- `RESTART_FORTUNA.bat` - Clean restart\n- `setup_wizard.py` - Interactive config tool\n\n### Python Backend (`python_service/`)\n- `api.py` - Web server (FastAPI)\n- `engine.py` - Master data orchestrator\n- `analyzer.py` - Race scoring logic\n- `models.py` - Data structure definitions\n- `adapters/` - Individual data source plugins\n\n### Frontend (`web_platform/frontend/`)\n- `src/app/page.tsx` - Main dashboard\n- `src/components/RaceCard.tsx` - Individual race display\n- `.env.local` - Frontend API key\n\n---\n\n## \ud83c\udf93 Customization Ideas\n\n### Change Analyzer Thresholds\nEdit `python_service/analyzer.py`:\n```python\nclass TrifectaAnalyzer(BaseAnalyzer):\n    def __init__(self,\n                 max_field_size: int = 8,      # \u2190 Change this\n                 min_favorite_odds: float = 3.0, # \u2190 Or this\n                 min_second_favorite_odds: float = 5.0): # \u2190 Or this\n```\n\n### Add New Data Sources\n1. Copy `python_service/adapters/template_adapter.py`\n2. Rename and implement the `fetch_races()` method\n3. Register in `python_service/adapters/__init__.py`\n4. Add to `python_service/engine.py` adapter list\n\n### Customize Dashboard Colors\nEdit `web_platform/frontend/tailwind.config.ts`:\n```typescript\ntheme: {\n  extend: {\n    colors: {\n      'fortuna-primary': '#your-hex-color',\n    }\n  }\n}\n```\n\n---\n\n## \ud83d\udca1 Pro Tips\n\n### Tip 1: Use Windows Task Scheduler\nRun `SCHEDULE_FORTUNA.bat` for:\n- Auto-start on login\n- Daily 3 AM maintenance restart\n\n### Tip 2: Monitor Multiple Days\nThe analyzer works for \"today\" by default, but you can query any date:\n```\nhttp://localhost:8000/api/races/qualified/trifecta?race_date=2025-10-25\n```\n\n### Tip 3: Export Data\nThe API returns pure JSON. Use tools like:\n- **Postman** for testing\n- **PowerShell** for scripting:\n```powershell\nInvoke-RestMethod -Uri \"http://localhost:8000/api/races/qualified/trifecta\" `\n  -Headers @{\"X-API-Key\"=\"your_key\"} | ConvertTo-Json -Depth 10\n```\n\n### Tip 4: Mobile Access\nIf you want to check from your phone on the same WiFi:\n1. Find your PC's IP: `ipconfig` in Command Prompt\n2. Open firewall port 3000\n3. Access from phone: `http://192.168.1.X:3000`\n\n---\n\n## \ud83c\udf89 You're Ready!\n\nThis is a **professional-grade** system that you now control. It was built with years of racing analytics experience and modern software practices.\n\n### What You Can Do Now:\n\u2705 Track races from 20+ global sources\n\u2705 Identify value opportunities with AI scoring\n\u2705 Monitor live odds movements\n\u2705 Run 24/7 as a background service\n\u2705 Customize thresholds and filters\n\u2705 Expand with new data sources\n\n**Welcome to the world of algorithmic racing analysis!** \ud83c\udfc7\ud83d\ude80\n\n---\n\n## \ud83d\udcde Additional Resources\n\n### Project Documentation\n- `HISTORY.md` - Project evolution story\n- `ARCHITECTURAL_MANDATE.md` - System design principles\n- `WISDOM.md` - Developer best practices\n- `ROADMAP_APPENDICES.md` - Future expansion ideas\n\n### Useful Commands\n```batch\n# View all active Python processes\ntasklist | findstr python\n\n# Check if ports are available\nnetstat -ano | findstr :8000\nnetstat -ano | findstr :3000\n\n# Update Python packages\n.venv\\Scripts\\activate\npip install --upgrade -r requirements.txt\n```\n\n### Need Help?\n1. Check `fortuna_restart.log` for error history\n2. Run `fortuna_monitor.py` to see real-time system status\n3. Verify `.env` file has all required keys\n\nHappy Racing! \ud83c\udfb0\ud83c\udfc6",
    "assets/sounds/.gitkeep": "# This directory is for audio alert sound files (e.g., alert_premium.wav)",
    "audit-ignore.txt": "# Starlette - GHSA-f96h-pmfr-66vw - Medium severity\n# anyio.to_thread.run_sync is vulnerable to blocking the event loop in Starlette < 0.38.3\n# This is a dependency of FastAPI and is not trivially upgradeable.\nGHSA-f96h-pmfr-66vw\n\n# Starlette - GHSA-2c2j-9gv5-cj73 - High severity\n# Starlette's `StaticFiles` is vulnerable to path traversal.\n# This is not a direct risk as we do not use `StaticFiles` in production.\nGHSA-2c2j-9gv5-cj73\n\n# Cryptography - GHSA-h4gh-qq45-vh27 - High severity\n# Loading a specially crafted X.509 certificate could lead to a NULL pointer dereference and crash.\n# We have pinned this version to satisfy a pyopenssl dependency and cannot upgrade easily.\nGHSA-h4gh-qq45-vh27\n\n# Cryptography - GHSA-79v4-65xg-pq4g - High severity\n# Side-channel attack vulnerability in ECDSA signature generation.\n# We have pinned this version and cannot upgrade easily.\nGHSA-79v4-65xg-pq4g\n\n# Certifi - PYSEC-2024-230 - High severity\n# certifi contains a Pem-parsing vulnerability.\nPYSEC-2024-230\n\n# h11 - GHSA-vqfr-h8mv-ghfj - High severity\n# h11 is vulnerable to HTTP request smuggling.\nGHSA-vqfr-h8mv-ghfj\n\n# h2 - GHSA-847f-9342-265h - High severity\n# h2 is vulnerable to a \"continuation flood\" denial of service attack.\nGHSA-847f-9342-265h\n",
    "configure_startup.py": "# configure_startup.py\nimport sys\nimport winreg\nfrom pathlib import Path\n\n\nclass StartupManager:\n    \"\"\"Manage Windows startup registry entries for the current user.\"\"\"\n\n    REGISTRY_PATH = r\"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n    APP_NAME = \"FortunaFaucetTray\"\n\n    @classmethod\n    def is_enabled(cls) -> bool:\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_READ)\n            winreg.QueryValueEx(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            return True\n        except FileNotFoundError:\n            return False\n\n    @classmethod\n    def enable(cls):\n        launcher_path = Path(__file__).parent / \"launcher.ps1\"\n        cmd = f'powershell.exe -WindowStyle Hidden -File \"{launcher_path}\"'\n\n        key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n        winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, cmd)\n        winreg.CloseKey(key)\n        print(\"Startup enabled.\")\n\n    @classmethod\n    def disable(cls):\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n            winreg.DeleteValue(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            print(\"Startup disabled.\")\n        except FileNotFoundError:\n            print(\"Already disabled.\")\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"enable\":\n            StartupManager.enable()\n        elif sys.argv[1] == \"disable\":\n            StartupManager.disable()\n        elif sys.argv[1] == \"status\":\n            print(f\"Startup is currently {'enabled' if StartupManager.is_enabled() else 'disabled'}\")\n    else:\n        print(\"Usage: python configure_startup.py [enable|disable|status]\")\n",
    "electron/main.js": "// electron/main.js - CORRECTED VERSION\nconst { app, BrowserWindow, Tray, Menu, nativeImage, ipcMain, dialog } = require('electron');\nconst { autoUpdater } = require('electron-updater');\nconst { spawn } = require('child_process');\nconst net = require('net');\nconst path = require('path');\nconst fs = require('fs');\nconst SecureSettingsManager = require('./secure-settings-manager');\n\nclass FortunaDesktopApp {\n constructor() {\n this.backendProcess = null;\n this.mainWindow = null;\n this.tray = null;\n this.backendState = 'stopped'; // \"stopped\", \"starting\", \"running\", \"error\"\n this.backendLogs = [];\n this.isBackendStarting = false;\n }\n\n sendBackendStatusUpdate() {\n if (this.mainWindow) {\n this.mainWindow.webContents.send('backend-status-update', {\n state: this.backendState,\n logs: this.backendLogs.slice(-20) // Send last 20 log entries\n });\n }\n }\n\n stopBackend() {\n if (this.backendProcess && !this.backendProcess.killed) {\n console.log('Stopping backend process...');\n this.backendProcess.kill();\n this.backendState = 'stopped';\n this.isBackendStarting = false; // Ensure lock is released on stop\n this.backendLogs.push('Backend process stopped by user.');\n this.sendBackendStatusUpdate();\n }\n }\n \n  checkPortInUse(port) {\n    return new Promise((resolve, reject) => {\n      const server = net.createServer();\n      server.once('error', (err) => {\n        if (err.code === 'EADDRINUSE') {\n          resolve(true); // Port is in use\n        } else {\n          reject(err);\n        }\n      });\n      server.once('listening', () => {\n        server.close(() => {\n          resolve(false); // Port is free\n        });\n      });\n      server.listen(port, '127.0.0.1');\n    });\n  }\n\n  async startBackend() {\n    if (this.isBackendStarting) {\n      console.log('Backend start already in progress. Ignoring request.');\n      return;\n    }\n    this.isBackendStarting = true;\n\n    const isPortInUse = await this.checkPortInUse(8000);\n    if (isPortInUse) {\n      const errorMsg = 'FATAL: Port 8000 is already in use. Another process may be running.';\n      console.error(errorMsg);\n      this.backendState = 'error';\n      this.backendLogs.push(errorMsg);\n      this.sendBackendStatusUpdate();\n      dialog.showErrorBox(\n        'Backend Conflict',\n        'Port 8000 is already in use. Please close any other running instances of Fortuna Faucet or the backend service and try again.'\n      );\n      this.isBackendStarting = false;\n      return;\n    }\n\n this.backendState = 'starting';\n this.backendLogs = ['Attempting to start backend process...'];\n this.sendBackendStatusUpdate();\n\n if (this.backendProcess && !this.backendProcess.killed) {\n console.log('Backend process already running. Killing old process.');\n this.backendProcess.kill();\n }\n\n const isDev = !app.isPackaged;\n let backendCommand;\n let backendArgs = [];\n let backendCwd = process.cwd();\n\n if (isDev) {\n console.log('[DEV MODE] Configuring backend to run from Python venv...');\n backendCommand = path.join(__dirname, '..', '.venv', 'Scripts', 'python.exe');\n backendArgs = ['-m', 'uvicorn', 'api:app', '--host', '127.0.0.1', '--port', '8000'];\n backendCwd = path.join(__dirname, '..', 'python_service');\n\n if (!fs.existsSync(backendCommand)) {\n const errorMsg = `FATAL: Python executable for dev not found at ${backendCommand}. Run setup first.`;\n this.backendState = 'error';\n this.backendLogs.push(errorMsg);\n this.sendBackendStatusUpdate();\n this.isBackendStarting = false;\n return;\n }\n } else {\n console.log('[PROD MODE] Configuring backend to run from packaged executable...');\n backendCommand = path.join(process.resourcesPath, 'fortuna-backend.exe');\n if (!fs.existsSync(backendCommand)) {\n const errorMsg = `FATAL: Backend executable missing at ${backendCommand}`;\n console.error(errorMsg);\n this.backendState = 'error';\n this.backendLogs.push(errorMsg);\n this.sendBackendStatusUpdate();\n const { dialog } = require('electron');\n dialog.showErrorBox(\n 'Backend Missing',\n 'The backend service is missing. Please reinstall Fortuna Faucet.'\n );\n this.isBackendStarting = false;\n return;\n }\n }\n\n console.log(`Spawning backend: ${backendCommand} ${backendArgs.join(' ')}`);\n this.backendProcess = spawn(backendCommand, backendArgs, {\n cwd: backendCwd,\n env: { ...process.env, HOST: '127.0.0.1', PORT: '8000' },\n stdio: ['ignore', 'pipe', 'pipe']\n });\n\n // Common event handlers for the backend process\n this.backendProcess.stdout.on('data', (data) => {\n const output = data.toString().trim();\n console.log(`[Backend] ${output}`);\n this.backendLogs.push(output);\n\n if (this.backendState !== 'running' && (output.includes('Uvicorn running') || output.includes('Application startup complete'))) {\n console.log('\u2705 Backend is ready!');\n this.backendState = 'running';\n this.isBackendStarting = false;\n }\n this.sendBackendStatusUpdate();\n });\n\n this.backendProcess.stderr.on('data', (data) => {\n const errorOutput = data.toString().trim();\n console.error(`[Backend ERROR] ${errorOutput}`);\n this.backendLogs.push(`ERROR: ${errorOutput}`);\n this.backendState = 'error';\n this.isBackendStarting = false;\n this.sendBackendStatusUpdate();\n });\n\n this.backendProcess.on('error', (err) => {\n const errorMsg = `FATAL: Failed to start backend process: ${err.message}`;\n console.error(errorMsg);\n this.backendLogs.push(errorMsg);\n this.backendState = 'error';\n this.isBackendStarting = false;\n this.sendBackendStatusUpdate();\n });\n\n this.backendProcess.on('exit', (code) => {\n if (code !== 0 && this.backendState !== 'stopped') {\n const errorMsg = `Backend process exited unexpectedly with code ${code}`;\n console.error(errorMsg);\n this.backendLogs.push(errorMsg);\n this.backendState = 'error';\n this.isBackendStarting = false;\n this.sendBackendStatusUpdate();\n }\n });\n }\n\n getFrontendPath() {\n const isDev = !app.isPackaged;\n\n if (isDev) {\n return 'http://localhost:3000';\n }\n\n const indexPath = path.join(app.getAppPath(), 'web-ui-build', 'out', 'index.html');\n const { pathToFileURL } = require('url');\n return pathToFileURL(indexPath).toString();\n }\n\n createMainWindow() {\n this.mainWindow = new BrowserWindow({\n width: 1600,\n height: 1000,\n title: 'Fortuna Faucet - Racing Analysis',\n icon: path.join(__dirname, 'assets', 'icon.ico'),\n webPreferences: {\n nodeIntegration: false,\n contextIsolation: true,\n preload: path.join(__dirname, 'preload.js')\n },\n autoHideMenuBar: true,\n backgroundColor: '#1a1a2e'\n });\n\n const frontendUrl = this.getFrontendPath();\n this.mainWindow.loadURL(frontendUrl);\n\n if (!app.isPackaged) {\n this.mainWindow.webContents.openDevTools();\n }\n\n this.mainWindow.on('close', (event) => {\n if (!app.isQuitting) {\n event.preventDefault();\n this.mainWindow.hide();\n }\n });\n }\n\n createSystemTray() {\n // ... (rest of the file is unchanged)\n }\n\n initialize() {\n this.createMainWindow();\n this.createSystemTray();\n this.startBackend();\n\n // Check for updates\n autoUpdater.checkForUpdatesAndNotify();\n\n autoUpdater.on('update-downloaded', (info) => {\n const dialogOpts = {\n type: 'info',\n buttons: ['Restart', 'Later'],\n title: 'Application Update',\n message: process.platform === 'win32' ? info.releaseName : info.releaseName,\n detail: 'A new version has been downloaded. Restart the application to apply the updates.'\n };\n\n dialog.showMessageBox(dialogOpts).then((returnValue) => {\n if (returnValue.response === 0) autoUpdater.quitAndInstall();\n });\n });\n\n ipcMain.on('restart-backend', () => this.startBackend());\n ipcMain.on('stop-backend', () => this.stopBackend());\n ipcMain.handle('get-backend-status', async () => ({\n state: this.backendState,\n logs: this.backendLogs.slice(-20)\n }));\n\n ipcMain.handle('get-api-key', async () => {\n return SecureSettingsManager.getApiKey();\n });\n\n ipcMain.handle('generate-api-key', async () => {\n const crypto = require('node:crypto');\n const newKey = crypto.randomBytes(16).toString('hex');\n SecureSettingsManager.saveApiKey(newKey);\n return newKey;\n });\n\n ipcMain.handle('save-api-key', async (event, apiKey) => {\n return SecureSettingsManager.saveApiKey(apiKey);\n });\n\n ipcMain.handle('save-betfair-credentials', async (event, credentials) => {\n return SecureSettingsManager.saveBetfairCredentials(credentials);\n });\n }\n\n cleanup() {\n if (this.backendProcess && !this.backendProcess.killed) {\n this.backendProcess.kill();\n }\n }\n}\n\nlet fortunaApp;\n\napp.whenReady().then(() => {\n fortunaApp = new FortunaDesktopApp();\n fortunaApp.initialize();\n});\n\napp.on('window-all-closed', () => {\n if (process.platform !== 'darwin') {\n // Do nothing, keep app running in tray\n }\n});\n\napp.on('activate', () => {\n if (BrowserWindow.getAllWindows().length === 0) {\n fortunaApp.createMainWindow();\n } else {\n fortunaApp.mainWindow.show();\n }\n});\n\napp.on('before-quit', () => {\n app.isQuitting = true;\n if (fortunaApp) {\n fortunaApp.cleanup();\n }\n});\n",
    "electron/resources/.gitkeep": "",
    "fortuna_app.py": "import os\nimport socket\nimport subprocess\nimport sys\nimport threading\nimport time\nimport tkinter as tk\nfrom pathlib import Path\nfrom tkinter import messagebox\nfrom tkinter import scrolledtext\nfrom tkinter import ttk\n\nimport psutil\nimport requests\n\n\n# --- Control Panel Tab (from former launcher_gui.py) ---\nclass ControlPanelTab(tk.Frame):\n    def __init__(self, parent, master_app):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self.master_app = master_app\n        self.backend_proc = None\n        self.frontend_proc = None\n        self.backend_unresponsive_count = 0\n        self.frontend_unresponsive_count = 0\n        self.first_launch = not (Path(os.environ[\"USERPROFILE\"]) / \"Desktop\" / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\").exists()\n        self._create_ui()\n        self.monitor_thread = threading.Thread(target=self.monitor_services, daemon=True)\n        self.monitor_thread.start()\n\n    def log_output(self, message):\n        self.log_text.config(state=tk.NORMAL)\n        self.log_text.insert(tk.END, f\"[{time.strftime('%H:%M:%S')}] {message}\\n\")\n        self.log_text.config(state=tk.DISABLED)\n        self.log_text.see(tk.END)\n\n    def smart_start(self):\n        \"\"\"On first launch, run verification, create shortcuts, and then start.\"\"\"\n        if messagebox.askokcancel(\n            \"First-Time Setup\",\n            \"Welcome to Fortuna Faucet!\\n\\nThis first launch will verify your system and create a desktop shortcut for easy access. Proceed?\",\n        ):\n            # Steal and run the logic from the System Tools Tab\n            self.master_app.notebook.select(self.master_app.system_tools_tab)\n            self.master_app.system_tools_tab.run_verification()\n            self.master_app.system_tools_tab.run_create_shortcuts()\n\n            # Once done, revert to a normal start button\n            messagebox.showinfo(\"Setup Complete\", \"Setup is complete! The main services will now start.\")\n            self.launch_btn.config(text=\"\u25b6 START FORTUNA\", bg=\"#00ff88\", command=self.launch_services)\n            self.launch_services()\n\n    def _create_ui(self):\n        title = tk.Label(\n            self,\n            text=\"\ud83d\udc34 System Control Panel\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        )\n        title.pack(pady=20)\n\n        status_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        status_frame.pack(fill=tk.X, padx=40, pady=10)\n\n        tk.Label(\n            status_frame,\n            text=\"Backend Service (API)\",\n            font=(\"Segoe UI\", 10),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        self.backend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg=\"#0f3460\", highlightthickness=0)\n        self.backend_status_canvas.pack(fill=tk.X, pady=(0, 10))\n        self.backend_indicator = self.backend_status_canvas.create_oval(15, 10, 35, 30, fill=\"#ff4444\", outline=\"\")\n        self.backend_text = self.backend_status_canvas.create_text(\n            55, 20, text=\"Stopped\", fill=\"#ffffff\", anchor=\"w\", font=(\"Segoe UI\", 9)\n        )\n\n        tk.Label(\n            status_frame,\n            text=\"Frontend Dashboard (UI)\",\n            font=(\"Segoe UI\", 10),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        self.frontend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg=\"#0f3460\", highlightthickness=0)\n        self.frontend_status_canvas.pack(fill=tk.X)\n        self.frontend_indicator = self.frontend_status_canvas.create_oval(15, 10, 35, 30, fill=\"#ff4444\", outline=\"\")\n        self.frontend_text = self.frontend_status_canvas.create_text(\n            55, 20, text=\"Stopped\", fill=\"#ffffff\", anchor=\"w\", font=(\"Segoe UI\", 9)\n        )\n\n        button_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        button_frame.pack(fill=tk.X, padx=40, pady=20)\n\n        self.launch_btn = tk.Button(\n            button_frame,\n            text=\"\u25b6 START FORTUNA\",\n            font=(\"Segoe UI\", 14, \"bold\"),\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            height=2,\n            relief=tk.FLAT,\n        )\n        if self.first_launch:\n            self.launch_btn.config(\n                text=\"\u25b6 FIRST-TIME START & SETUP\",\n                bg=\"#ff9900\",\n                command=self.smart_start,\n            )\n        else:\n            self.launch_btn.config(command=self.launch_services)\n        self.launch_btn.pack(fill=tk.X, pady=(0, 10))\n\n        self.stop_btn = tk.Button(\n            button_frame,\n            text=\"\u23f9 STOP SERVICES\",\n            font=(\"Segoe UI\", 12),\n            bg=\"#ff4444\",\n            fg=\"#ffffff\",\n            command=self.stop_services,\n            state=tk.DISABLED,\n            height=1,\n            relief=tk.FLAT,\n        )\n        self.stop_btn.pack(fill=tk.X)\n\n        self.log_text = scrolledtext.ScrolledText(self, height=5, bg=\"#000000\", fg=\"#00ff88\", state=tk.DISABLED)\n        self.log_text.pack(pady=10, padx=40, fill=tk.X)\n\n    def check_ports(self, ports=[8000, 3000]):\n        unavailable_ports = []\n        for port in ports:\n            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n                if s.connect_ex((\"127.0.0.1\", port)) == 0:\n                    unavailable_ports.append(port)\n        return unavailable_ports\n\n    def launch_services(self):\n        unavailable = self.check_ports()\n        if unavailable:\n            messagebox.showerror(\n                \"Port Conflict\",\n                f\"Cannot launch. Port(s) {', '.join(map(str, unavailable))} are already in use by another application.\",\n            )\n            return\n\n        self.launch_btn.config(state=tk.DISABLED)\n        self.update_status(\"backend\", \"starting\", \"Launching...\")\n        self.update_status(\"frontend\", \"starting\", \"Launching...\")\n\n        try:\n            venv_python = Path(\".venv/Scripts/python.exe\")\n            self.backend_proc = subprocess.Popen(\n                [\n                    str(venv_python),\n                    \"-m\",\n                    \"uvicorn\",\n                    \"python_service.api:app\",\n                    \"--host\",\n                    \"127.0.0.1\",\n                    \"--port\",\n                    \"8000\",\n                ],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                cwd=Path(__file__).parent,\n                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n            )\n        except Exception as e:\n            self.update_status(\"backend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        try:\n            self.frontend_proc = subprocess.Popen(\n                [\"npm\", \"run\", \"dev\"],\n                shell=True,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                cwd=\"web_platform/frontend\",\n                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n            )\n        except Exception as e:\n            self.update_status(\"frontend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        self.stop_btn.config(state=tk.NORMAL)\n\n    def stop_services(self):\n        self.stop_btn.config(state=tk.DISABLED)\n        for proc_name in [\"backend\", \"frontend\"]:\n            proc = getattr(self, f\"{proc_name}_proc\")\n            if proc and proc.poll() is None:\n                try:\n                    parent = psutil.Process(proc.pid)\n                    for child in parent.children(recursive=True):\n                        child.kill()\n                    parent.kill()\n                except psutil.NoSuchProcess:\n                    pass\n            setattr(self, f\"{proc_name}_proc\", None)\n        self.launch_btn.config(state=tk.NORMAL)\n\n    def restart_service(self, service_name: str):\n        \"\"\"Gracefully stop and restart a single failed service.\"\"\"\n        proc_attr = f\"{service_name}_proc\"\n        proc = getattr(self, proc_attr)\n\n        # Stop the specific process\n        if proc and proc.poll() is None:\n            try:\n                parent = psutil.Process(proc.pid)\n                for child in parent.children(recursive=True):\n                    child.kill()\n                parent.kill()\n            except psutil.NoSuchProcess:\n                pass\n        setattr(self, proc_attr, None)\n\n        # Wait a moment\n        time.sleep(2)\n\n        # Relaunch the specific process\n        self.update_status(service_name, \"starting\", \"Attempting auto-restart...\")\n        try:\n            if service_name == \"backend\":\n                venv_python = Path(\".venv/Scripts/python.exe\")\n                new_proc = subprocess.Popen(\n                    [\n                        str(venv_python),\n                        \"-m\",\n                        \"uvicorn\",\n                        \"python_service.api:app\",\n                        \"--host\",\n                        \"127.0.0.1\",\n                        \"--port\",\n                        \"8000\",\n                    ],\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                    cwd=Path(__file__).parent.parent,\n                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n                )\n            else:  # frontend\n                new_proc = subprocess.Popen(\n                    [\"npm\", \"run\", \"dev\"],\n                    shell=True,\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                    cwd=\"web_platform/frontend\",\n                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n                )\n            setattr(self, proc_attr, new_proc)\n        except Exception as e:\n            self.update_status(service_name, \"error\", f\"Auto-restart failed: {e}\")\n\n    def monitor_services(self):\n        while True:\n            # --- Backend Monitoring ---\n            if self.backend_proc and self.backend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:8000/health\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"backend\", \"ok\", \"Healthy (200 OK)\")\n                        self.backend_unresponsive_count = 0  # Reset counter on success\n                    else:\n                        self.update_status(\"backend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"backend\", \"unresponsive\", \"Unresponsive\")\n                    self.backend_unresponsive_count += 1\n                    if self.backend_unresponsive_count >= 3:  # If unresponsive for 3 cycles (15s)\n                        self.log_output(\"Backend unresponsive. Attempting automatic restart...\")\n                        self.restart_service(\"backend\")\n                        self.backend_unresponsive_count = 0  # Reset after attempt\n            else:\n                self.update_status(\"backend\", \"stopped\", \"Stopped\")\n\n            # --- Frontend Monitoring ---\n            if self.frontend_proc and self.frontend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:3000\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"frontend\", \"ok\", \"Healthy (200 OK)\")\n                        self.frontend_unresponsive_count = 0\n                    else:\n                        self.update_status(\"frontend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"frontend\", \"unresponsive\", \"Unresponsive\")\n                    self.frontend_unresponsive_count += 1\n                    if self.frontend_unresponsive_count >= 3:\n                        self.log_output(\"Frontend unresponsive. Attempting automatic restart...\")\n                        self.restart_service(\"frontend\")\n                        self.frontend_unresponsive_count = 0\n            else:\n                self.update_status(\"frontend\", \"stopped\", \"Stopped\")\n            time.sleep(5)\n\n    def update_status(self, service: str, status: str, message: str):\n        colors = {\n            \"ok\": \"#00ff88\",\n            \"unresponsive\": \"#ffcc00\",\n            \"error\": \"#ff4444\",\n            \"stopped\": \"#ff4444\",\n            \"starting\": \"#0f6cbd\",\n        }\n        canvas = getattr(self, f\"{service}_status_canvas\")\n        indicator = getattr(self, f\"{service}_indicator\")\n        text = getattr(self, f\"{service}_text\")\n\n        canvas.itemconfig(indicator, fill=colors.get(status, \"#404060\"))\n        canvas.itemconfig(text, text=message)\n\n\n# --- Setup Wizard Tab (from former setup_wizard_gui.py) ---\nclass SetupWizardTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self.current_step = 0\n        self.settings = {}\n        self._create_widgets()\n        self.show_step(0)\n\n    def _create_widgets(self):\n        header = tk.Label(\n            self,\n            text=\"\ud83d\udd27 First-Time Setup & Configuration\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        header.pack(pady=20)\n        self.step_label = tk.Label(\n            self,\n            text=\"Step 1 of 4: Generate API Key\",\n            font=(\"Segoe UI\", 11),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        self.step_label.pack(pady=10)\n        self.content_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        self.content_frame.pack(fill=tk.BOTH, expand=True, padx=30, pady=20)\n        button_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        button_frame.pack(fill=tk.X, padx=30, pady=20)\n        self.prev_btn = tk.Button(\n            button_frame,\n            text=\"< Back\",\n            command=self.previous_step,\n            state=tk.DISABLED,\n            bg=\"#404060\",\n            fg=\"#ffffff\",\n            padx=20,\n        )\n        self.prev_btn.pack(side=tk.LEFT)\n        self.next_btn = tk.Button(\n            button_frame,\n            text=\"Next >\",\n            command=self.next_step,\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            font=(\"Segoe UI\", 11, \"bold\"),\n            padx=20,\n        )\n        self.next_btn.pack(side=tk.RIGHT)\n\n    def show_step(self, step_index):\n        self._clear_content()\n        self.current_step = step_index\n        if step_index == 0:\n            self._show_step_1()\n        elif step_index == 1:\n            self._show_step_2()\n        elif step_index == 2:\n            self._show_step_3()\n        elif step_index == 3:\n            self._show_step_4()\n        self.update_buttons()\n\n    def _show_step_1(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83d\udd10 Secure API Key\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        tk.Label(\n            self.content_frame,\n            text=\"A secure API key will be generated and stored.\",\n            wraplength=600,\n            justify=tk.LEFT,\n            bg=\"#1a1a2e\",\n            fg=\"#cccccc\",\n        ).pack(anchor=\"w\", pady=10)\n        # ... Add API key generation logic and display ...\n\n    def _show_step_2(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83c\udfc7 Betfair Exchange (Optional)\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        # ... Add Betfair configuration form ...\n\n    def _show_step_3(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\u2713 Verifying Setup\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(anchor=\"w\")\n        # ... Add verification checks logic ...\n\n    def _show_step_4(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83c\udf89 Setup Complete!\",\n            font=(\"Segoe UI\", 14, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(pady=20)\n        self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n\n    def next_step(self):\n        if self.current_step < 3:\n            self.show_step(self.current_step + 1)\n\n    def previous_step(self):\n        if self.current_step > 0:\n            self.show_step(self.current_step - 1)\n\n    def finish_setup(self):\n        messagebox.showinfo(\"Setup Complete\", \"Your configuration has been saved.\")\n\n    def _clear_content(self):\n        for widget in self.content_frame.winfo_children():\n            widget.destroy()\n\n    def update_buttons(self):\n        self.prev_btn.config(state=tk.NORMAL if self.current_step > 0 else tk.DISABLED)\n        if self.current_step == 3:\n            self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n        else:\n            self.next_btn.config(text=\"Next >\", command=self.next_step)\n\n\n# --- System Tools Tab ---\nclass SystemToolsTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self._create_ui()\n\n    def _create_ui(self):\n        title = tk.Label(\n            self,\n            text=\"\u2699\ufe0f System Tools\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        title.pack(pady=20)\n        tk.Button(\n            self,\n            text=\"Create Desktop Shortcuts\",\n            command=self.run_create_shortcuts,\n            font=(\"Segoe UI\", 12),\n        ).pack(pady=10, padx=40, fill=tk.X)\n        tk.Button(\n            self,\n            text=\"Verify Installation\",\n            command=self.run_verification,\n            font=(\"Segoe UI\", 12),\n        ).pack(pady=10, padx=40, fill=tk.X)\n        self.output_box = scrolledtext.ScrolledText(self, height=10, bg=\"#0f3460\", fg=\"#ffffff\", state=tk.DISABLED)\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n    def log_output(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n\n    def run_create_shortcuts(self):\n        self.log_output(\"--- Creating Desktop Shortcut ---\")\n        try:\n            from win32com.client import Dispatch\n\n            desktop = Path(os.environ[\"USERPROFILE\"]) / \"Desktop\"\n            app_path = Path(__file__).resolve()\n            shortcut_path = desktop / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\"\n\n            if shortcut_path.exists():\n                self.log_output(\"\ud83d\udfe1 Shortcut already exists. Overwriting.\")\n\n            shell = Dispatch(\"WScript.Shell\")\n            shortcut = shell.CreateShortCut(str(shortcut_path))\n            shortcut.TargetPath = sys.executable\n            shortcut.Arguments = f'\"{app_path}\"'\n            shortcut.WorkingDirectory = str(app_path.parent)\n\n            ico_path = app_path.parent / \"fortuna.ico\"\n            if ico_path.exists():\n                shortcut.IconLocation = str(ico_path)\n            else:\n                self.log_output(\"\ud83d\udfe1 Icon file not found, using default.\")\n\n            shortcut.save()\n            self.log_output(\"\u2705 Success: Shortcut created on Desktop.\")\n        except ImportError:\n            self.log_output(\"\u274c ERROR: 'pywin32' is not installed. Cannot create shortcuts.\")\n            self.log_output(\"  Please run: pip install pywin32\")\n        except Exception as e:\n            self.log_output(f\"\u274c ERROR: An unexpected error occurred: {e}\")\n\n    def run_verification(self):\n        self.log_output(\"\\n--- Verifying System Setup ---\")\n        verifications = [\n            (\"Python 3.11+\", lambda: sys.version_info >= (3, 11)),\n            (\n                \"Python Virtual Env (.venv)\",\n                lambda: Path(\".venv\").exists() and Path(\".venv/Scripts/python.exe\").exists(),\n            ),\n            (\n                \"Node.js (npm)\",\n                lambda: subprocess.run(\"npm -v\", shell=True, capture_output=True).returncode == 0,\n            ),\n            (\n                \"Frontend Dependencies (node_modules)\",\n                lambda: Path(\"web_platform/frontend/node_modules\").exists(),\n            ),\n        ]\n\n        all_ok = True\n        for name, check in verifications:\n            result = check()\n            self.log_output(f\"- {name}: {'\u2705 OK' if result else '\u274c FAILED'}\")\n            if not result:\n                all_ok = False\n\n        if all_ok:\n            self.log_output(\"\\n\u2705 All checks passed. System is ready.\")\n        else:\n            self.log_output(\"\\n\u274c Some checks failed. Please review the log.\")\n\n\n# --- Main Application Window ---\nclass FortunaApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"\ud83d\udc34 Fortuna Faucet\")\n        self.geometry(\"700x550\")\n        self.configure(bg=\"#1a1a2e\")\n\n        style = ttk.Style()\n        style.theme_use(\"clam\")\n        style.configure(\"TNotebook\", background=\"#1a1a2e\", borderwidth=0)\n        style.configure(\"TNotebook.Tab\", background=\"#404060\", foreground=\"#ffffff\", padding=[10, 5])\n        style.map(\"TNotebook.Tab\", background=[(\"selected\", \"#0f6cbd\")])\n\n        self.notebook = ttk.Notebook(self)\n\n        self.control_panel_tab = ControlPanelTab(self.notebook, self)\n        self.setup_wizard_tab = SetupWizardTab(self.notebook)\n        self.system_tools_tab = SystemToolsTab(self.notebook)\n\n        self.notebook.add(self.control_panel_tab, text=\"Control Panel\")\n        self.notebook.add(self.setup_wizard_tab, text=\"Setup & Config\")\n        self.notebook.add(self.system_tools_tab, text=\"System Tools\")\n\n        self.notebook.pack(expand=True, fill=\"both\", padx=10, pady=10)\n\n    def on_closing(self):\n        if self.control_panel_tab.backend_proc or self.control_panel_tab.frontend_proc:\n            if messagebox.askokcancel(\"Quit\", \"Services are still running. Do you want to stop them and exit?\"):\n                self.control_panel_tab.stop_services()\n                self.destroy()\n        else:\n            self.destroy()\n\n\n# --- NEW: Self-Setup UI and Logic ---\nclass SetupApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - First-Time Setup\")\n        self.geometry(\"700x500\")\n        self.configure(bg=\"#1a1a2e\")\n\n        self.protocol(\"WM_DELETE_WINDOW\", self.quit)\n\n        header_font = tk.font.Font(family=\"Segoe UI\", size=16, weight=\"bold\")\n        body_font = tk.font.Font(family=\"Segoe UI\", size=10)\n        button_font = tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\")\n\n        tk.Label(\n            self,\n            text=\"\ud83d\udce6 Welcome to Fortuna Faucet\",\n            font=header_font,\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(pady=(20, 10))\n        tk.Label(\n            self,\n            text=\"The necessary dependencies are not installed. Click 'Start Installation' to begin.\",\n            font=body_font,\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(pady=(0, 20))\n\n        self.install_button = tk.Button(\n            self,\n            text=\"\u25b6\ufe0f Start Installation\",\n            font=button_font,\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            command=self.start_installation,\n            relief=tk.FLAT,\n            padx=20,\n            pady=10,\n        )\n        self.install_button.pack(pady=10)\n\n        self.output_box = scrolledtext.ScrolledText(\n            self,\n            height=15,\n            bg=\"#0f3460\",\n            fg=\"#cccccc\",\n            state=tk.DISABLED,\n            relief=tk.FLAT,\n            bd=0,\n            padx=10,\n            pady=10,\n        )\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n        self.status_label = tk.Label(self, text=\"Waiting to start...\", font=body_font, bg=\"#1a1a2e\", fg=\"#ffffff\")\n        self.status_label.pack(pady=10)\n\n    def log(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n        self.update_idletasks()\n\n    def start_installation(self):\n        self.install_button.config(state=tk.DISABLED, text=\"Installation in progress...\")\n        self.log(\"--- Starting installation ---\")\n        self.status_label.config(text=\"Installing... Please be patient, this may take several minutes.\")\n        threading.Thread(target=self.run_install_commands, daemon=True).start()\n\n    def run_command(self, command):\n        process = subprocess.Popen(\n            command,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n            encoding=\"utf-8\",\n            errors=\"replace\",\n            shell=True,\n        )\n        for line in iter(process.stdout.readline, \"\"):\n            self.log(line.strip())\n        process.wait()\n        return process.returncode\n\n    def run_install_commands(self):\n        commands = [\n            (\n                \"1/3: Creating Python virtual environment...\",\n                f\"{sys.executable} -m venv .venv\",\n            ),\n            (\n                \"2/3: Installing Python dependencies...\",\n                '\"' + str(Path(\".venv/Scripts/python.exe\")) + '\" -m pip install -r requirements.txt',\n            ),\n            (\n                \"3/3: Installing Node.js dependencies...\",\n                \"npm install --prefix web_platform/frontend\",\n            ),\n        ]\n\n        for i, (msg, cmd) in enumerate(commands):\n            self.log(f\"\\\\n--- STEP {msg} ---\")\n            return_code = self.run_command(cmd)\n            if return_code != 0:\n                self.log(f\"\\\\n--- ERROR: Step {i + 1} failed with code {return_code}. ---\")\n                self.status_label.config(\n                    text=\"Installation Failed. Please see log for details.\",\n                    fg=\"#ff4444\",\n                )\n                self.install_button.config(state=tk.NORMAL, text=\"Retry Installation\")\n                return\n\n        self.log(\"\\\\n--- \u2705 INSTALLATION COMPLETE! ---\")\n        self.status_label.config(text=\"Setup successful! You can now launch the application.\", fg=\"#00ff88\")\n        self.install_button.destroy()\n        launch_button = tk.Button(\n            self,\n            text=\"\ud83d\ude80 Launch Fortuna\",\n            font=tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\"),\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            command=self.launch_app,\n            relief=tk.FLAT,\n            padx=20,\n            pady=10,\n        )\n        launch_button.pack(pady=10)\n\n    def launch_app(self):\n        self.destroy()\n        # Relaunch the script to start the main app\n        subprocess.Popen([sys.executable, __file__])\n\n\n# --- NEW: Main Execution Block ---\nif __name__ == \"__main__\":\n    VENV_PATH = Path(__file__).parent / \".venv\"\n    if not VENV_PATH.exists() or not (VENV_PATH / \"Scripts\" / \"python.exe\").exists():\n        # If the virtual environment doesn't exist, run the setup wizard.\n        setup_app = SetupApp()\n        setup_app.mainloop()\n    else:\n        # Otherwise, run the main application.\n        app = FortunaApp()\n        app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n        app.mainloop()\n",
    "jules-scratch/verification/verify_error_handling.py": "# jules-scratch/verification/verify_error_handling.py\nfrom playwright.sync_api import expect\nfrom playwright.sync_api import sync_playwright\n\n\ndef run(playwright):\n    browser = playwright.chromium.launch(headless=True)\n    page = browser.new_page()\n\n    # Mock the API call to return an error\n    page.route(\n        \"**/api/races/qualified/trifecta?**\",\n        lambda route: route.fulfill(\n            status=500,\n            json={\n                \"error\": {\n                    \"message\": \"A data source is currently unavailable.\",\n                    \"suggestion\": \"This is usually temporary. Please try again in a few minutes.\",\n                    \"details\": \"AdapterHttpError: HTTP Error 503 for https://example.com\",\n                }\n            },\n        ),\n    )\n\n    page.goto(\"http://localhost:3000\")\n\n    # Wait for the status indicator to show \"Offline\"\n    offline_indicator = page.get_by_text(\"Offline\")\n    expect(offline_indicator).to_be_visible()\n\n    # Now that we know the app is in an error state, check for the detailed message\n    error_message = page.get_by_text(\"A data source is currently unavailable.\")\n    expect(error_message).to_be_visible()\n\n    page.screenshot(path=\"jules-scratch/verification/error_handling.png\")\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n",
    "jules-scratch/verification/verify_frontend.py": "from playwright.sync_api import sync_playwright\n\n\ndef run():\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=True)\n        page = browser.new_page()\n        page.goto(\"http://localhost:3000\")\n        page.screenshot(path=\"jules-scratch/verification/verification.png\")\n        browser.close()\n\n\nif __name__ == \"__main__\":\n    run()\n",
    "jules-scratch/verification/verify_page.py": "from playwright.sync_api import sync_playwright\n\n\ndef run():\n    with sync_playwright() as p:\n        browser = p.chromium.launch()\n        page = browser.new_page()\n        page.goto(\"http://localhost:3000\")\n        page.screenshot(path=\"jules-scratch/verification/verification.png\")\n        browser.close()\n\n\nif __name__ == \"__main__\":\n    run()\n",
    "manual_override_tool.py": "import argparse\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Manual Override Tool for Checkmate Data Warehouse.\")\n    parser.add_argument(\"--file\", required=True, help=\"Path to the CSV file for ingestion.\")\n    parser.add_argument(\"--user\", required=True, help=\"The user ID performing the override.\")\n    args = parser.parse_args()\n\n    print(f\"Executing manual override by '{args.user}' for file '{args.file}'...\")\n\n    # 1. Connect to PostgreSQL\n    # engine = create_engine('postgresql://user:password@host:port/database')\n\n    # 2. Read and validate the CSV data\n    # race_df = pd.read_csv(args.file)\n    # ... validation logic ...\n\n    # 3. Add the manual_override_by column\n    # race_df['manual_override_by'] = args.user\n\n    # 4. Insert data into the 'historical_races' table\n    # race_df.to_sql('historical_races', engine, if_exists='append', index=False)\n\n    print(\"Manual override completed successfully.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "package-lock.json": "{\n  \"name\": \"app\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"dependencies\": {\n        \"@playwright/test\": \"^1.56.1\"\n      }\n    },\n    \"node_modules/@playwright/test\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/@playwright/test/-/test-1.56.1.tgz\",\n      \"integrity\": \"sha512-vSMYtL/zOcFpvJCW71Q/OEGQb7KYBPAdKh35WNSkaZA75JlAO8ED8UN6GUNTm3drWomcbcqRPFqQbLae8yBTdg==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"playwright\": \"1.56.1\"\n      },\n      \"bin\": {\n        \"playwright\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      }\n    },\n    \"node_modules/fsevents\": {\n      \"version\": \"2.3.2\",\n      \"resolved\": \"https://registry.npmjs.org/fsevents/-/fsevents-2.3.2.tgz\",\n      \"integrity\": \"sha512-xiqMQR4xAeHTuB9uWm+fFRcIOgKBMiOBP+eXiyT7jsgVCq1bkVygt00oASowB7EdtpOHaaPgKt812P9ab+DDKA==\",\n      \"hasInstallScript\": true,\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"os\": [\n        \"darwin\"\n      ],\n      \"engines\": {\n        \"node\": \"^8.16.0 || ^10.6.0 || >=11.0.0\"\n      }\n    },\n    \"node_modules/playwright\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/playwright/-/playwright-1.56.1.tgz\",\n      \"integrity\": \"sha512-aFi5B0WovBHTEvpM3DzXTUaeN6eN0qWnTkKx4NQaH4Wvcmc153PdaY2UBdSYKaGYw+UyWXSVyxDUg5DoPEttjw==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"playwright-core\": \"1.56.1\"\n      },\n      \"bin\": {\n        \"playwright\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      },\n      \"optionalDependencies\": {\n        \"fsevents\": \"2.3.2\"\n      }\n    },\n    \"node_modules/playwright-core\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/playwright-core/-/playwright-core-1.56.1.tgz\",\n      \"integrity\": \"sha512-hutraynyn31F+Bifme+Ps9Vq59hKuUCz7H1kDOcBs+2oGguKkWTU50bBWrtz34OUWmIwpBTWDxaRPXrIXkgvmQ==\",\n      \"license\": \"Apache-2.0\",\n      \"bin\": {\n        \"playwright-core\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      }\n    }\n  }\n}\n",
    "pyproject.toml": "[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"paddock-parser-ng\"\nversion = \"0.1.0\"\ndescription = \"A toolkit to identify the best racecards for betting.\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\n\n[project.scripts]\npaddock_parser_ui = \"paddock_parser.entry_points:run_terminal_ui\"\npaddock_parser_dashboard = \"paddock_parser.entry_points:run_dashboard\"\npaddock_parser_predict = \"paddock_parser.entry_points:run_prediction_engine\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n\n# Configuration for the Ruff linter\n[tool.ruff]\n# Allow lines to be up to 120 characters long.\nline-length = 120\n\n[tool.ruff.lint]\n# Enable Pyflakes (F), pycodestyle (E, W), and isort (I) rules.\nselect = [\"E\", \"F\", \"W\", \"I\"]\nignore = []\n\n[tool.ruff.lint.isort]\n# Sort imports within their sections alphabetically.\nforce-single-line = true\n",
    "pytest.ini": "[pytest]\npythonpath = python_service\nnorecursedirs = attic tests/checkmate_v7\ntestpaths = tests/adapters tests/api tests/database tests/ui tests/utils tests/test_backtester.py tests/test_fetcher.py tests/test_forager_client.py tests/test_log_analyzer.py tests/test_merger.py tests/test_pipeline.py tests/test_python_service.py tests/test_scorer.py tests/test_api.py tests/test_legacy_scenarios.py\n",
    "python_service/__init__.py": "# This file makes the python_service directory a Python package.\n",
    "python_service/adapters/base_adapter_v3.py": "# python_service/adapters/base_v3.py\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom typing import Any\nfrom typing import AsyncGenerator\nfrom typing import List\n\nimport httpx\nimport structlog\nfrom tenacity import RetryError\nfrom tenacity import retry\nfrom tenacity import stop_after_attempt\nfrom tenacity import wait_exponential\n\nfrom ..core.exceptions import AdapterHttpError\nfrom ..manual_override_manager import ManualOverrideManager\nfrom ..models import Race\n\n\nclass BaseAdapterV3(ABC):\n    \"\"\"\n    Abstract base class for all V3 data adapters.\n    Enforces a standardized fetch/parse pattern and includes robust request handling.\n    \"\"\"\n\n    def __init__(self, source_name: str, base_url: str, config=None, timeout: int = 20):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.config = config\n        self.timeout = timeout\n        self.logger = structlog.get_logger(adapter_name=self.source_name)\n        self.http_client: httpx.AsyncClient = None  # Injected by the engine\n        self.manual_override_manager: ManualOverrideManager = None\n        self.supports_manual_override = True  # Can be overridden by subclasses\n\n    def enable_manual_override(self, manager: ManualOverrideManager):\n        \"\"\"Injects the manual override manager into the adapter.\"\"\"\n        self.manual_override_manager = manager\n\n    @abstractmethod\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw data (e.g., HTML, JSON) for the given date.\n        This is the only method that should perform network operations.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        Parses the raw data retrieved by _fetch_data into a list of Race objects.\n        This method should be a pure function with no side effects.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        Orchestrates the fetch-then-parse pipeline for the adapter.\n        This public method should not be overridden by subclasses.\n        \"\"\"\n        raw_data = None\n\n        if self.manual_override_manager:\n            # This is not a full URL, but a representative key for the fetch operation\n            # Subclasses might need to override get_races to provide a more specific URL if needed\n            lookup_key = f\"{self.base_url}/racecards/{date}\"\n            manual_data = self.manual_override_manager.get_manual_data(self.source_name, lookup_key)\n            if manual_data:\n                self.logger.info(\"Using manually submitted data for request\", url=lookup_key)\n                # Reconstruct a dictionary similar to what _fetch_data would return\n                # This may need adjustment based on adapter specifics\n                raw_data = {\"pages\": [manual_data[0]], \"date\": date}\n\n        if raw_data is None:\n            try:\n                raw_data = await self._fetch_data(date)\n            except AdapterHttpError as e:\n                if self.manual_override_manager and self.supports_manual_override:\n                    self.manual_override_manager.register_failure(self.source_name, e.url)\n                raise  # Reraise the exception to be handled by the OddsEngine\n\n        if raw_data is not None:\n            parsed_races = self._parse_races(raw_data)\n            for race in parsed_races:\n                yield race\n\n    @retry(\n        wait=wait_exponential(multiplier=1, min=2, max=10),\n        stop=stop_after_attempt(3),\n        reraise=True,  # Reraise the final exception to be caught by get_races\n    )\n    async def make_request(self, http_client: httpx.AsyncClient, method: str, url: str, **kwargs) -> httpx.Response:\n        \"\"\"\n        Makes a resilient HTTP request with built-in retry logic using tenacity.\n        \"\"\"\n        # Ensure the URL is correctly formed, whether it's relative or absolute\n        full_url = url if url.startswith(\"http\") else f\"{self.base_url.rstrip('/')}/{url.lstrip('/')}\"\n\n        try:\n            self.logger.info(\"Making request\", method=method.upper(), url=full_url)\n            response = await http_client.request(method, full_url, timeout=self.timeout, **kwargs)\n            response.raise_for_status()  # Raise an exception for 4xx/5xx responses\n            return response\n        except httpx.HTTPStatusError as e:\n            self.logger.error(\n                \"HTTP Status Error during request\",\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            )\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            ) from e\n        except (httpx.RequestError, RetryError) as e:\n            self.logger.error(\"Request Error or Retry Error\", error=str(e))\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=503,  # Service Unavailable\n                url=full_url,\n            ) from e\n\n    def get_status(self) -> dict:\n        \"\"\"\n        Returns a dictionary representing the adapter's current status.\n        Subclasses can extend this to include more specific health checks.\n        \"\"\"\n        return {\n            \"adapter_name\": self.source_name,\n            \"status\": \"OK\",  # Basic status; can be enhanced in subclasses\n        }\n",
    "python_service/adapters/equibase_adapter.py": "# python_service/adapters/equibase_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass EquibaseAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Equibase race entries, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Equibase\"\n    BASE_URL = \"https://www.equibase.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        d = datetime.strptime(date, \"%Y-%m-%d\").date()\n        index_url = f\"/entries/Entries.cfm?ELEC_DATE={d.month}/{d.day}/{d.year}&STYLE=EQB\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Equibase index page\", url=index_url)\n            return None\n\n        parser = HTMLParser(index_response.text)\n        track_links = [\n            link.attributes[\"href\"]\n            for link in parser.css(\"div.track-information a\")\n            if \"race=\" not in link.attributes.get(\"href\", \"\")\n        ]\n\n        async def get_race_links_from_track(track_url: str):\n            response = await self.make_request(self.http_client, \"GET\", track_url, headers=self._get_headers())\n            if not response:\n                return []\n            parser = HTMLParser(response.text)\n            return [link.attributes[\"href\"] for link in parser.css(\"a.program-race-link\")]\n\n        tasks = [get_race_links_from_track(link) for link in track_links]\n        results = await asyncio.gather(*tasks)\n        race_links = [f\"{self.base_url}{link}\" for sublist in results for link in sublist]\n\n        async def fetch_single_html(race_url: str):\n            response = await self.make_request(self.http_client, \"GET\", race_url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        date = raw_data[\"date\"]\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first(\"div.track-information strong\")\n                if not venue_node:\n                    continue\n                venue = clean_text(venue_node.text())\n\n                race_number_node = parser.css_first(\"div.race-information strong\")\n                if not race_number_node:\n                    continue\n                race_number_text = race_number_node.text().replace(\"Race\", \"\").strip()\n                if not race_number_text.isdigit():\n                    continue\n                race_number = int(race_number_text)\n\n                post_time_node = parser.css_first(\"p.post-time span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text().strip()\n                start_time = self._parse_post_time(date, post_time_str)\n\n                runners = []\n                runner_nodes = parser.css(\"table.entries-table tbody tr\")\n                for node in runner_nodes:\n                    if runner := self._parse_runner(node):\n                        runners.append(runner)\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"eqb_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse Equibase race page.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first(\"td:nth-child(1)\")\n            if not number_node or not number_node.text(strip=True).isdigit():\n                return None\n            number = int(number_node.text(strip=True))\n\n            name_node = node.css_first(\"td:nth-child(3)\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            odds_node = node.css_first(\"td:nth-child(10)\")\n            odds_str = clean_text(odds_node.text()) if odds_node else \"\"\n\n            scratched = \"scratched\" in node.attributes.get(\"class\", \"\").lower()\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError, IndexError):\n            self.logger.warning(\"Could not parse Equibase runner, skipping.\", exc_info=True)\n            return None\n\n    def _parse_post_time(self, date_str: str, time_str: str) -> datetime:\n        \"\"\"Parses a time string like 'Post Time: 12:30 PM ET' into a datetime object.\"\"\"\n        time_part = time_str.split(\" \")[-2] + \" \" + time_str.split(\" \")[-1]\n        dt_str = f\"{date_str} {time_part}\"\n        return datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/gbgb_api_adapter.py": "# python_service/adapters/gbgb_api_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass GbgbApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for the Greyhound Board of Great Britain API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"GBGB\"\n    BASE_URL = \"https://api.gbgb.org.uk/api/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches the raw meeting data from the GBGB API.\"\"\"\n        endpoint = f\"results/meeting/{date}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, meetings_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw meeting data into a list of Race objects.\"\"\"\n        if not meetings_data:\n            return []\n\n        all_races = []\n        for meeting in meetings_data:\n            track_name = meeting.get(\"trackName\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name):\n                        all_races.append(race)\n                except (KeyError, TypeError):\n                    self.logger.error(\n                        \"Error parsing GBGB race\",\n                        race_id=race_data.get(\"raceId\"),\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: Dict[str, Any], track_name: str) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race_data.get(\"raceId\")\n        race_number = race_data.get(\"raceNumber\")\n        race_time = race_data.get(\"raceTime\")\n\n        if not all([race_id, race_number, race_time]):\n            return None\n\n        return Race(\n            id=f\"gbgb_{race_id}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=datetime.fromisoformat(race_time.replace(\"Z\", \"+00:00\")),\n            runners=self._parse_runners(race_data.get(\"traps\", [])),\n            source=self.source_name,\n            race_name=race_data.get(\"raceTitle\"),\n            distance=f\"{race_data.get('raceDistance')}m\",\n        )\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                trap_number = runner_data.get(\"trapNumber\")\n                dog_name = runner_data.get(\"dogName\")\n                if not all([trap_number, dog_name]):\n                    continue\n\n                odds_data = {}\n                sp = runner_data.get(\"sp\")\n                if sp:\n                    win_odds = parse_odds_to_decimal(sp)\n                    if win_odds and win_odds < 999:\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=trap_number,\n                        name=dog_name,\n                        odds=odds_data,\n                    )\n                )\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Error parsing GBGB runner, skipping.\",\n                    runner_name=runner_data.get(\"dogName\"),\n                )\n                continue\n        return runners\n",
    "python_service/adapters/greyhound_adapter.py": "# python_service/adapters/greyhound_adapter.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nfrom pydantic import ValidationError\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass GreyhoundAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for fetching Greyhound racing data, migrated to BaseAdapterV3.\n    Activated by setting GREYHOUND_API_URL in .env.\n    \"\"\"\n\n    SOURCE_NAME = \"Greyhound Racing\"\n\n    def __init__(self, config=None):\n        if not hasattr(config, \"GREYHOUND_API_URL\") or not config.GREYHOUND_API_URL:\n            raise AdapterConfigError(self.SOURCE_NAME, \"GREYHOUND_API_URL is not configured.\")\n        super().__init__(\n            source_name=self.SOURCE_NAME,\n            base_url=config.GREYHOUND_API_URL,\n            config=config,\n        )\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw card data from the greyhound API.\"\"\"\n        endpoint = f\"v1/cards/{date}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw card data into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"cards\"):\n            self.logger.warning(\"No 'cards' in greyhound response or empty list.\")\n            return []\n\n        all_races = []\n        for card in raw_data.get(\"cards\", []):\n            venue = card.get(\"track_name\", \"Unknown Venue\")\n            for race_data in card.get(\"races\", []):\n                try:\n                    if not race_data.get(\"runners\"):\n                        continue\n\n                    race_id = race_data.get(\"race_id\")\n                    race_number = race_data.get(\"race_number\")\n                    start_timestamp = race_data.get(\"start_time\")\n                    if not all([race_id, race_number, start_timestamp]):\n                        continue\n\n                    race = Race(\n                        id=f\"greyhound_{race_id}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=datetime.fromtimestamp(start_timestamp),\n                        runners=self._parse_runners(race_data.get(\"runners\", [])),\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n                except (ValidationError, KeyError) as e:\n                    self.logger.error(\n                        \"Error parsing greyhound race\",\n                        race_id=race_data.get(\"race_id\", \"N/A\"),\n                        error=str(e),\n                    )\n                    continue\n        return all_races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                if runner_data.get(\"scratched\", False):\n                    continue\n\n                trap_number = runner_data.get(\"trap_number\")\n                dog_name = runner_data.get(\"dog_name\")\n                if not all([trap_number, dog_name]):\n                    continue\n\n                odds_data = {}\n                win_odds_val = runner_data.get(\"odds\", {}).get(\"win\")\n                if win_odds_val is not None:\n                    win_odds = Decimal(str(win_odds_val))\n                    if win_odds > 1:\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=trap_number,\n                        name=dog_name,\n                        scratched=runner_data.get(\"scratched\", False),\n                        odds=odds_data,\n                    )\n                )\n            except (KeyError, ValidationError):\n                self.logger.warning(\"Error parsing greyhound runner, skipping.\", runner_data=runner_data)\n                continue\n        return runners\n",
    "python_service/adapters/harness_adapter.py": "# python_service/adapters/harness_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass HarnessAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US harness racing data with manual override support.\"\"\"\n\n    SOURCE_NAME = \"USTrotting\"\n    BASE_URL = \"https://data.ustrotting.com/api/racenet/racing/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches all harness races for a given date.\"\"\"\n        response = await self.make_request(self.http_client, \"GET\", f\"card/{date}\")\n\n        if not response:\n            return None\n\n        card_data = response.json()\n        return {\"data\": card_data, \"date\": date}\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw card data into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"data\") or not raw_data.get(\"data\", {}).get(\"meetings\"):\n            self.logger.warning(\"No meetings found in harness data response.\")\n            return []\n\n        all_races = []\n        date = raw_data.get(\"date\")\n        for meeting in raw_data.get(\"data\", {}).get(\"meetings\", []):\n            track_name = meeting.get(\"track\", {}).get(\"name\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name, date):\n                        all_races.append(race)\n                except Exception:\n                    self.logger.warning(\n                        \"Failed to parse harness race, skipping.\",\n                        race_data=race_data,\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: dict, track_name: str, date: str) -> Optional[Race]:\n        \"\"\"Parses a single race from the USTA API into a Race object.\"\"\"\n        race_number = race_data.get(\"raceNumber\")\n        post_time_str = race_data.get(\"postTime\")\n        if not all([race_number, post_time_str]):\n            return None\n\n        start_time = self._parse_post_time(date, post_time_str)\n\n        runners = []\n        for runner_data in race_data.get(\"runners\", []):\n            if runner_data.get(\"scratched\", False):\n                continue\n\n            odds_str = runner_data.get(\"morningLineOdds\", \"\")\n            if \"/\" not in odds_str and odds_str.isdigit():\n                odds_str = f\"{odds_str}/1\"\n\n            odds = {}\n            win_odds = parse_odds_to_decimal(odds_str)\n            if win_odds and win_odds < 999:\n                odds = {\n                    self.SOURCE_NAME: OddsData(\n                        win=win_odds,\n                        source=self.SOURCE_NAME,\n                        last_updated=datetime.now(),\n                    )\n                }\n\n            runners.append(\n                Runner(\n                    number=runner_data.get(\"postPosition\", 0),\n                    name=runner_data.get(\"horse\", {}).get(\"name\", \"Unknown Horse\"),\n                    odds=odds,\n                    scratched=False,\n                )\n            )\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"ust_{track_name.lower().replace(' ', '')}_{date}_{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME,\n        )\n\n    def _parse_post_time(self, date: str, post_time: str) -> datetime:\n        \"\"\"Parses a time string like '07:00 PM' into a timezone-aware datetime object.\"\"\"\n        dt_str = f\"{date} {post_time}\"\n        naive_dt = datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n        # Assume Eastern Time for USTA data, a common standard for US racing.\n        eastern = ZoneInfo(\"America/New_York\")\n        return naive_dt.replace(tzinfo=eastern)\n",
    "python_service/adapters/nyrabets_adapter.py": "# python_service/adapters/nyrabets_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass NYRABetsAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for nyrabets.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"NYRABets\"\n    BASE_URL = \"https://nyrabets.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/adapters/racingpost_adapter.py": "# python_service/adapters/racingpost_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingPostAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Racing Post racecards, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"RacingPost\"\n    BASE_URL = \"https://www.racingpost.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw HTML content for all races on a given date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch RacingPost index page\", url=index_url)\n            return None\n\n        index_parser = HTMLParser(index_response.text)\n        links = index_parser.css('a[data-test-selector^=\"RC-meetingItem__link_race\"]')\n        race_card_urls = [link.attributes[\"href\"] for link in links]\n\n        async def fetch_single_html(url: str):\n            response = await self.make_request(self.http_client, \"GET\", url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(url) for url in race_card_urls]\n        html_contents = await asyncio.gather(*tasks)\n        return {\"date\": date, \"html_contents\": html_contents}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"html_contents\"):\n            return []\n\n        date = raw_data[\"date\"]\n        html_contents = raw_data[\"html_contents\"]\n        all_races: List[Race] = []\n\n        for html in html_contents:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first('a[data-test-selector=\"RC-course__name\"]')\n                if not venue_node:\n                    continue\n                venue_raw = venue_node.text(strip=True)\n                venue = normalize_venue_name(venue_raw)\n\n                race_time_node = parser.css_first('span[data-test-selector=\"RC-course__time\"]')\n                if not race_time_node:\n                    continue\n                race_time_str = race_time_node.text(strip=True)\n\n                race_datetime_str = f\"{date} {race_time_str}\"\n                start_time = datetime.strptime(race_datetime_str, \"%Y-%m-%d %H:%M\")\n\n                runners = self._parse_runners(parser)\n\n                if venue and runners:\n                    race_number = self._get_race_number(parser, start_time)\n                    race = Race(\n                        id=f\"rp_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=start_time,\n                        runners=runners,\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse RacingPost race from HTML content.\", exc_info=True)\n                continue\n        return all_races\n\n    def _get_race_number(self, parser: HTMLParser, start_time: datetime) -> int:\n        \"\"\"Derives the race number by finding the active time in the nav bar.\"\"\"\n        time_str_to_find = start_time.strftime(\"%H:%M\")\n        time_links = parser.css('a[data-test-selector=\"RC-raceTime\"]')\n        for i, link in enumerate(time_links):\n            if link.text(strip=True) == time_str_to_find:\n                return i + 1\n        return 1\n\n    def _parse_runners(self, parser: HTMLParser) -> list[Runner]:\n        \"\"\"Parses all runners from a single race card page.\"\"\"\n        runners = []\n        runner_nodes = parser.css('div[data-test-selector=\"RC-runnerCard\"]')\n        for node in runner_nodes:\n            if runner := self._parse_runner(node):\n                runners.append(runner)\n        return runners\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first('span[data-test-selector=\"RC-runnerNumber\"]')\n            name_node = node.css_first('a[data-test-selector=\"RC-runnerName\"]')\n            odds_node = node.css_first('span[data-test-selector=\"RC-runnerPrice\"]')\n\n            if not all([number_node, name_node, odds_node]):\n                return None\n\n            number_str = clean_text(number_node.text())\n            number = int(number_str) if number_str and number_str.isdigit() else 0\n            name = clean_text(name_node.text())\n            odds_str = clean_text(odds_node.text())\n            scratched = \"NR\" in odds_str.upper() or not odds_str\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError):\n            self.logger.warning(\"Could not parse RacingPost runner, skipping.\", exc_info=True)\n            return None\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/the_racing_api_adapter.py": "# python_service/adapters/the_racing_api_adapter.py\n\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TheRacingApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for The Racing API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"TheRacingAPI\"\n    BASE_URL = \"https://api.theracingapi.com/v1/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"THE_RACING_API_KEY\") or not config.THE_RACING_API_KEY:\n            raise AdapterConfigError(self.source_name, \"THE_RACING_API_KEY is not configured.\")\n        self.api_key = config.THE_RACING_API_KEY\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw racecard data from The Racing API.\"\"\"\n        endpoint = f\"racecards?date={date}&course=all&region=gb,ire\"\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n        response = await self.make_request(self.http_client, \"GET\", endpoint, headers=headers)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw JSON response into a list of Race objects.\"\"\"\n        if not raw_data or \"racecards\" not in raw_data:\n            self.logger.warning(\"'racecards' key missing in TheRacingAPI response.\")\n            return []\n\n        races = []\n        for race_data in raw_data.get(\"racecards\", []):\n            try:\n                race_id = race_data.get(\"race_id\")\n                off_time = race_data.get(\"off_time\")\n                course = race_data.get(\"course\")\n                race_no = race_data.get(\"race_no\")\n\n                if not all([race_id, off_time, course, race_no]):\n                    continue\n\n                start_time = datetime.fromisoformat(off_time.replace(\"Z\", \"+00:00\"))\n\n                race = Race(\n                    id=f\"tra_{race_id}\",\n                    venue=course,\n                    race_number=race_no,\n                    start_time=start_time,\n                    runners=self._parse_runners(race_data.get(\"runners\", [])),\n                    source=self.source_name,\n                    race_name=race_data.get(\"race_name\"),\n                    distance=race_data.get(\"distance_f\"),\n                )\n                races.append(race)\n            except Exception:\n                self.logger.error(\n                    \"Error parsing TheRacingAPI race\",\n                    race_id=race_data.get(\"race_id\"),\n                    exc_info=True,\n                )\n        return races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for i, runner_data in enumerate(runners_data):\n            try:\n                horse = runner_data.get(\"horse\")\n                if not horse:\n                    continue\n\n                odds_data = {}\n                odds_list = runner_data.get(\"odds\", [])\n                if odds_list:\n                    odds_decimal_str = odds_list[0].get(\"odds_decimal\")\n                    if odds_decimal_str:\n                        win_odds = Decimal(str(odds_decimal_str))\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=runner_data.get(\"number\", i + 1),\n                        name=horse,\n                        odds=odds_data,\n                        jockey=runner_data.get(\"jockey\"),\n                        trainer=runner_data.get(\"trainer\"),\n                    )\n                )\n            except Exception:\n                self.logger.error(\n                    \"Error parsing TheRacingAPI runner\",\n                    runner_name=runner_data.get(\"horse\"),\n                    exc_info=True,\n                )\n        return runners\n",
    "python_service/adapters/timeform_adapter.py": "# python_service/adapters/timeform_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TimeformAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for timeform.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Timeform\"\n    BASE_URL = \"https://www.timeform.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        index_url = f\"/horse-racing/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Timeform index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        links = {a[\"href\"] for a in index_soup.select(\"a.rp-racecard-off-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to TimeformAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n\n                track_name_node = soup.select_one(\"h1.rp-raceTimeCourseName_name\")\n                if not track_name_node:\n                    continue\n                track_name = clean_text(track_name_node.get_text())\n\n                race_time_node = soup.select_one(\"span.rp-raceTimeCourseName_time\")\n                if not race_time_node:\n                    continue\n                race_time_str = clean_text(race_time_node.get_text())\n\n                start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n\n                all_times = [clean_text(a.get_text()) for a in soup.select(\"a.rp-racecard-off-link\")]\n                race_number = all_times.index(race_time_str) + 1 if race_time_str in all_times else 1\n\n                runner_rows = soup.select(\"div.rp-horseTable_mainRow\")\n                if not runner_rows:\n                    continue\n\n                runners = [self._parse_runner(row) for row in runner_rows]\n                race = Race(\n                    id=f\"tf_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],  # Filter out None values\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError, TypeError):\n                self.logger.warning(\"Error parsing a race from Timeform, skipping race.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"a.rp-horseTable_horse-name\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.get_text())\n\n            num_node = row.select_one(\"span.rp-horseTable_horse-number\")\n            if not num_node:\n                return None\n            num_str = clean_text(num_node.get_text())\n            number_part = \"\".join(filter(str.isdigit, num_str.strip(\"()\")))\n            number = int(number_part)\n\n            odds_data = {}\n            if odds_tag := row.select_one(\"button.rp-bet-placer-btn__odds\"):\n                odds_str = clean_text(odds_tag.get_text())\n                if win_odds := parse_odds_to_decimal(odds_str):\n                    if win_odds < 999:\n                        odds_data = {\n                            self.source_name: OddsData(\n                                win=win_odds,\n                                source=self.source_name,\n                                last_updated=datetime.now(),\n                            )\n                        }\n\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError, TypeError):\n            self.logger.warning(\"Failed to parse a runner from Timeform, skipping runner.\")\n            return None\n",
    "python_service/adapters/twinspires_adapter.py": "# python_service/adapters/twinspires_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TwinSpiresAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for twinspires.com.\n    This is a placeholder for a full implementation using the discovered JSON API.\n    \"\"\"\n\n    SOURCE_NAME = \"TwinSpires\"\n    BASE_URL = \"https://www.twinspires.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Reads HTML content from a local fixture file instead of making a live API call.\n        This is a temporary measure to allow development while the live API is blocking requests.\n        \"\"\"\n        # Read the local HTML fixture\n        try:\n            with open(\"tests/fixtures/twinspires_sample.html\", \"r\") as f:\n                html_content = f.read()\n        except FileNotFoundError:\n            self.logger.error(\"TwinSpires test fixture not found.\")\n            return None\n\n        # To maintain the data structure the parser expects, we will create a mock\n        # raw_data object that resembles the original API response, but includes\n        # the HTML content.\n        return {\n            \"html_content\": html_content,\n            \"mock_track_data\": {\n                \"trackId\": \"cd\",\n                \"trackName\": \"Churchill Downs\",\n                \"raceType\": \"Thoroughbred\"\n            },\n            \"mock_race_card\": {\n                \"raceNumber\": 5,\n                \"postTime\": \"2025-10-26T16:30:00Z\"\n            }\n        }\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Parses race and runner data from the mock raw_data object, which now\n        includes the HTML content from the local fixture.\n        \"\"\"\n        if not raw_data or \"html_content\" not in raw_data:\n            return []\n\n        self.logger.info(\"Parsing TwinSpires data from local fixture.\")\n\n        html_content = raw_data[\"html_content\"]\n        track = raw_data[\"mock_track_data\"]\n        race_card = raw_data[\"mock_race_card\"]\n\n        # Parse the runners from the HTML content\n        runners = self._parse_runners_from_html(html_content)\n\n        try:\n            start_time = datetime.fromisoformat(race_card.get(\"postTime\").replace(\"Z\", \"+00:00\"))\n\n            race = Race(\n                id=f\"ts_{track.get('trackId')}_{race_card.get('raceNumber')}\",\n                venue=track.get(\"trackName\"),\n                race_number=race_card.get(\"raceNumber\"),\n                start_time=start_time,\n                discipline=track.get(\"raceType\", \"Unknown\"),\n                runners=runners,\n                source=self.SOURCE_NAME,\n            )\n            return [race]\n        except Exception as e:\n            self.logger.warning(\n                \"Failed to parse race card from mock data.\",\n                error=e,\n                exc_info=True,\n            )\n            return []\n\n    def _parse_runners_from_html(self, html_content: str) -> List[Runner]:\n        \"\"\"Parses runner data from a race card's HTML content.\"\"\"\n        runners = []\n        soup = BeautifulSoup(html_content, \"html.parser\")\n        runner_elements = soup.select(\"li.runner\")\n\n        for element in runner_elements:\n            try:\n                scratched = \"scratched\" in element.get(\"class\", [])\n\n                number_tag = element.select_one(\"span.runner-number\")\n                name_tag = element.select_one(\"span.runner-name\")\n                odds_tag = element.select_one(\"span.runner-odds\")\n\n                if not all([number_tag, name_tag, odds_tag]):\n                    continue\n\n                number = int(number_tag.text.strip())\n                name = name_tag.text.strip()\n                odds_str = odds_tag.text.strip()\n\n                odds = {}\n                if not scratched and odds_str not in [\"SCR\", \"\"]:\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    if win_odds:\n                        odds[self.SOURCE_NAME] = OddsData(\n                            win=win_odds,\n                            source=self.SOURCE_NAME,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=number,\n                        name=name,\n                        scratched=scratched,\n                        odds=odds,\n                    )\n                )\n            except (ValueError, TypeError) as e:\n                self.logger.warning(\"Failed to parse a runner, skipping.\", error=e, exc_info=True)\n                continue\n\n        return runners\n\n    async def _get_races_async(self, date: str) -> List[Race]:\n        raw_data = await self._fetch_data(date)\n        return self._parse_races(raw_data)\n\n    def get_races(self, date: str) -> List[Race]:\n        \"\"\"\n        Orchestrates the fetching and parsing of race data for a given date.\n        This method will be called by the FortunaEngine.\n        \"\"\"\n        self.logger.info(f\"Getting races for {date} from {self.SOURCE_NAME}\")\n        # This is a synchronous wrapper for the async orchestrator\n        # It's a temporary measure to allow me to see the API response.\n        import asyncio\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        races = loop.run_until_complete(self._get_races_async(date))\n        return races\n",
    "python_service/adapters/universal_adapter.py": "# python_service/adapters/universal_adapter.py\nimport json\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass UniversalAdapter(BaseAdapterV3):\n    \"\"\"\n    An adapter that executes logic from a declarative JSON definition file.\n    NOTE: This is a simplified proof-of-concept implementation.\n    \"\"\"\n\n    def __init__(self, config, definition_path: str):\n        with open(definition_path, \"r\") as f:\n            self.definition = json.load(f)\n\n        super().__init__(\n            source_name=self.definition[\"adapter_name\"],\n            base_url=self.definition[\"base_url\"],\n            config=config,\n        )\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Executes the fetch steps defined in the JSON definition.\"\"\"\n        self.logger.info(f\"Executing Universal Adapter PoC for {self.source_name}\")\n        response = await self.make_request(self.http_client, \"GET\", self.definition[\"start_url\"])\n        if not response:\n            return None\n\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        track_links = [self.base_url + a[\"href\"] for a in soup.select(self.definition[\"steps\"][0][\"selector\"])]\n\n        # In a full implementation, we would fetch and return each track page's content.\n        # For this PoC, we are not fetching the individual track links.\n        self.logger.warning(\"UniversalAdapter is a proof-of-concept and does not fully fetch all data.\")\n        return track_links\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a proof-of-concept and does not parse any data.\"\"\"\n        return []\n",
    "python_service/analyzer.py": "from abc import ABC\nfrom abc import abstractmethod\nfrom decimal import Decimal\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\n\nimport structlog\n\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\ntry:\n    # winsound is a built-in Windows library\n    import winsound\nexcept ImportError:\n    winsound = None\ntry:\n    from win10toast_py3 import ToastNotifier\nexcept (ImportError, RuntimeError):\n    # Fails gracefully on non-Windows systems\n    ToastNotifier = None\n\nlog = structlog.get_logger(__name__)\n\n\ndef _get_best_win_odds(runner: Runner) -> Optional[Decimal]:\n    \"\"\"Gets the best win odds for a runner, filtering out invalid or placeholder values.\"\"\"\n    if not runner.odds:\n        return None\n\n    # Filter out invalid or placeholder odds (e.g., > 999)\n    valid_odds = [o.win for o in runner.odds.values() if o.win is not None and o.win > 0 and o.win < 999]\n\n    if not valid_odds:\n        return None\n\n    return min(valid_odds)\n\n\nclass BaseAnalyzer(ABC):\n    \"\"\"The abstract interface for all future analyzer plugins.\"\"\"\n\n    def __init__(self, **kwargs):\n        pass\n\n    @abstractmethod\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"The core method every analyzer must implement.\"\"\"\n        pass\n\n\nclass TrifectaAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzes races and assigns a qualification score based on the 'Trifecta of Factors'.\"\"\"\n\n    @property\n    def name(self) -> str:\n        return \"trifecta_analyzer\"\n\n    def __init__(\n        self,\n        max_field_size: int = 10,\n        min_favorite_odds: float = 2.5,\n        min_second_favorite_odds: float = 4.0,\n    ):\n        self.max_field_size = max_field_size\n        self.min_favorite_odds = Decimal(str(min_favorite_odds))\n        self.min_second_favorite_odds = Decimal(str(min_second_favorite_odds))\n        self.notifier = RaceNotifier()\n\n    def is_race_qualified(self, race: Race) -> bool:\n        \"\"\"A race is qualified for a trifecta if it has at least 3 non-scratched runners.\"\"\"\n        if not race or not race.runners:\n            return False\n\n        active_runners = sum(1 for r in race.runners if not r.scratched)\n        return active_runners >= 3\n\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"Scores all races and returns a dictionary with criteria and a sorted list.\"\"\"\n        qualified_races = []\n        for race in races:\n            score = self._evaluate_race(race)\n            if score > 0:\n                race.qualification_score = score\n                qualified_races.append(race)\n\n        qualified_races.sort(key=lambda r: r.qualification_score, reverse=True)\n\n        criteria = {\n            \"max_field_size\": self.max_field_size,\n            \"min_favorite_odds\": float(self.min_favorite_odds),\n            \"min_second_favorite_odds\": float(self.min_second_favorite_odds),\n        }\n\n        log.info(\n            \"Universal scoring complete\",\n            total_races_scored=len(qualified_races),\n            criteria=criteria,\n        )\n\n        for race in qualified_races:\n            if race.qualification_score and race.qualification_score >= 85:\n                self.notifier.notify_qualified_race(race)\n\n        return {\"criteria\": criteria, \"races\": qualified_races}\n\n    def _evaluate_race(self, race: Race) -> float:\n        \"\"\"Evaluates a single race and returns a qualification score.\"\"\"\n        # --- Constants for Scoring Logic ---\n        FAV_ODDS_NORMALIZATION = 10.0\n        SEC_FAV_ODDS_NORMALIZATION = 15.0\n        FAV_ODDS_WEIGHT = 0.6\n        SEC_FAV_ODDS_WEIGHT = 0.4\n        FIELD_SIZE_SCORE_WEIGHT = 0.3\n        ODDS_SCORE_WEIGHT = 0.7\n\n        active_runners = [r for r in race.runners if not r.scratched]\n\n        runners_with_odds = []\n        for runner in active_runners:\n            best_odds = _get_best_win_odds(runner)\n            if best_odds is not None:\n                runners_with_odds.append((runner, best_odds))\n\n        if len(runners_with_odds) < 2:\n            return 0.0\n\n        runners_with_odds.sort(key=lambda x: x[1])\n        favorite_odds = runners_with_odds[0][1]\n        second_favorite_odds = runners_with_odds[1][1]\n\n        # --- Calculate Qualification Score (as inspired by the TypeScript Genesis) ---\n        field_score = (self.max_field_size - len(active_runners)) / self.max_field_size\n\n        # Normalize odds scores - cap influence of extremely high odds\n        fav_odds_score = min(float(favorite_odds) / FAV_ODDS_NORMALIZATION, 1.0)\n        sec_fav_odds_score = min(float(second_favorite_odds) / SEC_FAV_ODDS_NORMALIZATION, 1.0)\n\n        # Weighted average\n        odds_score = (fav_odds_score * FAV_ODDS_WEIGHT) + (sec_fav_odds_score * SEC_FAV_ODDS_WEIGHT)\n        final_score = (field_score * FIELD_SIZE_SCORE_WEIGHT) + (odds_score * ODDS_SCORE_WEIGHT)\n\n        # --- Apply a penalty if hard filters are not met, instead of returning None ---\n        if (\n            len(active_runners) > self.max_field_size\n            or favorite_odds < self.min_favorite_odds\n            or second_favorite_odds < self.min_second_favorite_odds\n        ):\n            # Assign a score of 0 to races that would have been filtered out\n            return 0.0\n\n        score = round(final_score * 100, 2)\n        race.qualification_score = score\n        return score\n\n\nclass AnalyzerEngine:\n    \"\"\"Discovers and manages all available analyzer plugins.\"\"\"\n\n    def __init__(self):\n        self.analyzers: Dict[str, Type[BaseAnalyzer]] = {}\n        self._discover_analyzers()\n\n    def _discover_analyzers(self):\n        # In a real plugin system, this would inspect a folder.\n        # For now, we register them manually.\n        self.register_analyzer(\"trifecta\", TrifectaAnalyzer)\n        log.info(\n            \"AnalyzerEngine discovered plugins\",\n            available_analyzers=list(self.analyzers.keys()),\n        )\n\n    def register_analyzer(self, name: str, analyzer_class: Type[BaseAnalyzer]):\n        self.analyzers[name] = analyzer_class\n\n    def get_analyzer(self, name: str, **kwargs) -> BaseAnalyzer:\n        analyzer_class = self.analyzers.get(name)\n        if not analyzer_class:\n            log.error(\"Requested analyzer not found\", requested_analyzer=name)\n            raise ValueError(f\"Analyzer '{name}' not found.\")\n        return analyzer_class(**kwargs)\n\n\nclass AudioAlertSystem:\n    \"\"\"Plays sound alerts for important events.\"\"\"\n\n    def __init__(self):\n        self.sounds = {\n            \"high_value\": Path(__file__).parent.parent.parent / \"assets\" / \"sounds\" / \"alert_premium.wav\",\n        }\n        self.enabled = winsound is not None\n\n    def play(self, sound_type: str):\n        if not self.enabled:\n            return\n\n        sound_file = self.sounds.get(sound_type)\n        if sound_file and sound_file.exists():\n            try:\n                winsound.PlaySound(str(sound_file), winsound.SND_FILENAME | winsound.SND_ASYNC)\n            except Exception as e:\n                log.warning(\"Could not play sound\", file=sound_file, error=e)\n\n\nclass RaceNotifier:\n    \"\"\"Handles sending native Windows notifications and audio alerts for high-value races.\"\"\"\n\n    def __init__(self):\n        self.toaster = ToastNotifier(\"Fortuna\") if ToastNotifier else None\n        self.audio_system = AudioAlertSystem()\n        self.notified_races = set()\n\n    def notify_qualified_race(self, race):\n        if not self.toaster or race.id in self.notified_races:\n            return\n\n        title = \"\ud83c\udfc7 High-Value Opportunity!\"\n        message = f\"\"\"{race.venue} - Race {race.race_number}\nScore: {race.qualification_score:.0f}%\nPost Time: {race.start_time.strftime(\"%I:%M %p\")}\"\"\"\n\n        try:\n            # The `threaded=True` argument is crucial to prevent blocking the main application thread.\n            self.toaster.show_toast(title, message, duration=10, threaded=True)\n            self.notified_races.add(race.id)\n            self.audio_system.play(\"high_value\")\n            log.info(\"Notification and audio alert sent for high-value race\", race_id=race.id)\n        except Exception as e:\n            # Catch potential exceptions from the notification library itself\n            log.error(\"Failed to send notification\", error=str(e), exc_info=True)\n",
    "python_service/api.py": "# python_service/api.py\n\nimport asyncio\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom contextlib import asynccontextmanager\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import List\nfrom typing import Optional\n\nimport aiosqlite\nimport structlog\nfrom fastapi import Depends\nfrom fastapi import FastAPI\nfrom fastapi import HTTPException\nfrom fastapi import Query\nfrom fastapi import Request\nfrom fastapi import WebSocket\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom slowapi import Limiter\nfrom slowapi import _rate_limit_exceeded_handler\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi.middleware import SlowAPIMiddleware\nfrom slowapi.util import get_remote_address\nfrom starlette.websockets import WebSocketDisconnect\n\n# --- PyInstaller Explicit Imports ---\nfrom .analyzer import AnalyzerEngine\nfrom .cache_manager import cache_manager\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .engine import OddsEngine\nfrom .health import router as health_router\nfrom .logging_config import configure_logging\nfrom .manual_override_manager import ManualOverrideManager\nfrom .middleware.error_handler import UserFriendlyException\nfrom .middleware.error_handler import user_friendly_exception_handler\nfrom .middleware.error_handler import validation_exception_handler\nfrom .models import AggregatedResponse\nfrom .models import ManualParseRequest\nfrom .models import QualifiedRacesResponse\nfrom .models import Race\nfrom .models import TipsheetRace\nfrom .security import verify_api_key\n\n# ------------------------------------\n\nlog = structlog.get_logger()\n\n# Create a fixed thread pool for blocking calls at the module level\nexecutor = ThreadPoolExecutor(max_workers=1)\n\n\ndef _initialize_heavy_resources_sync(app: FastAPI):\n    \"\"\"\n    This synchronous function contains the blocking I/O and CPU-intensive\n    initialization of the OddsEngine and its ~25 adapters. By isolating it,\n    we can run it in a background thread without stalling the main Uvicorn event loop.\n    \"\"\"\n    log.info(\"Background initialization of heavy resources started.\")\n    try:\n        settings = get_settings()\n\n        # Initialize WebSocket connection manager\n        connection_manager = ConnectionManager()\n\n        # Initialize manual override manager\n        manual_override_manager = ManualOverrideManager()\n\n        # Initialize engine with manual override and WebSocket support\n        engine = OddsEngine(\n            config=settings,\n            manual_override_manager=manual_override_manager,\n            connection_manager=connection_manager,\n        )\n\n        # Store the initialized components on the app state\n        app.state.engine = engine\n        app.state.analyzer_engine = AnalyzerEngine()\n        app.state.manual_override_manager = manual_override_manager\n        app.state.connection_manager = connection_manager\n        log.info(\"Background initialization of heavy resources completed successfully.\")\n    except Exception:\n        log.critical(\"CRITICAL: Background initialization failed.\", exc_info=True)\n        # In a real-world scenario, you might want a more robust way\n        # to signal this failure to the main application.\n        app.state.engine = None\n\n\nclass ConnectionManager:\n    \"\"\"Manages active WebSocket connections.\"\"\"\n\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        log.info(\"WebSocket ConnectionManager initialized.\")\n\n    async def connect(self, websocket: WebSocket):\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        log.info(\"New WebSocket connection established.\")\n\n    def disconnect(self, websocket: WebSocket):\n        self.active_connections.remove(websocket)\n        log.info(\"WebSocket connection closed.\")\n\n    async def broadcast(self, message: dict):\n        \"\"\"Broadcasts a message to all connected clients.\"\"\"\n        if not self.active_connections:\n            return\n\n        log.info(\n            \"Broadcasting message to connected clients\",\n            client_count=len(self.active_connections),\n        )\n        for connection in self.active_connections:\n            try:\n                await connection.send_json(message)\n            except Exception:\n                log.error(\"Error sending message to a WebSocket client.\", exc_info=True)\n\n\n# Lifespan context manager\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    configure_logging()\n    log.info(\"Uvicorn is online, starting lifespan hook.\")\n\n    # 1. Perform lightweight, non-blocking startup tasks\n    settings = get_settings()\n    await cache_manager.connect(settings.REDIS_URL)\n    log.info(\"Fast, non-blocking startup tasks complete (Redis connected).\")\n\n    # 2. Schedule the heavy, synchronous initialization to run in a background thread\n    loop = asyncio.get_event_loop()\n    loop.run_in_executor(executor, _initialize_heavy_resources_sync, app)\n    log.info(\"Heavy resource initialization has been scheduled in a background thread.\")\n\n    # 3. Wait for the engine to be initialized before yielding control.\n    start_time = time.time()\n    while not hasattr(app.state, \"engine\") or app.state.engine is None:\n        if time.time() - start_time > 30:  # 30-second timeout\n            raise RuntimeError(\"Engine initialization timed out.\")\n        await asyncio.sleep(0.1)\n\n    log.info(\"Engine is initialized. Server is ready to accept requests.\")\n    yield\n\n    # --- Shutdown Sequence ---\n    log.info(\"Server shutdown sequence initiated.\")\n    if hasattr(app.state, \"engine\") and app.state.engine:\n        log.info(\"Closing HTTP client resources.\")\n        await app.state.engine.close()\n\n    await cache_manager.disconnect()\n    executor.shutdown(wait=False)\n    log.info(\"Server shutdown sequence complete.\")\n\n\nlimiter = Limiter(key_func=get_remote_address)\napp = FastAPI(\n    title=\"Fortuna Faucet API\",\n    version=\"2.1\",\n    lifespan=lifespan,\n    docs_url=\"/api/docs\",\n    redoc_url=\"/api/redoc\",\n    openapi_url=\"/api/openapi.json\",\n)\n\napp.add_middleware(SlowAPIMiddleware)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\napp.add_exception_handler(RequestValidationError, validation_exception_handler)\napp.add_exception_handler(UserFriendlyException, user_friendly_exception_handler)\napp.include_router(health_router)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\", \"http://localhost:3001\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\"],\n    allow_headers=[\"*\"],\n)\n\n\ndef get_engine(request: Request) -> OddsEngine:\n    return request.app.state.engine\n\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"ok\", \"timestamp\": datetime.now().isoformat()}\n\n\n@app.get(\"/api/adapters/status\")\n@limiter.limit(\"60/minute\")\nasync def get_all_adapter_statuses(\n    request: Request,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        return engine.get_all_adapter_statuses()\n    except Exception:\n        log.error(\"Error in /api/adapters/status\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@app.get(\"/api/races/qualified/{analyzer_name}\", response_model=QualifiedRacesResponse)\n@limiter.limit(\"120/minute\")\nasync def get_qualified_races(\n    analyzer_name: str,\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n    max_field_size: int = Query(10, ge=3, le=20),\n    min_favorite_odds: float = Query(2.5, ge=1.0, le=100.0),\n    min_second_favorite_odds: float = Query(4.0, ge=1.0, le=100.0),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        aggregated_data = await engine.fetch_all_odds(date_str)\n        races = [Race(**r) for r in aggregated_data.get(\"races\", [])]\n        analyzer_engine = request.app.state.analyzer_engine\n        custom_params = {\n            \"max_field_size\": max_field_size,\n            \"min_favorite_odds\": min_favorite_odds,\n            \"min_second_favorite_odds\": min_second_favorite_odds,\n        }\n        analyzer = analyzer_engine.get_analyzer(analyzer_name, **custom_params)\n        result = analyzer.qualify_races(races)\n        return QualifiedRacesResponse(**result)\n    except ValueError as e:\n        log.warning(\"Requested analyzer not found\", analyzer_name=analyzer_name)\n        raise HTTPException(status_code=404, detail=str(e))\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(\"Error in /api/races/qualified\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\n@app.get(\"/api/races/filter-suggestions\")\nasync def get_filter_suggestions(engine: OddsEngine = Depends(get_engine)):\n    try:\n        date_str = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n        aggregated = await engine.fetch_all_odds(date_str)\n        if not aggregated or not aggregated.get(\"races\"):\n            return {\"suggestions\": {}}\n        field_sizes = [len(r[\"runners\"]) for r in aggregated[\"races\"]]\n        favorite_odds, second_favorite_odds = [], []\n        for race_data in aggregated[\"races\"]:\n            race = Race(**race_data)\n            runners = race.runners\n            if len(runners) >= 2:\n                odds_list = []\n                for runner in runners:\n                    if not runner.scratched and runner.odds:\n                        best_odd = min(\n                            (o.win for o in runner.odds.values() if o.win is not None),\n                            default=None,\n                        )\n                        if best_odd is not None:\n                            odds_list.append(float(best_odd))\n                if len(odds_list) >= 2:\n                    odds_list.sort()\n                    favorite_odds.append(odds_list[0])\n                    second_favorite_odds.append(odds_list[1])\n        return {\n            \"suggestions\": {\n                \"max_field_size\": {\"recommended\": (int(sum(field_sizes) / len(field_sizes)) if field_sizes else 10)},\n                \"min_favorite_odds\": {\"recommended\": 2.5},\n                \"min_second_favorite_odds\": {\"recommended\": 4.0},\n            }\n        }\n    except Exception:\n        log.error(\"Error generating filter suggestions\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Failed to generate suggestions\")\n\n\n@app.get(\"/api/races/source/{source_name}\", response_model=AggregatedResponse)\n@limiter.limit(\"60/minute\")\nasync def get_races_by_source(\n    source_name: str,\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        return await engine.fetch_all_odds(date_str, source=source_name)\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(f\"Error in /api/races/source/{source_name}\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\n@app.get(\"/api/races\", response_model=AggregatedResponse)\n@limiter.limit(\"30/minute\")\nasync def get_races(\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    source: Optional[str] = None,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        return await engine.fetch_all_odds(date_str, source)\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(\"Error in /api/races\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\nDB_PATH = \"fortuna.db\"\n\n\ndef get_current_date() -> date:\n    return datetime.now().date()\n\n\n@app.get(\"/api/tipsheet\", response_model=List[TipsheetRace])\n@limiter.limit(\"30/minute\")\nasync def get_tipsheet_endpoint(request: Request, date: date = Depends(get_current_date)):\n    results = []\n    try:\n        async with aiosqlite.connect(DB_PATH) as db:\n            db.row_factory = aiosqlite.Row\n            query = \"SELECT * FROM tipsheet WHERE date(post_time) = ? ORDER BY post_time ASC\"\n            async with db.execute(query, (date.isoformat(),)) as cursor:\n                async for row in cursor:\n                    results.append(dict(row))\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return results\n\n\n# API Models\nclass ManualDataSubmission(BaseModel):\n    request_id: str\n    content: str\n    content_type: str = \"html\"\n\n\n# New endpoints\n@app.get(\"/api/manual-overrides/pending\")\n@limiter.limit(\"60/minute\")\nasync def get_pending_overrides(\n    request: Request,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Get all pending manual override requests\"\"\"\n    pending = manager.get_pending_requests()\n    return {\"pending_requests\": [req.model_dump() for req in pending]}\n\n\n@app.post(\"/api/manual-overrides/submit\")\n@limiter.limit(\"30/minute\")\nasync def submit_manual_data(\n    request: Request,\n    submission: ManualDataSubmission,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Submit manually-provided data for a failed fetch\"\"\"\n    success = manager.submit_manual_data(\n        request_id=submission.request_id,\n        raw_content=submission.content,\n        content_type=submission.content_type,\n    )\n\n    if success:\n        return {\"status\": \"success\", \"message\": \"Manual data submitted\"}\n    else:\n        raise HTTPException(status_code=404, detail=\"Request not found\")\n\n\n@app.post(\"/api/manual-overrides/skip/{request_id}\")\n@limiter.limit(\"60/minute\")\nasync def skip_manual_override(\n    request: Request,\n    request_id: str,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Skip a manual override request\"\"\"\n    success = manager.skip_request(request_id)\n\n    if success:\n        return {\"status\": \"success\", \"message\": \"Request skipped\"}\n    else:\n        raise HTTPException(status_code=404, detail=\"Request not found\")\n\n\n@app.post(\"/api/manual-overrides/cleanup\")\n@limiter.limit(\"60/minute\")\nasync def cleanup_old_overrides(\n    request: Request,\n    max_age_hours: int = 24,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Clean up old manual override requests\"\"\"\n    manager.clear_old_requests(max_age_hours)\n    return {\"status\": \"success\", \"message\": \"Old requests cleaned\"}\n\n\n@app.websocket(\"/ws/live-updates\")\nasync def websocket_endpoint(websocket: WebSocket, api_key: str = Query(...)):\n    \"\"\"WebSocket endpoint for live race updates.\"\"\"\n    try:\n        # Use the existing API key verification logic\n        # This is a synchronous call, which is fine for auth at the start.\n        # In a real-world scenario with high connection rates, you might\n        # want to make this check asynchronous if it involved I/O.\n        verify_api_key(api_key)\n    except HTTPException as e:\n        log.warning(\"WebSocket connection rejected due to invalid API key.\")\n        await websocket.close(code=4001, reason=f\"Authentication failed: {e.detail}\")\n        return\n\n    manager = websocket.app.state.connection_manager\n    await manager.connect(websocket)\n    try:\n        # Keep the connection alive, listening for messages (if any)\n        while True:\n            # You could implement logic here to handle incoming messages if needed\n            # For now, it's just a broadcast-only connection\n            await websocket.receive_text()\n    except WebSocketDisconnect:\n        manager.disconnect(websocket)\n        log.info(\"Client disconnected from WebSocket.\")\n\n\n@app.post(\"/api/races/parse-manual\", response_model=List[Race])\n@limiter.limit(\"30/minute\")\nasync def parse_manual_html(\n    request: Request,\n    parse_request: ManualParseRequest,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    \"\"\"\n    Manually parses a block of HTML using a specified adapter.\n    \"\"\"\n    try:\n        adapter = engine.get_adapter(parse_request.adapter_name)\n        if not adapter:\n            raise HTTPException(\n                status_code=404,\n                detail=f\"Adapter '{parse_request.adapter_name}' not found.\",\n            )\n\n        # The _parse_races method is synchronous, so we run it in a thread\n        # to avoid blocking the asyncio event loop.\n        loop = asyncio.get_event_loop()\n        parsed_races_data = await loop.run_in_executor(\n            executor, adapter._parse_races, parse_request.html_content\n        )\n\n        # Validate the parsed data with the Race model\n        validated_races = [Race(**race_data) for race_data in parsed_races_data]\n        return validated_races\n\n    except Exception as e:\n        log.error(\"Error during manual parsing\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n",
    "python_service/cache_manager.py": "# python_service/cache_manager.py\nimport asyncio\nimport hashlib\nimport json\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom functools import wraps\nfrom typing import Any\nfrom typing import Callable\n\nimport structlog\n\ntry:\n    import redis\n\n    REDIS_AVAILABLE = True\nexcept ImportError:\n    REDIS_AVAILABLE = False\n\nlog = structlog.get_logger(__name__)\n\n\nclass CacheManager:\n    def __init__(self):\n        self.redis_client = None\n        self.memory_cache = {}\n        self.is_configured = False\n        log.info(\"CacheManager initialized (not connected).\")\n\n    async def connect(self, redis_url: str):\n        if self.is_configured or not REDIS_AVAILABLE or not redis_url:\n            return\n\n        try:\n            log.info(\"Attempting to connect to Redis...\", url=redis_url)\n            # Use the async version of the client\n            self.redis_client = redis.asyncio.from_url(redis_url, decode_responses=True)\n            await self.redis_client.ping()  # Verify connection asynchronously\n            self.is_configured = True\n            log.info(\"Redis cache connected successfully.\")\n        except (redis.exceptions.ConnectionError, asyncio.TimeoutError) as e:\n            log.warning(\n                \"Failed to connect to Redis. Falling back to in-memory cache.\",\n                error=str(e),\n            )\n            self.redis_client = None\n            self.is_configured = False\n\n    async def disconnect(self):\n        if self.redis_client:\n            await self.redis_client.close()\n            log.info(\"Redis connection closed.\")\n\n    def _generate_key(self, prefix: str, *args, **kwargs) -> str:\n        key_data = f\"{prefix}:{args}:{sorted(kwargs.items())}\"\n        return hashlib.md5(key_data.encode()).hexdigest()\n\n    async def get(self, key: str) -> Any | None:\n        if self.redis_client:\n            try:\n                value = await self.redis_client.get(key)\n                return json.loads(value) if value else None\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis GET failed, falling back to memory cache.\", error=e)\n\n        entry = self.memory_cache.get(key)\n        if entry and entry.get(\"expires_at\", datetime.min) > datetime.now():\n            return entry.get(\"value\")\n        return None\n\n    async def set(self, key: str, value: Any, ttl_seconds: int = 300):\n        try:\n            serialized = json.dumps(value, default=str)\n        except (TypeError, ValueError) as e:\n            log.error(\"Failed to serialize value for caching.\", value=value, error=str(e))\n            return\n\n        if self.redis_client:\n            try:\n                await self.redis_client.setex(key, ttl_seconds, serialized)\n                return\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis SET failed, falling back to memory cache.\", error=e)\n\n        self.memory_cache[key] = {\n            \"value\": value,\n            \"expires_at\": datetime.now() + timedelta(seconds=ttl_seconds),\n        }\n\n\n# --- Singleton Instance & Decorator ---\ncache_manager = CacheManager()\n\n\ndef cache_async_result(ttl_seconds: int = 300, key_prefix: str = \"cache\"):\n    def decorator(func: Callable):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            instance_args = args[1:] if args and hasattr(args[0], func.__name__) else args\n            cache_key = cache_manager._generate_key(f\"{key_prefix}:{func.__name__}\", *instance_args, **kwargs)\n\n            cached_result = await cache_manager.get(cache_key)\n            if cached_result is not None:\n                log.debug(\"Cache hit\", function=func.__name__)\n                return cached_result\n\n            log.debug(\"Cache miss\", function=func.__name__)\n            result = await func(*args, **kwargs)\n\n            try:\n                await cache_manager.set(cache_key, result, ttl_seconds)\n            except Exception as e:\n                log.error(\"Failed to store result in cache.\", error=str(e), key=cache_key)\n\n            return result\n\n        return wrapper\n\n    return decorator\n",
    "python_service/core/__init__.py": "",
    "python_service/core/exceptions.py": "# python_service/core/exceptions.py\n\"\"\"\nCustom, application-specific exceptions for the Fortuna Faucet service.\n\nThis module defines a hierarchy of exception classes to provide standardized\nerror handling, particularly for the data adapter layer. Using these specific\nexceptions instead of generic ones allows for more precise error handling and\nclearer logging throughout the application.\n\"\"\"\n\n\nclass FortunaException(Exception):\n    \"\"\"Base class for all custom exceptions in this application.\"\"\"\n\n    pass\n\n\nclass AdapterError(FortunaException):\n    \"\"\"Base class for all adapter-related errors.\"\"\"\n\n    def __init__(self, adapter_name: str, message: str):\n        self.adapter_name = adapter_name\n        super().__init__(f\"[{adapter_name}] {message}\")\n\n\nclass AdapterRequestError(AdapterError):\n    \"\"\"Raised for general network or request-related issues.\"\"\"\n\n    pass\n\n\nclass AdapterHttpError(AdapterRequestError):\n    \"\"\"Raised for unsuccessful HTTP responses (e.g., 4xx or 5xx status codes).\"\"\"\n\n    def __init__(self, adapter_name: str, status_code: int, url: str):\n        self.status_code = status_code\n        self.url = url\n        message = f\"Received HTTP {status_code} from {url}\"\n        super().__init__(adapter_name, message)\n\n\nclass AdapterAuthError(AdapterHttpError):\n    \"\"\"Raised specifically for HTTP 401/403 errors, indicating an auth failure.\"\"\"\n\n    pass\n\n\nclass AdapterRateLimitError(AdapterHttpError):\n    \"\"\"Raised specifically for HTTP 429 errors, indicating a rate limit has been hit.\"\"\"\n\n    pass\n\n\nclass AdapterTimeoutError(AdapterRequestError):\n    \"\"\"Raised when a request to an external API times out.\"\"\"\n\n    pass\n\n\nclass AdapterConnectionError(AdapterRequestError):\n    \"\"\"Raised for DNS lookup failures or refused connections.\"\"\"\n\n    pass\n\n\nclass AdapterConfigError(AdapterError):\n    \"\"\"Raised when an adapter is missing necessary configuration (e.g., an API key).\"\"\"\n\n    pass\n\n\nclass AdapterParsingError(AdapterError):\n    \"\"\"Raised when an adapter fails to parse the response from an API.\"\"\"\n\n    pass\n",
    "python_service/fortuna_windows_service.py": "# fortuna_windows_service.py\n\nimport logging\nimport os\nimport sys\n\nimport servicemanager\nimport win32event\nimport win32service\nimport win32serviceutil\n\n# Ensure the script's directory is at the front of the path\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.insert(0, script_dir)\n\ntry:\n    from fortuna_service import FortunaBackgroundService\nexcept ImportError as e:\n    # Log a detailed error to the Windows Event Log if the import fails\n    servicemanager.LogErrorMsg(f\"FATAL: Could not import FortunaBackgroundService. Error: {e}\")\n    sys.exit(1)  # Exit with an error code\n\n\nclass FortunaWindowsService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaV8Service\"\n    _svc_display_name_ = \"Fortuna V8 Racing Analysis Service\"\n    _svc_description_ = \"Continuously fetches and analyzes horse racing data.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)\n        self.fortuna_service = FortunaBackgroundService()\n        # Configure logging to use the Windows Event Log\n        logging.basicConfig(\n            level=logging.INFO,\n            format=\"%(name)s - %(levelname)s - %(message)s\",\n            handlers=[servicemanager.LogHandler()],\n        )\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        self.fortuna_service.stop()\n        win32event.SetEvent(self.hWaitStop)\n        self.ReportServiceStatus(win32service.SERVICE_STOPPED)\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(\n            servicemanager.EVENTLOG_INFORMATION_TYPE,\n            servicemanager.PYS_SERVICE_STARTED,\n            (self._svc_name_, \"\"),\n        )\n        self.main()\n\n    def main(self):\n        self.fortuna_service.start()\n        win32event.WaitForSingleObject(self.hWaitStop, win32event.INFINITE)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaWindowsService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaWindowsService)\n",
    "python_service/manual_override_manager.py": "# python_service/manual_override_manager.py\nimport hashlib\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\n\nfrom pydantic import BaseModel\nfrom pydantic import Field\n\n\nclass ManualOverrideRequest(BaseModel):\n    request_id: str\n    adapter_name: str\n    url: str\n    timestamp: datetime = Field(default_factory=datetime.now)\n    status: str = \"pending\"  # pending, submitted, skipped\n\n\nclass ManualOverrideManager:\n    def __init__(self):\n        self._requests: Dict[str, ManualOverrideRequest] = {}\n        self._data: Dict[str, Tuple[str, str]] = {}  # request_id -> (content, content_type)\n\n    def _generate_id(self, adapter_name: str, url: str) -> str:\n        \"\"\"Generates a consistent ID for a given adapter and URL.\"\"\"\n        return hashlib.sha256(f\"{adapter_name}:{url}\".encode()).hexdigest()[:16]\n\n    def register_failure(self, adapter_name: str, url: str) -> str:\n        \"\"\"\n        Registers a failed fetch attempt and returns a unique request ID.\n        If a pending request for this exact resource already exists, it returns the existing ID.\n        \"\"\"\n        request_id = self._generate_id(adapter_name, url)\n        if request_id not in self._requests or self._requests[request_id].status != \"pending\":\n            request = ManualOverrideRequest(request_id=request_id, adapter_name=adapter_name, url=url)\n            self._requests[request_id] = request\n        return request_id\n\n    def submit_manual_data(self, request_id: str, raw_content: str, content_type: str) -> bool:\n        \"\"\"Submits manual data for a pending request.\"\"\"\n        if request_id in self._requests and self._requests[request_id].status == \"pending\":\n            self._data[request_id] = (raw_content, content_type)\n            self._requests[request_id].status = \"submitted\"\n            return True\n        return False\n\n    def skip_request(self, request_id: str) -> bool:\n        \"\"\"Marks a pending request as skipped.\"\"\"\n        if request_id in self._requests and self._requests[request_id].status == \"pending\":\n            self._requests[request_id].status = \"skipped\"\n            return True\n        return False\n\n    def get_pending_requests(self) -> List[ManualOverrideRequest]:\n        \"\"\"Returns a list of all requests that are currently pending.\"\"\"\n        return [req for req in self._requests.values() if req.status == \"pending\"]\n\n    def get_manual_data(self, adapter_name: str, url: str) -> Optional[Tuple[str, str]]:\n        \"\"\"\n        Retrieves submitted manual data for a given adapter and URL, if it exists.\n        Once retrieved, the data is consumed and will not be returned again.\n        \"\"\"\n        request_id = self._generate_id(adapter_name, url)\n        if request_id in self._data:\n            # Data is single-use; remove it after retrieval.\n            return self._data.pop(request_id)\n        return None\n\n    def clear_old_requests(self, max_age_hours: int = 24):\n        \"\"\"Removes requests and associated data older than a specified age.\"\"\"\n        cutoff = datetime.now() - timedelta(hours=max_age_hours)\n        old_request_ids = [req_id for req_id, req in self._requests.items() if req.timestamp < cutoff]\n        for req_id in old_request_ids:\n            self._requests.pop(req_id, None)\n            self._data.pop(req_id, None)\n",
    "python_service/middleware/__init__.py": "",
    "python_service/middleware/error_handler.py": "# python_service/middleware/error_handler.py\n\nfrom fastapi import Request\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\n\nfrom ..user_friendly_errors import ERROR_MAP\n\n\nclass UserFriendlyException(Exception):\n    def __init__(self, error_key: str, status_code: int = 500, details: str = None):\n        self.error_key = error_key\n        self.status_code = status_code\n        self.details = details\n        error_info = ERROR_MAP.get(error_key, ERROR_MAP[\"default\"])\n        self.message = error_info[\"message\"]\n        self.suggestion = error_info[\"suggestion\"]\n        super().__init__(self.message)\n\n\nasync def user_friendly_exception_handler(request: Request, exc: UserFriendlyException):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"error\": {\n                \"message\": exc.message,\n                \"suggestion\": exc.suggestion,\n                \"details\": exc.details,\n            }\n        },\n    )\n\n\nasync def validation_exception_handler(request: Request, exc: RequestValidationError):\n    \"\"\"Convert Pydantic validation errors to user-friendly messages.\"\"\"\n    return JSONResponse(\n        status_code=422,\n        content={\n            \"detail\": \"Invalid request parameters\",\n            \"errors\": [\n                {\n                    \"field\": error[\"loc\"][-1] if error[\"loc\"] else \"unknown\",\n                    \"message\": error[\"msg\"],\n                    \"type\": error[\"type\"],\n                }\n                for error in exc.errors()\n            ],\n        },\n    )\n",
    "python_service/requirements.in": "#\n# Fortuna Faucet - High-Level Backend Dependencies\n# This is the source of truth. Run 'pip-compile' to generate requirements.txt.\n#\n\n# --- Core Application Framework (Hard Pins) ---\nfastapi\nuvicorn==0.30.1\ncryptography\n\n# --- Core Application Dependencies (Flexible) ---\ntenacity\npydantic-settings\nhttpx[http2]\nselectolax==0.4.0\nbeautifulsoup4\nslowapi\nredis\npandas\nnumpy\nscipy\naiosqlite\nSQLAlchemy\npsycopg2-binary\nstructlog\ncertifi\n\n# --- Desktop & OS Integration (Flexible) ---\npsutil\npywin32 ; sys_platform == 'win32'\nwindows-toasts ; sys_platform == 'win32'\nkeyring\npynput ; sys_platform == 'win32'\n\n# --- Development & Testing Dependencies ---\npytest\npytest-asyncio\nblack\n\n# --- Build Dependencies (Hard Pins) ---\n# THE FIX: Upgraded to 6.6.0 for official Python 3.12 support.\npyinstaller==6.6.0\nwheel\nsetuptools>=78.1.1,<81\npip-tools\nrequests>=2.32.4\nurllib3>=2.5.0\n",
    "python_service/tests/test_manual_override.py": "# python_service/tests/test_manual_override.py\nimport pytest\n\nfrom python_service.manual_override_manager import ManualOverrideManager\n\n\n@pytest.fixture\ndef manager():\n    # The manager is now in-memory and doesn't need a path\n    return ManualOverrideManager()\n\n\ndef test_register_and_retrieve(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n    content = \"<html>Manual content</html>\"\n    content_type = \"text/html\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    success = manager.submit_manual_data(\n        request_id=request_id,\n        raw_content=content,\n        content_type=content_type,\n    )\n\n    assert success\n\n    # Verify that the data can be retrieved correctly\n    retrieved_data = manager.get_manual_data(adapter_name=adapter, url=url)\n    assert retrieved_data is not None\n    retrieved_content, retrieved_type = retrieved_data\n    assert retrieved_content == content\n    assert retrieved_type == content_type\n\n    # Verify that data is consumed after retrieval\n    assert manager.get_manual_data(adapter_name=adapter, url=url) is None\n",
    "python_service/user_friendly_errors.py": "# python_service/user_friendly_errors.py\n\n\"\"\"\nCentralized dictionary for mapping technical exceptions to user-friendly messages.\n\"\"\"\n\nERROR_MAP = {\n    \"AdapterHttpError\": {\n        \"message\": \"A data source is currently unavailable.\",\n        \"suggestion\": (\n            \"This is usually temporary. Please try again in a few minutes. \"\n            \"If the problem persists, the website may be down for maintenance.\"\n        ),\n    },\n    \"AdapterConfigError\": {\n        \"message\": \"A data adapter is misconfigured.\",\n        \"suggestion\": \"Please check that all required API keys and settings are present in your .env file.\",\n    },\n    \"default\": {\n        \"message\": \"An unexpected error occurred.\",\n        \"suggestion\": \"Please check the application logs for more details or contact support.\",\n    },\n}\n",
    "python_service/utils/__init__.py": "",
    "requirements-dev.in": "#\n# Fortuna Faucet - High-Level Development & Testing Dependencies\n# This file is the source of truth for development dependencies.\n# Run 'pip-compile' to generate requirements-dev.txt.\n#\n\n# --- Core Testing Frameworks ---\npytest\npytest-asyncio\nfakeredis[lua]\nrespx\nplaywright\n\n# --- Code Quality & Linting ---\nblack\n# ruff is often used with black\n\n# --- Analysis & Notebooks ---\n# pandas is already in the main requirements.in\naltair\npydeck\nstreamlit\ntabula-py\n\n# --- Git & Versioning ---\nGitPython\n\n# --- Security & Auditing ---\npip-audit\n",
    "requirements-dev.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=requirements-dev.txt requirements-dev.in\n#\naltair==5.5.0\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\nanyio==4.11.0\n    # via httpx\nattrs==25.4.0\n    # via\n    #   jsonschema\n    #   referencing\nblack==25.11.0\n    # via -r requirements-dev.in\nblinker==1.9.0\n    # via streamlit\nboolean-py==5.0\n    # via license-expression\ncachecontrol[filecache]==0.14.3\n    # via\n    #   cachecontrol\n    #   pip-audit\ncachetools==6.2.1\n    # via streamlit\ncertifi==2023.7.22\n    # via\n    #   httpcore\n    #   httpx\n    #   requests\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.0\n    # via\n    #   black\n    #   streamlit\ncyclonedx-python-lib==9.1.0\n    # via pip-audit\ndefusedxml==0.7.1\n    # via py-serializable\ndistro==1.9.0\n    # via tabula-py\nfakeredis[lua]==2.23.0\n    # via -r requirements-dev.in\nfilelock==3.20.0\n    # via cachecontrol\ngitdb==4.0.12\n    # via gitpython\ngitpython==3.1.45\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\ngreenlet==3.2.4\n    # via playwright\nh11==0.16.0\n    # via httpcore\nhttpcore==1.0.9\n    # via httpx\nhttpx==0.28.1\n    # via respx\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njinja2==3.1.6\n    # via\n    #   altair\n    #   pydeck\njsonschema==4.25.1\n    # via altair\njsonschema-specifications==2025.9.1\n    # via jsonschema\nlicense-expression==30.4.4\n    # via cyclonedx-python-lib\nlupa==2.6\n    # via fakeredis\nmarkdown-it-py==4.0.0\n    # via rich\nmarkupsafe==3.0.3\n    # via jinja2\nmdurl==0.1.2\n    # via markdown-it-py\nmsgpack==1.1.2\n    # via cachecontrol\nmypy-extensions==1.1.0\n    # via black\nnarwhals==2.9.0\n    # via altair\nnumpy==2.3.4\n    # via\n    #   pandas\n    #   pydeck\n    #   streamlit\n    #   tabula-py\npackageurl-python==0.17.5\n    # via cyclonedx-python-lib\npackaging==25.0\n    # via\n    #   altair\n    #   black\n    #   pip-audit\n    #   pip-requirements-parser\n    #   pytest\n    #   streamlit\npandas==2.3.3\n    # via\n    #   streamlit\n    #   tabula-py\npathspec==0.12.1\n    # via black\npillow==11.3.0\n    # via streamlit\npip-api==0.0.34\n    # via pip-audit\npip-audit==2.9.0\n    # via -r requirements-dev.in\npip-requirements-parser==32.0.1\n    # via pip-audit\nplatformdirs==4.5.0\n    # via\n    #   black\n    #   pip-audit\nplaywright==1.55.0\n    # via -r requirements-dev.in\npluggy==1.6.0\n    # via pytest\nprotobuf==6.33.0\n    # via streamlit\npy-serializable==2.1.0\n    # via cyclonedx-python-lib\npyarrow==21.0.0\n    # via streamlit\npydeck==0.9.1\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\npyee==13.0.0\n    # via playwright\npygments==2.19.2\n    # via\n    #   pytest\n    #   rich\npyparsing==3.2.5\n    # via pip-requirements-parser\npytest==8.4.2\n    # via\n    #   -r requirements-dev.in\n    #   pytest-asyncio\npytest-asyncio==1.2.0\n    # via -r requirements-dev.in\npython-dateutil==2.9.0.post0\n    # via pandas\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==7.0.1\n    # via fakeredis\nreferencing==0.37.0\n    # via\n    #   jsonschema\n    #   jsonschema-specifications\nrequests==2.32.5\n    # via\n    #   cachecontrol\n    #   pip-audit\n    #   streamlit\nrespx==0.22.0\n    # via -r requirements-dev.in\nrich==14.2.0\n    # via pip-audit\nrpds-py==0.28.0\n    # via\n    #   jsonschema\n    #   referencing\nsix==1.17.0\n    # via python-dateutil\nsmmap==5.0.2\n    # via gitdb\nsniffio==1.3.1\n    # via anyio\nsortedcontainers==2.4.0\n    # via\n    #   cyclonedx-python-lib\n    #   fakeredis\nstreamlit==1.50.0\n    # via -r requirements-dev.in\ntabula-py==2.10.0\n    # via -r requirements-dev.in\ntenacity==8.2.3\n    # via streamlit\ntoml==0.10.2\n    # via\n    #   pip-audit\n    #   streamlit\ntornado==6.5.2\n    # via streamlit\ntyping-extensions==4.15.0\n    # via\n    #   altair\n    #   anyio\n    #   pyee\n    #   pytest-asyncio\n    #   referencing\n    #   streamlit\ntzdata==2025.2\n    # via pandas\nurllib3==2.5.0\n    # via requests\nwatchdog==6.0.0\n    # via streamlit\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools\n",
    "scripts/install_fortuna_gui.bat": "@echo off\nREM Interactive MSI installation with standard Windows UI\n\ntitle Fortuna Faucet Installation Wizard\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Administrator privileges required\n    echo Please right-click this file and select \"Run as Administrator\"\n    pause\n    exit /b 1\n)\n\nREM Assumes the MSI is in the 'dist' subfolder relative to the project root\nmsiexec.exe /i \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" /L*v \"%TEMP%\\fortuna_install.log\"\n\nif %errorlevel% equ 0 (\n    echo Installation completed successfully!\n    echo Access dashboard at: http://localhost:3000\n) else (\n    echo Installation failed. Log: %TEMP%\\fortuna_install.log\n)\npause",
    "setup.py": "# setup.py\nfrom setuptools import find_packages\nfrom setuptools import setup\n\nwith open(\"requirements.txt\") as f:\n    requirements = f.read().splitlines()\n\nsetup(\n    name=\"fortuna_engine\",\n    version=\"1.0.0\",\n    packages=find_packages(),\n    author=\"Jules\",\n    author_email=\"\",\n    description=\"The Python backend for the Fortuna Faucet application.\",\n    long_description=\"This package contains the FastAPI server and all related data adapters and analysis tools.\",\n    install_requires=requirements,\n    entry_points={\n        \"console_scripts\": [\n            \"fortuna-engine=python_service.run_api:main\",\n        ],\n    },\n    include_package_data=True,\n    package_data={\n        \"python_service\": [\"*.py\"],\n    },\n)\n",
    "tests/adapters/test_gbgb_api_adapter.py": "# tests/adapters/test_gbgb_api_adapter.py\n\nfrom datetime import date\nfrom decimal import Decimal\nfrom unittest.mock import AsyncMock\n\nimport pytest\n\nfrom python_service.adapters.gbgb_api_adapter import GbgbApiAdapter\nfrom tests.conftest import get_test_settings\n\n\n@pytest.fixture\ndef gbgb_adapter():\n    \"\"\"Returns a GbgbApiAdapter instance for testing.\"\"\"\n    return GbgbApiAdapter(config=get_test_settings())\n\n\n@pytest.mark.asyncio\nasync def test_get_gbgb_races_successfully(gbgb_adapter):\n    \"\"\"\n    SPEC: The GbgbApiAdapter should correctly parse a standard API response,\n    creating Race and Runner objects with the correct data, including fractional odds.\n    \"\"\"\n    # ARRANGE\n    mock_date = date.today().strftime(\"%Y-%m-%d\")\n    mock_api_response = [\n        {\n            \"trackName\": \"Towcester\",\n            \"races\": [\n                {\n                    \"raceId\": 12345,\n                    \"raceNumber\": 1,\n                    \"raceTime\": \"2025-10-09T18:00:00Z\",\n                    \"raceTitle\": \"The October Sprint\",\n                    \"raceDistance\": 500,\n                    \"traps\": [\n                        {\"trapNumber\": 1, \"dogName\": \"Rapid Rover\", \"sp\": \"5/2\"},\n                        {\"trapNumber\": 2, \"dogName\": \"Speedy Sue\", \"sp\": \"EVS\"},\n                        {\"trapNumber\": 3, \"dogName\": \"Lazy Larry\", \"sp\": \"10/1\"},\n                    ],\n                }\n            ],\n        }\n    ]\n    gbgb_adapter._fetch_data = AsyncMock(return_value=mock_api_response)\n\n    # ACT\n    races = [race async for race in gbgb_adapter.get_races(mock_date)]\n\n    # ASSERT\n    assert len(races) == 1\n    race = races[0]\n    assert race.venue == \"Towcester\"\n    assert race.race_number == 1\n    assert race.race_name == \"The October Sprint\"\n    assert race.distance == \"500m\"\n    assert len(race.runners) == 3\n\n    runner1 = next(r for r in race.runners if r.number == 1)\n    assert runner1.name == \"Rapid Rover\"\n    assert runner1.odds[\"GBGB\"].win == Decimal(\"3.5\")\n\n    runner2 = next(r for r in race.runners if r.number == 2)\n    assert runner2.name == \"Speedy Sue\"\n    assert runner2.odds[\"GBGB\"].win == Decimal(\"2.0\")\n\n    runner3 = next(r for r in race.runners if r.number == 3)\n    assert runner3.name == \"Lazy Larry\"\n    assert runner3.odds[\"GBGB\"].win == Decimal(\"11.0\")\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_fetch_failure(gbgb_adapter):\n    \"\"\"\n    Tests that get_races returns an empty list when _fetch_data returns None.\n    \"\"\"\n    # ARRANGE\n    mock_date = date.today().strftime(\"%Y-%m-%d\")\n    gbgb_adapter._fetch_data = AsyncMock(return_value=None)\n\n    # ACT\n    races = [race async for race in gbgb_adapter.get_races(mock_date)]\n\n    # ASSERT\n    assert races == []\n",
    "tests/adapters/test_greyhound_adapter.py": "from datetime import date\nfrom datetime import datetime\nfrom unittest.mock import AsyncMock\n\nimport pytest\n\nfrom python_service.adapters.greyhound_adapter import GreyhoundAdapter\nfrom tests.conftest import get_test_settings\n\n\n@pytest.fixture\ndef test_settings():\n    \"\"\"Provides a valid Settings object for testing.\"\"\"\n    return get_test_settings()\n\n\n@pytest.mark.asyncio\nasync def test_get_races_parses_correctly(test_settings):\n    \"\"\"\n    Tests that the GreyhoundAdapter correctly parses a valid API response via get_races.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n\n    mock_api_response = {\n        \"cards\": [\n            {\n                \"track_name\": \"Test Track\",\n                \"races\": [\n                    {\n                        \"race_id\": \"test_race_123\",\n                        \"race_number\": 1,\n                        \"start_time\": int(datetime.now().timestamp()),\n                        \"runners\": [\n                            {\n                                \"dog_name\": \"Rapid Rover\",\n                                \"trap_number\": 1,\n                                \"odds\": {\"win\": \"2.5\"},\n                            },\n                            {\n                                \"dog_name\": \"Swift Sprint\",\n                                \"trap_number\": 2,\n                                \"scratched\": True,\n                            },\n                            {\n                                \"dog_name\": \"Lazy Larry\",\n                                \"trap_number\": 3,\n                                \"odds\": {\"win\": \"10.0\"},\n                            },\n                        ],\n                    }\n                ],\n            }\n        ]\n    }\n    adapter._fetch_data = AsyncMock(return_value=mock_api_response)\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert len(races) == 1\n    race = races[0]\n    assert race.id == \"greyhound_test_race_123\"\n    assert race.venue == \"Test Track\"\n    assert len(race.runners) == 2  # One was scratched\n\n    runner1 = race.runners[0]\n    assert runner1.name == \"Rapid Rover\"\n    assert runner1.number == 1\n    assert runner1.odds[\"Greyhound Racing\"].win == 2.5\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_empty_response(test_settings):\n    \"\"\"\n    Tests that the GreyhoundAdapter handles an empty API response gracefully.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(return_value={\"cards\": []})\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert races == []\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_fetch_failure(test_settings):\n    \"\"\"\n    Tests that get_races returns an empty list when _fetch_data returns None.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(return_value=None)\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert races == []\n",
    "tests/fixtures/timeform_modern_sample.html": "<div class=\"rp-horseTable_mainRow\">\n  <a class=\"rp-horseTable_horse-name\">Braveheart</a>\n  <span class=\"rp-horseTable_horse-number\">(1)</span>\n  <button class=\"rp-bet-placer-btn__odds\">5/2</button>\n</div>\n<div class=\"rp-horseTable_mainRow\">\n  <a class=\"rp-horseTable_horse-name\">Speedster</a>\n  <span class=\"rp-horseTable_horse-number\">(2)</span>\n  <button class=\"rp-bet-placer-btn__odds\">10/1</button>\n</div>\n<div class=\"rp-horseTable_mainRow\">\n  <a class=\"rp-horseTable_horse-name\">Steady Eddy</a>\n  <span class=\"rp-horseTable_horse-number\">(3)</span>\n  <button class=\"rp-bet-placer-btn__odds\">EVENS</button>\n</div>\n",
    "tests/fixtures/twinspires_sample.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <title>Race Results - Twinspires</title>\n</head>\n<body>\n    <div id=\"race-card\">\n        <h1>Race 5 - Churchill Downs - 2025-10-26</h1>\n        <div class=\"race-details\">\n            <span class=\"post-time\">Post Time: 04:30 PM</span>\n            <span class=\"distance\">1 Mile</span>\n            <span class=\"surface\">Dirt</span>\n        </div>\n        <ul class=\"runners-list\">\n            <li class=\"runner\">\n                <span class=\"runner-number\">1</span>\n                <span class=\"runner-name\">Braveheart</span>\n                <span class=\"runner-odds\">5/2</span>\n            </li>\n            <li class=\"runner\">\n                <span class=\"runner-number\">2</span>\n                <span class=\"runner-name\">Speedster</span>\n                <span class=\"runner-odds\">10/1</span>\n            </li>\n            <li class=\"runner scratched\">\n                <span class=\"runner-number\">3</span>\n                <span class=\"runner-name\">Steady Eddy</span>\n                <span class=\"runner-odds\">SCR</span>\n            </li>\n             <li class=\"runner\">\n                <span class=\"runner-number\">4</span>\n                <span class=\"runner-name\">Gallant Gus</span>\n                <span class=\"runner-odds\">3/1</span>\n            </li>\n        </ul>\n    </div>\n</body>\n</html>\n",
    "tests/test_api.py": "# tests/test_api.py\nfrom datetime import date\nfrom datetime import datetime\nfrom unittest.mock import AsyncMock\nfrom unittest.mock import patch\n\nimport aiosqlite\nimport pytest\n\n# --- Fixtures ---\nfrom python_service.models import AggregatedResponse\n\n# The client fixture is now correctly sourced from conftest.py,\n# which handles the settings override globally.\n\n# --- API Tests ---\n\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine.fetch_all_odds\", new_callable=AsyncMock)\nasync def test_get_races_endpoint_success(mock_fetch_all_odds, client):\n    \"\"\"\n    SPEC: The /api/races endpoint should return data with a valid API key.\n    \"\"\"\n    # ARRANGE\n    today = date.today()\n    mock_response = AggregatedResponse(\n        date=today,\n        races=[],\n        sources=[],\n        metadata={},\n        # This was the missing field causing the validation error\n        source_info=[],\n    )\n    mock_fetch_all_odds.return_value = mock_response.model_dump()\n    headers = {\"X-API-Key\": \"a_secure_test_api_key_that_is_long_enough\"}\n\n    # ACT\n    response = client.get(f\"/api/races?race_date={today.isoformat()}\", headers=headers)\n\n    # ASSERT\n    assert response.status_code == 200\n    mock_fetch_all_odds.assert_awaited_once()\n\n\n@pytest.mark.asyncio\nasync def test_get_tipsheet_endpoint_success(tmp_path, client):\n    \"\"\"\n    SPEC: The /api/tipsheet endpoint should return a list of tipsheet races from the database.\n    \"\"\"\n    db_path = tmp_path / \"test.db\"\n    post_time = datetime.now()\n\n    with patch(\"python_service.api.DB_PATH\", db_path):\n        async with aiosqlite.connect(db_path) as db:\n            await db.execute(\n                \"\"\"\n                CREATE TABLE tipsheet (\n                    race_id TEXT PRIMARY KEY,\n                    track_name TEXT,\n                    race_number INTEGER,\n                    post_time TEXT,\n                    score REAL,\n                    factors TEXT\n                )\n            \"\"\"\n            )\n            await db.execute(\n                \"INSERT INTO tipsheet VALUES (?, ?, ?, ?, ?, ?)\",\n                (\"test_race_1\", \"Test Park\", 1, post_time.isoformat(), 85.5, \"{}\"),\n            )\n            await db.commit()\n\n        # ACT\n        response = client.get(f\"/api/tipsheet?date={post_time.date().isoformat()}\")\n\n        # ASSERT\n        assert response.status_code == 200\n        response_data = response.json()\n        assert len(response_data) == 1\n        # The database returns snake_case, but the Pydantic model is camelCase\n        assert response_data[0][\"raceId\"] == \"test_race_1\"\n        assert response_data[0][\"score\"] == 85.5\n\n\ndef test_health_check_unauthenticated(client):\n    \"\"\"Ensures the /health endpoint is accessible without an API key.\"\"\"\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    json_response = response.json()\n    assert json_response[\"status\"] == \"ok\"\n    assert \"timestamp\" in json_response\n\n\ndef test_api_key_authentication_failure(client):\n    \"\"\"Ensures that endpoints are protected and fail with an invalid API key.\"\"\"\n    response = client.get(\"/api/races/qualified/trifecta\", headers={\"X-API-KEY\": \"invalid_key\"})\n    assert response.status_code == 403\n    assert \"Invalid or missing API Key\" in response.json()[\"detail\"]\n\n\ndef test_api_key_authentication_missing(client):\n    \"\"\"Ensures that endpoints are protected and fail with a missing API key.\"\"\"\n    response = client.get(\"/api/races/qualified/trifecta\")\n    assert response.status_code == 403\n    assert \"Not authenticated\" in response.json()[\"detail\"]\n",
    "tests/test_models/test_validation.py": "import pytest\nfrom pydantic import ValidationError\n\nfrom python_service.models import Race\n\n\ndef test_race_model_valid_data():\n    \"\"\"Tests that the Race model can be created with valid data.\"\"\"\n    race_data = {\n        \"id\": \"test_race_123\",\n        \"venue\": \"Test Park\",\n        \"race_number\": 1,\n        \"start_time\": \"2025-10-20T12:00:00Z\",\n        \"runners\": [],\n        \"source\": \"test_source\",\n    }\n    race = Race(**race_data)\n    assert race.id == \"test_race_123\"\n    assert race.venue == \"Test Park\"\n\n\ndef test_race_model_invalid_data():\n    \"\"\"Tests that the Race model raises a ValidationError with invalid data.\"\"\"\n    invalid_race_data = {\n        \"id\": \"test_race_456\",\n        \"venue\": 12345,  # Invalid type\n        \"race_number\": \"two\",  # Invalid type\n        \"start_time\": \"not-a-date\",\n        \"runners\": \"not-a-list\",\n        \"source\": \"test_source\",\n    }\n    with pytest.raises(ValidationError):\n        Race(**invalid_race_data)\n",
    "web_platform/frontend/.gitignore": "# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.\n\n# Dependencies\n/node_modules\n/.pnp\n.pnp.js\n\n# Testing\n/coverage\n\n# Next.js\n/.next/\n/out/\n\n# Production\n/build\n\n# Misc\n.DS_Store\n*.pem\n\n# Local .env files\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n\n# Log files\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# Editor directories and files\n.vscode\n.idea\n*.suo\n*.ntvs*\n*.njsproj\n*.sln\n*.sw?",
    "web_platform/frontend/next.config.mjs": "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  output: 'export',  // Critical for static HTML export\n  distDir: 'out',\n  trailingSlash: true,\n  images: {\n    unoptimized: true  // Required for static export\n  },\n  async rewrites() {\n    return [\n      {\n        source: '/api/:path*',\n        destination: 'http://127.0.0.1:8000/api/:path*',\n      },\n    ]\n  },\n};\n\nexport default nextConfig;\n",
    "web_platform/frontend/public/manifest.json": "{\n  \"name\": \"Fortuna Faucet Command Deck\",\n  \"short_name\": \"Fortuna\",\n  \"description\": \"Real-time racing analysis.\",\n  \"start_url\": \"/\",\n  \"display\": \"standalone\",\n  \"background_color\": \"#1a202c\",\n  \"theme_color\": \"#1a202c\",\n  \"icons\": [\n    {\n      \"src\": \"/icons/icon-192x192.png\",\n      \"sizes\": \"192x192\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/icon-512x512.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\"\n    }\n  ]\n}\n",
    "web_platform/frontend/public/workbox-4754cb34.js": "define([\"exports\"],function(t){\"use strict\";try{self[\"workbox:core:6.5.4\"]&&_()}catch(t){}const e=(t,...e)=>{let s=t;return e.length>0&&(s+=` :: ${JSON.stringify(e)}`),s};class s extends Error{constructor(t,s){super(e(t,s)),this.name=t,this.details=s}}try{self[\"workbox:routing:6.5.4\"]&&_()}catch(t){}const n=t=>t&&\"object\"==typeof t?t:{handle:t};class r{constructor(t,e,s=\"GET\"){this.handler=n(e),this.match=t,this.method=s}setCatchHandler(t){this.catchHandler=n(t)}}class i extends r{constructor(t,e,s){super(({url:e})=>{const s=t.exec(e.href);if(s&&(e.origin===location.origin||0===s.index))return s.slice(1)},e,s)}}class a{constructor(){this.t=new Map,this.i=new Map}get routes(){return this.t}addFetchListener(){self.addEventListener(\"fetch\",t=>{const{request:e}=t,s=this.handleRequest({request:e,event:t});s&&t.respondWith(s)})}addCacheListener(){self.addEventListener(\"message\",t=>{if(t.data&&\"CACHE_URLS\"===t.data.type){const{payload:e}=t.data,s=Promise.all(e.urlsToCache.map(e=>{\"string\"==typeof e&&(e=[e]);const s=new Request(...e);return this.handleRequest({request:s,event:t})}));t.waitUntil(s),t.ports&&t.ports[0]&&s.then(()=>t.ports[0].postMessage(!0))}})}handleRequest({request:t,event:e}){const s=new URL(t.url,location.href);if(!s.protocol.startsWith(\"http\"))return;const n=s.origin===location.origin,{params:r,route:i}=this.findMatchingRoute({event:e,request:t,sameOrigin:n,url:s});let a=i&&i.handler;const o=t.method;if(!a&&this.i.has(o)&&(a=this.i.get(o)),!a)return;let c;try{c=a.handle({url:s,request:t,event:e,params:r})}catch(t){c=Promise.reject(t)}const h=i&&i.catchHandler;return c instanceof Promise&&(this.o||h)&&(c=c.catch(async n=>{if(h)try{return await h.handle({url:s,request:t,event:e,params:r})}catch(t){t instanceof Error&&(n=t)}if(this.o)return this.o.handle({url:s,request:t,event:e});throw n})),c}findMatchingRoute({url:t,sameOrigin:e,request:s,event:n}){const r=this.t.get(s.method)||[];for(const i of r){let r;const a=i.match({url:t,sameOrigin:e,request:s,event:n});if(a)return r=a,(Array.isArray(r)&&0===r.length||a.constructor===Object&&0===Object.keys(a).length||\"boolean\"==typeof a)&&(r=void 0),{route:i,params:r}}return{}}setDefaultHandler(t,e=\"GET\"){this.i.set(e,n(t))}setCatchHandler(t){this.o=n(t)}registerRoute(t){this.t.has(t.method)||this.t.set(t.method,[]),this.t.get(t.method).push(t)}unregisterRoute(t){if(!this.t.has(t.method))throw new s(\"unregister-route-but-not-found-with-method\",{method:t.method});const e=this.t.get(t.method).indexOf(t);if(!(e>-1))throw new s(\"unregister-route-route-not-registered\");this.t.get(t.method).splice(e,1)}}let o;const c=()=>(o||(o=new a,o.addFetchListener(),o.addCacheListener()),o);function h(t,e,n){let a;if(\"string\"==typeof t){const s=new URL(t,location.href);a=new r(({url:t})=>t.href===s.href,e,n)}else if(t instanceof RegExp)a=new i(t,e,n);else if(\"function\"==typeof t)a=new r(t,e,n);else{if(!(t instanceof r))throw new s(\"unsupported-route-type\",{moduleName:\"workbox-routing\",funcName:\"registerRoute\",paramName:\"capture\"});a=t}return c().registerRoute(a),a}try{self[\"workbox:strategies:6.5.4\"]&&_()}catch(t){}const u={cacheWillUpdate:async({response:t})=>200===t.status||0===t.status?t:null},l={googleAnalytics:\"googleAnalytics\",precache:\"precache-v2\",prefix:\"workbox\",runtime:\"runtime\",suffix:\"undefined\"!=typeof registration?registration.scope:\"\"},f=t=>[l.prefix,t,l.suffix].filter(t=>t&&t.length>0).join(\"-\"),w=t=>t||f(l.precache),d=t=>t||f(l.runtime);function p(t,e){const s=new URL(t);for(const t of e)s.searchParams.delete(t);return s.href}class y{constructor(){this.promise=new Promise((t,e)=>{this.resolve=t,this.reject=e})}}const g=new Set;function m(t){return\"string\"==typeof t?new Request(t):t}class v{constructor(t,e){this.h={},Object.assign(this,e),this.event=e.event,this.u=t,this.l=new y,this.p=[],this.m=[...t.plugins],this.v=new Map;for(const t of this.m)this.v.set(t,{});this.event.waitUntil(this.l.promise)}async fetch(t){const{event:e}=this;let n=m(t);if(\"navigate\"===n.mode&&e instanceof FetchEvent&&e.preloadResponse){const t=await e.preloadResponse;if(t)return t}const r=this.hasCallback(\"fetchDidFail\")?n.clone():null;try{for(const t of this.iterateCallbacks(\"requestWillFetch\"))n=await t({request:n.clone(),event:e})}catch(t){if(t instanceof Error)throw new s(\"plugin-error-request-will-fetch\",{thrownErrorMessage:t.message})}const i=n.clone();try{let t;t=await fetch(n,\"navigate\"===n.mode?void 0:this.u.fetchOptions);for(const s of this.iterateCallbacks(\"fetchDidSucceed\"))t=await s({event:e,request:i,response:t});return t}catch(t){throw r&&await this.runCallbacks(\"fetchDidFail\",{error:t,event:e,originalRequest:r.clone(),request:i.clone()}),t}}async fetchAndCachePut(t){const e=await this.fetch(t),s=e.clone();return this.waitUntil(this.cachePut(t,s)),e}async cacheMatch(t){const e=m(t);let s;const{cacheName:n,matchOptions:r}=this.u,i=await this.getCacheKey(e,\"read\"),a=Object.assign(Object.assign({},r),{cacheName:n});s=await caches.match(i,a);for(const t of this.iterateCallbacks(\"cachedResponseWillBeUsed\"))s=await t({cacheName:n,matchOptions:r,cachedResponse:s,request:i,event:this.event})||void 0;return s}async cachePut(t,e){const n=m(t);var r;await(r=0,new Promise(t=>setTimeout(t,r)));const i=await this.getCacheKey(n,\"write\");if(!e)throw new s(\"cache-put-with-no-response\",{url:(a=i.url,new URL(String(a),location.href).href.replace(new RegExp(`^${location.origin}`),\"\"))});var a;const o=await this.R(e);if(!o)return!1;const{cacheName:c,matchOptions:h}=this.u,u=await self.caches.open(c),l=this.hasCallback(\"cacheDidUpdate\"),f=l?await async function(t,e,s,n){const r=p(e.url,s);if(e.url===r)return t.match(e,n);const i=Object.assign(Object.assign({},n),{ignoreSearch:!0}),a=await t.keys(e,i);for(const e of a)if(r===p(e.url,s))return t.match(e,n)}(u,i.clone(),[\"__WB_REVISION__\"],h):null;try{await u.put(i,l?o.clone():o)}catch(t){if(t instanceof Error)throw\"QuotaExceededError\"===t.name&&await async function(){for(const t of g)await t()}(),t}for(const t of this.iterateCallbacks(\"cacheDidUpdate\"))await t({cacheName:c,oldResponse:f,newResponse:o.clone(),request:i,event:this.event});return!0}async getCacheKey(t,e){const s=`${t.url} | ${e}`;if(!this.h[s]){let n=t;for(const t of this.iterateCallbacks(\"cacheKeyWillBeUsed\"))n=m(await t({mode:e,request:n,event:this.event,params:this.params}));this.h[s]=n}return this.h[s]}hasCallback(t){for(const e of this.u.plugins)if(t in e)return!0;return!1}async runCallbacks(t,e){for(const s of this.iterateCallbacks(t))await s(e)}*iterateCallbacks(t){for(const e of this.u.plugins)if(\"function\"==typeof e[t]){const s=this.v.get(e),n=n=>{const r=Object.assign(Object.assign({},n),{state:s});return e[t](r)};yield n}}waitUntil(t){return this.p.push(t),t}async doneWaiting(){let t;for(;t=this.p.shift();)await t}destroy(){this.l.resolve(null)}async R(t){let e=t,s=!1;for(const t of this.iterateCallbacks(\"cacheWillUpdate\"))if(e=await t({request:this.request,response:e,event:this.event})||void 0,s=!0,!e)break;return s||e&&200!==e.status&&(e=void 0),e}}class R{constructor(t={}){this.cacheName=d(t.cacheName),this.plugins=t.plugins||[],this.fetchOptions=t.fetchOptions,this.matchOptions=t.matchOptions}handle(t){const[e]=this.handleAll(t);return e}handleAll(t){t instanceof FetchEvent&&(t={event:t,request:t.request});const e=t.event,s=\"string\"==typeof t.request?new Request(t.request):t.request,n=\"params\"in t?t.params:void 0,r=new v(this,{event:e,request:s,params:n}),i=this.q(r,s,e);return[i,this.D(i,r,s,e)]}async q(t,e,n){let r;await t.runCallbacks(\"handlerWillStart\",{event:n,request:e});try{if(r=await this.U(e,t),!r||\"error\"===r.type)throw new s(\"no-response\",{url:e.url})}catch(s){if(s instanceof Error)for(const i of t.iterateCallbacks(\"handlerDidError\"))if(r=await i({error:s,event:n,request:e}),r)break;if(!r)throw s}for(const s of t.iterateCallbacks(\"handlerWillRespond\"))r=await s({event:n,request:e,response:r});return r}async D(t,e,s,n){let r,i;try{r=await t}catch(i){}try{await e.runCallbacks(\"handlerDidRespond\",{event:n,request:s,response:r}),await e.doneWaiting()}catch(t){t instanceof Error&&(i=t)}if(await e.runCallbacks(\"handlerDidComplete\",{event:n,request:s,response:r,error:i}),e.destroy(),i)throw i}}function b(t){t.then(()=>{})}function q(){return q=Object.assign?Object.assign.bind():function(t){for(var e=1;e<arguments.length;e++){var s=arguments[e];for(var n in s)({}).hasOwnProperty.call(s,n)&&(t[n]=s[n])}return t},q.apply(null,arguments)}let D,U;const x=new WeakMap,L=new WeakMap,I=new WeakMap,C=new WeakMap,E=new WeakMap;let N={get(t,e,s){if(t instanceof IDBTransaction){if(\"done\"===e)return L.get(t);if(\"objectStoreNames\"===e)return t.objectStoreNames||I.get(t);if(\"store\"===e)return s.objectStoreNames[1]?void 0:s.objectStore(s.objectStoreNames[0])}return k(t[e])},set:(t,e,s)=>(t[e]=s,!0),has:(t,e)=>t instanceof IDBTransaction&&(\"done\"===e||\"store\"===e)||e in t};function O(t){return t!==IDBDatabase.prototype.transaction||\"objectStoreNames\"in IDBTransaction.prototype?(U||(U=[IDBCursor.prototype.advance,IDBCursor.prototype.continue,IDBCursor.prototype.continuePrimaryKey])).includes(t)?function(...e){return t.apply(B(this),e),k(x.get(this))}:function(...e){return k(t.apply(B(this),e))}:function(e,...s){const n=t.call(B(this),e,...s);return I.set(n,e.sort?e.sort():[e]),k(n)}}function T(t){return\"function\"==typeof t?O(t):(t instanceof IDBTransaction&&function(t){if(L.has(t))return;const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"complete\",r),t.removeEventListener(\"error\",i),t.removeEventListener(\"abort\",i)},r=()=>{e(),n()},i=()=>{s(t.error||new DOMException(\"AbortError\",\"AbortError\")),n()};t.addEventListener(\"complete\",r),t.addEventListener(\"error\",i),t.addEventListener(\"abort\",i)});L.set(t,e)}(t),e=t,(D||(D=[IDBDatabase,IDBObjectStore,IDBIndex,IDBCursor,IDBTransaction])).some(t=>e instanceof t)?new Proxy(t,N):t);var e}function k(t){if(t instanceof IDBRequest)return function(t){const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"success\",r),t.removeEventListener(\"error\",i)},r=()=>{e(k(t.result)),n()},i=()=>{s(t.error),n()};t.addEventListener(\"success\",r),t.addEventListener(\"error\",i)});return e.then(e=>{e instanceof IDBCursor&&x.set(e,t)}).catch(()=>{}),E.set(e,t),e}(t);if(C.has(t))return C.get(t);const e=T(t);return e!==t&&(C.set(t,e),E.set(e,t)),e}const B=t=>E.get(t);const P=[\"get\",\"getKey\",\"getAll\",\"getAllKeys\",\"count\"],M=[\"put\",\"add\",\"delete\",\"clear\"],W=new Map;function j(t,e){if(!(t instanceof IDBDatabase)||e in t||\"string\"!=typeof e)return;if(W.get(e))return W.get(e);const s=e.replace(/FromIndex$/,\"\"),n=e!==s,r=M.includes(s);if(!(s in(n?IDBIndex:IDBObjectStore).prototype)||!r&&!P.includes(s))return;const i=async function(t,...e){const i=this.transaction(t,r?\"readwrite\":\"readonly\");let a=i.store;return n&&(a=a.index(e.shift())),(await Promise.all([a[s](...e),r&&i.done]))[0]};return W.set(e,i),i}N=(t=>q({},t,{get:(e,s,n)=>j(e,s)||t.get(e,s,n),has:(e,s)=>!!j(e,s)||t.has(e,s)}))(N);try{self[\"workbox:expiration:6.5.4\"]&&_()}catch(t){}const S=\"cache-entries\",K=t=>{const e=new URL(t,location.href);return e.hash=\"\",e.href};class A{constructor(t){this._=null,this.L=t}I(t){const e=t.createObjectStore(S,{keyPath:\"id\"});e.createIndex(\"cacheName\",\"cacheName\",{unique:!1}),e.createIndex(\"timestamp\",\"timestamp\",{unique:!1})}C(t){this.I(t),this.L&&function(t,{blocked:e}={}){const s=indexedDB.deleteDatabase(t);e&&s.addEventListener(\"blocked\",t=>e(t.oldVersion,t)),k(s).then(()=>{})}(this.L)}async setTimestamp(t,e){const s={url:t=K(t),timestamp:e,cacheName:this.L,id:this.N(t)},n=(await this.getDb()).transaction(S,\"readwrite\",{durability:\"relaxed\"});await n.store.put(s),await n.done}async getTimestamp(t){const e=await this.getDb(),s=await e.get(S,this.N(t));return null==s?void 0:s.timestamp}async expireEntries(t,e){const s=await this.getDb();let n=await s.transaction(S).store.index(\"timestamp\").openCursor(null,\"prev\");const r=[];let i=0;for(;n;){const s=n.value;s.cacheName===this.L&&(t&&s.timestamp<t||e&&i>=e?r.push(n.value):i++),n=await n.continue()}const a=[];for(const t of r)await s.delete(S,t.id),a.push(t.url);return a}N(t){return this.L+\"|\"+K(t)}async getDb(){return this._||(this._=await function(t,e,{blocked:s,upgrade:n,blocking:r,terminated:i}={}){const a=indexedDB.open(t,e),o=k(a);return n&&a.addEventListener(\"upgradeneeded\",t=>{n(k(a.result),t.oldVersion,t.newVersion,k(a.transaction),t)}),s&&a.addEventListener(\"blocked\",t=>s(t.oldVersion,t.newVersion,t)),o.then(t=>{i&&t.addEventListener(\"close\",()=>i()),r&&t.addEventListener(\"versionchange\",t=>r(t.oldVersion,t.newVersion,t))}).catch(()=>{}),o}(\"workbox-expiration\",1,{upgrade:this.C.bind(this)})),this._}}class F{constructor(t,e={}){this.O=!1,this.T=!1,this.k=e.maxEntries,this.B=e.maxAgeSeconds,this.P=e.matchOptions,this.L=t,this.M=new A(t)}async expireEntries(){if(this.O)return void(this.T=!0);this.O=!0;const t=this.B?Date.now()-1e3*this.B:0,e=await this.M.expireEntries(t,this.k),s=await self.caches.open(this.L);for(const t of e)await s.delete(t,this.P);this.O=!1,this.T&&(this.T=!1,b(this.expireEntries()))}async updateTimestamp(t){await this.M.setTimestamp(t,Date.now())}async isURLExpired(t){if(this.B){const e=await this.M.getTimestamp(t),s=Date.now()-1e3*this.B;return void 0===e||e<s}return!1}async delete(){this.T=!1,await this.M.expireEntries(1/0)}}try{self[\"workbox:range-requests:6.5.4\"]&&_()}catch(t){}async function H(t,e){try{if(206===e.status)return e;const n=t.headers.get(\"range\");if(!n)throw new s(\"no-range-header\");const r=function(t){const e=t.trim().toLowerCase();if(!e.startsWith(\"bytes=\"))throw new s(\"unit-must-be-bytes\",{normalizedRangeHeader:e});if(e.includes(\",\"))throw new s(\"single-range-only\",{normalizedRangeHeader:e});const n=/(\\d*)-(\\d*)/.exec(e);if(!n||!n[1]&&!n[2])throw new s(\"invalid-range-values\",{normalizedRangeHeader:e});return{start:\"\"===n[1]?void 0:Number(n[1]),end:\"\"===n[2]?void 0:Number(n[2])}}(n),i=await e.blob(),a=function(t,e,n){const r=t.size;if(n&&n>r||e&&e<0)throw new s(\"range-not-satisfiable\",{size:r,end:n,start:e});let i,a;return void 0!==e&&void 0!==n?(i=e,a=n+1):void 0!==e&&void 0===n?(i=e,a=r):void 0!==n&&void 0===e&&(i=r-n,a=r),{start:i,end:a}}(i,r.start,r.end),o=i.slice(a.start,a.end),c=o.size,h=new Response(o,{status:206,statusText:\"Partial Content\",headers:e.headers});return h.headers.set(\"Content-Length\",String(c)),h.headers.set(\"Content-Range\",`bytes ${a.start}-${a.end-1}/${i.size}`),h}catch(t){return new Response(\"\",{status:416,statusText:\"Range Not Satisfiable\"})}}function $(t,e){const s=e();return t.waitUntil(s),s}try{self[\"workbox:precaching:6.5.4\"]&&_()}catch(t){}function z(t){if(!t)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(\"string\"==typeof t){const e=new URL(t,location.href);return{cacheKey:e.href,url:e.href}}const{revision:e,url:n}=t;if(!n)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(!e){const t=new URL(n,location.href);return{cacheKey:t.href,url:t.href}}const r=new URL(n,location.href),i=new URL(n,location.href);return r.searchParams.set(\"__WB_REVISION__\",e),{cacheKey:r.href,url:i.href}}class G{constructor(){this.updatedURLs=[],this.notUpdatedURLs=[],this.handlerWillStart=async({request:t,state:e})=>{e&&(e.originalRequest=t)},this.cachedResponseWillBeUsed=async({event:t,state:e,cachedResponse:s})=>{if(\"install\"===t.type&&e&&e.originalRequest&&e.originalRequest instanceof Request){const t=e.originalRequest.url;s?this.notUpdatedURLs.push(t):this.updatedURLs.push(t)}return s}}}class V{constructor({precacheController:t}){this.cacheKeyWillBeUsed=async({request:t,params:e})=>{const s=(null==e?void 0:e.cacheKey)||this.W.getCacheKeyForURL(t.url);return s?new Request(s,{headers:t.headers}):t},this.W=t}}let J,Q;async function X(t,e){let n=null;if(t.url){n=new URL(t.url).origin}if(n!==self.location.origin)throw new s(\"cross-origin-copy-response\",{origin:n});const r=t.clone(),i={headers:new Headers(r.headers),status:r.status,statusText:r.statusText},a=e?e(i):i,o=function(){if(void 0===J){const t=new Response(\"\");if(\"body\"in t)try{new Response(t.body),J=!0}catch(t){J=!1}J=!1}return J}()?r.body:await r.blob();return new Response(o,a)}class Y extends R{constructor(t={}){t.cacheName=w(t.cacheName),super(t),this.j=!1!==t.fallbackToNetwork,this.plugins.push(Y.copyRedirectedCacheableResponsesPlugin)}async U(t,e){const s=await e.cacheMatch(t);return s||(e.event&&\"install\"===e.event.type?await this.S(t,e):await this.K(t,e))}async K(t,e){let n;const r=e.params||{};if(!this.j)throw new s(\"missing-precache-entry\",{cacheName:this.cacheName,url:t.url});{const s=r.integrity,i=t.integrity,a=!i||i===s;n=await e.fetch(new Request(t,{integrity:\"no-cors\"!==t.mode?i||s:void 0})),s&&a&&\"no-cors\"!==t.mode&&(this.A(),await e.cachePut(t,n.clone()))}return n}async S(t,e){this.A();const n=await e.fetch(t);if(!await e.cachePut(t,n.clone()))throw new s(\"bad-precaching-response\",{url:t.url,status:n.status});return n}A(){let t=null,e=0;for(const[s,n]of this.plugins.entries())n!==Y.copyRedirectedCacheableResponsesPlugin&&(n===Y.defaultPrecacheCacheabilityPlugin&&(t=s),n.cacheWillUpdate&&e++);0===e?this.plugins.push(Y.defaultPrecacheCacheabilityPlugin):e>1&&null!==t&&this.plugins.splice(t,1)}}Y.defaultPrecacheCacheabilityPlugin={cacheWillUpdate:async({response:t})=>!t||t.status>=400?null:t},Y.copyRedirectedCacheableResponsesPlugin={cacheWillUpdate:async({response:t})=>t.redirected?await X(t):t};class Z{constructor({cacheName:t,plugins:e=[],fallbackToNetwork:s=!0}={}){this.F=new Map,this.H=new Map,this.$=new Map,this.u=new Y({cacheName:w(t),plugins:[...e,new V({precacheController:this})],fallbackToNetwork:s}),this.install=this.install.bind(this),this.activate=this.activate.bind(this)}get strategy(){return this.u}precache(t){this.addToCacheList(t),this.G||(self.addEventListener(\"install\",this.install),self.addEventListener(\"activate\",this.activate),this.G=!0)}addToCacheList(t){const e=[];for(const n of t){\"string\"==typeof n?e.push(n):n&&void 0===n.revision&&e.push(n.url);const{cacheKey:t,url:r}=z(n),i=\"string\"!=typeof n&&n.revision?\"reload\":\"default\";if(this.F.has(r)&&this.F.get(r)!==t)throw new s(\"add-to-cache-list-conflicting-entries\",{firstEntry:this.F.get(r),secondEntry:t});if(\"string\"!=typeof n&&n.integrity){if(this.$.has(t)&&this.$.get(t)!==n.integrity)throw new s(\"add-to-cache-list-conflicting-integrities\",{url:r});this.$.set(t,n.integrity)}if(this.F.set(r,t),this.H.set(r,i),e.length>0){const t=`Workbox is precaching URLs without revision info: ${e.join(\", \")}\\nThis is generally NOT safe. Learn more at https://bit.ly/wb-precache`;console.warn(t)}}}install(t){return $(t,async()=>{const e=new G;this.strategy.plugins.push(e);for(const[e,s]of this.F){const n=this.$.get(s),r=this.H.get(e),i=new Request(e,{integrity:n,cache:r,credentials:\"same-origin\"});await Promise.all(this.strategy.handleAll({params:{cacheKey:s},request:i,event:t}))}const{updatedURLs:s,notUpdatedURLs:n}=e;return{updatedURLs:s,notUpdatedURLs:n}})}activate(t){return $(t,async()=>{const t=await self.caches.open(this.strategy.cacheName),e=await t.keys(),s=new Set(this.F.values()),n=[];for(const r of e)s.has(r.url)||(await t.delete(r),n.push(r.url));return{deletedURLs:n}})}getURLsToCacheKeys(){return this.F}getCachedURLs(){return[...this.F.keys()]}getCacheKeyForURL(t){const e=new URL(t,location.href);return this.F.get(e.href)}getIntegrityForCacheKey(t){return this.$.get(t)}async matchPrecache(t){const e=t instanceof Request?t.url:t,s=this.getCacheKeyForURL(e);if(s){return(await self.caches.open(this.strategy.cacheName)).match(s)}}createHandlerBoundToURL(t){const e=this.getCacheKeyForURL(t);if(!e)throw new s(\"non-precached-url\",{url:t});return s=>(s.request=new Request(t),s.params=Object.assign({cacheKey:e},s.params),this.strategy.handle(s))}}const tt=()=>(Q||(Q=new Z),Q);class et extends r{constructor(t,e){super(({request:s})=>{const n=t.getURLsToCacheKeys();for(const r of function*(t,{ignoreURLParametersMatching:e=[/^utm_/,/^fbclid$/],directoryIndex:s=\"index.html\",cleanURLs:n=!0,urlManipulation:r}={}){const i=new URL(t,location.href);i.hash=\"\",yield i.href;const a=function(t,e=[]){for(const s of[...t.searchParams.keys()])e.some(t=>t.test(s))&&t.searchParams.delete(s);return t}(i,e);if(yield a.href,s&&a.pathname.endsWith(\"/\")){const t=new URL(a.href);t.pathname+=s,yield t.href}if(n){const t=new URL(a.href);t.pathname+=\".html\",yield t.href}if(r){const t=r({url:i});for(const e of t)yield e.href}}(s.url,e)){const e=n.get(r);if(e){return{cacheKey:e,integrity:t.getIntegrityForCacheKey(e)}}}},t.strategy)}}t.CacheFirst=class extends R{async U(t,e){let n,r=await e.cacheMatch(t);if(!r)try{r=await e.fetchAndCachePut(t)}catch(t){t instanceof Error&&(n=t)}if(!r)throw new s(\"no-response\",{url:t.url,error:n});return r}},t.ExpirationPlugin=class{constructor(t={}){this.cachedResponseWillBeUsed=async({event:t,request:e,cacheName:s,cachedResponse:n})=>{if(!n)return null;const r=this.V(n),i=this.J(s);b(i.expireEntries());const a=i.updateTimestamp(e.url);if(t)try{t.waitUntil(a)}catch(t){}return r?n:null},this.cacheDidUpdate=async({cacheName:t,request:e})=>{const s=this.J(t);await s.updateTimestamp(e.url),await s.expireEntries()},this.X=t,this.B=t.maxAgeSeconds,this.Y=new Map,t.purgeOnQuotaError&&function(t){g.add(t)}(()=>this.deleteCacheAndMetadata())}J(t){if(t===d())throw new s(\"expire-custom-caches-only\");let e=this.Y.get(t);return e||(e=new F(t,this.X),this.Y.set(t,e)),e}V(t){if(!this.B)return!0;const e=this.Z(t);if(null===e)return!0;return e>=Date.now()-1e3*this.B}Z(t){if(!t.headers.has(\"date\"))return null;const e=t.headers.get(\"date\"),s=new Date(e).getTime();return isNaN(s)?null:s}async deleteCacheAndMetadata(){for(const[t,e]of this.Y)await self.caches.delete(t),await e.delete();this.Y=new Map}},t.NetworkFirst=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u),this.tt=t.networkTimeoutSeconds||0}async U(t,e){const n=[],r=[];let i;if(this.tt){const{id:s,promise:a}=this.et({request:t,logs:n,handler:e});i=s,r.push(a)}const a=this.st({timeoutId:i,request:t,logs:n,handler:e});r.push(a);const o=await e.waitUntil((async()=>await e.waitUntil(Promise.race(r))||await a)());if(!o)throw new s(\"no-response\",{url:t.url});return o}et({request:t,logs:e,handler:s}){let n;return{promise:new Promise(e=>{n=setTimeout(async()=>{e(await s.cacheMatch(t))},1e3*this.tt)}),id:n}}async st({timeoutId:t,request:e,logs:s,handler:n}){let r,i;try{i=await n.fetchAndCachePut(e)}catch(t){t instanceof Error&&(r=t)}return t&&clearTimeout(t),!r&&i||(i=await n.cacheMatch(e)),i}},t.RangeRequestsPlugin=class{constructor(){this.cachedResponseWillBeUsed=async({request:t,cachedResponse:e})=>e&&t.headers.has(\"range\")?await H(t,e):e}},t.StaleWhileRevalidate=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u)}async U(t,e){const n=e.fetchAndCachePut(t).catch(()=>{});e.waitUntil(n);let r,i=await e.cacheMatch(t);if(i);else try{i=await n}catch(t){t instanceof Error&&(r=t)}if(!i)throw new s(\"no-response\",{url:t.url,error:r});return i}},t.cleanupOutdatedCaches=function(){self.addEventListener(\"activate\",t=>{const e=w();t.waitUntil((async(t,e=\"-precache-\")=>{const s=(await self.caches.keys()).filter(s=>s.includes(e)&&s.includes(self.registration.scope)&&s!==t);return await Promise.all(s.map(t=>self.caches.delete(t))),s})(e).then(t=>{}))})},t.clientsClaim=function(){self.addEventListener(\"activate\",()=>self.clients.claim())},t.precacheAndRoute=function(t,e){!function(t){tt().precache(t)}(t),function(t){const e=tt();h(new et(e,t))}(e)},t.registerRoute=h});\n",
    "web_platform/frontend/src/components/EmptyState.tsx": "// web_platform/frontend/src/components/EmptyState.tsx\nimport React from 'react';\n\ninterface EmptyStateProps {\n  title: string;\n  message: string;\n  actionButton?: React.ReactNode;\n}\n\nexport const EmptyState: React.FC<EmptyStateProps> = ({ title, message, actionButton }) => {\n  return (\n    <div className=\"text-center p-8 bg-gray-800/50 border border-gray-700 rounded-lg mt-8\">\n      <svg\n        className=\"mx-auto h-12 w-12 text-gray-500\"\n        fill=\"none\"\n        viewBox=\"0 0 24 24\"\n        stroke=\"currentColor\"\n        aria-hidden=\"true\"\n      >\n        <path\n          vectorEffect=\"non-scaling-stroke\"\n          strokeLinecap=\"round\"\n          strokeLinejoin=\"round\"\n          strokeWidth={2}\n          d=\"M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z\"\n        />\n      </svg>\n      <h3 className=\"mt-2 text-xl font-semibold text-white\">{title}</h3>\n      <p className=\"mt-1 text-md text-gray-400\">\n        {message}\n      </p>\n      {actionButton && <div className=\"mt-6\">{actionButton}</div>}\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/ErrorDisplay.tsx": "// web_platform/frontend/src/components/ErrorDisplay.tsx\n'use client';\n\nimport React from 'react';\n\ninterface ErrorInfo {\n  message: string;\n  suggestion: string;\n  details?: string;\n}\n\ninterface ErrorDisplayProps {\n  error: ErrorInfo;\n}\n\nexport const ErrorDisplay: React.FC<ErrorDisplayProps> = ({ error }) => {\n  return (\n    <div className=\"bg-red-900/20 border border-red-500/30 text-white rounded-lg p-6 max-w-2xl mx-auto my-8\">\n      <div className=\"flex items-center mb-4\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-8 w-8 text-red-400 mr-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n          <path fillRule=\"evenodd\" d=\"M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z\" clipRule=\"evenodd\" />\n        </svg>\n        <h2 className=\"text-2xl font-bold text-red-400\">An Error Occurred</h2>\n      </div>\n      <p className=\"text-lg text-slate-300 mb-2\">{error.message}</p>\n      <p className=\"text-slate-400 mb-6\">{error.suggestion}</p>\n      {error.details && (\n        <details className=\"bg-slate-800/50 rounded-lg p-4\">\n          <summary className=\"cursor-pointer text-sm text-slate-500 hover:text-white\">\n            Technical Details\n          </summary>\n          <pre className=\"text-xs text-slate-400 mt-2 p-2 bg-black/30 rounded overflow-x-auto\">\n            <code>{error.details}</code>\n          </pre>\n        </details>\n      )}\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/LiveRaceDashboardNoSSR.tsx": "// web_platform/frontend/src/components/LiveRaceDashboardNoSSR.tsx\nimport dynamic from 'next/dynamic';\n\nconst LiveRaceDashboardNoSSR = dynamic(\n  () => import('./LiveRaceDashboard').then((mod) => mod.LiveRaceDashboard),\n  { ssr: false }\n);\n\nexport default LiveRaceDashboardNoSSR;\n",
    "web_platform/frontend/src/components/RaceFilters.tsx": "// web_platform/frontend/src/components/RaceFilters.tsx\n'use client';\n\nimport { useState, useCallback } from 'react';\nimport { Settings, RotateCcw } from 'lucide-react';\n\ninterface FilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nexport interface RaceFiltersProps {\n  onParamsChange: (params: FilterParams) => void;\n  isLoading: boolean;\n  refetch: () => void;\n}\n\nconst DEFAULT_PARAMS: FilterParams = {\n  maxFieldSize: 10,\n  minFavoriteOdds: 2.5,\n  minSecondFavoriteOdds: 4.0,\n};\n\nexport function RaceFilters({ onParamsChange, isLoading, refetch }: RaceFiltersProps) {\n  const [params, setParams] = useState<FilterParams>(DEFAULT_PARAMS);\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // Handle individual parameter changes\n  const handleChange = useCallback((key: keyof FilterParams, value: number) => {\n    setParams(prev => {\n      const updated = { ...prev, [key]: value };\n      onParamsChange(updated);\n      return updated;\n    });\n    // Debounce the refetch call\n    const timer = setTimeout(() => {\n      refetch();\n    }, 500);\n    return () => clearTimeout(timer);\n  }, [onParamsChange, refetch]);\n\n  // Reset to defaults\n  const handleReset = useCallback(() => {\n    setParams(DEFAULT_PARAMS);\n    onParamsChange(DEFAULT_PARAMS);\n    refetch();\n  }, [onParamsChange, refetch]);\n\n  return (\n    <div className=\"bg-gradient-to-r from-slate-800 to-slate-900 rounded-lg p-4 mb-6 border border-slate-700\">\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-2\">\n          <Settings className=\"w-5 h-5 text-amber-500\" />\n          <h3 className=\"text-lg font-semibold text-white\">Race Filters</h3>\n        </div>\n        <button\n          onClick={() => setIsExpanded(!isExpanded)}\n          className=\"text-sm text-slate-400 hover:text-slate-200 transition\"\n        >\n          {isExpanded ? 'Hide' : 'Show'}\n        </button>\n      </div>\n\n      {isExpanded && (\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 pt-4 border-t border-slate-700\">\n          {/* Max Field Size */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Max Field Size\n              <span className=\"text-amber-500 ml-2\">{params.maxFieldSize}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2\"\n              max=\"20\"\n              value={params.maxFieldSize}\n              onChange={(e) => handleChange('maxFieldSize', parseInt(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Filters races with larger fields</p>\n          </div>\n\n          {/* Min Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"1.5\"\n              max=\"5\"\n              step=\"0.1\"\n              value={params.minFavoriteOdds}\n              onChange={(e) => handleChange('minFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = pickier favorites</p>\n          </div>\n\n          {/* Min Second Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min 2nd Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minSecondFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2.0\"\n              max=\"8\"\n              step=\"0.1\"\n              value={params.minSecondFavoriteOdds}\n              onChange={(e) => handleChange('minSecondFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = better odds separation</p>\n          </div>\n\n          {/* Reset Button */}\n          <div className=\"md:col-span-3 flex justify-end pt-4 border-t border-slate-700\">\n            <button\n              onClick={handleReset}\n              disabled={isLoading}\n              className=\"inline-flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-600 text-slate-200 rounded text-sm font-medium transition disabled:opacity-50\"\n            >\n              <RotateCcw className=\"w-4 h-4\" />\n              Reset to Defaults\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/components/SettingsPage.tsx": "// src/components/SettingsPage.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\n\nexport function SettingsPage() {\n  const [apiKey, setApiKey] = useState('');\n  const [betfairAppKey, setBetfairAppKey] = useState('');\n  const [betfairUsername, setBetfairUsername] = useState('');\n  const [betfairPassword, setBetfairPassword] = useState('');\n\n  useEffect(() => {\n    // Fetch the current API key when the component mounts\n    const fetchApiKey = async () => {\n      if (window.electronAPI?.getApiKey) {\n        const key = await window.electronAPI.getApiKey();\n        if (key) {\n          setApiKey(key);\n        }\n      }\n    };\n    fetchApiKey();\n  }, []);\n\n  const handleGenerateApiKey = async () => {\n    if (window.electronAPI?.generateApiKey) {\n      const newKey = await window.electronAPI.generateApiKey();\n      setApiKey(newKey);\n    }\n  };\n\n  const handleSaveSettings = async () => {\n    if (window.electronAPI?.saveApiKey && window.electronAPI?.saveBetfairCredentials) {\n      await window.electronAPI.saveApiKey(apiKey);\n      await window.electronAPI.saveBetfairCredentials({\n        appKey: betfairAppKey,\n        username: betfairUsername,\n        password: betfairPassword,\n      });\n      alert('Settings saved successfully!');\n    }\n  };\n\n  return (\n    <div className=\"bg-slate-800 p-8 rounded-lg border border-slate-700 text-white max-w-2xl mx-auto\">\n      <h2 className=\"text-3xl font-bold text-white mb-6\">Application Settings</h2>\n\n      <div className=\"space-y-8\">\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">API Key</h3>\n          <p className=\"text-sm text-slate-400 mb-3\">This key is required for the dashboard to communicate with the backend service.</p>\n          <div className=\"flex items-center space-x-2\">\n            <input\n              type=\"text\"\n              readOnly\n              value={apiKey}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 font-mono text-sm\"\n            />\n            <button\n              onClick={handleGenerateApiKey}\n              className=\"px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded transition-colors font-semibold\"\n            >\n              Generate New Key\n            </button>\n          </div>\n        </div>\n\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">Betfair Credentials (Optional)</h3>\n           <p className=\"text-sm text-slate-400 mb-3\">Required for adapters that use the Betfair Exchange API.</p>\n          <div className=\"space-y-3\">\n            <input\n              type=\"password\"\n              placeholder=\"App Key\"\n              value={betfairAppKey}\n              onChange={(e) => setBetfairAppKey(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"text\"\n              placeholder=\"Username\"\n              value={betfairUsername}\n              onChange={(e) => setBetfairUsername(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"password\"\n              placeholder=\"Password\"\n              value={betfairPassword}\n              onChange={(e) => setBetfairPassword(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n          </div>\n        </div>\n\n        <div className=\"flex justify-end pt-6 border-t border-slate-700\">\n          <button\n            onClick={handleSaveSettings}\n            className=\"px-8 py-3 bg-green-600 hover:bg-green-700 rounded font-bold text-lg transition-colors\"\n          >\n            Save All Settings\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/lib/queryClient.ts": "// web_platform/frontend/src/lib/queryClient.ts\nimport { QueryClient } from '@tanstack/react-query';\n\nexport const queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      retry: 3,\n      staleTime: 1000 * 60 * 5, // 5 minutes\n    },\n  },\n});\n",
    "windows_service.py": "# windows_service.py\nimport os\nimport socket\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nimport servicemanager\nimport win32event\nimport win32service\nimport win32serviceutil\n\n\nclass FortunaBackendService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaFaucetBackend\"\n    _svc_display_name_ = \"Fortuna Faucet Racing Analysis Service\"\n    _svc_description_ = \"Background service for continuous racing data monitoring.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.stop_event = win32event.CreateEvent(None, 0, 0, None)\n        self.backend_process = None\n        socket.setdefaulttimeout(60)\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        win32event.SetEvent(self.stop_event)\n        if self.backend_process:\n            self.backend_process.terminate()\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(\n            servicemanager.EVENTLOG_INFORMATION_TYPE,\n            servicemanager.PYS_SERVICE_STARTED,\n            (self._svc_name_, \"\"),\n        )\n        self.main()\n\n    def main(self):\n        install_dir = Path(__file__).parent.resolve()\n        venv_python = install_dir / \".venv\" / \"Scripts\" / \"python.exe\"\n        api_module_dir = install_dir / \"python_service\"\n\n        env = os.environ.copy()\n        env_file = install_dir / \".env\"\n        if env_file.exists():\n            with open(env_file) as f:\n                for line in f:\n                    if \"=\" in line and not line.startswith(\"#\"):\n                        key, value = line.strip().split(\"=\", 1)\n                        env[key] = value.strip('\"')\n\n        self.backend_process = subprocess.Popen(\n            [\n                str(venv_python),\n                \"-m\",\n                \"uvicorn\",\n                \"api:app\",\n                \"--host\",\n                \"127.0.0.1\",\n                \"--port\",\n                \"8000\",\n            ],\n            cwd=str(api_module_dir),\n            env=env,\n        )\n\n        win32event.WaitForSingleObject(self.stop_event, win32event.INFINITE)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaBackendService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaBackendService)\n",
    "wix/WixUI_CustomInstallDir.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:WixUI=\"http://schemas.microsoft.com/wix/WixUIExtension\">\n  <Fragment>\n    <UI Id=\"WixUI_CustomInstallDir\">\n        <DialogRef Id=\"BrowseDlg\" />\n        <DialogRef Id=\"DiskCostDlg\" />\n        <DialogRef Id=\"ErrorDlg\" />\n        <DialogRef Id=\"FatalError\" />\n        <DialogRef Id=\"FilesInUse\" />\n        <DialogRef Id=\"MsiRMFilesInUse\" />\n        <DialogRef Id=\"PrepareDlg\" />\n        <DialogRef Id=\"UserExit\" />\n        <DialogRef Id=\"WelcomeDlg\" />\n        <DialogRef Id=\"InstallDirDlg\" />\n        <DialogRef Id=\"VerifyReadyDlg\" />\n\n        <!-- Use our custom progress dialog instead of the default -->\n        <DialogRef Id=\"InstallProgressDlg\" />\n\n        <Publish Dialog=\"WelcomeDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"InstallDirDlg\">1</Publish>\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"WelcomeDlg\">1</Publish>\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Next\" Event=\"SetTargetPath\" Value=\"[WIXUI_INSTALLDIR]\" Order=\"1\" />\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"VerifyReadyDlg\" Order=\"2\">1</Publish>\n        <Publish Dialog=\"VerifyReadyDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"InstallDirDlg\" Order=\"1\">NOT Installed</Publish>\n        <Publish Dialog=\"VerifyReadyDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"MaintenanceTypeDlg\" Order=\"2\">Installed</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n",
    "wix/WixUI_CustomProgress.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\">\n  <Fragment>\n    <UI>\n      <!-- Override the default InstallProgress dialog -->\n      <Dialog Id=\"InstallProgressDlg\" Width=\"370\" Height=\"270\" Title=\"Fortuna Faucet Installation\" Modeless=\"yes\">\n        <Control Id=\"Title\" Type=\"Title\" X=\"20\" Y=\"6\" Width=\"330\" Height=\"18\" Text=\"Installation Progress\" />\n        <Control Id=\"BannerBitmap\" Type=\"Bitmap\" X=\"0\" Y=\"0\" Width=\"370\" Height=\"44\" TabSkip=\"no\" Text=\"WixUI_Bmp_Banner\" />\n        <Control Id=\"Back\" Type=\"PushButton\" X=\"180\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Back\" Disabled=\"yes\" />\n        <Control Id=\"Next\" Type=\"PushButton\" X=\"236\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Next\" Disabled=\"yes\" />\n        <Control Id=\"Cancel\" Type=\"PushButton\" X=\"304\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"Cancel\" />\n\n        <Control Id=\"ActionText\" Type=\"Text\" X=\"70\" Y=\"80\" Width=\"280\" Height=\"20\" TabSkip=\"no\">\n          <Subscribe Event=\"ActionText\" Attribute=\"Text\" />\n        </Control>\n        <Control Id=\"Description\" Type=\"Text\" X=\"35\" Y=\"55\" Width=\"300\" Height=\"20\" Text=\"Please wait while the installer copies files.\" />\n\n        <!-- This is the new control to display the current filename -->\n        <Control Id=\"CurrentFileText\" Type=\"Text\" X=\"70\" Y=\"100\" Width=\"280\" Height=\"20\">\n            <Subscribe Event=\"SetProgress\" Attribute=\"Text\" />\n        </Control>\n\n        <Control Id=\"ProgressBar\" Type=\"ProgressBar\" X=\"35\" Y=\"120\" Width=\"300\" Height=\"10\" ProgressBlocks=\"yes\" Text=\"Progress\">\n          <Subscribe Event=\"SetProgress\" Attribute=\"Progress\" />\n        </Control>\n      </Dialog>\n\n      <!-- The Publish element must be a child of UI, not Dialog -->\n      <Publish Dialog=\"InstallProgressDlg\" Control=\"Cancel\" Event=\"SpawnDialog\" Value=\"CancelDlg\">1</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n"
}