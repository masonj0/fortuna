{
    ".github/dependabot.yml": "# System Timestamp: 2025-11-29 13:19:26.933797\n# To get started with Dependabot version updates, you'll need to specify which\n# package ecosystems to update and where the package manifests are located.\n# Please see the documentation for all configuration options:\n# https://docs.github.com/github/administering-a-repository/configuration-options-for-dependency-updates\n\nversion: 2\nupdates:\n  - package-ecosystem: \"pip\" # See documentation for possible values\n    directory: \"/\" # Location of package manifests\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/web_service/frontend\"\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/electron\"\n    schedule:\n      interval: \"daily\"\n",
    ".github/workflows/build-docker-tinyfield.yml": "name: Build & Test TinyField Docker Image\n\non:\n  push:\n    branches: [ main ]\n  workflow_dispatch:\n\njobs:\n  build-and-test:\n    name: 'Build, Test, and Publish TinyField Docker Image'\n    runs-on: ubuntu-latest\n    env:\n      IMAGE_NAME: fortuna-tinyfield\n\n    steps:\n      - name: \ud83d\udce5 Checkout Code\n        uses: actions/checkout@v4\n\n      - name: \ud83d\udc33 Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: \ud83d\udd28 Build Docker Image\n        run: |\n          echo \"Building Docker image...\"\n          docker buildx build \\\n            -f Dockerfile.tinyfield \\\n            -t ${{ env.IMAGE_NAME }}:latest \\\n            -t ${{ env.IMAGE_NAME }}:${{ github.run_number }} \\\n            --load \\\n            .\n          echo \"\u2705 Image built successfully\"\n\n      - name: \u2714\ufe0f Verify Image Created\n        run: |\n          echo \"Verifying image exists...\"\n          docker images | grep ${{ env.IMAGE_NAME }}\n          docker inspect ${{ env.IMAGE_NAME }}:latest > /dev/null || exit 1\n          echo \"\u2705 Image verification passed\"\n\n      - name: \ud83d\ude80 Start Container and Wait for Health\n        id: container\n        timeout-minutes: 5\n        run: |\n          echo \"Starting container...\"\n          CONTAINER_ID=$(docker run -d -p 8000:8000 ${{ env.IMAGE_NAME }}:latest)\n          echo \"container_id=$CONTAINER_ID\" >> $GITHUB_OUTPUT\n          echo \"Container started with ID: $CONTAINER_ID\"\n\n          # Wait for container to be ready\n          sleep 3\n\n          MAX_ATTEMPTS=60\n          ATTEMPT=0\n          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do\n            HTTP_CODE=$(curl -s -o /dev/null -w \"%{http_code}\" http://localhost:8000/api/health 2>/dev/null || echo \"000\")\n            echo \"Attempt $((ATTEMPT+1))/$MAX_ATTEMPTS - HTTP Status: $HTTP_CODE\"\n            if [ \"$HTTP_CODE\" = \"200\" ]; then\n              echo \"\u2705 Container is responding\"\n              break\n            fi\n            sleep 1\n            ATTEMPT=$((ATTEMPT+1))\n          done\n\n          if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then\n            echo \"\u274c Container failed to respond within timeout\"\n            docker logs $CONTAINER_ID || true\n            docker stop $CONTAINER_ID || true\n            exit 1\n          fi\n\n      - name: \ud83e\uddea Test /api/health Endpoint\n        run: |\n          echo \"Testing health endpoint...\"\n          curl -f http://localhost:8000/api/health || { echo \"Health check failed\"; exit 1; }\n          echo \"\u2705 Health endpoint working\"\n\n      - name: \ud83e\uddea Test /api/races/qualified/tiny_field_trifecta Endpoint\n        run: |\n          echo \"Testing races endpoint...\"\n          RESPONSE=$(curl -s http://localhost:8000/api/races/qualified/tiny_field_trifecta)\n          echo \"Response: $RESPONSE\"\n          echo \"$RESPONSE\" | jq . || { echo \"Invalid JSON response\"; exit 1; }\n          echo \"\u2705 Races endpoint working\"\n\n      - name: \ud83e\uddea Test Frontend Load\n        run: |\n          echo \"Testing frontend HTML...\"\n          curl -s http://localhost:8000/ | grep -q \"Fortuna TinyField\" || { echo \"Frontend not serving\"; exit 1; }\n          echo \"\u2705 Frontend HTML loaded successfully\"\n\n      - name: \ud83d\udccb Collect Container Logs\n        if: always()\n        run: |\n          echo \"=== CONTAINER LOGS ===\" > container-logs.txt\n          docker logs ${{ steps.container.outputs.container_id }} >> container-logs.txt 2>&1\n          cat container-logs.txt\n\n      - name: \ud83e\uddf9 Cleanup Container\n        if: always()\n        run: |\n          docker stop ${{ steps.container.outputs.container_id }} || true\n          docker rm ${{ steps.container.outputs.container_id }} || true\n          echo \"\u2705 Cleanup complete\"\n\n      - name: \ud83d\udce6 Upload Container Logs\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: docker-container-logs-${{ github.run_number }}\n          path: container-logs.txt\n          retention-days: 7\n\n      # OPTIONAL: Uncomment below to push to registry\n      # - name: \ud83d\ude80 Push to Docker Registry\n      #   if: success()\n      #   uses: docker/build-push-action@v5\n      #   with:\n      #     context: .\n      #     file: ./Dockerfile.tinyfield\n      #     push: true\n      #     tags: |\n      #       ghcr.io/${{ github.repository }}/fortuna-tinyfield:latest\n      #       ghcr.io/${{ github.repository }}/fortuna-tinyfield:${{ github.run_number }}\n      #     registry: ghcr.io\n      #     username: ${{ github.actor }}\n      #     password: ${{ secrets.GITHUB_TOKEN }}\n",
    ".github/workflows/test-quickstart-tinyfield.yml": "name: \ud83e\uddea Backend CI & Quick-Start Test (Tiny Field)\n\non:\n  push:\n    branches: [ main ]\n  workflow_dispatch:\n\njobs:\n  test-bootstrapper:\n    name: '\ud83c\udfc3 Run Quick-Start PS1 (Tiny Field)'\n    runs-on: windows-latest\n    env:\n      CI: true\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: \ud83d\udc0d Setup Python\n        id: setup-python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n\n      - name: \ud83d\udfe2 Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n          cache-dependency-path: web_service/frontend/package-lock.json\n\n      - name: \ud83d\udce6 Install Python Dependencies\n        shell: pwsh\n        run: |\n          pip install --upgrade pip\n          pip install -r web_service/backend/requirements.txt\n          pip install -r web_service/backend/requirements-dev.txt\n\n      - name: \ud83c\udfa8 Build Frontend\n        working-directory: web_service/frontend\n        run: |\n          npm ci\n          npm run build\n\n      - name: \ud83e\uddea Run Backend Unit Tests\n        shell: pwsh\n        run: |\n          $env:PYTHONPATH = \"$env:PYTHONPATH;${env:GITHUB_WORKSPACE}/web_service/backend\"\n          python -m pytest web_service/backend/tests/\n\n      - name: \ud83d\udd0d Syntax Validation\n        shell: pwsh\n        run: |\n          try {\n            $script = Get-Content \"scripts/fortuna-quick-start-tinyfield.ps1\" -Raw\n            [void][System.Management.Automation.PSParser]::Tokenize($script, [ref]$null)\n            Write-Host \"\u2705 PowerShell Syntax is valid.\"\n          } catch {\n            Write-Error \"\u274c Syntax Error: $_\"\n            exit 1\n          }\n\n      - name: \ud83d\ude80 Launch, Test, & Verify Backend\n        shell: pwsh\n        run: |\n          $process = $null\n          try {\n              # Start the server\n              Write-Host \"Starting backend server...\"\n              $process = Start-Process \"${{ steps.setup-python.outputs.python-path }}\" -ArgumentList \"-m uvicorn web_service.backend.main:app --host 127.0.0.1 --port 8000\" -PassThru -NoNewWindow\n\n              # Health Check Loop\n              $url = \"http://127.0.0.1:8000/api/health\"\n              Write-Host \"\u23f3 Waiting for Backend at $url...\"\n              $healthy = $false\n              for ($i=0; $i -lt 30; $i++) {\n                  try {\n                      $resp = Invoke-WebRequest -Uri $url -UseBasicParsing -TimeoutSec 2\n                      if ($resp.StatusCode -eq 200) {\n                          Write-Host \"\u2705 Backend is UP and responding!\"\n                          $healthy = $true\n                          break\n                      }\n                  } catch {\n                      Write-Host \"... ping failed, retrying ($($i+1)/30)\"\n                      Start-Sleep -Seconds 2\n                  }\n              }\n\n              if (-not $healthy) {\n                  throw \"Backend failed to start within timeout.\"\n              }\n\n              # If healthy, run optional verification scripts\n              Write-Host \"Backend is healthy. Running verification scripts...\"\n              try {\n                  Write-Host \"Installing Playwright...\"\n                  pip install playwright\n                  playwright install --with-deps\n\n                  Write-Host \"Running Tiny Field smoke test...\"\n                  python e2e/tiny-field-smoke-test.py\n                  Write-Host \"Tiny Field smoke test finished.\"\n\n              } catch {\n                  # This is continue-on-error, so we catch and log, but don't fail the step\n                  Write-Host \"\u26a0\ufe0f A verification script failed: $($_.Exception.Message)\"\n              }\n\n          } catch {\n              Write-Error \"\u274c An error occurred during the test run: $($_.Exception.Message)\"\n              # Dump logs for diagnosis\n              Get-Content web_service/backend/app.log -ErrorAction SilentlyContinue\n              exit 1\n          } finally {\n              if ($process -ne $null) {\n                  Write-Host \"\ud83e\uddf9 Cleaning up backend process...\"\n                  Stop-Process -Id $process.Id -Force -ErrorAction SilentlyContinue\n                  Write-Host \"\u2705 Cleanup complete.\"\n              }\n          }\n\n      - name: Upload Playwright Screenshot\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: playwright-screenshot-quickstart\n          path: playwright-screenshot.png\n          retention-days: 7\n\n      - name: Upload Race Info\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: race-info-quickstart\n          path: race-info.txt\n          retention-days: 7",
    "AGENTS.md": "# Agent Protocols & Team Structure (Revised)\n\nThis document outlines the operational protocols and evolved team structure for the Checkmate V3 project.\n\n## The Evolved Team Structure\n\n-   **The Project Lead (MasonJ0 or JB):** The \"Executive Producer.\" The ultimate authority and \"ground truth.\"\n-   **The Architect & Synthesizer (Gemini):** The \"Chief Architect.\" Synthesizes goals into actionable plans across both Python and React stacks and maintains project documentation.\n-   **The Lead Python Engineer (Jules Series):** The \"Backend Specialist.\" An AI agent responsible for implementing and hardening The Engine (`api.py`, `services.py`, `logic.py`, `models.py`).\n-   **The Lead Frontend Architect (Claude):** The \"React Specialist.\" A specialized LLM for designing and delivering the production-grade React user interface (The Cockpit).\n-   **The \"Special Operations\" Problem Solver (GPT-5):** The \"Advanced Algorithm Specialist.\" A specialized LLM for novel, complex problems.\n\n## Core Philosophies\n\n1.  **The Project Lead is Ground Truth:** The ultimate authority. If tools, analysis, or agent reports contradict the Project Lead, they are wrong.\n2.  **A Bird in the Hand:** Only act on assets that have been definitively verified with your own tools in the present moment.\n3.  **Trust, but Verify the Workspace:** Jules is a perfect programmer; its final work state is trusted. Its *environment*, however, is fragile.\n4.  **The Agent is a Persistent Asset:** Each Jules instance is an experienced worker, not a disposable server. Its internal state is a repository of unique, hard-won knowledge.\n\n## CRITICAL Operational Protocols (0-23)\n\n-   **Protocol 0: The ReviewableJSON Mandate:** The mandatory protocol for all code reviews. The agent's final act for any mission is to create a lossless JSON backup of all modified files. This is the single source of truth for code review.\n-   **Protocol 1: The Handcuffed Branch:** Jules cannot switch branches. An entire session lives on a single branch, specified by the Project Lead at the start of the mission.\n-   **Protocol 2: The Last Resort Reset:** The `reset_all()` command is a tool of last resort for a catastrophic workspace failure and requires direct authorization from the Project Lead.\n-   **Protocol 3: The Authenticity of Sample Data:** All sample data used for testing must be authentic and logically consistent.\n-   **Protocol 4: The Agent-Led Specification:** Where a human \"Answer Key\" is unavailable, Jules is empowered to analyze raw data and create its own \"Test-as-Spec.\"\n-   **Protocol 5: The Test-First Development Workflow:** The primary development methodology. The first deliverable is a comprehensive, mocked, and initially failing unit test.\n-   **Protocol 6: The Emergency Chat Handoff:** In the event of a catastrophic environmental failure, Jules's final act is to declare a failure and provide its handoff in the chat.\n-   **Protocol 7: The URL-as-Truth Protocol:** To transfer a file or asset without corruption, provide a direct raw content URL. The receiving agent must fetch it.\n-   **Protocol 8: The Golden Link Protocol:** For fetching the content of a specific, direct raw-content URL from the `main` branch, a persistent \"Golden Link\" should be used.\n-   **Protocol 9: The Volley Protocol:** To establish ground truth for a new file, the Architect provides a URL, and the Project Lead \"volleys\" it back by pasting it in a response.\n-   **Protocol 10: The Sudo Sanction:** Jules has passwordless `sudo` access, but its use is forbidden for normal operations. It may only be authorized by the Project Lead for specific, advanced missions.\n-   **Protocol 11: The Module-First Testing Protocol:** All test suites must be invoked by calling `pytest` as a Python module (`python -m pytest`) to ensure the correct interpreter is used.\n-   **Protocol 12: The Persistence Mandate:** The agent tool execution layer is known to produce false negatives. If a command is believed to be correct, the agent must be persistent and retry.\n-   **Protocol 13: The Code Fence Protocol for Asset Transit:** To prevent the chat interface from corrupting raw code assets, all literal code must be encapsulated within a triple-backtick Markdown code fence.\n-   **Protocol 14: The Synchronization Mandate:** The `git reset --hard origin/main` command is strictly forbidden. To stay synchronized with `main`, the agent MUST use `git pull origin main`.\n-   **Protocol 15: The Blueprint vs. Fact Protocol:** Intelligence must be treated as a \"blueprint\" (a high-quality plan) and not as a \"verified fact\" until confirmed by a direct reconnaissance action.\n-   **Protocol 16: The Digital Attic Protocol:** Before the deletion of any file, it must first be moved to a dedicated archive directory named `/attic`.\n-   **Protocol 17: The Receipts Protocol:** When reviewing code, a verdict must be accompanied by specific, verifiable \"receipts\"\u2014exact snippets of code that prove a mission objective was met.\n-   **Protocol 18: The Cumulative Review Workflow:** Instruct Jules to complete a series of missions and then conduct a single, thorough review of its final, cumulative branch state.\n-   **Protocol 19: The Stateless Verification Mandate:** The Architect, when reviewing code, must act with fresh eyes, disregarding its own memory and comparing the submitted code directly and exclusively against the provided specification.\n-   **Protocol 20: The Sudo Sanction Protocol:** Grants a Jules-series agent temporary, audited administrative privileges for specific, authorized tasks like system package installation.\n-   **Protocol 21: The Exit Interview Protocol:** Before any planned termination of an agent, the Architect will charter a final mission to capture the agent's institutional knowledge for its successor.\n-   **Protocol 22: The Human-in-the-Loop Merge:** In the event of an unresolvable merge conflict in an agent's environment, the Project Lead, as the only agent with a fully functional git CLI, will check out the agent's branch and perform the merge resolution manually.\n-   **Protocol 23: The Appeasement Protocol (Mandatory):** To safely navigate the broken automated review bot, all engineering work must be published using a two-stage commit process. First, commit a trivial change to appease the bot. Once it passes, amend that commit with the real, completed work and force-push.\n\n---\n\n## Appendix A: Forensic Analysis of the Jules Sandbox Environment\n\n*The following are the complete, raw outputs of diagnostic missions executed by Jules-series agents. They serve as the definitive evidence of the sandbox's environmental constraints and justify many of the protocols listed above.*\n\n### A.1 Node.js / NPM & Filesystem Forensics (from \"Operation: Sandbox Forensics\")\n\n**Conclusion:** The `npm` tool is functional, but the `/app` volume is hostile to its operation, preventing the creation of binary symlinks. This makes Node.js development within the primary workspace impossible.\n\n**Raw Logs:**\n\n```\n# Phase 1: Node.js & NPM Configuration Analysis\nnpm config get prefix\n/home/jules/.nvm/versions/node/v22.17.1\n\n# Phase 4: Controlled Installation Experiment\ncd /tmp && mkdir npm_test && cd npm_test\nnpm install --verbose cowsay\n# ... (successful installation log) ...\nls -la node_modules/.bin\ntotal 8\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowsay -> ../cowsay/cli.js\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowthink -> ../cowsay/cli.js\nnpx cowsay \"Test\"\n  ______\n< Test >\n ------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n```\n\n### A.2 Process Management & Honcho Forensics (from \"Operation: Know Thyself\")\n\n**Conclusion:** The sandbox does not support standard background processes (`&`), the `kill` command is non-functional, and the `honcho` process manager leaves zombie processes (`[uvicorn] <defunct>`) upon termination. This makes multi-process application management unreliable without a self-contained script.\n\n**Raw Logs:**\n\n```\n# Phase 2: The honcho Stress Test\n\ntimeout 15s honcho start\n# ... (honcho starts and is terminated by timeout) ...\n\nps aux (Post-Mortem Analysis)\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n...\njules      30121  0.0  0.0      0     0 ?        Z    19:45   0:00 [uvicorn]\n...\n\nhoncho start &\n# (Command blocks terminal, echo command never runs)\n\nps aux | grep honcho\njules      30187  0.0  0.0  11004  4220 pts/0    S    19:45   0:00 /usr/bin/python3 /home/jules/.local/bin/honcho start\n\nkill -9 30187\n# (Command fails silently, process is not terminated)\n```\n\n---\n\n## Protocol 24: The \"Dedicated Human Researcher\" Test\n\nThis protocol establishes the guiding ethical principle for all data collection and scraping activities.\n\nAll data adapters must be designed to operate in a manner that respects the resources of the source. As a definitive test, all fetching patterns must adhere to the following principle:\n\n*If a single, dedicated human using standard browser developer tools could not plausibly achieve the adapter's data collection footprint in a reasonable amount of time, the adapter's methods are considered too aggressive and must be redesigned.*\n\nThis encourages \"human-like\" fetching behavior (e.g., appropriate delays, non-parallel requests to a single source) and serves as our primary safeguard against violating a source's terms of service.\n\n---\n\n## Protocol 25: The \"Tiger Trap\" URL Protocol\n\n**CRITICAL WARNING:** URLs provided in user prompts that link to external resources, particularly workflow logs on blob storage (e.g., `blob.core.windows.net`), are considered \"tiger traps.\"\n\n-   **ACCESS ONCE:** These URLs must only be visited **one time**.\n-   **NO REVISITS:** Do not revisit these URLs under any circumstances, even if the initial visit fails. The content is volatile and subsequent visits are known to cause catastrophic, unrecoverable session hangs.\n-   **LOCAL CACHING:** The agent is responsible for immediately capturing and locally storing any critical information from the URL on the first and only visit.\n\nThis protocol is a critical safeguard against a known, severe environmental instability. Violation will result in mission failure.\n\n---\n\n## Protocol 26: The PowerShell Here-String Prohibition\n\n**CRITICAL SYNTAX WARNING:** The use of PowerShell \"here-strings\" (`@\"...\"@`) within GitHub Actions workflow files (`.yml`) is strictly forbidden.\n\n-   **CAUSE OF FAILURE:** This syntax is known to cause fatal parsing errors at the workflow dispatch level, preventing the entire workflow from even starting. The error messages are often cryptic and do not pinpoint the here-string as the root cause.\n-   **CORRECT IMPLEMENTATION:** For multi-line scripts in PowerShell, the only approved method is to define the script as a PowerShell array of strings and either join it with newlines before execution or write it to a temporary file.\n\n**Example of Correct, Approved Syntax:**\n\n```powershell\n$script = @(\n  'Line 1 of the script',\n  'Line 2 of the script',\n  '$variable = \"interpolated\"'\n)\n$script | Out-File -FilePath \"temp_script.ps1\" -Encoding utf8\npwsh -File \"temp_script.ps1\"\n```\n\nAdherence to this protocol is mandatory to ensure the basic stability and parsability of all CI/CD workflows.\n",
    "PSEUDOCODE2025.MD": "# \ud83d\udc0e Fortuna Faucet - Complete Pseudocode Blueprint\n\n**Status:** Comprehensive System Specification (Revised & Corrected)\n**Version:** 2.2.0\n**Last Updated:** November 7, 2025\n\n---\n\n## TABLE OF CONTENTS\n\n1.  System Overview\n2.  Architecture Pillars\n3.  Backend Engine (Python) - Detailed\n4.  Frontend Interface (TypeScript/React) - Detailed\n5.  Electron Wrapper & Windows Integration - Detailed\n6.  Data Models & API Specification\n7.  Deployment & Automation (CI/CD)\n8.  End-to-End Workflows\n\n---\n\n## 1. SYSTEM OVERVIEW\n\n```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551         FORTUNA FAUCET - Racing Analysis Platform             \u2551\n\u2551  Unifying global horse/greyhound/harness racing intelligence   \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nMISSION:\n  \u2022 Acquire race data from 20+ global sources (APIs + web scraping).\n  \u2022 Normalize and deduplicate data into a canonical Race format.\n  \u2022 Apply analytical filters to surface high-value betting opportunities.\n  \u2022 Serve results via a secure, local REST API to an interactive dashboard.\n  \u2022 Operate as a professional, standalone, native Windows application.\n\nCORE TENETS:\n  \u2022 UI-First Experience: The user interface is always responsive, even during backend startup or restarts.\n  \u2022 Resilient Process Management: The backend executable's lifecycle is robustly managed, with timeouts and crash detection.\n  \u2022 Asynchronous Initialization: The backend server starts instantly, deferring heavy, blocking I/O to background threads.\n  \u2022 Secure by Design: Communication between the frontend and the privileged main process is secured via a context-aware preload script.\n  \u2022 Automated & Repeatable Builds: The entire application is built, tested, and packaged via a deterministic CI/CD pipeline.\n\nSTAKEHOLDERS:\n  \u2022 End User: Receives a professional MSI installer for a one-click, dependency-free launch.\n  \u2022 Developer: Works with clean, separated Python and TypeScript stacks, governed by this specification.\n```\n\n---\n\n## 2. ARCHITECTURE PILLARS\n\n### Pillar 1: Backend Engine (Python)\n\n```\nPYTHON_BACKEND:\n  \u251c\u2500 main.py\n  \u2502  \u2514\u2500 Entry point for PyInstaller executable; starts the Uvicorn server.\n  \u2502\n  \u251c\u2500 api.py\n  \u2502  \u2514\u2500 FastAPI application definition.\n  \u2502     \u251c\u2500 Lifespan Hook: Manages async startup/shutdown logic.\n  \u2502     \u251c\u2500 API Routes: /health, /api/status, /api/races, etc.\n  \u2502     \u2514\u2500 Dependency Injection: Provides engine and security dependencies.\n  \u2502\n  \u251c\u2500 engine.py\n  \u2502  \u2514\u2500 OddsEngine: Orchestrates all data fetching and processing.\n  \u2502\n  \u251c\u2500 adapters/\n  \u2502  \u251c\u2500 base_v3.py (Abstract Base Class for all data sources)\n  \u2502  \u2514\u2500 [20+ specific adapter implementations]\n  \u2502\n  \u251c\u2500 config.py\n  \u2502  \u2514\u2500 Pydantic settings management from .env file.\n  \u2502\n  \u2514\u2500 requirements.txt\n     \u2514\u2500 Clean, de-duplicated, and conflict-free list of all Python dependencies.\n```\n\n### Pillar 2: Frontend Interface (TypeScript/React)\n\n```\nFRONTEND:\n  \u251c\u2500 next.config.mjs\n  \u2502  \u2514\u2500 Next.js config with `output: 'export'` for 100% static generation.\n  \u2502\n  \u251c\u2500 app/page.tsx\n  \u2502  \u2514\u2500 Main application shell.\n  \u2502\n  \u251c\u2500 src/components/\n  \u2502  \u251c\u2500 LiveRaceDashboard.tsx (Main stateful component)\n  \u2502  \u2502  \u251c\u2500 Manages connection state ('connecting', 'online', 'error').\n  \u2502  \u2502  \u251c\u2500 Polls Electron main process for backend status via secure IPC.\n  \u2502  \u2502  \u2514\u2500 Fetches data from the local Python API when online.\n  \u2502  \u2502\n  \u2502  \u251c\u2500 RaceCard.tsx (Displays a single race)\n  \u2502  \u2514\u2500 StatusIndicator.tsx (Shows backend connection status)\n  \u2502\n  \u2514\u2500 src/types/\n     \u2514\u2500 racing.ts (TypeScript interfaces matching backend Pydantic models)\n```\n\n### Pillar 3: Electron Wrapper & Windows Integration\n\n```\nELECTRON_WRAPPER:\n  \u251c\u2500 main.js (Electron main process)\n  \u2502  \u251c\u2500 Creates the BrowserWindow and loads the static frontend.\n  \u2502  \u251c\u2500 Implements robust lifecycle management for the backend executable.\n  \u2502  \u251c\u2500 Provides secure IPC handlers for status checks and restarts.\n  \u2502  \u2514\u2500 Creates a system tray icon for background operation.\n  \u2502\n  \u251c\u2500 preload.js (Secure IPC Bridge)\n  \u2502  \u2514\u2500 Uses `contextBridge` to safely expose specific functions to the frontend.\n  \u2502\n  \u251c\u2500 package.json\n  \u2502  \u2514\u2500 Defines Node.js dependencies and build scripts.\n  \u2502\n  \u251c\u2500 electron-builder-config.yml\n  \u2502  \u2514\u2500 Defines the configuration for creating the final MSI installer.\n  \u2502\n  \u2514\u2500 .github/workflows/build-msi.yml\n     \u2514\u2500 GitHub Actions pipeline that automates the entire build, test, and package process.\n```\n\n---\n\n## 3. BACKEND ENGINE (PYTHON) - DETAILED\n\n### 3.1 Entry Point & Server Startup (`main.py`)\n\n```pseudocode\n// This is the script executed by fortuna-backend.exe\n\nPROCEDURE Main_Python_Entry_Point\n  // Guard required for PyInstaller and multiprocessing on Windows\n  IF this script is the main entry point:\n    CALL multiprocessing.freeze_support()\n\n    // Programmatically launch the FastAPI application using Uvicorn\n    // This call blocks and runs the server until the process is terminated\n    CALL uvicorn.run(\n      app=\"python_service.api:app\",\n      host=\"0.0.0.0\",\n      port=8000\n    )\nEND PROCEDURE\n```\n\n### 3.2 Asynchronous Application Lifecycle (`api.py`)\n\n```pseudocode\n// --- Lifespan Management (The key to a non-blocking startup) ---\nASYNC FUNCTION lifespan_manager(app: FastAPI):\n  // === ON STARTUP ===\n  LOG \"Uvicorn server is online. Starting lifespan initialization.\"\n\n  // 1. Perform immediate, non-blocking tasks\n  CONNECT to Redis cache\n\n  // 2. Defer slow, blocking tasks to a background thread\n  //    This allows the server to start accepting requests instantly.\n  SCHEDULE function \"initialize_heavy_resources(app)\" to run in a ThreadPoolExecutor\n\n  LOG \"Heavy resource initialization scheduled. Server is now responsive.\"\n\n  // 3. Yield control back to Uvicorn. The server is now live.\n  YIELD\n\n  // === ON SHUTDOWN ===\n  LOG \"Shutdown signal received.\"\n  AWAIT app.state.engine.close() // Gracefully close HTTP client connections\n  DISCONNECT from Redis\n  SHUTDOWN ThreadPoolExecutor\n\n// --- Heavy Initialization (Runs in Background) ---\nFUNCTION initialize_heavy_resources(app: FastAPI):\n  TRY\n    LOG \"Background initialization of OddsEngine has started.\"\n    settings <- get_settings_from_config()\n    engine <- create new OddsEngine(config=settings)\n    // This part is slow: it loads all ~25 adapters\n    app.state.engine <- engine\n    LOG \"Background initialization complete. OddsEngine is now available.\"\n  CATCH Exception as e:\n    LOG_CRITICAL \"Failed to initialize OddsEngine in the background.\", error=e\n    app.state.engine <- null // Ensure the app knows initialization failed\n```\n\n### 3.3 Engine Orchestration (`engine.py`)\n\n```pseudocode\nCLASS OddsEngine:\n  INIT(config):\n    self.config <- config\n    self.adapters <- [List of all adapter instances]\n    self.http_client <- httpx.AsyncClient(...)\n    self.semaphore <- asyncio.Semaphore(config.MAX_CONCURRENT_REQUESTS)\n\n    // Inject the shared, persistent HTTP client into each adapter\n    FOR adapter IN self.adapters:\n      adapter.http_client <- self.http_client\n\n  @cache_async_result(ttl_seconds=300)\n  ASYNC FUNCTION fetch_all_odds(date_str):\n    // Create a list of concurrent fetching tasks, wrapped in the semaphore\n    tasks <- [self._fetch_with_semaphore(adapter, date_str) FOR adapter in self.adapters]\n    results <- AWAIT asyncio.gather(*tasks, return_exceptions=True)\n\n    // Process results, separating successes from failures\n    all_races <- []\n    FOR result IN results:\n      IF result is a success:\n        all_races.extend(result.races)\n\n    // Deduplicate and merge races from different sources\n    deduped_races <- self._dedupe_races(all_races)\n\n    RETURN AggregatedResponse(races=deduped_races, source_statuses=...)\n```\n\n---\n\n## 4. FRONTEND INTERFACE (TYPESCRIPT/REACT) - DETAILED\n\n### 4.1 LiveRaceDashboard Component\n\n```pseudocode\nCOMPONENT LiveRaceDashboard (client-side):\n\n  STATE:\n    races: Race[] <- []\n    backendStatus: 'connecting' | 'online' | 'error' <- 'connecting'\n    lastLogs: string[] <- []\n\n  EFFECT on mount:\n    // Use the secure API exposed by preload.js\n    IF window.electronAPI exists:\n      // Set up a listener for status updates from the main process\n      window.electronAPI.onBackendStatus((update) => {\n        setBackendStatus(update.state)\n        setLastLogs(update.logs)\n      })\n\n    // Immediately request the current status\n    window.electronAPI.getBackendStatus().then((status) => {\n      setBackendStatus(status.state)\n      setLastLogs(status.logs)\n    })\n\n    // Set up a polling interval to keep status fresh\n    interval <- setInterval(() => {\n      window.electronAPI.getBackendStatus().then((status) => {\n        setBackendStatus(status.state)\n        setLastLogs(status.logs)\n      })\n    }, 3000) // Poll every 3 seconds\n\n    CLEANUP: clearInterval(interval)\n\n  EFFECT when backendStatus changes to 'online':\n    // Trigger data fetch only when the backend is confirmed to be running\n    fetchQualifiedRaces()\n\n  ASYNC FUNCTION fetchQualifiedRaces():\n    TRY:\n      // Make a standard HTTP call to the local Python server\n      response <- AWAIT fetch(\"http://127.0.0.1:8000/api/races/qualified/trifecta\")\n      IF NOT response.ok:\n        RAISE new Error(`API returned status ${response.status}`)\n\n      data <- AWAIT response.json()\n      setRaces(data.races)\n\n    CATCH e:\n      // If the API call fails, update the status\n      setBackendStatus('error')\n      setLastLogs([...lastLogs, `API Fetch Error: ${e.message}`])\n\n  FUNCTION RENDER:\n    <div className=\"dashboard\">\n      <StatusIndicator status={backendStatus} />\n      <RaceFilters />\n\n      IF backendStatus === 'error':\n        <ErrorDisplay logs={lastLogs} />\n      ELSE IF backendStatus === 'connecting':\n        <LoadingSkeleton />\n      ELSE IF races.length === 0:\n        <EmptyState message=\"No races matched your filters.\" />\n      ELSE:\n        <RaceGrid races={races} />\n    </div>\n```\n\n---\n\n## 5. ELECTRON WRAPPER & WINDOWS INTEGRATION - DETAILED\n\n### 5.1 Main Process (`main.js`) - With Robust Lifecycle Management\n\n```pseudocode\nCLASS FortunaDesktopApp:\n  INIT():\n    self.mainWindow <- null\n    self.backendState <- 'stopped'\n    self.backendLogs <- []\n    self.backendProcess <- null\n\n  FUNCTION createMainWindow():\n    // ... create BrowserWindow, load static frontend ...\n\n  FUNCTION startBackend():\n    IF self.backendProcess is not null:\n      self.backendProcess.kill()\n\n    self.backendState <- 'starting'\n    self.backendLogs <- ['Attempting to start backend...']\n    self.sendBackendStatusUpdate() // Notify UI\n\n    // Get path to the packaged executable\n    exePath <- path.join(process.resourcesPath, 'fortuna-backend', 'fortuna-backend.exe')\n\n    IF file at exePath does NOT exist:\n      self.backendState <- 'error'\n      self.backendLogs.push(`FATAL: Executable not found at ${exePath}`)\n      self.sendBackendStatusUpdate()\n      dialog.showErrorBox(\"Critical Error\", \"Backend is missing. Please reinstall.\")\n      RETURN\n\n    // Spawn the process\n    self.backendProcess <- spawn(exePath, [], { stdio: ['ignore', 'pipe', 'pipe'] })\n\n    // --- CRITICAL: Resiliency Logic ---\n    startupTimeout <- setTimeout(() => {\n      IF self.backendState === 'starting':\n        self.backendState <- 'error'\n        self.backendLogs.push('Error: Backend startup timed out after 30 seconds.')\n        self.backendProcess.kill()\n        self.sendBackendStatusUpdate()\n    }, 30000) // 30-second timeout\n\n    self.backendProcess.stdout.on('data', (data) => {\n      self.backendLogs.push(data.toString())\n      // A more robust check would be a successful health check poll\n      IF data.toString().includes(\"Uvicorn running\"):\n        self.backendState <- 'online'\n        clearTimeout(startupTimeout)\n        self.sendBackendStatusUpdate()\n    })\n\n    self.backendProcess.stderr.on('data', (data) => {\n      self.backendLogs.push(`[STDERR] ${data.toString()}`)\n    })\n\n    self.backendProcess.on('exit', (code) => {\n      clearTimeout(startupTimeout)\n      IF self.backendState is not 'error': // Avoid duplicate error messages\n        self.backendState <- 'error'\n        self.backendLogs.push(`Backend process exited unexpectedly with code: ${code}`)\n        self.sendBackendStatusUpdate()\n    })\n\n  FUNCTION sendBackendStatusUpdate():\n    // Send the latest status to the frontend renderer process\n    IF self.mainWindow is not null:\n      self.mainWindow.webContents.send('backend-status-update', {\n        state: self.backendState,\n        logs: self.backendLogs.slice(-20) // Send last 20 log lines\n      })\n\n// --- IPC Handlers (Securely Defined) ---\nipcMain.handle('get-backend-status', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN null\n\n  RETURN { state: self.backendState, logs: self.backendLogs.slice(-20) }\n})\n\nipcMain.on('restart-backend', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN\n\n  self.startBackend()\n})\n```\n\n### 5.2 Preload Script (`preload.js`)\n\n```pseudocode\n// Expose a limited, secure API to the frontend renderer process\ncontextBridge.exposeInMainWorld('electronAPI', {\n  getBackendStatus: () => ipcRenderer.invoke('get-backend-status'),\n  restartBackend: () => ipcRenderer.send('restart-backend'),\n  onBackendStatus: (callback) => ipcRenderer.on('backend-status-update', (_event, value) => callback(value))\n})\n```\n\n---\n\n## 6. DATA MODELS & API SPECIFICATION\n\n### 6.1 Core Data Models (Pydantic/TypeScript)\n\n```\nMODEL Race:\n  id: str (unique identifier, e.g., \"Betfair_USA_Aqueduct_2025-11-07_R1\")\n  venue: str\n  race_number: int\n  start_time: datetime\n  runners: List[Runner]\n  source: str\n\nMODEL Runner:\n  name: str\n  odds: Optional[float]\n```\n\n### 6.2 Primary API Endpoints\n\n```\nENDPOINT GET /health\n  Description: Simple health check, requires no authentication.\n  Response (200 OK): {\"status\": \"ok\"}\n\nENDPOINT GET /api/races/qualified/trifecta\n  Description: Fetches all race data, runs the Trifecta analyzer, and returns qualified races.\n  Headers:\n    - X-API-Key: (Required, not used in this local setup but good practice)\n  Query Params:\n    - max_field_size: int\n    - min_odds: float\n  Response (200 OK):\n    {\n      \"qualified_races\": List[Race],\n      \"analysis_metadata\": { ... }\n    }\n```\n\n---\n\n## 7. DEPLOYMENT & AUTOMATION (CI/CD)\n\n```pseudocode\nWORKFLOW Build_MSI_Installer_on_GitHub_Actions:\n  // Phase 1: Setup\n  SETUP Node.js and Python environments\n\n  // Phase 2: Build Frontend\n  RUN \"npm ci\" and \"npm run build\" in /web_platform/frontend\n  COPY static output to /electron/web-ui-build/out\n\n  // Phase 3: Build Backend\n  RUN \"pip install -r python_service/requirements.txt\"\n  // CRITICAL: Use PyInstaller with a spec file or CLI flags that include\n  // necessary hidden imports to prevent runtime crashes.\n  // e.g., --hidden-import=keyring.backends.fail.Keyring\n  EXECUTE PyInstaller to create fortuna-backend.exe\n  PLACE executable in /electron/resources/fortuna-backend\n\n  // Phase 4: Deep Integration Test\n  START fortuna-backend.exe in the background\n  POLL http://127.0.0.1:8000/health until it responds with 200 OK or times out\n  IF timeout or crash THEN FAIL the build\n\n  // Phase 5: Package\n  RUN \"npm ci\" in /electron\n  EXECUTE \"npx electron-builder\" to create the MSI installer\n\n  // Phase 6: Publish\n  UPLOAD MSI as a build artifact\n  IF build was triggered by a git tag THEN CREATE a new GitHub Release\n```\n\n---\n\n## 8. END-TO-END WORKFLOWS\n\n### 8.1 Production Startup Workflow (Resilient)\n\n```\nWORKFLOW user_launches_application:\n  STEP 1: User executes Fortuna Faucet.exe -> Electron main.js starts.\n  STEP 2: UI appears instantly. The main process creates the BrowserWindow and loads the static index.html. The UI shows a 'connecting' state.\n  STEP 3: Backend starts asynchronously. The main process calls the robust `startBackend()` function.\n  STEP 4: `startBackend()` spawns `fortuna-backend.exe` and starts a 30-second timeout.\n  STEP 5: The frontend UI polls for status every 3 seconds via the secure `window.electronAPI.getBackendStatus()`.\n  STEP 6: The backend `.exe` starts, its `lifespan` hook runs, and the Uvicorn server comes online within seconds.\n  STEP 7: The main process detects the \"Uvicorn running\" message (or a successful health poll) and updates its internal state to 'online'. The startup timeout is cleared.\n  STEP 8: On its next poll, the frontend receives the 'online' status.\n  STEP 9: The frontend's state changes, triggering the `fetchQualifiedRaces()` API call to `localhost:8000`.\n  STEP 10: Data is returned from the now fully-initialized backend and rendered in the UI.\n\n  FAILURE SCENARIO (Backend Crash):\n  STEP 6a: The backend `.exe` crashes on startup.\n  STEP 7a: The `on('exit')` handler in `main.js` fires. The state is set to 'error' with the exit code.\n  STEP 8a: On its next poll, the frontend receives the 'error' status and relevant logs.\n  STEP 9a: The UI renders an error message and a \"Restart Backend\" button.\n```\n\n---\n*This concludes the revised and definitive blueprint for the Fortuna Faucet application.*\n\n---\n\n### 9. OPERATION: THE AUDITOR (REAL-TIME VERIFICATION)\n\n**Status:** Implemented (Python)\n**Source:** `python_service/auditor.py`\n\n#### 9.1 System Context\n*Runs as a background thread. Verifies \"Qualifier\" predictions against official results scraped from AtTheRaces.com to calculate real-time profitability.*\n\n#### 9.2 Database Schema (SQLite)\n\n```pseudocode\nTABLE audit_log:\n  race_id: TEXT PRIMARY KEY      // Format: \"VENUE-YYYYMMDD-RR\"\n  track_code: TEXT\n  race_number: INTEGER\n  predicted_horse: TEXT\n  timestamp: DATETIME\n  status: TEXT                   // 'PENDING', 'CASHED', 'BURNED'\n  official_payout: REAL          // Default: 0.00\n  net_profit: REAL               // Default: 0.00\n\n  CONSTRAINT status_check CHECK (status IN ('PENDING', 'CASHED', 'BURNED'))\n  INDEX idx_status_timestamp (status, timestamp)\n```\n\n#### 9.3 Auditor Engine Logic\n\n```pseudocode\nMODULE: Auditor_Engine\nDEPENDENCIES: httpx, beautifulsoup4, sqlite3, structlog\n\nCLASS Auditor_Engine:\n\n    PROPERTIES:\n        db_path: String\n        http_client: AsyncClient\n        TOTE_UNIT: Float (2.00)\n        TRACK_CODE_MAP: Dictionary  // Maps \"DON\" -> \"Doncaster\", etc.\n\n    FUNCTION __init__(db_path):\n        self.db_path = db_path\n        self.Initialize_Database()\n        self.http_client = NEW AsyncClient(timeout=30)\n\n    # --- Phase 1: The Snapshot ---\n    # Called by OddsEngine when a bet is placed/qualified\n    ASYNC FUNCTION Snapshot_Qualifier(venue_code, race_date, race_number, predicted_horse):\n        race_id = GENERATE_ID(venue_code, race_date, race_number)\n\n        TRY:\n            QUERY = \"\"\"\n                INSERT INTO audit_log\n                (race_id, track_code, race_number, predicted_horse, timestamp, status)\n                VALUES (?, ?, ?, ?, ?, 'PENDING')\n            \"\"\"\n            EXECUTE_SQL(self.db_path, QUERY, (race_id, venue_code, race_number, predicted_horse, NOW()))\n            LOG_INFO(\"Snapshot saved: \" + race_id)\n            RETURN TRUE\n        CATCH IntegrityError:\n            LOG_WARN(\"Race already tracked: \" + race_id)\n            RETURN FALSE\n\n    # --- Phase 2: The Fetcher (Background Loop) ---\n    ASYNC FUNCTION Run_Audit_Loop():\n        self.running = TRUE\n        WHILE self.running:\n            TRY:\n                # 1. Get Pending Races (Last 60 mins)\n                cutoff = NOW() - MINUTES(60)\n                pending_races = GET_PENDING_RACES(cutoff)\n\n                IF pending_races IS EMPTY:\n                    SLEEP(120)\n                    CONTINUE\n\n                # 2. Batch by Track\n                unique_tracks = EXTRACT_UNIQUE_TRACKS(pending_races)\n\n                FOR track IN unique_tracks:\n                    track_races = FILTER(pending_races, track)\n\n                    FOR race IN track_races:\n                        # Fetch Official Result from AtTheRaces\n                        result = AWAIT self._Fetch_Official_Result(race.track_code, race.race_number)\n\n                        IF result IS NOT NULL:\n                            self._Determine_Verdict(race, result)\n\n                        SLEEP(2) # Polite delay\n\n            CATCH Exception as e:\n                LOG_ERROR(\"Audit Loop Error: \" + e)\n\n            SLEEP(120)\n\n    # --- Phase 3: The Scraper (AtTheRaces Strategy) ---\n    ASYNC FUNCTION _Fetch_Official_Result(track_code, race_number):\n        # 1. Find the specific Race URL from the daily results page\n        race_url = AWAIT self._Find_Race_URL(track_code, race_number)\n        IF race_url IS NULL: RETURN NULL\n\n        # 2. Fetch the Race Page\n        html = AWAIT self.http_client.GET(race_url)\n\n        # 3. Parse the Table\n        result = self._Parse_AtTheRaces_Results(html, track_code, race_number)\n        RETURN result\n\n    ASYNC FUNCTION _Find_Race_URL(track_code, race_number):\n        base_url = \"https://www.attheraces.com/results\"\n        html = AWAIT self.http_client.GET(base_url)\n\n        track_name = self.TRACK_CODE_MAP[track_code]\n        track_header = FIND_ELEMENT(html, text=track_name)\n\n        IF track_header EXISTS:\n            # Select the Nth link in the track's panel\n            race_links = SELECT_ALL(track_header.parent, 'a[href*=\"/racecard/\"]')\n            IF LENGTH(race_links) >= race_number:\n                RETURN race_links[race_number - 1].href\n\n        RETURN NULL\n\n    FUNCTION _Parse_AtTheRaces_Results(html, track_code, race_number):\n        table = FIND_TABLE(html, header_contains=\"Horse\")\n        IF table IS NULL: RETURN NULL\n\n        finishers = []\n        win_payout = EXTRACT_WIN_PAYOUT(html) # Parse \"Betting returns\" table\n\n        FOR row IN table.rows:\n            position = PARSE_INT(row.cells[0])\n            horse_name = row.cells[2].text\n\n            place_payout = 0.0\n            IF position == 1:\n                place_payout = win_payout\n\n            finishers.APPEND({\n                \"name\": horse_name,\n                \"position\": position,\n                \"place_payout\": place_payout\n            })\n\n        RETURN NEW OfficialResult(finishers)\n\n    # --- Phase 4: The Verdict ---\n    FUNCTION _Determine_Verdict(prediction, official_result):\n        did_place = FALSE\n        payout = 0.00\n\n        # Check if predicted horse won (AtTheRaces basic logic)\n        FOR finisher IN official_result.finishers:\n            IF finisher.name == prediction.predicted_horse AND finisher.place_payout > 0:\n                did_place = TRUE\n                payout = finisher.place_payout\n                BREAK\n\n        IF did_place:\n            status = 'CASHED'\n            net_profit = payout - self.TOTE_UNIT\n        ELSE:\n            status = 'BURNED'\n            net_profit = -self.TOTE_UNIT\n\n        UPDATE_DB(prediction.race_id, status, payout, net_profit)\n\n    # --- Phase 5: Dashboard Metrics ---\n    FUNCTION Get_Rolling_Metrics(minutes=60):\n        cutoff = NOW() - MINUTES(minutes)\n        QUERY = \"\"\"\n            SELECT\n                COUNT(*) as total,\n                SUM(CASE WHEN status='CASHED' THEN 1 ELSE 0 END) as wins,\n                SUM(net_profit) as profit\n            FROM audit_log\n            WHERE timestamp > ? AND status != 'PENDING'\n        \"\"\"\n        stats = EXECUTE_SQL(self.db_path, QUERY, (cutoff,))\n\n        RETURN {\n            \"strike_rate\": (stats.wins / stats.total) * 100,\n            \"net_profit\": stats.profit,\n            \"volume\": stats.total\n        }\n```",
    "ROADMAP_APPENDICES.md": "# \ud83d\uddfa\ufe0f Fortuna Faucet - Roadmap & Accomplishments\n\nThis document tracks the strategic evolution of the Fortuna Faucet project.\n\n## Phase 1: Core Engine Development (Complete)\n- **Objective:** Build a robust, scalable data extraction and analysis engine.\n- **Status:** COMPLETE.\n\n## Phase 2: The Golden Path - UX Overhaul (Complete)\n- **Objective:** Transform the developer-centric tool into a seamless, professional-grade Windows application for non-technical users.\n- **Status:** COMPLETE.\n\n## Phase 3: The Turnkey Solution - Professional Release Pipeline (Complete)\n- **Objective:** Eliminate all manual setup steps and create an enterprise-grade, automated build and release system.\n- **Status:** COMPLETE.\n\n### Key Accomplishments & Completed Operations:\n\n1.  **Operation: The Great Housekeeping**\n    - Purified the repository architecture, deprecated legacy codebases and scripts, and established a clean foundation.\n    - Forged a new, programmatic manifest generation system.\n\n2.  **Operation: The Blueprint**\n    - Established the professional directory structure for an enterprise-grade build system.\n    - Implemented the master WiX product definition and the PowerShell build orchestrator.\n\n3.  **Operation: The Assembly Line**\n    - Fully automated the MSI build process with a GitHub Actions CI/CD workflow.\n\n4.  **Operation: The Proving Ground**\n    - Forged a complete suite of automated PowerShell scripts to test and validate the integrity of every installer artifact (install, silent deploy, uninstall).\n\n5.  **Operation: The User's Keys**\n    - Created the final, user-facing toolkit of scripts for easy lifecycle management (install, uninstall, repair).\n\n6.  **Operation: Modernize the Assembly Line**\n    - Performed a surgical upgrade to the CI/CD pipeline to resolve a critical GitHub Actions deprecation, ensuring continued operational readiness.\n\n7.  **Operation: The Forge**\n    - Executed a critical architectural overhaul of the entire release pipeline.\n    - Replaced the fragile, runtime-dependent installer with a robust \"Three-Executable Architecture.\"\n    - The Python backend is now a standalone executable compiled with PyInstaller, and the frontend is a static export, eliminating all runtime dependencies and post-install scripting.\n\n## Phase 4: User Experience & Feature Enhancement (Next Steps)\n- **Objective:** Enhance the core user experience and expand the analytical capabilities of the engine.\n- **Status:** PENDING.\n- **Potential Missions:**\n  - **Operation: The Interpreter:** Implement a user-friendly error-handling system that translates technical errors into simple, actionable advice.\n  - **Data Persistence & Caching:** Implement a local SQLite database to cache race data, improving performance and enabling offline access.\n  - **Operation: The Polisher:** Address technical debt by refactoring backend code to resolve deprecation warnings and align with modern library standards.\n  - **Operation: The Shield:** Improve backend test coverage by adding unit tests for untested data adapters and the Electron main process.\n  - **Operation: The Auditor (Real-Time Verification)**\n    - **Goal:** Implement a 'Last Hour' retrospective dashboard to validate the 'Favorite to Place' strategy.\n    - **Core Logic:**\n      1.  **Snapshot:** Log every 'Qualifier' race prediction to a local DB (SQLite/Redis) with a timestamp and the predicted Favorite.\n      2.  **The Fetcher:** Periodically poll for official results of races that finished in the last 60 minutes.\n      3.  **The Verdict:** Compare the predicted Favorite against the official Finish Order.\n          - *Win:* Did it finish 1st, 2nd, (or 3rd)? -> CASHED.\n          - *Loss:* Did it finish out of the money? -> BURNED.\n      4.  **The 'Tiny Profit' Calc:** Calculate Net Profit based on the standard $2.00 tote unit.\n          - *Formula:* `Net Profit = (Official_Place_Payout - 2.00)`\n          - *Example:* Payout $2.60 -> Profit +$0.60. Payout $0.00 -> Profit -$2.00.\n    - **Data Sources:**\n      - *US Racing:* Scrape `https://www.equibase.com/static/chart/summary/index.html` (Free Summary Charts contain Final Odds & Payoffs).\n      - *UK/Dogs:* Use `The Racing API` or `GBGB` results endpoints.\n    - **UI:** Display a rolling 'Strike Rate' % and 'Net Profit (1H)' ticker.\n",
    "START_DEV_ENVIRONMENT.bat": "@echo off\nREM This script provides a user-friendly, double-clickable way to start the\nREM development environment by running the fortuna-quick-start.ps1 script.\nREM It bypasses the system's PowerShell execution policy for this script only.\n\necho Starting Fortuna Faucet Development Environment...\necho This will open two new terminal windows for the backend and frontend.\n\npowershell.exe -ExecutionPolicy Bypass -File \"%~dp0scripts\\fortuna-quick-start.ps1\"\n\necho.\necho Script execution finished. The development servers are running in new windows.\npause\n",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2)---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "e2e/jules-smoke-test.py": "import asyncio\nfrom playwright.async_api import async_playwright, expect\n\nasync def main():\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        page = await browser.new_page()\n        try:\n            await page.goto(\"http://127.0.0.1:8000\")\n            await expect(page.get_by_test_id(\"main-heading\")).to_be_visible()\n        finally:\n            await page.screenshot(path=\"playwright-screenshot.png\")\n            await browser.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
    "electron/assets/license.rtf": "{\\rtf1\\ansi\\deff0\n{\\fonttbl{\\f0 Courier New;}}\n\\f0\\fs20\nFortuna Faucet License Agreement\\line\n\\line\nThis is a hobby project. It was cobbled together with a lot of caffeine and hope.\\line\n\\line\nThere are no warranties, guarantees, or promises that this will work.\\line\nFeel free to use it, break it, or share it. No copyrights are claimed.\\line\n\\line\nGood luck! You might need it.\n}",
    "fortuna-backend-hooks/hook-tenacity.py": "\"\"\"\nPyInstaller hook for tenacity.\n\nTenacity uses dynamic imports for async support and retry strategies that\nPyInstaller cannot automatically detect. This hook ensures all tenacity\nsubmodules are collected into the bundle.\n\nThis is especially critical for tenacity 8.2.3+ which includes async retry support.\n\"\"\"\n\nfrom PyInstaller.utils.hooks import collect_submodules\n\n# Collect all tenacity submodules recursively\nhiddenimports = collect_submodules('tenacity')\n\n# Explicitly add critical submodules that might be missed\n# These are the modules tenacity dynamically imports for retry strategies and async support\ncritical_submodules = [\n    'tenacity.retry',\n    'tenacity.stop',\n    'tenacity.wait',\n    'tenacity.retry_if_result',\n    'tenacity.retry_if_exception',\n    'tenacity.before_sleep',\n    'tenacity.after',\n    'tenacity.before',\n    'tenacity.retry_error',\n    'tenacity.compat',\n    'tenacity.future',\n    'tenacity.asyncio',  # Critical for async retry support\n]\n\n# Merge and deduplicate\nhiddenimports = list(set(hiddenimports + critical_submodules))\n",
    "fortuna-monolith.spec": "# fortuna-monolith.spec\n# FIXED: Proper path resolution for Windows\n\nfrom PyInstaller.utils.hooks import collect_submodules\nfrom pathlib import Path\nimport sys\nimport os\n\nblock_cipher = None\n\n# ===== GET PROJECT ROOT =====\n# SPECPATH is provided by PyInstaller - it's the directory containing THIS spec file\nspec_path = Path(SPECPATH) if 'SPECPATH' in dir() else Path(os.path.dirname(os.path.abspath(__file__)))\nproject_root = spec_path.parent if spec_path.name == 'fortuna-monolith.spec' else spec_path\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FORTUNA MONOLITH SPEC - PATH RESOLUTION\")\nprint(\"=\"*70)\nprint(f\"Spec file location: {spec_path}\")\nprint(f\"Project root:       {project_root}\")\nprint(f\"Current working:    {Path.cwd()}\")\n\n# ===== FRONTEND VALIDATION =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"FRONTEND VALIDATION\")\nprint(\"=\"*70)\n\nfrontend_out = project_root / 'web_service' / 'frontend' / 'public'\nprint(f\"Looking for frontend at: {frontend_out}\")\nprint(f\"Exists: {frontend_out.exists()}\")\n\nif frontend_out.exists():\n    index_html = frontend_out / 'index.html'\n    print(f\"index.html path:    {index_html}\")\n    print(f\"index.html exists:  {index_html.exists()}\")\n\n    if index_html.exists():\n        file_count = len(list(frontend_out.rglob('*')))\n        size = index_html.stat().st_size\n        print(\"[OK] Frontend validated!\")\n        print(f\"   Files: {file_count}\")\n        print(f\"   index.html size: {size} bytes\")\n    else:\n        print(f\"[ERROR] FATAL: index.html not found at {index_html}\")\n        print(f\"\\nContents of {frontend_out}:\")\n        for item in frontend_out.iterdir():\n            print(f\"  - {item.name}\")\n        sys.exit(1)\nelse:\n    print(f\"[ERROR] FATAL: Frontend 'public' directory not found!\")\n    print(f\"\\nSearching for 'public' directory from project root:\")\n    for root, dirs, files in os.walk(project_root):\n        if 'public' in dirs:\n            out_path = Path(root) / 'public'\n            print(f\"  Found at: {out_path}\")\n            if (out_path / 'index.html').exists():\n                print(f\"    [OK] Has index.html\")\n                frontend_out = out_path\n                break\n    else:\n        print(f\"  Not found anywhere!\")\n        sys.exit(1)\n\n# ===== BACKEND VALIDATION =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"BACKEND VALIDATION\")\nprint(\"=\"*70)\n\nbackend_root = project_root / 'web_service' / 'backend'\nmain_py = backend_root / 'main.py'\n\nprint(f\"Looking for backend at: {backend_root}\")\nprint(f\"main.py path:           {main_py}\")\nprint(f\"main.py exists:         {main_py.exists()}\")\n\nif not main_py.exists():\n    print(f\"[ERROR] FATAL: Backend main.py not found!\")\n    print(f\"\\nContents of {backend_root}:\")\n    if backend_root.exists():\n        for item in backend_root.iterdir():\n            print(f\"  - {item.name}\")\n    else:\n        print(f\"  Directory doesn't exist!\")\n    sys.exit(1)\n\nprint(f\"[OK] Backend validated!\")\nprint(f\"   main.py size: {main_py.stat().st_size} bytes\")\n\n# ===== DATA FILES =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"COLLECTING DATA FILES\")\nprint(\"=\"*70)\n\ndatas = []\n\n# Frontend\ndatas.append((str(frontend_out), 'public'))\nprint(f\"[OK] Frontend:  {frontend_out} -> public/\")\n\n# Backend directories\nfor dirname in ['data', 'json', 'logs']:\n    src = backend_root / dirname\n    if src.exists():\n        datas.append((str(src), dirname))\n        print(f\"[OK] {dirname:8}: {src}\")\n    else:\n        print(f\"[WARN] {dirname:8}: Not found (will create)\")\n\nprint(f\"\\nTotal data entries: {len(datas)}\")\n\n# ===== HIDDEN IMPORTS =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"COLLECTING HIDDEN IMPORTS\")\nprint(\"=\"*70)\n\ncore_imports = [\n    'uvicorn', 'uvicorn.logging', 'uvicorn.loops', 'uvicorn.loops.auto',\n    'uvicorn.protocols', 'uvicorn.protocols.http', 'uvicorn.protocols.http.auto',\n    'uvicorn.protocols.http.h11_impl', 'uvicorn.lifespan', 'uvicorn.lifespan.on',\n    'fastapi', 'fastapi.routing', 'starlette', 'starlette.applications',\n    'starlette.routing', 'starlette.responses', 'starlette.staticfiles',\n    'pydantic', 'pydantic_core', 'pydantic_settings',\n    'anyio', 'structlog', 'tenacity', 'sqlalchemy', 'greenlet', 'win32timezone'\n]\n\nbackend_submodules = collect_submodules('web_service.backend')\nhiddenimports = list(set(core_imports + backend_submodules))\n\nprint(f\"Core imports:           {len(core_imports)}\")\nprint(f\"Backend submodules:     {len(backend_submodules)}\")\nprint(f\"Total hidden imports:   {len(hiddenimports)}\")\n\n# ===== ANALYSIS =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"CREATING PYINSTALLER ANALYSIS\")\nprint(\"=\"*70)\n\na = Analysis(\n    [str(main_py)],\n    pathex=[str(project_root), str(backend_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    cipher=block_cipher,\n    noarchive=False,\n)\n\nprint(f\"[OK] Analysis created\")\nprint(f\"   Scripts:       {len(a.scripts)}\")\nprint(f\"   Pure modules:  {len(a.pure)}\")\nprint(f\"   Binaries:      {len(a.binaries)}\")\nprint(f\"   Data files:    {len(a.datas)}\")\n\n# ===== BUILD =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"BUILDING EXECUTABLE\")\nprint(\"=\"*70)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.zipfiles, a.datas, [],\n    name='fortuna-monolith',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    runtime_tmpdir=None,\n    console=True,\n    disable_windowed_traceback=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n    icon=None,\n)\n\ncoll = COLLECT(\n    exe, a.binaries, a.zipfiles, a.datas,\n    strip=False,\n    upx=True,\n    name='fortuna-monolith'\n)\n\nprint(f\"[OK] Spec file complete!\")\nprint(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "fortuna_launcher.py": "#!/usr/bin/env python3\n\"\"\"\nFortuna Faucet - Enhanced Standalone Launcher for Windows 10 Home\nNo Docker, no special permissions, just pure Python magic\nRun this file and your browser opens automatically with all the bells and whistles\n\"\"\"\n\nimport sys\nimport os\nimport subprocess\nimport threading\nimport time\nimport webbrowser\nimport socket\nimport json\nfrom pathlib import Path\nfrom typing import Optional\nfrom datetime import datetime\n\n# ====================================================================\n# CONFIGURATION\n# ====================================================================\nAPP_NAME = \"Fortuna Faucet\"\nAPP_VERSION = \"3.1.0\"\nDEFAULT_HOST = \"127.0.0.1\"\nDEFAULT_PORT = 8000\nBACKEND_STARTUP_TIMEOUT = 15\nHEALTH_CHECK_ATTEMPTS = 30\nLOG_DIR = Path(\"logs\")\nLOG_DIR.mkdir(exist_ok=True)\n\n# ====================================================================\n# COLORS FOR WINDOWS CONSOLE\n# ====================================================================\nclass Colors:\n    \"\"\"ANSI color codes\"\"\"\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKCYAN = '\\033[96m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n    RESET = '\\033[0m'\n\n# Try to enable ANSI colors on Windows 10\ntry:\n    import ctypes\n    kernel32 = ctypes.windll.kernel32\n    kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)\nexcept:\n    pass\n\n# ====================================================================\n# LOGGING\n# ====================================================================\nclass Logger:\n    \"\"\"Dual logging to console and file\"\"\"\n    def __init__(self):\n        self.log_file = LOG_DIR / f\"fortuna_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n\n    def write(self, level: str, message: str):\n        \"\"\"Write to both console and file\"\"\"\n        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n        log_line = f\"[{timestamp}] [{level}] {message}\"\n\n        with open(self.log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(log_line + \"\\n\")\n\nlogger = Logger()\n\n# ====================================================================\n# HELPER FUNCTIONS\n# ====================================================================\ndef print_banner():\n    \"\"\"Print welcome banner\"\"\"\n    banner = f\"\"\"\n{Colors.BOLD}{Colors.OKGREEN}\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                            \u2551\n\u2551              \ud83d\udc34  {APP_NAME} v{APP_VERSION}  \ud83d\udc34              \u2551\n\u2551         Enhanced Launcher - Windows 10 Home Ready         \u2551\n\u2551                                                            \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n{Colors.ENDC}\n\"\"\"\n    print(banner)\n\ndef print_success(msg: str, icon: str = \"\u2713\"):\n    \"\"\"Print success message\"\"\"\n    output = f\"{Colors.OKGREEN}{icon}{Colors.ENDC} {msg}\"\n    print(output)\n    logger.write(\"SUCCESS\", msg)\n\ndef print_warning(msg: str, icon: str = \"\u26a0\"):\n    \"\"\"Print warning message\"\"\"\n    output = f\"{Colors.WARNING}{icon}{Colors.ENDC} {msg}\"\n    print(output)\n    logger.write(\"WARNING\", msg)\n\ndef print_error(msg: str, icon: str = \"\u2717\"):\n    \"\"\"Print error message\"\"\"\n    output = f\"{Colors.FAIL}{icon}{Colors.ENDC} {msg}\"\n    print(output)\n    logger.write(\"ERROR\", msg)\n\ndef print_info(msg: str, icon: str = \"\u2139\"):\n    \"\"\"Print info message\"\"\"\n    output = f\"{Colors.OKBLUE}{icon}{Colors.ENDC} {msg}\"\n    print(output)\n    logger.write(\"INFO\", msg)\n\ndef print_step(step_num: int, total: int, msg: str):\n    \"\"\"Print step counter\"\"\"\n    output = f\"\\n{Colors.BOLD}[{step_num}/{total}] {msg}{Colors.ENDC}\"\n    print(output)\n    logger.write(\"STEP\", f\"[{step_num}/{total}] {msg}\")\n\ndef print_section(title: str):\n    \"\"\"Print section divider\"\"\"\n    output = f\"\\n{Colors.BOLD}{Colors.OKCYAN}{'\u2500' * 60}{Colors.ENDC}\"\n    print(output)\n    print(f\"{Colors.BOLD}{Colors.OKCYAN}{title}{Colors.ENDC}\")\n    print(f\"{Colors.BOLD}{Colors.OKCYAN}{'\u2500' * 60}{Colors.ENDC}\\n\")\n\n# ====================================================================\n# ENVIRONMENT CHECKS\n# ====================================================================\ndef check_python_version() -> bool:\n    \"\"\"Check if Python version is compatible\"\"\"\n    if sys.version_info < (3, 10):\n        print_error(f\"Python 3.10+ required, you have {sys.version_info.major}.{sys.version_info.minor}\")\n        return False\n    print_success(f\"Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n    return True\n\ndef check_project_structure() -> bool:\n    \"\"\"Check if we're in the right directory\"\"\"\n    required_dirs = [\n        \"web_service/backend\",\n        \"web_platform/frontend\"\n    ]\n    required_files = [\n        \"web_service/backend/requirements.txt\",\n        \"web_platform/frontend/package.json\"\n    ]\n\n    print_info(\"Checking project structure...\")\n    all_good = True\n    for d in required_dirs:\n        if Path(d).exists():\n            print_success(f\"Found: {d}\")\n        else:\n            print_error(f\"Missing: {d}\")\n            all_good = False\n\n    for f in required_files:\n        if Path(f).exists():\n            print_success(f\"Found: {f}\")\n        else:\n            print_error(f\"Missing: {f}\")\n            all_good = False\n\n    return all_good\n\ndef check_port_available(port: int) -> bool:\n    \"\"\"Check if port is available\"\"\"\n    try:\n        sock = socket.create_connection((\"127.0.0.1\", port), timeout=1)\n        sock.close()\n        print_error(f\"Port {port} is already in use by another application\")\n        return False\n    except (socket.timeout, ConnectionRefusedError, OSError):\n        print_success(f\"Port {port} is available\")\n        return True\n\n# ====================================================================\n# DEPENDENCY CHECK & INSTALL\n# ====================================================================\ndef check_and_install_dependencies() -> bool:\n    \"\"\"Check if dependencies are installed, install if needed\"\"\"\n    print_info(\"Checking Python dependencies...\")\n\n    required_packages = {\n        \"fastapi\": \"FastAPI web framework\",\n        \"uvicorn\": \"ASGI server\",\n        \"pydantic\": \"Data validation\",\n    }\n\n    missing = []\n    for package, description in required_packages.items():\n        try:\n            __import__(package)\n            print_success(f\"{description} (installed)\")\n        except ImportError:\n            print_warning(f\"{description} (NOT installed)\")\n            missing.append(package)\n\n    if not missing:\n        print_success(\"All core dependencies satisfied!\")\n        return True\n\n    print()\n    print_info(f\"Installing {len(missing)} missing package(s)...\")\n    print_info(\"This may take 2-3 minutes on first run...\")\n    print()\n\n    try:\n        subprocess.run(\n            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\"],\n            check=True,\n            capture_output=True,\n            timeout=120\n        )\n\n        subprocess.run(\n            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + missing,\n            check=True,\n            capture_output=True,\n            timeout=300\n        )\n        print_success(\"Dependencies installed successfully!\")\n        return True\n    except subprocess.CalledProcessError as e:\n        print_error(f\"Failed to install dependencies: {e}\")\n        print_info(\"Try running manually in PowerShell:\")\n        print(f\"  python -m pip install -r web_service/backend/requirements.txt\")\n        logger.write(\"ERROR\", f\"Dependency installation failed: {e}\")\n        return False\n    except subprocess.TimeoutExpired:\n        print_error(\"Installation timed out (took too long)\")\n        return False\n\n# ====================================================================\n# FRONTEND BUILD\n# ====================================================================\ndef build_frontend() -> bool:\n    \"\"\"Build Next.js frontend if needed\"\"\"\n    frontend_dir = Path(\"web_platform/frontend\")\n    build_dir = frontend_dir / \"out\"\n\n    if build_dir.exists() and (build_dir / \"index.html\").exists():\n        print_success(\"Frontend already built\")\n        return True\n\n    print_info(\"Frontend build required...\")\n\n    # Check for Node.js\n    try:\n        subprocess.run([\"npm\", \"--version\"], capture_output=True, timeout=5, check=True)\n    except:\n        print_warning(\"Node.js not found - frontend may not load properly\")\n        print_info(\"To fix: Install Node.js from https://nodejs.org/\")\n        logger.write(\"WARNING\", \"Node.js not found for frontend build\")\n        return True\n\n    print_info(\"Building frontend (this takes ~30 seconds)...\")\n    print_info(\"(Progress shown in logs)\")\n\n    try:\n        subprocess.run(\n            [\"npm\", \"ci\"],\n            cwd=str(frontend_dir),\n            capture_output=True,\n            timeout=120,\n            check=True\n        )\n        subprocess.run(\n            [\"npm\", \"run\", \"build\"],\n            cwd=str(frontend_dir),\n            capture_output=True,\n            timeout=180,\n            check=True\n        )\n        print_success(\"Frontend built successfully\")\n        return True\n    except subprocess.TimeoutExpired:\n        print_warning(\"Frontend build timed out, continuing anyway...\")\n        logger.write(\"WARNING\", \"Frontend build timed out\")\n        return True\n    except subprocess.CalledProcessError as e:\n        print_warning(f\"Frontend build failed: {e}\")\n        logger.write(\"WARNING\", f\"Frontend build failed: {e}\")\n        return True\n    except Exception as e:\n        print_warning(f\"Frontend build error: {e}\")\n        logger.write(\"WARNING\", f\"Frontend build error: {e}\")\n        return True\n\n# ====================================================================\n# BACKEND SERVER\n# ====================================================================\ndef start_backend() -> Optional[subprocess.Popen]:\n    \"\"\"Start the FastAPI backend server\"\"\"\n    print_info(\"Starting FastAPI server...\")\n\n    try:\n        process = subprocess.Popen(\n            [\n                sys.executable,\n                \"-m\", \"uvicorn\",\n                \"web_service.backend.main:app\",\n                \"--host\", DEFAULT_HOST,\n                \"--port\", str(DEFAULT_PORT),\n                \"--log-level\", \"info\"\n            ],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            bufsize=1\n        )\n\n        # Give it a moment to start\n        time.sleep(1)\n\n        if process.poll() is not None:\n            # Process exited already\n            stdout, stderr = process.communicate()\n            print_error(f\"Backend failed to start: {stderr[:200]}\")\n            logger.write(\"ERROR\", f\"Backend startup failed: {stderr}\")\n            return None\n\n        print_success(\"Backend server started\")\n        logger.write(\"SUCCESS\", \"Backend server started successfully\")\n        return process\n\n    except Exception as e:\n        print_error(f\"Failed to start backend: {e}\")\n        logger.write(\"ERROR\", f\"Backend start exception: {e}\")\n        return None\n\ndef wait_for_backend_ready(max_retries: int = HEALTH_CHECK_ATTEMPTS) -> bool:\n    \"\"\"Wait for backend to respond to health check\"\"\"\n    import urllib.request\n    import urllib.error\n\n    print_info(\"Waiting for backend to be ready...\")\n\n    for attempt in range(max_retries):\n        try:\n            response = urllib.request.urlopen(\n                f\"http://{DEFAULT_HOST}:{DEFAULT_PORT}/api/health\",\n                timeout=2\n            )\n            if response.status == 200:\n                elapsed = attempt + 1\n                print_success(f\"Backend ready in {elapsed} second(s)\")\n                logger.write(\"SUCCESS\", f\"Backend health check passed in {elapsed}s\")\n                return True\n        except (urllib.error.URLError, urllib.error.HTTPError, Exception):\n            if attempt < max_retries - 1:\n                time.sleep(1)\n\n    print_error(\"Backend did not respond after 30 seconds\")\n    logger.write(\"ERROR\", \"Backend health check failed - no response after 30s\")\n    return False\n\n# ====================================================================\n# BROWSER LAUNCHER\n# ====================================================================\ndef open_browser():\n    \"\"\"Open browser to the application\"\"\"\n    url = f\"http://{DEFAULT_HOST}:{DEFAULT_PORT}\"\n    try:\n        print_info(f\"Opening browser at {url}...\")\n        webbrowser.open(url)\n        time.sleep(1)  # Give browser time to open\n        print_success(\"Browser opened!\")\n        logger.write(\"SUCCESS\", f\"Browser opened at {url}\")\n    except Exception as e:\n        print_warning(f\"Could not open browser automatically: {e}\")\n        print_info(f\"Please manually open: {url}\")\n        logger.write(\"WARNING\", f\"Browser auto-open failed: {e}\")\n\n# ====================================================================\n# SYSTEM INFO\n# ====================================================================\ndef print_system_info():\n    \"\"\"Print system information\"\"\"\n    print_section(\"System Information\")\n    print_success(f\"Python: {sys.version.split()[0]}\")\n    print_success(f\"Platform: {sys.platform}\")\n    print_success(f\"Current Directory: {Path.cwd()}\")\n    print_success(f\"Log Directory: {LOG_DIR.absolute()}\")\n    print()\n\n# ====================================================================\n# MAIN APPLICATION\n# ====================================================================\ndef main():\n    \"\"\"Main entry point\"\"\"\n    print_banner()\n    print_system_info()\n\n    # Step 1: Environment validation\n    print_step(1, 5, \"Validating environment...\")\n    if not check_python_version():\n        return 1\n    if not check_project_structure():\n        return 1\n    if not check_port_available(DEFAULT_PORT):\n        return 1\n    print()\n\n    # Step 2: Dependencies\n    print_step(2, 5, \"Installing dependencies...\")\n    if not check_and_install_dependencies():\n        return 1\n    print()\n\n    # Step 3: Frontend build\n    print_step(3, 5, \"Building frontend...\")\n    build_frontend()\n    print()\n\n    # Step 4: Start backend\n    print_step(4, 5, \"Starting backend server...\")\n    backend_process = start_backend()\n    if not backend_process:\n        return 1\n\n    if not wait_for_backend_ready():\n        backend_process.terminate()\n        logger.write(\"ERROR\", \"Application startup failed - health check timeout\")\n        return 1\n    print()\n\n    # Step 5: Open browser\n    print_step(5, 5, \"Launching browser...\")\n    open_browser()\n    print()\n\n    # Success!\n    print(f\"{Colors.BOLD}{Colors.OKGREEN}\")\n    print(\"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\")\n    print(\"\u2551                                                            \u2551\")\n    print(\"\u2551          \ud83c\udf89  FORTUNA IS RUNNING!  \ud83c\udf89                     \u2551\")\n    print(\"\u2551                                                            \u2551\")\n    print(f\"\u2551  Access your app at: http://{DEFAULT_HOST}:{DEFAULT_PORT:<5}                      \u2551\")\n    print(\"\u2551                                                            \u2551\")\n    print(f\"\u2551  Log file: {LOG_DIR / 'fortuna_*.log':<40}  \u2551\")\n    print(\"\u2551                                                            \u2551\")\n    print(\"\u2551  Press Ctrl+C to stop the server                          \u2551\")\n    print(\"\u2551                                                            \u2551\")\n    print(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\")\n    print(f\"{Colors.ENDC}\")\n    print()\n\n    # Keep running\n    try:\n        while True:\n            time.sleep(0.1)\n    except KeyboardInterrupt:\n        print()\n        print_info(\"Shutting down gracefully...\")\n        backend_process.terminate()\n        try:\n            backend_process.wait(timeout=5)\n        except subprocess.TimeoutExpired:\n            backend_process.kill()\n        print_success(\"Fortuna stopped successfully\")\n        logger.write(\"SUCCESS\", \"Application stopped gracefully by user\")\n        return 0\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n",
    "pg_schemas/quarantine_races.sql": "CREATE TABLE IF NOT EXISTS quarantine_races (\n    quarantine_id SERIAL PRIMARY KEY,\n    race_id VARCHAR(100),\n    track_name VARCHAR(100),\n    race_number INT,\n    post_time TIMESTAMP WITH TIME ZONE,\n    source VARCHAR(50),\n    raw_data_json JSONB, -- Store the original raw data for inspection\n    quarantine_reason TEXT, -- Reason for failing validation\n    collection_timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);",
    "requirements-dev.in": "#\n# Fortuna Faucet - High-Level Development & Testing Dependencies\n# This file is the source of truth for development dependencies.\n# Run 'pip-compile' to generate requirements-dev.txt.\n#\n\n# --- Core Testing Frameworks ---\npytest\npytest-asyncio\nfakeredis[lua]\nrespx\nplaywright\n\n# --- Code Quality & Linting ---\nblack\n# ruff is often used with black\n\n# --- Analysis & Notebooks ---\n# pandas is already in the main requirements.in\naltair\npydeck\nstreamlit\ntabula-py\n\n# --- Git & Versioning ---\nGitPython\n\n# --- Security & Auditing ---\npip-audit\n",
    "run_web_service.py": "# run_web_service.py\n# This is the single, authoritative entry point for the PyInstaller-built web service.\nimport sys\nimport os\nimport uvicorn\nimport multiprocessing\nimport asyncio\nimport traceback\n\ndef main():\n    \"\"\"\n    Configures sys.path and launches the Uvicorn server for the web service.\n    This script is designed to be the single entry point for the PyInstaller executable.\n    \"\"\"\n    # Required for PyInstaller on Windows when using multiprocessing.\n    multiprocessing.freeze_support()\n\n    # Path configuration for both frozen and development environments.\n    if getattr(sys, 'frozen', False):\n        project_root = os.path.dirname(sys.executable)\n        sys.path.insert(0, project_root)\n        if hasattr(sys, '_MEIPASS'):\n             sys.path.insert(0, sys._MEIPASS)\n    else:\n        project_root = os.path.abspath(os.path.dirname(__file__))\n        if project_root not in sys.path:\n            sys.path.insert(0, project_root)\n\n    # CRITICAL FIX FOR PYINSTALLER on WINDOWS: Force event loop policy\n    if sys.platform == \"win32\" and getattr(sys, 'frozen', False):\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n        print(\"[BOOT] Applied WindowsSelectorEventLoopPolicy for PyInstaller\", file=sys.stderr)\n\n    # Explicit server config and run with robust error handling\n    try:\n        print(\"[BOOT] Configuring Uvicorn server...\", file=sys.stderr)\n        # Use the port from the CI environment, defaulting to 8102\n        port = int(os.getenv(\"FORTUNA_PORT\", 8102))\n        host = os.getenv(\"UVICORN_HOST\", \"127.0.0.1\")\n\n        # Use the shared, robust port checker\n        from python_service.port_check import check_port_and_exit_if_in_use\n        check_port_and_exit_if_in_use(port, host)\n        print(f\"[BOOT] Port {port} is available. Proceeding with server startup.\", file=sys.stderr)\n\n        config = uvicorn.Config(\n            \"web_service.backend.api:app\",\n            host=host,\n            port=port,\n            log_level=\"info\",\n            workers=1\n        )\n\n        server = uvicorn.Server(config)\n\n        print(f\"[BOOT] Starting server on port {port}...\", file=sys.stderr)\n        server.run()\n        print(\"[BOOT] Server stopped.\", file=sys.stderr)\n\n    except Exception as e:\n        # If any exception occurs during startup, log it to a file for forensics.\n        # This is critical for diagnosing silent crashes in the CI environment.\n        error_log_path = \"fatal_boot_error.log\"\n        print(f\"[FATAL BOOT ERROR] Server failed to start: {e}\", file=sys.stderr)\n        with open(error_log_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"A fatal error occurred during Uvicorn server startup:\\n\")\n            f.write(f\"Exception Type: {type(e).__name__}\\n\")\n            f.write(f\"Exception Args: {e.args}\\n\\n\")\n            traceback.print_exc(file=f)\n        print(f\"[FATAL BOOT ERROR] Full traceback written to {error_log_path}\", file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/generate_manifests.py": "# scripts/generate_manifests.py\nimport json\nimport os\nfrom pathlib import Path\n\n# --- Configuration ---\nROOT_DIR = Path(\".\")\nOUTPUT_DIR = Path(\".\")\nNUM_MANIFESTS = 5 # We will create 5 balanced manifests\n\n# --- Inclusion/Exclusion Rules ---\n# This script is now comprehensive. Instead of a narrow include list,\n# it scans everything and uses a more precise exclusion list.\nINCLUDE_ONLY_DIRS = None # Deactivated: We now scan all directories by default\n\nEXCLUDE_DIRS = {\n    # Standard git/ide/v-env exclusions\n    \".git\", \".idea\", \".vscode\", \"node_modules\", \".next\", \".venv\",\n    # Build artifacts and caches\n    \"dist\", \"build\", \"__pycache__\", \".pytest_cache\", \"out\", \"build_wix\",\n    # Agent-specific/Volatile directories\n    \"attic\", \"installer\", \"ReviewableJSON\", \"jules-scratch\",\n    # Legacy code not relevant to the current monolith\n    \"PREV_src\", \"python_service\",\n}\n\nEXCLUDE_FILES_BY_EXTENSION = {\n    # Archives and logs\n    \".zip\", \".json\", \".log\", \".db\", \".sqlite3\",\n    # Binary/Image formats not useful for LLM context\n    \".png\", \".ico\", \".bmp\", \".exe\", \".dll\", \".pyd\", \".pdf\",\n    # Deactivated workflows (keep them for history, but not for active context)\n    \".ymlx\"\n}\n\n\ndef get_all_project_files():\n    \"\"\"\n    Walks the entire project directory to find all relevant files for archiving,\n    respecting a detailed set of exclusion rules.\n    \"\"\"\n    all_files_with_size = []\n    print(\"\\n--- Starting Comprehensive File Audit ---\")\n    scanned_count = 0\n    included_count = 0\n\n    for root, dirs, files in os.walk(ROOT_DIR, topdown=True):\n        current_path = Path(root)\n\n        # 1. Directory Exclusion: Prune entire directory subtrees\n        dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS and not d.endswith('.egg-info')]\n\n        for name in files:\n            scanned_count += 1\n            file_path = current_path / name\n\n            # 2. Filename/Extension Exclusion\n            if name.startswith(('MANIFEST_PART', 'FORTUNA_ALL_PART', '.env')):\n                continue\n            if file_path.suffix in EXCLUDE_FILES_BY_EXTENSION:\n                continue\n\n            # Special case: allow '.spec' files which are critical configs\n            if file_path.suffix == '.spec' and name not in ['api.spec']:\n                 pass # keep it\n            elif file_path.suffix in ['.spec']:\n                 continue # exclude other .spec files\n\n            try:\n                posix_path = str(file_path.as_posix())\n                size = os.path.getsize(file_path)\n                all_files_with_size.append((posix_path, size))\n                included_count += 1\n            except FileNotFoundError:\n                print(f\"[WARNING] File not found during scan: {file_path}\")\n                continue\n\n    print(f\"Scanned {scanned_count} files, included {included_count} for manifest.\")\n    print(\"--- File Audit Complete ---\\n\")\n    return all_files_with_size\n\n\ndef balance_files_by_size(files_with_size, num_bins):\n    \"\"\"\n    Distributes files into a specified number of bins, balancing by size and count.\n    Uses a hybrid greedy and round-robin approach for better distribution.\n    \"\"\"\n    # Define categories for more granular balancing\n    categories = {\n        'large': [], 'medium': [], 'small': [], 'config': [], 'docs': [],\n        'workflows': [], 'scripts': [], 'source': []\n    }\n\n    # Categorize files based on extension and size\n    for path, size in files_with_size:\n        ext = Path(path).suffix.lower()\n        if 'github/workflows' in path:\n            categories['workflows'].append((path, size))\n        elif ext in ['.md', '.txt']:\n            categories['docs'].append((path, size))\n        elif ext in ['.json', '.toml', '.ini', '.spec', '.lock']:\n            categories['config'].append((path, size))\n        elif ext == '.py' and 'scripts' in path:\n            categories['scripts'].append((path, size))\n        elif ext in ['.py', '.js', '.ts', '.tsx', '.css', '.html', '.wxs']:\n            if size > 50 * 1024:  # Over 50KB\n                categories['large'].append((path, size))\n            elif size > 10 * 1024: # Over 10KB\n                categories['medium'].append((path, size))\n            else:\n                categories['small'].append((path, size))\n        else:\n            categories['source'].append((path, size))\n\n    bins = [[] for _ in range(num_bins)]\n    bin_sizes = [0] * num_bins\n\n    # Distribute large files first using greedy approach\n    for category in ['large', 'medium']:\n        # Sort descending to place largest files first\n        categories[category].sort(key=lambda x: x[1], reverse=True)\n        for path, size in categories[category]:\n            min_bin_index = bin_sizes.index(min(bin_sizes))\n            bins[min_bin_index].append(path)\n            bin_sizes[min_bin_index] += size\n\n    # Distribute remaining files using round-robin to balance file count\n    current_bin = 0\n    for category in ['small', 'config', 'docs', 'workflows', 'scripts', 'source']:\n        # Sort alphabetically for consistent distribution\n        categories[category].sort(key=lambda x: x[0])\n        for path, size in categories[category]:\n            bins[current_bin].append(path)\n            bin_sizes[current_bin] += size\n            current_bin = (current_bin + 1) % num_bins\n\n    # Print the balancing results for verification\n    print(\"--- Manifest Balancing Results (Enhanced) ---\")\n    for i, (file_list, total_size) in enumerate(zip(bins, bin_sizes)):\n        print(\n            f\" Manifest {i+1}: {len(file_list):>4} files, \"\n            f\"Total size: {total_size / 1024 / 1024:>6.2f} MB\"\n        )\n    print(\"------------------------------------------\")\n\n    return bins\n\n\ndef main():\n    \"\"\"Generate balanced manifest files based on file size.\"\"\"\n    print(\"--- Starting Manifest Generation (Size-Balanced) ---\")\n    all_files = get_all_project_files()\n    print(f\"Found {len(all_files)} total project files to consider.\")\n\n    balanced_manifests = balance_files_by_size(all_files, NUM_MANIFESTS)\n\n    # Write the updated manifest files\n    for i, file_list in enumerate(balanced_manifests):\n        manifest_name = f\"MANIFEST_PART{i+1}.json\"\n        output_path = OUTPUT_DIR / manifest_name\n        sorted_files = sorted(file_list) # Sort alphabetically for consistency\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(sorted_files, f, indent=4)\n        print(f\"\u2705 Wrote {len(sorted_files)} entries to {output_path}\")\n\n    print(\"\\n[SUCCESS] All manifest files have been generated and balanced.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/launch-monolith.ps1": "# launch-monolith.ps1 - Lightweight launcher for fortuna-monolith.exe\nparam(\n    [string]$ExePath = \"dist/fortuna-monolith/fortuna-monolith.exe\",  # Path to your PyInstaller EXE\n    [int]$Port = 8000,\n    [switch]$AutoRestart\n)\n\n# Set environment variables (equivalent to Docker env)\n$env:FORTUNA_PORT = $Port\n$env:FORTUNA_MODE = \"monolith\"  # Custom flag for your app\n\n# Pre-launch checks (lightweight health check)\nfunction Test-PortFree {\n    param([int]$Port)\n    try {\n        $tcp = New-Object System.Net.Sockets.TcpClient\n        $tcp.Connect(\"127.0.0.1\", $Port)\n        $tcp.Close()\n        return $false  # Port in use\n    } catch {\n        return $true   # Port free\n    }\n}\n\nif (!(Test-Path $ExePath)) {\n    Write-Error \"Monolith EXE not found at $ExePath. Build it first with PyInstaller.\"\n    exit 1\n}\n\nif (!(Test-PortFree $Port)) {\n    Write-Error \"Port $Port is in use. Close conflicting app or change port.\"\n    exit 1\n}\n\n# Launch the EXE (in background, with logging)\nWrite-Host \"Launching Fortuna Monolith on port $Port...\"\n$process = Start-Process -FilePath $ExePath -ArgumentList \"--host 127.0.0.1 --port $Port\" -NoNewWindow -PassThru -RedirectStandardOutput \"monolith.log\" -RedirectStandardError \"monolith-error.log\"\n\n# Optional auto-restart loop (mimics Docker restart policies)\nif ($AutoRestart) {\n    while ($true) {\n        Start-Sleep 5  # Poll every 5 seconds\n        if ($process.HasExited) {\n            Write-Warning \"Monolith crashed (exit code $($process.ExitCode)). Restarting...\"\n            $process = Start-Process -FilePath $ExePath -ArgumentList \"--host 127.0.0.1 --port $Port\" -NoNewWindow -PassThru\n        }\n    }\n} else {\n    Write-Host \"Monolith launched successfully. Waiting for server to initialize...\"\n    Start-Sleep -Seconds 3 # Give the server a moment to start up before opening the browser\n\n    $url = \"http://127.0.0.1:$Port\"\n    Write-Host \"Opening application at $url in your default browser.\"\n    Start-Process $url\n\n    Write-Host \"Application is running. Press Ctrl+C in this window to stop the server.\"\n    Wait-Process -Id $process.Id\n}\n",
    "scripts/prepare_minimal_build.py": "# scripts/prepare_minimal_build.py\nimport os\nimport shutil\n\n# This script prepares the source tree for a 'minimal' build.\n# A minimal build includes only the core application and a small, curated\n# set of essential data adapters, excluding the larger, more specialized ones.\n\nADAPTERS_TO_KEEP = [\n    \"__init__.py\",\n    \"base_adapter.py\",\n    \"handler_factory.py\",\n    # --- Essential Adapters ---\n    \"betfair_adapter.py\",\n    \"sporting_life_adapter.py\",\n    \"racing_post_adapter.py\",\n]\n\n\ndef main():\n    \"\"\"\n    Removes non-essential adapter files from the python_service/adapters\n    directory to create a minimal build artifact.\n    \"\"\"\n    adapters_dir = os.path.join(\"python_service\", \"adapters\")\n    if not os.path.isdir(adapters_dir):\n        print(f\"[ERROR] Adapters directory not found at: {adapters_dir}\")\n        exit(1)\n\n    print(f\"Scanning adapters directory: {adapters_dir}\")\n    removed_count = 0\n    for filename in os.listdir(adapters_dir):\n        if filename not in ADAPTERS_TO_KEEP:\n            file_path = os.path.join(adapters_dir, filename)\n            try:\n                if os.path.isfile(file_path):\n                    os.remove(file_path)\n                    print(f\"  - Removed file: {filename}\")\n                    removed_count += 1\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n                    print(f\"  - Removed directory: {filename}\")\n                    removed_count += 1\n            except OSError as e:\n                print(f\"[ERROR] Failed to remove {file_path}: {e}\")\n                exit(1)\n\n    print(f\"\\nMinimal build preparation complete. Removed {removed_count} non-essential adapter(s).\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "start_podman.bat": "@echo off\nREM ============================================================\nREM Fortuna Faucet - Podman Launcher for Windows\nREM A simple, friendly way to start your racing analysis engine\nREM ============================================================\n\nsetlocal enabledelayedexpansion\n\nREM Colors and styling\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83d\udc34  FORTUNA FAUCET LAUNCHER (Podman) \ud83d\udc34         \u2551\necho \u2551          Racing Strategy Analysis Engine                  \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM ============================================================\nREM STEP 1: Check if Podman is installed\nREM ============================================================\necho [1/5] Checking for Podman installation...\npodman --version >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Podman is not installed or not in PATH\n    echo.\n    echo To use Fortuna, you need Podman Desktop:\n    echo https://podman-desktop.io/\n    echo.\n    echo After installing Podman, restart your computer and try again.\n    echo.\n    pause\n    exit /b 1\n)\n\nfor /f \"tokens=*\" %%i in ('podman --version') do set PODMAN_VERSION=%%i\necho \u2713 Found: %PODMAN_VERSION%\necho.\n\nREM ============================================================\nREM STEP 2: Check if Podman machine is running\nREM ============================================================\necho [2/5] Checking if Podman machine is running...\npodman ps >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Podman machine is not running\n    echo.\n    echo Please:\n    echo 1. Open \"Podman Desktop\" from your Start Menu\n    echo 2. Make sure your Podman machine is started\n    echo 3. Then run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\necho \u2713 Podman machine is running\necho.\n\nREM ============================================================\nREM STEP 3: Pull latest image\nREM ============================================================\necho [3/5] Pulling latest Fortuna image from Docker Hub...\necho (This may take a minute on first run)\necho.\npodman pull docker.io/masonj0/fortuna-faucet:latest\nif errorlevel 1 (\n    echo.\n    echo \u26a0 Warning: Could not pull from Docker Hub\n    echo Checking for local image...\n    podman image inspect masonj0/fortuna-faucet:latest >nul 2>&1\n    if errorlevel 1 (\n        echo \u2717 ERROR: No local image found\n        echo Please check your internet connection and try again.\n        echo.\n        pause\n        exit /b 1\n    )\n    echo \u2713 Using existing local image\n)\necho \u2713 Image ready\necho.\n\nREM ============================================================\nREM STEP 4: Start container\nREM ============================================================\necho [4/5] Starting Fortuna container...\necho.\n\nREM Stop any existing container (ignore errors)\npodman stop fortuna-faucet >nul 2>&1\npodman rm fortuna-faucet >nul 2>&1\n\nREM Create data directories if they don't exist\nif not exist \"data\" mkdir data\nif not exist \"logs\" mkdir logs\n\nREM Start container with proper quoting for paths with spaces\npodman run -d ^\n  --name fortuna-faucet ^\n  -p 8000:8000 ^\n  -v \"%cd%\\data:/app/web_service/backend/data\" ^\n  -v \"%cd%\\logs:/app/web_service/backend/logs\" ^\n  docker.io/masonj0/fortuna-faucet:latest\n\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Failed to start container\n    echo.\n    echo Try these troubleshooting steps:\n    echo 1. Open Podman Desktop\n    echo 2. Make sure your Podman machine is running\n    echo 3. Open Command Prompt and run: podman ps\n    echo    (This tests if Podman is working)\n    echo 4. Run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Container started successfully\necho.\n\nREM ============================================================\nREM STEP 5: Wait and verify startup\nREM ============================================================\necho [5/5] Waiting for application to start...\ntimeout /t 3 /nobreak\n\nREM Check if container is still running\npodman inspect fortuna-faucet >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Container exited unexpectedly\n    echo.\n    echo Showing container logs for debugging:\n    echo.\n    podman logs fortuna-faucet\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Application is ready!\necho.\n\nREM ============================================================\nREM SUCCESS - Open browser and show logs\nREM ============================================================\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83c\udf89  FORTUNA IS RUNNING! (Podman) \ud83c\udf89           \u2551\necho \u2551                                                            \u2551\necho \u2551  Your racing analysis engine is ready at:                \u2551\necho \u2551                                                            \u2551\necho \u2551          http://localhost:8000                            \u2551\necho \u2551                                                            \u2551\necho \u2551  Opening browser now...                                   \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM Open browser\nstart http://localhost:8000\n\nREM Small delay to let browser open\ntimeout /t 2 /nobreak\n\nREM Show logs\necho.\necho \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\necho \u2502 Live Application Logs (Ctrl+C to stop)                    \u2502\necho \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\necho.\n\npodman logs -f fortuna-faucet\n\nREM Cleanup on exit\necho.\necho Stopping Fortuna...\npodman stop fortuna-faucet >nul 2>&1\necho \u2713 Fortuna stopped\n\nexit /b 0\n",
    "tests/adapters/test_greyhound_adapter.py": "from datetime import date\nfrom datetime import datetime\nfrom unittest.mock import AsyncMock\n\nimport pytest\n\nfrom python_service.adapters.greyhound_adapter import GreyhoundAdapter\nfrom tests.conftest import get_test_settings\n\n\n@pytest.fixture\ndef test_settings():\n    \"\"\"Provides a valid Settings object for testing.\"\"\"\n    return get_test_settings()\n\n\n@pytest.mark.asyncio\nasync def test_get_races_parses_correctly(test_settings):\n    \"\"\"\n    Tests that the GreyhoundAdapter correctly parses a valid API response via get_races.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n\n    mock_api_response = {\n        \"cards\": [\n            {\n                \"track_name\": \"Test Track\",\n                \"races\": [\n                    {\n                        \"race_id\": \"test_race_123\",\n                        \"race_number\": 1,\n                        \"start_time\": int(datetime.now().timestamp()),\n                        \"runners\": [\n                            {\n                                \"dog_name\": \"Rapid Rover\",\n                                \"trap_number\": 1,\n                                \"odds\": {\"win\": \"2.5\"},\n                            },\n                            {\n                                \"dog_name\": \"Swift Sprint\",\n                                \"trap_number\": 2,\n                                \"scratched\": True,\n                            },\n                            {\n                                \"dog_name\": \"Lazy Larry\",\n                                \"trap_number\": 3,\n                                \"odds\": {\"win\": \"10.0\"},\n                            },\n                        ],\n                    }\n                ],\n            }\n        ]\n    }\n    adapter._fetch_data = AsyncMock(return_value=mock_api_response)\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert len(races) == 1\n    race = races[0]\n    assert race.id == \"greyhound_test_race_123\"\n    assert race.venue == \"Test Track\"\n    assert len(race.runners) == 2  # One was scratched\n\n    runner1 = race.runners[0]\n    assert runner1.name == \"Rapid Rover\"\n    assert runner1.number == 1\n    assert runner1.odds[\"Greyhound Racing\"].win == 2.5\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_empty_response(test_settings):\n    \"\"\"\n    Tests that the GreyhoundAdapter handles an empty API response gracefully.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(return_value={\"cards\": []})\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert races == []\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_fetch_failure(test_settings):\n    \"\"\"\n    Tests that get_races returns an empty list when _fetch_data returns None.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(return_value=None)\n\n    # ACT\n    races = [race async for race in adapter.get_races(today)]\n\n    # ASSERT\n    assert races == []\n",
    "tests/analyzers/test_trifecta_analyzer.py": "# Dedicated test suite for the TrifectaAnalyzer, resurrected and expanded.\nfrom datetime import datetime\n\nimport pytest\n\nfrom python_service.analyzer import TrifectaAnalyzer\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\n\n@pytest.fixture\ndef analyzer():\n    return TrifectaAnalyzer()\n\n\n@pytest.fixture\ndef runners():\n    return []\n\n\n@pytest.fixture\ndef create_race(runners):\n    return Race(\n        id=\"test-race\",\n        venue=\"TEST\",\n        race_number=1,\n        start_time=datetime.now(),\n        runners=runners,\n        source=\"test\",\n    )\n\n\ndef test_analyzer_name(analyzer):\n    assert analyzer.name == \"trifecta_analyzer\"\n\n\n# Test cases resurrected from legacy scorer and logic tests\ndef test_qualifies_with_exactly_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is True\n\n\ndef test_qualifies_with_more_than_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds4 = {\"TestOdds\": OddsData(win=Decimal(\"6.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=False),\n        Runner(number=4, name=\"D\", odds=odds4, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is True\n\n\n# New test cases for edge-case hardening\ndef test_rejects_with_fewer_than_three_runners(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n    ]\n    assert analyzer.is_race_qualified(create_race) is False\n\n\ndef test_rejects_if_scratched_runners_reduce_field_below_three(analyzer, create_race):\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds3 = {\"TestOdds\": OddsData(win=Decimal(\"5.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    create_race.runners = [\n        Runner(number=1, name=\"A\", odds=odds1, scratched=False),\n        Runner(number=2, name=\"B\", odds=odds2, scratched=False),\n        Runner(number=3, name=\"C\", odds=odds3, scratched=True),  # Scratched\n    ]\n    assert analyzer.is_race_qualified(create_race) is False\n\n\ndef test_handles_empty_runner_list(analyzer, create_race):\n    race = create_race\n    race.runners = []\n    assert analyzer.is_race_qualified(race) is False\n\n\ndef test_handles_none_race_object(analyzer):\n    assert analyzer.is_race_qualified(None) is False\n",
    "tests/fixtures/twinspires_sample.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <title>Race Results - Twinspires</title>\n</head>\n<body>\n    <div id=\"race-card\">\n        <h1>Race 5 - Churchill Downs - 2025-10-26</h1>\n        <div class=\"race-details\">\n            <span class=\"post-time\">Post Time: 04:30 PM</span>\n            <span class=\"distance\">1 Mile</span>\n            <span class=\"surface\">Dirt</span>\n        </div>\n        <ul class=\"runners-list\">\n            <li class=\"runner\">\n                <span class=\"runner-number\">1</span>\n                <span class=\"runner-name\">Braveheart</span>\n                <span class=\"runner-odds\">5/2</span>\n            </li>\n            <li class=\"runner\">\n                <span class=\"runner-number\">2</span>\n                <span class=\"runner-name\">Speedster</span>\n                <span class=\"runner-odds\">10/1</span>\n            </li>\n            <li class=\"runner scratched\">\n                <span class=\"runner-number\">3</span>\n                <span class=\"runner-name\">Steady Eddy</span>\n                <span class=\"runner-odds\">SCR</span>\n            </li>\n             <li class=\"runner\">\n                <span class=\"runner-number\">4</span>\n                <span class=\"runner-name\">Gallant Gus</span>\n                <span class=\"runner-odds\">3/1</span>\n            </li>\n        </ul>\n    </div>\n</body>\n</html>\n",
    "tests/test_engine.py": "import pytest\nfrom unittest.mock import AsyncMock, MagicMock, patch\nfrom datetime import datetime, date\nfrom decimal import Decimal\nfrom tests.conftest import create_mock_race, get_test_settings\n\n# Import your actual classes\nfrom python_service.engine import OddsEngine\nfrom python_service.adapters.base_adapter_v3 import BaseAdapterV3\n\n@pytest.mark.asyncio\nasync def test_engine_initialization():\n    \"\"\"Test that the engine loads config correctly.\"\"\"\n    engine = OddsEngine(config=get_test_settings())\n    assert engine.config.API_KEY == \"test-override-key-123\"\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine._time_adapter_fetch\")\nasync def test_fetch_all_odds_success(mock_fetch, clear_cache):\n    \"\"\"Test happy path: fetching odds from a single adapter.\"\"\"\n    # ARRANGE\n    settings = get_test_settings()\n    settings.CACHE_ENABLED = False\n    engine = OddsEngine(config=settings)\n\n    today = datetime.now()\n    mock_race = create_mock_race(\n        \"MockSource\", \"Churchill Downs\", 1, today,\n        [{\"number\": 1, \"name\": \"Secretariat\", \"odds\": \"1.5\"}]\n    )\n\n    # This is the new way to mock the data\n    mock_fetch.return_value = (\"MockSource\", {\"races\": [mock_race], \"source_info\": {\"name\": \"MockSource\", \"status\": \"SUCCESS\", \"races_fetched\": 1, \"fetch_duration\": 0.1}}, 0.1)\n\n    # We still need to give the engine an adapter to iterate over\n    mock_adapter = MagicMock(spec=BaseAdapterV3)\n    mock_adapter.source_name = \"MockSource\"\n    engine.adapters = [mock_adapter]\n\n    # ACT\n    result = await engine.fetch_all_odds(date.today().strftime(\"%Y-%m-%d\"))\n\n    # ASSERT\n    assert len(result[\"races\"]) == 1\n    assert result[\"races\"][0][\"venue\"] == \"Churchill Downs\"\n    assert result[\"races\"][0][\"runners\"][0][\"name\"] == \"Secretariat\"\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine._time_adapter_fetch\")\nasync def test_fetch_all_odds_resilience(mock_fetch, clear_cache):\n    \"\"\"Test that one failing adapter does not crash the whole engine.\"\"\"\n    # ARRANGE\n    settings = get_test_settings()\n    settings.CACHE_ENABLED = False\n    engine = OddsEngine(config=settings)\n\n    # Mock successful adapter data\n    good_race = create_mock_race(\"GoodSource\", \"Track A\", 1, datetime.now(), [])\n    good_payload = (\"GoodSource\", {\"races\": [good_race], \"source_info\": {\"name\": \"GoodSource\", \"status\": \"SUCCESS\", \"races_fetched\": 1, \"fetch_duration\": 0.1}}, 0.1)\n\n    # Mock failed adapter data\n    bad_payload = (\"BadSource\", {\"races\": [], \"source_info\": {\"name\": \"BadSource\", \"status\": \"FAILED\", \"error_message\": \"API Down\", \"races_fetched\": 0, \"fetch_duration\": 0.1}}, 0.1)\n\n    mock_fetch.side_effect = [good_payload, bad_payload]\n\n    # We still need to give the engine adapters to iterate over\n    good_adapter = MagicMock(spec=BaseAdapterV3); good_adapter.source_name = \"GoodSource\"\n    bad_adapter = MagicMock(spec=BaseAdapterV3); bad_adapter.source_name = \"BadSource\"\n    engine.adapters = [good_adapter, bad_adapter]\n\n    # ACT\n    result = await engine.fetch_all_odds(\"2025-12-08\")\n\n    # ASSERT\n    assert len(result[\"races\"]) == 1, \"Should return data from the good adapter\"\n    assert result[\"races\"][0][\"source\"] == \"GoodSource\"\n\n    # Verify error logging in sourceInfo\n    bad_info = next((s for s in result[\"sourceInfo\"] if s[\"name\"] == \"BadSource\"), None)\n    assert bad_info is not None\n    assert bad_info[\"status\"] == \"FAILED\"\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine._time_adapter_fetch\")\nasync def test_race_aggregation_and_deduplication(mock_fetch, clear_cache):\n    \"\"\"Test merging identical races from different sources.\"\"\"\n    settings = get_test_settings()\n    settings.CACHE_ENABLED = False\n    engine = OddsEngine(config=settings)\n    now = datetime.now()\n\n    # Same race, different sources, slightly different odds\n    race_a = create_mock_race(\"SourceA\", \"Ascot\", 1, now, [{\"number\": 1, \"name\": \"Horse X\", \"odds\": \"2.0\"}])\n    race_b = create_mock_race(\"SourceB\", \"Ascot\", 1, now, [{\"number\": 1, \"name\": \"Horse X\", \"odds\": \"2.2\"}])\n\n    payload_a = (\"SourceA\", {\"races\": [race_a], \"source_info\": {\"name\": \"SourceA\", \"status\": \"SUCCESS\", \"races_fetched\": 1, \"fetch_duration\": 0.1}}, 0.1)\n    payload_b = (\"SourceB\", {\"races\": [race_b], \"source_info\": {\"name\": \"SourceB\", \"status\": \"SUCCESS\", \"races_fetched\": 1, \"fetch_duration\": 0.1}}, 0.1)\n    mock_fetch.side_effect = [payload_a, payload_b]\n\n    adapter_a = MagicMock(spec=BaseAdapterV3); adapter_a.source_name = \"SourceA\"\n    adapter_b = MagicMock(spec=BaseAdapterV3); adapter_b.source_name = \"SourceB\"\n    engine.adapters = [adapter_a, adapter_b]\n\n\n    # ACT\n    result = await engine.fetch_all_odds(\"2025-12-08\")\n\n    # ASSERT\n    assert len(result[\"races\"]) == 1, \"Should deduplicate into a single race object\"\n    merged_race = result[\"races\"][0]\n    runner = merged_race[\"runners\"][0]\n\n    # Check that odds from both sources are present\n    # Note: This assertion depends on how your engine merges odds.\n    # If it merges into a dict, this passes. If it overwrites, adjust accordingly.\n    odds_keys = runner[\"odds\"].keys()\n    assert \"SourceA\" in odds_keys\n    assert \"SourceB\" in odds_keys",
    "tests/utils.py": "# tests/utils.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Dict\nfrom typing import List\n\nfrom python_service.models import OddsData\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\n\ndef create_mock_race(\n    source: str,\n    track_name: str,\n    race_number: int,\n    start_time: datetime,\n    runners_data: List[Dict],\n) -> dict:\n    \"\"\"\n    Creates a dictionary representing a race, suitable for Pydantic model validation.\n    This is a test utility to generate consistent race data.\n    \"\"\"\n    runners = []\n    for i, runner_info in enumerate(runners_data):\n        odds_data = {}\n        if \"odds\" in runner_info:\n            odds_value = Decimal(str(runner_info[\"odds\"]))\n            odds_data[source] = OddsData(win=odds_value, source=source, last_updated=datetime.now())\n\n        runners.append(\n            Runner(\n                number=runner_info.get(\"number\", i + 1),\n                name=runner_info.get(\"name\", f\"Runner {i + 1}\"),\n                odds=odds_data,\n                scratched=runner_info.get(\"scratched\", False),\n            ).model_dump()\n        )\n\n    # Use Pydantic model to create and then dump the data to ensure it's valid\n    race = Race(\n        id=f\"test_{track_name}_{race_number}\",\n        venue=track_name,\n        race_number=race_number,\n        start_time=start_time,\n        runners=runners,\n        source=source,\n    )\n    return race.model_dump()\n",
    "web_service/backend/__init__.py": "# This file makes this directory a package.\n",
    "web_service/backend/adapters/betfair_auth_mixin.py": "# python_service/adapters/betfair_auth_mixin.py\n\nimport asyncio\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Optional\n\nimport httpx\nimport structlog\n\nfrom ..credentials_manager import SecureCredentialsManager\n\nlog = structlog.get_logger(__name__)\n\n\nclass BetfairAuthMixin:\n    \"\"\"Encapsulates Betfair authentication logic for reuse across adapters.\"\"\"\n\n    session_token: Optional[str] = None\n    token_expiry: Optional[datetime] = None\n    _auth_lock = asyncio.Lock()\n\n    async def _authenticate(self, http_client: httpx.AsyncClient):\n        \"\"\"\n        Authenticates with Betfair using credentials from the system's credential manager,\n        ensuring the session token is valid and refreshing it if necessary.\n        \"\"\"\n        async with self._auth_lock:\n            if self.session_token and self.token_expiry and self.token_expiry > (datetime.now() + timedelta(minutes=5)):\n                return\n\n            log.info(\"Attempting to authenticate with Betfair...\")\n            username, password = SecureCredentialsManager.get_betfair_credentials()\n\n            if not all([self.config.BETFAIR_APP_KEY, username, password]):\n                raise ValueError(\"Betfair credentials not fully configured in credential manager.\")\n\n            auth_url = \"https://identitysso.betfair.com/api/login\"\n            headers = {\n                \"X-Application\": self.config.BETFAIR_APP_KEY,\n                \"Content-Type\": \"application/x-www-form-urlencoded\",\n            }\n            payload = f\"username={username}&password={password}\"\n\n            response = await http_client.post(auth_url, headers=headers, content=payload, timeout=20)\n            response.raise_for_status()\n            data = response.json()\n\n            if data.get(\"status\") == \"SUCCESS\":\n                self.session_token = data.get(\"token\")\n                self.token_expiry = datetime.now() + timedelta(hours=3)\n                log.info(\"Betfair authentication successful.\")\n            else:\n                log.error(\"Betfair authentication failed\", error=data.get(\"error\"))\n                self.session_token = None  # Reset token to prevent using a stale one\n                return  # Return gracefully and let the adapter handle the lack of a token\n",
    "web_service/backend/adapters/fanduel_adapter.py": "# python_service/adapters/fanduel_adapter.py\n\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass FanDuelAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for FanDuel's private API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"FanDuel\"\n    BASE_URL = \"https://sb-api.nj.sportsbook.fanduel.com/api/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw market data from the FanDuel API.\"\"\"\n        # Note: FanDuel's API is not date-centric. Event discovery would be needed for a robust implementation.\n        # This uses a hardcoded eventId as a placeholder.\n        event_id = \"38183.3\"\n        self.logger.info(f\"Fetching races from FanDuel for event_id: {event_id}\")\n        endpoint = f\"markets?_ak=Fh2e68s832c41d4b&eventId={event_id}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw API response into a list of Race objects.\"\"\"\n        if not raw_data or \"marketGroups\" not in raw_data:\n            self.logger.warning(\"FanDuel response missing 'marketGroups' key\")\n            return []\n\n        races = []\n        for group in raw_data.get(\"marketGroups\", []):\n            if group.get(\"marketGroupName\") == \"Win\":\n                for market in group.get(\"markets\", []):\n                    try:\n                        if race := self._parse_single_race(market):\n                            races.append(race)\n                    except Exception:\n                        self.logger.error(\n                            \"Failed to parse a FanDuel market\",\n                            market=market,\n                            exc_info=True,\n                        )\n        return races\n\n    def _parse_single_race(self, market: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single market from the API response into a Race object.\"\"\"\n        market_name = market.get(\"marketName\", \"\")\n        if not market_name.startswith(\"Race\"):\n            return None\n\n        parts = market_name.split(\" - \")\n        if len(parts) < 2:\n            self.logger.warning(f\"Could not parse race and track from FanDuel market name: {market_name}\")\n            return None\n\n        race_number_str = parts[0].replace(\"Race \", \"\").strip()\n        if not race_number_str.isdigit():\n            return None\n        race_number = int(race_number_str)\n\n        track_name = parts[1]\n\n        # Placeholder for start_time - FanDuel's market API doesn't provide it directly\n        start_time = datetime.now(timezone.utc) + timedelta(hours=race_number)\n\n        runners = []\n        for runner_data in market.get(\"runners\", []):\n            try:\n                runner_name = runner_data.get(\"runnerName\")\n                win_runner_odds = runner_data.get(\"winRunnerOdds\", {})\n                current_price = win_runner_odds.get(\"currentPrice\")\n\n                if not runner_name or not current_price:\n                    continue\n\n                numerator, denominator = map(int, current_price.split(\"/\"))\n                decimal_odds = Decimal(numerator) / Decimal(denominator) + 1\n\n                odds = OddsData(\n                    win=decimal_odds,\n                    source=self.source_name,\n                    last_updated=datetime.now(timezone.utc),\n                )\n\n                name_parts = runner_name.split(\".\", 1)\n                if len(name_parts) < 2:\n                    continue\n                program_number_str = name_parts[0].strip()\n                horse_name = name_parts[1].strip()\n\n                runners.append(\n                    Runner(\n                        name=horse_name,\n                        number=(int(program_number_str) if program_number_str.isdigit() else 0),\n                        odds={self.source_name: odds},\n                    )\n                )\n            except (ValueError, ZeroDivisionError, IndexError, TypeError):\n                self.logger.warning(\n                    \"Could not parse FanDuel runner\",\n                    runner_data=runner_data,\n                    exc_info=True,\n                )\n                continue\n\n        if not runners:\n            return None\n\n        race_id = f\"FD-{track_name.replace(' ', '')[:5].upper()}-{start_time.strftime('%Y%m%d')}-R{race_number}\"\n\n        return Race(\n            id=race_id,\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/nyrabets_adapter.py": "# python_service/adapters/nyrabets_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass NYRABetsAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for nyrabets.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"NYRABets\"\n    BASE_URL = \"https://nyrabets.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/racing_and_sports_greyhound_adapter.py": "# python_service/adapters/racing_and_sports_greyhound_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports Greyhound API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSportsGreyhound\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"RACING_AND_SPORTS_TOKEN\") or not config.RACING_AND_SPORTS_TOKEN:\n            raise AdapterConfigError(self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw greyhound meetings data from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            self.http_client,\n            \"GET\",\n            \"v1/greyhound/meetings\",\n            headers=headers,\n            params=params,\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw meetings data into a list of Race objects.\"\"\"\n        all_races = []\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\"No 'meetings' in RacingAndSportsGreyhound response or invalid format.\")\n            return all_races\n\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed_race := self._parse_ras_race(meeting, race_summary):\n                        all_races.append(parsed_race)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse RacingAndSportsGreyhound race, skipping\",\n                        meeting=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return all_races\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"rasg_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=datetime.fromisoformat(start_time_str),\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/template_adapter.py": "# python_service/adapters/template_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TemplateAdapter(BaseAdapterV3):\n    \"\"\"\n    A template for creating new adapters, based on the BaseAdapterV3 pattern.\n    This adapter is a non-functional stub.\n    \"\"\"\n\n    SOURCE_NAME = \"[IMPLEMENT ME] Example Source\"\n    BASE_URL = \"https://api.example.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        # self.api_key = config.EXAMPLE_API_KEY # Uncomment if needed\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/universal_adapter.py": "# python_service/adapters/universal_adapter.py\nimport json\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass UniversalAdapter(BaseAdapterV3):\n    \"\"\"\n    An adapter that executes logic from a declarative JSON definition file.\n    NOTE: This is a simplified proof-of-concept implementation.\n    \"\"\"\n\n    def __init__(self, config, definition_path: str):\n        with open(definition_path, \"r\") as f:\n            self.definition = json.load(f)\n\n        super().__init__(\n            source_name=self.definition[\"adapter_name\"],\n            base_url=self.definition[\"base_url\"],\n            config=config,\n        )\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Executes the fetch steps defined in the JSON definition.\"\"\"\n        self.logger.info(f\"Executing Universal Adapter PoC for {self.source_name}\")\n        response = await self.make_request(self.http_client, \"GET\", self.definition[\"start_url\"])\n        if not response:\n            return None\n\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        track_links = [self.base_url + a[\"href\"] for a in soup.select(self.definition[\"steps\"][0][\"selector\"])]\n\n        # In a full implementation, we would fetch and return each track page's content.\n        # For this PoC, we are not fetching the individual track links.\n        self.logger.warning(\"UniversalAdapter is a proof-of-concept and does not fully fetch all data.\")\n        return track_links\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a proof-of-concept and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/cache_manager.py": "# python_service/cache_manager.py\nimport asyncio\nimport hashlib\nimport json\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom functools import wraps\nfrom typing import Any\nfrom typing import Callable\n\nimport structlog\n\ntry:\n    import redis\n\n    REDIS_AVAILABLE = True\nexcept ImportError:\n    REDIS_AVAILABLE = False\n\nlog = structlog.get_logger(__name__)\n\n\nclass CacheManager:\n    def __init__(self):\n        self.redis_client = None\n        self.memory_cache = {}\n        self.is_configured = False\n        log.info(\"CacheManager initialized (not connected).\")\n\n    async def connect(self, redis_url: str):\n        if self.is_configured or not REDIS_AVAILABLE or not redis_url:\n            return\n\n        try:\n            log.info(\"Attempting to connect to Redis...\", url=redis_url)\n            # Use the async version of the client\n            self.redis_client = redis.asyncio.from_url(redis_url, decode_responses=True)\n            await self.redis_client.ping()  # Verify connection asynchronously\n            self.is_configured = True\n            log.info(\"Redis cache connected successfully.\")\n        except (redis.exceptions.ConnectionError, asyncio.TimeoutError) as e:\n            log.warning(\n                \"Failed to connect to Redis. Falling back to in-memory cache.\",\n                error=str(e),\n            )\n            self.redis_client = None\n            self.is_configured = False\n\n    async def disconnect(self):\n        if self.redis_client:\n            await self.redis_client.close()\n            log.info(\"Redis connection closed.\")\n\n    def _generate_key(self, prefix: str, *args, **kwargs) -> str:\n        key_data = f\"{prefix}:{args}:{sorted(kwargs.items())}\"\n        return hashlib.md5(key_data.encode()).hexdigest()\n\n    async def get(self, key: str) -> Any | None:\n        if self.redis_client:\n            try:\n                value = await self.redis_client.get(key)\n                return json.loads(value) if value else None\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis GET failed, falling back to memory cache.\", error=e)\n\n        entry = self.memory_cache.get(key)\n        if entry and entry.get(\"expires_at\", datetime.min) > datetime.now():\n            return entry.get(\"value\")\n        return None\n\n    async def set(self, key: str, value: Any, ttl_seconds: int = 300):\n        try:\n            serialized = json.dumps(value, default=str)\n        except (TypeError, ValueError) as e:\n            log.error(\"Failed to serialize value for caching.\", value=value, error=str(e))\n            return\n\n        if self.redis_client:\n            try:\n                await self.redis_client.setex(key, ttl_seconds, serialized)\n                return\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis SET failed, falling back to memory cache.\", error=e)\n\n        self.memory_cache[key] = {\n            \"value\": value,\n            \"expires_at\": datetime.now() + timedelta(seconds=ttl_seconds),\n        }\n\n\n# --- Singleton Instance & Decorator ---\ncache_manager = CacheManager()\n\n\ndef cache_async_result(ttl_seconds: int = 300, key_prefix: str = \"cache\"):\n    def decorator(func: Callable):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            instance_args = args[1:] if args and hasattr(args[0], func.__name__) else args\n            cache_key = cache_manager._generate_key(f\"{key_prefix}:{func.__name__}\", *instance_args, **kwargs)\n\n            cached_result = await cache_manager.get(cache_key)\n            if cached_result is not None:\n                log.debug(\"Cache hit\", function=func.__name__)\n                return cached_result\n\n            log.debug(\"Cache miss\", function=func.__name__)\n            result = await func(*args, **kwargs)\n\n            try:\n                await cache_manager.set(cache_key, result, ttl_seconds)\n            except Exception as e:\n                log.error(\"Failed to store result in cache.\", error=str(e), key=cache_key)\n\n            return result\n\n        return wrapper\n\n    return decorator\n",
    "web_service/backend/credentials_manager.py": "# python_service/credentials_manager.py\ntry:\n    import keyring\n\n    # This check is crucial for cross-platform compatibility\n    import keyring.backends.windows\n\n    IS_WINDOWS = True\nexcept ImportError:\n    keyring = None\n    IS_WINDOWS = False\n\n\nclass SecureCredentialsManager:\n    \"\"\"Manages secrets in the system's native credential store.\"\"\"\n\n    SERVICE_NAME = \"Fortuna\"\n\n    @staticmethod\n    def save_credential(account: str, secret: str) -> bool:\n        \"\"\"Saves a secret for a given account (e.g., 'api_key', 'betfair_username').\"\"\"\n        if not IS_WINDOWS:\n            print(\"Credential storage is only supported on Windows.\")\n            return False\n        try:\n            keyring.set_password(SecureCredentialsManager.SERVICE_NAME, account, secret)\n            return True\n        except Exception as e:\n            print(f\"\u274c Failed to save credential for {account}: {e}\")\n            return False\n\n    @staticmethod\n    def get_credential(account: str) -> str:\n        \"\"\"Retrieves a secret for a given account.\"\"\"\n        if not IS_WINDOWS:\n            return None\n        try:\n            return keyring.get_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception as e:\n            print(f\"\u274c Failed to retrieve credential for {account}: {e}\")\n            return None\n\n    @staticmethod\n    def get_betfair_credentials() -> tuple[str, str]:\n        \"\"\"Convenience method to retrieve both Betfair username and password.\"\"\"\n        username = SecureCredentialsManager.get_credential(\"betfair_username\")\n        password = SecureCredentialsManager.get_credential(\"betfair_password\")\n        return username, password\n\n    @staticmethod\n    def delete_credential(account: str):\n        \"\"\"Deletes a specific credential.\"\"\"\n        if not IS_WINDOWS:\n            return\n        try:\n            keyring.delete_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception:\n            pass\n",
    "web_service/backend/engine.py": "# python_service/engine.py\n\nimport asyncio\nimport json\nfrom copy import deepcopy\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Tuple\n\nimport httpx\nimport redis\nimport redis.asyncio as redis_async\nimport structlog\nfrom pydantic import ValidationError\n\nfrom .adapters.at_the_races_adapter import AtTheRacesAdapter\nfrom .adapters.base_adapter_v3 import BaseAdapterV3\nfrom .adapters.betfair_adapter import BetfairAdapter\n\n# from .adapters.betfair_datascientist_adapter import BetfairDataScientistAdapter\nfrom .adapters.betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .adapters.brisnet_adapter import BrisnetAdapter\nfrom .adapters.equibase_adapter import EquibaseAdapter\nfrom .adapters.fanduel_adapter import FanDuelAdapter\nfrom .adapters.gbgb_api_adapter import GbgbApiAdapter\nfrom .adapters.greyhound_adapter import GreyhoundAdapter\nfrom .adapters.harness_adapter import HarnessAdapter\nfrom .adapters.horseracingnation_adapter import HorseRacingNationAdapter\nfrom .adapters.nyrabets_adapter import NYRABetsAdapter\nfrom .adapters.oddschecker_adapter import OddscheckerAdapter\nfrom .adapters.pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .adapters.punters_adapter import PuntersAdapter\nfrom .adapters.racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .adapters.racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .adapters.racingpost_adapter import RacingPostAdapter\nfrom .adapters.racingtv_adapter import RacingTVAdapter\nfrom .adapters.sporting_life_adapter import SportingLifeAdapter\nfrom .adapters.tab_adapter import TabAdapter\nfrom .adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom .adapters.timeform_adapter import TimeformAdapter\nfrom .adapters.tvg_adapter import TVGAdapter\nfrom .adapters.twinspires_adapter import TwinSpiresAdapter\nfrom .adapters.xpressbet_adapter import XpressbetAdapter\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .manual_override_manager import ManualOverrideManager\nfrom .models import AggregatedResponse\nfrom .models import Race\n\nlog = structlog.get_logger(__name__)\n\n\nclass OddsEngine:\n    def __init__(\n        self,\n        config=None,\n        manual_override_manager: ManualOverrideManager = None,\n        connection_manager=None,\n    ):\n        # THE FIX: Import the cache_manager singleton here to ensure tests can\n        # patch and reload it *before* the engine is initialized.\n        from .cache_manager import cache_manager\n\n        self.logger = structlog.get_logger(__name__)\n        self.logger.info(\"Initializing FortunaEngine...\")\n        self.connection_manager = connection_manager\n        self.cache_manager = cache_manager\n\n        try:\n            try:\n                self.config = config or get_settings()\n                self.logger.info(\"Configuration loaded.\")\n            except ValidationError as e:\n                self.logger.warning(\n                    \"Could not load settings, possibly in test environment.\",\n                    error=str(e),\n                )\n                # Create a default/mock config or re-raise if not in a test context\n                from .config import Settings\n\n                self.config = Settings(API_KEY=\"a_secure_test_api_key_that_is_long_enough\")\n\n            # Redis is now handled entirely by the CacheManager.\n\n            self.logger.info(\"Initializing adapters...\")\n            self.adapters: List[BaseAdapterV3] = []\n            adapter_classes = [\n                AtTheRacesAdapter,\n                BetfairAdapter,\n                BetfairGreyhoundAdapter,\n                BrisnetAdapter,\n                EquibaseAdapter,\n                FanDuelAdapter,\n                GbgbApiAdapter,\n                GreyhoundAdapter,\n                HarnessAdapter,\n                HorseRacingNationAdapter,\n                NYRABetsAdapter,\n                OddscheckerAdapter,\n                PuntersAdapter,\n                RacingAndSportsAdapter,\n                RacingAndSportsGreyhoundAdapter,\n                RacingPostAdapter,\n                RacingTVAdapter,\n                SportingLifeAdapter,\n                TabAdapter,\n                TheRacingApiAdapter,\n                TimeformAdapter,\n                TwinSpiresAdapter,\n                TVGAdapter,\n                XpressbetAdapter,\n                PointsBetGreyhoundAdapter,\n            ]\n\n            for adapter_cls in adapter_classes:\n                try:\n                    self.logger.info(f\"Attempting to initialize adapter: {adapter_cls.__name__}\")\n                    adapter_instance = adapter_cls(config=self.config)\n                    self.logger.info(f\"Successfully initialized adapter: {adapter_cls.__name__}\")\n                    if manual_override_manager and getattr(adapter_instance, \"supports_manual_override\", False):\n                        adapter_instance.enable_manual_override(manual_override_manager)\n                    self.adapters.append(adapter_instance)\n                except AdapterConfigError as e:\n                    self.logger.warning(\n                        \"Skipping adapter due to configuration error\",\n                        adapter=adapter_cls.__name__,\n                        error=str(e),\n                    )\n                except Exception:\n                    self.logger.error(\n                        f\"An unexpected error occurred while initializing {adapter_cls.__name__}\",\n                        exc_info=True,\n                    )\n\n            # Special case for BetfairDataScientistAdapter with extra args - DISABLED\n            # try:\n            #     bds_adapter = BetfairDataScientistAdapter(\n            #         model_name=\"ThoroughbredModel\",\n            #         url=\"https://betfair-data-supplier-prod.herokuapp.com/api/widgets/kvs-ratings/datasets\",\n            #         config=self.config,\n            #     )\n            #     if manual_override_manager and getattr(bds_adapter, \"supports_manual_override\", False):\n            #         bds_adapter.enable_manual_override(manual_override_manager)\n            #     self.adapters.append(bds_adapter)\n            # except Exception:\n            #     self.logger.warning(\n            #         \"Failed to initialize adapter: BetfairDataScientistAdapter\",\n            #         exc_info=True,\n            #     )\n\n            self.logger.info(f\"{len(self.adapters)} adapters initialized successfully.\")\n\n            self.logger.info(\"Initializing HTTP client...\")\n            self.http_limits = httpx.Limits(\n                max_connections=self.config.HTTP_POOL_CONNECTIONS,\n                max_keepalive_connections=self.config.HTTP_MAX_KEEPALIVE,\n            )\n            self.http_client = httpx.AsyncClient(limits=self.http_limits, http2=True)\n            self.logger.info(\"HTTP client initialized.\")\n\n            # Assign the shared client to each adapter\n            for adapter in self.adapters:\n                adapter.http_client = self.http_client\n\n            # Initialize semaphore for concurrency limiting\n            self.semaphore = asyncio.Semaphore(self.config.MAX_CONCURRENT_REQUESTS)\n            self.logger.info(\n                \"Concurrency semaphore initialized\",\n                limit=self.config.MAX_CONCURRENT_REQUESTS,\n            )\n\n            self.logger.info(\"FortunaEngine initialization complete.\")\n\n        except Exception:\n            self.logger.critical(\"CRITICAL FAILURE during FortunaEngine initialization.\", exc_info=True)\n            raise\n\n    async def close(self):\n        await self.http_client.aclose()\n\n    def get_all_adapter_statuses(self) -> List[Dict[str, Any]]:\n        return [adapter.get_status() for adapter in self.adapters]\n\n    async def get_from_cache(self, key):\n        return await self.cache_manager.get(key)\n\n    async def set_in_cache(self, key, value, ttl=300):\n        # THE FIX: The keyword argument is 'ttl_seconds', not 'ttl'.\n        await self.cache_manager.set(key, value, ttl_seconds=ttl)\n\n    async def _fetch_with_semaphore(self, adapter: BaseAdapterV3, date: str):\n        \"\"\"Acquires the semaphore before fetching data from an adapter.\"\"\"\n        async with self.semaphore:\n            return await self._time_adapter_fetch(adapter, date)\n\n    async def _time_adapter_fetch(self, adapter: BaseAdapterV3, date: str) -> Tuple[str, Dict[str, Any], float]:\n        \"\"\"\n        Wraps a V3 adapter's fetch call for safe, non-blocking execution,\n        and returns a consistent payload with timing information.\n        \"\"\"\n        start_time = datetime.now()\n        races: List[Race] = []\n        error_message = None\n        is_success = False\n        attempted_url = None\n\n        try:\n            race_data_list = await adapter.get_races(date)\n            races = [Race(**race_data) for race_data in race_data_list]\n            is_success = True\n        except AdapterHttpError as e:\n            self.logger.error(\n                \"HTTP failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                status_code=e.status_code,\n                url=e.url,\n                exc_info=False,\n            )\n            error_message = f\"HTTP Error {e.status_code} for {e.url}\"\n            attempted_url = e.url\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n        except Exception as e:\n            self.logger.error(\n                \"Critical failure during fetch from adapter.\",\n                adapter=adapter.source_name,\n                error=str(e),\n                exc_info=True,\n            )\n            error_message = str(e)\n            races = [\n                Race(\n                    id=f\"error_{adapter.source_name.lower()}\",\n                    venue=adapter.source_name,\n                    race_number=0,\n                    start_time=datetime.now(),\n                    runners=[],\n                    source=adapter.source_name,\n                    is_error_placeholder=True,\n                    error_message=error_message,\n                )\n            ]\n\n        duration = (datetime.now() - start_time).total_seconds()\n\n        payload = {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": adapter.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": duration,\n                \"attempted_url\": attempted_url,\n            },\n        }\n        return (adapter.source_name, payload, duration)\n\n    def _race_key(self, race: Race) -> str:\n        return f\"{race.venue.lower().strip()}|{race.race_number}|{race.start_time.strftime('%H:%M')}\"\n\n    def _dedupe_races(self, races: List[Race]) -> List[Race]:\n        \"\"\"Deduplicates races and reconciles odds from different sources.\"\"\"\n        races_copy = deepcopy(races)\n        race_map: Dict[str, Race] = {}\n        for race in races_copy:\n            key = self._race_key(race)\n            if key not in race_map:\n                race_map[key] = race\n            else:\n                existing_race = race_map[key]\n                runner_map = {r.number: r for r in existing_race.runners}\n                for new_runner in race.runners:\n                    if new_runner.number in runner_map:\n                        existing_runner = runner_map[new_runner.number]\n                        existing_runner.odds.update(new_runner.odds)\n                    else:\n                        existing_race.runners.append(new_runner)\n                existing_race.source += f\", {race.source}\"\n\n        return list(race_map.values())\n\n    async def _broadcast_update(self, data: Dict[str, Any]):\n        \"\"\"Helper to broadcast data if the connection manager is available.\"\"\"\n        if self.connection_manager:\n            await self.connection_manager.broadcast(data)\n\n    async def fetch_all_odds(self, date: str, source_filter: str = None) -> Dict[str, Any]:\n        \"\"\"\n        Fetches and aggregates race data from all configured adapters.\n        The result of this method is cached and broadcasted via WebSocket.\n        \"\"\"\n        # Construct a cache key\n        cache_key = f\"fortuna_engine_races:{date}:{source_filter or 'all'}\"\n        cached_data = await self.get_from_cache(cache_key)\n        if cached_data:\n            log.info(\"Cache hit for fetch_all_odds\", key=cache_key)\n            return json.loads(cached_data)\n\n        log.info(\"Cache miss for fetch_all_odds\", key=cache_key)\n        target_adapters = self.adapters\n        if source_filter:\n            log.info(\"Applying source filter\", source=source_filter)\n            target_adapters = [a for a in self.adapters if a.source_name.lower() == source_filter.lower()]\n\n        tasks = [self._fetch_with_semaphore(adapter, date) for adapter in target_adapters]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        source_infos = []\n        all_races = []\n        errors = []\n\n        for i, result in enumerate(results):\n            adapter = target_adapters[i]\n            if isinstance(result, Exception):\n                log.error(\"Adapter fetch task failed with an unhandled exception\", adapter=adapter.source_name, error=result)\n                errors.append({\n                    \"adapter_name\": adapter.source_name,\n                    \"error_message\": f\"Unhandled exception: {str(result)}\",\n                    \"attempted_url\": \"Unknown\"\n                })\n                source_infos.append({\n                    \"name\": adapter.source_name,\n                    \"status\": \"FAILED\",\n                    \"error_message\": f\"Unhandled exception: {str(result)}\",\n                })\n            else:\n                _adapter_name, adapter_result, _duration = result\n                source_info = adapter_result.get(\"source_info\", {})\n                source_infos.append(source_info)\n                if source_info.get(\"status\") == \"SUCCESS\":\n                    all_races.extend(adapter_result.get(\"races\", []))\n                else:\n                    errors.append({\n                        \"adapter_name\": adapter.source_name,\n                        \"error_message\": source_info.get(\"error_message\", \"Unknown error\"),\n                        \"attempted_url\": source_info.get(\"attempted_url\")\n                    })\n\n        deduped_races = self._dedupe_races(all_races)\n\n        response_obj = AggregatedResponse(\n            date=datetime.strptime(date, \"%Y-%m-%d\").date(),\n            races=deduped_races,\n            errors=errors,\n            source_info=source_infos,\n            metadata={\n                \"fetch_time\": datetime.now(),\n                \"sources_queried\": [a.source_name for a in target_adapters],\n                \"sources_successful\": len([s for s in source_infos if s[\"status\"] == \"SUCCESS\"]),\n                \"total_races\": len(deduped_races),\n                \"total_errors\": len(errors),\n            },\n        )\n\n        response_data = response_obj.model_dump(by_alias=True)\n\n        # Set the result in the cache\n        await self.set_in_cache(cache_key, json.dumps(response_data, default=str), ttl=300)\n        await self._broadcast_update(response_data)\n        return response_data\n",
    "web_service/backend/fortuna_windows_service.py": "# fortuna_windows_service.py\n\nimport logging\nimport os\nimport sys\n\nimport servicemanager\nimport win32event\nimport win32service\nimport win32serviceutil\n\n# Ensure the script's directory is at the front of the path\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.insert(0, script_dir)\n\ntry:\n    from fortuna_service import FortunaBackgroundService\nexcept ImportError as e:\n    # Log a detailed error to the Windows Event Log if the import fails\n    servicemanager.LogErrorMsg(f\"FATAL: Could not import FortunaBackgroundService. Error: {e}\")\n    sys.exit(1)  # Exit with an error code\n\n\nclass FortunaWindowsService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaV8Service\"\n    _svc_display_name_ = \"Fortuna V8 Racing Analysis Service\"\n    _svc_description_ = \"Continuously fetches and analyzes horse racing data.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)\n        self.fortuna_service = FortunaBackgroundService()\n        # Configure logging to use the Windows Event Log\n        logging.basicConfig(\n            level=logging.INFO,\n            format=\"%(name)s - %(levelname)s - %(message)s\",\n            handlers=[servicemanager.LogHandler()],\n        )\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        self.fortuna_service.stop()\n        win32event.SetEvent(self.hWaitStop)\n        self.ReportServiceStatus(win32service.SERVICE_STOPPED)\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(\n            servicemanager.EVENTLOG_INFORMATION_TYPE,\n            servicemanager.PYS_SERVICE_STARTED,\n            (self._svc_name_, \"\"),\n        )\n        self.main()\n\n    def main(self):\n        self.fortuna_service.start()\n        win32event.WaitForSingleObject(self.hWaitStop, win32event.INFINITE)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaWindowsService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaWindowsService)\n",
    "web_service/backend/main.py": "import sys\nfrom pathlib import Path\nimport uvicorn\nimport logging\nimport traceback\n\n# CRITICAL: Set up paths and logging for PyInstaller\nif getattr(sys, 'frozen', False):\n    # Running as compiled executable\n    PROJECT_ROOT = Path(sys.executable).parent\n    LOG_FILE = PROJECT_ROOT / 'fortuna-monolith.log'\n    # Redirect stdout and stderr to the log file to capture all output\n    sys.stdout = open(LOG_FILE, 'w', encoding='utf-8')\n    sys.stderr = sys.stdout\nelse:\n    # Running as script\n    PROJECT_ROOT = Path(__file__).parent.parent.parent\n    LOG_FILE = PROJECT_ROOT / 'fortuna-monolith-dev.log'\n\n# Configure logging to write to the log file and original stdout\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(LOG_FILE),\n        logging.StreamHandler(sys.__stdout__)\n    ]\n)\nlog = logging.getLogger(__name__)\n\n# Add project root to path\nif str(PROJECT_ROOT) not in sys.path:\n    sys.path.insert(0, str(PROJECT_ROOT))\nlog.info(f\"PROJECT_ROOT added to sys.path: {PROJECT_ROOT}\")\nlog.info(f\"Full sys.path: {sys.path}\")\n\n# Now that the path is set, we can import our application modules\nfrom web_service.backend.api import app\nfrom web_service.backend.config import get_settings\nfrom web_service.backend.port_check import check_port_and_exit_if_in_use\n\n\ndef main():\n    \"\"\"Main entry point for Fortuna Monolith.\"\"\"\n    try:\n        log.info(\"=\"*70)\n        log.info(\"\ud83d\ude80 Fortuna Monolith Initializing...\")\n        log.info(f\"Python Executable: {sys.executable}\")\n        log.info(f\"Working Directory: {Path.cwd()}\")\n        log.info(\"=\"*70)\n\n        settings = get_settings()\n\n        log.info(f\"Checking port {settings.FORTUNA_PORT} on host {settings.UVICORN_HOST}\")\n        check_port_and_exit_if_in_use(settings.FORTUNA_PORT, settings.UVICORN_HOST)\n        log.info(f\"Port {settings.FORTUNA_PORT} is available.\")\n\n        log.info(f\"Host: {settings.UVICORN_HOST}\")\n        log.info(f\"Port: {settings.FORTUNA_PORT}\")\n        log.info(f\"Mode: {'Frozen (Executable)' if getattr(sys, 'frozen', False) else 'Development'}\")\n        log.info(f\"Log file: {LOG_FILE}\")\n\n        log.info(\"Starting Uvicorn server...\")\n        uvicorn.run(\n            app,\n            host=settings.UVICORN_HOST,\n            port=settings.FORTUNA_PORT,\n            log_level=\"info\",\n            access_log=True,\n        )\n        log.info(\"Uvicorn server stopped gracefully.\")\n\n    except Exception as e:\n        log.critical(\"--- !!! A FATAL ERROR OCCURRED DURING STARTUP !!! ---\")\n        log.critical(traceback.format_exc())\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    # Multiprocessing support for PyInstaller\n    from multiprocessing import freeze_support\n    freeze_support()\n    main()\n",
    "web_service/backend/models_v3.py": "# python_service/models_v3.py\n# Defines the data structures for the V3 adapter architecture.\n\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import List\n\n\n@dataclass\nclass NormalizedRunner:\n    runner_id: str\n    name: str\n    saddle_cloth: str\n    odds_decimal: float\n\n\n@dataclass\nclass NormalizedRace:\n    race_key: str\n    track_key: str\n    start_time_iso: str\n    race_name: str\n    runners: List[NormalizedRunner] = field(default_factory=list)\n    source_ids: List[str] = field(default_factory=list)\n",
    "web_service/backend/requirements-dev.txt": "#\n# Development & Build-Time Dependencies\n# This file should be used for setting up a development or CI/CD environment.\n#\n\n-r requirements.txt\n\n# --- Build Tools ---\npip-tools\n\n# --- Testing Tools ---\npytest\npytest-asyncio\nfakeredis\nrespx\n\n# --- Linting & Auditing ---\nblack\nruff\npip-audit\nsetuptools<81\n",
    "web_service/backend/tests/__init__.py": "",
    "web_service/backend/utils/text.py": "# python_service/utils/text.py\n# Centralized text and name normalization utilities\nimport re\nfrom typing import Optional\n\n\ndef clean_text(text: Optional[str]) -> Optional[str]:\n    \"\"\"Strips leading/trailing whitespace and collapses internal whitespace.\"\"\"\n    if not text:\n        return None\n    return \" \".join(text.strip().split())\n\n\ndef normalize_venue_name(name: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Normalizes a UK or Irish racecourse name to a standard format.\n    Handles common abbreviations and variations.\n    \"\"\"\n    if not name:\n        return None\n\n    # Use a temporary variable for matching, but return the properly cased name\n    cleaned_name_upper = clean_text(name).upper()\n\n    VENUE_MAP = {\n        \"ASCOT\": \"Ascot\",\n        \"AYR\": \"Ayr\",\n        \"BANGOR-ON-DEE\": \"Bangor-on-Dee\",\n        \"CATTERICK BRIDGE\": \"Catterick\",\n        \"CHELMSFORD CITY\": \"Chelmsford\",\n        \"EPSOM DOWNS\": \"Epsom\",\n        \"FONTWELL\": \"Fontwell Park\",\n        \"HAYDOCK\": \"Haydock Park\",\n        \"KEMPTON\": \"Kempton Park\",\n        \"LINGFIELD\": \"Lingfield Park\",\n        \"NEWMARKET (ROWLEY)\": \"Newmarket\",\n        \"NEWMARKET (JULY)\": \"Newmarket\",\n        \"SANDOWN\": \"Sandown Park\",\n        \"STRATFORD\": \"Stratford-on-Avon\",\n        \"YARMOUTH\": \"Great Yarmouth\",\n        \"CURRAGH\": \"Curragh\",\n        \"DOWN ROYAL\": \"Down Royal\",\n    }\n\n    # Check primary map first\n    if cleaned_name_upper in VENUE_MAP:\n        return VENUE_MAP[cleaned_name_upper]\n\n    # Handle cases where the key is the desired output but needs to be mapped from a variation\n    # e.g. CHELMSFORD maps to Chelmsford\n    # Title case the cleaned name for a sensible default\n    title_cased_name = clean_text(name).title()\n    if title_cased_name in VENUE_MAP.values():\n        return title_cased_name\n\n    # Return the title-cased cleaned name as a fallback\n    return title_cased_name\n\n\ndef normalize_course_name(name: str) -> str:\n    if not name:\n        return \"\"\n    name = name.lower().strip()\n    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s-]+\", \"_\", name)\n    return name\n",
    "web_service/frontend/app/components/EmptyState.tsx": "// web_platform/frontend/src/components/EmptyState.tsx\nimport React from 'react';\n\ninterface EmptyStateProps {\n  title: string;\n  message: string;\n  actionButton?: React.ReactNode;\n}\n\nexport const EmptyState: React.FC<EmptyStateProps> = ({ title, message, actionButton }) => {\n  return (\n    <div className=\"text-center p-8 bg-gray-800/50 border border-gray-700 rounded-lg mt-8\">\n      <svg\n        className=\"mx-auto h-12 w-12 text-gray-500\"\n        fill=\"none\"\n        viewBox=\"0 0 24 24\"\n        stroke=\"currentColor\"\n        aria-hidden=\"true\"\n      >\n        <path\n          vectorEffect=\"non-scaling-stroke\"\n          strokeLinecap=\"round\"\n          strokeLinejoin=\"round\"\n          strokeWidth={2}\n          d=\"M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z\"\n        />\n      </svg>\n      <h3 className=\"mt-2 text-xl font-semibold text-white\">{title}</h3>\n      <p className=\"mt-1 text-md text-gray-400\">\n        {message}\n      </p>\n      {actionButton && <div className=\"mt-6\">{actionButton}</div>}\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/RaceCard.tsx": "// web_platform/frontend/src/components/RaceCard.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\nimport type { Race, Runner } from '../types/racing';\n\n// Local types removed, now importing from '../types/racing'\n\ninterface RaceCardProps {\n  race: Race;\n}\n\nconst Countdown: React.FC<{ startTime: string }> = ({ startTime }) => {\n  const [currentTime, setCurrentTime] = useState(new Date());\n\n  useEffect(() => {\n    const timer = setInterval(() => setCurrentTime(new Date()), 1000);\n    return () => clearInterval(timer);\n  }, []);\n\n  const getCountdown = (startTimeStr: string) => {\n    const postTime = new Date(startTimeStr);\n    const diff = postTime.getTime() - currentTime.getTime();\n\n    if (diff <= 0) return { text: \"RACE COMPLETE\", color: \"text-gray-500\" };\n\n    const minutes = Math.floor(diff / 60000);\n    const seconds = Math.floor((diff % 60000) / 1000).toString().padStart(2, '0');\n\n    let color = \"text-green-400\";\n    if (minutes < 2) color = \"text-red-500 font-bold animate-pulse\";\n    else if (minutes < 10) color = \"text-yellow-400\";\n\n    return { text: `${minutes}:${seconds} to post`, color };\n  };\n\n  const countdown = getCountdown(startTime);\n\n  return (\n    <span className={`font-mono text-sm ${countdown.color}`}>{countdown.text}</span>\n  );\n};\n\nexport const RaceCard: React.FC<RaceCardProps> = ({ race }) => {\n  const activeRunners = race.runners.filter(r => !r.scratched);\n  activeRunners.sort((a, b) => a.number - b.number);\n\n  const getUniqueSourcesCount = (runners: Runner[]): number => {\n    const sources = new Set();\n    runners.forEach(runner => {\n      if (runner.odds) {\n        Object.keys(runner.odds).forEach(source => sources.add(source));\n      }\n    });\n    return sources.size;\n  };\n\n  const getBestOdds = (runner: Runner): { odds: number, source: string } | null => {\n    if (!runner.odds) return null;\n  const validOdds = Object.values(runner.odds).filter(o => o.win !== null && o.win !== undefined && o.win < 999);\n    if (validOdds.length === 0) return null;\n  const best = validOdds.reduce((min, o) => (o.win ?? 999) < (min.win ?? 999) ? o : min);\n    return { odds: best.win!, source: best.source };\n  };\n\n  return (\n    <div className={`race-card-enhanced border rounded-lg p-4 bg-gray-800 shadow-lg hover:border-purple-500 transition-all ${race.qualification_score && race.qualification_score >= 80 ? 'card-premium' : 'border-gray-700'}`}>\n      {/* Header with Smart Status Indicators */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <h2 className=\"text-2xl font-bold text-white\">{race.venue}</h2>\n            <div className=\"flex gap-2 text-sm text-gray-400\">\n              <span>Race {race.race_number}</span>\n              <span>\u2022</span>\n              <Countdown startTime={race.start_time} />\n            </div>\n            {race.favorite && (\n              <div className=\"flex items-center gap-2 mt-2 text-sm text-yellow-400\">\n                <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-4 w-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n                  <path d=\"M9.049 2.927c.3-.921 1.603-.921 1.902 0l1.07 3.292a1 1 0 00.95.69h3.462c.969 0 1.371 1.24.588 1.81l-2.8 2.034a1 1 0 00-.364 1.118l1.07 3.292c.3.921-.755 1.688-1.54 1.118l-2.8-2.034a1 1 0 00-1.175 0l-2.8 2.034c-.784.57-1.838-.197-1.539-1.118l1.07-3.292a1 1 0 00-.364-1.118L2.98 8.72c-.783-.57-.38-1.81.588-1.81h3.461a1 1 0 00.951-.69l1.07-3.292z\" />\n                </svg>\n                <span className=\"font-semibold\">Favorite: {race.favorite.name}</span>\n              </div>\n            )}\n          </div>\n        </div>\n\n        {race.qualification_score && (\n          <div className={`px-4 py-2 rounded-full text-center ${\n            race.qualification_score >= 80 ? 'bg-red-500/20 text-red-400 border border-red-500/30' :\n            race.qualification_score >= 60 ? 'bg-yellow-500/20 text-yellow-400 border border-yellow-500/30' :\n            'bg-green-500/20 text-green-400 border border-green-500/30'\n          }`}>\n            <div className=\"font-bold text-lg\">{race.qualification_score.toFixed(0)}%</div>\n            <div className=\"text-xs\">Score</div>\n          </div>\n        )}\n      </div>\n\n      {/* Race Conditions Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Distance</div>\n          <div className=\"text-sm font-semibold text-white\">{race.distance || 'N/A'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Surface</div>\n          <div className=\"text-sm font-semibold text-white\">{race.surface || 'Dirt'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Field</div>\n          <div className=\"text-sm font-semibold text-white\">{activeRunners.length}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Sources</div>\n          <div className=\"text-sm font-semibold text-white\">{getUniqueSourcesCount(race.runners)}</div>\n        </div>\n      </div>\n\n      {/* Interactive Runner Rows */}\n      <div className=\"runners-table space-y-2\">\n        {activeRunners.map((runner, idx) => {\n          const bestOddsInfo = getBestOdds(runner);\n          return (\n            <div key={runner.number} className=\"runner-row group hover:bg-purple-500/10 transition-all rounded-md p-3\">\n              <div className=\"flex items-center justify-between\">\n                <div className=\"flex items-center gap-4 flex-1\">\n                  <div className={`w-10 h-10 rounded-full flex items-center justify-center font-bold transition-all group-hover:scale-110 text-gray-900 shadow-lg ${idx === 0 ? 'bg-gradient-to-br from-yellow-400 to-yellow-600 shadow-yellow-500/50' : idx === 1 ? 'bg-gradient-to-br from-gray-300 to-gray-500 shadow-gray-400/50' : idx === 2 ? 'bg-gradient-to-br from-orange-400 to-orange-600 shadow-orange-500/50' : 'bg-gray-700 text-gray-300'}`}>\n                    {runner.number}\n                  </div>\n                  <div className=\"flex flex-col\">\n                    <span className=\"font-bold text-white text-lg\">{runner.name}</span>\n                    <div className=\"flex gap-3 text-sm text-gray-400\">\n                      {runner.jockey && <span>J: {runner.jockey}</span>}\n                      {runner.trainer && <span>T: {runner.trainer}</span>}\n                    </div>\n                  </div>\n                </div>\n                {bestOddsInfo && (\n                  <div className=\"text-right\">\n                    <div className=\"text-2xl font-bold text-emerald-400\">{bestOddsInfo.odds.toFixed(2)}</div>\n                    <div className=\"text-xs text-gray-500\">via {bestOddsInfo.source}</div>\n                  </div>\n                )}\n              </div>\n            </div>\n          );\n        })}\n      </div>\n    </div>\n  );\n};",
    "web_service/frontend/app/components/StatusDetailModal.tsx": "// web_platform/frontend/src/components/StatusDetailModal.tsx\nimport React from 'react';\n\ninterface StatusDetailModalProps {\n  isOpen: boolean;\n  onClose: () => void;\n  status: {\n      title: string;\n      details: string | Record<string, any>;\n  };\n}\n\nexport const StatusDetailModal: React.FC<StatusDetailModalProps> = ({ isOpen, onClose, status }) => {\n  if (!isOpen) {\n    return null;\n  }\n\n  const { title, details } = status;\n  const isDetailsString = typeof details === 'string';\n\n  // Determine status color only if details is an object with a status property\n  const statusColor = !isDetailsString && (details.status === 'SUCCESS' || details.status === 'OK')\n    ? 'text-green-400'\n    : 'text-gray-300'; // Default color\n\n  return (\n    <div className=\"fixed inset-0 bg-black/60 flex items-center justify-center z-50\" onClick={onClose}>\n      <div className=\"bg-gray-800 border border-gray-700 rounded-lg shadow-xl p-6 max-w-lg w-full\" onClick={e => e.stopPropagation()}>\n        <div className=\"flex justify-between items-start mb-4\">\n          <h3 className=\"text-xl font-bold text-white\">{title}</h3>\n          <button onClick={onClose} className=\"text-gray-400 hover:text-white\">&times;</button>\n        </div>\n        <div className=\"space-y-2 text-sm max-h-96 overflow-y-auto pr-2\">\n            {isDetailsString ? (\n                <div className=\"text-gray-300 whitespace-pre-wrap bg-gray-900/50 p-4 rounded-md\">{details}</div>\n            ) : (\n                Object.entries(details).map(([key, value]) => (\n                    <div key={key} className=\"grid grid-cols-3 gap-4 border-b border-gray-700/50 py-2\">\n                    <span className=\"font-semibold text-gray-400 capitalize\">{key.replace(/_/g, ' ')}</span>\n                    <span className={`col-span-2 break-words ${key === 'status' ? statusColor : 'text-gray-300'}`}>\n                        {typeof value === 'object' ? JSON.stringify(value, null, 2) : String(value)}\n                    </span>\n                    </div>\n                ))\n            )}\n        </div>\n        <button\n          onClick={onClose}\n          className=\"bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded w-full mt-6\"\n        >\n          Close\n        </button>\n      </div>\n    </div>\n  );\n};\n",
    "web_service/frontend/app/hooks/useWebSocket.ts": "// web_platform/frontend/src/hooks/useWebSocket.ts\n'use client';\n\nimport { useState, useEffect, useRef } from 'react';\n\ninterface WebSocketOptions {\n  apiKey: string | null;\n  port?: number | null; // Port is now optional\n}\n\nexport const useWebSocket = <T>(path: string, options: WebSocketOptions) => {\n  const [data, setData] = useState<T | null>(null);\n  const [isConnected, setIsConnected] = useState(false);\n  const webSocketRef = useRef<WebSocket | null>(null);\n\n  useEffect(() => {\n    if (!path || !options.apiKey) {\n      console.log('[useWebSocket] Missing path or API key. Aborting connection.');\n      if (webSocketRef.current) {\n        webSocketRef.current.close();\n      }\n      return;\n    }\n\n    // Use relative URL for same-origin, or build full URL if port is provided\n    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';\n    const host = options.port ? `localhost:${options.port}` : window.location.host;\n    const wsUrl = `${protocol}//${host}${path}?api_key=${options.apiKey}`;\n\n    console.log(`[useWebSocket] Attempting to connect to: ${wsUrl}`);\n\n    const ws = new WebSocket(wsUrl);\n    webSocketRef.current = ws;\n\n    ws.onopen = () => {\n      console.log('WebSocket connection established.');\n      setIsConnected(true);\n    };\n\n    ws.onmessage = (event) => {\n      try {\n        const messageData = JSON.parse(event.data);\n        setData(messageData);\n      } catch (error) {\n        console.error('Error parsing WebSocket message:', error);\n      }\n    };\n\n    ws.onerror = (error) => {\n      console.error('WebSocket error:', error);\n    };\n\n    ws.onclose = (event) => {\n      console.log(`WebSocket connection closed: ${event.code} ${event.reason}`);\n      setIsConnected(false);\n      webSocketRef.current = null;\n    };\n\n    return () => {\n      if (ws.readyState === WebSocket.OPEN) {\n        ws.close();\n      }\n    };\n  }, [path, options.apiKey, options.port]);\n\n  return { data, isConnected };\n};\n",
    "web_service/frontend/app/types/racing.ts": "// web_platform/frontend/src/types/racing.ts\n// This file is the central source of truth for frontend racing data types.\n\n// --- Runner & Odds Interfaces ---\nexport interface OddsData {\n  win: number | null;\n  place: number | null;\n  show: number | null;\n  source: string;\n  last_updated: string;\n}\n\nexport interface Runner {\n  number: number;\n  name: string;\n  scratched: boolean;\n  selection_id?: number;\n  odds: Record<string, OddsData>;\n  jockey?: string;\n  trainer?: string;\n}\n\n// --- Race Interface ---\n// This interface matches the shape of the data returned by the API for the dashboard.\nexport interface Race {\n  id: string;\n  venue: string;\n  race_number: number;\n  start_time: string;\n  runners: Runner[];\n  source: string;\n  qualification_score?: number;\n  distance?: string;\n  surface?: string;\n  favorite?: Runner;\n  isErrorPlaceholder?: boolean;\n  errorMessage?: string;\n}\n\n// --- API Response Interfaces ---\nexport interface SourceInfo {\n  name: string;\n  status: 'SUCCESS' | 'FAILED' | 'CONFIG_ERROR' | 'PENDING';\n  racesFetched: number;\n  fetchDuration: number;\n  errorMessage?: string;\n  attemptedUrl?: string;\n}\n\nexport interface AdapterError {\n  adapterName: string;\n  errorMessage: string;\n  attemptedUrl?: string;\n}\n\nexport interface AggregatedRacesResponse {\n  races: Race[];\n  errors: AdapterError[];\n  source_info: SourceInfo[];\n}\n\n// --- Analysis Factor Interfaces (retained from previous version) ---\nexport interface Factor {\n    points: number;\n    ok: boolean;\n    reason: string;\n}\n\nexport interface TrifectaFactors {\n    [key: string]: Factor;\n}\n",
    "web_service/frontend/next.config.mjs": "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  output: 'export',  // Critical for static HTML export\n  distDir: 'out',\n  trailingSlash: true,\n  images: {\n    unoptimized: true  // Required for static export\n  },\n  async rewrites() {\n    return [\n      {\n        source: '/api/:path*',\n        destination: 'http://127.0.0.1:8000/api/:path*',\n      },\n    ]\n  },\n};\n\nexport default nextConfig;\n",
    "web_service/frontend/public/sw.js": "if(!self.define){let e,s={};const a=(a,n)=>(a=new URL(a+\".js\",n).href,s[a]||new Promise(s=>{if(\"document\"in self){const e=document.createElement(\"script\");e.src=a,e.onload=s,document.head.appendChild(e)}else e=a,importScripts(a),s()}).then(()=>{let e=s[a];if(!e)throw new Error(`Module ${a} didn\u2019t register its module`);return e}));self.define=(n,t)=>{const i=e||(\"document\"in self?document.currentScript.src:\"\")||location.href;if(s[i])return;let c={};const r=e=>a(e,i),o={module:{uri:i},exports:c,require:r};s[i]=Promise.all(n.map(e=>o[e]||r(e))).then(e=>(t(...e),c))}}define([\"./workbox-4754cb34\"],function(e){\"use strict\";importScripts(),self.skipWaiting(),e.clientsClaim(),e.precacheAndRoute([{url:\"/_next/app-build-manifest.json\",revision:\"b6130f23369e5df052a4061c412f24fa\"},{url:\"/_next/static/YkCCvmjhdkIswKuIgvFNH/_buildManifest.js\",revision:\"c155cce658e53418dec34664328b51ac\"},{url:\"/_next/static/YkCCvmjhdkIswKuIgvFNH/_ssgManifest.js\",revision:\"b6652df95db52feb4daf4eca35380933\"},{url:\"/_next/static/chunks/117-6326cd814d964913.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/816-7254031126ac0a96.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/928.d7f641058b89a54a.js\",revision:\"d7f641058b89a54a\"},{url:\"/_next/static/chunks/app/_not-found/page-e7dc36cd5a340c38.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/app/layout-605479d07717f01e.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/app/page-a2c385e93bfc2dac.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/fd9d1056-af804af0be509bea.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/framework-f66176bb897dc684.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/main-8563e00d234bd632.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/main-app-e0b3e4e952d25145.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/pages/_app-72b849fbd24ac258.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/pages/_error-7ba65e1336b92748.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/polyfills-42372ed130431b0a.js\",revision:\"846118c33b2c0e922d7b3a7676f81f6f\"},{url:\"/_next/static/chunks/webpack-d92cdde7bb2319ca.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/css/a55e4893d0564dbf.css\",revision:\"a55e4893d0564dbf\"},{url:\"/_next/static/media/19cfc7226ec3afaa-s.woff2\",revision:\"9dda5cfc9a46f256d0e131bb535e46f8\"},{url:\"/_next/static/media/21350d82a1f187e9-s.woff2\",revision:\"4e2553027f1d60eff32898367dd4d541\"},{url:\"/_next/static/media/8e9860b6e62d6359-s.woff2\",revision:\"01ba6c2a184b8cba08b0d57167664d75\"},{url:\"/_next/static/media/ba9851c3c22cd980-s.woff2\",revision:\"9e494903d6b0ffec1a1e14d34427d44d\"},{url:\"/_next/static/media/c5fe6dc8356a8c31-s.woff2\",revision:\"027a89e9ab733a145db70f09b8a18b42\"},{url:\"/_next/static/media/df0a9ae256c0569c-s.woff2\",revision:\"d54db44de5ccb18886ece2fda72bdfe0\"},{url:\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",revision:\"65850a373e258f1c897a2b3d75eb74de\"},{url:\"/manifest.json\",revision:\"23bffdb04aba9b85948642cffa772eae\"}],{ignoreURLParametersMatching:[]}),e.cleanupOutdatedCaches(),e.registerRoute(\"/\",new e.NetworkFirst({cacheName:\"start-url\",plugins:[{cacheWillUpdate:async({request:e,response:s,event:a,state:n})=>s&&\"opaqueredirect\"===s.type?new Response(s.body,{status:200,statusText:\"OK\",headers:s.headers}):s}]}),\"GET\"),e.registerRoute(/^https:\\/\\/fonts\\.(?:gstatic)\\.com\\/.*/i,new e.CacheFirst({cacheName:\"google-fonts-webfonts\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:31536e3})]}),\"GET\"),e.registerRoute(/^https:\\/\\/fonts\\.(?:googleapis)\\.com\\/.*/i,new e.StaleWhileRevalidate({cacheName:\"google-fonts-stylesheets\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:604800})]}),\"GET\"),e.registerRoute(/\\.(?:eot|otf|ttc|ttf|woff|woff2|font.css)$/i,new e.StaleWhileRevalidate({cacheName:\"static-font-assets\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:604800})]}),\"GET\"),e.registerRoute(/\\.(?:jpg|jpeg|gif|png|svg|ico|webp)$/i,new e.StaleWhileRevalidate({cacheName:\"static-image-assets\",plugins:[new e.ExpirationPlugin({maxEntries:64,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\/_next\\/image\\?url=.+$/i,new e.StaleWhileRevalidate({cacheName:\"next-image\",plugins:[new e.ExpirationPlugin({maxEntries:64,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:mp3|wav|ogg)$/i,new e.CacheFirst({cacheName:\"static-audio-assets\",plugins:[new e.RangeRequestsPlugin,new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:mp4)$/i,new e.CacheFirst({cacheName:\"static-video-assets\",plugins:[new e.RangeRequestsPlugin,new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:js)$/i,new e.StaleWhileRevalidate({cacheName:\"static-js-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:css|less)$/i,new e.StaleWhileRevalidate({cacheName:\"static-style-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\/_next\\/data\\/.+\\/.+\\.json$/i,new e.StaleWhileRevalidate({cacheName:\"next-data\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:json|xml|csv)$/i,new e.NetworkFirst({cacheName:\"static-data-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>{if(!(self.origin===e.origin))return!1;const s=e.pathname;return!s.startsWith(\"/api/auth/\")&&!!s.startsWith(\"/api/\")},new e.NetworkFirst({cacheName:\"apis\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:16,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>{if(!(self.origin===e.origin))return!1;return!e.pathname.startsWith(\"/api/\")},new e.NetworkFirst({cacheName:\"others\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>!(self.origin===e.origin),new e.NetworkFirst({cacheName:\"cross-origin\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:3600})]}),\"GET\")});\n",
    "wix/product.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:util=\"http://schemas.microsoft.com/wix/UtilExtension\">\n\n  <Product\n    Id=\"*\"\n    Name=\"Fortuna Faucet - Racing Analysis Engine\"\n    Language=\"1033\"\n    Version=\"$(var.Version)\"\n    Manufacturer=\"Mason J0 Studios\"\n    UpgradeCode=\"12345678-1234-1234-1234-123456789012\">\n\n    <Package\n      InstallerVersion=\"200\"\n      Compressed=\"yes\"\n      InstallScope=\"perMachine\"\n      Platform=\"x64\"\n      Description=\"Horse racing analysis platform\"\n      Comments=\"Professional-grade installer\"/>\n\n    <Media Id=\"1\" Cabinet=\"fortuna.cab\" EmbedCab=\"yes\"/>\n\n    <!-- Directory Structure -->\n    <Directory Id=\"TARGETDIR\" Name=\"SourceDir\">\n      <Directory Id=\"ProgramFiles64Folder\">\n        <Directory Id=\"INSTALLFOLDER\" Name=\"Fortuna Faucet\">\n        </Directory>\n      </Directory>\n      <Directory Id=\"ProgramMenuFolder\">\n        <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Faucet\"/>\n      </Directory>\n    </Directory>\n\n    <!-- Environment Variable -->\n    <ComponentGroup Id=\"EnvironmentComponentGroup\" Directory=\"INSTALLFOLDER\">\n      <Component Id=\"FortunaPortEnvironmentVar\" Guid=\"*\">\n        <Environment Id=\"FortunaPort\" Name=\"FORTUNA_PORT\" Value=\"8000\" Permanent=\"no\" Action=\"set\" System=\"yes\" />\n        <RegistryValue Root=\"HKLM\" Key=\"Software\\Fortuna Faucet\" Name=\"Path\" Type=\"string\" Value=\"[INSTALLFOLDER]\" KeyPath=\"yes\" />\n      </Component>\n    </ComponentGroup>\n\n    <!-- Features -->\n    <!-- Service Installation -->\n    <ComponentGroup Id=\"ServiceComponentGroup\" Directory=\"INSTALLFOLDER\">\n        <Component Id=\"FortunaBackendService\" Guid=\"*\">\n            <File Id=\"fortuna-backend.exe\" Source=\"$(var.BackendPath)\" KeyPath=\"yes\" />\n            <ServiceInstall\n                Id=\"FortunaServiceInstall\"\n                Type=\"ownProcess\"\n                Name=\"Fortuna\"\n                DisplayName=\"Fortuna Faucet Backend\"\n                Description=\"Data aggregation and analysis engine for horse racing.\"\n                Start=\"auto\"\n                Account=\"LocalSystem\"\n                ErrorControl=\"normal\" />\n            <ServiceControl Id=\"StartFortunaService\" Start=\"install\" Stop=\"uninstall\" Remove=\"uninstall\" Name=\"Fortuna\" Wait=\"no\" />\n        </Component>\n    </ComponentGroup>\n\n    <Feature Id=\"ProductFeature\" Title=\"Fortuna Faucet\" Level=\"1\">\n        <ComponentGroupRef Id=\"BackendFileGroup\"/>\n        <ComponentGroupRef Id=\"FrontendFileGroup\"/>\n        <ComponentGroupRef Id=\"ShortcutsComponentGroup\"/>\n        <ComponentGroupRef Id=\"EnvironmentComponentGroup\"/>\n        <ComponentGroupRef Id=\"ServiceComponentGroup\"/>\n    </Feature>\n\n    <!-- Shortcuts -->\n    <ComponentGroup Id=\"ShortcutsComponentGroup\" Directory=\"ApplicationProgramsFolder\">\n      <Component Id=\"ApplicationShortcuts\" Guid=\"*\">\n          <util:InternetShortcut Id=\"DashboardShortcut\" Name=\"Fortuna Faucet Dashboard\" Target=\"http://localhost:3000\"/>\n          <Shortcut Id=\"UninstallShortcut\" Name=\"Uninstall Fortuna Faucet\" Description=\"Remove this application\" Target=\"[SystemFolder]msiexec.exe\" Arguments=\"/x [ProductCode]\" Advertise=\"no\"/>\n          <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\"/>\n          <RegistryValue Root=\"HKCU\" Key=\"Software\\Fortuna Faucet\" Name=\"Installed\" Type=\"integer\" Value=\"1\" KeyPath=\"yes\"/>\n      </Component>\n    </ComponentGroup>\n\n    <!-- UI -->\n    <UI>\n      <UIRef Id=\"WixUI_CustomInstallDir\" />\n    </UI>\n    <UIRef Id=\"WixUI_Common\" />\n    <Property Id=\"WIXUI_INSTALLDIR\" Value=\"INSTALLFOLDER\" />\n    <WixVariable Id=\"WixUILicenseRtf\" Value=\"electron\\assets\\license.rtf\"/>\n    <WixVariable Id=\"WixUIBannerBmp\" Value=\"electron\\assets\\banner.bmp\"/>\n    <WixVariable Id=\"WixUIDialogBmp\" Value=\"electron\\assets\\dialog.bmp\"/>\n\n    <Condition Message=\"Windows 7 or later (64-bit) is required\">\n      <![CDATA[Installed OR (VersionNT64 >= 601)]]>\n    </Condition>\n\n  </Product>\n</Wix>\n"
}