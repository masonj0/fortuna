{
    ".github/dependabot.yml": "# System Timestamp: 2025-11-29 13:19:26.933797\n# To get started with Dependabot version updates, you'll need to specify which\n# package ecosystems to update and where the package manifests are located.\n# Please see the documentation for all configuration options:\n# https://docs.github.com/github/administering-a-repository/configuration-options-for-dependency-updates\n\nversion: 2\nupdates:\n  - package-ecosystem: \"pip\" # See documentation for possible values\n    directory: \"/\" # Location of package manifests\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/web_service/frontend\"\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/electron\"\n    schedule:\n      interval: \"daily\"\n",
    ".github/workflows/unified-race-report.yml": "# unified-race-report.yml\nname: 'Unified Race Report'\n\non:\n  workflow_dispatch:\n    inputs:\n      force_refresh:\n        description: 'Force refresh all data (ignore cache)'\n        required: false\n        default: 'false'\n        type: boolean\n      analyzer_type:\n        description: 'Analyzer to use'\n        required: false\n        default: 'tiny_field_trifecta'\n        type: choice\n        options:\n          - tiny_field_trifecta\n          - value_bet\n          - longshot_finder\n  push:\n    branches:\n      - main\n    paths:\n      - 'scripts/**'\n      - 'web_service/backend/**'\n      - '.github/workflows/unified-race-report.yml'\n  schedule:\n    # Run at 6 AM, 12 PM, and 6 PM UTC\n    - cron: '0 6,12,18 * * *'\n\nconcurrency:\n  group: race-report-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  PYTHON_VERSION: '3.11'\n  REPORT_RETENTION_DAYS: 14\n  MAX_RETRIES: 3\n  REQUEST_TIMEOUT: 30\n\njobs:\n  generate-unified-report:\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n\n    permissions:\n      contents: read\n      actions: write\n\n    outputs:\n      race_count: ${{ steps.run-reporter.outputs.race_count }}\n      status: ${{ steps.run-reporter.outputs.status }}\n\n    steps:\n      - name: '\ud83d\udce5 Checkout Code'\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 1\n\n      - name: '\ud83d\udc0d Setup Python'\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'web_service/backend/requirements.txt'\n\n      - name: '\ud83d\udce6 Install Dependencies'\n        run: |\n          python -m pip install --upgrade pip setuptools wheel\n          pip install -r web_service/backend/requirements.txt\n\n      - name: '\ud83d\udcc2 Create Runtime Directories'\n        run: |\n          mkdir -p web_service/backend/{data,json,logs}\n          mkdir -p reports/archive\n\n      - name: '\ud83d\udd04 Restore Data Cache'\n        if: inputs.force_refresh != 'true'\n        uses: actions/cache@v4\n        with:\n          path: |\n            web_service/backend/data/*.cache\n            web_service/backend/json/*.cache\n          key: race-data-${{ runner.os }}-${{ hashFiles('web_service/backend/requirements.txt') }}\n          restore-keys: |\n            race-data-${{ runner.os }}-\n\n      - name: '\ud83d\ude80 Run Unified Reporter'\n        id: run-reporter\n        env:\n          ANALYZER_TYPE: ${{ inputs.analyzer_type || 'tiny_field_trifecta' }}\n          FORCE_REFRESH: ${{ inputs.force_refresh || 'false' }}\n          MAX_RETRIES: ${{ env.MAX_RETRIES }}\n          REQUEST_TIMEOUT: ${{ env.REQUEST_TIMEOUT }}\n        run: |\n          set -o pipefail\n          python scripts/fortuna_reporter.py 2>&1 | tee reporter_output.log\n\n          # Extract metrics from the log for outputs\n          if [ -f \"qualified_races.json\" ]; then\n            RACE_COUNT=$(python scripts/get_race_count.py)\n            echo \"race_count=${RACE_COUNT}\" >> $GITHUB_OUTPUT\n            echo \"status=success\" >> $GITHUB_OUTPUT\n          else\n            echo \"race_count=0\" >> $GITHUB_OUTPUT\n            echo \"status=failed\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: '\ud83d\udcca Upload Report Artifacts'\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: race-reports-${{ github.run_number }}-${{ github.run_attempt }}\n          path: |\n            race-report.html\n            qualified_races.json\n            raw_race_data.json\n            reporter_output.log\n            atr_debug.html\n            sl_debug.html\n            brisnet_debug.html\n            equibase_debug.html\n            oddschecker_debug.html\n            racingpost_debug.html\n            timeform_debug.html\n          retention-days: ${{ env.REPORT_RETENTION_DAYS }}\n          if-no-files-found: warn\n          compression-level: 9\n\n      - name: '\ud83d\udcdd Post Summary to GitHub Actions'\n        if: always()\n        run: |\n          {\n            echo \"## \ud83d\udc34 Fortuna Race Report Summary\"\n            echo \"\"\n            echo \"**Run:** #${{ github.run_number }} | **Status:** ${{ steps.run-reporter.outputs.status || 'unknown' }}\"\n            echo \"**Analyzer:** ${{ inputs.analyzer_type || 'tiny_field_trifecta' }}\"\n            echo \"\"\n\n            if [ -f \"github_summary.md\" ]; then\n              cat github_summary.md\n            else\n              echo \"### \u26a0\ufe0f Detailed summary not available\"\n              echo \"\"\n              echo \"Check the artifacts for the full report.\"\n            fi\n\n            echo \"\"\n            echo \"---\"\n            echo \"*Generated at $(date -u '+%Y-%m-%d %H:%M:%S UTC')*\"\n          } >> $GITHUB_STEP_SUMMARY\n\n      - name: 'Analyze HTML on Failure'\n        if: failure()\n        id: analyze-html\n        run: |\n          mkdir -p debug-analysis\n          [ -f \"sl_debug.html\" ] && python scripts/debug_html_parser.py sl_debug.html debug-analysis/sl_analysis.json || echo \"sl_debug.html not found, skipping analysis.\"\n          [ -f \"atr_debug.html\" ] && python scripts/debug_html_parser.py atr_debug.html debug-analysis/atr_analysis.json || echo \"atr_debug.html not found, skipping analysis.\"\n          [ -f \"brisnet_debug.html\" ] && python scripts/debug_html_parser.py brisnet_debug.html debug-analysis/brisnet_analysis.json || echo \"brisnet_debug.html not found, skipping analysis.\"\n          [ -f \"equibase_debug.html\" ] && python scripts/debug_html_parser.py equibase_debug.html debug-analysis/equibase_analysis.json || echo \"equibase_debug.html not found, skipping analysis.\"\n          [ -f \"oddschecker_debug.html\" ] && python scripts/debug_html_parser.py oddschecker_debug.html debug-analysis/oddschecker_analysis.json || echo \"oddschecker_debug.html not found, skipping analysis.\"\n          [ -f \"racingpost_debug.html\" ] && python scripts/debug_html_parser.py racingpost_debug.html debug-analysis/racingpost_analysis.json || echo \"racingpost_debug.html not found, skipping analysis.\"\n          [ -f \"timeform_debug.html\" ] && python scripts/debug_html_parser.py timeform_debug.html debug-analysis/timeform_analysis.json || echo \"timeform_debug.html not found, skipping analysis.\"\n\n      - name: 'Upload Debug Analysis Artifact'\n        if: failure()\n        uses: actions/upload-artifact@v4\n        with:\n          name: debug-analysis\n          path: debug-analysis/\n          retention-days: ${{ env.REPORT_RETENTION_DAYS }}\n\n      - name: '\ud83e\uddf9 Cleanup on Failure'\n        if: failure()\n        run: |\n          echo \"::warning::Report generation failed. Check logs for details.\"\n          # Archive any partial data for debugging\n          if ls *.json 1> /dev/null 2>&1; then\n            tar -czf debug-data.tar.gz *.json *.log 2>/dev/null || true\n          fi\n\n  notify-on-failure:\n    needs: generate-unified-report\n    runs-on: ubuntu-latest\n    if: failure() && github.event_name == 'schedule'\n    steps:\n      - name: '\ud83d\udea8 Create Failure Issue'\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const title = `\ud83d\udea8 Scheduled Race Report Failed - ${new Date().toISOString().split('T')[0]}`;\n            const body = `\n            ## Automated Report Failure\n\n            The scheduled race report generation failed.\n\n            **Run ID:** ${{ github.run_id }}\n            **Run Number:** ${{ github.run_number }}\n            **Workflow:** ${{ github.workflow }}\n\n            [View Run Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n\n            Please investigate and fix any issues.\n            `;\n\n            // Check for existing open issue with the same title\n            const { data: issues } = await github.rest.issues.listForRepo({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              state: 'open',\n              labels: 'automated-failure',\n              title: title\n            });\n\n            if (issues.length === 0) {\n              await github.rest.issues.create({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                title: title,\n                body: body,\n                labels: ['automated-failure', 'bug']\n              });\n            } else {\n              console.log(`An open issue with the title \"${title}\" already exists. Skipping creation.`);\n            }\n",
    "ARCHITECTURAL_MANDATE.md": "# Fortuna Faucet - Architectural Mandate (v3.0)\n\nThis document codifies the architectural laws and philosophical principles that govern the Fortuna Faucet kingdom. Adherence to this mandate is non-negotiable for all development.\n\n---\n\n## The Prime Directive: A Professional, Resilient System\n\nThe ultimate goal of this project is to be a professional-grade, A+ intelligence engine. This is achieved through three core pillars:\n\n1.  **Rigid Standardization:** Code should be consistent and predictable. Shared logic must be centralized. Common patterns must be enforced, not merely suggested.\n2.  **Resilience Engineering:** The system must be self-healing and gracefully handle the failure of its individual components. We do not simply handle errors; we build a system that anticipates and survives them.\n3.  **Developer Clarity:** The codebase must be easy to understand, maintain, and extend. Code should be self-documenting, and its intent should be obvious.\n\n---\n\n## The Law of the Adapters: The `BaseAdapterV3` Pattern\n\nAll new data adapters **MUST** inherit from the `BaseAdapterV3` abstract base class. This is the cornerstone of our standardization and resilience strategy.\n\nThe `BaseAdapterV3` enforces a strict separation of concerns:\n\n1.  **`_fetch_data(self, date)` -> `Any`:** This method's **only** responsibility is to perform network operations and retrieve raw data (e.g., HTML, JSON). It should contain no parsing logic.\n2.  **`_parse_races(self, raw_data)` -> `list[Race]`:** This method's **only** responsibility is to parse the raw data provided by `_fetch_data` into a list of `Race` objects. It must be a pure function with no side effects or network calls.\n\nThe public-facing `get_races()` method is provided by the base class and **MUST NOT** be overridden. It orchestrates the fetch-then-parse pipeline, ensuring that all adapters behave identically from the engine's perspective.\n\nThis pattern guarantees that every adapter in our fleet is consistent, predictable, and easy to test.\n\n---\n\n## The Law of the Engine: Orchestrate, Don't Participate\n\nThe `OddsEngine` is the central orchestrator. Its responsibilities are:\n\n-   To manage the fleet of active adapters.\n-   To execute all adapter fetches in parallel.\n-   To gracefully handle the failure of any individual adapter without halting the entire process.\n-   To perform the deduplication and merging of race data from multiple sources.\n-   To manage the caching layer (Redis).\n\nThe engine should remain agnostic to the internal workings of any specific adapter. It interacts only with the standardized interface provided by `BaseAdapterV3`.\n\n---\n\n## The Law of the Core Texts: Maintain the Truth\n\nThe project's core documentation is not optional. It is the living memory and strategic guide of the kingdom.\n\n-   **`ROADMAP_APPENDICES.MD`:** The Grand Strategy must be kept current. Completed objectives must be marked as such.\n-   **`HISTORY.MD`:** Significant architectural shifts and completed campaigns must be chronicled.\n-   **`PSEUDOCODE.MD`:** The architectural blueprint must be updated to reflect major changes to the system's design.\n-   **Manifests (`MANIFEST*.md`):** All new files must be added to the appropriate manifest to ensure the integrity of the archival system.\n\n\n---\n\n## The Final Law: The Law of the True Scribe\n\n**Effective Date:** 2025-10-15\n\n**Verdict:** The system of manually maintained manifest files (`MANIFEST.md`, `MANIFEST2.md`, `MANIFEST3.md`) is hereby declared a catastrophic failure and is **permanently deprecated**.\n\n**The New Law:** The one and only method for generating the project's `FORTUNA_ALL` archives is the `ARCHIVE_PROJECT.py` script. This 'True Scribe' is the single, automated source of truth. It programmatically scans and categorizes the entire kingdom, ensuring a perfect, complete, and uncorrupted archive is generated every time.\n\nAll previous archival scripts (`create_fortuna_json.py`, `MANAGE_MANIFESTS.py`) are not to be used under any circumstances.",
    "PSEUDOCODE2026.MD": "# \ud83d\udc0e Fortuna Faucet - Complete Pseudocode Blueprint\n\n**Status:** Unified Monolith Architecture\n**Version:** 3.0.0\n**Last Updated:** January 13, 2026\n\n---\n\n## TABLE OF CONTENTS\n\n1.  System Overview\n2.  Architecture: The Unified Monolith\n3.  Backend Engine (Python/FastAPI)\n4.  Frontend Interface (TypeScript/Next.js)\n5.  Data Models & API Specification\n6.  Deployment & Automation (CI/CD)\n7.  End-to-End Workflow\n\n---\n\n## 1. SYSTEM OVERVIEW\n\n```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551         FORTUNA FAUCET - Racing Analysis Platform             \u2551\n\u2551      Unified Monolith Architecture for Cross-Platform Use      \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nMISSION:\n  \u2022 Acquire race data from 20+ global sources (APIs + web scraping).\n  \u2022 Normalize and deduplicate data into a canonical Race format.\n  \u2022 Apply analytical filters to surface high-value betting opportunities.\n  \u2022 Serve a static frontend and a REST API from a single, self-contained executable.\n  \u2022 Provide cross-platform access via launcher scripts for a Podman container.\n\nCORE TENETS:\n  \u2022 Single Origin: The backend serves the frontend, eliminating all CORS and cross-origin security issues.\n  \u2022 Zero Dependencies: The primary Windows artifact is a single .exe file that requires no external installation or setup.\n  \u2022 Containerization: For non-Windows users, a Podman container provides a consistent, isolated environment.\n  \u2022 Automated & Repeatable Builds: The entire application is built, tested, and packaged via a deterministic CI/CD pipeline (`build-monolith.yml`).\n```\n\n---\n\n## 2. ARCHITECTURE: THE UNIFIED MONOLITH\n\nThe application is a **Unified Monolith**. A single Python executable, built with PyInstaller, contains the complete application. It runs a FastAPI web server that both serves the static Next.js frontend and provides the backend REST API.\n\n```\n+------------------------------------------------------+\n| fortuna-monolith.exe (Single Executable)             |\n|                                                      |\n|  +-------------------------------------------------+ |\n|  | Python Environment                              | |\n|  |                                                 | |\n|  |  +-------------------------------------------+  | |\n|  |  | FastAPI / Uvicorn Server (localhost:8000) |  | |\n|  |  |                                           |  | |\n|  |  |  +------------------+  +----------------+ |  | |\n|  |  |  | API Router       |  | Static Files   | |  | |\n|  |  |  | (/api/*)         |  | (/, /_next/*)  | |  | |\n|  |  |  +------------------+  +----------------+ |  | |\n|  |  |           |                     |         |  | |\n|  |  +-----------|---------------------|---------+  | |\n|  |             |                     |            | |\n|  |  +----------v-----------+  +-------v--------+   | |\n|  |  | OddsEngine (engine.py)|  | Bundled Next.js|   | |\n|  |  +----------------------+  | 'out' directory|   | |\n|  |                            +----------------+   | |\n|  +-------------------------------------------------+ |\n|                                                      |\n+------------------------------------------------------+\n```\n\n---\n\n## 3. BACKEND ENGINE (PYTHON/FASTAPI)\n\n### 3.1 Entry Point & Server Startup (`web_service/backend/main.py`)\n\nThe entry point directly runs the Uvicorn server, loading the FastAPI app instance from `api.py`.\n\n```pseudocode\n// main.py\nPROCEDURE Main_Python_Entry_Point\n  // Path modifications for PyInstaller compatibility\n  IF running in a frozen (PyInstaller) environment:\n    base_path <- sys._MEIPASS\n  ELSE:\n    base_path <- path to project root\n  ADD base_path to sys.path\n\n  // Programmatically launch the FastAPI application\n  CALL uvicorn.run(\n    app=\"web_service.backend.api:app\",\n    host=\"0.0.0.0\",\n    port=8000\n  )\nEND PROCEDURE\n```\n\n### 3.2 Application & Frontend Serving (`web_service/backend/api.py`)\n\nThe `api.py` file is the core of the backend. It defines the FastAPI app, manages the application lifecycle, and includes the critical logic for serving the static frontend.\n\n```pseudocode\n// api.py\n\n// --- Lifespan Management ---\nASYNC FUNCTION lifespan_manager(app: FastAPI):\n  // ON STARTUP:\n  CONFIGURE logging\n  CREATE OddsEngine instance\n  STORE engine in app.state\n  YIELD\n  // ON SHUTDOWN:\n  AWAIT app.state.engine.close() // Gracefully close connections\n\n// --- FastAPI App Initialization ---\napp <- CREATE FastAPI(lifespan=lifespan_manager)\nADD CORS middleware\nADD Rate Limiting middleware\nINCLUDE API router (for /api/* routes)\n\n// --- CRITICAL: Unified Frontend Serving ---\nFUNCTION get_ui_directory():\n  IF running in a frozen (PyInstaller) environment:\n    RETURN path to bundled 'ui' directory (sys._MEIPASS/ui)\n  ELSE:\n    RETURN path to `web_platform/frontend/out`\nEND FUNCTION\n\nUI_DIR <- get_ui_directory()\nVERIFY UI_DIR and index.html exist, otherwise RAISE RuntimeError\n\n// --- SPA Middleware ---\n// All requests that are not for '/api/*' or a known static file type\n// will be served the `index.html` file. This allows the Next.js\n// client-side router to handle all frontend navigation.\napp.add_middleware(SPAMiddleware)\n\n// --- Static File Mount ---\n// This serves the actual .js, .css, and image files from the\n// bundled 'ui' directory.\napp.mount(\"/\", StaticFiles(directory=UI_DIR, html=True), name=\"ui\")\n```\n\n### 3.3 Resilient Fetching Strategy (`web_service/backend/engine.py`)\n\nThe `OddsEngine` is designed for resilience, using a multi-tiered fallback strategy to ensure data is returned even when some sources fail.\n\n```pseudocode\n// engine.py\n\nCLASS OddsEngine:\n  INIT():\n    self.adapters: Dict[str, Adapter]\n    self.health_monitor: AdapterHealthMonitor\n    self.stale_data_cache: StaleDataCache\n    // ... other initializations\n\n  ASYNC FUNCTION fetch_all_odds(date):\n    // Tier 1: Attempt to fetch from healthy adapters\n    healthy_adapters <- self.health_monitor.get_healthy_adapters()\n    live_results <- FETCH_IN_PARALLEL(healthy_adapters)\n\n    IF count(live_results) >= MINIMUM_REQUIRED_SOURCES:\n      MERGE and RETURN live_results\n\n    // Tier 2: Augment with degraded adapters if necessary\n    degraded_adapters <- self.health_monitor.get_degraded_adapters()\n    degraded_results <- FETCH_IN_PARALLEL(degraded_adapters)\n    live_results.extend(degraded_results)\n\n    IF count(live_results) > 0:\n      MERGE, CACHE, and RETURN live_results\n\n    // Tier 3: Fall back to stale data from the last successful run\n    stale_data <- self.stale_data_cache.get(date)\n    IF stale_data IS NOT NULL:\n      LOG \"Using stale data as a last resort.\"\n      RETURN stale_data with a 'stale' freshness flag\n\n    // Final fallback: Return an error response\n    RETURN error_response(\"All live adapters failed and no stale cache was available.\")\n\n```\n---\n\n## 4. FRONTEND INTERFACE (TYPESCRIPT/NEXT.JS)\n\n### 4.1 Configuration (`next.config.mjs`)\n\nThe frontend is a standard Next.js application configured for static export. This means it is pre-built into a set of HTML, CSS, and JS files that can be served by any static web server.\n\n```javascript\n// next.config.mjs\nconst nextConfig = {\n  output: 'export',   // CRITICAL: Generates a static site in the 'out' directory\n  distDir: 'out',\n  images: { unoptimized: true }, // Required for static export\n  trailingSlash: true,\n};\n```\n\n### 4.2 Main Dashboard Component (`src/components/LiveRaceDashboard.tsx`)\n\nWith the unified architecture, the frontend no longer needs a complex IPC mechanism. It behaves like a standard web application, making HTTP requests to the same origin that served it.\n\n```pseudocode\n// LiveRaceDashboard.tsx (Simplified)\nCOMPONENT LiveRaceDashboard:\n  STATE:\n    races: Race[] <- []\n    status: 'loading' | 'success' | 'error' <- 'loading'\n    errorMessage: string <- \"\"\n\n  EFFECT on mount:\n    fetchQualifiedRaces() // Fetch data immediately on component load\n\n  ASYNC FUNCTION fetchQualifiedRaces():\n    TRY:\n      // Make a standard, same-origin API call. No full URL needed.\n      response <- AWAIT fetch(\"/api/races/qualified/trifecta\")\n      IF NOT response.ok:\n        RAISE new Error(`API Error: ${response.statusText}`)\n\n      data <- AWAIT response.json()\n      setRaces(data.races)\n      setStatus('success')\n    CATCH e:\n      setStatus('error')\n      setErrorMessage(e.message)\nEND COMPONENT\n```\n\n---\n\n## 5. DATA MODELS & API SPECIFICATION\n\nThe data models and API endpoints remain largely the same, with the key difference being that they are all served from the `localhost:8000` origin.\n\n```\nENDPOINT GET /api/health\n  Response (200 OK): {\"status\":\"ok\"}\n\nENDPOINT GET /api/races/qualified/trifecta\n  Response (200 OK):\n    {\n      \"qualified_races\": List[Race],\n      \"analysis_metadata\": { ... }\n    }\n```\n\n---\n\n## 6. DEPLOYMENT & AUTOMATION (CI/CD)\n\nThe primary build workflow is `.github/workflows/build-monolith.yml`. It creates the single Windows executable. The `.github/workflows/build-podman.yml` workflow provides a container-based alternative for cross-platform use.\n\n### 6.1 Monolith Build (`build-monolith.yml`)\n\n```pseudocode\n// build-monolith.yml\nWORKFLOW Build_Fortuna_Monolith_EXE:\n  // Phase 1: Build Frontend\n  SETUP Node.js\n  RUN \"npm ci\" and \"npm run build\" in /web_platform/frontend\n  COPY the 'out' directory to a staging area (`frontend_dist`)\n\n  // Phase 2: Build Backend Executable\n  SETUP Python\n  INSTALL Python dependencies from requirements.txt\n  INSTALL PyInstaller\n  CREATE required data/log directories\n\n  // Phase 3: Package with PyInstaller\n  // The spec file (`fortuna-monolith.spec`) is configured to:\n  // 1. Identify `web_service/backend/main.py` as the entry point.\n  // 2. Bundle the `frontend_dist` directory into the .exe at the root 'ui'.\n  // 3. Add application icon and version info.\n  EXECUTE PyInstaller using `fortuna-monolith.spec`\n\n  // Phase 4: Smoke Test\n  START the generated `fortuna-monolith.exe` in the background\n  POLL `http://127.0.0.1:8000/api/health` until it responds with 200 OK or times out\n  IF timeout THEN FAIL build\n  KILL the process\n\n  // Phase 5: Upload Artifact\n  UPLOAD the `fortuna-monolith.exe` as a build artifact\n```\n\n### 6.2 Race Report Generation (`unified-race-report.yml`)\n\nThis workflow runs on a schedule or manually to generate the daily race reports.\n\n```pseudocode\n// unified-race-report.yml\nWORKFLOW Generate_Race_Report:\n  // Phase 1: Setup Environment\n  SETUP Python\n  INSTALL dependencies from requirements.txt\n\n  // Phase 2: Run Reporter Script\n  // The script directly invokes the OddsEngine and AnalyzerEngine\n  // without needing a live web server.\n  EXECUTE `scripts/fortuna_reporter.py`\n\n  // Phase 3: Publish Artifacts\n  // The script generates a comprehensive set of artifacts for observability.\n  UPLOAD the following files:\n    - race-report.html (The primary user-facing report)\n    - qualified_races.json (Data for the HTML report)\n    - raw_race_data.json (Unfiltered data for debugging)\n    - reporter_output.log (Full log of the reporter script)\n    - github_summary.md (For display in the GitHub Actions UI)\n```\n---\n\n## 7. END-TO-END WORKFLOW\n\n### 7.1 Windows User Workflow\n\nThe user downloads and runs a single `.exe` file.\n\n```\nWORKFLOW user_launches_monolith_exe:\n  STEP 1: User executes `fortuna-monolith.exe`.\n  STEP 2: The embedded Python environment starts.\n  STEP 3: The Uvicorn server starts inside the process.\n  STEP 4: The FastAPI application initializes, mounts the bundled 'ui' directory, and opens the API endpoints.\n  STEP 5: The user's default web browser is automatically opened to `http://127.0.0.1:8000`.\n  STEP 6: The browser loads `index.html` from the FastAPI server.\n  STEP 7: The Next.js application hydrates and makes same-origin API calls to `/api/*` to fetch data.\n```\n\n### 7.2 Cross-Platform (Podman) User Workflow\n\nThe user runs a launcher script that manages a Podman container.\n\n```\nWORKFLOW user_launches_podman_script:\n  STEP 1: User executes `launcher.bat` or `./launcher.sh`.\n  STEP 2: The script pulls the latest `ghcr.io/masonj0/fortuna-faucet` image.\n  STEP 3: The script starts a Podman container, mapping port 8000 and volume mounting local `data` and `logs` directories.\n  STEP 4: The container runs the same Python application, which starts the Uvicorn/FastAPI server.\n  STEP 5: The user's default web browser is automatically opened to `http://127.0.0.1:8000`.\n  STEP 6: The workflow proceeds identically to the Windows user workflow from Step 6 onward.\n```\n\n---\n*This concludes the blueprint for the Fortuna Faucet unified monolith architecture.*\n",
    "ROADMAP_APPENDICES.md": "# \ud83d\uddfa\ufe0f Fortuna Faucet - Roadmap & Accomplishments\n\nThis document tracks the strategic evolution of the Fortuna Faucet project.\n\n## Phase 1: Core Engine Development (Complete)\n- **Objective:** Build a robust, scalable data extraction and analysis engine.\n- **Status:** COMPLETE.\n\n## Phase 2: The Golden Path - UX Overhaul (Complete)\n- **Objective:** Transform the developer-centric tool into a seamless, professional-grade Windows application for non-technical users.\n- **Status:** COMPLETE.\n\n## Phase 3: The Turnkey Solution - Professional Release Pipeline (Complete)\n- **Objective:** Eliminate all manual setup steps and create an enterprise-grade, automated build and release system.\n- **Status:** COMPLETE.\n\n### Key Accomplishments & Completed Operations:\n\n1.  **Operation: The Great Housekeeping**\n    - Purified the repository architecture, deprecated legacy codebases and scripts, and established a clean foundation.\n    - Forged a new, programmatic manifest generation system.\n\n2.  **Operation: The Blueprint**\n    - Established the professional directory structure for an enterprise-grade build system.\n    - Implemented the master WiX product definition and the PowerShell build orchestrator.\n\n3.  **Operation: The Assembly Line**\n    - Fully automated the MSI build process with a GitHub Actions CI/CD workflow.\n\n4.  **Operation: The Proving Ground**\n    - Forged a complete suite of automated PowerShell scripts to test and validate the integrity of every installer artifact (install, silent deploy, uninstall).\n\n5.  **Operation: The User's Keys**\n    - Created the final, user-facing toolkit of scripts for easy lifecycle management (install, uninstall, repair).\n\n6.  **Operation: Modernize the Assembly Line**\n    - Performed a surgical upgrade to the CI/CD pipeline to resolve a critical GitHub Actions deprecation, ensuring continued operational readiness.\n\n7.  **Operation: The Forge**\n    - Executed a critical architectural overhaul of the entire release pipeline.\n    - Replaced the fragile, runtime-dependent installer with a robust \"Three-Executable Architecture.\"\n    - The Python backend is now a standalone executable compiled with PyInstaller, and the frontend is a static export, eliminating all runtime dependencies and post-install scripting.\n\n## Phase 4: User Experience & Feature Enhancement (Next Steps)\n- **Objective:** Enhance the core user experience and expand the analytical capabilities of the engine.\n- **Status:** PENDING.\n- **Potential Missions:**\n  - **Operation: The Interpreter:** Implement a user-friendly error-handling system that translates technical errors into simple, actionable advice.\n  - **Data Persistence & Caching:** Implement a local SQLite database to cache race data, improving performance and enabling offline access.\n  - **Operation: The Polisher:** Address technical debt by refactoring backend code to resolve deprecation warnings and align with modern library standards.\n  - **Operation: The Shield:** Improve backend test coverage by adding unit tests for untested data adapters and the Electron main process.\n  - **Operation: The Auditor (Real-Time Verification)**\n    - **Goal:** Implement a 'Last Hour' retrospective dashboard to validate the 'Favorite to Place' strategy.\n    - **Core Logic:**\n      1.  **Snapshot:** Log every 'Qualifier' race prediction to a local DB (SQLite/Redis) with a timestamp and the predicted Favorite.\n      2.  **The Fetcher:** Periodically poll for official results of races that finished in the last 60 minutes.\n      3.  **The Verdict:** Compare the predicted Favorite against the official Finish Order.\n          - *Win:* Did it finish 1st, 2nd, (or 3rd)? -> CASHED.\n          - *Loss:* Did it finish out of the money? -> BURNED.\n      4.  **The 'Tiny Profit' Calc:** Calculate Net Profit based on the standard $2.00 tote unit.\n          - *Formula:* `Net Profit = (Official_Place_Payout - 2.00)`\n          - *Example:* Payout $2.60 -> Profit +$0.60. Payout $0.00 -> Profit -$2.00.\n    - **Data Sources:**\n      - *US Racing:* Scrape `https://www.equibase.com/static/chart/summary/index.html` (Free Summary Charts contain Final Odds & Payoffs).\n      - *UK/Dogs:* Use `The Racing API` or `GBGB` results endpoints.\n    - **UI:** Display a rolling 'Strike Rate' % and 'Net Profit (1H)' ticker.\n",
    "START_DEV_ENVIRONMENT.bat": "@echo off\nREM This script provides a user-friendly, double-clickable way to start the\nREM development environment by running the fortuna-quick-start.ps1 script.\nREM It bypasses the system's PowerShell execution policy for this script only.\n\necho Starting Fortuna Faucet Development Environment...\necho This will open two new terminal windows for the backend and frontend.\n\npowershell.exe -ExecutionPolicy Bypass -File \"%~dp0scripts\\fortuna-quick-start.ps1\"\n\necho.\necho Script execution finished. The development servers are running in new windows.\npause\n",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2)---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "configure_startup.py": "# configure_startup.py\nimport sys\nimport winreg\nfrom pathlib import Path\n\n\nclass StartupManager:\n    \"\"\"Manage Windows startup registry entries for the current user.\"\"\"\n\n    REGISTRY_PATH = r\"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n    APP_NAME = \"FortunaFaucetTray\"\n\n    @classmethod\n    def is_enabled(cls) -> bool:\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_READ)\n            winreg.QueryValueEx(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            return True\n        except FileNotFoundError:\n            return False\n\n    @classmethod\n    def enable(cls):\n        launcher_path = Path(__file__).parent / \"launcher.ps1\"\n        cmd = f'powershell.exe -WindowStyle Hidden -File \"{launcher_path}\"'\n\n        key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n        winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, cmd)\n        winreg.CloseKey(key)\n        print(\"Startup enabled.\")\n\n    @classmethod\n    def disable(cls):\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n            winreg.DeleteValue(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            print(\"Startup disabled.\")\n        except FileNotFoundError:\n            print(\"Already disabled.\")\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"enable\":\n            StartupManager.enable()\n        elif sys.argv[1] == \"disable\":\n            StartupManager.disable()\n        elif sys.argv[1] == \"status\":\n            print(f\"Startup is currently {'enabled' if StartupManager.is_enabled() else 'disabled'}\")\n    else:\n        print(\"Usage: python configure_startup.py [enable|disable|status]\")\n",
    "electron/assets/license.rtf": "{\\rtf1\\ansi\\deff0\n{\\fonttbl{\\f0 Courier New;}}\n\\f0\\fs20\nFortuna Faucet License Agreement\\line\n\\line\nThis is a hobby project. It was cobbled together with a lot of caffeine and hope.\\line\n\\line\nThere are no warranties, guarantees, or promises that this will work.\\line\nFeel free to use it, break it, or share it. No copyrights are claimed.\\line\n\\line\nGood luck! You might need it.\n}",
    "electron/preload.js": "// electron/preload.js\n// This script runs in a privileged environment with access to Node.js APIs.\n// It's used to securely expose specific functionality to the renderer process (the web UI).\n\nconst { contextBridge, ipcRenderer } = require('electron');\n\n// Expose a safe, limited API to the frontend.\ncontextBridge.exposeInMainWorld('electronAPI', {\n /**\n * Asynchronously fetches the secure API key from the main process.\n * @returns {Promise<string|null>} A promise that resolves with the API key or null if not found.\n */\n getApiKey: () => ipcRenderer.invoke('get-api-key'),\n\n /**\n * Asynchronously generates and saves a new secure API key.\n * @returns {Promise<string>} A promise that resolves with the newly generated API key.\n */\n generateApiKey: () => ipcRenderer.invoke('generate-api-key'),\n\n /**\n * Asynchronously saves a provided API key.\n * @param {string} apiKey - The API key to save.\n * @returns {Promise<{success: boolean}>} A promise that resolves with the result of the save operation.\n */\n saveApiKey: (apiKey) => ipcRenderer.invoke('save-api-key', apiKey),\n\n /**\n * Asynchronously saves Betfair credentials.\n * @param {{username: string, apiKey: string}} credentials - The credentials to save.\n * @returns {Promise<{success: boolean}>} A promise that resolves with the result of the save operation.\n */\n saveBetfairCredentials: (credentials) => ipcRenderer.invoke('save-betfair-credentials', credentials),\n\n /**\n  * Restarts the backend service.\n  */\n restartBackend: () => ipcRenderer.send('restart-backend'),\n\n /**\n  * Stops the backend service.\n  */\n stopBackend: () => ipcRenderer.send('stop-backend'),\n\n /**\n  * Fetches the current status of the backend service.\n  * @returns {Promise<{state: string, logs: string[]}>} A promise that resolves with the backend status.\n  */\n getBackendStatus: () => ipcRenderer.invoke('get-backend-status'),\n\n /**\n  * Subscribes to backend status updates.\n  * @param {function(event, {state: string, logs: string[]})} callback - The function to call with status updates.\n  */\n onBackendStatusUpdate: (callback) => {\n    // Deliberately strip event sender from callback to avoid security risks\n    const subscription = (event, ...args) => callback(...args);\n    ipcRenderer.on('backend-status-update', subscription);\n\n    // Return a function to unsubscribe\n    return () => {\n      ipcRenderer.removeListener('backend-status-update', subscription);\n    };\n  },\n\n  /**\n   * Gets the port the backend API is running on.\n   * @returns {Promise<number>} A promise that resolves with the port number.\n   */\n  getApiPort: () => ipcRenderer.invoke('get-api-port'),\n});\n",
    "fortuna-backend-electron.spec": "# -*- mode: python ; coding: utf-8 -*-\nfrom pathlib import Path\nfrom PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\nblock_cipher = None\nproject_root = Path(SPECPATH).parent\n# FIXED: Target the consolidated backend\nbackend_root = project_root / 'web_service' / 'backend'\n\n# Collect data folders\ndatas = []\nfor folder in ['data', 'json', 'adapters']:\n    source_path = backend_root / folder\n    if source_path.exists():\n        datas.append((str(source_path), folder))\n\n# CRITICAL: Bundle the frontend assets\nfrontend_dist = project_root / 'web_service' / 'frontend' / 'public'\nif frontend_dist.exists():\n    datas.append((str(frontend_dist), 'public'))\n\n# Collect dependencies\nhiddenimports = [\n    'uvicorn', 'fastapi', 'starlette', 'pydantic', 'structlog',\n    'tenacity', 'redis', 'sqlalchemy', 'greenlet', 'win32timezone'\n] + collect_submodules('web_service.backend')\n\na = Analysis(\n    ['web_service/backend/main.py'], # FIXED: Entry point\n    pathex=[str(project_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.zipfiles, a.datas,\n    name='fortuna-backend',\n    debug=False,\n    strip=False,\n    upx=True,\n    console=True, # Keep console for Electron backend debugging\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\n",
    "fortuna-unified.spec": "# -*- mode: python ; coding: utf-8 -*-\nfrom PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\nblock_cipher = None\n\n# Collect data folders\ndatas = [\n    # Python service data\n    ('web_service/backend/data', 'data'),\n    ('web_service/backend/json', 'json'),\n    ('web_service/backend/adapters', 'adapters'),\n    # CRITICAL: Bundle the Next.js static frontend build\n    ('web_platform/frontend/out', 'ui'),\n]\n\n# Collect dependencies\nhiddenimports = [\n    'uvicorn', 'fastapi', 'starlette', 'pydantic', 'structlog',\n    'tenacity', 'redis', 'sqlalchemy', 'greenlet', 'win32timezone'\n] + collect_submodules('web_service.backend')\n\na = Analysis(\n    ['web_service/backend/main.py'],\n    pathex=['.'],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.zipfiles, a.datas,\n    name='fortuna-webservice',\n    debug=False,\n    strip=False,\n    upx=True,\n    console=True,\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n    icon='assets/icon.ico',\n    version='file_version_info.txt'\n)",
    "manual_override_tool.py": "import argparse\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Manual Override Tool for Checkmate Data Warehouse.\")\n    parser.add_argument(\"--file\", required=True, help=\"Path to the CSV file for ingestion.\")\n    parser.add_argument(\"--user\", required=True, help=\"The user ID performing the override.\")\n    args = parser.parse_args()\n\n    print(f\"Executing manual override by '{args.user}' for file '{args.file}'...\")\n\n    # 1. Connect to PostgreSQL\n    # engine = create_engine('postgresql://user:password@host:port/database')\n\n    # 2. Read and validate the CSV data\n    # race_df = pd.read_csv(args.file)\n    # ... validation logic ...\n\n    # 3. Add the manual_override_by column\n    # race_df['manual_override_by'] = args.user\n\n    # 4. Insert data into the 'historical_races' table\n    # race_df.to_sql('historical_races', engine, if_exists='append', index=False)\n\n    print(\"Manual override completed successfully.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "pg_schemas/quarantine_races.sql": "CREATE TABLE IF NOT EXISTS quarantine_races (\n    quarantine_id SERIAL PRIMARY KEY,\n    race_id VARCHAR(100),\n    track_name VARCHAR(100),\n    race_number INT,\n    post_time TIMESTAMP WITH TIME ZONE,\n    source VARCHAR(50),\n    raw_data_json JSONB, -- Store the original raw data for inspection\n    quarantine_reason TEXT, -- Reason for failing validation\n    collection_timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);",
    "requirements-dev.in": "#\n# Fortuna Faucet - High-Level Development & Testing Dependencies\n# This file is the source of truth for development dependencies.\n# Run 'pip-compile' to generate requirements-dev.txt.\n#\n\n# --- Core Testing Frameworks ---\npytest\npytest-asyncio\nfakeredis[lua]\nrespx\nplaywright\n\n# --- Code Quality & Linting ---\nblack\n# ruff is often used with black\n\n# --- Analysis & Notebooks ---\n# pandas is already in the main requirements.in\naltair\npydeck\nstreamlit\ntabula-py\n\n# --- Git & Versioning ---\nGitPython\n\n# --- Security & Auditing ---\npip-audit\n",
    "requirements-dev.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=requirements-dev.txt requirements-dev.in\n#\naltair==5.5.0\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\nanyio==4.11.0\n    # via httpx\nattrs==25.4.0\n    # via\n    #   jsonschema\n    #   referencing\nblack==25.11.0\n    # via -r requirements-dev.in\nblinker==1.9.0\n    # via streamlit\nboolean-py==5.0\n    # via license-expression\ncachecontrol[filecache]==0.14.3\n    # via\n    #   cachecontrol\n    #   pip-audit\ncachetools==6.2.1\n    # via streamlit\ncertifi==2023.7.22\n    # via\n    #   httpcore\n    #   httpx\n    #   requests\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.0\n    # via\n    #   black\n    #   streamlit\ncyclonedx-python-lib==9.1.0\n    # via pip-audit\ndefusedxml==0.7.1\n    # via py-serializable\ndistro==1.9.0\n    # via tabula-py\nfakeredis[lua]==2.23.0\n    # via -r requirements-dev.in\nfilelock==3.20.0\n    # via cachecontrol\ngitdb==4.0.12\n    # via gitpython\ngitpython==3.1.45\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\ngreenlet==3.2.4\n    # via playwright\nh11==0.16.0\n    # via httpcore\nhttpcore==1.0.9\n    # via httpx\nhttpx==0.28.1\n    # via respx\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njinja2==3.1.6\n    # via\n    #   altair\n    #   pydeck\njsonschema==4.25.1\n    # via altair\njsonschema-specifications==2025.9.1\n    # via jsonschema\nlicense-expression==30.4.4\n    # via cyclonedx-python-lib\nlupa==2.6\n    # via fakeredis\nmarkdown-it-py==4.0.0\n    # via rich\nmarkupsafe==3.0.3\n    # via jinja2\nmdurl==0.1.2\n    # via markdown-it-py\nmsgpack==1.1.2\n    # via cachecontrol\nmypy-extensions==1.1.0\n    # via black\nnarwhals==2.9.0\n    # via altair\nnumpy==2.3.4\n    # via\n    #   pandas\n    #   pydeck\n    #   streamlit\n    #   tabula-py\npackageurl-python==0.17.5\n    # via cyclonedx-python-lib\npackaging==25.0\n    # via\n    #   altair\n    #   black\n    #   pip-audit\n    #   pip-requirements-parser\n    #   pytest\n    #   streamlit\npandas==2.3.3\n    # via\n    #   streamlit\n    #   tabula-py\npathspec==0.12.1\n    # via black\npillow==11.3.0\n    # via streamlit\npip-api==0.0.34\n    # via pip-audit\npip-audit==2.9.0\n    # via -r requirements-dev.in\npip-requirements-parser==32.0.1\n    # via pip-audit\nplatformdirs==4.5.0\n    # via\n    #   black\n    #   pip-audit\nplaywright==1.55.0\n    # via -r requirements-dev.in\npluggy==1.6.0\n    # via pytest\nprotobuf==6.33.0\n    # via streamlit\npy-serializable==2.1.0\n    # via cyclonedx-python-lib\npyarrow==21.0.0\n    # via streamlit\npydeck==0.9.1\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\npyee==13.0.0\n    # via playwright\npygments==2.19.2\n    # via\n    #   pytest\n    #   rich\npyparsing==3.2.5\n    # via pip-requirements-parser\npytest==8.4.2\n    # via\n    #   -r requirements-dev.in\n    #   pytest-asyncio\npytest-asyncio==1.2.0\n    # via -r requirements-dev.in\npython-dateutil==2.9.0.post0\n    # via pandas\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==7.0.1\n    # via fakeredis\nreferencing==0.37.0\n    # via\n    #   jsonschema\n    #   jsonschema-specifications\nrequests==2.32.5\n    # via\n    #   cachecontrol\n    #   pip-audit\n    #   streamlit\nrespx==0.22.0\n    # via -r requirements-dev.in\nrich==14.2.0\n    # via pip-audit\nrpds-py==0.28.0\n    # via\n    #   jsonschema\n    #   referencing\nsix==1.17.0\n    # via python-dateutil\nsmmap==5.0.2\n    # via gitdb\nsniffio==1.3.1\n    # via anyio\nsortedcontainers==2.4.0\n    # via\n    #   cyclonedx-python-lib\n    #   fakeredis\nstreamlit==1.50.0\n    # via -r requirements-dev.in\ntabula-py==2.10.0\n    # via -r requirements-dev.in\ntenacity==8.2.3\n    # via streamlit\ntoml==0.10.2\n    # via\n    #   pip-audit\n    #   streamlit\ntornado==6.5.2\n    # via streamlit\ntyping-extensions==4.15.0\n    # via\n    #   altair\n    #   anyio\n    #   pyee\n    #   pytest-asyncio\n    #   referencing\n    #   streamlit\ntzdata==2025.2\n    # via pandas\nurllib3==2.6.2\n    # via requests\nwatchdog==6.0.0\n    # via streamlit\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n",
    "scripts/generate_manifests.py": "# scripts/generate_manifests.py\nimport json\nimport os\nfrom pathlib import Path\n\n# --- Configuration ---\nROOT_DIR = Path(\".\")\nOUTPUT_DIR = Path(\".\")\nNUM_MANIFESTS = 5 # We will create 5 balanced manifests\n\n# --- Inclusion/Exclusion Rules ---\n# This script is now comprehensive. Instead of a narrow include list,\n# it scans everything and uses a more precise exclusion list.\nINCLUDE_ONLY_DIRS = None # Deactivated: We now scan all directories by default\n\nEXCLUDE_DIRS = {\n    # Standard git/ide/v-env exclusions\n    \".git\", \".idea\", \".vscode\", \"node_modules\", \".next\", \".venv\",\n    # Build artifacts and caches\n    \"dist\", \"build\", \"__pycache__\", \".pytest_cache\", \"out\", \"build_wix\",\n    # Agent-specific/Volatile directories\n    \"attic\", \"installer\", \"ReviewableJSON\", \"jules-scratch\",\n    # Legacy code not relevant to the current monolith\n    \"PREV_src\", \"python_service\",\n}\n\nEXCLUDE_FILES_BY_EXTENSION = {\n    # Archives and logs\n    \".zip\", \".json\", \".log\", \".db\", \".sqlite3\",\n    # Binary/Image formats not useful for LLM context\n    \".png\", \".ico\", \".bmp\", \".exe\", \".dll\", \".pyd\", \".pdf\",\n    # Deactivated workflows (keep them for history, but not for active context)\n    \".ymlx\"\n}\n\n\ndef get_all_project_files():\n    \"\"\"\n    Walks the entire project directory to find all relevant files for archiving,\n    respecting a detailed set of exclusion rules.\n    \"\"\"\n    all_files_with_size = []\n    print(\"\\n--- Starting Comprehensive File Audit ---\")\n    scanned_count = 0\n    included_count = 0\n\n    for root, dirs, files in os.walk(ROOT_DIR, topdown=True):\n        current_path = Path(root)\n\n        # 1. Directory Exclusion: Prune entire directory subtrees\n        dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS and not d.endswith('.egg-info')]\n\n        for name in files:\n            scanned_count += 1\n            file_path = current_path / name\n\n            # 2. Filename/Extension Exclusion\n            if name.startswith(('MANIFEST_PART', 'FORTUNA_ALL_PART', '.env')):\n                continue\n            if file_path.suffix in EXCLUDE_FILES_BY_EXTENSION:\n                continue\n\n            # Special case: allow '.spec' files which are critical configs\n            if file_path.suffix == '.spec' and name not in ['api.spec']:\n                 pass # keep it\n            elif file_path.suffix in ['.spec']:\n                 continue # exclude other .spec files\n\n            try:\n                posix_path = str(file_path.as_posix())\n                size = os.path.getsize(file_path)\n                all_files_with_size.append((posix_path, size))\n                included_count += 1\n            except FileNotFoundError:\n                print(f\"[WARNING] File not found during scan: {file_path}\")\n                continue\n\n    print(f\"Scanned {scanned_count} files, included {included_count} for manifest.\")\n    print(\"--- File Audit Complete ---\\n\")\n    return all_files_with_size\n\n\ndef balance_files_by_size(files_with_size, num_bins):\n    \"\"\"\n    Distributes files into a specified number of bins, balancing by size and count.\n    Uses a hybrid greedy and round-robin approach for better distribution.\n    \"\"\"\n    # Define categories for more granular balancing\n    categories = {\n        'large': [], 'medium': [], 'small': [], 'config': [], 'docs': [],\n        'workflows': [], 'scripts': [], 'source': []\n    }\n\n    # Categorize files based on extension and size\n    for path, size in files_with_size:\n        ext = Path(path).suffix.lower()\n        if 'github/workflows' in path:\n            categories['workflows'].append((path, size))\n        elif ext in ['.md', '.txt']:\n            categories['docs'].append((path, size))\n        elif ext in ['.json', '.toml', '.ini', '.spec', '.lock']:\n            categories['config'].append((path, size))\n        elif ext == '.py' and 'scripts' in path:\n            categories['scripts'].append((path, size))\n        elif ext in ['.py', '.js', '.ts', '.tsx', '.css', '.html', '.wxs']:\n            if size > 50 * 1024:  # Over 50KB\n                categories['large'].append((path, size))\n            elif size > 10 * 1024: # Over 10KB\n                categories['medium'].append((path, size))\n            else:\n                categories['small'].append((path, size))\n        else:\n            categories['source'].append((path, size))\n\n    bins = [[] for _ in range(num_bins)]\n    bin_sizes = [0] * num_bins\n\n    # Distribute large files first using greedy approach\n    for category in ['large', 'medium']:\n        # Sort descending to place largest files first\n        categories[category].sort(key=lambda x: x[1], reverse=True)\n        for path, size in categories[category]:\n            min_bin_index = bin_sizes.index(min(bin_sizes))\n            bins[min_bin_index].append(path)\n            bin_sizes[min_bin_index] += size\n\n    # Distribute remaining files using round-robin to balance file count\n    current_bin = 0\n    for category in ['small', 'config', 'docs', 'workflows', 'scripts', 'source']:\n        # Sort alphabetically for consistent distribution\n        categories[category].sort(key=lambda x: x[0])\n        for path, size in categories[category]:\n            bins[current_bin].append(path)\n            bin_sizes[current_bin] += size\n            current_bin = (current_bin + 1) % num_bins\n\n    # Print the balancing results for verification\n    print(\"--- Manifest Balancing Results (Enhanced) ---\")\n    for i, (file_list, total_size) in enumerate(zip(bins, bin_sizes)):\n        print(\n            f\" Manifest {i+1}: {len(file_list):>4} files, \"\n            f\"Total size: {total_size / 1024 / 1024:>6.2f} MB\"\n        )\n    print(\"------------------------------------------\")\n\n    return bins\n\n\ndef main():\n    \"\"\"Generate balanced manifest files based on file size.\"\"\"\n    print(\"--- Starting Manifest Generation (Size-Balanced) ---\")\n    all_files = get_all_project_files()\n    print(f\"Found {len(all_files)} total project files to consider.\")\n\n    balanced_manifests = balance_files_by_size(all_files, NUM_MANIFESTS)\n\n    # Write the updated manifest files\n    for i, file_list in enumerate(balanced_manifests):\n        manifest_name = f\"MANIFEST_PART{i+1}.json\"\n        output_path = OUTPUT_DIR / manifest_name\n        sorted_files = sorted(file_list) # Sort alphabetically for consistency\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(sorted_files, f, indent=4)\n        print(f\"\u2705 Wrote {len(sorted_files)} entries to {output_path}\")\n\n    print(\"\\n[SUCCESS] All manifest files have been generated and balanced.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/install_fortuna_silent.bat": "@echo off\nREM Automated deployment (no UI, minimal interaction)\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\nREM Assumes the MSI is in the 'dist' subfolder relative to the project root\nmsiexec.exe /i \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" ^\n    /qn ^\n    /l*v \"%TEMP%\\fortuna_silent_install.log\" ^\n    /norestart ^\n    ALLUSERS=1 ^\n    INSTALLSCOPE=perMachine\n\nexit /b %errorlevel%",
    "scripts/templates/race_report_template.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>\ud83d\udc34 Fortuna Faucet - Race Report</title>\n    <style>\n        :root {\n            --color-primary: #00ff88;\n            --color-primary-dim: rgba(0, 255, 136, 0.1);\n            --color-primary-muted: rgba(0, 255, 136, 0.2);\n            --color-bg-dark: #0f1419;\n            --color-bg-card: #0f3460;\n            --color-bg-card-hover: #1a4d7a;\n            --color-text: #e2e8f0;\n            --color-text-muted: #a0aec0;\n            --color-border: #1a3a52;\n            --color-error: #ff4444;\n            --color-warning: #ffaa00;\n            --shadow-card: 0 4px 20px rgba(0, 0, 0, 0.3);\n            --shadow-glow: 0 0 10px rgba(0, 255, 136, 0.5);\n            --transition-fast: 0.2s ease;\n            --transition-normal: 0.3s ease;\n        }\n\n        .light-mode {\n            --color-bg-dark: #f5f7fa;\n            --color-bg-card: #ffffff;\n            --color-bg-card-hover: #f0f4f8;\n            --color-text: #1a202c;\n            --color-text-muted: #718096;\n            --color-border: #e2e8f0;\n            --shadow-card: 0 4px 20px rgba(0, 0, 0, 0.1);\n        }\n\n        * { margin: 0; padding: 0; box-sizing: border-box; }\n        html { scroll-behavior: smooth; }\n\n        body {\n            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;\n            background: linear-gradient(135deg, var(--color-bg-dark) 0%, #1a1f2e 50%, #16213e 100%);\n            color: var(--color-text);\n            line-height: 1.6;\n            min-height: 100vh;\n        }\n\n        .light-mode body {\n            background: var(--color-bg-dark);\n        }\n\n        .container {\n            max-width: 1400px;\n            margin: 0 auto;\n            padding: 1rem;\n        }\n\n        @media (min-width: 768px) {\n            .container { padding: 2rem; }\n        }\n\n        /* Header */\n        header {\n            text-align: center;\n            margin-bottom: 2rem;\n            background: linear-gradient(135deg, rgba(15, 52, 96, 0.5), var(--color-primary-dim));\n            border: 2px solid var(--color-primary);\n            border-radius: 12px;\n            padding: 2rem 1rem;\n            box-shadow: 0 8px 32px var(--color-primary-muted);\n        }\n\n        @media (min-width: 768px) {\n            header { padding: 3rem 2rem; }\n        }\n\n        h1 {\n            color: var(--color-primary);\n            font-size: clamp(1.5rem, 5vw, 2.8rem);\n            margin-bottom: 0.5rem;\n            text-shadow: var(--shadow-glow);\n        }\n\n        .subtitle {\n            color: var(--color-text-muted);\n            font-size: 0.9rem;\n            margin-top: 0.25rem;\n        }\n\n        /* Controls */\n        .controls {\n            display: flex;\n            flex-wrap: wrap;\n            gap: 1rem;\n            margin: 1.5rem 0;\n            padding: 1rem;\n            background: var(--color-primary-dim);\n            border-radius: 8px;\n            align-items: center;\n        }\n\n        .search-box {\n            flex: 1;\n            min-width: 200px;\n            padding: 0.75rem 1rem;\n            border: 1px solid var(--color-border);\n            border-radius: 6px;\n            background: rgba(0, 0, 0, 0.2);\n            color: var(--color-text);\n            font-size: 1rem;\n        }\n\n        .light-mode .search-box {\n            background: white;\n        }\n\n        .search-box:focus {\n            outline: none;\n            border-color: var(--color-primary);\n            box-shadow: 0 0 0 2px var(--color-primary-muted);\n        }\n\n        .search-box::placeholder {\n            color: var(--color-text-muted);\n        }\n\n        .btn {\n            padding: 0.75rem 1.25rem;\n            border: 1px solid var(--color-primary);\n            border-radius: 6px;\n            background: transparent;\n            color: var(--color-primary);\n            font-size: 0.9rem;\n            cursor: pointer;\n            transition: all var(--transition-fast);\n            white-space: nowrap;\n        }\n\n        .btn:hover, .btn:focus {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .btn:focus {\n            outline: none;\n            box-shadow: 0 0 0 2px var(--color-primary-muted);\n        }\n\n        .btn.active {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .sort-controls {\n            display: flex;\n            gap: 0.5rem;\n            flex-wrap: wrap;\n        }\n\n        .theme-toggle {\n            margin-left: auto;\n        }\n\n        /* Summary Box */\n        .summary-box {\n            background: var(--color-primary-dim);\n            border-left: 4px solid var(--color-primary);\n            border-radius: 8px;\n            padding: 1.25rem 1.5rem;\n            margin: 1.5rem 0;\n            display: flex;\n            flex-wrap: wrap;\n            gap: 1rem;\n            justify-content: space-between;\n            align-items: center;\n        }\n\n        .summary-stat {\n            text-align: center;\n        }\n\n        .summary-stat-value {\n            font-size: 1.5rem;\n            font-weight: bold;\n            color: var(--color-primary);\n        }\n\n        .summary-stat-label {\n            font-size: 0.8rem;\n            color: var(--color-text-muted);\n            text-transform: uppercase;\n            letter-spacing: 0.5px;\n        }\n\n        /* Race Cards */\n        .race-grid {\n            display: grid;\n            gap: 1.5rem;\n        }\n\n        .race-card {\n            background: linear-gradient(135deg, var(--color-bg-card) 0%, var(--color-bg-card-hover) 100%);\n            border: 1px solid var(--color-primary-muted);\n            border-left: 4px solid var(--color-primary);\n            border-radius: 12px;\n            padding: 1.5rem;\n            box-shadow: var(--shadow-card);\n            transition: all var(--transition-normal);\n        }\n\n        .light-mode .race-card {\n            background: var(--color-bg-card);\n        }\n\n        .race-card:hover {\n            transform: translateY(-2px);\n            box-shadow: 0 8px 30px var(--color-primary-muted);\n            border-color: rgba(0, 255, 136, 0.5);\n        }\n\n        .race-card.collapsed .race-content {\n            display: none;\n        }\n\n        .race-header {\n            display: flex;\n            justify-content: space-between;\n            align-items: flex-start;\n            margin-bottom: 1rem;\n            padding-bottom: 1rem;\n            border-bottom: 2px solid var(--color-primary);\n            flex-wrap: wrap;\n            gap: 0.75rem;\n            cursor: pointer;\n        }\n\n        .race-header-info {\n            flex: 1;\n            min-width: 200px;\n        }\n\n        .race-title {\n            font-size: 1.2rem;\n            font-weight: bold;\n            color: var(--color-primary);\n            display: flex;\n            align-items: center;\n            gap: 0.5rem;\n        }\n\n        .race-meta {\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n            margin-top: 0.25rem;\n        }\n\n        .race-badges {\n            display: flex;\n            gap: 0.5rem;\n            flex-wrap: wrap;\n        }\n\n        .badge {\n            padding: 0.25rem 0.75rem;\n            border-radius: 20px;\n            font-size: 0.75rem;\n            font-weight: 600;\n            text-transform: uppercase;\n            letter-spacing: 0.5px;\n        }\n\n        .badge-score {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .badge-runners {\n            background: var(--color-primary-muted);\n            color: var(--color-primary);\n        }\n\n        .collapse-icon {\n            transition: transform var(--transition-fast);\n        }\n\n        .race-card.collapsed .collapse-icon {\n            transform: rotate(-90deg);\n        }\n\n        /* Runners Table */\n        .runners-table {\n            width: 100%;\n            border-collapse: collapse;\n            margin-top: 1rem;\n        }\n\n        .runners-table thead {\n            background: var(--color-primary-dim);\n            position: sticky;\n            top: 0;\n        }\n\n        .runners-table th {\n            padding: 0.75rem 1rem;\n            text-align: left;\n            font-weight: 600;\n            color: var(--color-primary);\n            text-transform: uppercase;\n            font-size: 0.75rem;\n            letter-spacing: 1px;\n            border-bottom: 2px solid var(--color-primary);\n        }\n\n        .runners-table td {\n            padding: 0.6rem 1rem;\n            border-bottom: 1px solid var(--color-border);\n            vertical-align: middle;\n        }\n\n        .runners-table tbody tr {\n            transition: background var(--transition-fast);\n        }\n\n        .runners-table tbody tr:hover {\n            background: var(--color-primary-dim);\n        }\n\n        .runners-table tbody tr:last-child td {\n            border-bottom: none;\n        }\n\n        .runner-name {\n            font-weight: 600;\n            color: var(--color-text);\n        }\n\n        .runner-number {\n            display: inline-flex;\n            align-items: center;\n            justify-content: center;\n            width: 1.75rem;\n            height: 1.75rem;\n            border-radius: 50%;\n            background: var(--color-primary-muted);\n            color: var(--color-primary);\n            font-weight: bold;\n            font-size: 0.8rem;\n            margin-right: 0.5rem;\n        }\n\n        .odds {\n            font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;\n            color: var(--color-primary);\n            font-weight: bold;\n            font-size: 1rem;\n        }\n\n        .source {\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n        }\n\n        /* Responsive Table */\n        @media (max-width: 640px) {\n            .runners-table thead {\n                display: none;\n            }\n\n            .runners-table tbody tr {\n                display: block;\n                padding: 0.75rem 0;\n                border-bottom: 1px solid var(--color-border);\n            }\n\n            .runners-table td {\n                display: flex;\n                justify-content: space-between;\n                padding: 0.35rem 0;\n                border: none;\n            }\n\n            .runners-table td::before {\n                content: attr(data-label);\n                font-weight: 600;\n                color: var(--color-text-muted);\n                font-size: 0.8rem;\n                text-transform: uppercase;\n            }\n        }\n\n        /* No Races */\n        .no-races {\n            text-align: center;\n            padding: 3rem 2rem;\n            background: var(--color-bg-card);\n            border: 2px dashed var(--color-error);\n            border-radius: 12px;\n            color: var(--color-text-muted);\n        }\n\n        .no-races-icon {\n            font-size: 3rem;\n            margin-bottom: 1rem;\n        }\n\n        /* Metrics Panel */\n        .metrics-panel {\n            background: var(--color-bg-card);\n            border: 1px solid var(--color-border);\n            border-radius: 8px;\n            padding: 1rem 1.5rem;\n            margin: 2rem 0;\n        }\n\n        .metrics-panel summary {\n            cursor: pointer;\n            font-weight: 600;\n            color: var(--color-primary);\n            padding: 0.5rem 0;\n        }\n\n        .metrics-grid {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));\n            gap: 1rem;\n            margin-top: 1rem;\n        }\n\n        .metric-item {\n            padding: 0.75rem;\n            background: var(--color-primary-dim);\n            border-radius: 6px;\n        }\n\n        .metric-label {\n            font-size: 0.75rem;\n            color: var(--color-text-muted);\n            text-transform: uppercase;\n        }\n\n        .metric-value {\n            font-size: 1.1rem;\n            font-weight: 600;\n            color: var(--color-text);\n        }\n\n        /* Footer */\n        footer {\n            text-align: center;\n            margin-top: 3rem;\n            padding: 2rem 1rem;\n            border-top: 1px solid var(--color-border);\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n        }\n\n        footer a {\n            color: var(--color-primary);\n            text-decoration: none;\n            transition: color var(--transition-fast);\n        }\n\n        footer a:hover {\n            text-decoration: underline;\n        }\n\n        /* Animations */\n        @keyframes fadeIn {\n            from { opacity: 0; transform: translateY(10px); }\n            to { opacity: 1; transform: translateY(0); }\n        }\n\n        .race-card {\n            animation: fadeIn 0.3s ease forwards;\n        }\n\n        /* Skip Link for Accessibility */\n        .skip-link {\n            position: absolute;\n            top: -40px;\n            left: 0;\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n            padding: 8px 16px;\n            z-index: 100;\n            transition: top var(--transition-fast);\n        }\n\n        .skip-link:focus {\n            top: 0;\n        }\n\n        /* Loading State */\n        .loading {\n            text-align: center;\n            padding: 3rem;\n            color: var(--color-text-muted);\n        }\n\n        .spinner {\n            width: 40px;\n            height: 40px;\n            border: 4px solid var(--color-border);\n            border-top-color: var(--color-primary);\n            border-radius: 50%;\n            animation: spin 1s linear infinite;\n            margin: 0 auto 1rem;\n        }\n\n        @keyframes spin {\n            to { transform: rotate(360deg); }\n        }\n\n        /* Print Styles */\n        @media print {\n            body { background: white; color: black; }\n            .controls, .theme-toggle, .btn { display: none; }\n            .race-card { break-inside: avoid; box-shadow: none; border: 1px solid #ccc; }\n        }\n    </style>\n</head>\n<body>\n    <a href=\"#main-content\" class=\"skip-link\">Skip to main content</a>\n\n    <div class=\"container\">\n        <div id=\"app\" class=\"loading\">\n            <div class=\"spinner\" aria-hidden=\"true\"></div>\n            <p>Loading race data...</p>\n        </div>\n    </div>\n\n    <!-- Data placeholder -->\n    <script id=\"race_data\" type=\"application/json\">__RACE_DATA_PLACEHOLDER__</script>\n\n    <script>\n        (function() {\n            'use strict';\n\n            // State management\n            const state = {\n                races: [],\n                filteredRaces: [],\n                searchQuery: '',\n                sortBy: 'time',\n                sortAsc: true,\n                theme: localStorage.getItem('theme') || 'dark',\n                collapsedCards: new Set(),\n                metadata: null\n            };\n\n            // Utility functions\n            const formatTime = (dateStr) => {\n                if (!dateStr) return 'N/A';\n                try {\n                    const date = new Date(dateStr);\n                    if (isNaN(date.getTime())) return 'N/A';\n                    return date.toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit', hour12: false });\n                } catch {\n                    return 'N/A';\n                }\n            };\n\n            const formatDate = (dateStr) => {\n                if (!dateStr) return 'N/A';\n                try {\n                    const date = new Date(dateStr);\n                    if (isNaN(date.getTime())) return 'N/A';\n                    return date.toLocaleDateString('en-US', {\n                        year: 'numeric',\n                        month: 'short',\n                        day: 'numeric',\n                        hour: '2-digit',\n                        minute: '2-digit'\n                    });\n                } catch {\n                    return 'N/A';\n                }\n            };\n\n            const escapeHtml = (str) => {\n                if (typeof str !== 'string') return str;\n                const div = document.createElement('div');\n                div.textContent = str;\n                return div.innerHTML;\n            };\n\n            const getBestOdds = (runner) => {\n                if (!runner.odds || typeof runner.odds !== 'object') {\n                    return { odds: 'N/A', source: 'N/A' };\n                }\n\n                let bestVal = 0;\n                let bestSource = 'N/A';\n\n                for (const [source, data] of Object.entries(runner.odds)) {\n                    const winOdds = data?.win || data;\n                    if (typeof winOdds === 'number' && winOdds > bestVal) {\n                        bestVal = winOdds;\n                        bestSource = source;\n                    }\n                }\n\n                return {\n                    odds: bestVal > 0 ? bestVal.toFixed(2) : 'N/A',\n                    source: bestSource\n                };\n            };\n\n            // Sorting functions\n            const sortFunctions = {\n                time: (a, b) => new Date(a.start_time || 0) - new Date(b.start_time || 0),\n                venue: (a, b) => (a.venue || '').localeCompare(b.venue || ''),\n                score: (a, b) => (b.qualification_score || 0) - (a.qualification_score || 0),\n                runners: (a, b) => (b.runners?.length || 0) - (a.runners?.length || 0)\n            };\n\n            // Filter and sort races\n            const updateFilteredRaces = () => {\n                let filtered = [...state.races];\n\n                // Apply search filter\n                if (state.searchQuery) {\n                    const query = state.searchQuery.toLowerCase();\n                    filtered = filtered.filter(race => {\n                        const venueMatch = (race.venue || '').toLowerCase().includes(query);\n                        const runnerMatch = (race.runners || []).some(r =>\n                            (r.name || '').toLowerCase().includes(query)\n                        );\n                        return venueMatch || runnerMatch;\n                    });\n                }\n\n                // Apply sorting\n                const sortFn = sortFunctions[state.sortBy] || sortFunctions.time;\n                filtered.sort((a, b) => {\n                    const result = sortFn(a, b);\n                    return state.sortAsc ? result : -result;\n                });\n\n                state.filteredRaces = filtered;\n            };\n\n            // Render functions\n            const renderHeader = (timestamp) => `\n                <header>\n                    <h1>\ud83d\udc34 Fortuna Faucet Race Report</h1>\n                    <p class=\"subtitle\">Filtered Trifecta Opportunities</p>\n                    <p class=\"subtitle\">Generated: ${formatDate(timestamp)}</p>\n                </header>\n            `;\n\n            const renderControls = () => `\n                <div class=\"controls\" role=\"search\" aria-label=\"Filter and sort controls\">\n                    <input\n                        type=\"search\"\n                        id=\"search-input\"\n                        class=\"search-box\"\n                        placeholder=\"Search venues or horses...\"\n                        value=\"${escapeHtml(state.searchQuery)}\"\n                        aria-label=\"Search races\"\n                    />\n                    <div class=\"sort-controls\" role=\"group\" aria-label=\"Sort options\">\n                        <button class=\"btn ${state.sortBy === 'time' ? 'active' : ''}\" data-sort=\"time\">\n                            \u23f0 Time\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'score' ? 'active' : ''}\" data-sort=\"score\">\n                            \u2b50 Score\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'venue' ? 'active' : ''}\" data-sort=\"venue\">\n                            \ud83d\udccd Venue\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'runners' ? 'active' : ''}\" data-sort=\"runners\">\n                            \ud83c\udfc7 Runners\n                        </button>\n                    </div>\n                    <button id=\"theme-toggle\" class=\"btn theme-toggle\" aria-label=\"Toggle theme\">\n                        ${state.theme === 'dark' ? '\u2600\ufe0f Light' : '\ud83c\udf19 Dark'}\n                    </button>\n                </div>\n            `;\n\n            const renderSummary = () => {\n                const totalRunners = state.filteredRaces.reduce((sum, r) => sum + (r.runners?.length || 0), 0);\n                const avgScore = state.filteredRaces.length > 0\n                    ? (state.filteredRaces.reduce((sum, r) => sum + (r.qualification_score || 0), 0) / state.filteredRaces.length).toFixed(1)\n                    : 'N/A';\n\n                return `\n                    <div class=\"summary-box\" role=\"region\" aria-label=\"Summary statistics\">\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${state.filteredRaces.length}</div>\n                            <div class=\"summary-stat-label\">Qualified Races</div>\n                        </div>\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${totalRunners}</div>\n                            <div class=\"summary-stat-label\">Total Runners</div>\n                        </div>\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${avgScore}</div>\n                            <div class=\"summary-stat-label\">Avg Score</div>\n                        </div>\n                        ${state.searchQuery ? `\n                            <div class=\"summary-stat\">\n                                <div class=\"summary-stat-value\">${state.races.length}</div>\n                                <div class=\"summary-stat-label\">Total Available</div>\n                            </div>\n                        ` : ''}\n                    </div>\n                `;\n            };\n\n            const renderRunner = (runner, index) => {\n                const { odds, source } = getBestOdds(runner);\n                const number = runner.number || runner.post_position || index + 1;\n\n                return `\n                    <tr>\n                        <td data-label=\"Horse\">\n                            <span class=\"runner-number\">${number}</span>\n                            <span class=\"runner-name\">${escapeHtml(runner.name || 'Unknown')}</span>\n                        </td>\n                        <td data-label=\"Win Odds\" class=\"odds\">${odds}</td>\n                        <td data-label=\"Source\" class=\"source\">${escapeHtml(source)}</td>\n                    </tr>\n                `;\n            };\n\n            const renderRaceCard = (race, index) => {\n                const raceId = `race-${race.venue}-${race.race_number}`.replace(/\\s+/g, '-');\n                const isCollapsed = state.collapsedCards.has(raceId);\n                const score = race.qualification_score != null ? race.qualification_score.toFixed(1) : 'N/A';\n                const runners = race.runners || [];\n\n                return `\n                    <article\n                        class=\"race-card ${isCollapsed ? 'collapsed' : ''}\"\n                        data-race-id=\"${raceId}\"\n                        style=\"animation-delay: ${index * 0.05}s\"\n                    >\n                        <div class=\"race-header\"\n                             role=\"button\"\n                             tabindex=\"0\"\n                             aria-expanded=\"${!isCollapsed}\"\n                             aria-controls=\"${raceId}-content\">\n                            <div class=\"race-header-info\">\n                                <h2 class=\"race-title\">\n                                    <span class=\"collapse-icon\" aria-hidden=\"true\">\u25bc</span>\n                                    ${escapeHtml(race.venue || 'Unknown')} - Race ${race.race_number || '?'}\n                                </h2>\n                                <div class=\"race-meta\">\n                                    Post Time: ${formatTime(race.start_time)}\n                                    ${race.distance ? ` \u2022 ${escapeHtml(race.distance)}` : ''}\n                                    ${race.surface ? ` \u2022 ${escapeHtml(race.surface)}` : ''}\n                                </div>\n                            </div>\n                            <div class=\"race-badges\">\n                                <span class=\"badge badge-score\" title=\"Qualification Score\">\u2b50 ${score}</span>\n                                <span class=\"badge badge-runners\" title=\"Number of Runners\">\ud83c\udfc7 ${runners.length}</span>\n                            </div>\n                        </div>\n                        <div class=\"race-content\" id=\"${raceId}-content\">\n                            ${runners.length > 0 ? `\n                                <table class=\"runners-table\" role=\"table\">\n                                    <thead>\n                                        <tr>\n                                            <th scope=\"col\">Horse</th>\n                                            <th scope=\"col\">Win Odds</th>\n                                            <th scope=\"col\">Best Source</th>\n                                        </tr>\n                                    </thead>\n                                    <tbody>\n                                        ${runners.map((r, i) => renderRunner(r, i)).join('')}\n                                    </tbody>\n                                </table>\n                            ` : '<p class=\"no-runners\">No runner data available</p>'}\n                        </div>\n                    </article>\n                `;\n            };\n\n            const renderNoRaces = () => `\n                <div class=\"no-races\" role=\"alert\">\n                    <div class=\"no-races-icon\">\ud83d\udd2d</div>\n                    <h2>No Races Found</h2>\n                    <p>${state.searchQuery\n                        ? `No races match \"${escapeHtml(state.searchQuery)}\". Try a different search term.`\n                        : 'No qualified races found at this time. Check back later for updates.'\n                    }</p>\n                    ${state.searchQuery ? '<button class=\"btn\" id=\"clear-search\">Clear Search</button>' : ''}\n                </div>\n            `;\n\n            const renderMetrics = () => {\n                if (!state.metadata?.generation_metrics) return '';\n\n                const m = state.metadata.generation_metrics;\n                return `\n                    <details class=\"metrics-panel\">\n                        <summary>\ud83d\udcca Generation Metrics</summary>\n                        <div class=\"metrics-grid\">\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Total Fetched</div>\n                                <div class=\"metric-value\">${m.total_races_fetched || 0}</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Qualified</div>\n                                <div class=\"metric-value\">${m.qualified_races || 0}</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Duration</div>\n                                <div class=\"metric-value\">${(m.duration_seconds || 0).toFixed(1)}s</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Adapters Used</div>\n                                <div class=\"metric-value\">${m.adapters_used?.length || 0}</div>\n                            </div>\n                        </div>\n                    </details>\n                `;\n            };\n\n            const renderFooter = () => `\n                <footer>\n                    <p>This report was automatically generated by <strong>Fortuna Faucet</strong> via GitHub Actions.</p>\n                    <p>Data sources: Multiple racing exchanges and bookmakers.</p>\n                    <p>\n                        <kbd>?</kbd> Help \u2022\n                        <kbd>\u2191\u2193</kbd> Navigate \u2022\n                        <kbd>Enter</kbd> Expand/Collapse\n                    </p>\n                </footer>\n            `;\n\n            const render = () => {\n                updateFilteredRaces();\n\n                const app = document.getElementById('app');\n                app.className = '';\n                app.innerHTML = `\n                    ${renderHeader(state.metadata?.timestamp)}\n                    ${renderControls()}\n                    ${renderSummary()}\n                    <main id=\"main-content\" class=\"race-grid\" role=\"main\" aria-label=\"Race cards\">\n                        ${state.filteredRaces.length > 0\n                            ? state.filteredRaces.map((race, i) => renderRaceCard(race, i)).join('')\n                            : renderNoRaces()\n                        }\n                    </main>\n                    ${renderMetrics()}\n                    ${renderFooter()}\n                `;\n\n                attachEventListeners();\n            };\n\n            const attachEventListeners = () => {\n                // Search input\n                const searchInput = document.getElementById('search-input');\n                if (searchInput) {\n                    let debounceTimer;\n                    searchInput.addEventListener('input', (e) => {\n                        clearTimeout(debounceTimer);\n                        debounceTimer = setTimeout(() => {\n                            state.searchQuery = e.target.value;\n                            render();\n                            document.getElementById('search-input')?.focus();\n                        }, 300);\n                    });\n                }\n\n                // Sort buttons\n                document.querySelectorAll('[data-sort]').forEach(btn => {\n                    btn.addEventListener('click', (e) => {\n                        const sortBy = e.target.dataset.sort;\n                        if (state.sortBy === sortBy) {\n                            state.sortAsc = !state.sortAsc;\n                        } else {\n                            state.sortBy = sortBy;\n                            state.sortAsc = sortBy !== 'score'; // Score defaults descending\n                        }\n                        render();\n                    });\n                });\n\n                // Theme toggle\n                const themeToggle = document.getElementById('theme-toggle');\n                if (themeToggle) {\n                    themeToggle.addEventListener('click', () => {\n                        state.theme = state.theme === 'dark' ? 'light' : 'dark';\n                        document.documentElement.classList.toggle('light-mode', state.theme === 'light');\n                        localStorage.setItem('theme', state.theme);\n                        render();\n                    });\n                }\n\n                // Clear search button\n                const clearSearch = document.getElementById('clear-search');\n                if (clearSearch) {\n                    clearSearch.addEventListener('click', () => {\n                        state.searchQuery = '';\n                        render();\n                    });\n                }\n\n                // Race card collapse/expand\n                document.querySelectorAll('.race-header').forEach(header => {\n                    const handleToggle = () => {\n                        const card = header.closest('.race-card');\n                        const raceId = card.dataset.raceId;\n\n                        if (state.collapsedCards.has(raceId)) {\n                            state.collapsedCards.delete(raceId);\n                        } else {\n                            state.collapsedCards.add(raceId);\n                        }\n\n                        card.classList.toggle('collapsed');\n                        header.setAttribute('aria-expanded', !card.classList.contains('collapsed'));\n                    };\n\n                    header.addEventListener('click', handleToggle);\n                    header.addEventListener('keydown', (e) => {\n                        if (e.key === 'Enter' || e.key === ' ') {\n                            e.preventDefault();\n                            handleToggle();\n                        }\n                    });\n                });\n            };\n\n            // Keyboard navigation\n            document.addEventListener('keydown', (e) => {\n                if (e.target.matches('input, textarea')) return;\n\n                if (e.key === '/') {\n                    e.preventDefault();\n                    document.getElementById('search-input')?.focus();\n                } else if (e.key === 'Escape') {\n                    document.getElementById('search-input')?.blur();\n                }\n            });\n\n            // Initialize\n            const init = () => {\n                // Apply saved theme\n                if (state.theme === 'light') {\n                    document.documentElement.classList.add('light-mode');\n                }\n\n                try {\n                    const dataEl = document.getElementById('race_data');\n                    if (!dataEl) throw new Error('Data element not found');\n\n                    const jsonData = JSON.parse(dataEl.textContent);\n                    state.races = jsonData.races || [];\n                    state.metadata = jsonData;\n\n                    render();\n                } catch (err) {\n                    console.error('Failed to initialize:', err);\n                    document.getElementById('app').innerHTML = `\n                        <div class=\"no-races\">\n                            <div class=\"no-races-icon\">\u26a0\ufe0f</div>\n                            <h2>Failed to Load Data</h2>\n                            <p>Error: ${escapeHtml(err.message)}</p>\n                        </div>\n                    `;\n                }\n            };\n\n            if (document.readyState === 'loading') {\n                document.addEventListener('DOMContentLoaded', init);\n            } else {\n                init();\n            }\n        })();\n    </script>\n</body>\n</html>\n",
    "scripts/test_api_query.py": "#!/usr/bin/env python\n\"\"\"\nSimple Fortuna Race Data Query Script\n\nThis is a lightweight script for testing the race data API locally.\nIt queries for filtered races and outputs the results.\n\nUsage:\n  python scripts/test_api_query.py\n\nThe script expects the backend to be running on http://127.0.0.1:8000\n\"\"\"\n\nimport json\nimport os\nimport sys\nimport time\nfrom datetime import datetime\n\ntry:\n    import requests\nexcept ImportError:\n    print(\"\u274c Error: 'requests' module not found.\")\n    print(\"Install it with: pip install requests\")\n    sys.exit(1)\n\n\n# Configuration\nAPI_BASE_URL = os.getenv(\"FORTUNA_API_URL\", \"http://127.0.0.1:8000\")\nAPI_KEY = os.getenv(\"API_KEY\", \"a_secure_test_api_key_that_is_long_enough\")\nTIMEOUT = 10\n\n\ndef log(message, level=\"INFO\"):\n    \"\"\"Print timestamped log message.\"\"\"\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    emoji = {\"INFO\": \"\u2139\ufe0f\", \"SUCCESS\": \"\u2705\", \"ERROR\": \"\u274c\", \"WARNING\": \"\u26a0\ufe0f\"}\n    print(f\"[{timestamp}] {emoji.get(level, '\u2022')} {message}\")\n\n\ndef check_backend_health():\n    \"\"\"Check if the backend API is responding.\"\"\"\n    log(\"Checking backend health...\", \"INFO\")\n    try:\n        response = requests.get(\n            f\"{API_BASE_URL}/api/health\",\n            timeout=TIMEOUT,\n            headers={\"X-API-Key\": API_KEY},\n        )\n        if response.status_code == 200:\n            log(\"Backend is healthy\", \"SUCCESS\")\n            return True\n    except requests.RequestException as e:\n        log(f\"Health check failed: {e}\", \"ERROR\")\n        return False\n    return False\n\n\ndef fetch_filtered_races():\n    \"\"\"Fetch trifecta-qualified races from the API.\"\"\"\n    endpoint = \"/api/races/qualified/trifecta\"\n    url = f\"{API_BASE_URL}{endpoint}\"\n\n    log(f\"Querying {url}\", \"INFO\")\n\n    try:\n        headers = {\"X-API-Key\": API_KEY}\n        response = requests.get(url, timeout=TIMEOUT, headers=headers)\n        response.raise_for_status()\n\n        data = response.json()\n        races = data.get(\"races\", [])\n\n        log(f\"Retrieved {len(races)} qualified races\", \"SUCCESS\")\n        return data\n\n    except requests.exceptions.Timeout:\n        log(f\"Request timed out after {TIMEOUT} seconds\", \"ERROR\")\n        return None\n    except requests.exceptions.ConnectionError as e:\n        log(f\"Connection error: {e}\", \"ERROR\")\n        log(f\"Is the backend running at {API_BASE_URL}?\", \"WARNING\")\n        return None\n    except requests.exceptions.HTTPError as e:\n        log(f\"HTTP error: {response.status_code} {response.reason}\", \"ERROR\")\n        return None\n    except json.JSONDecodeError:\n        log(\"Response was not valid JSON\", \"ERROR\")\n        return None\n    except Exception as e:\n        log(f\"Unexpected error: {e}\", \"ERROR\")\n        return None\n\n\ndef display_races(races_data):\n    \"\"\"Pretty-print the races to console.\"\"\"\n    if not races_data:\n        log(\"No data to display\", \"WARNING\")\n        return\n\n    races = races_data.get(\"races\", [])\n\n    print(\"\\\\n\" + \"=\" * 80)\n    print(f\"FORTUNA FILTERED RACE REPORT - {len(races)} Races\")\n    print(\"=\" * 80 + \"\\\\n\")\n\n    if not races:\n        print(\"\u274c No qualified races found at this time.\\\\n\")\n        return\n\n    for idx, race in enumerate(races, 1):\n        venue = race.get(\"venue\", \"Unknown\")\n        race_num = race.get(\"race_number\", \"?\")\n        start_time = race.get(\"startTime\", \"N/A\")\n        runners = race.get(\"runners\", [])\n\n        print(f\"[{idx}] {venue} - Race {race_num}\")\n        print(f\"    Post Time: {start_time}\")\n        print(f\"    Runners: {len(runners)}\")\n        print(\"\\\\n    Horse Name                  | Win Odds | Best Source\")\n        print(\"    \" + \"-\" * 60)\n\n        for runner in runners:\n            name = runner.get(\"name\", \"Unknown\")\n            odds_data = runner.get(\"odds\", {})\n\n            # Find best win odds\n            best_odds = \"N/A\"\n            best_source = \"N/A\"\n            if odds_data:\n                best_val = 0.0\n                for source, odds_obj in odds_data.items():\n                    win_odds = odds_obj.get(\"win\", 0.0)\n                    if win_odds > best_val:\n                        best_val = win_odds\n                        best_odds = f\"{best_val:.2f}\"\n                        best_source = source\n\n            # Truncate long names\n            display_name = name[:28]\n            print(f\"    {display_name:28} | {best_odds:>8} | {best_source}\")\n\n        print()\n\n\ndef save_to_json(races_data, filename=\"qualified_races.json\"):\n    \"\"\"Save race data to JSON file.\"\"\"\n    try:\n        with open(filename, \"w\", encoding=\"utf-8\") as f:\n            json.dump(races_data, f, indent=2)\n        log(f\"Saved race data to {filename}\", \"SUCCESS\")\n        return True\n    except Exception as e:\n        log(f\"Failed to save JSON: {e}\", \"ERROR\")\n        return False\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    log(\"=== Fortuna Race Data Query ===\", \"INFO\")\n    log(f\"API URL: {API_BASE_URL}\", \"INFO\")\n\n    # Check backend health\n    if not check_backend_health():\n        log(\"Backend is not responding\", \"ERROR\")\n        log(\"Make sure to start the backend with:\", \"WARNING\")\n        log(\"  python -m uvicorn web_service.backend.main:app --port 8000\", \"WARNING\")\n        return 1\n\n    # Fetch races\n    races_data = fetch_filtered_races()\n    if not races_data:\n        log(\"Failed to fetch race data\", \"ERROR\")\n        return 1\n\n    # Display results\n    display_races(races_data)\n\n    # Save to JSON\n    save_to_json(races_data)\n\n    log(\"Complete\", \"SUCCESS\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n",
    "start_docker.bat": "@echo off\nREM ============================================================\nREM Fortuna Faucet - Docker Launcher for Windows\nREM A simple, friendly way to start your racing analysis engine\nREM ============================================================\n\nsetlocal enabledelayedexpansion\n\nREM Colors and styling\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83d\udc34  FORTUNA FAUCET LAUNCHER  \ud83d\udc34                \u2551\necho \u2551          Racing Strategy Analysis Engine                  \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM ============================================================\nREM STEP 1: Check if Docker is installed\nREM ============================================================\necho [1/5] Checking for Docker installation...\ndocker --version >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Docker is not installed or not in PATH\n    echo.\n    echo To use Fortuna, you need Docker Desktop:\n    echo https://www.docker.com/products/docker-desktop\n    echo.\n    echo After installing Docker, restart your computer and try again.\n    echo.\n    pause\n    exit /b 1\n)\n\nfor /f \"tokens=*\" %%i in ('docker --version') do set DOCKER_VERSION=%%i\necho \u2713 Found: %DOCKER_VERSION%\necho.\n\nREM ============================================================\nREM STEP 2: Check if Docker daemon is running\nREM ============================================================\necho [2/5] Checking if Docker daemon is running...\ndocker ps >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Docker daemon is not running\n    echo.\n    echo Please:\n    echo 1. Open \"Docker Desktop\" from your Start Menu\n    echo 2. Wait 30 seconds for Docker to fully start\n    echo 3. Then run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\necho \u2713 Docker daemon is running\necho.\n\nREM ============================================================\nREM STEP 3: Pull latest Docker image\nREM ============================================================\necho [3/5] Pulling latest Fortuna image from Docker Hub...\necho (This may take a minute on first run)\necho.\ndocker pull masonj0/fortuna-faucet:latest\nif errorlevel 1 (\n    echo.\n    echo \u26a0 Warning: Could not pull from Docker Hub\n    echo Checking for local image...\n    docker image inspect masonj0/fortuna-faucet:latest >nul 2>&1\n    if errorlevel 1 (\n        echo \u2717 ERROR: No local image found\n        echo Please check your internet connection and try again.\n        echo.\n        pause\n        exit /b 1\n    )\n    echo \u2713 Using existing local image\n)\necho \u2713 Image ready\necho.\n\nREM ============================================================\nREM STEP 4: Start container\nREM ============================================================\necho [4/5] Starting Fortuna container...\necho.\n\nREM Stop any existing container (ignore errors)\ndocker stop fortuna-faucet >nul 2>&1\ndocker rm fortuna-faucet >nul 2>&1\n\nREM Create data directories if they don't exist\nif not exist \"data\" mkdir data\nif not exist \"logs\" mkdir logs\n\nREM Start container with proper quoting for paths with spaces\ndocker run -d ^\n  --name fortuna-faucet ^\n  -p 8000:8000 ^\n  -v \"%cd%\\data:/app/web_service/backend/data\" ^\n  -v \"%cd%\\logs:/app/web_service/backend/logs\" ^\n  masonj0/fortuna-faucet:latest\n\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Failed to start container\n    echo.\n    echo Try these troubleshooting steps:\n    echo 1. Open Docker Desktop\n    echo 2. Wait for it to fully start\n    echo 3. Open Command Prompt and run: docker ps\n    echo    (This tests if Docker is working)\n    echo 4. Run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Container started successfully\necho.\n\nREM ============================================================\nREM STEP 5: Wait and verify startup\nREM ============================================================\necho [5/5] Waiting for application to start...\ntimeout /t 3 /nobreak\n\nREM Check if container is still running\ndocker inspect fortuna-faucet >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Container exited unexpectedly\n    echo.\n    echo Showing container logs for debugging:\n    echo.\n    docker logs fortuna-faucet\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Application is ready!\necho.\n\nREM ============================================================\nREM SUCCESS - Open browser and show logs\nREM ============================================================\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83c\udf89  FORTUNA IS RUNNING!  \ud83c\udf89                   \u2551\necho \u2551                                                            \u2551\necho \u2551  Your racing analysis engine is ready at:                \u2551\necho \u2551                                                            \u2551\necho \u2551          http://localhost:8000                            \u2551\necho \u2551                                                            \u2551\necho \u2551  Opening browser now...                                   \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM Open browser\nstart http://localhost:8000\n\nREM Small delay to let browser open\ntimeout /t 2 /nobreak\n\nREM Show logs\necho.\necho \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\necho \u2502 Live Application Logs (Ctrl+C to stop)                    \u2502\necho \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\necho.\n\ndocker logs -f fortuna-faucet\n\nREM Cleanup on exit\necho.\necho Stopping Fortuna...\ndocker stop fortuna-faucet >nul 2>&1\necho \u2713 Fortuna stopped\n\nexit /b 0\n",
    "tests/__init__.py": "# This file makes the 'tests' directory a package.\n",
    "tests/adapters/test_timeform_adapter_modernized.py": "# Modernized test resurrected from attic/legacy_tests_pre_triage/adapters/test_timeform_adapter.py\nfrom decimal import Decimal\nfrom unittest.mock import MagicMock\n\nimport pytest\n\nfrom python_service.adapters.timeform_adapter import TimeformAdapter\n\n\n@pytest.fixture\ndef timeform_adapter():\n    mock_config = MagicMock()\n    return TimeformAdapter(config=mock_config)\n\n\ndef read_fixture(file_path):\n    with open(file_path, \"r\") as f:\n        return f.read()\n\n\n@pytest.mark.asyncio\nasync def test_timeform_adapter_parses_html_correctly(timeform_adapter):\n    \"\"\"Verify adapter correctly parses a known HTML fixture.\"\"\"\n    mock_html = read_fixture(\"tests/fixtures/timeform_modern_sample.html\")\n\n    # Directly test the parsing of runners from the correct HTML structure\n    from bs4 import BeautifulSoup\n\n    soup = BeautifulSoup(mock_html, \"html.parser\")\n    runners = [timeform_adapter._parse_runner(row) for row in soup.select(\"div.rp-horseTable_mainRow\")]\n\n    assert len(runners) == 3, \"Should parse three runners\"\n\n    braveheart = next((r for r in runners if r.name == \"Braveheart\"), None)\n    assert braveheart is not None\n    assert braveheart.odds[\"Timeform\"].win == Decimal(\"3.5\")\n\n    steady_eddy = next((r for r in runners if r.name == \"Steady Eddy\"), None)\n    assert steady_eddy is not None\n    assert steady_eddy.odds[\"Timeform\"].win == Decimal(\"2.0\")\n",
    "tests/fixtures/timeform_legacy_sample.html": "<!DOCTYPE html><html><body><div class='race-card'><div class='runner'><span class='runner-name'>Braveheart</span><span class='runner-odds'>5/2</span></div><div class='runner'><span class='runner-name'>Speedster</span><span class='runner-odds'>10/1</span></div><div class='runner'><span class='runner-name'>Steady Eddy</span><span class='runner-odds'>EVENS</span></div></div></body></html>",
    "tests/test_api/test_endpoints.py": "import pytest\nfrom fastapi.testclient import TestClient\n\nfrom python_service.api import app\n\nclient = TestClient(app)\n\n\n@pytest.mark.asyncio\nasync def test_health_check(client):\n    \"\"\"Tests the unauthenticated /health endpoint.\"\"\"\n    response = await client.get(\"/health\")\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"healthy\"\n",
    "tests/test_models.py": "# Test suite for Pydantic models, resurrected from attic/legacy_tests_pre_triage/checkmate_v7/test_models.py\nimport datetime\n\nimport pytest\nfrom pydantic import ValidationError\n\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\n\ndef test_runner_model_creation():\n    \"\"\"Tests basic successful creation of the Runner model.\"\"\"\n    from datetime import datetime\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds_data = {\"TestOdds\": OddsData(win=Decimal(\"6.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    runner = Runner(number=5, name=\"Test Horse\", odds=odds_data, scratched=False)\n    assert runner.number == 5\n    assert runner.name == \"Test Horse\"\n    assert not runner.scratched\n\n\ndef test_race_model_with_valid_runners():\n    \"\"\"Tests basic successful creation of the Race model.\"\"\"\n    from datetime import datetime\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    runner1 = Runner(number=1, name=\"A\", odds=odds1, scratched=False)\n    runner2 = Runner(number=2, name=\"B\", odds=odds2, scratched=False)\n    race = Race(\n        id=\"test-race-1\",\n        venue=\"TEST\",\n        race_number=1,\n        start_time=datetime.now(),\n        runners=[runner1, runner2],\n        source=\"test\",\n    )\n    assert race.venue == \"TEST\"\n    assert len(race.runners) == 2\n\n\ndef test_model_validation_fails_on_missing_required_field():\n    \"\"\"Ensures Pydantic's validation fires for missing required fields.\"\"\"\n    with pytest.raises(ValidationError):\n        # 'name' is a required field for a Runner\n        Runner(number=3, odds=\"3/1\", scratched=False)\n\n    with pytest.raises(ValidationError):\n        # 'venue' is a required field for a Race\n        Race(\n            id=\"test-race-2\",\n            race_number=2,\n            start_time=datetime.datetime.now(),\n            runners=[],\n            source=\"test\",\n        )\n",
    "verify_dashboard.py": "\nfrom playwright.sync_api import sync_playwright\n\ndef verify_dashboard(page):\n    \"\"\"\n    Navigates to the dashboard and takes a screenshot.\n    \"\"\"\n    page.goto(\"http://localhost:3000\")\n    page.wait_for_selector(\"text=Fortuna Faucet\")\n    page.screenshot(path=\"verification.png\")\n\nif __name__ == \"__main__\":\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=True)\n        page = browser.new_page()\n        try:\n            verify_dashboard(page)\n        finally:\n            browser.close()\n",
    "web_service/backend/adapters/at_the_races_adapter.py": "# python_service/adapters/at_the_races_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass AtTheRacesAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for attheraces.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"AtTheRaces\"\n    BASE_URL = \"https://www.attheraces.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        Returns a dictionary containing a list of (URL, HTML content) tuples and the date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(\n            self.http_client, \"GET\", index_url, headers=self._get_headers()\n        )\n        if not index_response:\n            self.logger.warning(\"Failed to fetch AtTheRaces index page\", url=index_url)\n            return None\n\n        # Save the raw HTML for debugging in CI\n        try:\n            with open(\"atr_debug.html\", \"w\", encoding=\"utf-8\") as f:\n                f.write(index_response.text)\n        except Exception as e:\n            self.logger.warning(\"Failed to save debug HTML for AtTheRaces\", error=str(e))\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        links = {a[\"href\"] for a in index_soup.select('a[href^=\"/racecard/\"]')}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(\n                self.http_client, \"GET\", url_path, headers=self._get_headers()\n            )\n            return (url_path, response.text) if response else (url_path, \"\")\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages_with_urls = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages_with_urls, \"date\": date}\n\n    def _get_headers(self) -> dict:\n        return {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-US,en;q=0.9\",\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Host\": \"www.attheraces.com\",\n            \"Pragma\": \"no-cache\",\n            \"sec-ch-ua\": '\"Not/A)Brand\";v=\"99\", \"Google Chrome\";v=\"115\", \"Chromium\";v=\"115\"',\n            \"sec-ch-ua-mobile\": \"?0\",\n            \"sec-ch-ua-platform\": '\"Windows\"',\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"none\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n            \"Referer\": \"https://www.attheraces.com/racecards\",\n        }\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of (URL, raw HTML string) tuples into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to AtTheRacesAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for url_path, html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n                details_container = soup.select_one(\"atr-racecard-race-header .container\")\n                if not details_container:\n                    continue\n\n                track_name_node = details_container.select_one(\"h1 a\")\n                track_name_raw = clean_text(track_name_node.get_text()) if track_name_node else \"\"\n                track_name = normalize_venue_name(track_name_raw)\n\n                race_time_node = details_container.select_one(\"h1 span\")\n                race_time_str = (\n                    clean_text(race_time_node.get_text()).replace(\" ATR\", \"\") if race_time_node else \"\"\n                )\n\n                start_time = datetime.combine(\n                    race_date, datetime.strptime(race_time_str, \"%H:%M\").time()\n                )\n\n                race_number = 1  # Defaulting to 1 as the race number is not in the URL\n\n                runners = [self._parse_runner(row) for row in soup.select(\"atr-horse-in-racecard\")]\n\n                race = Race(\n                    id=f\"atr_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from AtTheRaces, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"h3\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.get_text())\n\n            num_node = row.select_one(\".horse-in-racecard__saddle-cloth-number\")\n            if not num_node:\n                return None\n            num_str = clean_text(num_node.get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n\n            odds_node = row.select_one(\".horse-in-racecard__odds\")\n            odds_str = clean_text(odds_node.get_text()) if odds_node else \"\"\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {\n                    self.source_name: OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n                }\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on AtTheRaces, skipping runner.\")\n            return None\n",
    "web_service/backend/adapters/brisnet_adapter.py": "# python_service/adapters/brisnet_adapter.py\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom dateutil.parser import parse\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass BrisnetAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for brisnet.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Brisnet\"\n    BASE_URL = \"https://www.brisnet.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"Fetches the raw HTML from the Brisnet race page.\"\"\"\n        url = \"/cgi-bin/intoday.cgi\"\n        response = await self.make_request(self.http_client, \"GET\", url, headers=self._get_headers())\n        if not response or not response.text:\n            return None\n\n        # Save the raw HTML for debugging in CI\n        try:\n            with open(\"brisnet_debug.html\", \"w\", encoding=\"utf-8\") as f:\n                f.write(response.text)\n        except Exception as e:\n            self.logger.warning(\"Failed to save debug HTML for Brisnet\", error=str(e))\n            \n        return {\"html\": response.text, \"date\": date}\n\n    def _get_headers(self) -> dict:\n        return {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-US,en;q=0.9\",\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Host\": \"www.brisnet.com\",\n            \"Pragma\": \"no-cache\",\n            \"sec-ch-ua\": '\"Google Chrome\";v=\"125\", \"Chromium\";v=\"125\", \"Not.A/Brand\";v=\"24\"',\n            \"sec-ch-ua-mobile\": \"?0\",\n            \"sec-ch-ua-platform\": '\"Windows\"',\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"none\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n        }\n\n    def _parse_races(self, raw_data: Optional[dict]) -> List[Race]:\n        \"\"\"Parses the raw HTML into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"html\"):\n            self.logger.warning(\"No HTML content received from Brisnet\")\n            return []\n\n        html = raw_data[\"html\"]\n        race_date = raw_data[\"date\"]\n        soup = BeautifulSoup(html, \"html.parser\")\n\n        races = []\n        for race_link in soup.select(\"a[href*='brisnet.com/cgi-bin/briswatch.cgi/public/Brad/TODAY.PM']\"):\n            try:\n                race_number_str = race_link.text.strip()\n                if not race_number_str.isdigit():\n                    continue\n                race_number = int(race_number_str)\n\n                # Venue and start time are not available on the index page, so we have to be creative\n                # This is a significant simplification and may need to be revisited\n                venue = \"Unknown\"\n                if parent_table := race_link.find_parent(\"table\"):\n                    if caption := parent_table.find(\"caption\"):\n                        venue = normalize_venue_name(caption.text.strip())\n\n                # Create a placeholder start time as it's not available on this page\n                start_time = datetime.now()\n\n                # Since we don't have runner data on this page, we create a placeholder race\n                # A more complete implementation would require fetching each race link\n                race = Race(\n                    id=f\"brisnet_{venue.replace(' ', '').lower()}_{race_date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[],\n                    source=self.source_name,\n                )\n                races.append(race)\n            except (ValueError, IndexError, TypeError) as e:\n                self.logger.warning(\n                    \"Failed to parse a race link on Brisnet\",\n                    link=race_link.get(\"href\"),\n                    error=e,\n                    exc_info=True,\n                )\n                continue\n\n        return races\n",
    "web_service/backend/adapters/harness_adapter.py": "# python_service/adapters/harness_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass HarnessAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US harness racing data with manual override support.\"\"\"\n\n    SOURCE_NAME = \"USTrotting\"\n    BASE_URL = \"https://data.ustrotting.com/api/racenet/racing/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches all harness races for a given date.\"\"\"\n        response = await self.make_request(self.http_client, \"GET\", f\"card/{date}\")\n\n        if not response:\n            return None\n\n        card_data = response.json()\n        return {\"data\": card_data, \"date\": date}\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw card data into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"data\") or not raw_data.get(\"data\", {}).get(\"meetings\"):\n            self.logger.warning(\"No meetings found in harness data response.\")\n            return []\n\n        all_races = []\n        date = raw_data.get(\"date\")\n        for meeting in raw_data.get(\"data\", {}).get(\"meetings\", []):\n            track_name = meeting.get(\"track\", {}).get(\"name\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name, date):\n                        all_races.append(race)\n                except Exception:\n                    self.logger.warning(\n                        \"Failed to parse harness race, skipping.\",\n                        race_data=race_data,\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: dict, track_name: str, date: str) -> Optional[Race]:\n        \"\"\"Parses a single race from the USTA API into a Race object.\"\"\"\n        race_number = race_data.get(\"raceNumber\")\n        post_time_str = race_data.get(\"postTime\")\n        if not all([race_number, post_time_str]):\n            return None\n\n        start_time = self._parse_post_time(date, post_time_str)\n\n        runners = []\n        for runner_data in race_data.get(\"runners\", []):\n            if runner_data.get(\"scratched\", False):\n                continue\n\n            odds_str = runner_data.get(\"morningLineOdds\", \"\")\n            if \"/\" not in odds_str and odds_str.isdigit():\n                odds_str = f\"{odds_str}/1\"\n\n            odds = {}\n            win_odds = parse_odds_to_decimal(odds_str)\n            if win_odds and win_odds < 999:\n                odds = {\n                    self.SOURCE_NAME: OddsData(\n                        win=win_odds,\n                        source=self.SOURCE_NAME,\n                        last_updated=datetime.now(),\n                    )\n                }\n\n            runners.append(\n                Runner(\n                    number=runner_data.get(\"postPosition\", 0),\n                    name=runner_data.get(\"horse\", {}).get(\"name\", \"Unknown Horse\"),\n                    odds=odds,\n                    scratched=False,\n                )\n            )\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"ust_{track_name.lower().replace(' ', '')}_{date}_{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME,\n        )\n\n    def _parse_post_time(self, date: str, post_time: str) -> datetime:\n        \"\"\"Parses a time string like '07:00 PM' into a timezone-aware datetime object.\"\"\"\n        dt_str = f\"{date} {post_time}\"\n        naive_dt = datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n        # Assume Eastern Time for USTA data, a common standard for US racing.\n        eastern = ZoneInfo(\"America/New_York\")\n        return naive_dt.replace(tzinfo=eastern)\n",
    "web_service/backend/adapters/punters_adapter.py": "# python_service/adapters/punters_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass PuntersAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for punters.com.au.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"Punters\"\n    BASE_URL = \"https://www.punters.com.au\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/sporting_life_adapter.py": "# python_service/adapters/sporting_life_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass SportingLifeAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for sportinglife.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"SportingLife\"\n    BASE_URL = \"https://www.sportinglife.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        Returns a dictionary containing the HTML content and the date.\n        \"\"\"\n        index_url = \"/racing/racecards\"  # The dated URL is causing a 307 redirect\n        index_response = await self.make_request(\n            self.http_client,\n            \"GET\",\n            index_url,\n            headers=self._get_headers(),\n            follow_redirects=True,\n        )\n        if not index_response:\n            self.logger.warning(\"Failed to fetch SportingLife index page\", url=index_url)\n            return None\n\n        # Save the raw HTML for debugging in CI\n        try:\n            with open(\"sl_debug.html\", \"w\", encoding=\"utf-8\") as f:\n                f.write(index_response.text)\n        except Exception as e:\n            self.logger.warning(\"Failed to save debug HTML for SportingLife\", error=str(e))\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        links = {\n            a[\"href\"]\n            for a in index_soup.select('li[class^=\"MeetingSummary__LineWrapper\"] a[href*=\"/racecard/\"]')\n        }\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(\n                self.http_client, \"GET\", url_path, headers=self._get_headers()\n            )\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _get_headers(self) -> dict:\n        return {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-US,en;q=0.9\",\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Host\": \"www.sportinglife.com\",\n            \"Pragma\": \"no-cache\",\n            \"sec-ch-ua\": '\"Not/A)Brand\";v=\"99\", \"Google Chrome\";v=\"115\", \"Chromium\";v=\"115\"',\n            \"sec-ch-ua-mobile\": \"?0\",\n            \"sec-ch-ua-platform\": '\"Windows\"',\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"none\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n            \"Referer\": \"https://www.sportinglife.com/racing/racecards\",\n        }\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to SportingLifeAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n\n                header_text = clean_text(soup.select_one(\"h1.hr-race-header-title__text\").get_text())\n                parts = header_text.split()\n                race_time_str = parts[0]\n                track_name = \" \".join(parts[1:])\n\n                start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n\n                race_number = 1\n                nav_links = soup.select(\"a.hr-race-header-navigation-link\")\n                active_link = soup.select_one(\"a.hr-race-header-navigation-link--active\")\n                if active_link and nav_links:\n                    try:\n                        # Add 1 because list index is 0-based\n                        race_number = nav_links.index(active_link) + 1\n                    except ValueError:\n                        self.logger.warning(\"Active race link not found in navigation links.\")\n\n                runners = [self._parse_runner(row) for row in soup.select(\"div.hr-racing-runner-card-wrapper\")]\n\n                race = Race(\n                    id=f\"sl_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from SportingLife, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"a[href*='/racing/profiles/horse/']\")\n            if not name_node:\n                return None\n            # Extract the name, removing any non-alphanumeric trailing characters\n            name = clean_text(name_node.get_text()).splitlines()[0].strip()\n\n            num_node = row.select_one(\"span.hr-racing-runner-saddle-cloth-number\")\n            if not num_node:\n                return None\n            num_str = clean_text(num_node.get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n\n            odds_node = row.select_one(\"span.hr-racing-runner-betting-odds__odd\")\n            odds_str = clean_text(odds_node.get_text()) if odds_node else \"\"\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {\n                    self.source_name: OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n                }\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on SportingLife, skipping runner.\")\n            return None\n",
    "web_service/backend/adapters/tvg_adapter.py": "# python_service/adapters/tvg_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..core.exceptions import AdapterParsingError\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TVGAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US racing data from the TVG API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"TVG\"\n    BASE_URL = \"https://api.tvg.com/v2/races/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"TVG_API_KEY\") or not config.TVG_API_KEY:\n            raise AdapterConfigError(self.source_name, \"TVG_API_KEY is not configured.\")\n        self.tvg_api_key = config.TVG_API_KEY\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches all race details for a given date by first getting tracks.\"\"\"\n        headers = {\"X-Api-Key\": self.tvg_api_key}\n        summary_url = f\"summary?date={date}&country=USA\"\n\n        tracks_response = await self.make_request(self.http_client, \"GET\", summary_url, headers=headers)\n        if not tracks_response:\n            return None\n        tracks_data = tracks_response.json()\n\n        race_detail_tasks = []\n        for track in tracks_data.get(\"tracks\", []):\n            track_id = track.get(\"id\")\n            for race in track.get(\"races\", []):\n                race_id = race.get(\"id\")\n                if track_id and race_id:\n                    details_url = f\"{track_id}/{race_id}\"\n                    race_detail_tasks.append(self.make_request(self.http_client, \"GET\", details_url, headers=headers))\n\n        race_detail_responses = await asyncio.gather(*race_detail_tasks, return_exceptions=True)\n\n        # Filter out exceptions and return only successful responses\n        return [resp.json() for resp in race_detail_responses if resp and not isinstance(resp, Exception)]\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of detailed race JSON objects into Race models.\"\"\"\n        races = []\n        if not isinstance(raw_data, list):\n            self.logger.warning(\"raw_data is not a list, cannot parse TVG races.\")\n            return races\n\n        for race_detail in raw_data:\n            try:\n                if race := self._parse_race(race_detail):\n                    races.append(race)\n            except AdapterParsingError:\n                self.logger.warning(\n                    \"Failed to parse TVG race detail, skipping.\",\n                    race_detail=race_detail,\n                    exc_info=True,\n                )\n        return races\n\n    def _parse_race(self, race_detail: dict) -> Optional[Race]:\n        \"\"\"Parses a single detailed race JSON object into a Race model.\"\"\"\n        track = race_detail.get(\"track\")\n        race_info = race_detail.get(\"race\")\n\n        if not track or not race_info:\n            raise AdapterParsingError(self.source_name, \"Missing track or race info in race detail.\")\n\n        runners = []\n        for runner_data in race_detail.get(\"runners\", []):\n            if runner_data.get(\"scratched\"):\n                continue\n\n            odds = runner_data.get(\"odds\", {})\n            current_odds = odds.get(\"currentPrice\", {})\n            odds_str = current_odds.get(\"fractional\") or odds.get(\"morningLinePrice\", {}).get(\"fractional\")\n\n            try:\n                number = int(runner_data.get(\"programNumber\", \"0\").replace(\"A\", \"\"))\n            except (ValueError, TypeError):\n                self.logger.warning(f\"Could not parse program number: {runner_data.get('programNumber')}\")\n                continue\n\n            odds_data = {}\n            if odds_str:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds_data[self.source_name] = OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n\n            runners.append(\n                Runner(\n                    number=number,\n                    name=clean_text(runner_data.get(\"name\")),\n                    odds=odds_data,\n                    scratched=False,\n                )\n            )\n\n        if not runners:\n            raise AdapterParsingError(self.source_name, \"No non-scratched runners found.\")\n\n        post_time = race_info.get(\"postTime\")\n        if not post_time:\n            raise AdapterParsingError(self.source_name, \"Missing post time.\")\n\n        try:\n            start_time = datetime.fromisoformat(post_time.replace(\"Z\", \"+00:00\"))\n        except (ValueError, TypeError, AttributeError) as e:\n            raise AdapterParsingError(\n                self.source_name,\n                f\"Could not parse post time: {post_time}\",\n            ) from e\n\n        return Race(\n            id=f\"tvg_{track.get('code', 'UNK')}_{race_info.get('date', 'NODATE')}_{race_info.get('number', 0)}\",\n            venue=track.get(\"name\"),\n            race_number=race_info.get(\"number\"),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/analyzer.py": "from abc import ABC\nfrom abc import abstractmethod\nfrom decimal import Decimal\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\n\nimport structlog\n\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\ntry:\n    # winsound is a built-in Windows library\n    import winsound\nexcept ImportError:\n    winsound = None\ntry:\n    from win10toast_py3 import ToastNotifier\nexcept (ImportError, RuntimeError):\n    # Fails gracefully on non-Windows systems\n    ToastNotifier = None\n\nlog = structlog.get_logger(__name__)\n\n\ndef _get_best_win_odds(runner: Runner) -> Optional[Decimal]:\n    \"\"\"Gets the best win odds for a runner, filtering out invalid or placeholder values.\"\"\"\n    if not runner.odds:\n        return None\n\n    valid_odds = []\n    for source_data in runner.odds.values():\n        # Handle both dict and primitive formats\n        if isinstance(source_data, dict):\n            win = source_data.get('win')\n        elif hasattr(source_data, 'win'):\n            win = source_data.win\n        else:\n            win = source_data\n\n        if win is not None and 0 < win < 999:\n            valid_odds.append(win)\n\n    return min(valid_odds) if valid_odds else None\n\n\nclass BaseAnalyzer(ABC):\n    \"\"\"The abstract interface for all future analyzer plugins.\"\"\"\n\n    def __init__(self, **kwargs):\n        pass\n\n    @abstractmethod\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"The core method every analyzer must implement.\"\"\"\n        pass\n\n\nclass TrifectaAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzes races and assigns a qualification score based on the 'Trifecta of Factors'.\"\"\"\n\n    @property\n    def name(self) -> str:\n        return \"trifecta_analyzer\"\n\n    def __init__(\n        self,\n        max_field_size: int = 10,\n        min_favorite_odds: float = 2.5,\n        min_second_favorite_odds: float = 4.0,\n    ):\n        self.max_field_size = max_field_size\n        self.min_favorite_odds = Decimal(str(min_favorite_odds))\n        self.min_second_favorite_odds = Decimal(str(min_second_favorite_odds))\n        self.notifier = RaceNotifier()\n\n    def is_race_qualified(self, race: Race) -> bool:\n        \"\"\"A race is qualified for a trifecta if it has at least 3 non-scratched runners.\"\"\"\n        if not race or not race.runners:\n            return False\n\n        active_runners = sum(1 for r in race.runners if not r.scratched)\n        return active_runners >= 3\n\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"Scores all races and returns a dictionary with criteria and a sorted list.\"\"\"\n        qualified_races = []\n        for race in races:\n            if not self.is_race_qualified(race):\n                continue\n            score = self._evaluate_race(race)\n            if score > 0:\n                race.qualification_score = score\n                qualified_races.append(race)\n\n        qualified_races.sort(key=lambda r: r.qualification_score, reverse=True)\n\n        criteria = {\n            \"max_field_size\": self.max_field_size,\n            \"min_favorite_odds\": float(self.min_favorite_odds),\n            \"min_second_favorite_odds\": float(self.min_second_favorite_odds),\n        }\n\n        log.info(\n            \"Universal scoring complete\",\n            total_races_scored=len(qualified_races),\n            criteria=criteria,\n        )\n\n        for race in qualified_races:\n            if race.qualification_score and race.qualification_score >= 85:\n                self.notifier.notify_qualified_race(race)\n\n        return {\"criteria\": criteria, \"races\": qualified_races}\n\n    def _evaluate_race(self, race: Race) -> float:\n        \"\"\"Evaluates a single race and returns a qualification score.\"\"\"\n        # --- Constants for Scoring Logic ---\n        FAV_ODDS_NORMALIZATION = 10.0\n        SEC_FAV_ODDS_NORMALIZATION = 15.0\n        FAV_ODDS_WEIGHT = 0.6\n        SEC_FAV_ODDS_WEIGHT = 0.4\n        FIELD_SIZE_SCORE_WEIGHT = 0.3\n        ODDS_SCORE_WEIGHT = 0.7\n\n        active_runners = [r for r in race.runners if not r.scratched]\n\n        runners_with_odds = []\n        for runner in active_runners:\n            best_odds = _get_best_win_odds(runner)\n            if best_odds is not None:\n                runners_with_odds.append((runner, best_odds))\n\n        if len(runners_with_odds) < 2:\n            return 0.0\n\n        runners_with_odds.sort(key=lambda x: x[1])\n        favorite_odds = runners_with_odds[0][1]\n        second_favorite_odds = runners_with_odds[1][1]\n\n        # --- Calculate Qualification Score (as inspired by the TypeScript Genesis) ---\n        field_score = (self.max_field_size - len(active_runners)) / self.max_field_size\n\n        # Normalize odds scores - cap influence of extremely high odds\n        fav_odds_score = min(float(favorite_odds) / FAV_ODDS_NORMALIZATION, 1.0)\n        sec_fav_odds_score = min(float(second_favorite_odds) / SEC_FAV_ODDS_NORMALIZATION, 1.0)\n\n        # Weighted average\n        odds_score = (fav_odds_score * FAV_ODDS_WEIGHT) + (sec_fav_odds_score * SEC_FAV_ODDS_WEIGHT)\n        final_score = (field_score * FIELD_SIZE_SCORE_WEIGHT) + (odds_score * ODDS_SCORE_WEIGHT)\n\n        # --- Apply hard filters before scoring ---\n        if (\n            len(active_runners) > self.max_field_size\n            or favorite_odds < self.min_favorite_odds\n            or second_favorite_odds < self.min_second_favorite_odds\n        ):\n            return 0.0\n\n        score = round(final_score * 100, 2)\n        race.qualification_score = score\n        return score\n\n\nclass TinyFieldTrifectaAnalyzer(TrifectaAnalyzer):\n    \"\"\"A specialized TrifectaAnalyzer that only considers races with 6 or fewer runners.\"\"\"\n\n    def __init__(self, **kwargs):\n        # Override the max_field_size to 6 for \"tiny field\" analysis\n        super().__init__(max_field_size=6, min_favorite_odds=0.75, min_second_favorite_odds=2.0, **kwargs)\n\n    @property\n    def name(self) -> str:\n        return \"tiny_field_trifecta_analyzer\"\n\n\nclass AnalyzerEngine:\n    \"\"\"Discovers and manages all available analyzer plugins.\"\"\"\n\n    def __init__(self):\n        self.analyzers: Dict[str, Type[BaseAnalyzer]] = {}\n        self._discover_analyzers()\n\n    def _discover_analyzers(self):\n        # In a real plugin system, this would inspect a folder.\n        # For now, we register them manually.\n        self.register_analyzer(\"trifecta\", TrifectaAnalyzer)\n        self.register_analyzer(\"tiny_field_trifecta\", TinyFieldTrifectaAnalyzer)\n        log.info(\n            \"AnalyzerEngine discovered plugins\",\n            available_analyzers=list(self.analyzers.keys()),\n        )\n\n    def register_analyzer(self, name: str, analyzer_class: Type[BaseAnalyzer]):\n        self.analyzers[name] = analyzer_class\n\n    def get_analyzer(self, name: str, **kwargs) -> BaseAnalyzer:\n        analyzer_class = self.analyzers.get(name)\n        if not analyzer_class:\n            log.error(\"Requested analyzer not found\", requested_analyzer=name)\n            raise ValueError(f\"Analyzer '{name}' not found.\")\n        return analyzer_class(**kwargs)\n\n\nclass AudioAlertSystem:\n    \"\"\"Plays sound alerts for important events.\"\"\"\n\n    def __init__(self):\n        self.sounds = {\n            \"high_value\": Path(__file__).parent.parent.parent / \"assets\" / \"sounds\" / \"alert_premium.wav\",\n        }\n        self.enabled = winsound is not None\n\n    def play(self, sound_type: str):\n        if not self.enabled:\n            return\n\n        sound_file = self.sounds.get(sound_type)\n        if sound_file and sound_file.exists():\n            try:\n                winsound.PlaySound(str(sound_file), winsound.SND_FILENAME | winsound.SND_ASYNC)\n            except Exception as e:\n                log.warning(\"Could not play sound\", file=sound_file, error=e)\n\n\nclass RaceNotifier:\n    \"\"\"Handles sending native Windows notifications and audio alerts for high-value races.\"\"\"\n\n    def __init__(self):\n        self.toaster = ToastNotifier(\"Fortuna\") if ToastNotifier else None\n        self.audio_system = AudioAlertSystem()\n        self.notified_races = set()\n\n    def notify_qualified_race(self, race):\n        if not self.toaster or race.id in self.notified_races:\n            return\n\n        title = \"\ud83c\udfc7 High-Value Opportunity!\"\n        message = f\"\"\"{race.venue} - Race {race.race_number}\nScore: {race.qualification_score:.0f}%\nPost Time: {race.start_time.strftime(\"%I:%M %p\")}\"\"\"\n\n        try:\n            # The `threaded=True` argument is crucial to prevent blocking the main application thread.\n            self.toaster.show_toast(title, message, duration=10, threaded=True)\n            self.notified_races.add(race.id)\n            self.audio_system.play(\"high_value\")\n            log.info(\"Notification and audio alert sent for high-value race\", race_id=race.id)\n        except Exception as e:\n            # Catch potential exceptions from the notification library itself\n            log.error(\"Failed to send notification\", error=str(e), exc_info=True)\n",
    "web_service/backend/core/errors.py": "# python_service/core/errors.py\nfrom enum import Enum\n\n\nclass ErrorCategory(Enum):\n    CONFIGURATION_ERROR = \"Configuration missing or invalid\"\n    NETWORK_ERROR = \"HTTP/Network request failed\"\n    PARSING_ERROR = \"Data parsing or validation unsuccessful\"\n    UNEXPECTED_ERROR = \"An unhandled exception occurred\"\n",
    "web_service/backend/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "web_service/backend/initialize_db.py": "# python_service/initialize_db.py\nfrom db.init import initialize_database\n\n\ndef main():\n    \"\"\"\n    This script exists solely to initialize the database.\n    It should be called before the main server process is started.\n    \"\"\"\n    print(\"Initializing database...\", flush=True)\n    initialize_database()\n    print(\"Database initialization complete.\", flush=True)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "web_service/backend/middleware/error_handler.py": "# python_service/middleware/error_handler.py\n\nfrom fastapi import Request\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\n\nfrom ..user_friendly_errors import ERROR_MAP\n\n\nclass UserFriendlyException(Exception):\n    def __init__(self, error_key: str, status_code: int = 500, details: str = None):\n        self.error_key = error_key\n        self.status_code = status_code\n        self.details = details\n        error_info = ERROR_MAP.get(error_key, ERROR_MAP[\"default\"])\n        self.message = error_info[\"message\"]\n        self.suggestion = error_info[\"suggestion\"]\n        super().__init__(self.message)\n\n\nasync def user_friendly_exception_handler(request: Request, exc: UserFriendlyException):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"error\": {\n                \"message\": exc.message,\n                \"suggestion\": exc.suggestion,\n                \"details\": exc.details,\n            }\n        },\n    )\n\n\nasync def validation_exception_handler(request: Request, exc: RequestValidationError):\n    \"\"\"Convert Pydantic validation errors to user-friendly messages.\"\"\"\n    return JSONResponse(\n        status_code=422,\n        content={\n            \"detail\": \"Invalid request parameters\",\n            \"errors\": [\n                {\n                    \"field\": error[\"loc\"][-1] if error[\"loc\"] else \"unknown\",\n                    \"message\": error[\"msg\"],\n                    \"type\": error[\"type\"],\n                }\n                for error in exc.errors()\n            ],\n        },\n    )\n",
    "web_service/backend/monolith.py": "\"\"\"\nFortuna Monolith - Single executable frontend + backend\nProduction-grade with enhanced error handling, user-friendly startup, and better logging\n\nIMPORTANT: Uses WinForms instead of CEF for Python 3.10 compatibility\n(CEFPython3 v66.0 doesn't support Python 3.10.11)\n\"\"\"\nimport sys\nimport os\nfrom pathlib import Path\nimport logging\nimport io\nimport threading\nimport time\nimport json\nfrom contextlib import suppress\n\n# ====================================================================\n# CONSTANTS & CONFIGURATION\n# ====================================================================\nAPP_NAME = \"Fortuna Faucet\"\nAPP_VERSION = \"1.0.0\"\nAPI_HOST = \"127.0.0.1\"\nAPI_PORT = 8000\nBACKEND_STARTUP_TIMEOUT = 10\nHEALTH_CHECK_ATTEMPTS = 10\nHEALTH_CHECK_INTERVAL = 1\n\n# ====================================================================\n# LOGGING SETUP (BEFORE ANYTHING ELSE)\n# ====================================================================\ndef _get_log_file() -> Path:\n    \"\"\"Get log file path (works in both dev and frozen modes)\"\"\"\n    if getattr(sys, \"frozen\", False):\n        log_dir = Path(os.environ.get(\"TEMP\", \".\"))\n    else:\n        log_dir = Path(\".\")\n    return log_dir / \"fortuna-monolith.log\"\n\ndef _force_utf8_stream(stream):\n    \"\"\"Ensure stream uses UTF-8 encoding\"\"\"\n    if hasattr(stream, \"reconfigure\"):\n        with suppress(Exception):\n            stream.reconfigure(encoding=\"utf-8\", errors=\"replace\")\n            return stream\n\n    buffer = getattr(stream, \"buffer\", None)\n    if buffer is None:\n        return stream\n\n    with suppress(Exception):\n        return io.TextIOWrapper(buffer, encoding=\"utf-8\", errors=\"replace\")\n\n    return stream\n\ndef setup_logging():\n    \"\"\"Configure logging to both file and console\"\"\"\n    log_file = _get_log_file()\n\n    # Force UTF-8 on stdout/stderr\n    sys.stdout = _force_utf8_stream(sys.stdout)\n    sys.stderr = _force_utf8_stream(sys.stderr)\n\n    # Logging handlers\n    file_handler = logging.FileHandler(log_file, mode=\"w\", encoding=\"utf-8\")\n    console_handler = logging.StreamHandler(sys.stdout)\n\n    # Format with timestamps\n    formatter = logging.Formatter(\n        \"[%(levelname)-8s] %(asctime)s - %(message)s\",\n        datefmt=\"%H:%M:%S\"\n    )\n    file_handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n\n    # Setup root logger\n    logging.basicConfig(\n        level=logging.INFO,\n        handlers=[file_handler, console_handler],\n    )\n\n    logger = logging.getLogger(\"fortuna\")\n    return logger\n\nlogger = setup_logging()\n\n# Banner\nlogger.info(\"=\" * 70)\nlogger.info(f\"{APP_NAME} v{APP_VERSION} - Starting up\")\nlogger.info(\"=\" * 70)\nlogger.info(f\"Mode: {'Frozen EXE' if getattr(sys, 'frozen', False) else 'Development'}\")\nlogger.info(f\"Python: {sys.version.split()[0]}\")\n\n# ====================================================================\n# UI HELPERS (DEFINE BEFORE IMPORTS)\n# ====================================================================\ndef show_error_dialog(title: str, message: str):\n    \"\"\"Show error dialog (fallback if no GUI available)\"\"\"\n    try:\n        import tkinter as tk\n        from tkinter import messagebox\n        root = tk.Tk()\n        root.withdraw()\n        messagebox.showerror(title, message)\n    except:\n        # If tkinter fails, just log it\n        logger.error(f\"{title}: {message}\")\n\n# ====================================================================\n# FORCE PYINSTALLER TO INCLUDE DEPENDENCIES (TOP-LEVEL IMPORTS)\n# ====================================================================\nif False:  # Never executes, but PyInstaller sees the imports\n    import fastapi\n    import uvicorn\n    import webview\n    import pydantic\n    import starlette\n    import requests\n    from fastapi import FastAPI\n    from fastapi.staticfiles import StaticFiles\n    from fastapi.middleware.cors import CORSMiddleware\n    from fastapi.responses import FileResponse, JSONResponse\n\n# ====================================================================\n# IMPORT DEPENDENCIES WITH FRIENDLY ERROR HANDLING\n# ====================================================================\ndef _import_dependencies():\n    \"\"\"Import all required modules with descriptive error messages\"\"\"\n    try:\n        global uvicorn, webview, FastAPI, StaticFiles, CORSMiddleware, FileResponse, JSONResponse, requests\n\n        import requests\n        import uvicorn\n        import webview\n        from fastapi import FastAPI\n        from fastapi.staticfiles import StaticFiles\n        from fastapi.middleware.cors import CORSMiddleware\n        from fastapi.responses import FileResponse, JSONResponse\n\n        logger.info(\"OK - All dependencies loaded successfully\")\n        return True\n    except ImportError as e:\n        logger.critical(f\"FAILED - Missing dependency: {e}\")\n        show_error_dialog(\n            \"Missing Dependencies\",\n            f\"Could not load required library:\\n{str(e)}\\n\\n\"\n            \"Ensure all packages in requirements.txt are installed:\\n\"\n            \"pip install -r web_service/backend/requirements.txt\"\n        )\n        return False\n    except Exception as e:\n        logger.critical(f\"FAILED - Unexpected import error: {e}\", exc_info=True)\n        show_error_dialog(\n            \"Startup Error\",\n            f\"Unexpected error during startup:\\n{str(e)}\\n\\n\"\n            f\"Check the log file for details:\\n{_get_log_file()}\"\n        )\n        return False\n\nif not _import_dependencies():\n    sys.exit(1)\n\n# ====================================================================\n# UTILITY FUNCTIONS\n# ====================================================================\ndef get_resource_path(relative_path: str) -> Path:\n    \"\"\"Get absolute path to bundled resources\"\"\"\n    if getattr(sys, \"frozen\", False):\n        base_path = Path(sys._MEIPASS)\n    else:\n        base_path = Path(__file__).parent.parent.parent\n\n    full_path = base_path / relative_path\n    return full_path\n\n# ====================================================================\n# API CREATION\n# ====================================================================\ndef create_backend_api():\n    \"\"\"Create FastAPI instance with fallback support\"\"\"\n    api = FastAPI(title=\"Fortuna Backend\")\n\n    @api.get(\"/health\")\n    async def health():\n        \"\"\"Health check endpoint\"\"\"\n        return {\n            \"status\": \"ok\",\n            \"service\": \"fortuna-monolith\",\n            \"version\": APP_VERSION\n        }\n\n    try:\n        logger.info(\"Attempting to load full backend API...\")\n        from web_service.backend import api as backend_api\n\n        # Copy routes from full backend\n        for route in backend_api.app.routes:\n            api.routes.append(route)\n\n        logger.info(f\"OK - Full backend API loaded ({len(api.routes)} routes)\")\n        return api\n\n    except (ImportError, AttributeError) as e:\n        logger.warning(f\"Full backend import failed: {e}\")\n        logger.info(\"Running in minimal mode (basic endpoints only)\")\n\n        # Provide stub endpoints\n        @api.get(\"/races\")\n        async def get_races():\n            return {\n                \"status\": \"error\",\n                \"message\": \"Full API not available\",\n                \"sample\": [{\"id\": 1, \"name\": \"Example Race\", \"status\": \"pending\"}]\n            }\n\n        return api\n\n    except Exception as e:\n        logger.error(f\"Unexpected error loading backend: {e}\", exc_info=True)\n        return api\n\n# ====================================================================\n# APP CREATION\n# ====================================================================\ndef create_app():\n    \"\"\"Create main FastAPI application\"\"\"\n    logger.info(\"Creating FastAPI application...\")\n    app = FastAPI(title=\"Fortuna Monolith\")\n\n    # CORS for local development\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n    logger.info(\"OK - CORS middleware configured\")\n\n    # Mount backend API\n    logger.info(\"Mounting backend API at /api...\")\n    backend = create_backend_api()\n    app.mount(\"/api\", backend, name=\"backend\")\n\n    # Setup frontend serving\n    frontend_path = get_resource_path(\"frontend_dist\")\n    index_file = frontend_path / \"index.html\"\n\n    logger.info(f\"Frontend path: {frontend_path}\")\n\n    if not frontend_path.exists():\n        logger.error(\"Frontend directory not found - app will run without UI\")\n\n        @app.get(\"/\")\n        async def fallback():\n            return JSONResponse(\n                {\"message\": \"Frontend not available\", \"api\": \"/api/health\"},\n                status_code=503\n            )\n        return app\n\n    # Mount static files\n    logger.info(\"Configuring static file serving...\")\n\n    # Mount Next.js build output\n    next_dir = frontend_path / \"_next\"\n    if next_dir.exists():\n        app.mount(\"/_next\", StaticFiles(directory=str(next_dir)), name=\"next\")\n        logger.info(\"OK - Static assets mounted\")\n\n    public_dir = frontend_path / \"public\"\n    if public_dir.exists():\n        app.mount(\"/public\", StaticFiles(directory=str(public_dir)), name=\"public\")\n\n    # SPA routing - catch all unmapped routes and serve index.html\n    @app.get(\"/{full_path:path}\")\n    async def serve_spa(full_path: str):\n        # Skip API routes\n        if full_path.startswith(\"api/\"):\n            return JSONResponse({\"error\": \"Not found\"}, status_code=404)\n\n        # Try exact file\n        file_path = frontend_path / full_path\n        try:\n            if file_path.is_file() and file_path.is_relative_to(frontend_path):\n                return FileResponse(file_path)\n        except (ValueError, RuntimeError):\n            pass\n\n        # Try with .html extension\n        html_path = frontend_path / f\"{full_path}.html\"\n        try:\n            if html_path.is_file() and html_path.is_relative_to(frontend_path):\n                return FileResponse(html_path)\n        except (ValueError, RuntimeError):\n            pass\n\n        # SPA fallback to index\n        if index_file.exists():\n            return FileResponse(index_file)\n\n        return JSONResponse({\"error\": \"Not found\"}, status_code=404)\n\n    logger.info(\"OK - SPA routing configured\")\n    return app\n\n# ====================================================================\n# BACKEND SERVER\n# ====================================================================\ndef run_backend():\n    \"\"\"Run Uvicorn server\"\"\"\n    try:\n        logger.info(\"-\" * 70)\n        logger.info(\"STARTING BACKEND SERVER\")\n        logger.info(f\"API: http://{API_HOST}:{API_PORT}\")\n        logger.info(\"-\" * 70)\n\n        app = create_app()\n\n        # Run Uvicorn\n        uvicorn.run(\n            app,\n            host=API_HOST,\n            port=API_PORT,\n            log_level=\"warning\",\n            access_log=False,\n        )\n    except OSError as e:\n        logger.critical(f\"Port {API_PORT} is already in use: {e}\")\n        raise\n    except Exception as e:\n        logger.critical(f\"Backend error: {e}\", exc_info=True)\n        raise\n\n# ====================================================================\n# HEALTH CHECKS\n# ====================================================================\ndef check_backend_health(max_attempts: int = HEALTH_CHECK_ATTEMPTS) -> bool:\n    \"\"\"Check if backend is responding\"\"\"\n    logger.info(\"Testing backend health...\")\n\n    for attempt in range(1, max_attempts + 1):\n        try:\n            response = requests.get(\n                f\"http://{API_HOST}:{API_PORT}/api/health\",\n                timeout=2\n            )\n\n            if response.status_code == 200:\n                data = response.json()\n                logger.info(f\"OK - Backend responding: {data}\")\n                return True\n\n        except requests.ConnectionError:\n            if attempt < max_attempts:\n                logger.debug(f\"Attempt {attempt}/{max_attempts} - waiting...\")\n                time.sleep(HEALTH_CHECK_INTERVAL)\n        except Exception as e:\n            logger.warning(f\"Health check error: {e}\")\n\n    logger.warning(f\"Backend did not respond after {max_attempts} attempts\")\n    return False\n\n# ====================================================================\n# MAIN APPLICATION\n# ====================================================================\ndef main():\n    \"\"\"Main entry point\"\"\"\n    try:\n        logger.info(\"-\" * 70)\n        logger.info(f\"STARTING {APP_NAME}\")\n        logger.info(\"-\" * 70)\n\n        # Start backend in background\n        logger.info(\"Starting backend server...\")\n        backend_thread = threading.Thread(target=run_backend, daemon=True)\n        backend_thread.start()\n        logger.info(\"OK - Backend thread started\")\n\n        # Wait for backend to initialize\n        logger.info(f\"Waiting for backend to be ready (max {BACKEND_STARTUP_TIMEOUT}s)...\")\n        time.sleep(2)\n\n        # Health check\n        backend_ready = check_backend_health()\n\n        if not backend_ready:\n            logger.warning(\"Backend not responding - launching UI anyway\")\n\n        # Launch UI\n        logger.info(\"-\" * 70)\n        logger.info(\"LAUNCHING USER INTERFACE\")\n        logger.info(\"-\" * 70)\n\n        try:\n            # Use WinForms GUI (default on Windows, compatible with Python 3.10)\n            # CEF is not used here to avoid Python version compatibility issues\n            webview.create_window(\n                title=APP_NAME,\n                url=f\"http://{API_HOST}:{API_PORT}\",\n                width=1400,\n                height=900,\n                resizable=True,\n                min_size=(800, 600),\n                background_color=\"#1a1a1a\",\n            )\n\n            logger.info(\"Starting webview event loop...\")\n            # Don't specify gui='cef' - let pywebview auto-detect WinForms\n            webview.start(debug=False)\n\n        except Exception as e:\n            logger.error(f\"Webview error: {e}\", exc_info=True)\n            # Fall back to browser message\n            logger.info(f\"Open http://{API_HOST}:{API_PORT} in your browser\")\n            input(\"Press ENTER to exit...\")\n\n        logger.info(f\"{APP_NAME} closed normally\")\n\n    except KeyboardInterrupt:\n        logger.info(\"Application interrupted by user\")\n    except Exception as e:\n        logger.critical(f\"Fatal error: {e}\", exc_info=True)\n        show_error_dialog(\n            f\"{APP_NAME} Error\",\n            f\"Application failed to start:\\n{str(e)}\\n\\n\"\n            f\"Please check the log file at:\\n{_get_log_file()}\"\n        )\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
    "web_service/backend/requirements.txt": "# Project: Fortuna Faucet\n# Python Version: 3.10.11\n# Platform: Windows\n# Last Validated: 2026-01-10\n# Status: PRODUCTION READY\n# Notes: Manually validated, NOT auto-generated. All versions tested and confirmed working.\n\n# Installation: pip install -r requirements.txt\n\n# Core Web Framework\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\nstarlette==0.27.0\npydantic==2.5.0\npydantic-core==2.14.1\npydantic-settings==2.1.0\n\n# Asgi Http\nanyio==3.7.1\nh11==0.14.0\nh2==4.1.0\nhpack==4.0.0\nhttpcore==1.0.2\nhttptools==0.6.1\nhttpx==0.25.2\nhyperframe==6.1.0\nwebsockets==12.0\nwsproto==1.2.0\n\n# Http Client\nrequests==2.31.0\nurllib3==2.1.0\ncertifi==2023.7.22\ncharset-normalizer==3.3.2\nidna==3.6\n\n# Database Orm\nsqlalchemy==2.0.23\ngreenlet==3.0.2\naiosqlite==0.19.0\npsycopg2-binary==2.9.9\n\n# Data Processing\nnumpy==1.24.3\npandas==2.0.3\npython-dateutil==2.8.2\npytz==2023.3.post1\ntzdata==2023.3\nsix==1.16.0\n\n# Html Web Parsing\nbeautifulsoup4==4.12.2\nsoupsieve==2.5\nselectolax==0.3.20\n\n# Cli Configuration\nclick==8.1.7\npython-dotenv==1.0.0\npyyaml==6.0.1\n\n# Cryptography Security\ncryptography==41.0.7\ncffi==1.16.0\npycparser==2.21\nsecretstorage==3.5.0\nkeyring==24.3.0\njeepney==0.9.0\n\n# Caching Rate Limiting\nredis==5.0.1\nlimits==3.7.0\nslowapi==0.1.9\ntenacity==8.2.3\n\n# Desktop Gui Windows\npywebview==5.4\nbottle==0.13.4\nproxy-tools==0.1.0\n# NOTE: pywebview WITHOUT CEF (uses WinForms instead). CEFPython3 66.0 incompatible with Python 3.10.11\n\n# System Utilities\npsutil==5.9.6\n\n# Logging Monitoring\nstructlog==23.2.0\n\n# Code Quality Building\nblack==23.12.0\npyinstaller==6.1.0\npyinstaller-hooks-contrib==2023.11\naltgraph==0.17.3\nwheel==0.41.2\nbuild==1.0.3\npip-tools==7.3.0\n\n# Testing\npytest==7.4.3\npytest-asyncio==0.21.1\niniconfig==2.0.0\npluggy==1.3.0\npackaging==23.2\n\n# Type Hints Extensions\ntyping-extensions==4.8.0\ntyping-inspect==0.9.0\nannotated-types==0.6.0\n\n# Utilities\nmypy-extensions==1.0.0\npathspec==0.11.2\nplatformdirs==4.0.0\nmore-itertools==10.1.0\njaraco.classes==3.3.1\njaraco.context==5.3.0\njaraco.functools==4.0.0\ndeprecated==1.2.14\nsniffio==1.3.0\nwrapt==1.16.0\nwatchfiles==0.20.0\npygments==2.17.2\n\n# --- Excluded Packages ---\n# - uvloop : NOT supported on Windows (Unix-only features)\n# - numpy 2x: Requires Python 3.11+\n# - pandas 2.1+: Has compatibility issues with Python 3.10\n# - pywebview 6x: Has Windows compatibility issues\n# - cefpython3: Incompatible with Python 3.10.11\n",
    "web_service/backend/security.py": "# python_service/security.py\n\nimport secrets\nimport os\n\nfrom fastapi import Depends\nfrom fastapi import HTTPException\nfrom fastapi import Security\nfrom fastapi import status\nfrom fastapi.security import APIKeyHeader\n\nfrom .config import Settings\nfrom .config import get_settings\n\nAPI_KEY_NAME = \"X-API-Key\"\napi_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)\n\nasync def verify_api_key(key: str = Security(api_key_header), settings: Settings = Depends(get_settings)):\n    \"\"\"\n    Verifies the provided API key against the one in settings using a\n    timing-attack resistant comparison.\n\n    In a CI environment, this check is bypassed to allow for automated testing.\n    \"\"\"\n    is_ci = os.environ.get(\"CI\", \"false\").lower() in (\"true\", \"1\", \"yes\")\n    if is_ci:\n        return True\n\n    if secrets.compare_digest(key, settings.API_KEY):\n        return True\n    else:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Invalid or missing API Key\")\n",
    "web_service/backend/utils/__init__.py": "",
    "web_service/backend/windows_compat.py": "\"\"\"\nWindows Compatibility Utilities\n\nCRITICAL: This module MUST be imported and called at the top of EVERY entry point\nthat uses asyncio or uvicorn in a PyInstaller bundle on Windows.\n\nWithout this fix, the asyncio event loop will fail to bind network ports, causing\nsilent failures where uvicorn reports \"Application startup complete\" but the\nservice is actually inaccessible.\n\"\"\"\n\nimport sys\n\n\ndef setup_windows_event_loop():\n    \"\"\"\n    Configure Windows event loop policy for PyInstaller bundles.\n\n    This MUST be called BEFORE any asyncio or uvicorn initialization.\n\n    Context:\n    - PyInstaller bundles on Windows have a broken default event loop policy\n    - The default policy (ProactorEventLoop) silently fails to bind ports\n    - WindowsSelectorEventLoopPolicy is the only policy that works reliably\n\n    This function is idempotent and safe to call multiple times.\n    \"\"\"\n    if sys.platform == 'win32' and getattr(sys, 'frozen', False):\n        import asyncio\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n        print('[BOOT] \u2713 Applied WindowsSelectorEventLoopPolicy for PyInstaller',\n              file=sys.stderr)\n    else:\n        # Not Windows or not frozen - no action needed\n        pass\n",
    "web_service/frontend/.gitignore": "# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.\n\n# Dependencies\n/node_modules\n/.pnp\n.pnp.js\n\n# Testing\n/coverage\n\n# Next.js\n/.next/\n/out/\n\n# Production\n/build\n\n# Misc\n.DS_Store\n*.pem\n\n# Local .env files\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n\n# Log files\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# Editor directories and files\n.vscode\n.idea\n*.suo\n*.ntvs*\n*.njsproj\n*.sln\n*.sw?",
    "web_service/frontend/app/components/LiveModeToggle.tsx": "// web_platform/frontend/src/components/LiveModeToggle.tsx\n'use client';\n\nimport React from 'react';\n\ninterface LiveModeToggleProps {\n  isLive: boolean;\n  onToggle: (isLive: boolean) => void;\n  isDisabled: boolean;\n}\n\nexport const LiveModeToggle: React.FC<LiveModeToggleProps> = ({ isLive, onToggle, isDisabled }) => {\n  const handleToggle = () => {\n    if (!isDisabled) {\n      onToggle(!isLive);\n    }\n  };\n\n  return (\n    <button\n      onClick={handleToggle}\n      disabled={isDisabled}\n      className={`relative inline-flex items-center h-8 rounded-full w-32 transition-colors duration-300 ease-in-out focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-slate-800 focus:ring-blue-500 ${\n        isDisabled ? 'cursor-not-allowed bg-slate-700' : 'cursor-pointer'\n      } ${isLive ? 'bg-green-600' : 'bg-slate-600'}`}\n    >\n      <span className=\"sr-only\">Toggle Live Mode</span>\n      <span\n        className={`absolute left-1 top-1 inline-block w-6 h-6 rounded-full bg-white transform transition-transform duration-300 ease-in-out ${\n          isLive ? 'translate-x-[104px]' : 'translate-x-0'\n        }`}\n      />\n      <span\n        className={`absolute left-8 transition-opacity duration-200 ease-in-out ${\n          !isLive && !isDisabled ? 'opacity-100' : 'opacity-50'\n        }`}\n      >\n        Poll\n      </span>\n      <span\n        className={`absolute right-4 transition-opacity duration-200 ease-in-out ${\n          isLive && !isDisabled ? 'opacity-100' : 'opacity-50'\n        }`}\n      >\n        \u26a1 Live\n      </span>\n    </button>\n  );\n};\n",
    "web_service/frontend/app/components/RaceFilters.tsx": "// web_platform/frontend/src/components/RaceFilters.tsx\n'use client';\n\nimport { useState, useCallback } from 'react';\nimport { Settings, RotateCcw } from 'lucide-react';\n\ninterface FilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nexport interface RaceFiltersProps {\n  onParamsChange: (params: FilterParams) => void;\n  isLoading: boolean;\n  refetch: () => void;\n}\n\nconst DEFAULT_PARAMS: FilterParams = {\n  maxFieldSize: 10,\n  minFavoriteOdds: 2.5,\n  minSecondFavoriteOdds: 4.0,\n};\n\nexport function RaceFilters({ onParamsChange, isLoading, refetch }: RaceFiltersProps) {\n  const [params, setParams] = useState<FilterParams>(DEFAULT_PARAMS);\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // Handle individual parameter changes\n  const handleChange = useCallback((key: keyof FilterParams, value: number) => {\n    setParams(prev => {\n      const updated = { ...prev, [key]: value };\n      onParamsChange(updated);\n      return updated;\n    });\n    // Debounce the refetch call\n    const timer = setTimeout(() => {\n      refetch();\n    }, 500);\n    return () => clearTimeout(timer);\n  }, [onParamsChange, refetch]);\n\n  // Reset to defaults\n  const handleReset = useCallback(() => {\n    setParams(DEFAULT_PARAMS);\n    onParamsChange(DEFAULT_PARAMS);\n    refetch();\n  }, [onParamsChange, refetch]);\n\n  return (\n    <div className=\"bg-gradient-to-r from-slate-800 to-slate-900 rounded-lg p-4 mb-6 border border-slate-700\">\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-2\">\n          <Settings className=\"w-5 h-5 text-amber-500\" />\n          <h3 className=\"text-lg font-semibold text-white\">Race Filters</h3>\n        </div>\n        <button\n          onClick={() => setIsExpanded(!isExpanded)}\n          className=\"text-sm text-slate-400 hover:text-slate-200 transition\"\n        >\n          {isExpanded ? 'Hide' : 'Show'}\n        </button>\n      </div>\n\n      {isExpanded && (\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 pt-4 border-t border-slate-700\">\n          {/* Max Field Size */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Max Field Size\n              <span className=\"text-amber-500 ml-2\">{params.maxFieldSize}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2\"\n              max=\"20\"\n              value={params.maxFieldSize}\n              onChange={(e) => handleChange('maxFieldSize', parseInt(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Filters races with larger fields</p>\n          </div>\n\n          {/* Min Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"1.5\"\n              max=\"5\"\n              step=\"0.1\"\n              value={params.minFavoriteOdds}\n              onChange={(e) => handleChange('minFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = pickier favorites</p>\n          </div>\n\n          {/* Min Second Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min 2nd Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minSecondFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2.0\"\n              max=\"8\"\n              step=\"0.1\"\n              value={params.minSecondFavoriteOdds}\n              onChange={(e) => handleChange('minSecondFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = better odds separation</p>\n          </div>\n\n          {/* Reset Button */}\n          <div className=\"md:col-span-3 flex justify-end pt-4 border-t border-slate-700\">\n            <button\n              onClick={handleReset}\n              disabled={isLoading}\n              className=\"inline-flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-600 text-slate-200 rounded text-sm font-medium transition disabled:opacity-50\"\n            >\n              <RotateCcw className=\"w-4 h-4\" />\n              Reset to Defaults\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n",
    "web_service/frontend/app/components/TrifectaFactors.tsx": "// TrifectaFactors.tsx - FINAL, DYNAMIC VERSION\n'use client';\nimport React from 'react';\n\ninterface TrifectaFactorsProps {\n  factorsJson: string | null;\n}\n\nexport function TrifectaFactors({ factorsJson }: TrifectaFactorsProps) {\n  if (!factorsJson) {\n    return <div className=\"text-sm text-gray-500\">No analysis factors available.</div>;\n  }\n\n  try {\n    const factors = JSON.parse(factorsJson);\n    const positiveFactors = Object.entries(factors).filter(([key, value]: [string, any]) => value.ok);\n\n    if (positiveFactors.length === 0) {\n      return <div className=\"text-sm text-gray-500\">No positive factors identified.</div>;\n    }\n\n    return (\n      <div className=\"mt-2 text-xs\">\n        <h4 className=\"font-semibold mb-1\">Key Factors:</h4>\n        <ul className=\"list-disc list-inside space-y-1\">\n          {positiveFactors.map(([key, value]: [string, any]) => (\n            <li key={key} className=\"text-gray-700\">\n              <span className=\"font-medium text-green-600\">\u2713</span> {value.reason} ({value.points > 0 ? `+${value.points}` : value.points} pts)\n            </li>\n          ))}\n        </ul>\n      </div>\n    );\n  } catch (error) {\n    console.error(\"Failed to parse trifecta factors:\", error);\n    return <div className=\"text-sm text-red-500\">Error displaying analysis factors.</div>;\n  }\n}",
    "web_service/frontend/app/lib/queryClient.ts": "// web_platform/frontend/src/lib/queryClient.ts\nimport { QueryClient } from '@tanstack/react-query';\n\nexport const queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      retry: 3,\n      staleTime: 1000 * 60 * 5, // 5 minutes\n    },\n  },\n});\n",
    "web_service/frontend/next-env.d.ts": "/// <reference types=\"next\" />\n/// <reference types=\"next/image-types/global\" />\n\n// NOTE: This file should not be edited\n// see https://nextjs.org/docs/app/building-your-application/configuring/typescript for more information.\n",
    "wix/WixUI_CustomInstallDir.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:WixUI=\"http://schemas.microsoft.com/wix/WixUIExtension\">\n  <Fragment>\n    <UI Id=\"WixUI_CustomInstallDir\">\n        <DialogRef Id=\"BrowseDlg\" />\n        <DialogRef Id=\"DiskCostDlg\" />\n        <DialogRef Id=\"ErrorDlg\" />\n        <DialogRef Id=\"FatalError\" />\n        <DialogRef Id=\"FilesInUse\" />\n        <DialogRef Id=\"MsiRMFilesInUse\" />\n        <DialogRef Id=\"PrepareDlg\" />\n        <DialogRef Id=\"UserExit\" />\n        <DialogRef Id=\"WelcomeDlg\" />\n        <DialogRef Id=\"InstallDirDlg\" />\n        <DialogRef Id=\"VerifyReadyDlg\" />\n\n        <!-- Use our custom progress dialog instead of the default -->\n        <DialogRef Id=\"InstallProgressDlg\" />\n\n        <Publish Dialog=\"WelcomeDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"InstallDirDlg\">1</Publish>\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"WelcomeDlg\">1</Publish>\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Next\" Event=\"SetTargetPath\" Value=\"[WIXUI_INSTALLDIR]\" Order=\"1\" />\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"VerifyReadyDlg\" Order=\"2\">1</Publish>\n        <Publish Dialog=\"VerifyReadyDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"InstallDirDlg\" Order=\"1\">NOT Installed</Publish>\n        <Publish Dialog=\"VerifyReadyDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"MaintenanceTypeDlg\" Order=\"2\">Installed</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n"
}