{
    ".github/actions/run-smoke-test/action.yml": "name: 'Run 4-Step Diagnostic Smoke Test'\ndescription: 'Installs an MSI, then runs a 4-step diagnostic to verify file installation, service status, port binding, and API health, finishing with a Paparazzi screenshot.'\n\ninputs:\n  msi-artifact-name:\n    description: 'The name of the MSI artifact to download.'\n    required: true\n  service-name:\n    description: 'The name of the Windows Service to verify (e.g., FortunaWebService).'\n    required: true\n  executable-path:\n    description: 'The full, absolute path to the installed service executable to verify.'\n    required: true\n  port:\n    description: 'The port to check for a listener.'\n    required: true\n  firewall-rule-name:\n    description: 'The name of the firewall rule to create.'\n    required: true\n\nruns:\n  using: \"composite\"\n  steps:\n    - name: \ud83d\udce5 Download MSI Artifact\n      uses: actions/download-artifact@v4\n      with:\n        name: ${{ inputs.msi-artifact-name }}\n        path: installer\n\n    - name: \ud83d\udee1\ufe0f Firewall & Install\n      shell: pwsh\n      run: |\n        New-NetFirewallRule -DisplayName \"${{ inputs.firewall-rule-name }}\" -Direction Inbound -LocalPort ${{ inputs.port }} -Protocol TCP -Action Allow\n        if (Get-Service -Name \"${{ inputs.service-name }}\" -ErrorAction SilentlyContinue) {\n          sc.exe stop \"${{ inputs.service-name }}\" 2>&1 | Out-Null\n          sc.exe delete \"${{ inputs.service-name }}\" 2>&1 | Out-Null\n        }\n        $msi = Get-ChildItem installer -Filter \"*.msi\" -Recurse | Select-Object -First 1\n        if (!$msi) { throw \"No MSI found\" }\n        Write-Host \"Installing $($msi.Name)...\"\n        $msiPath = $msi.FullName\n        $args = \"/i `\"$msiPath`\" /qn /L*v installation.log\"\n        $proc = Start-Process msiexec.exe -ArgumentList $args -Wait -NoNewWindow -PassThru\n        if ($proc.ExitCode -ne 0) {\n          Get-Content installation.log -Tail 50\n          throw \"Install failed with code $($proc.ExitCode)\"\n        }\n\n    - name: \"\u2705 Create Required Runtime Directories Post-Install\"\n      shell: pwsh\n      run: |\n        $installRoot = Split-Path -Path \"${{ inputs.executable-path }}\" -Parent\n        if (-not (Test-Path $installRoot)) {\n          Write-Error \"Installation directory not found at $installRoot. Cannot create runtime directories.\"\n          exit 1\n        }\n        New-Item -Path \"$installRoot\\data\" -ItemType Directory -Force | Out-Null\n        New-Item -Path \"$installRoot\\json\" -ItemType Directory -Force | Out-Null\n        New-Item -Path \"$installRoot\\logs\" -ItemType Directory -Force | Out-Null\n        Write-Host \"\u2705 Created data, json, and logs directories in $installRoot\"\n\n    - name: '\ud83d\udd2c Complete Smoke Test (3-Layer Defense)'\n      shell: pwsh\n      run: |\n        Set-StrictMode -Version Latest\n        $ErrorActionPreference = \"Stop\"\n\n        # --- LAYER 1: INSTALLATION & FILE VERIFICATION ---\n        Write-Host \"`n--- DEFENSE LAYER 1: VERIFYING INSTALLATION ---\"\n        $installRoot = Split-Path -Path \"${{ inputs.executable-path }}\" -Parent\n        if (-not (Test-Path $installRoot)) {\n          Write-Error \"\u274c LAYER 1 FAILED: Install directory not found: $installRoot\"\n          exit 1\n        }\n        $mainExe = Get-ChildItem -Path $installRoot -Filter \"*.exe\" -Recurse | Where-Object { $_.Name -notmatch 'uninstall' } | Select -First 1\n        if (-not $mainExe) { Write-Error \"\u274c LAYER 1 FAILED: Main executable not found.\"; exit 1 }\n        Write-Host \"\u2705 Layer 1 Passed: Found main executable ($($mainExe.Name)).\"\n\n        # --- LAYER 2: PROCESS VERIFICATION ---\n        Write-Host \"`n--- DEFENSE LAYER 2: VERIFYING PROCESS STARTUP ---\"\n        $svc = Get-Service \"${{ inputs.service-name }}\" -ErrorAction SilentlyContinue\n        if (!$svc) {\n          Write-Error \"\u274c LAYER 2 FAILED: Service '${{ inputs.service-name }}' is NOT registered!\"\n          exit 1\n        }\n        if ($svc.Status -ne 'Running') {\n          Start-Service \"${{ inputs.service-name }}\"\n          Start-Sleep -Seconds 10\n        }\n        $svc = Get-Service \"${{ inputs.service-name }}\"\n        if ($svc.Status -ne 'Running') {\n          Write-Error \"\u274c LAYER 2 FAILED: Service failed to start. Status: $($svc.Status)\"\n          Get-EventLog -LogName System -Source \"Service Control Manager\" -Newest 20 | Format-Table -AutoSize\n          exit 1\n        }\n        Write-Host \"\u2705 Layer 2 Passed: Service is RUNNING.\"\n\n        # Inserted Backend Alive Check\n        Write-Host \"--- Verifying backend process stability (10s alive check) ---\"\n        Start-Sleep -Seconds 10\n        $svcProcess = Get-CimInstance win32_service | where name -eq \"${{ inputs.service-name }}\" | select -ExpandProperty ProcessId\n        if ($null -eq (Get-Process -Id $svcProcess -ErrorAction SilentlyContinue)) {\n          Write-Error \"\u274c Backend process crashed within 10 seconds of starting.\"\n          exit 1\n        }\n        Write-Host \"\u2705 Backend process is still alive.\"\n\n        # --- LAYER 3: NETWORK VERIFICATION ---\n        Write-Host \"`n--- DEFENSE LAYER 3: VERIFYING NETWORK ENDPOINT ---\"\n        $maxAttempts = 10\n        $healthUrl = \"http://localhost:${{ inputs.port }}/health\"\n        for ($i = 1; $i -le $maxAttempts; $i++) {\n          try {\n            Write-Host \"Attempt $i/${maxAttempts}: Pinging $healthUrl...\"\n            $response = Invoke-WebRequest -Uri $healthUrl -Method Get -UseBasicParsing -ErrorAction Stop\n            if ($response.StatusCode -eq 200) {\n              Write-Host \"\u2705\u2705\u2705 SMOKE TEST PASSED ALL 3 DEFENSE LAYERS \u2705\u2705\u2705\"\n              exit 0\n            }\n          } catch {\n            Write-Host \"\u23f3 Waiting for service...\"\n            Start-Sleep -Seconds 5\n          }\n        }\n        Write-Error \"\u274c LAYER 3 FAILED: Service Failed Health Check after $maxAttempts attempts\"\n        exit 1\n\n    - name: '\ud83d\udcf8 The Paparazzi (Visual Proof)'\n      shell: pwsh\n      run: |\n        Write-Host \"Installing Playwright...\"\n        npm install playwright\n        npx playwright install chromium --with-deps\n\n        $url = \"http://127.0.0.1:${{ inputs.port }}/docs\"\n\n        node -e \"\n          const { chromium } = require('playwright');\n          (async () => {\n            try {\n              const browser = await chromium.launch();\n              const page = await browser.newPage();\n              await page.goto('$url', { timeout: 15000 });\n              await page.waitForSelector('.swagger-ui', { timeout: 5000 }).catch(() => console.log('UI not fully loaded, snapping anyway...'));\n              await page.screenshot({ path: 'proof-of-life.png', fullPage: true });\n              await browser.close();\n            } catch (e) {\n              console.error(e); process.exit(1);\n            }\n          })();\n        \"\n\n    - name: Upload Visual Proof\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: visual-proof-${{ github.run_id }}\n        path: proof-of-life.png\n\n    - name: \ud83e\uddf9 Cleanup\n      if: always()\n      shell: pwsh\n      run: |\n        sc.exe stop ${{ inputs.service-name }}\n        sc.exe delete ${{ inputs.service-name }}\n        Remove-NetFirewallRule -DisplayName \"${{ inputs.firewall-rule-name }}\" -ErrorAction SilentlyContinue\n",
    ".github/scripts/generate_sbom.py": "import json\nfrom datetime import datetime\nfrom pathlib import Path\n\nfreeze = Path('backend/backend-freeze.txt')\npackages = []\nif freeze.exists():\n    for line in freeze.read_text().splitlines():\n        if '==' in line:\n            packages.append({\n                'name': line.split('==')[0],\n                'version': line.split('==')[1]\n            })\n\nsbom = {\n    'spdxVersion': 'SPDX-2.3',\n    'name': 'HatTrick Fusion Backend',\n    'packages': packages\n}\n\nPath('sbom.json').write_text(json.dumps(sbom, indent=2))\n",
    "ARCHITECTURAL_MANDATE.md": "# Fortuna Faucet - Architectural Mandate (v3.0)\n\nThis document codifies the architectural laws and philosophical principles that govern the Fortuna Faucet kingdom. Adherence to this mandate is non-negotiable for all development.\n\n---\n\n## The Prime Directive: A Professional, Resilient System\n\nThe ultimate goal of this project is to be a professional-grade, A+ intelligence engine. This is achieved through three core pillars:\n\n1.  **Rigid Standardization:** Code should be consistent and predictable. Shared logic must be centralized. Common patterns must be enforced, not merely suggested.\n2.  **Resilience Engineering:** The system must be self-healing and gracefully handle the failure of its individual components. We do not simply handle errors; we build a system that anticipates and survives them.\n3.  **Developer Clarity:** The codebase must be easy to understand, maintain, and extend. Code should be self-documenting, and its intent should be obvious.\n\n---\n\n## The Law of the Adapters: The `BaseAdapterV3` Pattern\n\nAll new data adapters **MUST** inherit from the `BaseAdapterV3` abstract base class. This is the cornerstone of our standardization and resilience strategy.\n\nThe `BaseAdapterV3` enforces a strict separation of concerns:\n\n1.  **`_fetch_data(self, date)` -> `Any`:** This method's **only** responsibility is to perform network operations and retrieve raw data (e.g., HTML, JSON). It should contain no parsing logic.\n2.  **`_parse_races(self, raw_data)` -> `list[Race]`:** This method's **only** responsibility is to parse the raw data provided by `_fetch_data` into a list of `Race` objects. It must be a pure function with no side effects or network calls.\n\nThe public-facing `get_races()` method is provided by the base class and **MUST NOT** be overridden. It orchestrates the fetch-then-parse pipeline, ensuring that all adapters behave identically from the engine's perspective.\n\nThis pattern guarantees that every adapter in our fleet is consistent, predictable, and easy to test.\n\n---\n\n## The Law of the Engine: Orchestrate, Don't Participate\n\nThe `OddsEngine` is the central orchestrator. Its responsibilities are:\n\n-   To manage the fleet of active adapters.\n-   To execute all adapter fetches in parallel.\n-   To gracefully handle the failure of any individual adapter without halting the entire process.\n-   To perform the deduplication and merging of race data from multiple sources.\n-   To manage the caching layer (Redis).\n\nThe engine should remain agnostic to the internal workings of any specific adapter. It interacts only with the standardized interface provided by `BaseAdapterV3`.\n\n---\n\n## The Law of the Core Texts: Maintain the Truth\n\nThe project's core documentation is not optional. It is the living memory and strategic guide of the kingdom.\n\n-   **`ROADMAP_APPENDICES.MD`:** The Grand Strategy must be kept current. Completed objectives must be marked as such.\n-   **`HISTORY.MD`:** Significant architectural shifts and completed campaigns must be chronicled.\n-   **`PSEUDOCODE.MD`:** The architectural blueprint must be updated to reflect major changes to the system's design.\n-   **Manifests (`MANIFEST*.md`):** All new files must be added to the appropriate manifest to ensure the integrity of the archival system.\n\n\n---\n\n## The Final Law: The Law of the True Scribe\n\n**Effective Date:** 2025-10-15\n\n**Verdict:** The system of manually maintained manifest files (`MANIFEST.md`, `MANIFEST2.md`, `MANIFEST3.md`) is hereby declared a catastrophic failure and is **permanently deprecated**.\n\n**The New Law:** The one and only method for generating the project's `FORTUNA_ALL` archives is the `ARCHIVE_PROJECT.py` script. This 'True Scribe' is the single, automated source of truth. It programmatically scans and categorizes the entire kingdom, ensuring a perfect, complete, and uncorrupted archive is generated every time.\n\nAll previous archival scripts (`create_fortuna_json.py`, `MANAGE_MANIFESTS.py`) are not to be used under any circumstances.",
    "Dockerfile": "# Main Application Stage\nFROM python:3.10.11-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    curl \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Copy requirements\nCOPY web_service/backend/requirements.txt /app/web_service/backend/\n\n# Install Python dependencies\nRUN pip install --no-cache-dir -r /app/web_service/backend/requirements.txt\n\n# Copy backend code\nCOPY web_service/backend /app/web_service/backend\nCOPY web_service/__init__.py /app/web_service/\n\n# Copy pre-built frontend assets\nCOPY web_service/frontend/public /app/web_service/frontend/public\n\n# Create required directories\nRUN mkdir -p /app/web_service/backend/data \\\n    && mkdir -p /app/web_service/backend/json \\\n    && mkdir -p /app/web_service/backend/logs\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:8000/api/health || exit 1\n\n# Set entrypoint\nWORKDIR /app\nENV PYTHONUNBUFFERED=1\nEXPOSE 8000\n\nCMD [\"python\", \"-m\", \"web_service.backend.main\"]\n",
    "PSEUDOCODE2026.MD": "# \ud83d\udc0e Fortuna Faucet - Complete Pseudocode Blueprint\n\n**Status:** Unified Monolith Architecture\n**Version:** 3.0.0\n**Last Updated:** January 13, 2026\n\n---\n\n## TABLE OF CONTENTS\n\n1.  System Overview\n2.  Architecture: The Unified Monolith\n3.  Backend Engine (Python/FastAPI)\n4.  Frontend Interface (TypeScript/Next.js)\n5.  Data Models & API Specification\n6.  Deployment & Automation (CI/CD)\n7.  End-to-End Workflow\n\n---\n\n## 1. SYSTEM OVERVIEW\n\n```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551         FORTUNA FAUCET - Racing Analysis Platform             \u2551\n\u2551      Unified Monolith Architecture for Cross-Platform Use      \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nMISSION:\n  \u2022 Acquire race data from 20+ global sources (APIs + web scraping).\n  \u2022 Normalize and deduplicate data into a canonical Race format.\n  \u2022 Apply analytical filters to surface high-value betting opportunities.\n  \u2022 Serve a static frontend and a REST API from a single, self-contained executable.\n  \u2022 Provide cross-platform access via launcher scripts for a Podman container.\n\nCORE TENETS:\n  \u2022 Single Origin: The backend serves the frontend, eliminating all CORS and cross-origin security issues.\n  \u2022 Zero Dependencies: The primary Windows artifact is a single .exe file that requires no external installation or setup.\n  \u2022 Containerization: For non-Windows users, a Podman container provides a consistent, isolated environment.\n  \u2022 Automated & Repeatable Builds: The entire application is built, tested, and packaged via a deterministic CI/CD pipeline (`build-monolith.yml`).\n```\n\n---\n\n## 2. ARCHITECTURE: THE UNIFIED MONOLITH\n\nThe application is a **Unified Monolith**. A single Python executable, built with PyInstaller, contains the complete application. It runs a FastAPI web server that both serves the static Next.js frontend and provides the backend REST API.\n\n```\n+------------------------------------------------------+\n| fortuna-monolith.exe (Single Executable)             |\n|                                                      |\n|  +-------------------------------------------------+ |\n|  | Python Environment                              | |\n|  |                                                 | |\n|  |  +-------------------------------------------+  | |\n|  |  | FastAPI / Uvicorn Server (localhost:8000) |  | |\n|  |  |                                           |  | |\n|  |  |  +------------------+  +----------------+ |  | |\n|  |  |  | API Router       |  | Static Files   | |  | |\n|  |  |  | (/api/*)         |  | (/, /_next/*)  | |  | |\n|  |  |  +------------------+  +----------------+ |  | |\n|  |  |           |                     |         |  | |\n|  |  +-----------|---------------------|---------+  | |\n|  |             |                     |            | |\n|  |  +----------v-----------+  +-------v--------+   | |\n|  |  | OddsEngine (engine.py)|  | Bundled Next.js|   | |\n|  |  +----------------------+  | 'out' directory|   | |\n|  |                            +----------------+   | |\n|  +-------------------------------------------------+ |\n|                                                      |\n+------------------------------------------------------+\n```\n\n---\n\n## 3. BACKEND ENGINE (PYTHON/FASTAPI)\n\n### 3.1 Entry Point & Server Startup (`web_service/backend/main.py`)\n\nThe entry point directly runs the Uvicorn server, loading the FastAPI app instance from `api.py`.\n\n```pseudocode\n// main.py\nPROCEDURE Main_Python_Entry_Point\n  // Path modifications for PyInstaller compatibility\n  IF running in a frozen (PyInstaller) environment:\n    base_path <- sys._MEIPASS\n  ELSE:\n    base_path <- path to project root\n  ADD base_path to sys.path\n\n  // Programmatically launch the FastAPI application\n  CALL uvicorn.run(\n    app=\"web_service.backend.api:app\",\n    host=\"0.0.0.0\",\n    port=8000\n  )\nEND PROCEDURE\n```\n\n### 3.2 Application & Frontend Serving (`web_service/backend/api.py`)\n\nThe `api.py` file is the core of the backend. It defines the FastAPI app, manages the application lifecycle, and includes the critical logic for serving the static frontend.\n\n```pseudocode\n// api.py\n\n// --- Lifespan Management ---\nASYNC FUNCTION lifespan_manager(app: FastAPI):\n  // ON STARTUP:\n  CONFIGURE logging\n  CREATE OddsEngine instance\n  STORE engine in app.state\n  YIELD\n  // ON SHUTDOWN:\n  AWAIT app.state.engine.close() // Gracefully close connections\n\n// --- FastAPI App Initialization ---\napp <- CREATE FastAPI(lifespan=lifespan_manager)\nADD CORS middleware\nADD Rate Limiting middleware\nINCLUDE API router (for /api/* routes)\n\n// --- CRITICAL: Unified Frontend Serving ---\nFUNCTION get_ui_directory():\n  IF running in a frozen (PyInstaller) environment:\n    RETURN path to bundled 'ui' directory (sys._MEIPASS/ui)\n  ELSE:\n    RETURN path to `web_platform/frontend/out`\nEND FUNCTION\n\nUI_DIR <- get_ui_directory()\nVERIFY UI_DIR and index.html exist, otherwise RAISE RuntimeError\n\n// --- SPA Middleware ---\n// All requests that are not for '/api/*' or a known static file type\n// will be served the `index.html` file. This allows the Next.js\n// client-side router to handle all frontend navigation.\napp.add_middleware(SPAMiddleware)\n\n// --- Static File Mount ---\n// This serves the actual .js, .css, and image files from the\n// bundled 'ui' directory.\napp.mount(\"/\", StaticFiles(directory=UI_DIR, html=True), name=\"ui\")\n```\n\n### 3.3 Resilient Fetching Strategy (`web_service/backend/engine.py`)\n\nThe `OddsEngine` is designed for resilience, using a multi-tiered fallback strategy to ensure data is returned even when some sources fail.\n\n```pseudocode\n// engine.py\n\nCLASS OddsEngine:\n  INIT():\n    self.adapters: Dict[str, Adapter]\n    self.health_monitor: AdapterHealthMonitor\n    self.stale_data_cache: StaleDataCache\n    // ... other initializations\n\n  ASYNC FUNCTION fetch_all_odds(date):\n    // Tier 1: Attempt to fetch from healthy adapters\n    healthy_adapters <- self.health_monitor.get_healthy_adapters()\n    live_results <- FETCH_IN_PARALLEL(healthy_adapters)\n\n    IF count(live_results) >= MINIMUM_REQUIRED_SOURCES:\n      MERGE and RETURN live_results\n\n    // Tier 2: Augment with degraded adapters if necessary\n    degraded_adapters <- self.health_monitor.get_degraded_adapters()\n    degraded_results <- FETCH_IN_PARALLEL(degraded_adapters)\n    live_results.extend(degraded_results)\n\n    IF count(live_results) > 0:\n      MERGE, CACHE, and RETURN live_results\n\n    // Tier 3: Fall back to stale data from the last successful run\n    stale_data <- self.stale_data_cache.get(date)\n    IF stale_data IS NOT NULL:\n      LOG \"Using stale data as a last resort.\"\n      RETURN stale_data with a 'stale' freshness flag\n\n    // Final fallback: Return an error response\n    RETURN error_response(\"All live adapters failed and no stale cache was available.\")\n\n```\n---\n\n## 4. FRONTEND INTERFACE (TYPESCRIPT/NEXT.JS)\n\n### 4.1 Configuration (`next.config.mjs`)\n\nThe frontend is a standard Next.js application configured for static export. This means it is pre-built into a set of HTML, CSS, and JS files that can be served by any static web server.\n\n```javascript\n// next.config.mjs\nconst nextConfig = {\n  output: 'export',   // CRITICAL: Generates a static site in the 'out' directory\n  distDir: 'out',\n  images: { unoptimized: true }, // Required for static export\n  trailingSlash: true,\n};\n```\n\n### 4.2 Main Dashboard Component (`src/components/LiveRaceDashboard.tsx`)\n\nWith the unified architecture, the frontend no longer needs a complex IPC mechanism. It behaves like a standard web application, making HTTP requests to the same origin that served it.\n\n```pseudocode\n// LiveRaceDashboard.tsx (Simplified)\nCOMPONENT LiveRaceDashboard:\n  STATE:\n    races: Race[] <- []\n    status: 'loading' | 'success' | 'error' <- 'loading'\n    errorMessage: string <- \"\"\n\n  EFFECT on mount:\n    fetchQualifiedRaces() // Fetch data immediately on component load\n\n  ASYNC FUNCTION fetchQualifiedRaces():\n    TRY:\n      // Make a standard, same-origin API call. No full URL needed.\n      response <- AWAIT fetch(\"/api/races/qualified/trifecta\")\n      IF NOT response.ok:\n        RAISE new Error(`API Error: ${response.statusText}`)\n\n      data <- AWAIT response.json()\n      setRaces(data.races)\n      setStatus('success')\n    CATCH e:\n      setStatus('error')\n      setErrorMessage(e.message)\nEND COMPONENT\n```\n\n---\n\n## 5. DATA MODELS & API SPECIFICATION\n\nThe data models and API endpoints remain largely the same, with the key difference being that they are all served from the `localhost:8000` origin.\n\n```\nENDPOINT GET /api/health\n  Response (200 OK): {\"status\":\"ok\"}\n\nENDPOINT GET /api/races/qualified/trifecta\n  Response (200 OK):\n    {\n      \"qualified_races\": List[Race],\n      \"analysis_metadata\": { ... }\n    }\n```\n\n---\n\n## 6. DEPLOYMENT & AUTOMATION (CI/CD)\n\nThe primary build workflow is `.github/workflows/build-monolith.yml`. It creates the single Windows executable. The `.github/workflows/build-podman.yml` workflow provides a container-based alternative for cross-platform use.\n\n### 6.1 Monolith Build (`build-monolith.yml`)\n\n```pseudocode\n// build-monolith.yml\nWORKFLOW Build_Fortuna_Monolith_EXE:\n  // Phase 1: Build Frontend\n  SETUP Node.js\n  RUN \"npm ci\" and \"npm run build\" in /web_platform/frontend\n  COPY the 'out' directory to a staging area (`frontend_dist`)\n\n  // Phase 2: Build Backend Executable\n  SETUP Python\n  INSTALL Python dependencies from requirements.txt\n  INSTALL PyInstaller\n  CREATE required data/log directories\n\n  // Phase 3: Package with PyInstaller\n  // The spec file (`fortuna-monolith.spec`) is configured to:\n  // 1. Identify `web_service/backend/main.py` as the entry point.\n  // 2. Bundle the `frontend_dist` directory into the .exe at the root 'ui'.\n  // 3. Add application icon and version info.\n  EXECUTE PyInstaller using `fortuna-monolith.spec`\n\n  // Phase 4: Smoke Test\n  START the generated `fortuna-monolith.exe` in the background\n  POLL `http://127.0.0.1:8000/api/health` until it responds with 200 OK or times out\n  IF timeout THEN FAIL build\n  KILL the process\n\n  // Phase 5: Upload Artifact\n  UPLOAD the `fortuna-monolith.exe` as a build artifact\n```\n\n### 6.2 Race Report Generation (`unified-race-report.yml`)\n\nThis workflow runs on a schedule or manually to generate the daily race reports.\n\n```pseudocode\n// unified-race-report.yml\nWORKFLOW Generate_Race_Report:\n  // Phase 1: Setup Environment\n  SETUP Python\n  INSTALL dependencies from requirements.txt\n\n  // Phase 2: Run Reporter Script\n  // The script directly invokes the OddsEngine and AnalyzerEngine\n  // without needing a live web server.\n  EXECUTE `scripts/fortuna_reporter.py`\n\n  // Phase 3: Publish Artifacts\n  // The script generates a comprehensive set of artifacts for observability.\n  UPLOAD the following files:\n    - race-report.html (The primary user-facing report)\n    - qualified_races.json (Data for the HTML report)\n    - raw_race_data.json (Unfiltered data for debugging)\n    - reporter_output.log (Full log of the reporter script)\n    - github_summary.md (For display in the GitHub Actions UI)\n```\n---\n\n## 7. END-TO-END WORKFLOW\n\n### 7.1 Windows User Workflow\n\nThe user downloads and runs a single `.exe` file.\n\n```\nWORKFLOW user_launches_monolith_exe:\n  STEP 1: User executes `fortuna-monolith.exe`.\n  STEP 2: The embedded Python environment starts.\n  STEP 3: The Uvicorn server starts inside the process.\n  STEP 4: The FastAPI application initializes, mounts the bundled 'ui' directory, and opens the API endpoints.\n  STEP 5: The user's default web browser is automatically opened to `http://127.0.0.1:8000`.\n  STEP 6: The browser loads `index.html` from the FastAPI server.\n  STEP 7: The Next.js application hydrates and makes same-origin API calls to `/api/*` to fetch data.\n```\n\n### 7.2 Cross-Platform (Podman) User Workflow\n\nThe user runs a launcher script that manages a Podman container.\n\n```\nWORKFLOW user_launches_podman_script:\n  STEP 1: User executes `launcher.bat` or `./launcher.sh`.\n  STEP 2: The script pulls the latest `ghcr.io/masonj0/fortuna-faucet` image.\n  STEP 3: The script starts a Podman container, mapping port 8000 and volume mounting local `data` and `logs` directories.\n  STEP 4: The container runs the same Python application, which starts the Uvicorn/FastAPI server.\n  STEP 5: The user's default web browser is automatically opened to `http://127.0.0.1:8000`.\n  STEP 6: The workflow proceeds identically to the Windows user workflow from Step 6 onward.\n```\n\n---\n*This concludes the blueprint for the Fortuna Faucet unified monolith architecture.*\n",
    "ROADMAP_APPENDICES.md": "# \ud83d\uddfa\ufe0f Fortuna Faucet - Roadmap & Accomplishments\n\nThis document tracks the strategic evolution of the Fortuna Faucet project.\n\n## Phase 1: Core Engine Development (Complete)\n- **Objective:** Build a robust, scalable data extraction and analysis engine.\n- **Status:** COMPLETE.\n\n## Phase 2: The Golden Path - UX Overhaul (Complete)\n- **Objective:** Transform the developer-centric tool into a seamless, professional-grade Windows application for non-technical users.\n- **Status:** COMPLETE.\n\n## Phase 3: The Turnkey Solution - Professional Release Pipeline (Complete)\n- **Objective:** Eliminate all manual setup steps and create an enterprise-grade, automated build and release system.\n- **Status:** COMPLETE.\n\n### Key Accomplishments & Completed Operations:\n\n1.  **Operation: The Great Housekeeping**\n    - Purified the repository architecture, deprecated legacy codebases and scripts, and established a clean foundation.\n    - Forged a new, programmatic manifest generation system.\n\n2.  **Operation: The Blueprint**\n    - Established the professional directory structure for an enterprise-grade build system.\n    - Implemented the master WiX product definition and the PowerShell build orchestrator.\n\n3.  **Operation: The Assembly Line**\n    - Fully automated the MSI build process with a GitHub Actions CI/CD workflow.\n\n4.  **Operation: The Proving Ground**\n    - Forged a complete suite of automated PowerShell scripts to test and validate the integrity of every installer artifact (install, silent deploy, uninstall).\n\n5.  **Operation: The User's Keys**\n    - Created the final, user-facing toolkit of scripts for easy lifecycle management (install, uninstall, repair).\n\n6.  **Operation: Modernize the Assembly Line**\n    - Performed a surgical upgrade to the CI/CD pipeline to resolve a critical GitHub Actions deprecation, ensuring continued operational readiness.\n\n7.  **Operation: The Forge**\n    - Executed a critical architectural overhaul of the entire release pipeline.\n    - Replaced the fragile, runtime-dependent installer with a robust \"Three-Executable Architecture.\"\n    - The Python backend is now a standalone executable compiled with PyInstaller, and the frontend is a static export, eliminating all runtime dependencies and post-install scripting.\n\n## Phase 4: User Experience & Feature Enhancement (Next Steps)\n- **Objective:** Enhance the core user experience and expand the analytical capabilities of the engine.\n- **Status:** PENDING.\n- **Potential Missions:**\n  - **Operation: The Interpreter:** Implement a user-friendly error-handling system that translates technical errors into simple, actionable advice.\n  - **Data Persistence & Caching:** Implement a local SQLite database to cache race data, improving performance and enabling offline access.\n  - **Operation: The Polisher:** Address technical debt by refactoring backend code to resolve deprecation warnings and align with modern library standards.\n  - **Operation: The Shield:** Improve backend test coverage by adding unit tests for untested data adapters and the Electron main process.\n  - **Operation: The Auditor (Real-Time Verification)**\n    - **Goal:** Implement a 'Last Hour' retrospective dashboard to validate the 'Favorite to Place' strategy.\n    - **Core Logic:**\n      1.  **Snapshot:** Log every 'Qualifier' race prediction to a local DB (SQLite/Redis) with a timestamp and the predicted Favorite.\n      2.  **The Fetcher:** Periodically poll for official results of races that finished in the last 60 minutes.\n      3.  **The Verdict:** Compare the predicted Favorite against the official Finish Order.\n          - *Win:* Did it finish 1st, 2nd, (or 3rd)? -> CASHED.\n          - *Loss:* Did it finish out of the money? -> BURNED.\n      4.  **The 'Tiny Profit' Calc:** Calculate Net Profit based on the standard $2.00 tote unit.\n          - *Formula:* `Net Profit = (Official_Place_Payout - 2.00)`\n          - *Example:* Payout $2.60 -> Profit +$0.60. Payout $0.00 -> Profit -$2.00.\n    - **Data Sources:**\n      - *US Racing:* Scrape `https://www.equibase.com/static/chart/summary/index.html` (Free Summary Charts contain Final Odds & Payoffs).\n      - *UK/Dogs:* Use `The Racing API` or `GBGB` results endpoints.\n    - **UI:** Display a rolling 'Strike Rate' % and 'Net Profit (1H)' ticker.\n",
    "configure_startup.py": "# configure_startup.py\nimport sys\nimport winreg\nfrom pathlib import Path\n\n\nclass StartupManager:\n    \"\"\"Manage Windows startup registry entries for the current user.\"\"\"\n\n    REGISTRY_PATH = r\"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n    APP_NAME = \"FortunaFaucetTray\"\n\n    @classmethod\n    def is_enabled(cls) -> bool:\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_READ)\n            winreg.QueryValueEx(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            return True\n        except FileNotFoundError:\n            return False\n\n    @classmethod\n    def enable(cls):\n        launcher_path = Path(__file__).parent / \"launcher.ps1\"\n        cmd = f'powershell.exe -WindowStyle Hidden -File \"{launcher_path}\"'\n\n        key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n        winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, cmd)\n        winreg.CloseKey(key)\n        print(\"Startup enabled.\")\n\n    @classmethod\n    def disable(cls):\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n            winreg.DeleteValue(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            print(\"Startup disabled.\")\n        except FileNotFoundError:\n            print(\"Already disabled.\")\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"enable\":\n            StartupManager.enable()\n        elif sys.argv[1] == \"disable\":\n            StartupManager.disable()\n        elif sys.argv[1] == \"status\":\n            print(f\"Startup is currently {'enabled' if StartupManager.is_enabled() else 'disabled'}\")\n    else:\n        print(\"Usage: python configure_startup.py [enable|disable|status]\")\n",
    "debug_installer.ps1": "# 1. Get the location of this script\n$currentDir = $PSScriptRoot\n\n# 2. Find all .msi files in this folder\n$msiFiles = Get-ChildItem -Path $currentDir -Filter \"*.msi\"\n\n# 3. Validate we found exactly one MSI\nif ($msiFiles.Count -eq 0) {\n    Write-Host \"\u274c Error: No MSI files found in $currentDir\" -ForegroundColor Red\n    Read-Host \"Press Enter to exit...\"\n    Exit\n}\nif ($msiFiles.Count -gt 1) {\n    Write-Host \"\u274c Error: Multiple MSI files found. I don't know which one to run:\" -ForegroundColor Red\n    $msiFiles | ForEach-Object { Write-Host \" - $($_.Name)\" }\n    Read-Host \"Press Enter to exit...\"\n    Exit\n}\n\n# 4. Set up file paths\n$targetMsi = $msiFiles[0].FullName\n$logFile = Join-Path -Path $currentDir -ChildPath \"install_debug.log\"\n\nWrite-Host \"------------------------------------------------\" -ForegroundColor Cyan\nWrite-Host \"\ud83d\ude80 Target Found: $($msiFiles[0].Name)\" -ForegroundColor Green\nWrite-Host \"\ud83d\udcdd Log File:     $logFile\" -ForegroundColor Yellow\nWrite-Host \"------------------------------------------------\" -ForegroundColor Cyan\n\n# 5. Run MSIEXEC\n# /i   = Install\n# /L*v = Log all information (Verbose)\ntry {\n    Start-Process -FilePath \"msiexec.exe\" -ArgumentList \"/i `\"$targetMsi`\" /L*v `\"$logFile`\"\" -Wait\n    Write-Host \"\u2705 Installer finished.\" -ForegroundColor Green\n}\ncatch {\n    Write-Host \"\u274c Failed to launch msiexec.\" -ForegroundColor Red\n    Write-Error $_\n}\n\n# 6. Pause so you can read the output\nRead-Host \"Press Enter to close this window...\"\n",
    "electron/preload.js": "// electron/preload.js\n// This script runs in a privileged environment with access to Node.js APIs.\n// It's used to securely expose specific functionality to the renderer process (the web UI).\n\nconst { contextBridge, ipcRenderer } = require('electron');\n\n// Expose a safe, limited API to the frontend.\ncontextBridge.exposeInMainWorld('electronAPI', {\n /**\n * Asynchronously fetches the secure API key from the main process.\n * @returns {Promise<string|null>} A promise that resolves with the API key or null if not found.\n */\n getApiKey: () => ipcRenderer.invoke('get-api-key'),\n\n /**\n * Asynchronously generates and saves a new secure API key.\n * @returns {Promise<string>} A promise that resolves with the newly generated API key.\n */\n generateApiKey: () => ipcRenderer.invoke('generate-api-key'),\n\n /**\n * Asynchronously saves a provided API key.\n * @param {string} apiKey - The API key to save.\n * @returns {Promise<{success: boolean}>} A promise that resolves with the result of the save operation.\n */\n saveApiKey: (apiKey) => ipcRenderer.invoke('save-api-key', apiKey),\n\n /**\n * Asynchronously saves Betfair credentials.\n * @param {{username: string, apiKey: string}} credentials - The credentials to save.\n * @returns {Promise<{success: boolean}>} A promise that resolves with the result of the save operation.\n */\n saveBetfairCredentials: (credentials) => ipcRenderer.invoke('save-betfair-credentials', credentials),\n\n /**\n  * Restarts the backend service.\n  */\n restartBackend: () => ipcRenderer.send('restart-backend'),\n\n /**\n  * Stops the backend service.\n  */\n stopBackend: () => ipcRenderer.send('stop-backend'),\n\n /**\n  * Fetches the current status of the backend service.\n  * @returns {Promise<{state: string, logs: string[]}>} A promise that resolves with the backend status.\n  */\n getBackendStatus: () => ipcRenderer.invoke('get-backend-status'),\n\n /**\n  * Subscribes to backend status updates.\n  * @param {function(event, {state: string, logs: string[]})} callback - The function to call with status updates.\n  */\n onBackendStatusUpdate: (callback) => {\n    // Deliberately strip event sender from callback to avoid security risks\n    const subscription = (event, ...args) => callback(...args);\n    ipcRenderer.on('backend-status-update', subscription);\n\n    // Return a function to unsubscribe\n    return () => {\n      ipcRenderer.removeListener('backend-status-update', subscription);\n    };\n  },\n\n  /**\n   * Gets the port the backend API is running on.\n   * @returns {Promise<number>} A promise that resolves with the port number.\n   */\n  getApiPort: () => ipcRenderer.invoke('get-api-port'),\n});\n",
    "electron/resources/.gitkeep": "",
    "fortuna-backend-electron.spec": "# -*- mode: python ; coding: utf-8 -*-\nfrom pathlib import Path\nfrom PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\nblock_cipher = None\nproject_root = Path(SPECPATH).parent\n# FIXED: Target the consolidated backend\nbackend_root = project_root / 'web_service' / 'backend'\n\n# Collect data folders\ndatas = []\nfor folder in ['data', 'json', 'adapters']:\n    source_path = backend_root / folder\n    if source_path.exists():\n        datas.append((str(source_path), folder))\n\n# CRITICAL: Bundle the frontend assets\nfrontend_dist = project_root / 'web_service' / 'frontend' / 'public'\nif frontend_dist.exists():\n    datas.append((str(frontend_dist), 'public'))\n\n# Collect dependencies\nhiddenimports = [\n    'uvicorn', 'fastapi', 'starlette', 'pydantic', 'structlog',\n    'tenacity', 'redis', 'sqlalchemy', 'greenlet', 'win32timezone'\n] + collect_submodules('web_service.backend')\n\na = Analysis(\n    ['web_service/backend/main.py'], # FIXED: Entry point\n    pathex=[str(project_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.zipfiles, a.datas,\n    name='fortuna-backend',\n    debug=False,\n    strip=False,\n    upx=True,\n    console=True, # Keep console for Electron backend debugging\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\n",
    "fortuna-unified.spec": "# -*- mode: python ; coding: utf-8 -*-\nfrom PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\nblock_cipher = None\n\n# Collect data folders\ndatas = [\n    # Python service data\n    ('web_service/backend/data', 'data'),\n    ('web_service/backend/json', 'json'),\n    ('web_service/backend/adapters', 'adapters'),\n    # CRITICAL: Bundle the Next.js static frontend build\n    ('web_platform/frontend/out', 'ui'),\n]\n\n# Collect dependencies\nhiddenimports = [\n    'uvicorn', 'fastapi', 'starlette', 'pydantic', 'structlog',\n    'tenacity', 'redis', 'sqlalchemy', 'greenlet', 'win32timezone'\n] + collect_submodules('web_service.backend')\n\na = Analysis(\n    ['web_service/backend/main.py'],\n    pathex=['.'],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.zipfiles, a.datas,\n    name='fortuna-webservice',\n    debug=False,\n    strip=False,\n    upx=True,\n    console=True,\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n    icon='assets/icon.ico',\n    version='file_version_info.txt'\n)",
    "fortuna_app.py": "import os\nimport socket\nimport subprocess\nimport sys\nimport threading\nimport time\nimport tkinter as tk\nfrom pathlib import Path\nfrom tkinter import messagebox\nfrom tkinter import scrolledtext\nfrom tkinter import ttk\n\nimport psutil\nimport requests\n\n\n# --- Control Panel Tab (from former launcher_gui.py) ---\nclass ControlPanelTab(tk.Frame):\n    def __init__(self, parent, master_app):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self.master_app = master_app\n        self.backend_proc = None\n        self.frontend_proc = None\n        self.backend_unresponsive_count = 0\n        self.frontend_unresponsive_count = 0\n        self.first_launch = not (Path(os.environ[\"USERPROFILE\"]) / \"Desktop\" / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\").exists()\n        self._create_ui()\n        self.monitor_thread = threading.Thread(target=self.monitor_services, daemon=True)\n        self.monitor_thread.start()\n\n    def log_output(self, message):\n        self.log_text.config(state=tk.NORMAL)\n        self.log_text.insert(tk.END, f\"[{time.strftime('%H:%M:%S')}] {message}\\n\")\n        self.log_text.config(state=tk.DISABLED)\n        self.log_text.see(tk.END)\n\n    def smart_start(self):\n        \"\"\"On first launch, run verification, create shortcuts, and then start.\"\"\"\n        if messagebox.askokcancel(\n            \"First-Time Setup\",\n            \"Welcome to Fortuna Faucet!\\n\\nThis first launch will verify your system and create a desktop shortcut for easy access. Proceed?\",\n        ):\n            # Steal and run the logic from the System Tools Tab\n            self.master_app.notebook.select(self.master_app.system_tools_tab)\n            self.master_app.system_tools_tab.run_verification()\n            self.master_app.system_tools_tab.run_create_shortcuts()\n\n            # Once done, revert to a normal start button\n            messagebox.showinfo(\"Setup Complete\", \"Setup is complete! The main services will now start.\")\n            self.launch_btn.config(text=\"\u25b6 START FORTUNA\", bg=\"#00ff88\", command=self.launch_services)\n            self.launch_services()\n\n    def _create_ui(self):\n        title = tk.Label(\n            self,\n            text=\"\ud83d\udc34 System Control Panel\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        )\n        title.pack(pady=20)\n\n        status_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        status_frame.pack(fill=tk.X, padx=40, pady=10)\n\n        tk.Label(\n            status_frame,\n            text=\"Backend Service (API)\",\n            font=(\"Segoe UI\", 10),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        self.backend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg=\"#0f3460\", highlightthickness=0)\n        self.backend_status_canvas.pack(fill=tk.X, pady=(0, 10))\n        self.backend_indicator = self.backend_status_canvas.create_oval(15, 10, 35, 30, fill=\"#ff4444\", outline=\"\")\n        self.backend_text = self.backend_status_canvas.create_text(\n            55, 20, text=\"Stopped\", fill=\"#ffffff\", anchor=\"w\", font=(\"Segoe UI\", 9)\n        )\n\n        tk.Label(\n            status_frame,\n            text=\"Frontend Dashboard (UI)\",\n            font=(\"Segoe UI\", 10),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        self.frontend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg=\"#0f3460\", highlightthickness=0)\n        self.frontend_status_canvas.pack(fill=tk.X)\n        self.frontend_indicator = self.frontend_status_canvas.create_oval(15, 10, 35, 30, fill=\"#ff4444\", outline=\"\")\n        self.frontend_text = self.frontend_status_canvas.create_text(\n            55, 20, text=\"Stopped\", fill=\"#ffffff\", anchor=\"w\", font=(\"Segoe UI\", 9)\n        )\n\n        button_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        button_frame.pack(fill=tk.X, padx=40, pady=20)\n\n        self.launch_btn = tk.Button(\n            button_frame,\n            text=\"\u25b6 START FORTUNA\",\n            font=(\"Segoe UI\", 14, \"bold\"),\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            height=2,\n            relief=tk.FLAT,\n        )\n        if self.first_launch:\n            self.launch_btn.config(\n                text=\"\u25b6 FIRST-TIME START & SETUP\",\n                bg=\"#ff9900\",\n                command=self.smart_start,\n            )\n        else:\n            self.launch_btn.config(command=self.launch_services)\n        self.launch_btn.pack(fill=tk.X, pady=(0, 10))\n\n        self.stop_btn = tk.Button(\n            button_frame,\n            text=\"\u23f9 STOP SERVICES\",\n            font=(\"Segoe UI\", 12),\n            bg=\"#ff4444\",\n            fg=\"#ffffff\",\n            command=self.stop_services,\n            state=tk.DISABLED,\n            height=1,\n            relief=tk.FLAT,\n        )\n        self.stop_btn.pack(fill=tk.X)\n\n        self.log_text = scrolledtext.ScrolledText(self, height=5, bg=\"#000000\", fg=\"#00ff88\", state=tk.DISABLED)\n        self.log_text.pack(pady=10, padx=40, fill=tk.X)\n\n    def check_ports(self, ports=[8000, 3000]):\n        unavailable_ports = []\n        for port in ports:\n            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n                if s.connect_ex((\"127.0.0.1\", port)) == 0:\n                    unavailable_ports.append(port)\n        return unavailable_ports\n\n    def launch_services(self):\n        unavailable = self.check_ports()\n        if unavailable:\n            messagebox.showerror(\n                \"Port Conflict\",\n                f\"Cannot launch. Port(s) {', '.join(map(str, unavailable))} are already in use by another application.\",\n            )\n            return\n\n        self.launch_btn.config(state=tk.DISABLED)\n        self.update_status(\"backend\", \"starting\", \"Launching...\")\n        self.update_status(\"frontend\", \"starting\", \"Launching...\")\n\n        try:\n            venv_python = Path(\".venv/Scripts/python.exe\")\n            self.backend_proc = subprocess.Popen(\n                [\n                    str(venv_python),\n                    \"-m\",\n                    \"uvicorn\",\n                    \"python_service.api:app\",\n                    \"--host\",\n                    \"127.0.0.1\",\n                    \"--port\",\n                    \"8000\",\n                ],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                cwd=Path(__file__).parent,\n                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n            )\n        except Exception as e:\n            self.update_status(\"backend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        try:\n            self.frontend_proc = subprocess.Popen(\n                [\"npm\", \"run\", \"dev\"],\n                shell=True,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                cwd=\"web_platform/frontend\",\n                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n            )\n        except Exception as e:\n            self.update_status(\"frontend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        self.stop_btn.config(state=tk.NORMAL)\n\n    def stop_services(self):\n        self.stop_btn.config(state=tk.DISABLED)\n        for proc_name in [\"backend\", \"frontend\"]:\n            proc = getattr(self, f\"{proc_name}_proc\")\n            if proc and proc.poll() is None:\n                try:\n                    parent = psutil.Process(proc.pid)\n                    for child in parent.children(recursive=True):\n                        child.kill()\n                    parent.kill()\n                except psutil.NoSuchProcess:\n                    pass\n            setattr(self, f\"{proc_name}_proc\", None)\n        self.launch_btn.config(state=tk.NORMAL)\n\n    def restart_service(self, service_name: str):\n        \"\"\"Gracefully stop and restart a single failed service.\"\"\"\n        proc_attr = f\"{service_name}_proc\"\n        proc = getattr(self, proc_attr)\n\n        # Stop the specific process\n        if proc and proc.poll() is None:\n            try:\n                parent = psutil.Process(proc.pid)\n                for child in parent.children(recursive=True):\n                    child.kill()\n                parent.kill()\n            except psutil.NoSuchProcess:\n                pass\n        setattr(self, proc_attr, None)\n\n        # Wait a moment\n        time.sleep(2)\n\n        # Relaunch the specific process\n        self.update_status(service_name, \"starting\", \"Attempting auto-restart...\")\n        try:\n            if service_name == \"backend\":\n                venv_python = Path(\".venv/Scripts/python.exe\")\n                new_proc = subprocess.Popen(\n                    [\n                        str(venv_python),\n                        \"-m\",\n                        \"uvicorn\",\n                        \"python_service.api:app\",\n                        \"--host\",\n                        \"127.0.0.1\",\n                        \"--port\",\n                        \"8000\",\n                    ],\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                    cwd=Path(__file__).parent.parent,\n                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n                )\n            else:  # frontend\n                new_proc = subprocess.Popen(\n                    [\"npm\", \"run\", \"dev\"],\n                    shell=True,\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                    cwd=\"web_platform/frontend\",\n                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n                )\n            setattr(self, proc_attr, new_proc)\n        except Exception as e:\n            self.update_status(service_name, \"error\", f\"Auto-restart failed: {e}\")\n\n    def monitor_services(self):\n        while True:\n            # --- Backend Monitoring ---\n            if self.backend_proc and self.backend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:8000/health\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"backend\", \"ok\", \"Healthy (200 OK)\")\n                        self.backend_unresponsive_count = 0  # Reset counter on success\n                    else:\n                        self.update_status(\"backend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"backend\", \"unresponsive\", \"Unresponsive\")\n                    self.backend_unresponsive_count += 1\n                    if self.backend_unresponsive_count >= 3:  # If unresponsive for 3 cycles (15s)\n                        self.log_output(\"Backend unresponsive. Attempting automatic restart...\")\n                        self.restart_service(\"backend\")\n                        self.backend_unresponsive_count = 0  # Reset after attempt\n            else:\n                self.update_status(\"backend\", \"stopped\", \"Stopped\")\n\n            # --- Frontend Monitoring ---\n            if self.frontend_proc and self.frontend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:3000\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"frontend\", \"ok\", \"Healthy (200 OK)\")\n                        self.frontend_unresponsive_count = 0\n                    else:\n                        self.update_status(\"frontend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"frontend\", \"unresponsive\", \"Unresponsive\")\n                    self.frontend_unresponsive_count += 1\n                    if self.frontend_unresponsive_count >= 3:\n                        self.log_output(\"Frontend unresponsive. Attempting automatic restart...\")\n                        self.restart_service(\"frontend\")\n                        self.frontend_unresponsive_count = 0\n            else:\n                self.update_status(\"frontend\", \"stopped\", \"Stopped\")\n            time.sleep(5)\n\n    def update_status(self, service: str, status: str, message: str):\n        colors = {\n            \"ok\": \"#00ff88\",\n            \"unresponsive\": \"#ffcc00\",\n            \"error\": \"#ff4444\",\n            \"stopped\": \"#ff4444\",\n            \"starting\": \"#0f6cbd\",\n        }\n        canvas = getattr(self, f\"{service}_status_canvas\")\n        indicator = getattr(self, f\"{service}_indicator\")\n        text = getattr(self, f\"{service}_text\")\n\n        canvas.itemconfig(indicator, fill=colors.get(status, \"#404060\"))\n        canvas.itemconfig(text, text=message)\n\n\n# --- Setup Wizard Tab (from former setup_wizard_gui.py) ---\nclass SetupWizardTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self.current_step = 0\n        self.settings = {}\n        self._create_widgets()\n        self.show_step(0)\n\n    def _create_widgets(self):\n        header = tk.Label(\n            self,\n            text=\"\ud83d\udd27 First-Time Setup & Configuration\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        header.pack(pady=20)\n        self.step_label = tk.Label(\n            self,\n            text=\"Step 1 of 4: Generate API Key\",\n            font=(\"Segoe UI\", 11),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        self.step_label.pack(pady=10)\n        self.content_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        self.content_frame.pack(fill=tk.BOTH, expand=True, padx=30, pady=20)\n        button_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        button_frame.pack(fill=tk.X, padx=30, pady=20)\n        self.prev_btn = tk.Button(\n            button_frame,\n            text=\"< Back\",\n            command=self.previous_step,\n            state=tk.DISABLED,\n            bg=\"#404060\",\n            fg=\"#ffffff\",\n            padx=20,\n        )\n        self.prev_btn.pack(side=tk.LEFT)\n        self.next_btn = tk.Button(\n            button_frame,\n            text=\"Next >\",\n            command=self.next_step,\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            font=(\"Segoe UI\", 11, \"bold\"),\n            padx=20,\n        )\n        self.next_btn.pack(side=tk.RIGHT)\n\n    def show_step(self, step_index):\n        self._clear_content()\n        self.current_step = step_index\n        if step_index == 0:\n            self._show_step_1()\n        elif step_index == 1:\n            self._show_step_2()\n        elif step_index == 2:\n            self._show_step_3()\n        elif step_index == 3:\n            self._show_step_4()\n        self.update_buttons()\n\n    def _show_step_1(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83d\udd10 Secure API Key\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        tk.Label(\n            self.content_frame,\n            text=\"A secure API key will be generated and stored.\",\n            wraplength=600,\n            justify=tk.LEFT,\n            bg=\"#1a1a2e\",\n            fg=\"#cccccc\",\n        ).pack(anchor=\"w\", pady=10)\n        # ... Add API key generation logic and display ...\n\n    def _show_step_2(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83c\udfc7 Betfair Exchange (Optional)\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(anchor=\"w\")\n        # ... Add Betfair configuration form ...\n\n    def _show_step_3(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\u2713 Verifying Setup\",\n            font=(\"Segoe UI\", 12, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(anchor=\"w\")\n        # ... Add verification checks logic ...\n\n    def _show_step_4(self):\n        tk.Label(\n            self.content_frame,\n            text=\"\ud83c\udf89 Setup Complete!\",\n            font=(\"Segoe UI\", 14, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(pady=20)\n        self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n\n    def next_step(self):\n        if self.current_step < 3:\n            self.show_step(self.current_step + 1)\n\n    def previous_step(self):\n        if self.current_step > 0:\n            self.show_step(self.current_step - 1)\n\n    def finish_setup(self):\n        messagebox.showinfo(\"Setup Complete\", \"Your configuration has been saved.\")\n\n    def _clear_content(self):\n        for widget in self.content_frame.winfo_children():\n            widget.destroy()\n\n    def update_buttons(self):\n        self.prev_btn.config(state=tk.NORMAL if self.current_step > 0 else tk.DISABLED)\n        if self.current_step == 3:\n            self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n        else:\n            self.next_btn.config(text=\"Next >\", command=self.next_step)\n\n\n# --- System Tools Tab ---\nclass SystemToolsTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg=\"#1a1a2e\")\n        self._create_ui()\n\n    def _create_ui(self):\n        title = tk.Label(\n            self,\n            text=\"\u2699\ufe0f System Tools\",\n            font=(\"Segoe UI\", 16, \"bold\"),\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        )\n        title.pack(pady=20)\n        tk.Button(\n            self,\n            text=\"Create Desktop Shortcuts\",\n            command=self.run_create_shortcuts,\n            font=(\"Segoe UI\", 12),\n        ).pack(pady=10, padx=40, fill=tk.X)\n        tk.Button(\n            self,\n            text=\"Verify Installation\",\n            command=self.run_verification,\n            font=(\"Segoe UI\", 12),\n        ).pack(pady=10, padx=40, fill=tk.X)\n        self.output_box = scrolledtext.ScrolledText(self, height=10, bg=\"#0f3460\", fg=\"#ffffff\", state=tk.DISABLED)\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n    def log_output(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n\n    def run_create_shortcuts(self):\n        self.log_output(\"--- Creating Desktop Shortcut ---\")\n        try:\n            from win32com.client import Dispatch\n\n            desktop = Path(os.environ[\"USERPROFILE\"]) / \"Desktop\"\n            app_path = Path(__file__).resolve()\n            shortcut_path = desktop / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\"\n\n            if shortcut_path.exists():\n                self.log_output(\"\ud83d\udfe1 Shortcut already exists. Overwriting.\")\n\n            shell = Dispatch(\"WScript.Shell\")\n            shortcut = shell.CreateShortCut(str(shortcut_path))\n            shortcut.TargetPath = sys.executable\n            shortcut.Arguments = f'\"{app_path}\"'\n            shortcut.WorkingDirectory = str(app_path.parent)\n\n            ico_path = app_path.parent / \"fortuna.ico\"\n            if ico_path.exists():\n                shortcut.IconLocation = str(ico_path)\n            else:\n                self.log_output(\"\ud83d\udfe1 Icon file not found, using default.\")\n\n            shortcut.save()\n            self.log_output(\"\u2705 Success: Shortcut created on Desktop.\")\n        except ImportError:\n            self.log_output(\"\u274c ERROR: 'pywin32' is not installed. Cannot create shortcuts.\")\n            self.log_output(\"  Please run: pip install pywin32\")\n        except Exception as e:\n            self.log_output(f\"\u274c ERROR: An unexpected error occurred: {e}\")\n\n    def run_verification(self):\n        self.log_output(\"\\n--- Verifying System Setup ---\")\n        verifications = [\n            (\"Python 3.11+\", lambda: sys.version_info >= (3, 11)),\n            (\n                \"Python Virtual Env (.venv)\",\n                lambda: Path(\".venv\").exists() and Path(\".venv/Scripts/python.exe\").exists(),\n            ),\n            (\n                \"Node.js (npm)\",\n                lambda: subprocess.run(\"npm -v\", shell=True, capture_output=True).returncode == 0,\n            ),\n            (\n                \"Frontend Dependencies (node_modules)\",\n                lambda: Path(\"web_platform/frontend/node_modules\").exists(),\n            ),\n        ]\n\n        all_ok = True\n        for name, check in verifications:\n            result = check()\n            self.log_output(f\"- {name}: {'\u2705 OK' if result else '\u274c FAILED'}\")\n            if not result:\n                all_ok = False\n\n        if all_ok:\n            self.log_output(\"\\n\u2705 All checks passed. System is ready.\")\n        else:\n            self.log_output(\"\\n\u274c Some checks failed. Please review the log.\")\n\n\n# --- Main Application Window ---\nclass FortunaApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"\ud83d\udc34 Fortuna Faucet\")\n        self.geometry(\"700x550\")\n        self.configure(bg=\"#1a1a2e\")\n\n        style = ttk.Style()\n        style.theme_use(\"clam\")\n        style.configure(\"TNotebook\", background=\"#1a1a2e\", borderwidth=0)\n        style.configure(\"TNotebook.Tab\", background=\"#404060\", foreground=\"#ffffff\", padding=[10, 5])\n        style.map(\"TNotebook.Tab\", background=[(\"selected\", \"#0f6cbd\")])\n\n        self.notebook = ttk.Notebook(self)\n\n        self.control_panel_tab = ControlPanelTab(self.notebook, self)\n        self.setup_wizard_tab = SetupWizardTab(self.notebook)\n        self.system_tools_tab = SystemToolsTab(self.notebook)\n\n        self.notebook.add(self.control_panel_tab, text=\"Control Panel\")\n        self.notebook.add(self.setup_wizard_tab, text=\"Setup & Config\")\n        self.notebook.add(self.system_tools_tab, text=\"System Tools\")\n\n        self.notebook.pack(expand=True, fill=\"both\", padx=10, pady=10)\n\n    def on_closing(self):\n        if self.control_panel_tab.backend_proc or self.control_panel_tab.frontend_proc:\n            if messagebox.askokcancel(\"Quit\", \"Services are still running. Do you want to stop them and exit?\"):\n                self.control_panel_tab.stop_services()\n                self.destroy()\n        else:\n            self.destroy()\n\n\n# --- NEW: Self-Setup UI and Logic ---\nclass SetupApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - First-Time Setup\")\n        self.geometry(\"700x500\")\n        self.configure(bg=\"#1a1a2e\")\n\n        self.protocol(\"WM_DELETE_WINDOW\", self.quit)\n\n        header_font = tk.font.Font(family=\"Segoe UI\", size=16, weight=\"bold\")\n        body_font = tk.font.Font(family=\"Segoe UI\", size=10)\n        button_font = tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\")\n\n        tk.Label(\n            self,\n            text=\"\ud83d\udce6 Welcome to Fortuna Faucet\",\n            font=header_font,\n            bg=\"#1a1a2e\",\n            fg=\"#00ff88\",\n        ).pack(pady=(20, 10))\n        tk.Label(\n            self,\n            text=\"The necessary dependencies are not installed. Click 'Start Installation' to begin.\",\n            font=body_font,\n            bg=\"#1a1a2e\",\n            fg=\"#ffffff\",\n        ).pack(pady=(0, 20))\n\n        self.install_button = tk.Button(\n            self,\n            text=\"\u25b6\ufe0f Start Installation\",\n            font=button_font,\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            command=self.start_installation,\n            relief=tk.FLAT,\n            padx=20,\n            pady=10,\n        )\n        self.install_button.pack(pady=10)\n\n        self.output_box = scrolledtext.ScrolledText(\n            self,\n            height=15,\n            bg=\"#0f3460\",\n            fg=\"#cccccc\",\n            state=tk.DISABLED,\n            relief=tk.FLAT,\n            bd=0,\n            padx=10,\n            pady=10,\n        )\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n        self.status_label = tk.Label(self, text=\"Waiting to start...\", font=body_font, bg=\"#1a1a2e\", fg=\"#ffffff\")\n        self.status_label.pack(pady=10)\n\n    def log(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n        self.update_idletasks()\n\n    def start_installation(self):\n        self.install_button.config(state=tk.DISABLED, text=\"Installation in progress...\")\n        self.log(\"--- Starting installation ---\")\n        self.status_label.config(text=\"Installing... Please be patient, this may take several minutes.\")\n        threading.Thread(target=self.run_install_commands, daemon=True).start()\n\n    def run_command(self, command):\n        process = subprocess.Popen(\n            command,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n            encoding=\"utf-8\",\n            errors=\"replace\",\n            shell=True,\n        )\n        for line in iter(process.stdout.readline, \"\"):\n            self.log(line.strip())\n        process.wait()\n        return process.returncode\n\n    def run_install_commands(self):\n        commands = [\n            (\n                \"1/3: Creating Python virtual environment...\",\n                f\"{sys.executable} -m venv .venv\",\n            ),\n            (\n                \"2/3: Installing Python dependencies...\",\n                '\"' + str(Path(\".venv/Scripts/python.exe\")) + '\" -m pip install -r requirements.txt',\n            ),\n            (\n                \"3/3: Installing Node.js dependencies...\",\n                \"npm install --prefix web_platform/frontend\",\n            ),\n        ]\n\n        for i, (msg, cmd) in enumerate(commands):\n            self.log(f\"\\\\n--- STEP {msg} ---\")\n            return_code = self.run_command(cmd)\n            if return_code != 0:\n                self.log(f\"\\\\n--- ERROR: Step {i + 1} failed with code {return_code}. ---\")\n                self.status_label.config(\n                    text=\"Installation Failed. Please see log for details.\",\n                    fg=\"#ff4444\",\n                )\n                self.install_button.config(state=tk.NORMAL, text=\"Retry Installation\")\n                return\n\n        self.log(\"\\\\n--- \u2705 INSTALLATION COMPLETE! ---\")\n        self.status_label.config(text=\"Setup successful! You can now launch the application.\", fg=\"#00ff88\")\n        self.install_button.destroy()\n        launch_button = tk.Button(\n            self,\n            text=\"\ud83d\ude80 Launch Fortuna\",\n            font=tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\"),\n            bg=\"#00ff88\",\n            fg=\"#000000\",\n            command=self.launch_app,\n            relief=tk.FLAT,\n            padx=20,\n            pady=10,\n        )\n        launch_button.pack(pady=10)\n\n    def launch_app(self):\n        self.destroy()\n        # Relaunch the script to start the main app\n        subprocess.Popen([sys.executable, __file__])\n\n\n# --- NEW: Main Execution Block ---\nif __name__ == \"__main__\":\n    VENV_PATH = Path(__file__).parent / \".venv\"\n    if not VENV_PATH.exists() or not (VENV_PATH / \"Scripts\" / \"python.exe\").exists():\n        # If the virtual environment doesn't exist, run the setup wizard.\n        setup_app = SetupApp()\n        setup_app.mainloop()\n    else:\n        # Otherwise, run the main application.\n        app = FortunaApp()\n        app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n        app.mainloop()\n",
    "manual_override_tool.py": "import argparse\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Manual Override Tool for Checkmate Data Warehouse.\")\n    parser.add_argument(\"--file\", required=True, help=\"Path to the CSV file for ingestion.\")\n    parser.add_argument(\"--user\", required=True, help=\"The user ID performing the override.\")\n    args = parser.parse_args()\n\n    print(f\"Executing manual override by '{args.user}' for file '{args.file}'...\")\n\n    # 1. Connect to PostgreSQL\n    # engine = create_engine('postgresql://user:password@host:port/database')\n\n    # 2. Read and validate the CSV data\n    # race_df = pd.read_csv(args.file)\n    # ... validation logic ...\n\n    # 3. Add the manual_override_by column\n    # race_df['manual_override_by'] = args.user\n\n    # 4. Insert data into the 'historical_races' table\n    # race_df.to_sql('historical_races', engine, if_exists='append', index=False)\n\n    print(\"Manual override completed successfully.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "podman-compose.yml": "version: '3.8'\n\nservices:\n  fortuna:\n    build: .\n    container_name: fortuna-faucet\n    ports:\n      - \"8000:8000\"\n    environment:\n      - PYTHONUNBUFFERED=1\n      - FORTUNA_MODE=podman\n    volumes:\n      - ./web_service/backend/data:/app/web_service/backend/data\n      - ./web_service/backend/logs:/app/web_service/backend/logs\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 5s\n",
    "requirements-dev.txt": "#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    pip-compile --output-file=requirements-dev.txt requirements-dev.in\n#\naltair==6.0.0\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\nanyio==3.7.1\n    # via\n    #   -r requirements-dev.in\n    #   httpx\nasync-timeout==5.0.1\n    # via redis\nattrs==25.4.0\n    # via\n    #   jsonschema\n    #   referencing\nbackports-asyncio-runner==1.2.0\n    # via pytest-asyncio\nblack==26.1.0\n    # via -r requirements-dev.in\nblinker==1.9.0\n    # via streamlit\nboolean-py==5.0\n    # via license-expression\ncachecontrol[filecache]==0.14.4\n    # via\n    #   cachecontrol\n    #   pip-audit\ncachetools==6.2.5\n    # via streamlit\ncertifi==2026.1.4\n    # via\n    #   httpcore\n    #   httpx\n    #   requests\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.1\n    # via\n    #   black\n    #   streamlit\ncyclonedx-python-lib==11.6.0\n    # via pip-audit\ndefusedxml==0.7.1\n    # via py-serializable\ndistro==1.9.0\n    # via tabula-py\nexceptiongroup==1.3.1\n    # via\n    #   anyio\n    #   pytest\nfakeredis[lua]==2.33.0\n    # via -r requirements-dev.in\nfilelock==3.20.3\n    # via cachecontrol\ngitdb==4.0.12\n    # via gitpython\ngitpython==3.1.46\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\ngreenlet==3.3.1\n    # via playwright\nh11==0.16.0\n    # via httpcore\nhttpcore==1.0.9\n    # via httpx\nhttpx==0.28.1\n    # via respx\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njinja2==3.1.6\n    # via\n    #   altair\n    #   pydeck\njsonschema==4.26.0\n    # via altair\njsonschema-specifications==2025.9.1\n    # via jsonschema\nlicense-expression==30.4.4\n    # via cyclonedx-python-lib\nlupa==2.6\n    # via fakeredis\nmarkdown-it-py==4.0.0\n    # via rich\nmarkupsafe==3.0.3\n    # via jinja2\nmdurl==0.1.2\n    # via markdown-it-py\nmsgpack==1.1.2\n    # via cachecontrol\nmypy-extensions==1.1.0\n    # via black\nnarwhals==2.15.0\n    # via altair\nnumpy==2.2.6\n    # via\n    #   pandas\n    #   pydeck\n    #   streamlit\n    #   tabula-py\npackageurl-python==0.17.6\n    # via cyclonedx-python-lib\npackaging==23.2\n    # via\n    #   -r requirements-dev.in\n    #   altair\n    #   black\n    #   pip-audit\n    #   pip-requirements-parser\n    #   pytest\n    #   streamlit\npandas==2.3.3\n    # via\n    #   streamlit\n    #   tabula-py\npathspec==1.0.3\n    # via black\npillow==12.1.0\n    # via streamlit\npip-api==0.0.34\n    # via pip-audit\npip-audit==2.10.0\n    # via -r requirements-dev.in\npip-requirements-parser==32.0.1\n    # via pip-audit\nplatformdirs==4.5.1\n    # via\n    #   black\n    #   pip-audit\nplaywright==1.57.0\n    # via -r requirements-dev.in\npluggy==1.6.0\n    # via pytest\nprotobuf==6.33.4\n    # via streamlit\npy-serializable==2.1.0\n    # via cyclonedx-python-lib\npyarrow==23.0.0\n    # via streamlit\npydeck==0.9.1\n    # via\n    #   -r requirements-dev.in\n    #   streamlit\npyee==13.0.0\n    # via playwright\npygments==2.19.2\n    # via\n    #   pytest\n    #   rich\npyparsing==3.3.2\n    # via pip-requirements-parser\npytest==9.0.2\n    # via\n    #   -r requirements-dev.in\n    #   pytest-asyncio\n    #   pytest-mock\npytest-asyncio==1.3.0\n    # via -r requirements-dev.in\npytest-mock==3.15.1\n    # via -r requirements-dev.in\npython-dateutil==2.9.0.post0\n    # via pandas\npytokens==0.4.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==7.1.0\n    # via fakeredis\nreferencing==0.37.0\n    # via\n    #   jsonschema\n    #   jsonschema-specifications\nrequests==2.32.5\n    # via\n    #   cachecontrol\n    #   pip-audit\n    #   streamlit\nrespx==0.22.0\n    # via -r requirements-dev.in\nrich==14.3.1\n    # via pip-audit\nrpds-py==0.30.0\n    # via\n    #   jsonschema\n    #   referencing\nsix==1.17.0\n    # via python-dateutil\nsmmap==5.0.2\n    # via gitdb\nsniffio==1.3.1\n    # via anyio\nsortedcontainers==2.4.0\n    # via\n    #   cyclonedx-python-lib\n    #   fakeredis\nstreamlit==1.53.1\n    # via -r requirements-dev.in\ntabula-py==2.10.0\n    # via -r requirements-dev.in\ntenacity==9.1.2\n    # via streamlit\ntoml==0.10.2\n    # via streamlit\ntomli==2.4.0\n    # via\n    #   black\n    #   pip-audit\n    #   pytest\ntomli-w==1.2.0\n    # via pip-audit\ntornado==6.5.4\n    # via streamlit\ntyping-extensions==4.15.0\n    # via\n    #   altair\n    #   black\n    #   cyclonedx-python-lib\n    #   exceptiongroup\n    #   fakeredis\n    #   pyee\n    #   pytest-asyncio\n    #   referencing\n    #   streamlit\ntzdata==2025.3\n    # via pandas\nurllib3==2.6.3\n    # via requests\nwatchdog==6.0.0\n    # via streamlit\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n",
    "scripts/extract_smartfetcher_health.py": "#!/usr/bin/env python3\n\"\"\"\nExtracts SmartFetcher health metrics from logs and adapter stats.\n\"\"\"\n\nimport json\nfrom pathlib import Path\nfrom collections import defaultdict\n\ndef main():\n    health_summary = {\n        \"engines_used\": [],\n        \"adapters_by_engine\": defaultdict(list),\n        \"total_requests\": 0\n    }\n\n    # Extract engines used from the engine_health.log (created by grep in workflow)\n    log_path = Path(\"engine_health.log\")\n    engines = set()\n    if log_path.exists():\n        content = log_path.read_text()\n        for engine_name in [\"playwright\", \"camoufox\", \"httpx\"]:\n            if engine_name in content.lower():\n                engines.add(engine_name)\n    \n    health_summary[\"engines_used\"] = sorted(list(engines))\n\n    # Read adapter stats to populate more info if possible\n    stats_path = Path(\"adapter_stats.json\")\n    if stats_path.exists():\n        try:\n            with open(stats_path) as f:\n                stats = json.load(f)\n            # Future enhancement: extract engine from stats if fortuna_reporter is updated\n        except:\n            pass\n\n    with open(\"smartfetcher_health.json\", \"w\") as f:\n        json.dump(health_summary, f, indent=2, default=list)\n\n    print(\"\u2705 SmartFetcher health summary generated\")\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/fortuna-quick-start.ps1": "<#\n.SYNOPSIS\n    Fortuna Supreme Developer Bootstrapper (v2.0)\n    Aligns with CI/CD 'Champion' workflows for robust local development.\n\n.DESCRIPTION\n    - Auto-detects and kills blocking processes on ports 8000/3000\n    - Validates Python/Node environments\n    - Installs dependencies using fast caching strategies (npm ci)\n    - Launches Backend (FastAPI) and Frontend (Next.js) in parallel\n\n.PARAMETER Clean\n    Removes build artifacts and caches (.next, __pycache__, etc.) before starting.\n\n.PARAMETER Production\n    Builds the frontend for production instead of running in dev mode.\n\n.PARAMETER NoFrontend\n    Launches only the backend API.\n#>\n\nparam(\n    [switch]$SkipChecks,\n    [switch]$NoFrontend,\n    [switch]$Production,\n    [switch]$Clean,\n    [switch]$Help,\n    [string]$PythonExecutable\n)\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Configuration ---\n$PROJECT_ROOT = Resolve-Path \"$PSScriptRoot\\..\"\n$BACKEND_DIR  = Join-Path $PROJECT_ROOT \"web_service\\backend\"\n$FRONTEND_DIR = Join-Path $PROJECT_ROOT \"web_service\\frontend\"\n$PYTHON_CMD   = if ($PythonExecutable) { $PythonExecutable } else { \"py -3.11\" }\n\n# --- Helper Functions ---\nfunction Show-Step($msg) { Write-Host \"`n\ud83d\udd35 $msg\" -ForegroundColor Cyan }\nfunction Show-Success($msg) { Write-Host \"   \u2705 $msg\" -ForegroundColor Green }\nfunction Show-Warn($msg) { Write-Host \"   \u26a0\ufe0f  $msg\" -ForegroundColor Yellow }\nfunction Show-Fail($msg) { Write-Host \"   \u274c $msg\" -ForegroundColor Red; exit 1 }\n\nfunction Clear-BuildCache {\n    Show-Step \"Cleaning build caches (-Clean active)...\"\n    $paths = @(\n        (Join-Path $FRONTEND_DIR \".next\"),\n        (Join-Path $FRONTEND_DIR \"node_modules\\.cache\"),\n        (Join-Path $BACKEND_DIR \"__pycache__\"),\n        (Join-Path $BACKEND_DIR \"*.spec\")\n    )\n    foreach ($p in $paths) {\n        if (Test-Path $p) {\n            Remove-Item -Path $p -Recurse -Force -ErrorAction SilentlyContinue\n            Write-Host \"   Deleted: $p\" -ForegroundColor Gray\n        }\n    }\n    Show-Success \"Cache cleared.\"\n}\n\nfunction Check-Port($port, $name) {\n    $process = Get-NetTCPConnection -LocalPort $port -State Listen -ErrorAction SilentlyContinue | Select-Object -ExpandProperty OwningProcess -Unique\n    if ($process) {\n        Show-Warn \"Port $port ($name) is blocked by PID $process. Killing it...\"\n        Stop-Process -Id $process -Force\n        Show-Success \"Port $port freed.\"\n    }\n}\n\n# --- Main Execution ---\n\nWrite-Host \"`n\ud83d\ude80 FORTUNA SUPREME BOOTSTRAPPER\" -ForegroundColor Magenta\nWrite-Host \"=================================\" -ForegroundColor Gray\n\nif ($Help) { Get-Help $PSCommandPath -Detailed; exit }\nif ($Clean) { Clear-BuildCache }\n\n# 1. Pre-flight Checks\nif (-not $SkipChecks) {\n    Show-Step \"System Health Check\"\n    Check-Port 8000 \"Backend API\"\n    Check-Port 3000 \"Frontend UI\"\n}\n\n# 2. Backend Setup\nShow-Step \"Preparing Backend (Python)...\"\nif (-not (Test-Path $BACKEND_DIR)) { Show-Fail \"Backend directory not found at: $BACKEND_DIR\" }\n\n# Check for Python\ntry {\n    & $PYTHON_CMD --version\n    Show-Success \"Python executable found.\"\n} catch {\n    Show-Fail \"Python not found in PATH or specified executable is invalid.\"\n}\n\n# Upgrade Pip & Wheel\nWrite-Host \"   Upgrading pip/wheel...\" -NoNewline\n& $PYTHON_CMD -m pip install --upgrade pip wheel --quiet\nWrite-Host \" Done.\" -ForegroundColor Green\n\n# Verify Critical Imports\nWrite-Host \"   Verifying dependencies...\" -NoNewline\n$testImport = & $PYTHON_CMD -c \"import fastapi, uvicorn, structlog; print('OK')\" 2>$null\nif ($testImport -match \"OK\") {\n    Write-Host \" OK (Skipping install)\" -ForegroundColor Green\n} else {\n    Write-Host \" Missing.\" -ForegroundColor Yellow\n    Show-Warn \"Installing requirements from requirements.txt...\"\n    Push-Location $BACKEND_DIR\n    & $PYTHON_CMD -m pip install -r requirements.txt\n    Pop-Location\n}\n\n# 3. Frontend Setup\nif (-not $NoFrontend) {\n    Show-Step \"Preparing Frontend (Node.js)...\"\n    if (-not (Test-Path $FRONTEND_DIR)) { Show-Fail \"Frontend directory not found at: $FRONTEND_DIR\" }\n\n    Push-Location $FRONTEND_DIR\n\n    # Smart Install (npm ci vs install)\n    if (Test-Path \"node_modules\") {\n        Show-Success \"Node modules present.\"\n    } else {\n        Show-Warn \"Installing dependencies (npm ci)...\"\n        npm ci --silent\n    }\n\n    # Production Build Logic\n    if ($Production) {\n        Show-Step \"Building for Production...\"\n        npm run build\n        Show-Success \"Production build complete.\"\n    }\n\n    Pop-Location\n}\n\n# 4. Launch Sequence\nShow-Step \"Launching Services...\"\n\n# In CI, we need to use Start-Job to get process output and add a wait\n# loop to ensure the service is ready before tests run.\nif ($env:CI) {\n    Show-Warn \"CI environment detected. Using Start-Job for backend...\"\n    $job = Start-Job -ScriptBlock {\n        # This script block runs in a separate process\n        param($path, $cmd)\n        Set-Location $path\n        & $cmd -m uvicorn main:app --port 8000 --host 0.0.0.0\n    } -ArgumentList $BACKEND_DIR, $PYTHON_CMD\n\n    Show-Success \"Backend job started (Job ID: $($job.Id))\"\n\n    # Wait for the backend to become healthy (up to 30 seconds)\n    $healthCheckUrl = \"http://localhost:8000/health\"\n    Write-Host \"   Pinging backend health endpoint ($healthCheckUrl)...\" -NoNewline\n    $timeout = 30\n    $start = Get-Date\n    $healthy = $false\n    while ((Get-Date) -lt $start.AddSeconds($timeout)) {\n        try {\n            $response = Invoke-WebRequest -Uri $healthCheckUrl -UseBasicParsing -TimeoutSec 2\n            if ($response.StatusCode -eq 200) {\n                Write-Host \" OK\" -ForegroundColor Green\n                Show-Success \"Backend is healthy and responding.\"\n                $healthy = $true\n                break\n            }\n        } catch {\n            # Catch exceptions for connection refused, etc.\n        }\n        Start-Sleep -Seconds 1\n        Write-Host \".\" -NoNewline\n    }\n\n    if (-not $healthy) {\n        Write-Host \" FAILED\" -ForegroundColor Red\n        Show-Fail \"Backend did not start within the $timeout-second timeout.\"\n        Receive-Job $job # Display any output from the failed job\n        Stop-Job $job\n        exit 1\n    }\n\n} else {\n    # -- LOCAL DEVELOPMENT (Existing Logic) --\n    $backendScript = \"cd `\"$BACKEND_DIR`\"; & $PYTHON_CMD -m uvicorn main:app --reload --port 8000\"\n    Start-Process pwsh -ArgumentList \"-NoExit\", \"-Command\", $backendScript -WindowStyle Normal\n    Show-Success \"Backend launched on Port 8000\"\n}\n\n# Launch Frontend (No changes needed here for now)\nif (-not $NoFrontend) {\n    if ($env:CI) {\n        # In CI, we would typically build and serve statically, but for this\n        # script's purpose, we'll assume the backend handles the UI\n        Show-Warn \"Frontend launch skipped in CI mode for this script.\"\n    } else {\n        $cmd = if ($Production) { \"start\" } else { \"dev\" }\n        $frontendScript = \"cd `\"$FRONTEND_DIR`\"; npm run $cmd\"\n        Start-Process pwsh -ArgumentList \"-NoExit\", \"-Command\", $frontendScript -WindowStyle Normal\n        Show-Success \"Frontend launched on Port 3000 ($cmd mode)\"\n    }\n}\n\n# Keep script running if interactive, otherwise exit for CI\nif ($env:CI) {\n    Write-Host \"`n\u2728 CI run complete. Exiting.\" -ForegroundColor Cyan\n} else {\n    Write-Host \"`n\u2728 Fortuna is running! Press Ctrl+C in the popup windows to stop.\" -ForegroundColor Cyan\n}\n",
    "scripts/get_api_key.py": "# scripts/get_api_key.py\nimport os\nimport sys\n\n# This is a workaround to ensure the script can find the python_service module,\n# especially when run from the packaged Electron app.\n# It assumes this script is in `resources/app/scripts` and the service is in `resources/app/python_service`.\ntry:\n    # Get the directory of the current script.\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    # Go up one level to the `app` directory and add `python_service` to the path.\n    project_root = os.path.dirname(script_dir)\n    sys.path.append(project_root)\n    from python_service.credentials_manager import SecureCredentialsManager\nexcept ImportError as e:\n    # If the import fails, write the error to stderr and exit.\n    # This helps in debugging path issues in the production environment.\n    print(\n        f\"Error: Failed to import SecureCredentialsManager. Details: {e}\",\n        file=sys.stderr,\n    )\n    sys.exit(1)\n\n\ndef retrieve_and_print_key():\n    \"\"\"\n    Retrieves the API key using the SecureCredentialsManager and prints it to stdout.\n    If the key is not found, it prints an empty string.\n    If an error occurs, it prints the error to stderr.\n    \"\"\"\n    try:\n        api_key = SecureCredentialsManager.get_api_key()\n        if api_key:\n            print(api_key, end=\"\")  # Print the key directly to stdout\n        else:\n            print(\"\", end=\"\")  # Print empty string if no key is found\n    except Exception as e:\n        print(f\"An error occurred while retrieving the API key: {e}\", file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    retrieve_and_print_key()\n",
    "scripts/realtime-race-monitor.ps1": "<#\n.SYNOPSIS\n    Fortuna Real-Time Race Monitor (v1.0)\n    Builds, launches, and queries the backend service to provide live racecard comparisons.\n#>\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Configuration ---\n$PYTHON_VERSION = \"3.11\"\n$BACKEND_DIR    = \"web_service/backend\"\n$SPEC_FILE      = \"fortuna-unified.spec\"\n$SERVICE_PORT   = 8102\n$API_KEY        = \"a_secure_test_api_key_that_is_long_enough\" # Mock key for local execution\n\n# --- Helper Functions ---\nfunction Show-Step($msg) { Write-Host \"`n\ud83d\ude80 $msg\" -ForegroundColor Cyan }\nfunction Show-Success($msg) { Write-Host \"   \u2705 $msg\" -ForegroundColor Green }\nfunction Show-Warn($msg) { Write-Host \"   \u26a0\ufe0f  $msg\" -ForegroundColor Yellow }\nfunction Show-Fail($msg) { Write-Host \"   \u274c $msg\" -ForegroundColor Red; exit 1 }\n\n# --- Main Execution ---\ntry {\n    # 1. Environment Setup & Dependency Installation\n    Show-Step \"Preparing environment...\"\n    try {\n        $pyVer = & python --version 2>&1\n        if ($pyVer -notmatch $PYTHON_VERSION) {\n            Show-Warn \"Python version mismatch. Expected $($PYTHON_VERSION), found $($pyVer).\"\n        }\n        Show-Success \"Found Python: $pyVer\"\n    } catch {\n        Show-Fail \"Python not found. Please ensure Python $($PYTHON_VERSION) is in your PATH.\"\n    }\n\n    Show-Step \"Installing dependencies...\"\n    try {\n        python -m pip install --upgrade pip --quiet\n        pip install -r \"$($BACKEND_DIR)/requirements.txt\"\n        pip install pyinstaller==6.6.0\n        Show-Success \"All Python dependencies are installed.\"\n    } catch {\n        Show-Fail \"Failed to install dependencies. Check logs for details.\"\n    }\n\n\n    # 2. Build the Backend Executable\n    Show-Step \"Building backend executable with PyInstaller...\"\n\n    # Clean previous builds\n    if (Test-Path \"dist\") { Remove-Item -Recurse -Force \"dist\" }\n    if (Test-Path \"build\") { Remove-Item -Recurse -Force \"build\" }\n\n    # PyInstaller requires these directories to exist at build time\n    New-Item -ItemType Directory -Path \"$($BACKEND_DIR)/data\", \"$($BACKEND_DIR)/json\", \"$($BACKEND_DIR)/logs\" -Force | Out-Null\n\n    try {\n        pyinstaller --noconfirm --clean $SPEC_FILE\n        Show-Success \"Backend executable built successfully.\"\n    } catch {\n        Show-Fail \"PyInstaller build failed. See output for details.\"\n    }\n\n    # 3. Launch the Backend Service\n    Show-Step \"Launching backend service...\"\n    $exePath = Resolve-Path \"dist/fortuna-webservice/fortuna-webservice.exe\"\n    if (-not (Test-Path $exePath)) {\n        Show-Fail \"Could not find the built executable at $($exePath).\"\n    }\n\n    # The executable needs its runtime directories in its own folder\n    $exeDir = Split-Path $exePath -Parent\n    New-Item -ItemType Directory -Path \"$($exeDir)/data\", \"$($exeDir)/json\", \"$($exeDir)/logs\" -Force | Out-Null\n    Show-Success \"Created runtime directories in $($exeDir).\"\n\n    # Start the process in the background\n    $process = Start-Process -FilePath $exePath -WindowStyle Hidden -PassThru\n    $Global:BackendProcessId = $process.Id # Store PID for cleanup\n    Show-Success \"Backend service is starting in the background (PID: $($Global:BackendProcessId)).\"\n\n\n    # 4. Health Check & API Query\n    Show-Step \"Waiting for service to become healthy...\"\n    $healthUrl = \"http://localhost:$($SERVICE_PORT)/health\"\n    $maxRetries = 20\n    $retryDelay = 3 # seconds\n\n    for ($i = 0; $i -lt $maxRetries; $i++) {\n        try {\n            $response = Invoke-WebRequest -Uri $healthUrl -UseBasicParsing\n            if ($response.StatusCode -eq 200) {\n                Show-Success \"Service is healthy and responding.\"\n                break\n            }\n        } catch {\n            Write-Host \"   ... waiting ($($i+1)/$($maxRetries))\"\n            Start-Sleep -Seconds $retryDelay\n        }\n        if ($i -eq $maxRetries - 1) {\n            Show-Fail \"Service failed to start within the timeout period.\"\n        }\n    }\n\n    Show-Step \"Querying API for live race data...\"\n    $racesUrl = \"http://localhost:$($SERVICE_PORT)/api/races\"\n    $headers = @{ \"X-API-Key\" = $API_KEY }\n    try {\n        $apiResponse = Invoke-RestMethod -Uri $racesUrl -Headers $headers -Method Get\n        Show-Success \"Successfully fetched data for $($apiResponse.races.Count) races.\"\n    } catch {\n        Show-Fail \"Failed to query the API. Error: $($_.Exception.Message)\"\n    }\n\n\n    # 5. Process and Format Data\n    Show-Step \"Formatting race comparison...\"\n    $now = [datetime]::UtcNow\n    $upcomingRaces = $apiResponse.races | Where-Object { [datetime]$_.startTime -gt $now } | Sort-Object startTime | Select-Object -First 3\n\n    $output = @()\n    $output += \"--- Fortuna Real-Time Race Monitor ---\"\n    $output += \"Generated: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss UTC')\"\n    $output += \"========================================\"\n\n    foreach ($race in $upcomingRaces) {\n        $raceTime = [datetime]$race.startTime\n        $timeToPost = New-TimeSpan -Start $now -End $raceTime\n        $output += \"\"\n        $output += \"$($race.venue) - Race $($race.race_number) ($($raceTime.ToLocalTime().ToString('h:mm tt')))\"\n        $output += \"Starts in: $($timeToPost.Minutes)m $($timeToPost.Seconds)s\"\n        $output += \"----------------------------------------\"\n        $output += \"{0,-25} {1,-15} {2,-15}\" -f \"Runner\", \"Best Odds\", \"Source\"\n        $output += \"{0,-25} {1,-15} {2,-15}\" -f \"-----\", \"---------\", \"------\"\n\n        foreach ($runner in $race.runners) {\n            $bestOdds = $null\n            $bestSource = \"N/A\"\n            if ($runner.odds) {\n                $oddsValues = $runner.odds.psobject.Properties | ForEach-Object { $_.Value }\n                if($oddsValues) {\n                    $best = $oddsValues | Sort-Object win -Descending | Select-Object -First 1\n                    if($best -and $best.win){\n                        $bestOdds = $best.win\n                        $bestSource = $best.source\n                    }\n                }\n            }\n            $output += \"{0,-25} {1,-15} {2,-15}\" -f $runner.name, $bestOdds, $bestSource\n        }\n    }\n\n    $output += \"========================================\"\n\n    # Display the formatted output in the console\n    $output | Out-Host\n\n} finally {\n    # 6. Cleanup\n    Show-Step \"Cleaning up...\"\n    if ($Global:BackendProcessId) {\n        try {\n            Stop-Process -Id $Global:BackendProcessId -Force\n            Show-Success \"Backend service (PID: $($Global:BackendProcessId)) stopped.\"\n        } catch {\n            Show-Warn \"Could not stop backend service (PID: $($Global:BackendProcessId)). It may have already exited.\"\n        }\n    } else {\n        Show-Success \"No backend process to stop.\"\n    }\n}\n",
    "scripts/validate_output.py": "#!/usr/bin/env python3\n\"\"\"Validate pipeline output files.\"\"\"\n\nimport json\nimport sys\nfrom pathlib import Path\n\n\ndef validate_races_file(filepath: Path) -> tuple[bool, list[str]]:\n    \"\"\"Validate a races JSON file.\"\"\"\n    errors = []\n\n    try:\n        with open(filepath) as f:\n            data = json.load(f)\n    except json.JSONDecodeError as e:\n        return False, [f\"Invalid JSON: {e}\"]\n    except FileNotFoundError:\n        return False, [f\"File not found: {filepath}\"]\n\n    if \"races\" not in data:\n        errors.append(\"Missing 'races' field\")\n        return False, errors\n\n    races = data[\"races\"]\n    if not isinstance(races, list):\n        errors.append(\"'races' should be an array\")\n        return False, errors\n\n    required_fields = [\"id\", \"venue\", \"race_number\", \"runners\"]\n\n    for i, race in enumerate(races[:10]):  # Check first 10\n        for field in required_fields:\n            if field not in race:\n                errors.append(f\"Race {i}: missing '{field}'\")\n\n    return len(errors) == 0, errors\n\n\ndef main():\n    print(\"=\" * 60)\n    print(\"OUTPUT VALIDATION\")\n    print(\"=\" * 60)\n\n    files = [\n        (\"qualified_races.json\", True),\n        (\"raw_race_data.json\", False),\n    ]\n\n    all_valid = True\n\n    for filename, required in files:\n        filepath = Path(filename)\n        print(f\"\\n\u2192 {filename}\")\n\n        if not filepath.exists():\n            if required:\n                print(f\"  \u274c Required file not found\")\n                all_valid = False\n            else:\n                print(f\"  \u26a0\ufe0f Optional file not found\")\n            continue\n\n        valid, errors = validate_races_file(filepath)\n\n        if valid:\n            with open(filepath) as f:\n                data = json.load(f)\n            race_count = len(data.get(\"races\", []))\n            print(f\"  \u2705 Valid ({race_count} races)\")\n\n            # Anomaly Gating\n            if filename == \"qualified_races.json\":\n                anomaly_path = Path(\"anomaly_history.json\")\n                if anomaly_path.exists():\n                    try:\n                        history = json.loads(anomaly_path.read_text())\n                        # Very simple check: if current count is < 20% of median, flag it\n                        counts = [h.get('race_count', 0) for h in history if 'race_count' in h]\n                        if counts:\n                            import statistics\n                            median = statistics.median(counts)\n                            if race_count < (median * 0.2) and median > 5:\n                                print(f\"  \u26a0\ufe0f ANOMALY DETECTED: Race count ({race_count}) is significantly lower than median ({median:.1f})\")\n                                # We don't fail the job, but we could if we wanted strict gating\n                    except:\n                        pass\n        else:\n            print(f\"  \u274c Invalid\")\n            for err in errors[:5]:\n                print(f\"     - {err}\")\n            all_valid = False\n\n    print(\"\\n\" + \"=\" * 60)\n    if all_valid:\n        print(\"\u2705 All validations passed\")\n        return 0\n    else:\n        print(\"\u274c Validation failed\")\n        return 1\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n",
    "start_podman.bat": "@echo off\nREM ============================================================\nREM Fortuna Faucet - Podman Launcher for Windows\nREM A simple, friendly way to start your racing analysis engine\nREM ============================================================\n\nsetlocal enabledelayedexpansion\n\nREM Colors and styling\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83d\udc34  FORTUNA FAUCET LAUNCHER (Podman) \ud83d\udc34         \u2551\necho \u2551          Racing Strategy Analysis Engine                  \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM ============================================================\nREM STEP 1: Check if Podman is installed\nREM ============================================================\necho [1/5] Checking for Podman installation...\npodman --version >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Podman is not installed or not in PATH\n    echo.\n    echo To use Fortuna, you need Podman Desktop:\n    echo https://podman-desktop.io/\n    echo.\n    echo After installing Podman, restart your computer and try again.\n    echo.\n    pause\n    exit /b 1\n)\n\nfor /f \"tokens=*\" %%i in ('podman --version') do set PODMAN_VERSION=%%i\necho \u2713 Found: %PODMAN_VERSION%\necho.\n\nREM ============================================================\nREM STEP 2: Check if Podman machine is running\nREM ============================================================\necho [2/5] Checking if Podman machine is running...\npodman ps >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Podman machine is not running\n    echo.\n    echo Please:\n    echo 1. Open \"Podman Desktop\" from your Start Menu\n    echo 2. Make sure your Podman machine is started\n    echo 3. Then run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\necho \u2713 Podman machine is running\necho.\n\nREM ============================================================\nREM STEP 3: Pull latest image\nREM ============================================================\necho [3/5] Pulling latest Fortuna image from Docker Hub...\necho (This may take a minute on first run)\necho.\npodman pull docker.io/masonj0/fortuna-faucet:latest\nif errorlevel 1 (\n    echo.\n    echo \u26a0 Warning: Could not pull from Docker Hub\n    echo Checking for local image...\n    podman image inspect masonj0/fortuna-faucet:latest >nul 2>&1\n    if errorlevel 1 (\n        echo \u2717 ERROR: No local image found\n        echo Please check your internet connection and try again.\n        echo.\n        pause\n        exit /b 1\n    )\n    echo \u2713 Using existing local image\n)\necho \u2713 Image ready\necho.\n\nREM ============================================================\nREM STEP 4: Start container\nREM ============================================================\necho [4/5] Starting Fortuna container...\necho.\n\nREM Stop any existing container (ignore errors)\npodman stop fortuna-faucet >nul 2>&1\npodman rm fortuna-faucet >nul 2>&1\n\nREM Create data directories if they don't exist\nif not exist \"data\" mkdir data\nif not exist \"logs\" mkdir logs\n\nREM Start container with proper quoting for paths with spaces\npodman run -d ^\n  --name fortuna-faucet ^\n  -p 8000:8000 ^\n  -v \"%cd%\\data:/app/web_service/backend/data\" ^\n  -v \"%cd%\\logs:/app/web_service/backend/logs\" ^\n  docker.io/masonj0/fortuna-faucet:latest\n\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Failed to start container\n    echo.\n    echo Try these troubleshooting steps:\n    echo 1. Open Podman Desktop\n    echo 2. Make sure your Podman machine is running\n    echo 3. Open Command Prompt and run: podman ps\n    echo    (This tests if Podman is working)\n    echo 4. Run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Container started successfully\necho.\n\nREM ============================================================\nREM STEP 5: Wait and verify startup\nREM ============================================================\necho [5/5] Waiting for application to start...\ntimeout /t 3 /nobreak\n\nREM Check if container is still running\npodman inspect fortuna-faucet >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Container exited unexpectedly\n    echo.\n    echo Showing container logs for debugging:\n    echo.\n    podman logs fortuna-faucet\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Application is ready!\necho.\n\nREM ============================================================\nREM SUCCESS - Open browser and show logs\nREM ============================================================\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83c\udf89  FORTUNA IS RUNNING! (Podman) \ud83c\udf89           \u2551\necho \u2551                                                            \u2551\necho \u2551  Your racing analysis engine is ready at:                \u2551\necho \u2551                                                            \u2551\necho \u2551          http://localhost:8000                            \u2551\necho \u2551                                                            \u2551\necho \u2551  Opening browser now...                                   \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM Open browser\nstart http://localhost:8000\n\nREM Small delay to let browser open\ntimeout /t 2 /nobreak\n\nREM Show logs\necho.\necho \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\necho \u2502 Live Application Logs (Ctrl+C to stop)                    \u2502\necho \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\necho.\n\npodman logs -f fortuna-faucet\n\nREM Cleanup on exit\necho.\necho Stopping Fortuna...\npodman stop fortuna-faucet >nul 2>&1\necho \u2713 Fortuna stopped\n\nexit /b 0\n",
    "tests/__init__.py": "# This file makes the 'tests' directory a package.\n",
    "tests/adapters/test_timeform_adapter_modernized.py": "# Modernized test resurrected from attic/legacy_tests_pre_triage/adapters/test_timeform_adapter.py\nfrom decimal import Decimal\nfrom unittest.mock import MagicMock\n\nimport pytest\n\nfrom python_service.adapters.timeform_adapter import TimeformAdapter\n\n\n@pytest.fixture\ndef timeform_adapter():\n    mock_config = MagicMock()\n    return TimeformAdapter(config=mock_config)\n\n\ndef read_fixture(file_path):\n    with open(file_path, \"r\") as f:\n        return f.read()\n\n\n@pytest.mark.asyncio\nasync def test_timeform_adapter_parses_html_correctly(timeform_adapter):\n    \"\"\"Verify adapter correctly parses a known HTML fixture.\"\"\"\n    mock_html = read_fixture(\"tests/fixtures/timeform_modern_sample.html\")\n\n    # Directly test the parsing of runners from the correct HTML structure\n    from selectolax.parser import HTMLParser\n\n    parser = HTMLParser(mock_html)\n    runners = [timeform_adapter._parse_runner(row) for row in parser.css(\"div.rp-horseTable_mainRow\")]\n\n    assert len(runners) == 3, \"Should parse three runners\"\n\n    braveheart = next((r for r in runners if r.name == \"Braveheart\"), None)\n    assert braveheart is not None\n    assert braveheart.odds[\"Timeform\"].win == Decimal(\"3.5\")\n\n    steady_eddy = next((r for r in runners if r.name == \"Steady Eddy\"), None)\n    assert steady_eddy is not None\n    assert steady_eddy.odds[\"Timeform\"].win == Decimal(\"2.0\")\n",
    "tests/fixtures/timeform_legacy_sample.html": "<!DOCTYPE html><html><body><div class='race-card'><div class='runner'><span class='runner-name'>Braveheart</span><span class='runner-odds'>5/2</span></div><div class='runner'><span class='runner-name'>Speedster</span><span class='runner-odds'>10/1</span></div><div class='runner'><span class='runner-name'>Steady Eddy</span><span class='runner-odds'>EVENS</span></div></div></body></html>",
    "tests/test_api/test_endpoints.py": "import pytest\nfrom fastapi.testclient import TestClient\n\nfrom python_service.api import app\n\nclient = TestClient(app)\n\n\n@pytest.mark.asyncio\nasync def test_health_check(client):\n    \"\"\"Tests the unauthenticated /health endpoint.\"\"\"\n    response = await client.get(\"/health\")\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"healthy\"\n",
    "tests/test_models.py": "# Test suite for Pydantic models, resurrected from attic/legacy_tests_pre_triage/checkmate_v7/test_models.py\nimport datetime\n\nimport pytest\nfrom pydantic import ValidationError\n\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\n\ndef test_runner_model_creation():\n    \"\"\"Tests basic successful creation of the Runner model.\"\"\"\n    from datetime import datetime\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds_data = {\"TestOdds\": OddsData(win=Decimal(\"6.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    runner = Runner(number=5, name=\"Test Horse\", odds=odds_data, scratched=False)\n    assert runner.number == 5\n    assert runner.name == \"Test Horse\"\n    assert not runner.scratched\n\n\ndef test_race_model_with_valid_runners():\n    \"\"\"Tests basic successful creation of the Race model.\"\"\"\n    from datetime import datetime\n    from decimal import Decimal\n\n    from python_service.models import OddsData\n\n    odds1 = {\"TestOdds\": OddsData(win=Decimal(\"3.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    odds2 = {\"TestOdds\": OddsData(win=Decimal(\"4.0\"), source=\"TestOdds\", last_updated=datetime.now())}\n    runner1 = Runner(number=1, name=\"A\", odds=odds1, scratched=False)\n    runner2 = Runner(number=2, name=\"B\", odds=odds2, scratched=False)\n    race = Race(\n        id=\"test-race-1\",\n        venue=\"TEST\",\n        race_number=1,\n        start_time=datetime.now(),\n        runners=[runner1, runner2],\n        source=\"test\",\n    )\n    assert race.venue == \"TEST\"\n    assert len(race.runners) == 2\n\n\ndef test_model_validation_fails_on_missing_required_field():\n    \"\"\"Ensures Pydantic's validation fires for missing required fields.\"\"\"\n    with pytest.raises(ValidationError):\n        # 'name' is a required field for a Runner\n        Runner(number=3, odds=\"3/1\", scratched=False)\n\n    with pytest.raises(ValidationError):\n        # 'venue' is a required field for a Race\n        Race(\n            id=\"test-race-2\",\n            race_number=2,\n            start_time=datetime.datetime.now(),\n            runners=[],\n            source=\"test\",\n        )\n",
    "verify_dashboard.py": "\nfrom playwright.sync_api import sync_playwright\n\ndef verify_dashboard(page):\n    \"\"\"\n    Navigates to the dashboard and takes a screenshot.\n    \"\"\"\n    page.goto(\"http://localhost:3000\")\n    page.wait_for_selector(\"text=Fortuna Faucet\")\n    page.screenshot(path=\"verification.png\")\n\nif __name__ == \"__main__\":\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=True)\n        page = browser.new_page()\n        try:\n            verify_dashboard(page)\n        finally:\n            browser.close()\n",
    "web_service/backend/adapters/at_the_races_adapter.py": "# python_service/adapters/at_the_races_adapter.py\n\"\"\"Adapter for attheraces.com.\"\"\"\n\nimport asyncio\nimport re\nfrom datetime import datetime\nfrom typing import Any, List, Optional\n\nfrom selectolax.parser import HTMLParser, Node\n\nfrom ..models import Race, Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text, normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .constants import MAX_VALID_ODDS\nfrom .mixins import BrowserHeadersMixin, DebugMixin\nfrom .utils.odds_validator import create_odds_data\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\n\n\nclass AtTheRacesAdapter(BrowserHeadersMixin, DebugMixin, BaseAdapterV3):\n    \"\"\"\n    Adapter for attheraces.com, migrated to BaseAdapterV3.\n\n    Uses simple HTTP requests as the site doesn't require JavaScript.\n    Standardized on selectolax for performance.\n    \"\"\"\n\n    SOURCE_NAME = \"AtTheRaces\"\n    BASE_URL = \"https://www.attheraces.com\"\n\n    # Robust selector strategies with fallbacks\n    SELECTORS = {\n        \"race_links\": [\n            'a[href^=\"/racecard/\"]',\n            'a[href*=\"/racecard/\"]',\n            '.racecard-link',\n            'a.atr-racecard-link',\n            '.meeting-race a',\n            'a[href*=\"/racecards/\"]', # sometimes index links show up\n        ],\n        \"details_container\": [\n            \"atr-racecard-race-header .container\",\n            \".racecard-header .container\",\n            \".racecard-header\",\n            \"header.race-header\",\n        ],\n        \"track_name\": [\"h1 a\", \"h1\", \".track-name\", \".venue-name\"],\n        \"race_time\": [\"h1 span\", \".race-time\", \".time\"],\n        \"runners\": [\"atr-horse-in-racecard\", \".horse-in-racecard\", \".runner-row\", \".horse-row\"],\n    }\n\n    def __init__(self, config=None):\n        super().__init__(\n            source_name=self.SOURCE_NAME,\n            base_url=self.BASE_URL,\n            config=config\n        )\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        \"\"\"AtTheRaces is a simple HTML site - HTTPX is fastest.\"\"\"\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX, enable_js=False)\n\n    def _get_headers(self) -> dict:\n        \"\"\"Get headers for ATR requests.\"\"\"\n        return self._get_browser_headers(\n            host=\"www.attheraces.com\",\n            referer=\"https://www.attheraces.com/racecards\",\n        )\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"Fetch race pages for a given date.\"\"\"\n        index_url = f\"/racecards/{date}\"\n\n        try:\n            index_response = await self.make_request(\n                \"GET\", index_url, headers=self._get_headers()\n            )\n        except Exception as e:\n            self.logger.error(\n                \"Failed to fetch AtTheRaces index page\", url=index_url, error=str(e)\n            )\n            return None\n\n        if not index_response:\n            self.logger.warning(\"No response from AtTheRaces index page\", url=index_url)\n            return None\n\n        self.logger.info(f\"AtTheRaces index fetched (size: {len(index_response.text)})\", url=index_url)\n        self._save_debug_snapshot(index_response.text, f\"atr_index_{date}\")\n\n        parser = HTMLParser(index_response.text)\n        links = self._find_links_with_fallback(parser)\n\n        if not links:\n            self.logger.warning(\"No race links found on index page\", date=date)\n            return None\n\n        self.logger.info(f\"Found {len(links)} race links for {date}\")\n\n        pages = await self._fetch_race_pages(links)\n        self.logger.info(f\"Successfully fetched {len(pages)}/{len(links)} race pages\")\n\n        return {\"pages\": pages, \"date\": date}\n\n    def _find_links_with_fallback(self, parser: HTMLParser) -> set:\n        \"\"\"Try multiple selectors to find race links.\"\"\"\n        links = set()\n        for selector in self.SELECTORS[\"race_links\"]:\n            found = {\n                a.attributes[\"href\"]\n                for a in parser.css(selector)\n                if a.attributes.get(\"href\")\n            }\n            links.update(found)\n\n        # Super-fallback: Regex search for anything that looks like a racecard link\n        if not links:\n            # selectolax parser has .html attribute\n            html = getattr(parser, 'html', '')\n            if html:\n                matches = re.findall(r'href=[\"\\'](/racecard/[^\"\\']+)[\"\\']', html)\n                links.update(matches)\n\n        return links\n\n    async def _fetch_race_pages(self, links: set) -> List[tuple]:\n        \"\"\"Fetch all race pages concurrently.\"\"\"\n        async def fetch_single(url_path: str):\n            response = await self.make_request(\n                \"GET\", url_path, headers=self._get_headers()\n            )\n            return (url_path, response.text) if response else (url_path, \"\")\n\n        tasks = [fetch_single(link) for link in links]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        return [\n            page for page in results\n            if not isinstance(page, Exception) and page and page[1]\n        ]\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parse race pages into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format\", date=raw_data.get(\"date\")\n            )\n            return []\n\n        races = []\n        for url_path, html in raw_data[\"pages\"]:\n            if not html:\n                continue\n\n            try:\n                if race := self._parse_single_race(html, url_path, race_date):\n                    races.append(race)\n            except Exception as e:\n                self.logger.warning(\n                    \"Error parsing race\", url=url_path, error=str(e), exc_info=True\n                )\n                self._save_debug_snapshot(html, f\"atr_parse_error_{url_path.split('/')[-1]}\", url=url_path)\n\n        return races\n\n    def _parse_single_race(\n        self, html: str, url_path: str, race_date\n    ) -> Optional[Race]:\n        \"\"\"Parse a single race from HTML.\"\"\"\n        parser = HTMLParser(html)\n\n        details = self._find_first_match(parser, self.SELECTORS[\"details_container\"])\n        if not details:\n            return None\n\n        track_node = self._find_first_match(details, self.SELECTORS[\"track_name\"])\n        track_name = normalize_venue_name(\n            clean_text(track_node.text()) if track_node else \"\"\n        )\n        if not track_name:\n            return None\n\n        time_node = self._find_first_match(details, self.SELECTORS[\"race_time\"])\n        time_str = (\n            clean_text(time_node.text()).replace(\" ATR\", \"\")\n            if time_node else \"\"\n        )\n        if not time_str:\n            return None\n\n        try:\n            start_time = datetime.combine(\n                race_date, datetime.strptime(time_str, \"%H:%M\").time()\n            )\n        except ValueError:\n            self.logger.warning(\"Invalid time format\", time_str=time_str)\n            return None\n\n        race_number = self._extract_race_number(url_path)\n        runners = self._parse_runners(parser)\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"atr_{track_name.replace(' ', '')}_{start_time:%Y%m%d}_R{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _find_first_match(self, parser, selectors: List[str]):\n        \"\"\"Try selectors until one matches.\"\"\"\n        for selector in selectors:\n            if node := parser.css_first(selector):\n                return node\n        return None\n\n    def _extract_race_number(self, url_path: str) -> int:\n        \"\"\"Extract race number from URL path.\"\"\"\n        # Standard: /racecard/GP/Attheraces-Sky-Sports-Racing-Hd-Virgin-535/2026-01-27/1520/1\n        # Alternative: /racecard/Vaal/27-January-2026/1010\n        \n        # Look for a specific race number segment (usually the last digit after a slash)\n        # We want to avoid matching the time (4 digits)\n        \n        # Try to match a single or double digit at the very end\n        pattern = r\"/(\\d{1,2})$\"\n        if match := re.search(pattern, url_path):\n            return int(match.group(1))\n            \n        # Fallback: Check if the race number is elsewhere in the URL\n        # Sometimes it's like /race1/ or similar\n        if 'race' in url_path.lower():\n             if match := re.search(r'race(\\d+)', url_path.lower()):\n                 return int(match.group(1))\n\n        # Fallback: Default to 1\n        return 1\n\n    def _parse_runners(self, parser: HTMLParser) -> List[Runner]:\n        \"\"\"Parse all runners from the page.\"\"\"\n        runner_nodes = []\n        for selector in self.SELECTORS[\"runners\"]:\n            if nodes := parser.css(selector):\n                runner_nodes = nodes\n                break\n\n        return [r for row in runner_nodes if (r := self._parse_runner(row))]\n\n    def _parse_runner(self, row: Node) -> Optional[Runner]:\n        \"\"\"Parse a single runner.\"\"\"\n        try:\n            name_node = row.css_first(\"h3\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            num_node = row.css_first(\".horse-in-racecard__saddle-cloth-number\")\n            if not num_node:\n                return None\n            num_str = clean_text(num_node.text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n\n            odds_node = row.css_first(\".horse-in-racecard__odds\")\n            odds_str = clean_text(odds_node.text()) if odds_node else \"\"\n            win_odds = parse_odds_to_decimal(odds_str)\n\n            odds = {}\n            if odds_data := create_odds_data(self.source_name, win_odds):\n                odds[self.source_name] = odds_data\n\n            return Runner(number=number, name=name, odds=odds)\n\n        except (AttributeError, ValueError) as e:\n            self.logger.debug(\"Failed to parse runner\", error=str(e))\n            return None\n",
    "web_service/backend/adapters/brisnet_adapter.py": "# python_service/adapters/brisnet_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom dateutil.parser import parse as parse_time\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .mixins import BrowserHeadersMixin, DebugMixin\nfrom .utils.odds_validator import create_odds_data\n\n\nclass BrisnetAdapter(BrowserHeadersMixin, DebugMixin, BaseAdapterV3):\n    \"\"\"\n    Adapter for brisnet.com, migrated to BaseAdapterV3 with enhanced track detection.\n    \"\"\"\n\n    SOURCE_NAME = \"Brisnet\"\n    BASE_URL = \"https://www.brisnet.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(\n            primary_engine=BrowserEngine.PLAYWRIGHT,\n            enable_js=True,\n            timeout=30,\n        )\n\n    def _get_headers(self) -> dict:\n        return self._get_browser_headers(host=\"www.brisnet.com\")\n\n    async def _fetch_track_links(self) -> List[str]:\n        \"\"\"Fetches the list of active track links from the Brisnet index page.\"\"\"\n        url = \"/cgi-bin/intoday.cgi\"\n        response = await self.make_request(\"GET\", url, headers=self._get_headers())\n        if not response or not response.text:\n            return []\n\n        parser = HTMLParser(response.text)\n        # Find links that look like track entries (briswatch.cgi links)\n        links = []\n        for a in parser.css(\"a[href*='briswatch.cgi']\"):\n            href = a.attributes.get(\"href\")\n            if href:\n                # Ensure it's an absolute URL or relative to base\n                if not href.startswith(\"http\"):\n                    href = href if href.startswith(\"/\") else f\"/{href}\"\n                links.append(href)\n\n        return list(set(links))\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"Fetches the raw HTML for all active tracks for the given date.\"\"\"\n        track_links = await self._fetch_track_links()\n        if not track_links:\n            self.logger.warning(\"No active tracks found on Brisnet index page.\")\n            return None\n\n        semaphore = asyncio.Semaphore(5)\n\n        async def fetch_track_page(url: str):\n            async with semaphore:\n                try:\n                    response = await self.make_request(\"GET\", url, headers=self._get_headers())\n                    if response:\n                        self._save_debug_html(response.text, f\"brisnet_{url.split('/')[-1]}_{date}\")\n                    return response.text if response else \"\"\n                except Exception as e:\n                    self.logger.warning(\"Failed to fetch track page\", url=url, error=str(e))\n                    return \"\"\n\n        tasks = [fetch_track_page(link) for link in track_links]\n        pages = await asyncio.gather(*tasks)\n\n        return {\n            \"pages\": [p for p in pages if p],\n            \"date\": date\n        }\n\n    def _parse_races(self, raw_data: Optional[dict]) -> List[Race]:\n        \"\"\"Parses the raw HTML pages into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        race_date = raw_data[\"date\"]\n        all_races = []\n\n        for html in raw_data[\"pages\"]:\n            parser = HTMLParser(html)\n\n            venue_node = parser.css_first(\"header h1\")\n            venue = \"Unknown\"\n            if venue_node:\n                venue_text = venue_node.text().split(\" - \")[0]\n                venue = normalize_venue_name(venue_text)\n\n            for race_section in parser.css(\"section.race\"):\n                try:\n                    race_number_str = race_section.attributes.get(\"data-racenumber\")\n                    if not race_number_str or not race_number_str.isdigit():\n                        continue\n                    race_number = int(race_number_str)\n\n                    post_time_node = race_section.css_first(\".race-title span\")\n                    if not post_time_node:\n                        continue\n                    post_time_str = post_time_node.text().replace(\"Post Time: \", \"\").strip()\n\n                    try:\n                        start_time = parse_time(f\"{race_date} {post_time_str}\")\n                    except (ValueError, TypeError):\n                        start_time = datetime.now()\n\n                    runners = []\n                    for row in race_section.css(\"tbody tr\"):\n                        classes = row.attributes.get(\"class\", \"\")\n                        if classes and \"scratched\" in classes.lower():\n                            continue\n\n                        cells = row.css(\"td\")\n                        if len(cells) < 3:\n                            continue\n\n                        number_text = cells[0].text().strip()\n                        number_digits = \"\".join(filter(str.isdigit, number_text))\n                        number = int(number_digits) if number_digits else 0\n\n                        name = cells[1].text().strip()\n                        odds_str = cells[2].text().strip()\n\n                        win_odds = parse_odds_to_decimal(odds_str)\n                        odds = {}\n                        if odds_data := create_odds_data(self.source_name, win_odds):\n                            odds[self.source_name] = odds_data\n\n                        runners.append(Runner(number=number, name=name, odds=odds))\n\n                    if not runners:\n                        continue\n\n                    race = Race(\n                        id=f\"brisnet_{venue.replace(' ', '').lower()}_{race_date}_{race_number}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=start_time,\n                        runners=runners,\n                        source=self.source_name,\n                        field_size=len(runners),\n                    )\n                    all_races.append(race)\n                except Exception:\n                    self.logger.warning(\"Failed to parse a race on Brisnet, skipping.\", exc_info=True)\n                    continue\n\n        return all_races\n",
    "web_service/backend/adapters/greyhound_adapter.py": "# python_service/adapters/greyhound_adapter.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any, Dict, List\n\nfrom pydantic import ValidationError\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race, Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .utils.odds_validator import create_odds_data\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\n\n\nclass GreyhoundAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for fetching Greyhound racing data, migrated to BaseAdapterV3.\n    Activated by setting GREYHOUND_API_URL in .env.\n    \"\"\"\n\n    SOURCE_NAME = \"Greyhound Racing\"\n\n    def __init__(self, config=None):\n        if not getattr(config, \"GREYHOUND_API_URL\", None):\n            raise AdapterConfigError(self.SOURCE_NAME, \"GREYHOUND_API_URL is not configured.\")\n        super().__init__(\n            source_name=self.SOURCE_NAME,\n            base_url=config.GREYHOUND_API_URL,\n            config=config,\n        )\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw card data from the greyhound API.\"\"\"\n        endpoint = f\"v1/cards/{date}\"\n        response = await self.make_request(\"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw card data into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"cards\"):\n            self.logger.warning(\"No 'cards' in greyhound response or empty list.\")\n            return []\n\n        all_races = []\n        for card in raw_data.get(\"cards\", []):\n            venue = card.get(\"track_name\", \"Unknown Venue\")\n            for race_data in card.get(\"races\", []):\n                try:\n                    if not race_data.get(\"runners\"):\n                        continue\n\n                    race_id = race_data.get(\"race_id\")\n                    race_number = race_data.get(\"race_number\")\n                    start_timestamp = race_data.get(\"start_time\")\n                    if not all([race_id, race_number, start_timestamp]):\n                        continue\n\n                    race = Race(\n                        id=f\"greyhound_{race_id}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=datetime.fromtimestamp(start_timestamp),\n                        runners=self._parse_runners(race_data.get(\"runners\", [])),\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n                except (ValidationError, KeyError) as e:\n                    self.logger.error(\n                        \"Error parsing greyhound race\",\n                        race_id=race_data.get(\"race_id\", \"N/A\"),\n                        error=str(e),\n                    )\n                    continue\n        return all_races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                if runner_data.get(\"scratched\", False):\n                    continue\n\n                trap_number = runner_data.get(\"trap_number\")\n                dog_name = runner_data.get(\"dog_name\")\n                if not all([trap_number, dog_name]):\n                    continue\n\n                odds_data = {}\n                win_odds_val = runner_data.get(\"odds\", {}).get(\"win\")\n                if win_odds_val is not None:\n                    win_odds = Decimal(str(win_odds_val))\n                    if odds_data_val := create_odds_data(self.source_name, win_odds):\n                        odds_data[self.source_name] = odds_data_val\n\n                runners.append(\n                    Runner(\n                        number=trap_number,\n                        name=dog_name,\n                        scratched=runner_data.get(\"scratched\", False),\n                        odds=odds_data,\n                    )\n                )\n            except (KeyError, ValidationError):\n                self.logger.warning(\"Error parsing greyhound runner, skipping.\", runner_data=runner_data)\n                continue\n        return runners\n",
    "web_service/backend/adapters/mixins/headers_mixin.py": "# python_service/adapters/mixins/headers_mixin.py\n\"\"\"Mixin for generating browser-like HTTP headers.\"\"\"\n\nfrom typing import Optional\n\nfrom ..constants import (\n    CHROME_SEC_CH_UA,\n    CHROME_USER_AGENT,\n    DEFAULT_BROWSER_HEADERS,\n)\n\n\nclass BrowserHeadersMixin:\n    \"\"\"Mixin that provides browser-like HTTP headers.\"\"\"\n\n    def _get_browser_headers(\n        self,\n        host: Optional[str] = None,\n        referer: Optional[str] = None,\n        *,\n        include_sec_ch: bool = True,\n    ) -> dict:\n        \"\"\"\n        Generate browser-like headers for HTTP requests.\n\n        Args:\n            host: The Host header value\n            referer: The Referer header value\n            include_sec_ch: Whether to include sec-ch-ua headers\n\n        Returns:\n            Dictionary of HTTP headers\n        \"\"\"\n        headers = {\n            **DEFAULT_BROWSER_HEADERS,\n            \"User-Agent\": CHROME_USER_AGENT,\n        }\n\n        if host:\n            headers[\"Host\"] = host\n\n        if referer:\n            headers[\"Referer\"] = referer\n\n        if include_sec_ch:\n            headers.update({\n                \"sec-ch-ua\": CHROME_SEC_CH_UA,\n                \"sec-ch-ua-mobile\": \"?0\",\n                \"sec-ch-ua-platform\": '\"Windows\"',\n            })\n\n        return headers\n",
    "web_service/backend/adapters/racingpost_adapter.py": "# python_service/adapters/racingpost_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any, List, Optional\n\nfrom selectolax.parser import HTMLParser, Node\n\nfrom ..models import Race, Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text, normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .mixins import BrowserHeadersMixin, DebugMixin\nfrom .utils.odds_validator import create_odds_data\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy, StealthMode\n\n\nclass RacingPostAdapter(BrowserHeadersMixin, DebugMixin, BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Racing Post racecards, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"RacingPost\"\n    BASE_URL = \"https://www.racingpost.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        \"\"\"\n        RacingPost has strong anti-bot measures. We need to use a full\n        browser with the highest stealth settings to avoid being blocked.\n        \"\"\"\n        return FetchStrategy(\n            primary_engine=BrowserEngine.PLAYWRIGHT,\n            enable_js=True,\n            stealth_mode=StealthMode.CAMOUFLAGE,  # Strongest stealth\n            block_resources=False,  # Load all resources to appear more human\n        )\n\n    def _get_headers(self) -> dict:\n        return self._get_browser_headers(host=\"www.racingpost.com\")\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw HTML content for all races on a given date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(\"GET\", index_url, headers=self._get_headers())\n        if not index_response or not index_response.text:\n            self.logger.warning(\"Failed to fetch RacingPost index page\", url=index_url)\n            return None\n\n        self._save_debug_html(index_response.text, f\"racingpost_index_{date}\")\n\n        index_parser = HTMLParser(index_response.text)\n        links = index_parser.css('a[data-test-selector^=\"RC-meetingItem__link_race\"]')\n        race_card_urls = [link.attributes[\"href\"] for link in links]\n\n        async def fetch_single_html(url: str):\n            response = await self.make_request(\"GET\", url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(url) for url in race_card_urls]\n        html_contents = await asyncio.gather(*tasks)\n        return {\"date\": date, \"html_contents\": html_contents}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"html_contents\"):\n            return []\n\n        date = raw_data[\"date\"]\n        html_contents = raw_data[\"html_contents\"]\n        all_races: List[Race] = []\n\n        for html in html_contents:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first('a[data-test-selector=\"RC-course__name\"]')\n                if not venue_node:\n                    continue\n                venue_raw = venue_node.text(strip=True)\n                venue = normalize_venue_name(venue_raw)\n\n                race_time_node = parser.css_first('span[data-test-selector=\"RC-course__time\"]')\n                if not race_time_node:\n                    continue\n                race_time_str = race_time_node.text(strip=True)\n\n                race_datetime_str = f\"{date} {race_time_str}\"\n                start_time = datetime.strptime(race_datetime_str, \"%Y-%m-%d %H:%M\")\n\n                runners = self._parse_runners(parser)\n\n                if venue and runners:\n                    race_number = self._get_race_number(parser, start_time)\n                    race = Race(\n                        id=f\"rp_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=start_time,\n                        runners=runners,\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse RacingPost race from HTML content.\", exc_info=True)\n                continue\n        return all_races\n\n    def _get_race_number(self, parser: HTMLParser, start_time: datetime) -> int:\n        \"\"\"Derives the race number by finding the active time in the nav bar.\"\"\"\n        time_str_to_find = start_time.strftime(\"%H:%M\")\n        time_links = parser.css('a[data-test-selector=\"RC-raceTime\"]')\n        for i, link in enumerate(time_links):\n            if link.text(strip=True) == time_str_to_find:\n                return i + 1\n        return 1\n\n    def _parse_runners(self, parser: HTMLParser) -> list[Runner]:\n        \"\"\"Parses all runners from a single race card page.\"\"\"\n        runners = []\n        runner_nodes = parser.css('div[data-test-selector=\"RC-runnerCard\"]')\n        for node in runner_nodes:\n            if runner := self._parse_runner(node):\n                runners.append(runner)\n        return runners\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first('span[data-test-selector=\"RC-runnerNumber\"]')\n            name_node = node.css_first('a[data-test-selector=\"RC-runnerName\"]')\n            odds_node = node.css_first('span[data-test-selector=\"RC-runnerPrice\"]')\n\n            if not all([number_node, name_node, odds_node]):\n                return None\n\n            number_str = clean_text(number_node.text())\n            number = int(number_str) if number_str and number_str.isdigit() else 0\n            name = clean_text(name_node.text())\n            odds_str = clean_text(odds_node.text())\n            scratched = \"NR\" in odds_str.upper() or not odds_str\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if odds_data := create_odds_data(self.source_name, win_odds):\n                    odds[self.source_name] = odds_data\n\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError):\n            self.logger.warning(\"Could not parse RacingPost runner, skipping.\", exc_info=True)\n            return None\n",
    "web_service/backend/adapters/stubs/punters_adapter.py": "# python_service/adapters/stubs/punters_adapter.py\nfrom ..base_stub_adapter import BaseStubAdapter\n\n\nclass PuntersAdapter(BaseStubAdapter):\n    \"\"\"Stub adapter for punters.com.au.\"\"\"\n\n    SOURCE_NAME = \"Punters\"\n    BASE_URL = \"https://www.punters.com.au\"\n",
    "web_service/backend/adapters/timeform_adapter.py": "# python_service/adapters/timeform_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any, List, Optional\n\nfrom selectolax.parser import HTMLParser, Node\n\nfrom ..models import Race, Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .mixins import BrowserHeadersMixin, DebugMixin\nfrom .utils.odds_validator import create_odds_data\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\n\n\nclass TimeformAdapter(BrowserHeadersMixin, DebugMixin, BaseAdapterV3):\n    \"\"\"\n    Adapter for timeform.com, migrated to BaseAdapterV3 and standardized on selectolax.\n    \"\"\"\n\n    SOURCE_NAME = \"Timeform\"\n    BASE_URL = \"https://www.timeform.com/horse-racing\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    def _get_headers(self) -> dict:\n        return self._get_browser_headers(host=\"www.timeform.com\")\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(\"GET\", index_url, headers=self._get_headers())\n        if not index_response or not index_response.text:\n            self.logger.warning(\"Failed to fetch Timeform index page\", url=index_url)\n            return None\n\n        self._save_debug_html(index_response.text, f\"timeform_index_{date}\")\n\n        parser = HTMLParser(index_response.text)\n        links = {a.attributes[\"href\"] for a in parser.css(\"a.rp-racecard-off-link[href]\") if a.attributes.get(\"href\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(\"GET\", url_path, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to TimeformAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                track_name_node = parser.css_first(\"h1.rp-raceTimeCourseName_name\")\n                if not track_name_node:\n                    continue\n                track_name = clean_text(track_name_node.text())\n\n                race_time_node = parser.css_first(\"span.rp-raceTimeCourseName_time\")\n                if not race_time_node:\n                    continue\n                race_time_str = clean_text(race_time_node.text())\n\n                start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n\n                all_times = [clean_text(a.text()) for a in parser.css(\"a.rp-racecard-off-link\")]\n                race_number = all_times.index(race_time_str) + 1 if race_time_str in all_times else 1\n\n                runner_rows = parser.css(\"div.rp-horseTable_mainRow\")\n                if not runner_rows:\n                    continue\n\n                runners = [self._parse_runner(row) for row in runner_rows]\n                race = Race(\n                    id=f\"tf_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],  # Filter out None values\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError, TypeError):\n                self.logger.warning(\"Error parsing a race from Timeform, skipping race.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Node) -> Optional[Runner]:\n        try:\n            name_node = row.css_first(\"a.rp-horseTable_horse-name\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            num_node = row.css_first(\"span.rp-horseTable_horse-number\")\n            if not num_node:\n                return None\n            num_str = clean_text(num_node.text())\n            number_part = \"\".join(filter(str.isdigit, num_str.strip(\"()\")))\n            number = int(number_part)\n\n            odds_data = {}\n            odds_tag = row.css_first(\"button.rp-bet-placer-btn__odds\")\n            if odds_tag:\n                odds_str = clean_text(odds_tag.text())\n                if win_odds := parse_odds_to_decimal(odds_str):\n                    if odds_data_val := create_odds_data(self.source_name, win_odds):\n                        odds_data[self.source_name] = odds_data_val\n\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError, TypeError):\n            self.logger.warning(\"Failed to parse a runner from Timeform, skipping runner.\")\n            return None\n",
    "web_service/backend/adapters/xpressbet_adapter.py": "# python_service/adapters/xpressbet_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race, Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .utils.odds_validator import create_odds_data\n\n\nclass XpressbetAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for Xpressbet API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Xpressbet\"\n    BASE_URL = \"https://api.xpressbet.com/v1/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not getattr(config, \"XPRESSBET_API_KEY\", None):\n            # Many adapters are skipped if not configured, this is standard.\n            self.api_key = None\n        else:\n            self.api_key = config.XPRESSBET_API_KEY\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw meetings data from the Xpressbet API.\"\"\"\n        if not self.api_key:\n            self.logger.warning(\"Xpressbet API key not configured, skipping fetch.\")\n            return None\n\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n        response = await self.make_request(\"GET\", f\"meetings?date={date}\", headers=headers)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw meetings data into a list of Race objects.\"\"\"\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            return []\n\n        all_races = []\n        for meeting in raw_data.get(\"meetings\", []):\n            venue = meeting.get(\"name\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, venue):\n                        all_races.append(race)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.error(\n                        \"Error parsing Xpressbet race\",\n                        race_id=race_data.get(\"id\"),\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: Dict[str, Any], venue: str) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race_data.get(\"id\")\n        race_number = race_data.get(\"number\")\n        start_time_str = race_data.get(\"startTime\")\n\n        if not all([race_id, race_number, start_time_str]):\n            return None\n\n        runners = []\n        for runner_data in race_data.get(\"runners\", []):\n            name = runner_data.get(\"name\")\n            number = runner_data.get(\"number\")\n            if not all([name, number]):\n                continue\n\n            runners.append(\n                Runner(\n                    name=name,\n                    number=number,\n                    scratched=runner_data.get(\"scratched\", False),\n                    odds={},\n                )\n            )\n\n        if not runners:\n            return None\n\n        try:\n            start_time = datetime.fromisoformat(start_time_str.replace(\"Z\", \"+00:00\"))\n        except (ValueError, TypeError):\n            start_time = datetime.now()\n\n        return Race(\n            id=f\"xb_{race_id}\",\n            venue=venue,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/core/errors.py": "# python_service/core/errors.py\nfrom enum import Enum\n\n\nclass ErrorCategory(Enum):\n    CONFIGURATION_ERROR = \"Configuration missing or invalid\"\n    NETWORK_ERROR = \"HTTP/Network request failed\"\n    PARSING_ERROR = \"Data parsing or validation unsuccessful\"\n    UNEXPECTED_ERROR = \"An unhandled exception occurred\"\n",
    "web_service/backend/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "web_service/backend/initialize_db.py": "# python_service/initialize_db.py\nfrom db.init import initialize_database\n\n\ndef main():\n    \"\"\"\n    This script exists solely to initialize the database.\n    It should be called before the main server process is started.\n    \"\"\"\n    print(\"Initializing database...\", flush=True)\n    initialize_database()\n    print(\"Database initialization complete.\", flush=True)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "web_service/backend/middleware/error_handler.py": "# python_service/middleware/error_handler.py\n\nfrom fastapi import Request\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\n\nfrom ..user_friendly_errors import ERROR_MAP\n\n\nclass UserFriendlyException(Exception):\n    def __init__(self, error_key: str, status_code: int = 500, details: str = None):\n        self.error_key = error_key\n        self.status_code = status_code\n        self.details = details\n        error_info = ERROR_MAP.get(error_key, ERROR_MAP[\"default\"])\n        self.message = error_info[\"message\"]\n        self.suggestion = error_info[\"suggestion\"]\n        super().__init__(self.message)\n\n\nasync def user_friendly_exception_handler(request: Request, exc: UserFriendlyException):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"error\": {\n                \"message\": exc.message,\n                \"suggestion\": exc.suggestion,\n                \"details\": exc.details,\n            }\n        },\n    )\n\n\nasync def validation_exception_handler(request: Request, exc: RequestValidationError):\n    \"\"\"Convert Pydantic validation errors to user-friendly messages.\"\"\"\n    return JSONResponse(\n        status_code=422,\n        content={\n            \"detail\": \"Invalid request parameters\",\n            \"errors\": [\n                {\n                    \"field\": error[\"loc\"][-1] if error[\"loc\"] else \"unknown\",\n                    \"message\": error[\"msg\"],\n                    \"type\": error[\"type\"],\n                }\n                for error in exc.errors()\n            ],\n        },\n    )\n",
    "web_service/backend/monolith.py": "\"\"\"\nFortuna Monolith - Single executable frontend + backend\nProduction-grade with enhanced error handling, user-friendly startup, and better logging\n\nIMPORTANT: Uses WinForms instead of CEF for Python 3.10 compatibility\n(CEFPython3 v66.0 doesn't support Python 3.10.11)\n\"\"\"\nimport sys\nimport os\nfrom pathlib import Path\nimport logging\nimport io\nimport threading\nimport time\nimport json\nfrom contextlib import suppress\n\n# ====================================================================\n# CONSTANTS & CONFIGURATION\n# ====================================================================\nAPP_NAME = \"Fortuna Faucet\"\nAPP_VERSION = \"1.0.0\"\nAPI_HOST = \"127.0.0.1\"\nAPI_PORT = 8000\nBACKEND_STARTUP_TIMEOUT = 10\nHEALTH_CHECK_ATTEMPTS = 10\nHEALTH_CHECK_INTERVAL = 1\n\n# ====================================================================\n# LOGGING SETUP (BEFORE ANYTHING ELSE)\n# ====================================================================\ndef _get_log_file() -> Path:\n    \"\"\"Get log file path (works in both dev and frozen modes)\"\"\"\n    if getattr(sys, \"frozen\", False):\n        log_dir = Path(os.environ.get(\"TEMP\", \".\"))\n    else:\n        log_dir = Path(\".\")\n    return log_dir / \"fortuna-monolith.log\"\n\ndef _force_utf8_stream(stream):\n    \"\"\"Ensure stream uses UTF-8 encoding\"\"\"\n    if hasattr(stream, \"reconfigure\"):\n        with suppress(Exception):\n            stream.reconfigure(encoding=\"utf-8\", errors=\"replace\")\n            return stream\n\n    buffer = getattr(stream, \"buffer\", None)\n    if buffer is None:\n        return stream\n\n    with suppress(Exception):\n        return io.TextIOWrapper(buffer, encoding=\"utf-8\", errors=\"replace\")\n\n    return stream\n\ndef setup_logging():\n    \"\"\"Configure logging to both file and console\"\"\"\n    log_file = _get_log_file()\n\n    # Force UTF-8 on stdout/stderr\n    sys.stdout = _force_utf8_stream(sys.stdout)\n    sys.stderr = _force_utf8_stream(sys.stderr)\n\n    # Logging handlers\n    file_handler = logging.FileHandler(log_file, mode=\"w\", encoding=\"utf-8\")\n    console_handler = logging.StreamHandler(sys.stdout)\n\n    # Format with timestamps\n    formatter = logging.Formatter(\n        \"[%(levelname)-8s] %(asctime)s - %(message)s\",\n        datefmt=\"%H:%M:%S\"\n    )\n    file_handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n\n    # Setup root logger\n    logging.basicConfig(\n        level=logging.INFO,\n        handlers=[file_handler, console_handler],\n    )\n\n    logger = logging.getLogger(\"fortuna\")\n    return logger\n\nlogger = setup_logging()\n\n# Banner\nlogger.info(\"=\" * 70)\nlogger.info(f\"{APP_NAME} v{APP_VERSION} - Starting up\")\nlogger.info(\"=\" * 70)\nlogger.info(f\"Mode: {'Frozen EXE' if getattr(sys, 'frozen', False) else 'Development'}\")\nlogger.info(f\"Python: {sys.version.split()[0]}\")\n\n# ====================================================================\n# UI HELPERS (DEFINE BEFORE IMPORTS)\n# ====================================================================\ndef show_error_dialog(title: str, message: str):\n    \"\"\"Show error dialog (fallback if no GUI available)\"\"\"\n    try:\n        import tkinter as tk\n        from tkinter import messagebox\n        root = tk.Tk()\n        root.withdraw()\n        messagebox.showerror(title, message)\n    except:\n        # If tkinter fails, just log it\n        logger.error(f\"{title}: {message}\")\n\n# ====================================================================\n# FORCE PYINSTALLER TO INCLUDE DEPENDENCIES (TOP-LEVEL IMPORTS)\n# ====================================================================\nif False:  # Never executes, but PyInstaller sees the imports\n    import fastapi\n    import uvicorn\n    import webview\n    import pydantic\n    import starlette\n    import requests\n    from fastapi import FastAPI\n    from fastapi.staticfiles import StaticFiles\n    from fastapi.middleware.cors import CORSMiddleware\n    from fastapi.responses import FileResponse, JSONResponse\n\n# ====================================================================\n# IMPORT DEPENDENCIES WITH FRIENDLY ERROR HANDLING\n# ====================================================================\ndef _import_dependencies():\n    \"\"\"Import all required modules with descriptive error messages\"\"\"\n    try:\n        global uvicorn, webview, FastAPI, StaticFiles, CORSMiddleware, FileResponse, JSONResponse, requests\n\n        import requests\n        import uvicorn\n        import webview\n        from fastapi import FastAPI\n        from fastapi.staticfiles import StaticFiles\n        from fastapi.middleware.cors import CORSMiddleware\n        from fastapi.responses import FileResponse, JSONResponse\n\n        logger.info(\"OK - All dependencies loaded successfully\")\n        return True\n    except ImportError as e:\n        logger.critical(f\"FAILED - Missing dependency: {e}\")\n        show_error_dialog(\n            \"Missing Dependencies\",\n            f\"Could not load required library:\\n{str(e)}\\n\\n\"\n            \"Ensure all packages in requirements.txt are installed:\\n\"\n            \"pip install -r web_service/backend/requirements.txt\"\n        )\n        return False\n    except Exception as e:\n        logger.critical(f\"FAILED - Unexpected import error: {e}\", exc_info=True)\n        show_error_dialog(\n            \"Startup Error\",\n            f\"Unexpected error during startup:\\n{str(e)}\\n\\n\"\n            f\"Check the log file for details:\\n{_get_log_file()}\"\n        )\n        return False\n\nif not _import_dependencies():\n    sys.exit(1)\n\n# ====================================================================\n# UTILITY FUNCTIONS\n# ====================================================================\ndef get_resource_path(relative_path: str) -> Path:\n    \"\"\"Get absolute path to bundled resources\"\"\"\n    if getattr(sys, \"frozen\", False):\n        base_path = Path(sys._MEIPASS)\n    else:\n        base_path = Path(__file__).parent.parent.parent\n\n    full_path = base_path / relative_path\n    return full_path\n\n# ====================================================================\n# API CREATION\n# ====================================================================\ndef create_backend_api():\n    \"\"\"Create FastAPI instance with fallback support\"\"\"\n    # Use the lifespan from the main API to ensure engine initialization\n    try:\n        from web_service.backend.api import lifespan as backend_lifespan\n        api = FastAPI(title=\"Fortuna Backend\", lifespan=backend_lifespan)\n    except ImportError:\n        api = FastAPI(title=\"Fortuna Backend\")\n\n    @api.get(\"/health\")\n    async def health():\n        \"\"\"Health check endpoint\"\"\"\n        return {\n            \"status\": \"ok\",\n            \"service\": \"fortuna-monolith\",\n            \"version\": APP_VERSION\n        }\n\n    try:\n        logger.info(\"Attempting to load full backend API...\")\n        from web_service.backend.api import router as backend_router\n\n        # Include the router directly instead of copying routes from app.\n        # This avoids double-prefixing (/api/api/...) and accidental copying\n        # of static mounts and middleware from the standalone app instance.\n        api.include_router(backend_router)\n\n        logger.info(\"OK - Full backend API router included\")\n        return api\n\n    except (ImportError, AttributeError) as e:\n        logger.warning(f\"Full backend import failed: {e}\")\n        logger.info(\"Running in minimal mode (basic endpoints only)\")\n\n        # Provide stub endpoints\n        @api.get(\"/races\")\n        async def get_races():\n            return {\n                \"status\": \"error\",\n                \"message\": \"Full API not available\",\n                \"sample\": [{\"id\": 1, \"name\": \"Example Race\", \"status\": \"pending\"}]\n            }\n\n        return api\n\n    except Exception as e:\n        logger.error(f\"Unexpected error loading backend: {e}\", exc_info=True)\n        return api\n\n# ====================================================================\n# APP CREATION\n# ====================================================================\ndef create_app():\n    \"\"\"Create main FastAPI application\"\"\"\n    logger.info(\"Creating FastAPI application...\")\n    app = FastAPI(title=\"Fortuna Monolith\")\n\n    # CORS for local development\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n    logger.info(\"OK - CORS middleware configured\")\n\n    # Mount backend API\n    logger.info(\"Mounting backend API at /api...\")\n    backend = create_backend_api()\n    app.mount(\"/api\", backend, name=\"backend\")\n\n    # Setup frontend serving\n    frontend_path = get_resource_path(\"frontend_dist\")\n    index_file = frontend_path / \"index.html\"\n\n    logger.info(f\"Frontend path: {frontend_path}\")\n\n    if not frontend_path.exists():\n        logger.error(\"Frontend directory not found - app will run without UI\")\n\n        @app.get(\"/\")\n        async def fallback():\n            return JSONResponse(\n                {\"message\": \"Frontend not available\", \"api\": \"/api/health\"},\n                status_code=503\n            )\n        return app\n\n    # Mount static files\n    logger.info(\"Configuring static file serving...\")\n\n    # Mount Next.js build output\n    next_dir = frontend_path / \"_next\"\n    if next_dir.exists():\n        app.mount(\"/_next\", StaticFiles(directory=str(next_dir)), name=\"next\")\n        logger.info(\"OK - Static assets mounted\")\n\n    public_dir = frontend_path / \"public\"\n    if public_dir.exists():\n        app.mount(\"/public\", StaticFiles(directory=str(public_dir)), name=\"public\")\n\n    # SPA routing - catch all unmapped routes and serve index.html\n    @app.get(\"/{full_path:path}\")\n    async def serve_spa(full_path: str):\n        # Skip API routes\n        if full_path.startswith(\"api/\"):\n            return JSONResponse({\"error\": \"Not found\"}, status_code=404)\n\n        # Try exact file\n        file_path = frontend_path / full_path\n        try:\n            if file_path.is_file() and file_path.is_relative_to(frontend_path):\n                return FileResponse(file_path)\n        except (ValueError, RuntimeError):\n            pass\n\n        # Try with .html extension\n        html_path = frontend_path / f\"{full_path}.html\"\n        try:\n            if html_path.is_file() and html_path.is_relative_to(frontend_path):\n                return FileResponse(html_path)\n        except (ValueError, RuntimeError):\n            pass\n\n        # SPA fallback to index\n        if index_file.exists():\n            return FileResponse(index_file)\n\n        return JSONResponse({\"error\": \"Not found\"}, status_code=404)\n\n    logger.info(\"OK - SPA routing configured\")\n    return app\n\n# ====================================================================\n# BACKEND SERVER\n# ====================================================================\ndef run_backend():\n    \"\"\"Run Uvicorn server\"\"\"\n    try:\n        logger.info(\"-\" * 70)\n        logger.info(\"STARTING BACKEND SERVER\")\n        logger.info(f\"API: http://{API_HOST}:{API_PORT}\")\n        logger.info(\"-\" * 70)\n\n        app = create_app()\n\n        # Run Uvicorn\n        uvicorn.run(\n            app,\n            host=API_HOST,\n            port=API_PORT,\n            log_level=\"warning\",\n            access_log=False,\n        )\n    except OSError as e:\n        logger.critical(f\"Port {API_PORT} is already in use: {e}\")\n        raise\n    except Exception as e:\n        logger.critical(f\"Backend error: {e}\", exc_info=True)\n        raise\n\n# ====================================================================\n# HEALTH CHECKS\n# ====================================================================\ndef check_backend_health(max_attempts: int = HEALTH_CHECK_ATTEMPTS) -> bool:\n    \"\"\"Check if backend is responding\"\"\"\n    logger.info(\"Testing backend health...\")\n\n    for attempt in range(1, max_attempts + 1):\n        try:\n            response = requests.get(\n                f\"http://{API_HOST}:{API_PORT}/api/health\",\n                timeout=2\n            )\n\n            if response.status_code == 200:\n                data = response.json()\n                logger.info(f\"OK - Backend responding: {data}\")\n                return True\n\n        except requests.ConnectionError:\n            if attempt < max_attempts:\n                logger.debug(f\"Attempt {attempt}/{max_attempts} - waiting...\")\n                time.sleep(HEALTH_CHECK_INTERVAL)\n        except Exception as e:\n            logger.warning(f\"Health check error: {e}\")\n\n    logger.warning(f\"Backend did not respond after {max_attempts} attempts\")\n    return False\n\n# ====================================================================\n# MAIN APPLICATION\n# ====================================================================\ndef main():\n    \"\"\"Main entry point\"\"\"\n    try:\n        logger.info(\"-\" * 70)\n        logger.info(f\"STARTING {APP_NAME}\")\n        logger.info(\"-\" * 70)\n\n        # Start backend in background\n        logger.info(\"Starting backend server...\")\n        backend_thread = threading.Thread(target=run_backend, daemon=True)\n        backend_thread.start()\n        logger.info(\"OK - Backend thread started\")\n\n        # Wait for backend to initialize\n        logger.info(f\"Waiting for backend to be ready (max {BACKEND_STARTUP_TIMEOUT}s)...\")\n        time.sleep(2)\n\n        # Health check\n        backend_ready = check_backend_health()\n\n        if not backend_ready:\n            logger.warning(\"Backend not responding - launching UI anyway\")\n\n        # Launch UI\n        logger.info(\"-\" * 70)\n        logger.info(\"LAUNCHING USER INTERFACE\")\n        logger.info(\"-\" * 70)\n\n        try:\n            # Use WinForms GUI (default on Windows, compatible with Python 3.10)\n            # CEF is not used here to avoid Python version compatibility issues\n            webview.create_window(\n                title=APP_NAME,\n                url=f\"http://{API_HOST}:{API_PORT}\",\n                width=1400,\n                height=900,\n                resizable=True,\n                min_size=(800, 600),\n                background_color=\"#1a1a1a\",\n            )\n\n            logger.info(\"Starting webview event loop...\")\n            # Don't specify gui='cef' - let pywebview auto-detect WinForms\n            webview.start(debug=False)\n\n        except Exception as e:\n            logger.error(f\"Webview error: {e}\", exc_info=True)\n            # Fall back to browser message\n            logger.info(f\"Open http://{API_HOST}:{API_PORT} in your browser\")\n            input(\"Press ENTER to exit...\")\n\n        logger.info(f\"{APP_NAME} closed normally\")\n\n    except KeyboardInterrupt:\n        logger.info(\"Application interrupted by user\")\n    except Exception as e:\n        logger.critical(f\"Fatal error: {e}\", exc_info=True)\n        show_error_dialog(\n            f\"{APP_NAME} Error\",\n            f\"Application failed to start:\\n{str(e)}\\n\\n\"\n            f\"Please check the log file at:\\n{_get_log_file()}\"\n        )\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
    "web_service/backend/requirements_minimal.txt": "httpx==0.25.0\nstructlog==23.2.0\npydantic==2.5.0\nuvicorn==0.24.0\nfastapi==0.104.1\ntenacity==8.2.3\n",
    "web_service/backend/security.py": "# python_service/security.py\n\nimport secrets\nimport os\n\nfrom fastapi import Depends\nfrom fastapi import HTTPException\nfrom fastapi import Security\nfrom fastapi import status\nfrom fastapi.security import APIKeyHeader\n\nfrom .config import Settings\nfrom .config import get_settings\n\nAPI_KEY_NAME = \"X-API-Key\"\napi_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)\n\nasync def verify_api_key(key: str = Security(api_key_header), settings: Settings = Depends(get_settings)):\n    \"\"\"\n    Verifies the provided API key against the one in settings using a\n    timing-attack resistant comparison.\n\n    In a CI environment, this check is bypassed to allow for automated testing.\n    \"\"\"\n    is_ci = os.environ.get(\"CI\", \"false\").lower() in (\"true\", \"1\", \"yes\")\n    if is_ci:\n        return True\n\n    if secrets.compare_digest(key, settings.API_KEY):\n        return True\n    else:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Invalid or missing API Key\")\n",
    "web_service/backend/utils/__init__.py": "",
    "web_service/backend/windows_compat.py": "\"\"\"\nWindows Compatibility Utilities\n\nCRITICAL: This module MUST be imported and called at the top of EVERY entry point\nthat uses asyncio or uvicorn in a PyInstaller bundle on Windows.\n\nWithout this fix, the asyncio event loop will fail to bind network ports, causing\nsilent failures where uvicorn reports \"Application startup complete\" but the\nservice is actually inaccessible.\n\"\"\"\n\nimport sys\n\n\ndef setup_windows_event_loop():\n    \"\"\"\n    Configure Windows event loop policy for PyInstaller bundles.\n\n    This MUST be called BEFORE any asyncio or uvicorn initialization.\n\n    Context:\n    - PyInstaller bundles on Windows have a broken default event loop policy\n    - The default policy (ProactorEventLoop) silently fails to bind ports\n    - WindowsSelectorEventLoopPolicy is the only policy that works reliably\n\n    This function is idempotent and safe to call multiple times.\n    \"\"\"\n    if sys.platform == 'win32' and getattr(sys, 'frozen', False):\n        import asyncio\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n        print('[BOOT] \u2713 Applied WindowsSelectorEventLoopPolicy for PyInstaller',\n              file=sys.stderr)\n    else:\n        # Not Windows or not frozen - no action needed\n        pass\n",
    "web_service/frontend/app/components/LiveModeToggle.tsx": "// web_platform/frontend/src/components/LiveModeToggle.tsx\n'use client';\n\nimport React from 'react';\n\ninterface LiveModeToggleProps {\n  isLive: boolean;\n  onToggle: (isLive: boolean) => void;\n  isDisabled: boolean;\n}\n\nexport const LiveModeToggle: React.FC<LiveModeToggleProps> = ({ isLive, onToggle, isDisabled }) => {\n  const handleToggle = () => {\n    if (!isDisabled) {\n      onToggle(!isLive);\n    }\n  };\n\n  return (\n    <button\n      onClick={handleToggle}\n      disabled={isDisabled}\n      className={`relative inline-flex items-center h-8 rounded-full w-32 transition-colors duration-300 ease-in-out focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-slate-800 focus:ring-blue-500 ${\n        isDisabled ? 'cursor-not-allowed bg-slate-700' : 'cursor-pointer'\n      } ${isLive ? 'bg-green-600' : 'bg-slate-600'}`}\n    >\n      <span className=\"sr-only\">Toggle Live Mode</span>\n      <span\n        className={`absolute left-1 top-1 inline-block w-6 h-6 rounded-full bg-white transform transition-transform duration-300 ease-in-out ${\n          isLive ? 'translate-x-[104px]' : 'translate-x-0'\n        }`}\n      />\n      <span\n        className={`absolute left-8 transition-opacity duration-200 ease-in-out ${\n          !isLive && !isDisabled ? 'opacity-100' : 'opacity-50'\n        }`}\n      >\n        Poll\n      </span>\n      <span\n        className={`absolute right-4 transition-opacity duration-200 ease-in-out ${\n          isLive && !isDisabled ? 'opacity-100' : 'opacity-50'\n        }`}\n      >\n        \u26a1 Live\n      </span>\n    </button>\n  );\n};\n",
    "web_service/frontend/app/components/RaceFilters.tsx": "// web_platform/frontend/src/components/RaceFilters.tsx\n'use client';\n\nimport { useState, useCallback } from 'react';\nimport { Settings, RotateCcw } from 'lucide-react';\n\ninterface FilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nexport interface RaceFiltersProps {\n  onParamsChange: (params: FilterParams) => void;\n  isLoading: boolean;\n  refetch: () => void;\n}\n\nconst DEFAULT_PARAMS: FilterParams = {\n  maxFieldSize: 10,\n  minFavoriteOdds: 2.5,\n  minSecondFavoriteOdds: 4.0,\n};\n\nexport function RaceFilters({ onParamsChange, isLoading, refetch }: RaceFiltersProps) {\n  const [params, setParams] = useState<FilterParams>(DEFAULT_PARAMS);\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // Handle individual parameter changes\n  const handleChange = useCallback((key: keyof FilterParams, value: number) => {\n    setParams(prev => {\n      const updated = { ...prev, [key]: value };\n      onParamsChange(updated);\n      return updated;\n    });\n    // Debounce the refetch call\n    const timer = setTimeout(() => {\n      refetch();\n    }, 500);\n    return () => clearTimeout(timer);\n  }, [onParamsChange, refetch]);\n\n  // Reset to defaults\n  const handleReset = useCallback(() => {\n    setParams(DEFAULT_PARAMS);\n    onParamsChange(DEFAULT_PARAMS);\n    refetch();\n  }, [onParamsChange, refetch]);\n\n  return (\n    <div className=\"bg-gradient-to-r from-slate-800 to-slate-900 rounded-lg p-4 mb-6 border border-slate-700\">\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-2\">\n          <Settings className=\"w-5 h-5 text-amber-500\" />\n          <h3 className=\"text-lg font-semibold text-white\">Race Filters</h3>\n        </div>\n        <button\n          onClick={() => setIsExpanded(!isExpanded)}\n          className=\"text-sm text-slate-400 hover:text-slate-200 transition\"\n        >\n          {isExpanded ? 'Hide' : 'Show'}\n        </button>\n      </div>\n\n      {isExpanded && (\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 pt-4 border-t border-slate-700\">\n          {/* Max Field Size */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Max Field Size\n              <span className=\"text-amber-500 ml-2\">{params.maxFieldSize}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2\"\n              max=\"20\"\n              value={params.maxFieldSize}\n              onChange={(e) => handleChange('maxFieldSize', parseInt(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Filters races with larger fields</p>\n          </div>\n\n          {/* Min Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"1.5\"\n              max=\"5\"\n              step=\"0.1\"\n              value={params.minFavoriteOdds}\n              onChange={(e) => handleChange('minFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = pickier favorites</p>\n          </div>\n\n          {/* Min Second Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min 2nd Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minSecondFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2.0\"\n              max=\"8\"\n              step=\"0.1\"\n              value={params.minSecondFavoriteOdds}\n              onChange={(e) => handleChange('minSecondFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = better odds separation</p>\n          </div>\n\n          {/* Reset Button */}\n          <div className=\"md:col-span-3 flex justify-end pt-4 border-t border-slate-700\">\n            <button\n              onClick={handleReset}\n              disabled={isLoading}\n              className=\"inline-flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-600 text-slate-200 rounded text-sm font-medium transition disabled:opacity-50\"\n            >\n              <RotateCcw className=\"w-4 h-4\" />\n              Reset to Defaults\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n",
    "web_service/frontend/app/components/TrifectaFactors.tsx": "// TrifectaFactors.tsx - FINAL, DYNAMIC VERSION\n'use client';\nimport React from 'react';\n\ninterface TrifectaFactorsProps {\n  factorsJson: string | null;\n}\n\nexport function TrifectaFactors({ factorsJson }: TrifectaFactorsProps) {\n  if (!factorsJson) {\n    return <div className=\"text-sm text-gray-500\">No analysis factors available.</div>;\n  }\n\n  try {\n    const factors = JSON.parse(factorsJson);\n    const positiveFactors = Object.entries(factors).filter(([key, value]: [string, any]) => value.ok);\n\n    if (positiveFactors.length === 0) {\n      return <div className=\"text-sm text-gray-500\">No positive factors identified.</div>;\n    }\n\n    return (\n      <div className=\"mt-2 text-xs\">\n        <h4 className=\"font-semibold mb-1\">Key Factors:</h4>\n        <ul className=\"list-disc list-inside space-y-1\">\n          {positiveFactors.map(([key, value]: [string, any]) => (\n            <li key={key} className=\"text-gray-700\">\n              <span className=\"font-medium text-green-600\">\u2713</span> {value.reason} ({value.points > 0 ? `+${value.points}` : value.points} pts)\n            </li>\n          ))}\n        </ul>\n      </div>\n    );\n  } catch (error) {\n    console.error(\"Failed to parse trifecta factors:\", error);\n    return <div className=\"text-sm text-red-500\">Error displaying analysis factors.</div>;\n  }\n}",
    "web_service/frontend/app/lib/queryClient.ts": "// web_platform/frontend/src/lib/queryClient.ts\nimport { QueryClient } from '@tanstack/react-query';\n\nexport const queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      retry: 3,\n      staleTime: 1000 * 60 * 5, // 5 minutes\n    },\n  },\n});\n",
    "web_service/frontend/next-env.d.ts": "/// <reference types=\"next\" />\n/// <reference types=\"next/image-types/global\" />\n\n// NOTE: This file should not be edited\n// see https://nextjs.org/docs/app/building-your-application/configuring/typescript for more information.\n",
    "web_service/frontend/next.config.mjs": "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  output: 'export',  // Critical for static HTML export\n  distDir: 'out',\n  trailingSlash: true,\n  images: {\n    unoptimized: true  // Required for static export\n  },\n  async rewrites() {\n    return [\n      {\n        source: '/api/:path*',\n        destination: 'http://127.0.0.1:8000/api/:path*',\n      },\n    ]\n  },\n};\n\nexport default nextConfig;\n",
    "wix/WixUI_CustomInstallDir.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:WixUI=\"http://schemas.microsoft.com/wix/WixUIExtension\">\n  <Fragment>\n    <UI Id=\"WixUI_CustomInstallDir\">\n        <DialogRef Id=\"BrowseDlg\" />\n        <DialogRef Id=\"DiskCostDlg\" />\n        <DialogRef Id=\"ErrorDlg\" />\n        <DialogRef Id=\"FatalError\" />\n        <DialogRef Id=\"FilesInUse\" />\n        <DialogRef Id=\"MsiRMFilesInUse\" />\n        <DialogRef Id=\"PrepareDlg\" />\n        <DialogRef Id=\"UserExit\" />\n        <DialogRef Id=\"WelcomeDlg\" />\n        <DialogRef Id=\"InstallDirDlg\" />\n        <DialogRef Id=\"VerifyReadyDlg\" />\n\n        <!-- Use our custom progress dialog instead of the default -->\n        <DialogRef Id=\"InstallProgressDlg\" />\n\n        <Publish Dialog=\"WelcomeDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"InstallDirDlg\">1</Publish>\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"WelcomeDlg\">1</Publish>\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Next\" Event=\"SetTargetPath\" Value=\"[WIXUI_INSTALLDIR]\" Order=\"1\" />\n        <Publish Dialog=\"InstallDirDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"VerifyReadyDlg\" Order=\"2\">1</Publish>\n        <Publish Dialog=\"VerifyReadyDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"InstallDirDlg\" Order=\"1\">NOT Installed</Publish>\n        <Publish Dialog=\"VerifyReadyDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"MaintenanceTypeDlg\" Order=\"2\">Installed</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n"
}