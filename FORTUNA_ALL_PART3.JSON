{
    ".github/actions/setup/action.yml": "name: 'Composite Setup Action'\ndescription: 'Checks out repo, sets up Node.js and Python'\ninputs:\n  architecture:\n    description: 'The architecture to set up Python for (x86, x64)'\n    required: false\n    default: 'x64'\nruns:\n  using: \"composite\"\n  steps:\n    - name: \ud83d\udce5 Checkout Repository\n      uses: actions/checkout@v4\n\n    - name: \ud83d\udce6 Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ env.NODE_VERSION }}\n        cache: 'npm'\n        cache-dependency-path: '**/package-lock.json'\n\n    - name: \ud83d\udc0d Set up Python\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ env.PYTHON_VERSION }}\n        architecture: ${{ inputs.architecture }}\n        cache: 'pip'\n",
    ".github/workflows/build-monolith.yml": "name: Fortuna Monolith Build\n\non:\n  push:\n    branches: [ main ]\n  workflow_dispatch:\n\njobs:\n  build-monolith:\n    name: 'Build Fortuna Monolith EXE'\n    runs-on: windows-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      # ========== FRONTEND ==========\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n\n      - name: Build Frontend\n        shell: pwsh\n        run: |\n          cd web_platform/frontend\n          npm ci\n          npm run build\n          if (-not (Test-Path \"out/index.html\")) {\n            throw \"Frontend build failed: index.html not found in 'out' directory.\"\n          }\n          Write-Host \"Frontend built successfully\"\n\n      # ========== BACKEND ==========\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n\n      - name: Install Dependencies\n        shell: pwsh\n        run: |\n          pip install --upgrade pip wheel\n          pip install pyinstaller==6.6.0\n          pip install -r web_service/backend/requirements.txt\n\n      - name: Create Data Directories\n        shell: pwsh\n        run: |\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/data\" | Out-Null\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/json\" | Out-Null\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/logs\" | Out-Null\n          New-Item -ItemType File -Force -Path \"web_service/backend/data/.gitkeep\" | Out-Null\n          New-Item -ItemType File -Force -Path \"web_service/backend/json/.gitkeep\" | Out-Null\n          New-Item -ItemType File -Force -Path \"web_service/backend/logs/.gitkeep\" | Out-Null\n\n      # ========== BUILD ==========\n      - name: Build Monolith EXE\n        shell: pwsh\n        env:\n          PYTHONIOENCODING: utf-8\n        run: |\n          Write-Host \"Building Fortuna Monolith...\"\n          pyinstaller --noconfirm --clean fortuna-monolith.spec\n          $exePath = \"dist/fortuna-monolith/fortuna-monolith.exe\"\n          if (-not (Test-Path $exePath)) {\n            throw \"Build failed - EXE not created at $exePath\"\n          }\n          $size = (Get-Item $exePath).Length / 1MB\n          Write-Host \"Build complete: $([math]::Round($size, 2)) MB\"\n\n      # ========== UPLOAD ==========\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: Fortuna-Monolith-${{ github.sha }}\n          path: dist/fortuna-monolith/fortuna-monolith.exe\n          retention-days: 30\n\n      # ========== SMOKE TEST ==========\n      - name: Smoke Test Monolith\n        shell: pwsh\n        timeout-minutes: 5\n        run: |\n          $exePath = \"dist/fortuna-monolith/fortuna-monolith.exe\"\n          $logFile = \"monolith-smoke-test.log\"\n\n          Write-Host \"Starting smoke test for $exePath...\"\n          $process = Start-Process -FilePath $exePath -PassThru -RedirectStandardOutput $logFile -RedirectStandardError $logFile -WindowStyle Hidden\n\n          Write-Host \"Waiting for process (PID: $($process.Id)) to initialize (max 30s)...\"\n          $success = $false\n          foreach ($i in 1..15) {\n            if ($process.HasExited) {\n              Write-Host \"Process exited prematurely with code $($process.ExitCode).\"\n              break\n            }\n            try {\n              $response = Invoke-WebRequest -Uri \"http://127.0.0.1:8000/api/health\" -UseBasicParsing -TimeoutSec 2\n              if ($response.StatusCode -eq 200) {\n                Write-Host \"\u2713 Health check passed on attempt $i.\"\n                $success = $true\n                break\n              }\n            } catch {\n              Write-Host \"Health check attempt $i failed. Retrying in 2s...\"\n              Start-Sleep -Seconds 2\n            }\n          }\n\n          # Additional check for the frontend root\n          if ($success) {\n            try {\n              $response = Invoke-WebRequest -Uri \"http://127.0.0.1:8000/\" -UseBasicParsing\n              if ($response.StatusCode -ne 200) {\n                Write-Host \"Frontend root page check failed with status $($response.StatusCode)\"\n                $success = $false\n              } else {\n                 Write-Host \"\u2713 Frontend root page loaded successfully.\"\n              }\n            } catch {\n              Write-Host \"Frontend root page check failed: $($_.Exception.Message)\"\n              $success = $false\n            }\n          }\n\n          Stop-Process -Id $process.Id -Force\n\n          if (-not $success) {\n            Write-Host \"\u274c Smoke test FAILED.\"\n            Get-Content $logFile -Tail 100\n            throw \"Monolith smoke test failed.\"\n          }\n\n          Write-Host \"\u2705 Smoke test PASSED successfully.\"\n\n      # ========== OPTIONAL VERIFICATION STEPS ==========\n      - name: Run Verification Scripts\n        shell: pwsh\n        continue-on-error: true\n        run: |\n          pip install playwright\n          playwright install\n          $exePath = \"dist/fortuna-monolith/fortuna-monolith.exe\"\n          $logFile = \"monolith-verification-test.log\"\n\n          Write-Host \"Starting monolith for verification tests...\"\n          $process = Start-Process -FilePath $exePath -PassThru -RedirectStandardOutput $logFile -RedirectStandardError $logFile -WindowStyle Hidden\n\n          Write-Host \"Waiting for application to initialize...\"\n          Start-Sleep -Seconds 15\n\n          Write-Host \"Running Playwright script...\"\n          python e2e/jules-smoke-test.py\n          Write-Host \"Playwright script finished.\"\n\n          Write-Host \"Running race info script...\"\n          python e2e/get-race-info.py\n          Write-Host \"Race info script finished.\"\n\n          Stop-Process -Id $process.Id -Force\n          Write-Host \"Verification tests complete.\"\n\n      - name: Upload Playwright Screenshot\n        uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: playwright-screenshot\n          path: playwright-screenshot.png\n          retention-days: 7\n\n      - name: Upload Race Info\n        uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: race-info\n          path: race-info.txt\n          retention-days: 7\n",
    ".github/workflows/test-quickstart.yml": "name: \ud83e\uddea Backend CI & Quick-Start Test\n\non:\n  workflow_dispatch:\n  push:\n    branches: [\"main\"]\n\njobs:\n  test-bootstrapper:\n    name: '\ud83c\udfc3 Run Quick-Start PS1'\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: \ud83d\udc0d Setup Python\n        id: setup-python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n\n      - name: \ud83d\udfe2 Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n          cache-dependency-path: web_platform/frontend/package-lock.json\n\n      - name: \ud83d\udce6 Install Python Dependencies\n        shell: pwsh\n        run: |\n          pip install --upgrade pip\n          pip install -r web_service/backend/requirements.txt\n          pip install -r web_service/backend/requirements-dev.txt\n\n      - name: \ud83c\udfa8 Build Frontend\n        working-directory: web_platform/frontend\n        run: |\n          npm ci\n          npm run build\n\n      - name: \ud83e\uddea Run Backend Unit Tests\n        shell: pwsh\n        run: |\n          $env:PYTHONPATH = \"$env:PYTHONPATH;${env:GITHUB_WORKSPACE}/web_service/backend\"\n          python -m pytest web_service/backend/tests/\n\n      - name: \ud83d\udd0d Syntax Validation\n        shell: pwsh\n        run: |\n          try {\n            $script = Get-Content \"scripts/fortuna-quick-start.ps1\" -Raw\n            [void][System.Management.Automation.PSParser]::Tokenize($script, [ref]$null)\n            Write-Host \"\u2705 PowerShell Syntax is valid.\"\n          } catch {\n            Write-Error \"\u274c Syntax Error: $_\"\n            exit 1\n          }\n\n      - name: \ud83d\ude80 Launch, Test, & Verify Backend\n        shell: pwsh\n        run: |\n          $process = $null\n          try {\n              # Start the server\n              Write-Host \"Starting backend server...\"\n              $process = Start-Process \"${{ steps.setup-python.outputs.python-path }}\" -ArgumentList \"-m uvicorn web_service.backend.main:app --host 127.0.0.1 --port 8000\" -PassThru -NoNewWindow\n\n              # Health Check Loop\n              $url = \"http://127.0.0.1:8000/api/health\"\n              Write-Host \"\u23f3 Waiting for Backend at $url...\"\n              $healthy = $false\n              for ($i=0; $i -lt 30; $i++) {\n                  try {\n                      $resp = Invoke-WebRequest -Uri $url -UseBasicParsing -TimeoutSec 2\n                      if ($resp.StatusCode -eq 200) {\n                          Write-Host \"\u2705 Backend is UP and responding!\"\n                          $healthy = $true\n                          break\n                      }\n                  } catch {\n                      Write-Host \"... ping failed, retrying ($($i+1)/30)\"\n                      Start-Sleep -Seconds 2\n                  }\n              }\n\n              if (-not $healthy) {\n                  throw \"Backend failed to start within timeout.\"\n              }\n\n              # If healthy, run optional verification scripts\n              Write-Host \"Backend is healthy. Running verification scripts...\"\n              try {\n                  Write-Host \"Installing Playwright...\"\n                  pip install playwright\n                  playwright install --with-deps\n\n                  Write-Host \"Running Playwright script...\"\n                  python e2e/jules-smoke-test.py\n                  Write-Host \"Playwright script finished.\"\n\n                  Write-Host \"Running race info script...\"\n                  python e2e/get-race-info.py\n                  Write-Host \"Race info script finished.\"\n              } catch {\n                  # This is continue-on-error, so we catch and log, but don't fail the step\n                  Write-Host \"\u26a0\ufe0f A verification script failed: $($_.Exception.Message)\"\n              }\n\n          } catch {\n              Write-Error \"\u274c An error occurred during the test run: $($_.Exception.Message)\"\n              # Dump logs for diagnosis\n              Get-Content web_service/backend/app.log -ErrorAction SilentlyContinue\n              exit 1\n          } finally {\n              if ($process -ne $null) {\n                  Write-Host \"\ud83e\uddf9 Cleaning up backend process...\"\n                  Stop-Process -Id $process.Id -Force -ErrorAction SilentlyContinue\n                  Write-Host \"\u2705 Cleanup complete.\"\n              }\n          }\n\n      - name: Upload Playwright Screenshot\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: playwright-screenshot-quickstart\n          path: playwright-screenshot.png\n          retention-days: 7\n\n      - name: Upload Race Info\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: race-info-quickstart\n          path: race-info.txt\n          retention-days: 7",
    "VERSION.txt": "1.0",
    "electron/resources/.gitkeep": "",
    "electron/secure-settings-manager.js": "// electron/secure-settings-manager.js\nconst { app } = require('electron');\nconst fs = require('fs');\nconst path = require('path');\n\nconst SETTINGS_FILE = path.join(app.getPath('userData'), 'settings.json');\n\nclass SecureSettingsManager {\n constructor() {\n this.settings = this.loadSettings();\n }\n\n loadSettings() {\n try {\n if (fs.existsSync(SETTINGS_FILE)) {\n const data = fs.readFileSync(SETTINGS_FILE, 'utf-8');\n return JSON.parse(data);\n }\n } catch (error) {\n console.error('Error loading settings:', error);\n }\n return {};\n }\n\n saveSettings() {\n try {\n fs.writeFileSync(SETTINGS_FILE, JSON.stringify(this.settings, null, 2));\n } catch (error) {\n console.error('Error saving settings:', error);\n }\n }\n\n getApiKey() {\n return this.settings.apiKey || null;\n }\n\n saveApiKey(apiKey) {\n this.settings.apiKey = apiKey;\n this.saveSettings();\n return { success: true };\n }\n\n getBetfairCredentials() {\n return this.settings.betfair || null;\n }\n\n saveBetfairCredentials(credentials) {\n this.settings.betfair = credentials;\n this.saveSettings();\n return { success: true };\n }\n}\n\nmodule.exports = new SecureSettingsManager();\n",
    "package-lock.json": "{\n  \"name\": \"app\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"dependencies\": {\n        \"@playwright/test\": \"^1.56.1\"\n      }\n    },\n    \"node_modules/@playwright/test\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/@playwright/test/-/test-1.56.1.tgz\",\n      \"integrity\": \"sha512-vSMYtL/zOcFpvJCW71Q/OEGQb7KYBPAdKh35WNSkaZA75JlAO8ED8UN6GUNTm3drWomcbcqRPFqQbLae8yBTdg==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"playwright\": \"1.56.1\"\n      },\n      \"bin\": {\n        \"playwright\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      }\n    },\n    \"node_modules/fsevents\": {\n      \"version\": \"2.3.2\",\n      \"resolved\": \"https://registry.npmjs.org/fsevents/-/fsevents-2.3.2.tgz\",\n      \"integrity\": \"sha512-xiqMQR4xAeHTuB9uWm+fFRcIOgKBMiOBP+eXiyT7jsgVCq1bkVygt00oASowB7EdtpOHaaPgKt812P9ab+DDKA==\",\n      \"hasInstallScript\": true,\n      \"license\": \"MIT\",\n      \"optional\": true,\n      \"os\": [\n        \"darwin\"\n      ],\n      \"engines\": {\n        \"node\": \"^8.16.0 || ^10.6.0 || >=11.0.0\"\n      }\n    },\n    \"node_modules/playwright\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/playwright/-/playwright-1.56.1.tgz\",\n      \"integrity\": \"sha512-aFi5B0WovBHTEvpM3DzXTUaeN6eN0qWnTkKx4NQaH4Wvcmc153PdaY2UBdSYKaGYw+UyWXSVyxDUg5DoPEttjw==\",\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"playwright-core\": \"1.56.1\"\n      },\n      \"bin\": {\n        \"playwright\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      },\n      \"optionalDependencies\": {\n        \"fsevents\": \"2.3.2\"\n      }\n    },\n    \"node_modules/playwright-core\": {\n      \"version\": \"1.56.1\",\n      \"resolved\": \"https://registry.npmjs.org/playwright-core/-/playwright-core-1.56.1.tgz\",\n      \"integrity\": \"sha512-hutraynyn31F+Bifme+Ps9Vq59hKuUCz7H1kDOcBs+2oGguKkWTU50bBWrtz34OUWmIwpBTWDxaRPXrIXkgvmQ==\",\n      \"license\": \"Apache-2.0\",\n      \"bin\": {\n        \"playwright-core\": \"cli.js\"\n      },\n      \"engines\": {\n        \"node\": \">=18\"\n      }\n    }\n  }\n}\n",
    "python_service/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching horse racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairExchange\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for a given date.\"\"\"\n        await self._authenticate(self.http_client)\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            self.http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"7\"],  # Horse Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\", \"US\", \"FR\", \"ZA\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\"Failed to parse a Betfair market.\", exc_info=True, market=market)\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bf_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 1m Mdn Stks').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "python_service/adapters/equibase_adapter.py": "# python_service/adapters/equibase_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass EquibaseAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Equibase race entries, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Equibase\"\n    BASE_URL = \"https://www.equibase.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        d = datetime.strptime(date, \"%Y-%m-%d\").date()\n        index_url = f\"/entries/Entries.cfm?ELEC_DATE={d.month}/{d.day}/{d.year}&STYLE=EQB\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Equibase index page\", url=index_url)\n            return None\n\n        parser = HTMLParser(index_response.text)\n        track_links = [\n            link.attributes[\"href\"]\n            for link in parser.css(\"div.track-information a\")\n            if \"race=\" not in link.attributes.get(\"href\", \"\")\n        ]\n\n        async def get_race_links_from_track(track_url: str):\n            response = await self.make_request(self.http_client, \"GET\", track_url, headers=self._get_headers())\n            if not response:\n                return []\n            parser = HTMLParser(response.text)\n            return [link.attributes[\"href\"] for link in parser.css(\"a.program-race-link\")]\n\n        tasks = [get_race_links_from_track(link) for link in track_links]\n        results = await asyncio.gather(*tasks)\n        race_links = [f\"{self.base_url}{link}\" for sublist in results for link in sublist]\n\n        async def fetch_single_html(race_url: str):\n            response = await self.make_request(self.http_client, \"GET\", race_url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        date = raw_data[\"date\"]\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first(\"div.track-information strong\")\n                if not venue_node:\n                    continue\n                venue = clean_text(venue_node.text())\n\n                race_number_node = parser.css_first(\"div.race-information strong\")\n                if not race_number_node:\n                    continue\n                race_number_text = race_number_node.text().replace(\"Race\", \"\").strip()\n                if not race_number_text.isdigit():\n                    continue\n                race_number = int(race_number_text)\n\n                post_time_node = parser.css_first(\"p.post-time span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text().strip()\n                start_time = self._parse_post_time(date, post_time_str)\n\n                runners = []\n                runner_nodes = parser.css(\"table.entries-table tbody tr\")\n                for node in runner_nodes:\n                    if runner := self._parse_runner(node):\n                        runners.append(runner)\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"eqb_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse Equibase race page.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first(\"td:nth-child(1)\")\n            if not number_node or not number_node.text(strip=True).isdigit():\n                return None\n            number = int(number_node.text(strip=True))\n\n            name_node = node.css_first(\"td:nth-child(3)\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            odds_node = node.css_first(\"td:nth-child(10)\")\n            odds_str = clean_text(odds_node.text()) if odds_node else \"\"\n\n            scratched = \"scratched\" in node.attributes.get(\"class\", \"\").lower()\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError, IndexError):\n            self.logger.warning(\"Could not parse Equibase runner, skipping.\", exc_info=True)\n            return None\n\n    def _parse_post_time(self, date_str: str, time_str: str) -> datetime:\n        \"\"\"Parses a time string like 'Post Time: 12:30 PM ET' into a datetime object.\"\"\"\n        time_part = time_str.split(\" \")[-2] + \" \" + time_str.split(\" \")[-1]\n        dt_str = f\"{date_str} {time_part}\"\n        return datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/horseracingnation_adapter.py": "# python_service/adapters/horseracingnation_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass HorseRacingNationAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for horseracingnation.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"HorseRacingNation\"\n    BASE_URL = \"https://www.horseracingnation.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/adapters/racing_and_sports_adapter.py": "# python_service/adapters/racing_and_sports_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSports\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"RACING_AND_SPORTS_TOKEN\") or not config.RACING_AND_SPORTS_TOKEN:\n            raise AdapterConfigError(self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw meetings data from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            self.http_client,\n            \"GET\",\n            \"v1/racing/meetings\",\n            headers=headers,\n            params=params,\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw meetings data into a list of Race objects.\"\"\"\n        all_races = []\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\"No 'meetings' in RacingAndSports response or invalid format.\")\n            return all_races\n\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed_race := self._parse_ras_race(meeting, race_summary):\n                        all_races.append(parsed_race)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse RacingAndSports race, skipping\",\n                        meeting=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return all_races\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        try:\n            start_time = datetime.fromisoformat(start_time_str)\n        except (ValueError, TypeError):\n            self.logger.warning(\n                \"Invalid start time format for RacingAndSports race\",\n                start_time_str=start_time_str,\n                race_id=race_id,\n            )\n            return None\n\n        return Race(\n            id=f\"ras_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/tab_adapter.py": "# python_service/adapters/tab_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TabAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for tab.com.au.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"TAB\"\n    BASE_URL = \"https://www.tab.com.au\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/adapters/twinspires_adapter.py": "# python_service/adapters/twinspires_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TwinSpiresAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for twinspires.com.\n    This is a placeholder for a full implementation using the discovered JSON API.\n    \"\"\"\n\n    SOURCE_NAME = \"TwinSpires\"\n    BASE_URL = \"https://www.twinspires.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Reads HTML content from a local fixture file instead of making a live API call.\n        This is a temporary measure to allow development while the live API is blocking requests.\n        \"\"\"\n        # Read the local HTML fixture\n        try:\n            with open(\"tests/fixtures/twinspires_sample.html\", \"r\") as f:\n                html_content = f.read()\n        except FileNotFoundError:\n            self.logger.error(\"TwinSpires test fixture not found.\")\n            return None\n\n        # To maintain the data structure the parser expects, we will create a mock\n        # raw_data object that resembles the original API response, but includes\n        # the HTML content.\n        return {\n            \"html_content\": html_content,\n            \"mock_track_data\": {\"trackId\": \"cd\", \"trackName\": \"Churchill Downs\", \"raceType\": \"Thoroughbred\"},\n            \"mock_race_card\": {\"raceNumber\": 5, \"postTime\": \"2025-10-26T16:30:00Z\"},\n        }\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Parses race and runner data from the mock raw_data object, which now\n        includes the HTML content from the local fixture.\n        \"\"\"\n        if not raw_data or \"html_content\" not in raw_data:\n            return []\n\n        self.logger.info(\"Parsing TwinSpires data from local fixture.\")\n\n        html_content = raw_data[\"html_content\"]\n        track = raw_data[\"mock_track_data\"]\n        race_card = raw_data[\"mock_race_card\"]\n\n        # Parse the runners from the HTML content\n        runners = self._parse_runners_from_html(html_content)\n\n        try:\n            start_time = datetime.fromisoformat(race_card.get(\"postTime\").replace(\"Z\", \"+00:00\"))\n\n            race = Race(\n                id=f\"ts_{track.get('trackId')}_{race_card.get('raceNumber')}\",\n                venue=track.get(\"trackName\"),\n                race_number=race_card.get(\"raceNumber\"),\n                start_time=start_time,\n                discipline=track.get(\"raceType\", \"Unknown\"),\n                runners=runners,\n                source=self.SOURCE_NAME,\n            )\n            return [race]\n        except Exception as e:\n            self.logger.warning(\n                \"Failed to parse race card from mock data.\",\n                error=e,\n                exc_info=True,\n            )\n            return []\n\n    def _parse_runners_from_html(self, html_content: str) -> List[Runner]:\n        \"\"\"Parses runner data from a race card's HTML content.\"\"\"\n        runners = []\n        soup = BeautifulSoup(html_content, \"html.parser\")\n        runner_elements = soup.select(\"li.runner\")\n\n        for element in runner_elements:\n            try:\n                scratched = \"scratched\" in element.get(\"class\", [])\n\n                number_tag = element.select_one(\"span.runner-number\")\n                name_tag = element.select_one(\"span.runner-name\")\n                odds_tag = element.select_one(\"span.runner-odds\")\n\n                if not all([number_tag, name_tag, odds_tag]):\n                    continue\n\n                number = int(number_tag.text.strip())\n                name = name_tag.text.strip()\n                odds_str = odds_tag.text.strip()\n\n                odds = {}\n                if not scratched and odds_str not in [\"SCR\", \"\"]:\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    if win_odds:\n                        odds[self.SOURCE_NAME] = OddsData(\n                            win=win_odds,\n                            source=self.SOURCE_NAME,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=number,\n                        name=name,\n                        scratched=scratched,\n                        odds=odds,\n                    )\n                )\n            except (ValueError, TypeError) as e:\n                self.logger.warning(\"Failed to parse a runner, skipping.\", error=e, exc_info=True)\n                continue\n\n        return runners\n\n    async def _get_races_async(self, date: str) -> List[Race]:\n        raw_data = await self._fetch_data(date)\n        return self._parse_races(raw_data)\n\n    def get_races(self, date: str) -> List[Race]:\n        \"\"\"\n        Orchestrates the fetching and parsing of race data for a given date.\n        This method will be called by the FortunaEngine.\n        \"\"\"\n        self.logger.info(f\"Getting races for {date} from {self.SOURCE_NAME}\")\n        # This is a synchronous wrapper for the async orchestrator\n        # It's a temporary measure to allow me to see the API response.\n        import asyncio\n\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        races = loop.run_until_complete(self._get_races_async(date))\n        return races\n",
    "python_service/auditor.py": "\"\"\"\nThe Auditor: Real-Time Race Verification System\n\nThis module runs as a background thread within the Python Backend.\nIt verifies predictions against official results and calculates profitability.\n\nRequirements:\n    pip install aiosqlite httpx beautifulsoup4 lxml structlog\n\"\"\"\n\nimport asyncio\nimport sqlite3\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, List, Any\nfrom dataclasses import dataclass\nimport httpx\nfrom bs4 import BeautifulSoup\nimport structlog\nimport re\n\nlogger = structlog.get_logger()\n\n\n@dataclass\nclass OfficialResult:\n    \"\"\"Represents official race results from Equibase/GBGB\"\"\"\n    race_id: str\n    finishers: List[Dict[str, Any]]  # List of {name, position, place_payout}\n\n\nclass AuditorEngine:\n    \"\"\"\n    Real-time verification engine that tracks predictions and verifies them\n    against official results.\n    \"\"\"\n\n    def __init__(self, db_path: str = \"audit.db\"):\n        self.db_path = db_path\n        self.http_client = httpx.AsyncClient(timeout=30.0, follow_redirects=True)\n        self.TOTE_UNIT = 2.00  # Standard $2.00 bet unit\n        self._running = False\n        self._init_database()\n\n        # Simple mapping for UK racecourses\n        self.TRACK_CODE_MAP = {\n            \"DON\": \"Doncaster\",\n            \"LING\": \"Lingfield\",\n            \"NCLE\": \"Newcastle\",\n            \"WOLV\": \"Wolverhampton\",\n            \"CHELT\": \"Cheltenham\",\n        }\n\n    def _init_database(self):\n        \"\"\"Initialize the SQLite database schema\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n\n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS audit_log (\n                race_id TEXT PRIMARY KEY,\n                track_code TEXT NOT NULL,\n                race_number INTEGER NOT NULL,\n                predicted_horse TEXT NOT NULL,\n                timestamp DATETIME NOT NULL,\n                status TEXT NOT NULL DEFAULT 'PENDING',\n                official_payout REAL DEFAULT 0.00,\n                net_profit REAL DEFAULT 0.00,\n                CHECK (status IN ('PENDING', 'CASHED', 'BURNED'))\n            )\n        \"\"\")\n\n        # Index for faster pending race queries\n        cursor.execute(\"\"\"\n            CREATE INDEX IF NOT EXISTS idx_status_timestamp\n            ON audit_log(status, timestamp)\n        \"\"\")\n\n        conn.commit()\n        conn.close()\n        logger.info(\"Database initialized\", db_path=self.db_path)\n\n    async def snapshot_qualifier(\n        self,\n        venue_code: str,\n        race_date: str,\n        race_number: int,\n        predicted_horse: str\n    ) -> bool:\n        \"\"\"\n        Phase 1: The Snapshot\n        Called by OddsEngine when a race qualifies as a bet.\n\n        Args:\n            venue_code: Track code (e.g., \"GP\", \"SA\")\n            race_date: Date in YYYYMMDD format\n            race_number: Race number\n            predicted_horse: Name of predicted horse\n\n        Returns:\n            True if snapshot saved, False if already exists\n        \"\"\"\n        race_id = self._generate_race_id(venue_code, race_date, race_number)\n\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n\n            cursor.execute(\"\"\"\n                INSERT INTO audit_log\n                (race_id, track_code, race_number, predicted_horse, timestamp, status)\n                VALUES (?, ?, ?, ?, ?, 'PENDING')\n            \"\"\", (race_id, venue_code, race_number, predicted_horse, datetime.now()))\n\n            conn.commit()\n            conn.close()\n\n            logger.info(\n                \"Snapshot saved for verification\",\n                race_id=race_id,\n                horse=predicted_horse\n            )\n            return True\n\n        except sqlite3.IntegrityError:\n            logger.warning(\"Race already tracked\", race_id=race_id)\n            return False\n\n    async def run_audit_loop(self):\n        \"\"\"\n        Phase 2: The Fetcher\n        Runs continuously to check results for pending races.\n        \"\"\"\n        self._running = True\n        logger.info(\"Audit loop started\")\n\n        while self._running:\n            try:\n                # Find pending races from the last 60 minutes\n                cutoff_time = datetime.now() - timedelta(minutes=60)\n                pending_races = self._get_pending_races(cutoff_time)\n\n                if not pending_races:\n                    logger.debug(\"No pending races to audit\")\n                    await asyncio.sleep(120)\n                    continue\n\n                logger.info(f\"Found {len(pending_races)} pending races to verify\")\n\n                # Fetch official results (batch by track to be polite)\n                tracks_to_check = set(race['track_code'] for race in pending_races)\n\n                for track_code in tracks_to_check:\n                    track_races = [r for r in pending_races if r['track_code'] == track_code]\n\n                    for race in track_races:\n                        official_result = await self._fetch_official_result(\n                            race['track_code'],\n                            race['race_number']\n                        )\n\n                        if official_result:\n                            self._determine_verdict(race, official_result)\n\n                        # Be polite to the server\n                        await asyncio.sleep(2)\n\n            except Exception as e:\n                logger.error(\"Error in audit loop\", error=str(e), exc_info=True)\n\n            await asyncio.sleep(120)\n\n    def stop_audit_loop(self):\n        \"\"\"Stop the audit loop gracefully\"\"\"\n        self._running = False\n        logger.info(\"Audit loop stopped\")\n\n    def _get_pending_races(self, cutoff_time: datetime) -> List[Dict]:\n        \"\"\"Get all pending races after cutoff time\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n        cursor = conn.cursor()\n\n        cursor.execute(\"\"\"\n            SELECT * FROM audit_log\n            WHERE status = 'PENDING' AND timestamp > ?\n            ORDER BY timestamp ASC\n        \"\"\", (cutoff_time,))\n\n        races = [dict(row) for row in cursor.fetchall()]\n        conn.close()\n\n        return races\n\n    def _determine_verdict(self, prediction: Dict, official_result: OfficialResult):\n        \"\"\"\n        Phase 3: The Verdict & Economics\n        Determine if prediction was correct and calculate profit/loss.\n        \"\"\"\n        did_place = False\n        payout = 0.00\n\n        # Check if our horse is in the official \"Place\" payouts\n        # Note: \"Place\" in US racing covers 1st and 2nd\n        for finisher in official_result.finishers:\n            if (finisher['name'].upper() == prediction['predicted_horse'].upper() and\n                finisher.get('place_payout', 0) > 0):\n                did_place = True\n                payout = finisher['place_payout']\n                break\n\n        # Calculate Net Profit based on $2.00 Unit\n        if did_place:\n            new_status = 'CASHED'\n            net_profit = payout - self.TOTE_UNIT\n            logger.info(\n                \"\ud83d\udcb0 CASHED\",\n                race_id=prediction['race_id'],\n                horse=prediction['predicted_horse'],\n                payout=payout,\n                profit=net_profit\n            )\n        else:\n            new_status = 'BURNED'\n            net_profit = -self.TOTE_UNIT  # Lost the $2.00 stake\n            logger.warning(\n                \"\ud83d\udd25 BURNED\",\n                race_id=prediction['race_id'],\n                horse=prediction['predicted_horse'],\n                loss=net_profit\n            )\n\n        # Update the Source of Truth\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n\n        cursor.execute(\"\"\"\n            UPDATE audit_log\n            SET status = ?, official_payout = ?, net_profit = ?\n            WHERE race_id = ?\n        \"\"\", (new_status, payout, net_profit, prediction['race_id']))\n\n        conn.commit()\n        conn.close()\n\n    async def _find_race_url(self, track_code: str, race_number: int) -> Optional[str]:\n        \"\"\"Finds the specific race URL from the main results page.\"\"\"\n        try:\n            base_url = \"https://www.attheraces.com\"\n            results_url = f\"{base_url}/results\"\n\n            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n            response = await self.http_client.get(results_url, headers=headers)\n            response.raise_for_status()\n\n            soup = BeautifulSoup(response.text, 'lxml')\n            track_name = self.TRACK_CODE_MAP.get(track_code.upper())\n            if not track_name:\n                logger.warning(\"Track code not mapped\", track_code=track_code)\n                return None\n\n            # Use a case-insensitive regex to make the search more robust\n            track_header = soup.find('h2', string=re.compile(track_name, re.IGNORECASE))\n            if not track_header:\n                logger.debug(\"Track not found on results page\", track_name=track_name)\n                return None\n\n            # Find the parent container of the track's results\n            track_container = track_header.find_parent(class_='panel')\n            if not track_container:\n                logger.debug(\"Could not find track container\", track_name=track_name)\n                return None\n\n            # Get all race links for that track and select by index\n            race_links = track_container.select('a[href*=\"/racecard/\"]')\n            if len(race_links) >= race_number:\n                race_path = race_links[race_number - 1]['href']\n                return f\"{base_url}{race_path}\"\n            else:\n                logger.debug(\"Race number out of bounds for track\", race_number=race_number, track_name=track_name)\n                return None\n\n        except Exception as e:\n            logger.error(\"Error finding race URL\", error=str(e), exc_info=True)\n            return None\n\n    async def _fetch_official_result(\n        self,\n        track_code: str,\n        race_number: int\n    ) -> Optional[OfficialResult]:\n        \"\"\"\n        Helper: Scraper Logic for attheraces.com\n        \"\"\"\n        try:\n            race_url = await self._find_race_url(track_code, race_number)\n            if not race_url:\n                return None\n\n            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n            response = await self.http_client.get(race_url, headers=headers)\n\n            if response.status_code == 404:\n                logger.debug(\"Results page not found (404)\", url=race_url)\n                return None\n\n            response.raise_for_status()\n\n            soup = BeautifulSoup(response.text, 'lxml')\n            race_result = self._parse_attheraces_results(soup, track_code, race_number)\n\n            if race_result:\n                logger.info(\"Official results fetched\", track=track_code, race=race_number)\n                return race_result\n            else:\n                logger.debug(\"Results not yet posted or parsed\", track=track_code, race=race_number)\n                return None\n\n        except httpx.HTTPError as e:\n            logger.warning(\"Failed to fetch results page\", url=getattr(e.request, 'url', ''), error=str(e))\n            return None\n        except Exception as e:\n            logger.error(\"Error parsing results\", track=track_code, race=race_number, error=str(e), exc_info=True)\n            return None\n\n    def _parse_attheraces_results(\n        self,\n        soup: BeautifulSoup,\n        track_code: str,\n        race_number: int\n    ) -> Optional[OfficialResult]:\n        \"\"\"\n        Parse attheraces.com HTML to extract race results using a table-based approach.\n        \"\"\"\n        results_table = None\n        all_tables = soup.find_all('table')\n        for table in all_tables:\n            header_cells = table.select('thead th')\n            if any(\"Horse\" in cell.text for cell in header_cells):\n                results_table = table\n                break\n\n        if not results_table:\n            logger.debug(\"Could not find a suitable results table on the page.\")\n            return None\n\n        finishers = []\n        rows = results_table.select('tbody tr')\n\n        for row in rows:\n            cells = row.find_all('td')\n            if len(cells) < 3:\n                continue\n\n            try:\n                pos_text = cells[0].text.strip()\n                try:\n                    position = int(pos_text)\n                except ValueError:\n                    position = 99\n\n                horse_name_el = cells[2].select_one('a[href*=\"/form/horse/\"]')\n                if not horse_name_el:\n                    continue\n\n                horse_name = horse_name_el.text.strip()\n\n                finisher = {\n                    'name': horse_name,\n                    'position': position,\n                    'place_payout': 0.0,\n                }\n                finishers.append(finisher)\n\n            except (ValueError, IndexError) as e:\n                logger.warning(\"Could not parse a result row\", error=str(e))\n                continue\n\n        if not finishers:\n            logger.debug(\"Table found, but could not parse any finishers.\")\n            return None\n\n        win_payout = 0.0\n        try:\n            betting_returns_header = soup.find('h3', string=re.compile(r'Betting returns'))\n            if betting_returns_header:\n                betting_returns_table = betting_returns_header.find_next('table')\n                if betting_returns_table:\n                    win_row = betting_returns_table.find('td', string=re.compile(r'Win'))\n                    if win_row:\n                        payout_str = win_row.find_next_sibling('td').text\n                        payout_match = re.search(r'[\\d\\.]+', payout_str)\n                        if payout_match:\n                            win_payout = float(payout_match.group(0))\n        except Exception as e:\n            logger.warning(\"Could not parse win payout\", error=str(e))\n\n        for f in finishers:\n            if f['position'] == 1:\n                f['place_payout'] = win_payout\n                break\n\n        race_id = self._generate_race_id(track_code, datetime.now().strftime(\"%Y%m%d\"), race_number)\n        return OfficialResult(race_id=race_id, finishers=finishers)\n\n    def _generate_race_id(self, venue_code: str, race_date: str, race_number: int) -> str:\n        \"\"\"Generate unique race ID\"\"\"\n        return f\"{venue_code.upper()}-{race_date}-{race_number:02d}\"\n\n    def get_rolling_metrics(self, minutes: int = 60) -> Dict[str, Any]:\n        \"\"\"\n        Phase 4: Dashboard Metrics\n        Returns stats for the UI \"Last Hour\" overlay.\n\n        Args:\n            minutes: Rolling window in minutes (default 60)\n\n        Returns:\n            Dictionary with strike_rate, net_profit, and volume\n        \"\"\"\n        cutoff = datetime.now() - timedelta(minutes=minutes)\n\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n\n        cursor.execute(\"\"\"\n            SELECT\n                COUNT(*) as total,\n                SUM(CASE WHEN status = 'CASHED' THEN 1 ELSE 0 END) as wins,\n                SUM(net_profit) as profit\n            FROM audit_log\n            WHERE timestamp > ? AND status != 'PENDING'\n        \"\"\", (cutoff,))\n\n        row = cursor.fetchone()\n        conn.close()\n\n        total = row[0] or 0\n        wins = row[1] or 0\n        profit = row[2] or 0.0\n\n        strike_rate = (wins / total * 100) if total > 0 else 0.0\n\n        return {\n            \"strike_rate\": round(strike_rate, 2),\n            \"net_profit\": round(profit, 2),\n            \"volume\": total,\n            \"window_minutes\": minutes\n        }\n\n    def get_recent_activity(self, limit: int = 10) -> List[Dict]:\n        \"\"\"Get recent audit activity for display\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n        cursor = conn.cursor()\n\n        cursor.execute(\"\"\"\n            SELECT * FROM audit_log\n            ORDER BY timestamp DESC\n            LIMIT ?\n        \"\"\", (limit,))\n\n        activity = [dict(row) for row in cursor.fetchall()]\n        conn.close()\n\n        return activity\n\n    async def cleanup(self):\n        \"\"\"Cleanup resources\"\"\"\n        self.stop_audit_loop()\n        await self.http_client.aclose()\n        logger.info(\"Auditor engine cleaned up\")\n\n\nasync def smoke_test_auditor():\n    \"\"\"A simple test to verify the new scraper logic.\"\"\"\n    logger.info(\"Starting Auditor smoke test...\")\n    auditor = AuditorEngine(db_path=\"smoke_test_audit.db\")\n\n    # We need a race that has results. Let's assume Doncaster, Race 1.\n    track_code = \"DON\"\n    race_number = 1\n\n    logger.info(f\"Attempting to fetch results for {track_code} Race {race_number}\")\n\n    # Directly call the fetcher\n    official_result = await auditor._fetch_official_result(track_code, race_number)\n\n    if official_result and official_result.finishers:\n        logger.info(\"Smoke test PASSED. Successfully fetched and parsed results.\")\n        print(\"\\n--- SMOKE TEST RESULTS ---\")\n        print(f\"Race ID: {official_result.race_id}\")\n        print(\"Finishers:\")\n        for finisher in official_result.finishers:\n            print(f\"  Position: {finisher['position']}, Name: {finisher['name']}, Payout: {finisher['place_payout']}\")\n        print(\"------------------------\\n\")\n    else:\n        logger.error(\"Smoke test FAILED. Could not fetch or parse results.\")\n        print(\"\\n--- SMOKE TEST FAILED ---\")\n        print(\"No results were returned. Check the logs for errors.\")\n        print(\"-----------------------\\n\")\n\n    await auditor.cleanup()\n    # Clean up the test database\n    import os\n    if os.path.exists(\"smoke_test_audit.db\"):\n        os.remove(\"smoke_test_audit.db\")\n\nif __name__ == \"__main__\":\n    # To run the smoke test: python -m python_service.auditor\n    structlog.configure(\n        processors=[\n            structlog.processors.add_log_level,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.dev.ConsoleRenderer(),\n        ]\n    )\n    asyncio.run(smoke_test_auditor())\n",
    "python_service/cache_manager.py": "# python_service/cache_manager.py\nimport asyncio\nimport hashlib\nimport json\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom functools import wraps\nfrom typing import Any\nfrom typing import Callable\n\nimport structlog\n\ntry:\n    import redis\n\n    REDIS_AVAILABLE = True\nexcept ImportError:\n    REDIS_AVAILABLE = False\n\nlog = structlog.get_logger(__name__)\n\n\nclass CacheManager:\n    def __init__(self):\n        self.redis_client = None\n        self.memory_cache = {}\n        self.is_configured = False\n        log.info(\"CacheManager initialized (not connected).\")\n\n    async def connect(self, redis_url: str):\n        if self.is_configured or not REDIS_AVAILABLE or not redis_url:\n            return\n\n        try:\n            log.info(\"Attempting to connect to Redis...\", url=redis_url)\n            # Use the async version of the client\n            self.redis_client = redis.asyncio.from_url(redis_url, decode_responses=True)\n            await self.redis_client.ping()  # Verify connection asynchronously\n            self.is_configured = True\n            log.info(\"Redis cache connected successfully.\")\n        except (redis.exceptions.ConnectionError, asyncio.TimeoutError) as e:\n            log.warning(\n                \"Failed to connect to Redis. Falling back to in-memory cache.\",\n                error=str(e),\n            )\n            self.redis_client = None\n            self.is_configured = False\n\n    async def disconnect(self):\n        if self.redis_client:\n            await self.redis_client.close()\n            log.info(\"Redis connection closed.\")\n\n    def _generate_key(self, prefix: str, *args, **kwargs) -> str:\n        key_data = f\"{prefix}:{args}:{sorted(kwargs.items())}\"\n        return hashlib.md5(key_data.encode()).hexdigest()\n\n    async def get(self, key: str) -> Any | None:\n        if self.redis_client:\n            try:\n                value = await self.redis_client.get(key)\n                return json.loads(value) if value else None\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis GET failed, falling back to memory cache.\", error=e)\n\n        entry = self.memory_cache.get(key)\n        if entry and entry.get(\"expires_at\", datetime.min) > datetime.now():\n            return entry.get(\"value\")\n        return None\n\n    async def set(self, key: str, value: Any, ttl_seconds: int = 300):\n        try:\n            serialized = json.dumps(value, default=str)\n        except (TypeError, ValueError) as e:\n            log.error(\"Failed to serialize value for caching.\", value=value, error=str(e))\n            return\n\n        if self.redis_client:\n            try:\n                await self.redis_client.setex(key, ttl_seconds, serialized)\n                return\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis SET failed, falling back to memory cache.\", error=e)\n\n        self.memory_cache[key] = {\n            \"value\": value,\n            \"expires_at\": datetime.now() + timedelta(seconds=ttl_seconds),\n        }\n\n\n# --- Singleton Instance & Decorator ---\ncache_manager = CacheManager()\n\n\ndef cache_async_result(ttl_seconds: int = 300, key_prefix: str = \"cache\"):\n    def decorator(func: Callable):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            instance_args = args[1:] if args and hasattr(args[0], func.__name__) else args\n            cache_key = cache_manager._generate_key(f\"{key_prefix}:{func.__name__}\", *instance_args, **kwargs)\n\n            cached_result = await cache_manager.get(cache_key)\n            if cached_result is not None:\n                log.debug(\"Cache hit\", function=func.__name__)\n                return cached_result\n\n            log.debug(\"Cache miss\", function=func.__name__)\n            result = await func(*args, **kwargs)\n\n            try:\n                await cache_manager.set(cache_key, result, ttl_seconds)\n            except Exception as e:\n                log.error(\"Failed to store result in cache.\", error=str(e), key=cache_key)\n\n            return result\n\n        return wrapper\n\n    return decorator\n",
    "python_service/credentials_manager.py": "# python_service/credentials_manager.py\ntry:\n    import keyring\n\n    # This check is crucial for cross-platform compatibility\n    import keyring.backends.windows\n\n    IS_WINDOWS = True\nexcept ImportError:\n    keyring = None\n    IS_WINDOWS = False\n\n\nclass SecureCredentialsManager:\n    \"\"\"Manages secrets in the system's native credential store.\"\"\"\n\n    SERVICE_NAME = \"Fortuna\"\n\n    @staticmethod\n    def save_credential(account: str, secret: str) -> bool:\n        \"\"\"Saves a secret for a given account (e.g., 'api_key', 'betfair_username').\"\"\"\n        if not IS_WINDOWS:\n            print(\"Credential storage is only supported on Windows.\")\n            return False\n        try:\n            keyring.set_password(SecureCredentialsManager.SERVICE_NAME, account, secret)\n            return True\n        except Exception as e:\n            print(f\"\u274c Failed to save credential for {account}: {e}\")\n            return False\n\n    @staticmethod\n    def get_credential(account: str) -> str:\n        \"\"\"Retrieves a secret for a given account.\"\"\"\n        if not IS_WINDOWS:\n            return None\n        try:\n            return keyring.get_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception as e:\n            print(f\"\u274c Failed to retrieve credential for {account}: {e}\")\n            return None\n\n    @staticmethod\n    def get_betfair_credentials() -> tuple[str, str]:\n        \"\"\"Convenience method to retrieve both Betfair username and password.\"\"\"\n        username = SecureCredentialsManager.get_credential(\"betfair_username\")\n        password = SecureCredentialsManager.get_credential(\"betfair_password\")\n        return username, password\n\n    @staticmethod\n    def delete_credential(account: str):\n        \"\"\"Deletes a specific credential.\"\"\"\n        if not IS_WINDOWS:\n            return\n        try:\n            keyring.delete_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception:\n            pass\n",
    "python_service/fortuna_windows_service.py": "# fortuna_windows_service.py\n\nimport logging\nimport os\nimport sys\n\nimport servicemanager\nimport win32event\nimport win32service\nimport win32serviceutil\n\n# Ensure the script's directory is at the front of the path\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.insert(0, script_dir)\n\ntry:\n    from fortuna_service import FortunaBackgroundService\nexcept ImportError as e:\n    # Log a detailed error to the Windows Event Log if the import fails\n    servicemanager.LogErrorMsg(f\"FATAL: Could not import FortunaBackgroundService. Error: {e}\")\n    sys.exit(1)  # Exit with an error code\n\n\nclass FortunaWindowsService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaV8Service\"\n    _svc_display_name_ = \"Fortuna V8 Racing Analysis Service\"\n    _svc_description_ = \"Continuously fetches and analyzes horse racing data.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)\n        self.fortuna_service = FortunaBackgroundService()\n        # Configure logging to use the Windows Event Log\n        logging.basicConfig(\n            level=logging.INFO,\n            format=\"%(name)s - %(levelname)s - %(message)s\",\n            handlers=[servicemanager.LogHandler()],\n        )\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        self.fortuna_service.stop()\n        win32event.SetEvent(self.hWaitStop)\n        self.ReportServiceStatus(win32service.SERVICE_STOPPED)\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(\n            servicemanager.EVENTLOG_INFORMATION_TYPE,\n            servicemanager.PYS_SERVICE_STARTED,\n            (self._svc_name_, \"\"),\n        )\n        self.main()\n\n    def main(self):\n        self.fortuna_service.start()\n        win32event.WaitForSingleObject(self.hWaitStop, win32event.INFINITE)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaWindowsService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaWindowsService)\n",
    "python_service/main.py": "import uvicorn\nimport sys\nimport os\nimport asyncio\nfrom multiprocessing import freeze_support\n\n# Force UTF-8 encoding for stdout and stderr, crucial for PyInstaller on Windows\nos.environ[\"PYTHONUTF8\"] = \"1\"\n\n# Import the 'app' object at the top level to make it accessible for import by other modules,\n# such as diagnostic scripts in CI/CD.\nfrom python_service.api import app, HTTPException\n\n# This is the definitive entry point for the Fortuna Faucet backend service.\n# It is designed to be compiled with PyInstaller.\n\n\ndef _configure_sys_path():\n    \"\"\"\n    Dynamically adds project paths to sys.path.\n    This is the robust solution to ensure that string-based imports like\n    \"web_service.backend.api:app\" work correctly when the application is\n    run from a PyInstaller executable. The `_MEIPASS` attribute is a temporary\n    directory created by PyInstaller at runtime.\n    \"\"\"\n    if getattr(sys, \"frozen\", False) and hasattr(sys, \"_MEIPASS\"):\n        # Running in a PyInstaller bundle. The project root is the _MEIPASS directory.\n        project_root = os.path.abspath(sys._MEIPASS)\n\n        # Aggressively add paths to resolve potential module lookup issues in frozen mode.\n        paths_to_add = [\n            project_root,\n            os.path.join(project_root, \"python_service\"),\n        ]\n\n        # Insert paths at the beginning of sys.path in reverse order\n        # to maintain the desired precedence.\n        for path in reversed(paths_to_add):\n            if path not in sys.path:\n                sys.path.insert(0, path)\n                print(f\"INFO: Added path to sys.path: {path}\")\n\n    else:\n        # Running as a normal script. The project root is one level up.\n        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n        if project_root not in sys.path:\n            sys.path.insert(0, project_root)\n            print(f\"INFO: Added project root to sys.path: {project_root}\")\n\n\ndef main():\n    \"\"\"\n    Primary entry point for the Fortuna Faucet backend application.\n    This function configures and runs the Uvicorn server.\n    It's crucial to launch the app this way to ensure PyInstaller's bootloader\n    can correctly resolve the package context.\n    \"\"\"\n    # CRITICAL: This must be called before any other application imports.\n    _configure_sys_path()\n\n    # When packaged, we need to ensure multiprocessing works correctly.\n    if getattr(sys, \"frozen\", False):\n        # CRITICAL for multiprocessing support in frozen mode on Windows.\n        freeze_support()\n\n        # \u2705 CRITICAL FIX: Set event loop policy BEFORE any imports that use asyncio\n        if sys.platform == \"win32\":\n            import asyncio\n            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n            print(\"[BOOT] \u2705 Applied WindowsSelectorEventLoopPolicy for PyInstaller\", file=sys.stderr)\n\n    from python_service.config import get_settings\n    from fastapi.staticfiles import StaticFiles\n    from fastapi.responses import FileResponse\n    from python_service.port_check import check_port_and_exit_if_in_use\n\n    settings = get_settings()\n\n    # --- Port Sanity Check ---\n    # Before doing anything else, ensure the target port is not already in use.\n    # This prevents a common and confusing crash scenario on startup.\n    check_port_and_exit_if_in_use(settings.FORTUNA_PORT, settings.UVICORN_HOST)\n\n    # --- Conditional UI Serving for Web Service Mode ---\n    # Only serve the UI if the FORTUNA_MODE environment variable is set to 'webservice'.\n    # This prevents the Electron-packaged backend from trying to serve files it doesn't have.\n    if os.environ.get(\"FORTUNA_MODE\") == \"webservice\":\n        # Define the path to the static UI files, accommodating PyInstaller's bundle.\n        if getattr(sys, \"frozen\", False):\n            # In a bundled app, the UI files are in the '_MEIPASS/ui' directory.\n            STATIC_DIR = os.path.join(sys._MEIPASS, \"ui\")\n        else:\n            # In development, they are in the frontend's output directory.\n            STATIC_DIR = os.path.abspath(\n                os.path.join(os.path.dirname(__file__), \"..\", \"web_platform\", \"frontend\", \"out\")\n            )\n\n        # Mount the static assets directory for CSS, JS, etc.\n        if os.path.exists(os.path.join(STATIC_DIR, \"_next\")):\n            app.mount(\"/_next\", StaticFiles(directory=os.path.join(STATIC_DIR, \"_next\")), name=\"next\")\n\n        # Serve the main index.html for any non-API path.\n        @app.get(\"/{full_path:path}\", include_in_schema=False)\n        async def serve_frontend(full_path: str):\n            if full_path.startswith(\"api/\") or full_path.startswith(\"docs\") or full_path == \"health\":\n                # This is an API route, let FastAPI handle it.\n                # A 404 will be raised naturally if no route matches.\n                return\n\n            index_path = os.path.join(STATIC_DIR, \"index.html\")\n            if os.path.exists(index_path):\n                return FileResponse(index_path)\n            else:\n                # This will only be hit if the frontend files are missing entirely.\n                raise HTTPException(\n                    status_code=404,\n                    detail=\"Frontend not found. Please build the frontend and ensure it's in the correct location.\",\n                )\n\n    uvicorn.run(app, host=settings.UVICORN_HOST, port=settings.FORTUNA_PORT, log_level=\"info\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "python_service/models_v3.py": "# python_service/models_v3.py\n# Defines the data structures for the V3 adapter architecture.\n\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import List\n\n\n@dataclass\nclass NormalizedRunner:\n    runner_id: str\n    name: str\n    saddle_cloth: str\n    odds_decimal: float\n\n\n@dataclass\nclass NormalizedRace:\n    race_key: str\n    track_key: str\n    start_time_iso: str\n    race_name: str\n    runners: List[NormalizedRunner] = field(default_factory=list)\n    source_ids: List[str] = field(default_factory=list)\n",
    "python_service/requirements_minimal.txt": "httpx==0.25.0\nstructlog==23.2.0\npydantic==2.5.0\nuvicorn==0.24.0\nfastapi==0.104.1\ntenacity==8.2.3\n",
    "python_service/security.py": "# python_service/security.py\n\nimport secrets\n\nfrom fastapi import Depends\nfrom fastapi import HTTPException\nfrom fastapi import Security\nfrom fastapi import status\nfrom fastapi.security import APIKeyHeader\n\nfrom .config import Settings\nfrom .config import get_settings\n\nAPI_KEY_NAME = \"X-API-Key\"\napi_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)\n\n\nasync def verify_api_key(key: str = Security(api_key_header), settings: Settings = Depends(get_settings)):\n    \"\"\"\n    Verifies the provided API key against the one in settings using a\n    timing-attack resistant comparison.\n    \"\"\"\n    if secrets.compare_digest(key, settings.API_KEY):\n        return True\n    else:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Invalid or missing API Key\")\n",
    "python_service/utils/text.py": "# python_service/utils/text.py\n# Centralized text and name normalization utilities\nimport re\nfrom typing import Optional\n\n\ndef clean_text(text: Optional[str]) -> Optional[str]:\n    \"\"\"Strips leading/trailing whitespace and collapses internal whitespace.\"\"\"\n    if not text:\n        return None\n    return \" \".join(text.strip().split())\n\n\ndef normalize_venue_name(name: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Normalizes a UK or Irish racecourse name to a standard format.\n    Handles common abbreviations and variations.\n    \"\"\"\n    if not name:\n        return None\n\n    # Use a temporary variable for matching, but return the properly cased name\n    cleaned_name_upper = clean_text(name).upper()\n\n    VENUE_MAP = {\n        \"ASCOT\": \"Ascot\",\n        \"AYR\": \"Ayr\",\n        \"BANGOR-ON-DEE\": \"Bangor-on-Dee\",\n        \"CATTERICK BRIDGE\": \"Catterick\",\n        \"CHELMSFORD CITY\": \"Chelmsford\",\n        \"EPSOM DOWNS\": \"Epsom\",\n        \"FONTWELL\": \"Fontwell Park\",\n        \"HAYDOCK\": \"Haydock Park\",\n        \"KEMPTON\": \"Kempton Park\",\n        \"LINGFIELD\": \"Lingfield Park\",\n        \"NEWMARKET (ROWLEY)\": \"Newmarket\",\n        \"NEWMARKET (JULY)\": \"Newmarket\",\n        \"SANDOWN\": \"Sandown Park\",\n        \"STRATFORD\": \"Stratford-on-Avon\",\n        \"YARMOUTH\": \"Great Yarmouth\",\n        \"CURRAGH\": \"Curragh\",\n        \"DOWN ROYAL\": \"Down Royal\",\n    }\n\n    # Check primary map first\n    if cleaned_name_upper in VENUE_MAP:\n        return VENUE_MAP[cleaned_name_upper]\n\n    # Handle cases where the key is the desired output but needs to be mapped from a variation\n    # e.g. CHELMSFORD maps to Chelmsford\n    # Title case the cleaned name for a sensible default\n    title_cased_name = clean_text(name).title()\n    if title_cased_name in VENUE_MAP.values():\n        return title_cased_name\n\n    # Return the title-cased cleaned name as a fallback\n    return title_cased_name\n\n\ndef normalize_course_name(name: str) -> str:\n    if not name:\n        return \"\"\n    name = name.lower().strip()\n    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s-]+\", \"_\", name)\n    return name\n",
    "scripts/generate_spec_dual.py": "# scripts/generate_spec_dual.py\n# A unified, intelligent spec generator by Jules 1221\n# This script generates distinct PyInstaller specs for different build modes.\n\nimport argparse\nimport os\nimport sys\nimport subprocess\nfrom pathlib import Path\n\n# Fix for UnicodeEncodeError on Windows runners with special characters in logs\nif sys.platform == 'win32':\n    try:\n        # This is the most reliable way to ensure UTF-8 output on Windows\n        sys.stdout.reconfigure(encoding='utf-8')\n        sys.stderr.reconfigure(encoding='utf-8')\n    except TypeError:\n        # In some environments (like older Python versions or certain terminals),\n        # reconfigure might not be available. We fall back to a less ideal but\n        # still helpful method.\n        import codecs\n        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')\n        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')\n\ndef generate_spec(mode: str):\n    \"\"\"\n    Generates a PyInstaller spec file based on the specified mode ('ui' or 'svc').\n    \"\"\"\n    print(f\"--- \ud83d\udc0d Unified Spec Generator (Mode: {mode}) ---\")\n\n    # 1. Determine configuration based on mode\n    if mode == 'ui':\n        binary_name = 'fortuna-ui-bridge'\n        entry_point_name = 'main.py'\n        is_console = True  # Electron bridge needs console for stdio\n        datas = f\"[('{frontend_dist.as_posix()}', 'frontend_dist')]\"\n        hidden_imports = \"\"\"[\n        'uvicorn',\n        'fastapi',\n        'starlette',\n        'anyio',\n        'pydantic',\n        'uvicorn.logging',\n        'uvicorn.loops.auto',\n        'uvicorn.protocols.http.auto',\n        'win32timezone'\n    ]\"\"\"\n    elif mode == 'svc':\n        binary_name = 'fortuna-core-service'\n        entry_point_name = 'service_entry.py' # Dedicated Windows Service entry\n        is_console = False # Windows Service should be a GUI app\n        datas = \"[]\" # Service does not bundle the UI\n        hidden_imports = \"\"\"[\n        'uvicorn',\n        'fastapi',\n        'starlette',\n        'anyio',\n        'pydantic',\n        'uvicorn.logging',\n        'uvicorn.loops.auto',\n        'uvicorn.protocols.http.auto',\n        'win32timezone',\n        'win32serviceutil',\n        'win32service',\n        'win32event'\n    ]\"\"\"\n    else:\n        print(f\"\u274c Invalid mode specified: {mode}. Use 'ui' or 'svc'.\")\n        sys.exit(1)\n\n    print(f\"Binary Name: {binary_name}\")\n    print(f\"Entry Point: {entry_point_name}\")\n\n    # 2. Path Validation\n    script_dir = Path(__file__).parent.resolve()\n    project_root = script_dir.parent.resolve()\n    entry_point = project_root / \"web_service\" / \"backend\" / entry_point_name\n    frontend_dist = project_root / \"web_platform\" / \"frontend\" / \"out\"\n\n    if not entry_point.exists():\n        print(f\"\u274c Entry point not found: {entry_point}\")\n        sys.exit(1)\n\n    # 3. Locate critical DLLs\n    python_home = Path(sys.base_prefix)\n    dlls_to_bundle = [\n        python_home / 'python311.dll',\n        python_home / 'vcruntime140.dll'\n    ]\n    binaries = []\n    for dll_path in dlls_to_bundle:\n        if dll_path.exists():\n            binaries.append((str(dll_path).replace('\\\\\\\\', '/'), '.'))\n            print(f\"\u2705 Found required DLL: {dll_path}\")\n        else:\n             print(f\"\u26a0\ufe0f Could not find optional DLL, skipping: {dll_path}\")\n\n    # 4. Define the spec file content\n    spec_content = f\"\"\"\n# -*- mode: python ; coding: utf-8 -*-\n# Generated by scripts/generate_spec_dual.py (Mode: {mode})\n\nblock_cipher = None\n\na = Analysis(\n    ['{entry_point.as_posix()}'],\n    pathex=['{project_root.as_posix()}'],\n    binaries={binaries},\n    datas={datas},\n    hiddenimports={hidden_imports},\n    hookspath=[],\n    runtime_hooks=[],\n    excludes=['python_service'],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz,\n    a.scripts,\n    [],\n    exclude_binaries=True,\n    name='{binary_name}',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    console={is_console},\n    icon=None,\n)\n\ncoll = COLLECT(\n    exe,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    name='{binary_name}',\n)\n\"\"\"\n\n    # 5. Write the spec file\n    spec_path = project_root / f\"{binary_name}.spec\"\n    print(f\"--- Writing spec file to {spec_path} ---\")\n    with open(spec_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(spec_content)\n    print(f\"\u2705 Spec file created.\")\n\n    # 6. Run PyInstaller\n    print(\"--- Running PyInstaller build ---\")\n    cmd = [\n        sys.executable,\n        \"-m\", \"PyInstaller\",\n        str(spec_path),\n        \"--clean\",\n        \"--noconfirm\",\n        \"--log-level\", \"WARN\"\n    ]\n    print(f\"Executing command: {' '.join(cmd)}\")\n\n    try:\n        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8')\n        print(\"\u2705 PyInstaller build successful.\")\n        print(result.stdout)\n    except subprocess.CalledProcessError as e:\n        print(\"\u274c PyInstaller build failed!\")\n        print(\"--- STDOUT ---\")\n        print(e.stdout)\n        print(\"--- STDERR ---\")\n        print(e.stderr)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Generate a PyInstaller spec file for different build modes.\")\n    parser.add_argument('--mode', required=True, choices=['ui', 'svc'], help=\"The build mode: 'ui' for Electron bridge or 'svc' for Windows Service.\")\n    args = parser.parse_args()\n    generate_spec(args.mode)\n",
    "scripts/realtime-race-monitor.ps1": "<#\n.SYNOPSIS\n    Fortuna Real-Time Race Monitor (v1.0)\n    Builds, launches, and queries the backend service to provide live racecard comparisons.\n#>\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Configuration ---\n$PYTHON_VERSION = \"3.11\"\n$BACKEND_DIR    = \"web_service/backend\"\n$SPEC_FILE      = \"fortuna-unified.spec\"\n$SERVICE_PORT   = 8102\n$API_KEY        = \"a_secure_test_api_key_that_is_long_enough\" # Mock key for local execution\n\n# --- Helper Functions ---\nfunction Show-Step($msg) { Write-Host \"`n\ud83d\ude80 $msg\" -ForegroundColor Cyan }\nfunction Show-Success($msg) { Write-Host \"   \u2705 $msg\" -ForegroundColor Green }\nfunction Show-Warn($msg) { Write-Host \"   \u26a0\ufe0f  $msg\" -ForegroundColor Yellow }\nfunction Show-Fail($msg) { Write-Host \"   \u274c $msg\" -ForegroundColor Red; exit 1 }\n\n# --- Main Execution ---\ntry {\n    # 1. Environment Setup & Dependency Installation\n    Show-Step \"Preparing environment...\"\n    try {\n        $pyVer = & python --version 2>&1\n        if ($pyVer -notmatch $PYTHON_VERSION) {\n            Show-Warn \"Python version mismatch. Expected $($PYTHON_VERSION), found $($pyVer).\"\n        }\n        Show-Success \"Found Python: $pyVer\"\n    } catch {\n        Show-Fail \"Python not found. Please ensure Python $($PYTHON_VERSION) is in your PATH.\"\n    }\n\n    Show-Step \"Installing dependencies...\"\n    try {\n        python -m pip install --upgrade pip --quiet\n        pip install -r \"$($BACKEND_DIR)/requirements.txt\"\n        pip install pyinstaller==6.6.0\n        Show-Success \"All Python dependencies are installed.\"\n    } catch {\n        Show-Fail \"Failed to install dependencies. Check logs for details.\"\n    }\n\n\n    # 2. Build the Backend Executable\n    Show-Step \"Building backend executable with PyInstaller...\"\n\n    # Clean previous builds\n    if (Test-Path \"dist\") { Remove-Item -Recurse -Force \"dist\" }\n    if (Test-Path \"build\") { Remove-Item -Recurse -Force \"build\" }\n\n    # PyInstaller requires these directories to exist at build time\n    New-Item -ItemType Directory -Path \"$($BACKEND_DIR)/data\", \"$($BACKEND_DIR)/json\", \"$($BACKEND_DIR)/logs\" -Force | Out-Null\n\n    try {\n        pyinstaller --noconfirm --clean $SPEC_FILE\n        Show-Success \"Backend executable built successfully.\"\n    } catch {\n        Show-Fail \"PyInstaller build failed. See output for details.\"\n    }\n\n    # 3. Launch the Backend Service\n    Show-Step \"Launching backend service...\"\n    $exePath = Resolve-Path \"dist/fortuna-webservice/fortuna-webservice.exe\"\n    if (-not (Test-Path $exePath)) {\n        Show-Fail \"Could not find the built executable at $($exePath).\"\n    }\n\n    # The executable needs its runtime directories in its own folder\n    $exeDir = Split-Path $exePath -Parent\n    New-Item -ItemType Directory -Path \"$($exeDir)/data\", \"$($exeDir)/json\", \"$($exeDir)/logs\" -Force | Out-Null\n    Show-Success \"Created runtime directories in $($exeDir).\"\n\n    # Start the process in the background\n    $process = Start-Process -FilePath $exePath -WindowStyle Hidden -PassThru\n    $Global:BackendProcessId = $process.Id # Store PID for cleanup\n    Show-Success \"Backend service is starting in the background (PID: $($Global:BackendProcessId)).\"\n\n\n    # 4. Health Check & API Query\n    Show-Step \"Waiting for service to become healthy...\"\n    $healthUrl = \"http://localhost:$($SERVICE_PORT)/health\"\n    $maxRetries = 20\n    $retryDelay = 3 # seconds\n\n    for ($i = 0; $i -lt $maxRetries; $i++) {\n        try {\n            $response = Invoke-WebRequest -Uri $healthUrl -UseBasicParsing\n            if ($response.StatusCode -eq 200) {\n                Show-Success \"Service is healthy and responding.\"\n                break\n            }\n        } catch {\n            Write-Host \"   ... waiting ($($i+1)/$($maxRetries))\"\n            Start-Sleep -Seconds $retryDelay\n        }\n        if ($i -eq $maxRetries - 1) {\n            Show-Fail \"Service failed to start within the timeout period.\"\n        }\n    }\n\n    Show-Step \"Querying API for live race data...\"\n    $racesUrl = \"http://localhost:$($SERVICE_PORT)/api/races\"\n    $headers = @{ \"X-API-Key\" = $API_KEY }\n    try {\n        $apiResponse = Invoke-RestMethod -Uri $racesUrl -Headers $headers -Method Get\n        Show-Success \"Successfully fetched data for $($apiResponse.races.Count) races.\"\n    } catch {\n        Show-Fail \"Failed to query the API. Error: $($_.Exception.Message)\"\n    }\n\n\n    # 5. Process and Format Data\n    Show-Step \"Formatting race comparison...\"\n    $now = [datetime]::UtcNow\n    $upcomingRaces = $apiResponse.races | Where-Object { [datetime]$_.startTime -gt $now } | Sort-Object startTime | Select-Object -First 3\n\n    $output = @()\n    $output += \"--- Fortuna Real-Time Race Monitor ---\"\n    $output += \"Generated: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss UTC')\"\n    $output += \"========================================\"\n\n    foreach ($race in $upcomingRaces) {\n        $raceTime = [datetime]$race.startTime\n        $timeToPost = New-TimeSpan -Start $now -End $raceTime\n        $output += \"\"\n        $output += \"$($race.venue) - Race $($race.race_number) ($($raceTime.ToLocalTime().ToString('h:mm tt')))\"\n        $output += \"Starts in: $($timeToPost.Minutes)m $($timeToPost.Seconds)s\"\n        $output += \"----------------------------------------\"\n        $output += \"{0,-25} {1,-15} {2,-15}\" -f \"Runner\", \"Best Odds\", \"Source\"\n        $output += \"{0,-25} {1,-15} {2,-15}\" -f \"-----\", \"---------\", \"------\"\n\n        foreach ($runner in $race.runners) {\n            $bestOdds = $null\n            $bestSource = \"N/A\"\n            if ($runner.odds) {\n                $oddsValues = $runner.odds.psobject.Properties | ForEach-Object { $_.Value }\n                if($oddsValues) {\n                    $best = $oddsValues | Sort-Object win -Descending | Select-Object -First 1\n                    if($best -and $best.win){\n                        $bestOdds = $best.win\n                        $bestSource = $best.source\n                    }\n                }\n            }\n            $output += \"{0,-25} {1,-15} {2,-15}\" -f $runner.name, $bestOdds, $bestSource\n        }\n    }\n\n    $output += \"========================================\"\n\n    # Display the formatted output in the console\n    $output | Out-Host\n\n} finally {\n    # 6. Cleanup\n    Show-Step \"Cleaning up...\"\n    if ($Global:BackendProcessId) {\n        try {\n            Stop-Process -Id $Global:BackendProcessId -Force\n            Show-Success \"Backend service (PID: $($Global:BackendProcessId)) stopped.\"\n        } catch {\n            Show-Warn \"Could not stop backend service (PID: $($Global:BackendProcessId)). It may have already exited.\"\n        }\n    } else {\n        Show-Success \"No backend process to stop.\"\n    }\n}\n",
    "web_platform/api_gateway/package.json": "{\n  \"name\": \"api_gateway\",\n  \"version\": \"1.0.0\",\n  \"main\": \"dist/server.js\",\n  \"scripts\": { \"start\": \"ts-node src/server.ts\" },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"dotenv\": \"^16.3.1\",\n    \"dotenv\": \"^16.3.1\",\n    \"sqlite\": \"^5.1.1\",\n    \"sqlite3\": \"^5.1.7\",\n    \"socket.io\": \"^4.7.4\",\n    \"cors\": \"^2.8.5\"\n  },\n  \"devDependencies\": {\n    \"@types/express\": \"^4.17.21\",\n    \"@types/node\": \"^20.10.0\",\n    \"@types/cors\": \"^2.8.17\",\n    \"ts-node\": \"^10.9.2\",\n    \"typescript\": \"^5.3.3\"\n  }\n}",
    "web_platform/frontend/app/globals.css": "@tailwind base;\n@tailwind components;\n@tailwind utilities;",
    "web_platform/frontend/postcss.config.js": "module.exports = {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n};",
    "web_platform/frontend/public/workbox-4754cb34.js": "define([\"exports\"],function(t){\"use strict\";try{self[\"workbox:core:6.5.4\"]&&_()}catch(t){}const e=(t,...e)=>{let s=t;return e.length>0&&(s+=` :: ${JSON.stringify(e)}`),s};class s extends Error{constructor(t,s){super(e(t,s)),this.name=t,this.details=s}}try{self[\"workbox:routing:6.5.4\"]&&_()}catch(t){}const n=t=>t&&\"object\"==typeof t?t:{handle:t};class r{constructor(t,e,s=\"GET\"){this.handler=n(e),this.match=t,this.method=s}setCatchHandler(t){this.catchHandler=n(t)}}class i extends r{constructor(t,e,s){super(({url:e})=>{const s=t.exec(e.href);if(s&&(e.origin===location.origin||0===s.index))return s.slice(1)},e,s)}}class a{constructor(){this.t=new Map,this.i=new Map}get routes(){return this.t}addFetchListener(){self.addEventListener(\"fetch\",t=>{const{request:e}=t,s=this.handleRequest({request:e,event:t});s&&t.respondWith(s)})}addCacheListener(){self.addEventListener(\"message\",t=>{if(t.data&&\"CACHE_URLS\"===t.data.type){const{payload:e}=t.data,s=Promise.all(e.urlsToCache.map(e=>{\"string\"==typeof e&&(e=[e]);const s=new Request(...e);return this.handleRequest({request:s,event:t})}));t.waitUntil(s),t.ports&&t.ports[0]&&s.then(()=>t.ports[0].postMessage(!0))}})}handleRequest({request:t,event:e}){const s=new URL(t.url,location.href);if(!s.protocol.startsWith(\"http\"))return;const n=s.origin===location.origin,{params:r,route:i}=this.findMatchingRoute({event:e,request:t,sameOrigin:n,url:s});let a=i&&i.handler;const o=t.method;if(!a&&this.i.has(o)&&(a=this.i.get(o)),!a)return;let c;try{c=a.handle({url:s,request:t,event:e,params:r})}catch(t){c=Promise.reject(t)}const h=i&&i.catchHandler;return c instanceof Promise&&(this.o||h)&&(c=c.catch(async n=>{if(h)try{return await h.handle({url:s,request:t,event:e,params:r})}catch(t){t instanceof Error&&(n=t)}if(this.o)return this.o.handle({url:s,request:t,event:e});throw n})),c}findMatchingRoute({url:t,sameOrigin:e,request:s,event:n}){const r=this.t.get(s.method)||[];for(const i of r){let r;const a=i.match({url:t,sameOrigin:e,request:s,event:n});if(a)return r=a,(Array.isArray(r)&&0===r.length||a.constructor===Object&&0===Object.keys(a).length||\"boolean\"==typeof a)&&(r=void 0),{route:i,params:r}}return{}}setDefaultHandler(t,e=\"GET\"){this.i.set(e,n(t))}setCatchHandler(t){this.o=n(t)}registerRoute(t){this.t.has(t.method)||this.t.set(t.method,[]),this.t.get(t.method).push(t)}unregisterRoute(t){if(!this.t.has(t.method))throw new s(\"unregister-route-but-not-found-with-method\",{method:t.method});const e=this.t.get(t.method).indexOf(t);if(!(e>-1))throw new s(\"unregister-route-route-not-registered\");this.t.get(t.method).splice(e,1)}}let o;const c=()=>(o||(o=new a,o.addFetchListener(),o.addCacheListener()),o);function h(t,e,n){let a;if(\"string\"==typeof t){const s=new URL(t,location.href);a=new r(({url:t})=>t.href===s.href,e,n)}else if(t instanceof RegExp)a=new i(t,e,n);else if(\"function\"==typeof t)a=new r(t,e,n);else{if(!(t instanceof r))throw new s(\"unsupported-route-type\",{moduleName:\"workbox-routing\",funcName:\"registerRoute\",paramName:\"capture\"});a=t}return c().registerRoute(a),a}try{self[\"workbox:strategies:6.5.4\"]&&_()}catch(t){}const u={cacheWillUpdate:async({response:t})=>200===t.status||0===t.status?t:null},l={googleAnalytics:\"googleAnalytics\",precache:\"precache-v2\",prefix:\"workbox\",runtime:\"runtime\",suffix:\"undefined\"!=typeof registration?registration.scope:\"\"},f=t=>[l.prefix,t,l.suffix].filter(t=>t&&t.length>0).join(\"-\"),w=t=>t||f(l.precache),d=t=>t||f(l.runtime);function p(t,e){const s=new URL(t);for(const t of e)s.searchParams.delete(t);return s.href}class y{constructor(){this.promise=new Promise((t,e)=>{this.resolve=t,this.reject=e})}}const g=new Set;function m(t){return\"string\"==typeof t?new Request(t):t}class v{constructor(t,e){this.h={},Object.assign(this,e),this.event=e.event,this.u=t,this.l=new y,this.p=[],this.m=[...t.plugins],this.v=new Map;for(const t of this.m)this.v.set(t,{});this.event.waitUntil(this.l.promise)}async fetch(t){const{event:e}=this;let n=m(t);if(\"navigate\"===n.mode&&e instanceof FetchEvent&&e.preloadResponse){const t=await e.preloadResponse;if(t)return t}const r=this.hasCallback(\"fetchDidFail\")?n.clone():null;try{for(const t of this.iterateCallbacks(\"requestWillFetch\"))n=await t({request:n.clone(),event:e})}catch(t){if(t instanceof Error)throw new s(\"plugin-error-request-will-fetch\",{thrownErrorMessage:t.message})}const i=n.clone();try{let t;t=await fetch(n,\"navigate\"===n.mode?void 0:this.u.fetchOptions);for(const s of this.iterateCallbacks(\"fetchDidSucceed\"))t=await s({event:e,request:i,response:t});return t}catch(t){throw r&&await this.runCallbacks(\"fetchDidFail\",{error:t,event:e,originalRequest:r.clone(),request:i.clone()}),t}}async fetchAndCachePut(t){const e=await this.fetch(t),s=e.clone();return this.waitUntil(this.cachePut(t,s)),e}async cacheMatch(t){const e=m(t);let s;const{cacheName:n,matchOptions:r}=this.u,i=await this.getCacheKey(e,\"read\"),a=Object.assign(Object.assign({},r),{cacheName:n});s=await caches.match(i,a);for(const t of this.iterateCallbacks(\"cachedResponseWillBeUsed\"))s=await t({cacheName:n,matchOptions:r,cachedResponse:s,request:i,event:this.event})||void 0;return s}async cachePut(t,e){const n=m(t);var r;await(r=0,new Promise(t=>setTimeout(t,r)));const i=await this.getCacheKey(n,\"write\");if(!e)throw new s(\"cache-put-with-no-response\",{url:(a=i.url,new URL(String(a),location.href).href.replace(new RegExp(`^${location.origin}`),\"\"))});var a;const o=await this.R(e);if(!o)return!1;const{cacheName:c,matchOptions:h}=this.u,u=await self.caches.open(c),l=this.hasCallback(\"cacheDidUpdate\"),f=l?await async function(t,e,s,n){const r=p(e.url,s);if(e.url===r)return t.match(e,n);const i=Object.assign(Object.assign({},n),{ignoreSearch:!0}),a=await t.keys(e,i);for(const e of a)if(r===p(e.url,s))return t.match(e,n)}(u,i.clone(),[\"__WB_REVISION__\"],h):null;try{await u.put(i,l?o.clone():o)}catch(t){if(t instanceof Error)throw\"QuotaExceededError\"===t.name&&await async function(){for(const t of g)await t()}(),t}for(const t of this.iterateCallbacks(\"cacheDidUpdate\"))await t({cacheName:c,oldResponse:f,newResponse:o.clone(),request:i,event:this.event});return!0}async getCacheKey(t,e){const s=`${t.url} | ${e}`;if(!this.h[s]){let n=t;for(const t of this.iterateCallbacks(\"cacheKeyWillBeUsed\"))n=m(await t({mode:e,request:n,event:this.event,params:this.params}));this.h[s]=n}return this.h[s]}hasCallback(t){for(const e of this.u.plugins)if(t in e)return!0;return!1}async runCallbacks(t,e){for(const s of this.iterateCallbacks(t))await s(e)}*iterateCallbacks(t){for(const e of this.u.plugins)if(\"function\"==typeof e[t]){const s=this.v.get(e),n=n=>{const r=Object.assign(Object.assign({},n),{state:s});return e[t](r)};yield n}}waitUntil(t){return this.p.push(t),t}async doneWaiting(){let t;for(;t=this.p.shift();)await t}destroy(){this.l.resolve(null)}async R(t){let e=t,s=!1;for(const t of this.iterateCallbacks(\"cacheWillUpdate\"))if(e=await t({request:this.request,response:e,event:this.event})||void 0,s=!0,!e)break;return s||e&&200!==e.status&&(e=void 0),e}}class R{constructor(t={}){this.cacheName=d(t.cacheName),this.plugins=t.plugins||[],this.fetchOptions=t.fetchOptions,this.matchOptions=t.matchOptions}handle(t){const[e]=this.handleAll(t);return e}handleAll(t){t instanceof FetchEvent&&(t={event:t,request:t.request});const e=t.event,s=\"string\"==typeof t.request?new Request(t.request):t.request,n=\"params\"in t?t.params:void 0,r=new v(this,{event:e,request:s,params:n}),i=this.q(r,s,e);return[i,this.D(i,r,s,e)]}async q(t,e,n){let r;await t.runCallbacks(\"handlerWillStart\",{event:n,request:e});try{if(r=await this.U(e,t),!r||\"error\"===r.type)throw new s(\"no-response\",{url:e.url})}catch(s){if(s instanceof Error)for(const i of t.iterateCallbacks(\"handlerDidError\"))if(r=await i({error:s,event:n,request:e}),r)break;if(!r)throw s}for(const s of t.iterateCallbacks(\"handlerWillRespond\"))r=await s({event:n,request:e,response:r});return r}async D(t,e,s,n){let r,i;try{r=await t}catch(i){}try{await e.runCallbacks(\"handlerDidRespond\",{event:n,request:s,response:r}),await e.doneWaiting()}catch(t){t instanceof Error&&(i=t)}if(await e.runCallbacks(\"handlerDidComplete\",{event:n,request:s,response:r,error:i}),e.destroy(),i)throw i}}function b(t){t.then(()=>{})}function q(){return q=Object.assign?Object.assign.bind():function(t){for(var e=1;e<arguments.length;e++){var s=arguments[e];for(var n in s)({}).hasOwnProperty.call(s,n)&&(t[n]=s[n])}return t},q.apply(null,arguments)}let D,U;const x=new WeakMap,L=new WeakMap,I=new WeakMap,C=new WeakMap,E=new WeakMap;let N={get(t,e,s){if(t instanceof IDBTransaction){if(\"done\"===e)return L.get(t);if(\"objectStoreNames\"===e)return t.objectStoreNames||I.get(t);if(\"store\"===e)return s.objectStoreNames[1]?void 0:s.objectStore(s.objectStoreNames[0])}return k(t[e])},set:(t,e,s)=>(t[e]=s,!0),has:(t,e)=>t instanceof IDBTransaction&&(\"done\"===e||\"store\"===e)||e in t};function O(t){return t!==IDBDatabase.prototype.transaction||\"objectStoreNames\"in IDBTransaction.prototype?(U||(U=[IDBCursor.prototype.advance,IDBCursor.prototype.continue,IDBCursor.prototype.continuePrimaryKey])).includes(t)?function(...e){return t.apply(B(this),e),k(x.get(this))}:function(...e){return k(t.apply(B(this),e))}:function(e,...s){const n=t.call(B(this),e,...s);return I.set(n,e.sort?e.sort():[e]),k(n)}}function T(t){return\"function\"==typeof t?O(t):(t instanceof IDBTransaction&&function(t){if(L.has(t))return;const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"complete\",r),t.removeEventListener(\"error\",i),t.removeEventListener(\"abort\",i)},r=()=>{e(),n()},i=()=>{s(t.error||new DOMException(\"AbortError\",\"AbortError\")),n()};t.addEventListener(\"complete\",r),t.addEventListener(\"error\",i),t.addEventListener(\"abort\",i)});L.set(t,e)}(t),e=t,(D||(D=[IDBDatabase,IDBObjectStore,IDBIndex,IDBCursor,IDBTransaction])).some(t=>e instanceof t)?new Proxy(t,N):t);var e}function k(t){if(t instanceof IDBRequest)return function(t){const e=new Promise((e,s)=>{const n=()=>{t.removeEventListener(\"success\",r),t.removeEventListener(\"error\",i)},r=()=>{e(k(t.result)),n()},i=()=>{s(t.error),n()};t.addEventListener(\"success\",r),t.addEventListener(\"error\",i)});return e.then(e=>{e instanceof IDBCursor&&x.set(e,t)}).catch(()=>{}),E.set(e,t),e}(t);if(C.has(t))return C.get(t);const e=T(t);return e!==t&&(C.set(t,e),E.set(e,t)),e}const B=t=>E.get(t);const P=[\"get\",\"getKey\",\"getAll\",\"getAllKeys\",\"count\"],M=[\"put\",\"add\",\"delete\",\"clear\"],W=new Map;function j(t,e){if(!(t instanceof IDBDatabase)||e in t||\"string\"!=typeof e)return;if(W.get(e))return W.get(e);const s=e.replace(/FromIndex$/,\"\"),n=e!==s,r=M.includes(s);if(!(s in(n?IDBIndex:IDBObjectStore).prototype)||!r&&!P.includes(s))return;const i=async function(t,...e){const i=this.transaction(t,r?\"readwrite\":\"readonly\");let a=i.store;return n&&(a=a.index(e.shift())),(await Promise.all([a[s](...e),r&&i.done]))[0]};return W.set(e,i),i}N=(t=>q({},t,{get:(e,s,n)=>j(e,s)||t.get(e,s,n),has:(e,s)=>!!j(e,s)||t.has(e,s)}))(N);try{self[\"workbox:expiration:6.5.4\"]&&_()}catch(t){}const S=\"cache-entries\",K=t=>{const e=new URL(t,location.href);return e.hash=\"\",e.href};class A{constructor(t){this._=null,this.L=t}I(t){const e=t.createObjectStore(S,{keyPath:\"id\"});e.createIndex(\"cacheName\",\"cacheName\",{unique:!1}),e.createIndex(\"timestamp\",\"timestamp\",{unique:!1})}C(t){this.I(t),this.L&&function(t,{blocked:e}={}){const s=indexedDB.deleteDatabase(t);e&&s.addEventListener(\"blocked\",t=>e(t.oldVersion,t)),k(s).then(()=>{})}(this.L)}async setTimestamp(t,e){const s={url:t=K(t),timestamp:e,cacheName:this.L,id:this.N(t)},n=(await this.getDb()).transaction(S,\"readwrite\",{durability:\"relaxed\"});await n.store.put(s),await n.done}async getTimestamp(t){const e=await this.getDb(),s=await e.get(S,this.N(t));return null==s?void 0:s.timestamp}async expireEntries(t,e){const s=await this.getDb();let n=await s.transaction(S).store.index(\"timestamp\").openCursor(null,\"prev\");const r=[];let i=0;for(;n;){const s=n.value;s.cacheName===this.L&&(t&&s.timestamp<t||e&&i>=e?r.push(n.value):i++),n=await n.continue()}const a=[];for(const t of r)await s.delete(S,t.id),a.push(t.url);return a}N(t){return this.L+\"|\"+K(t)}async getDb(){return this._||(this._=await function(t,e,{blocked:s,upgrade:n,blocking:r,terminated:i}={}){const a=indexedDB.open(t,e),o=k(a);return n&&a.addEventListener(\"upgradeneeded\",t=>{n(k(a.result),t.oldVersion,t.newVersion,k(a.transaction),t)}),s&&a.addEventListener(\"blocked\",t=>s(t.oldVersion,t.newVersion,t)),o.then(t=>{i&&t.addEventListener(\"close\",()=>i()),r&&t.addEventListener(\"versionchange\",t=>r(t.oldVersion,t.newVersion,t))}).catch(()=>{}),o}(\"workbox-expiration\",1,{upgrade:this.C.bind(this)})),this._}}class F{constructor(t,e={}){this.O=!1,this.T=!1,this.k=e.maxEntries,this.B=e.maxAgeSeconds,this.P=e.matchOptions,this.L=t,this.M=new A(t)}async expireEntries(){if(this.O)return void(this.T=!0);this.O=!0;const t=this.B?Date.now()-1e3*this.B:0,e=await this.M.expireEntries(t,this.k),s=await self.caches.open(this.L);for(const t of e)await s.delete(t,this.P);this.O=!1,this.T&&(this.T=!1,b(this.expireEntries()))}async updateTimestamp(t){await this.M.setTimestamp(t,Date.now())}async isURLExpired(t){if(this.B){const e=await this.M.getTimestamp(t),s=Date.now()-1e3*this.B;return void 0===e||e<s}return!1}async delete(){this.T=!1,await this.M.expireEntries(1/0)}}try{self[\"workbox:range-requests:6.5.4\"]&&_()}catch(t){}async function H(t,e){try{if(206===e.status)return e;const n=t.headers.get(\"range\");if(!n)throw new s(\"no-range-header\");const r=function(t){const e=t.trim().toLowerCase();if(!e.startsWith(\"bytes=\"))throw new s(\"unit-must-be-bytes\",{normalizedRangeHeader:e});if(e.includes(\",\"))throw new s(\"single-range-only\",{normalizedRangeHeader:e});const n=/(\\d*)-(\\d*)/.exec(e);if(!n||!n[1]&&!n[2])throw new s(\"invalid-range-values\",{normalizedRangeHeader:e});return{start:\"\"===n[1]?void 0:Number(n[1]),end:\"\"===n[2]?void 0:Number(n[2])}}(n),i=await e.blob(),a=function(t,e,n){const r=t.size;if(n&&n>r||e&&e<0)throw new s(\"range-not-satisfiable\",{size:r,end:n,start:e});let i,a;return void 0!==e&&void 0!==n?(i=e,a=n+1):void 0!==e&&void 0===n?(i=e,a=r):void 0!==n&&void 0===e&&(i=r-n,a=r),{start:i,end:a}}(i,r.start,r.end),o=i.slice(a.start,a.end),c=o.size,h=new Response(o,{status:206,statusText:\"Partial Content\",headers:e.headers});return h.headers.set(\"Content-Length\",String(c)),h.headers.set(\"Content-Range\",`bytes ${a.start}-${a.end-1}/${i.size}`),h}catch(t){return new Response(\"\",{status:416,statusText:\"Range Not Satisfiable\"})}}function $(t,e){const s=e();return t.waitUntil(s),s}try{self[\"workbox:precaching:6.5.4\"]&&_()}catch(t){}function z(t){if(!t)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(\"string\"==typeof t){const e=new URL(t,location.href);return{cacheKey:e.href,url:e.href}}const{revision:e,url:n}=t;if(!n)throw new s(\"add-to-cache-list-unexpected-type\",{entry:t});if(!e){const t=new URL(n,location.href);return{cacheKey:t.href,url:t.href}}const r=new URL(n,location.href),i=new URL(n,location.href);return r.searchParams.set(\"__WB_REVISION__\",e),{cacheKey:r.href,url:i.href}}class G{constructor(){this.updatedURLs=[],this.notUpdatedURLs=[],this.handlerWillStart=async({request:t,state:e})=>{e&&(e.originalRequest=t)},this.cachedResponseWillBeUsed=async({event:t,state:e,cachedResponse:s})=>{if(\"install\"===t.type&&e&&e.originalRequest&&e.originalRequest instanceof Request){const t=e.originalRequest.url;s?this.notUpdatedURLs.push(t):this.updatedURLs.push(t)}return s}}}class V{constructor({precacheController:t}){this.cacheKeyWillBeUsed=async({request:t,params:e})=>{const s=(null==e?void 0:e.cacheKey)||this.W.getCacheKeyForURL(t.url);return s?new Request(s,{headers:t.headers}):t},this.W=t}}let J,Q;async function X(t,e){let n=null;if(t.url){n=new URL(t.url).origin}if(n!==self.location.origin)throw new s(\"cross-origin-copy-response\",{origin:n});const r=t.clone(),i={headers:new Headers(r.headers),status:r.status,statusText:r.statusText},a=e?e(i):i,o=function(){if(void 0===J){const t=new Response(\"\");if(\"body\"in t)try{new Response(t.body),J=!0}catch(t){J=!1}J=!1}return J}()?r.body:await r.blob();return new Response(o,a)}class Y extends R{constructor(t={}){t.cacheName=w(t.cacheName),super(t),this.j=!1!==t.fallbackToNetwork,this.plugins.push(Y.copyRedirectedCacheableResponsesPlugin)}async U(t,e){const s=await e.cacheMatch(t);return s||(e.event&&\"install\"===e.event.type?await this.S(t,e):await this.K(t,e))}async K(t,e){let n;const r=e.params||{};if(!this.j)throw new s(\"missing-precache-entry\",{cacheName:this.cacheName,url:t.url});{const s=r.integrity,i=t.integrity,a=!i||i===s;n=await e.fetch(new Request(t,{integrity:\"no-cors\"!==t.mode?i||s:void 0})),s&&a&&\"no-cors\"!==t.mode&&(this.A(),await e.cachePut(t,n.clone()))}return n}async S(t,e){this.A();const n=await e.fetch(t);if(!await e.cachePut(t,n.clone()))throw new s(\"bad-precaching-response\",{url:t.url,status:n.status});return n}A(){let t=null,e=0;for(const[s,n]of this.plugins.entries())n!==Y.copyRedirectedCacheableResponsesPlugin&&(n===Y.defaultPrecacheCacheabilityPlugin&&(t=s),n.cacheWillUpdate&&e++);0===e?this.plugins.push(Y.defaultPrecacheCacheabilityPlugin):e>1&&null!==t&&this.plugins.splice(t,1)}}Y.defaultPrecacheCacheabilityPlugin={cacheWillUpdate:async({response:t})=>!t||t.status>=400?null:t},Y.copyRedirectedCacheableResponsesPlugin={cacheWillUpdate:async({response:t})=>t.redirected?await X(t):t};class Z{constructor({cacheName:t,plugins:e=[],fallbackToNetwork:s=!0}={}){this.F=new Map,this.H=new Map,this.$=new Map,this.u=new Y({cacheName:w(t),plugins:[...e,new V({precacheController:this})],fallbackToNetwork:s}),this.install=this.install.bind(this),this.activate=this.activate.bind(this)}get strategy(){return this.u}precache(t){this.addToCacheList(t),this.G||(self.addEventListener(\"install\",this.install),self.addEventListener(\"activate\",this.activate),this.G=!0)}addToCacheList(t){const e=[];for(const n of t){\"string\"==typeof n?e.push(n):n&&void 0===n.revision&&e.push(n.url);const{cacheKey:t,url:r}=z(n),i=\"string\"!=typeof n&&n.revision?\"reload\":\"default\";if(this.F.has(r)&&this.F.get(r)!==t)throw new s(\"add-to-cache-list-conflicting-entries\",{firstEntry:this.F.get(r),secondEntry:t});if(\"string\"!=typeof n&&n.integrity){if(this.$.has(t)&&this.$.get(t)!==n.integrity)throw new s(\"add-to-cache-list-conflicting-integrities\",{url:r});this.$.set(t,n.integrity)}if(this.F.set(r,t),this.H.set(r,i),e.length>0){const t=`Workbox is precaching URLs without revision info: ${e.join(\", \")}\\nThis is generally NOT safe. Learn more at https://bit.ly/wb-precache`;console.warn(t)}}}install(t){return $(t,async()=>{const e=new G;this.strategy.plugins.push(e);for(const[e,s]of this.F){const n=this.$.get(s),r=this.H.get(e),i=new Request(e,{integrity:n,cache:r,credentials:\"same-origin\"});await Promise.all(this.strategy.handleAll({params:{cacheKey:s},request:i,event:t}))}const{updatedURLs:s,notUpdatedURLs:n}=e;return{updatedURLs:s,notUpdatedURLs:n}})}activate(t){return $(t,async()=>{const t=await self.caches.open(this.strategy.cacheName),e=await t.keys(),s=new Set(this.F.values()),n=[];for(const r of e)s.has(r.url)||(await t.delete(r),n.push(r.url));return{deletedURLs:n}})}getURLsToCacheKeys(){return this.F}getCachedURLs(){return[...this.F.keys()]}getCacheKeyForURL(t){const e=new URL(t,location.href);return this.F.get(e.href)}getIntegrityForCacheKey(t){return this.$.get(t)}async matchPrecache(t){const e=t instanceof Request?t.url:t,s=this.getCacheKeyForURL(e);if(s){return(await self.caches.open(this.strategy.cacheName)).match(s)}}createHandlerBoundToURL(t){const e=this.getCacheKeyForURL(t);if(!e)throw new s(\"non-precached-url\",{url:t});return s=>(s.request=new Request(t),s.params=Object.assign({cacheKey:e},s.params),this.strategy.handle(s))}}const tt=()=>(Q||(Q=new Z),Q);class et extends r{constructor(t,e){super(({request:s})=>{const n=t.getURLsToCacheKeys();for(const r of function*(t,{ignoreURLParametersMatching:e=[/^utm_/,/^fbclid$/],directoryIndex:s=\"index.html\",cleanURLs:n=!0,urlManipulation:r}={}){const i=new URL(t,location.href);i.hash=\"\",yield i.href;const a=function(t,e=[]){for(const s of[...t.searchParams.keys()])e.some(t=>t.test(s))&&t.searchParams.delete(s);return t}(i,e);if(yield a.href,s&&a.pathname.endsWith(\"/\")){const t=new URL(a.href);t.pathname+=s,yield t.href}if(n){const t=new URL(a.href);t.pathname+=\".html\",yield t.href}if(r){const t=r({url:i});for(const e of t)yield e.href}}(s.url,e)){const e=n.get(r);if(e){return{cacheKey:e,integrity:t.getIntegrityForCacheKey(e)}}}},t.strategy)}}t.CacheFirst=class extends R{async U(t,e){let n,r=await e.cacheMatch(t);if(!r)try{r=await e.fetchAndCachePut(t)}catch(t){t instanceof Error&&(n=t)}if(!r)throw new s(\"no-response\",{url:t.url,error:n});return r}},t.ExpirationPlugin=class{constructor(t={}){this.cachedResponseWillBeUsed=async({event:t,request:e,cacheName:s,cachedResponse:n})=>{if(!n)return null;const r=this.V(n),i=this.J(s);b(i.expireEntries());const a=i.updateTimestamp(e.url);if(t)try{t.waitUntil(a)}catch(t){}return r?n:null},this.cacheDidUpdate=async({cacheName:t,request:e})=>{const s=this.J(t);await s.updateTimestamp(e.url),await s.expireEntries()},this.X=t,this.B=t.maxAgeSeconds,this.Y=new Map,t.purgeOnQuotaError&&function(t){g.add(t)}(()=>this.deleteCacheAndMetadata())}J(t){if(t===d())throw new s(\"expire-custom-caches-only\");let e=this.Y.get(t);return e||(e=new F(t,this.X),this.Y.set(t,e)),e}V(t){if(!this.B)return!0;const e=this.Z(t);if(null===e)return!0;return e>=Date.now()-1e3*this.B}Z(t){if(!t.headers.has(\"date\"))return null;const e=t.headers.get(\"date\"),s=new Date(e).getTime();return isNaN(s)?null:s}async deleteCacheAndMetadata(){for(const[t,e]of this.Y)await self.caches.delete(t),await e.delete();this.Y=new Map}},t.NetworkFirst=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u),this.tt=t.networkTimeoutSeconds||0}async U(t,e){const n=[],r=[];let i;if(this.tt){const{id:s,promise:a}=this.et({request:t,logs:n,handler:e});i=s,r.push(a)}const a=this.st({timeoutId:i,request:t,logs:n,handler:e});r.push(a);const o=await e.waitUntil((async()=>await e.waitUntil(Promise.race(r))||await a)());if(!o)throw new s(\"no-response\",{url:t.url});return o}et({request:t,logs:e,handler:s}){let n;return{promise:new Promise(e=>{n=setTimeout(async()=>{e(await s.cacheMatch(t))},1e3*this.tt)}),id:n}}async st({timeoutId:t,request:e,logs:s,handler:n}){let r,i;try{i=await n.fetchAndCachePut(e)}catch(t){t instanceof Error&&(r=t)}return t&&clearTimeout(t),!r&&i||(i=await n.cacheMatch(e)),i}},t.RangeRequestsPlugin=class{constructor(){this.cachedResponseWillBeUsed=async({request:t,cachedResponse:e})=>e&&t.headers.has(\"range\")?await H(t,e):e}},t.StaleWhileRevalidate=class extends R{constructor(t={}){super(t),this.plugins.some(t=>\"cacheWillUpdate\"in t)||this.plugins.unshift(u)}async U(t,e){const n=e.fetchAndCachePut(t).catch(()=>{});e.waitUntil(n);let r,i=await e.cacheMatch(t);if(i);else try{i=await n}catch(t){t instanceof Error&&(r=t)}if(!i)throw new s(\"no-response\",{url:t.url,error:r});return i}},t.cleanupOutdatedCaches=function(){self.addEventListener(\"activate\",t=>{const e=w();t.waitUntil((async(t,e=\"-precache-\")=>{const s=(await self.caches.keys()).filter(s=>s.includes(e)&&s.includes(self.registration.scope)&&s!==t);return await Promise.all(s.map(t=>self.caches.delete(t))),s})(e).then(t=>{}))})},t.clientsClaim=function(){self.addEventListener(\"activate\",()=>self.clients.claim())},t.precacheAndRoute=function(t,e){!function(t){tt().precache(t)}(t),function(t){const e=tt();h(new et(e,t))}(e)},t.registerRoute=h});\n",
    "web_platform/frontend/src/components/LiveModeToggle.tsx": "// web_platform/frontend/src/components/LiveModeToggle.tsx\n'use client';\n\nimport React from 'react';\n\ninterface LiveModeToggleProps {\n  isLive: boolean;\n  onToggle: (isLive: boolean) => void;\n  isDisabled: boolean;\n}\n\nexport const LiveModeToggle: React.FC<LiveModeToggleProps> = ({ isLive, onToggle, isDisabled }) => {\n  const handleToggle = () => {\n    if (!isDisabled) {\n      onToggle(!isLive);\n    }\n  };\n\n  return (\n    <button\n      onClick={handleToggle}\n      disabled={isDisabled}\n      className={`relative inline-flex items-center h-8 rounded-full w-32 transition-colors duration-300 ease-in-out focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-slate-800 focus:ring-blue-500 ${\n        isDisabled ? 'cursor-not-allowed bg-slate-700' : 'cursor-pointer'\n      } ${isLive ? 'bg-green-600' : 'bg-slate-600'}`}\n    >\n      <span className=\"sr-only\">Toggle Live Mode</span>\n      <span\n        className={`absolute left-1 top-1 inline-block w-6 h-6 rounded-full bg-white transform transition-transform duration-300 ease-in-out ${\n          isLive ? 'translate-x-[104px]' : 'translate-x-0'\n        }`}\n      />\n      <span\n        className={`absolute left-8 transition-opacity duration-200 ease-in-out ${\n          !isLive && !isDisabled ? 'opacity-100' : 'opacity-50'\n        }`}\n      >\n        Poll\n      </span>\n      <span\n        className={`absolute right-4 transition-opacity duration-200 ease-in-out ${\n          isLive && !isDisabled ? 'opacity-100' : 'opacity-50'\n        }`}\n      >\n        \u26a1 Live\n      </span>\n    </button>\n  );\n};\n",
    "web_platform/frontend/src/components/RaceFilters.tsx": "// web_platform/frontend/src/components/RaceFilters.tsx\n'use client';\n\nimport { useState, useCallback } from 'react';\nimport { Settings, RotateCcw } from 'lucide-react';\n\ninterface FilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nexport interface RaceFiltersProps {\n  onParamsChange: (params: FilterParams) => void;\n  isLoading: boolean;\n  refetch: () => void;\n}\n\nconst DEFAULT_PARAMS: FilterParams = {\n  maxFieldSize: 10,\n  minFavoriteOdds: 2.5,\n  minSecondFavoriteOdds: 4.0,\n};\n\nexport function RaceFilters({ onParamsChange, isLoading, refetch }: RaceFiltersProps) {\n  const [params, setParams] = useState<FilterParams>(DEFAULT_PARAMS);\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // Handle individual parameter changes\n  const handleChange = useCallback((key: keyof FilterParams, value: number) => {\n    setParams(prev => {\n      const updated = { ...prev, [key]: value };\n      onParamsChange(updated);\n      return updated;\n    });\n    // Debounce the refetch call\n    const timer = setTimeout(() => {\n      refetch();\n    }, 500);\n    return () => clearTimeout(timer);\n  }, [onParamsChange, refetch]);\n\n  // Reset to defaults\n  const handleReset = useCallback(() => {\n    setParams(DEFAULT_PARAMS);\n    onParamsChange(DEFAULT_PARAMS);\n    refetch();\n  }, [onParamsChange, refetch]);\n\n  return (\n    <div className=\"bg-gradient-to-r from-slate-800 to-slate-900 rounded-lg p-4 mb-6 border border-slate-700\">\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-2\">\n          <Settings className=\"w-5 h-5 text-amber-500\" />\n          <h3 className=\"text-lg font-semibold text-white\">Race Filters</h3>\n        </div>\n        <button\n          onClick={() => setIsExpanded(!isExpanded)}\n          className=\"text-sm text-slate-400 hover:text-slate-200 transition\"\n        >\n          {isExpanded ? 'Hide' : 'Show'}\n        </button>\n      </div>\n\n      {isExpanded && (\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 pt-4 border-t border-slate-700\">\n          {/* Max Field Size */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Max Field Size\n              <span className=\"text-amber-500 ml-2\">{params.maxFieldSize}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2\"\n              max=\"20\"\n              value={params.maxFieldSize}\n              onChange={(e) => handleChange('maxFieldSize', parseInt(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Filters races with larger fields</p>\n          </div>\n\n          {/* Min Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"1.5\"\n              max=\"5\"\n              step=\"0.1\"\n              value={params.minFavoriteOdds}\n              onChange={(e) => handleChange('minFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = pickier favorites</p>\n          </div>\n\n          {/* Min Second Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min 2nd Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minSecondFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2.0\"\n              max=\"8\"\n              step=\"0.1\"\n              value={params.minSecondFavoriteOdds}\n              onChange={(e) => handleChange('minSecondFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = better odds separation</p>\n          </div>\n\n          {/* Reset Button */}\n          <div className=\"md:col-span-3 flex justify-end pt-4 border-t border-slate-700\">\n            <button\n              onClick={handleReset}\n              disabled={isLoading}\n              className=\"inline-flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-600 text-slate-200 rounded text-sm font-medium transition disabled:opacity-50\"\n            >\n              <RotateCcw className=\"w-4 h-4\" />\n              Reset to Defaults\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/components/TrifectaFactors.tsx": "// TrifectaFactors.tsx - FINAL, DYNAMIC VERSION\n'use client';\nimport React from 'react';\n\ninterface TrifectaFactorsProps {\n  factorsJson: string | null;\n}\n\nexport function TrifectaFactors({ factorsJson }: TrifectaFactorsProps) {\n  if (!factorsJson) {\n    return <div className=\"text-sm text-gray-500\">No analysis factors available.</div>;\n  }\n\n  try {\n    const factors = JSON.parse(factorsJson);\n    const positiveFactors = Object.entries(factors).filter(([key, value]: [string, any]) => value.ok);\n\n    if (positiveFactors.length === 0) {\n      return <div className=\"text-sm text-gray-500\">No positive factors identified.</div>;\n    }\n\n    return (\n      <div className=\"mt-2 text-xs\">\n        <h4 className=\"font-semibold mb-1\">Key Factors:</h4>\n        <ul className=\"list-disc list-inside space-y-1\">\n          {positiveFactors.map(([key, value]: [string, any]) => (\n            <li key={key} className=\"text-gray-700\">\n              <span className=\"font-medium text-green-600\">\u2713</span> {value.reason} ({value.points > 0 ? `+${value.points}` : value.points} pts)\n            </li>\n          ))}\n        </ul>\n      </div>\n    );\n  } catch (error) {\n    console.error(\"Failed to parse trifecta factors:\", error);\n    return <div className=\"text-sm text-red-500\">Error displaying analysis factors.</div>;\n  }\n}",
    "web_platform/frontend/src/types/racing.ts": "// web_platform/frontend/src/types/racing.ts\n// This file is the central source of truth for frontend racing data types.\n\n// --- Runner & Odds Interfaces ---\nexport interface OddsData {\n  win: number | null;\n  place: number | null;\n  show: number | null;\n  source: string;\n  last_updated: string;\n}\n\nexport interface Runner {\n  number: number;\n  name: string;\n  scratched: boolean;\n  selection_id?: number;\n  odds: Record<string, OddsData>;\n  jockey?: string;\n  trainer?: string;\n}\n\n// --- Race Interface ---\n// This interface matches the shape of the data returned by the API for the dashboard.\nexport interface Race {\n  id: string;\n  venue: string;\n  race_number: number;\n  start_time: string;\n  runners: Runner[];\n  source: string;\n  qualification_score?: number;\n  distance?: string;\n  surface?: string;\n  favorite?: Runner;\n  isErrorPlaceholder?: boolean;\n  errorMessage?: string;\n}\n\n// --- API Response Interfaces ---\nexport interface SourceInfo {\n  name: string;\n  status: 'SUCCESS' | 'FAILED' | 'CONFIG_ERROR' | 'PENDING';\n  racesFetched: number;\n  fetchDuration: number;\n  errorMessage?: string;\n  attemptedUrl?: string;\n}\n\nexport interface AdapterError {\n  adapterName: string;\n  errorMessage: string;\n  attemptedUrl?: string;\n}\n\nexport interface AggregatedRacesResponse {\n  races: Race[];\n  errors: AdapterError[];\n  source_info: SourceInfo[];\n}\n\n// --- Analysis Factor Interfaces (retained from previous version) ---\nexport interface Factor {\n    points: number;\n    ok: boolean;\n    reason: string;\n}\n\nexport interface TrifectaFactors {\n    [key: string]: Factor;\n}\n",
    "web_platform/frontend/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"lib\": [\n      \"dom\",\n      \"dom.iterable\",\n      \"esnext\"\n    ],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": false,\n    \"noEmit\": true,\n    \"incremental\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ]\n  },\n  \"include\": [\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\",\n    \"out/types/**/*.ts\"\n  ],\n  \"exclude\": [\n    \"node_modules\"\n  ]\n}\n",
    "web_service/backend/adapters/__init__.py": "# python_service/adapters/__init__.py\n# TEMPORARY FIX: Comment out the problematic adapter\n\nfrom .at_the_races_adapter import AtTheRacesAdapter\nfrom .betfair_adapter import BetfairAdapter\nfrom .betfair_greyhound_adapter import BetfairGreyhoundAdapter\n\n# from .betfair_datascientist_adapter import BetfairDataScientistAdapter  # DISABLED: PyInstaller NumPy issue\nfrom .gbgb_api_adapter import GbgbApiAdapter\nfrom .greyhound_adapter import GreyhoundAdapter\nfrom .harness_adapter import HarnessAdapter\nfrom .pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .sporting_life_adapter import SportingLifeAdapter\nfrom .the_racing_api_adapter import TheRacingApiAdapter\nfrom .timeform_adapter import TimeformAdapter\nfrom .tvg_adapter import TVGAdapter\n\n__all__ = [\n    \"GbgbApiAdapter\",\n    \"TVGAdapter\",\n    \"BetfairAdapter\",\n    \"BetfairGreyhoundAdapter\",\n    \"RacingAndSportsGreyhoundAdapter\",\n    \"AtTheRacesAdapter\",\n    \"PointsBetGreyhoundAdapter\",\n    \"RacingAndSportsAdapter\",\n    \"SportingLifeAdapter\",\n    \"TimeformAdapter\",\n    \"HarnessAdapter\",\n    \"GreyhoundAdapter\",\n    \"TheRacingApiAdapter\",\n    # \"BetfairDataScientistAdapter\",  # DISABLED\n]\n",
    "web_service/backend/adapters/betfair_datascientist_adapter.py": "# python_service/adapters/betfair_datascientist_adapter.py\n\nfrom datetime import datetime\nfrom io import StringIO\nfrom typing import List\nfrom typing import Optional\n\nimport pandas as pd\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass BetfairDataScientistAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for the Betfair Data Scientist CSV models, migrated to BaseAdapterV3.\n    \"\"\"\n\n    ADAPTER_NAME = \"BetfairDataScientist\"\n\n    def __init__(self, model_name: str, url: str, config=None):\n        source_name = f\"{self.ADAPTER_NAME}_{model_name}\"\n        super().__init__(source_name=source_name, base_url=url, config=config)\n        self.model_name = model_name\n\n    async def _fetch_data(self, date: str) -> Optional[StringIO]:\n        \"\"\"Fetches the raw CSV data from the Betfair Data Scientist model endpoint.\"\"\"\n        endpoint = f\"?date={date}&presenter=RatingsPresenter&csv=true\"\n        self.logger.info(f\"Fetching data from {self.base_url}{endpoint}\")\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return StringIO(response.text) if response and response.text else None\n\n    def _parse_races(self, raw_data: Optional[StringIO]) -> List[Race]:\n        \"\"\"Parses the raw CSV data into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n        try:\n            df = pd.read_csv(raw_data)\n            if df.empty:\n                self.logger.warning(\"Received empty CSV from Betfair Data Scientist.\")\n                return []\n\n            df = df.rename(\n                columns={\n                    \"meetings.races.bfExchangeMarketId\": \"market_id\",\n                    \"meetings.races.runners.bfExchangeSelectionId\": \"selection_id\",\n                    \"meetings.races.runners.ratedPrice\": \"rated_price\",\n                    \"meetings.races.raceName\": \"race_name\",\n                    \"meetings.name\": \"meeting_name\",\n                    \"meetings.races.raceNumber\": \"race_number\",\n                    \"meetings.races.runners.runnerName\": \"runner_name\",\n                    \"meetings.races.runners.clothNumber\": \"saddle_cloth\",\n                }\n            )\n            races: List[Race] = []\n            for market_id, group in df.groupby(\"market_id\"):\n                race_info = group.iloc[0]\n                runners = []\n                for _, row in group.iterrows():\n                    rated_price = row.get(\"rated_price\")\n                    odds_data = {}\n                    if pd.notna(rated_price):\n                        odds_data[self.source_name] = OddsData(\n                            win=float(rated_price),\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                    runners.append(\n                        Runner(\n                            name=str(row.get(\"runner_name\", \"Unknown\")),\n                            number=int(row.get(\"saddle_cloth\", 0)),\n                            odds=odds_data,\n                        )\n                    )\n\n                race = Race(\n                    id=str(market_id),\n                    venue=normalize_venue_name(str(race_info.get(\"meeting_name\", \"\"))),\n                    race_number=int(race_info.get(\"race_number\", 0)),\n                    start_time=datetime.now(),  # Placeholder, not provided in source\n                    runners=runners,\n                    source=self.source_name,\n                )\n                races.append(race)\n            self.logger.info(f\"Normalized {len(races)} races from {self.model_name}.\")\n            return races\n        except (pd.errors.ParserError, KeyError) as e:\n            self.logger.error(\n                \"Failed to parse Betfair Data Scientist CSV.\",\n                exc_info=True,\n                error=str(e),\n            )\n            return []\n",
    "web_service/backend/adapters/gbgb_api_adapter.py": "# python_service/adapters/gbgb_api_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass GbgbApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for the Greyhound Board of Great Britain API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"GBGB\"\n    BASE_URL = \"https://api.gbgb.org.uk/api/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches the raw meeting data from the GBGB API.\"\"\"\n        endpoint = f\"results/meeting/{date}\"\n        response = await self.make_request(self.http_client, \"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, meetings_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw meeting data into a list of Race objects.\"\"\"\n        if not meetings_data:\n            return []\n\n        all_races = []\n        for meeting in meetings_data:\n            track_name = meeting.get(\"trackName\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name):\n                        all_races.append(race)\n                except (KeyError, TypeError):\n                    self.logger.error(\n                        \"Error parsing GBGB race\",\n                        race_id=race_data.get(\"raceId\"),\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: Dict[str, Any], track_name: str) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race_data.get(\"raceId\")\n        race_number = race_data.get(\"raceNumber\")\n        race_time = race_data.get(\"raceTime\")\n\n        if not all([race_id, race_number, race_time]):\n            return None\n\n        return Race(\n            id=f\"gbgb_{race_id}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=datetime.fromisoformat(race_time.replace(\"Z\", \"+00:00\")),\n            runners=self._parse_runners(race_data.get(\"traps\", [])),\n            source=self.source_name,\n            race_name=race_data.get(\"raceTitle\"),\n            distance=f\"{race_data.get('raceDistance')}m\",\n        )\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                trap_number = runner_data.get(\"trapNumber\")\n                dog_name = runner_data.get(\"dogName\")\n                if not all([trap_number, dog_name]):\n                    continue\n\n                odds_data = {}\n                sp = runner_data.get(\"sp\")\n                if sp:\n                    win_odds = parse_odds_to_decimal(sp)\n                    if win_odds and win_odds < 999:\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=trap_number,\n                        name=dog_name,\n                        odds=odds_data,\n                    )\n                )\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Error parsing GBGB runner, skipping.\",\n                    runner_name=runner_data.get(\"dogName\"),\n                )\n                continue\n        return runners\n",
    "web_service/backend/adapters/oddschecker_adapter.py": "# python_service/adapters/oddschecker_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass OddscheckerAdapter(BaseAdapterV3):\n    \"\"\"Adapter for scraping horse racing odds from Oddschecker, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"Oddschecker\"\n    BASE_URL = \"https://www.oddschecker.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date. This involves a multi-level fetch.\n        \"\"\"\n        # Note: Oddschecker doesn't seem to support historical dates well in its main nav,\n        # but we build the URL as if it does for future compatibility.\n        index_url = f\"/horse-racing/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Oddschecker index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        # Find all links to individual race pages\n        race_links = {a[\"href\"] for a in index_soup.select(\"a.race-time-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings from different races into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to OddscheckerAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n                race = self._parse_race_page(soup, race_date)\n                if race:\n                    all_races.append(race)\n            except (AttributeError, IndexError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from Oddschecker, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_race_page(self, soup: BeautifulSoup, race_date) -> Optional[Race]:\n        track_name_node = soup.select_one(\"h1.meeting-name\")\n        if not track_name_node:\n            return None\n        track_name = track_name_node.get_text(strip=True)\n\n        race_time_node = soup.select_one(\"span.race-time\")\n        if not race_time_node:\n            return None\n        race_time_str = race_time_node.get_text(strip=True)\n\n        # Heuristic to find race number from navigation\n        active_link = soup.select_one(\"a.race-time-link.active\")\n        race_number = 1\n        if active_link:\n            all_links = soup.select(\"a.race-time-link\")\n            try:\n                race_number = all_links.index(active_link) + 1\n            except ValueError:\n                pass  # Keep default race number if active link not in all links\n\n        start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n        runners = [runner for row in soup.select(\"tr.race-card-row\") if (runner := self._parse_runner_row(row))]\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"oc_{track_name.lower().replace(' ', '')}_{start_time.strftime('%Y%m%d')}_r{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _parse_runner_row(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"span.selection-name\")\n            if not name_node:\n                return None\n            name = name_node.get_text(strip=True)\n\n            odds_node = row.select_one(\"span.bet-button-odds-desktop, span.best-price\")\n            if not odds_node:\n                return None\n            odds_str = odds_node.get_text(strip=True)\n\n            number_node = row.select_one(\"td.runner-number\")\n            if not number_node or not number_node.get_text(strip=True).isdigit():\n                return None\n            number = int(number_node.get_text(strip=True))\n\n            if not name or not odds_str:\n                return None\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_dict = {}\n            if win_odds and win_odds < 999:\n                odds_dict[self.source_name] = OddsData(\n                    win=win_odds, source=self.source_name, last_updated=datetime.now()\n                )\n\n            return Runner(number=number, name=name, odds=odds_dict)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on Oddschecker, skipping runner.\")\n            return None\n",
    "web_service/backend/adapters/racingpost_adapter.py": "# python_service/adapters/racingpost_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingPostAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Racing Post racecards, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"RacingPost\"\n    BASE_URL = \"https://www.racingpost.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw HTML content for all races on a given date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch RacingPost index page\", url=index_url)\n            return None\n\n        index_parser = HTMLParser(index_response.text)\n        links = index_parser.css('a[data-test-selector^=\"RC-meetingItem__link_race\"]')\n        race_card_urls = [link.attributes[\"href\"] for link in links]\n\n        async def fetch_single_html(url: str):\n            response = await self.make_request(self.http_client, \"GET\", url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(url) for url in race_card_urls]\n        html_contents = await asyncio.gather(*tasks)\n        return {\"date\": date, \"html_contents\": html_contents}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"html_contents\"):\n            return []\n\n        date = raw_data[\"date\"]\n        html_contents = raw_data[\"html_contents\"]\n        all_races: List[Race] = []\n\n        for html in html_contents:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first('a[data-test-selector=\"RC-course__name\"]')\n                if not venue_node:\n                    continue\n                venue_raw = venue_node.text(strip=True)\n                venue = normalize_venue_name(venue_raw)\n\n                race_time_node = parser.css_first('span[data-test-selector=\"RC-course__time\"]')\n                if not race_time_node:\n                    continue\n                race_time_str = race_time_node.text(strip=True)\n\n                race_datetime_str = f\"{date} {race_time_str}\"\n                start_time = datetime.strptime(race_datetime_str, \"%Y-%m-%d %H:%M\")\n\n                runners = self._parse_runners(parser)\n\n                if venue and runners:\n                    race_number = self._get_race_number(parser, start_time)\n                    race = Race(\n                        id=f\"rp_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=start_time,\n                        runners=runners,\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse RacingPost race from HTML content.\", exc_info=True)\n                continue\n        return all_races\n\n    def _get_race_number(self, parser: HTMLParser, start_time: datetime) -> int:\n        \"\"\"Derives the race number by finding the active time in the nav bar.\"\"\"\n        time_str_to_find = start_time.strftime(\"%H:%M\")\n        time_links = parser.css('a[data-test-selector=\"RC-raceTime\"]')\n        for i, link in enumerate(time_links):\n            if link.text(strip=True) == time_str_to_find:\n                return i + 1\n        return 1\n\n    def _parse_runners(self, parser: HTMLParser) -> list[Runner]:\n        \"\"\"Parses all runners from a single race card page.\"\"\"\n        runners = []\n        runner_nodes = parser.css('div[data-test-selector=\"RC-runnerCard\"]')\n        for node in runner_nodes:\n            if runner := self._parse_runner(node):\n                runners.append(runner)\n        return runners\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first('span[data-test-selector=\"RC-runnerNumber\"]')\n            name_node = node.css_first('a[data-test-selector=\"RC-runnerName\"]')\n            odds_node = node.css_first('span[data-test-selector=\"RC-runnerPrice\"]')\n\n            if not all([number_node, name_node, odds_node]):\n                return None\n\n            number_str = clean_text(number_node.text())\n            number = int(number_str) if number_str and number_str.isdigit() else 0\n            name = clean_text(name_node.text())\n            odds_str = clean_text(odds_node.text())\n            scratched = \"NR\" in odds_str.upper() or not odds_str\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError):\n            self.logger.warning(\"Could not parse RacingPost runner, skipping.\", exc_info=True)\n            return None\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "web_service/backend/adapters/the_racing_api_adapter.py": "# python_service/adapters/the_racing_api_adapter.py\n\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TheRacingApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for The Racing API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"TheRacingAPI\"\n    BASE_URL = \"https://api.theracingapi.com/v1/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"THE_RACING_API_KEY\") or not config.THE_RACING_API_KEY:\n            raise AdapterConfigError(self.source_name, \"THE_RACING_API_KEY is not configured.\")\n        self.api_key = config.THE_RACING_API_KEY\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw racecard data from The Racing API.\"\"\"\n        endpoint = f\"racecards?date={date}&course=all&region=gb,ire\"\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n        response = await self.make_request(self.http_client, \"GET\", endpoint, headers=headers)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw JSON response into a list of Race objects.\"\"\"\n        if not raw_data or \"racecards\" not in raw_data:\n            self.logger.warning(\"'racecards' key missing in TheRacingAPI response.\")\n            return []\n\n        races = []\n        for race_data in raw_data.get(\"racecards\", []):\n            try:\n                race_id = race_data.get(\"race_id\")\n                off_time = race_data.get(\"off_time\")\n                course = race_data.get(\"course\")\n                race_no = race_data.get(\"race_no\")\n\n                if not all([race_id, off_time, course, race_no]):\n                    continue\n\n                start_time = datetime.fromisoformat(off_time.replace(\"Z\", \"+00:00\"))\n\n                race = Race(\n                    id=f\"tra_{race_id}\",\n                    venue=course,\n                    race_number=race_no,\n                    start_time=start_time,\n                    runners=self._parse_runners(race_data.get(\"runners\", [])),\n                    source=self.source_name,\n                    race_name=race_data.get(\"race_name\"),\n                    distance=race_data.get(\"distance_f\"),\n                )\n                races.append(race)\n            except Exception:\n                self.logger.error(\n                    \"Error parsing TheRacingAPI race\",\n                    race_id=race_data.get(\"race_id\"),\n                    exc_info=True,\n                )\n        return races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for i, runner_data in enumerate(runners_data):\n            try:\n                horse = runner_data.get(\"horse\")\n                if not horse:\n                    continue\n\n                odds_data = {}\n                odds_list = runner_data.get(\"odds\", [])\n                if odds_list:\n                    odds_decimal_str = odds_list[0].get(\"odds_decimal\")\n                    if odds_decimal_str:\n                        win_odds = Decimal(str(odds_decimal_str))\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=runner_data.get(\"number\", i + 1),\n                        name=horse,\n                        odds=odds_data,\n                        jockey=runner_data.get(\"jockey\"),\n                        trainer=runner_data.get(\"trainer\"),\n                    )\n                )\n            except Exception:\n                self.logger.error(\n                    \"Error parsing TheRacingAPI runner\",\n                    runner_name=runner_data.get(\"horse\"),\n                    exc_info=True,\n                )\n        return runners\n",
    "web_service/backend/adapters/utils.py": "# python_service/adapters/utils.py\n# Compatibility shim to re-export parse_odds from the centralized location.\n\nfrom ..utils.odds import parse_odds\n\n__all__ = [\"parse_odds\"]\n",
    "web_service/backend/config.py": "# python_service/config.py\nimport os\nimport sys\nfrom functools import lru_cache\nfrom pathlib import Path\nfrom typing import List\nfrom typing import Optional\n\nimport structlog\nfrom pydantic import Field\nfrom pydantic import model_validator\nfrom pydantic_settings import BaseSettings\n\nfrom .credentials_manager import SecureCredentialsManager\n\n# --- Encryption Setup ---\ntry:\n    from cryptography.fernet import Fernet\n\n    ENCRYPTION_ENABLED = True\nexcept ImportError:\n    ENCRYPTION_ENABLED = False\n\nKEY_FILE = Path(\".key\")\nCIPHER = None\nif ENCRYPTION_ENABLED and KEY_FILE.exists():\n    with open(KEY_FILE, \"rb\") as f:\n        key = f.read()\n    CIPHER = Fernet(key)\n\n\ndef decrypt_value(value: Optional[str]) -> str:\n    \"\"\"If a value is encrypted, decrypts it. Otherwise, returns it as is.\"\"\"\n    if value and value.startswith(\"encrypted:\") and CIPHER:\n        try:\n            return CIPHER.decrypt(value[10:].encode()).decode()\n        except Exception:\n            structlog.get_logger(__name__).error(\"Decryption failed on field.\")\n            return \"\"  # Fallback to an empty string on failure\n    return value or \"\"  # Ensure a non-None return value even if input is None\n\n\nclass Settings(BaseSettings):\n    API_KEY: str = Field(\"\")\n\n    # --- API Gateway Configuration ---\n    UVICORN_HOST: str = \"127.0.0.1\"\n    FORTUNA_PORT: int = 8000\n    UVICORN_RELOAD: bool = True\n\n    # --- Database Configuration ---\n    DATABASE_TYPE: str = \"sqlite\"\n    DATABASE_URL: str = \"sqlite:///./fortuna.db\"\n\n    # --- Optional Betfair Credentials ---\n    BETFAIR_APP_KEY: Optional[str] = None\n\n    # --- Caching & Performance ---\n    REDIS_URL: str = \"redis://localhost:6379\"\n    CACHE_TTL_SECONDS: int = 1800  # 30 minutes\n    MAX_CONCURRENT_REQUESTS: int = 10\n    HTTP_POOL_CONNECTIONS: int = 100\n    HTTP_POOL_MAXSIZE: int = 100\n    HTTP_MAX_KEEPALIVE: int = 50\n    DEFAULT_TIMEOUT: int = 30\n    ADAPTER_TIMEOUT: int = 20\n\n    # --- Logging ---\n    LOG_LEVEL: str = \"INFO\"\n\n    # --- Optional Adapter Keys ---\n    NEXT_PUBLIC_API_KEY: Optional[str] = None  # Allow frontend key to be present in .env\n    TVG_API_KEY: Optional[str] = None\n    RACING_AND_SPORTS_TOKEN: Optional[str] = None\n    POINTSBET_API_KEY: Optional[str] = None\n    GREYHOUND_API_URL: Optional[str] = None\n    THE_RACING_API_KEY: Optional[str] = None\n\n    # --- CORS Configuration ---\n    ALLOWED_ORIGINS: List[str] = [\"http://localhost:3000\", \"http://localhost:3001\"]\n\n    # --- Dynamic Path Configuration ---\n    # This determines the path to static files, crucial for PyInstaller builds\n    STATIC_FILES_DIR: Optional[str] = None\n\n    model_config = {\"env_file\": \".env\", \"case_sensitive\": True}\n\n    @model_validator(mode=\"after\")\n    def process_settings(self) -> \"Settings\":\n        \"\"\"\n        This validator runs after the initial settings are loaded from .env and\n        performs two key functions:\n        1. If API_KEY is missing, it falls back to the SecureCredentialsManager.\n        2. It decrypts any fields that were loaded from the .env file.\n        \"\"\"\n        # 1. Fallback for API_KEY\n        if not self.API_KEY:\n            self.API_KEY = SecureCredentialsManager.get_credential(\"api_key\") or \"MISSING\"\n\n        # 2. Security validation for API_KEY\n        insecure_keys = {\"test\", \"changeme\", \"default\", \"secret\", \"password\", \"admin\"}\n        if self.API_KEY in insecure_keys:\n            structlog.get_logger(__name__).warning(\n                \"insecure_api_key\",\n                key=self.API_KEY,\n                recommendation=\"The API_KEY should be a long, random string for security.\",\n            )\n\n        # 2. Decrypt sensitive fields\n        self.BETFAIR_APP_KEY = decrypt_value(self.BETFAIR_APP_KEY)\n\n        # 3. Set the static files directory for packaged apps\n        if getattr(sys, \"frozen\", False):\n            # Running in a PyInstaller bundle\n            self.STATIC_FILES_DIR = os.path.join(sys._MEIPASS, \"ui\")\n        else:\n            # Running in a normal Python environment\n            self.STATIC_FILES_DIR = None  # Not needed for local dev\n\n        return self\n\n\n@lru_cache()\ndef get_settings() -> Settings:\n    \"\"\"Loads settings and performs a proactive check for legacy paths.\"\"\"\n    log = structlog.get_logger(__name__)\n    if ENCRYPTION_ENABLED and not KEY_FILE.exists():\n        log.warning(\n            \"encryption_key_not_found\",\n            file=str(KEY_FILE),\n            recommendation=\"Run 'python manage_secrets.py' to generate a key.\",\n        )\n\n    settings = Settings()\n\n    # --- Legacy Path Detection ---\n    legacy_paths = [\"attic/\", \"checkmate_web/\", \"vba_source/\"]\n    for path in legacy_paths:\n        if os.path.exists(path):\n            log.warning(\n                \"legacy_path_detected\",\n                path=path,\n                recommendation=\"This directory is obsolete and should be removed for optimal performance and security.\",\n            )\n\n    return settings\n",
    "web_service/backend/db/init.py": "# python_service/db/init.py\nimport os\nimport sqlite3\n\nfrom ..config import get_settings\n\n\ndef initialize_database():\n    \"\"\"\n    Initializes the database based on the configuration.\n    Currently supports a simple SQLite fallback for local testing.\n    \"\"\"\n    settings = get_settings()\n    db_type = getattr(settings, \"DATABASE_TYPE\", \"sqlite\").lower()\n\n    if db_type == \"sqlite\":\n        # DATABASE_URL for sqlite will be like 'sqlite:///./fortuna.db'\n        db_path = settings.DATABASE_URL.split(\"///\")[1]\n\n        # Ensure the directory for the database exists\n        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n\n        try:\n            conn = sqlite3.connect(db_path)\n            cursor = conn.cursor()\n\n            # The schema is based on the provided pg_schemas, adapted for SQLite\n            # This is a simplified version for demonstration.\n            cursor.execute(\n                \"\"\"\n            CREATE TABLE IF NOT EXISTS races (\n                id TEXT PRIMARY KEY,\n                venue TEXT NOT NULL,\n                race_number INTEGER NOT NULL,\n                start_time TEXT NOT NULL,\n                source TEXT,\n                field_size INTEGER\n            )\n            \"\"\"\n            )\n\n            cursor.execute(\n                \"\"\"\n            CREATE TABLE IF NOT EXISTS runners (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                race_id TEXT,\n                number INTEGER,\n                name TEXT,\n                odds REAL,\n                FOREIGN KEY (race_id) REFERENCES races (id)\n            )\n            \"\"\"\n            )\n\n            conn.commit()\n            conn.close()\n            print(\"SQLite database initialized successfully.\")\n        except sqlite3.Error as e:\n            print(f\"Error initializing SQLite database: {e}\")\n            raise\n",
    "web_service/backend/health.py": "# python_service/health.py\nfrom datetime import datetime\nfrom typing import Dict\nfrom typing import List\n\nimport psutil\nimport structlog\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\nlog = structlog.get_logger(__name__)\n\n\nclass HealthMonitor:\n    def __init__(self):\n        self.adapter_health: Dict[str, Dict] = {}\n        self.system_metrics: List[Dict] = []\n        self.max_metrics_history = 100\n\n    def record_adapter_response(self, adapter_name: str, success: bool, duration: float):\n        if adapter_name not in self.adapter_health:\n            self.adapter_health[adapter_name] = {\n                \"total_requests\": 0,\n                \"successful_requests\": 0,\n                \"failed_requests\": 0,\n                \"avg_response_time\": 0.0,\n                \"last_success\": None,\n                \"last_failure\": None,\n            }\n\n        health = self.adapter_health[adapter_name]\n        health[\"total_requests\"] += 1\n\n        if success:\n            health[\"successful_requests\"] += 1\n            health[\"last_success\"] = datetime.now().isoformat()\n        else:\n            health[\"failed_requests\"] += 1\n            health[\"last_failure\"] = datetime.now().isoformat()\n\n        health[\"avg_response_time\"] = (\n            health[\"avg_response_time\"] * (health[\"total_requests\"] - 1) + duration\n        ) / health[\"total_requests\"]\n\n    def get_system_metrics(self) -> Dict:\n        cpu_percent = psutil.cpu_percent(interval=1)\n        memory = psutil.virtual_memory()\n        disk = psutil.disk_usage(\"/\")\n\n        metrics = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"cpu_percent\": cpu_percent,\n            \"memory_percent\": memory.percent,\n            \"memory_available_gb\": round(memory.available / (1024**3), 2),\n            \"disk_percent\": disk.percent,\n            \"disk_free_gb\": round(disk.free / (1024**3), 2),\n        }\n\n        self.system_metrics.append(metrics)\n        if len(self.system_metrics) > self.max_metrics_history:\n            self.system_metrics.pop(0)\n\n        return metrics\n\n    def get_health_report(self) -> Dict:\n        system_metrics = self.get_system_metrics()\n        return {\n            \"status\": \"healthy\" if self.is_system_healthy() else \"degraded\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"system\": system_metrics,\n            \"adapters\": self.adapter_health,\n            \"metrics_history\": self.system_metrics[-10:],\n        }\n\n    def is_system_healthy(self) -> bool:\n        if not self.system_metrics:\n            return True\n        latest = self.system_metrics[-1]\n        return latest[\"cpu_percent\"] < 80 and latest[\"memory_percent\"] < 85 and latest[\"disk_percent\"] < 90\n\n\nimport time\nfrom fastapi import Response\nfrom .version import get_version\n\n# Global instance for the application to use\nhealth_monitor = HealthMonitor()\nstart_time = time.time()\n\n\n@router.get(\"/health/detailed\", tags=[\"Health\"])\nasync def get_detailed_health():\n    \"\"\"Provides a comprehensive health check of the system.\"\"\"\n    return health_monitor.get_health_report()\n\n\n@router.get(\"/health\", tags=[\"Health\"])\nasync def get_basic_health(response: Response):\n    \"\"\"Provides a basic health check for load balancers and uptime monitoring.\"\"\"\n    uptime_seconds = time.time() - start_time\n    # Simple dependency check: assume healthy if we have adapter data\n    dependencies_healthy = len(health_monitor.adapter_health) > 0\n    status = \"ok\" if dependencies_healthy else \"degraded\"\n\n    # The service is still \"healthy\" even if degraded. The status is in the payload.\n    # if not dependencies_healthy:\n    #     response.status_code = 503 # Service Unavailable\n\n    return {\n        \"status\": status,\n        \"timestamp\": datetime.now().isoformat(),\n        \"version\": get_version(),\n        \"uptime_seconds\": int(uptime_seconds),\n        \"dependencies\": {\n            \"database\": \"connected\", # Placeholder\n            \"external_api\": \"healthy\" # Placeholder\n        }\n    }\n",
    "web_service/backend/manual_override_manager.py": "# python_service/manual_override_manager.py\nimport hashlib\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\n\nfrom pydantic import BaseModel\nfrom pydantic import Field\n\n\nclass ManualOverrideRequest(BaseModel):\n    request_id: str\n    adapter_name: str\n    url: str\n    timestamp: datetime = Field(default_factory=datetime.now)\n    status: str = \"pending\"  # pending, submitted, skipped\n\n\nclass ManualOverrideManager:\n    def __init__(self):\n        self._requests: Dict[str, ManualOverrideRequest] = {}\n        self._data: Dict[str, Tuple[str, str]] = {}  # request_id -> (content, content_type)\n\n    def _generate_id(self, adapter_name: str, url: str) -> str:\n        \"\"\"Generates a consistent ID for a given adapter and URL.\"\"\"\n        return hashlib.sha256(f\"{adapter_name}:{url}\".encode()).hexdigest()[:16]\n\n    def register_failure(self, adapter_name: str, url: str) -> str:\n        \"\"\"\n        Registers a failed fetch attempt and returns a unique request ID.\n        If a pending request for this exact resource already exists, it returns the existing ID.\n        \"\"\"\n        request_id = self._generate_id(adapter_name, url)\n        if request_id not in self._requests or self._requests[request_id].status != \"pending\":\n            request = ManualOverrideRequest(request_id=request_id, adapter_name=adapter_name, url=url)\n            self._requests[request_id] = request\n        return request_id\n\n    def submit_manual_data(self, request_id: str, raw_content: str, content_type: str) -> bool:\n        \"\"\"Submits manual data for a pending request.\"\"\"\n        if request_id in self._requests and self._requests[request_id].status == \"pending\":\n            self._data[request_id] = (raw_content, content_type)\n            self._requests[request_id].status = \"submitted\"\n            return True\n        return False\n\n    def skip_request(self, request_id: str) -> bool:\n        \"\"\"Marks a pending request as skipped.\"\"\"\n        if request_id in self._requests and self._requests[request_id].status == \"pending\":\n            self._requests[request_id].status = \"skipped\"\n            return True\n        return False\n\n    def get_pending_requests(self) -> List[ManualOverrideRequest]:\n        \"\"\"Returns a list of all requests that are currently pending.\"\"\"\n        return [req for req in self._requests.values() if req.status == \"pending\"]\n\n    def get_manual_data(self, adapter_name: str, url: str) -> Optional[Tuple[str, str]]:\n        \"\"\"\n        Retrieves submitted manual data for a given adapter and URL, if it exists.\n        Once retrieved, the data is consumed and will not be returned again.\n        \"\"\"\n        request_id = self._generate_id(adapter_name, url)\n        if request_id in self._data:\n            # Data is single-use; remove it after retrieval.\n            return self._data.pop(request_id)\n        return None\n\n    def clear_old_requests(self, max_age_hours: int = 24):\n        \"\"\"Removes requests and associated data older than a specified age.\"\"\"\n        cutoff = datetime.now() - timedelta(hours=max_age_hours)\n        old_request_ids = [req_id for req_id, req in self._requests.items() if req.timestamp < cutoff]\n        for req_id in old_request_ids:\n            self._requests.pop(req_id, None)\n            self._data.pop(req_id, None)\n",
    "web_service/backend/monolith.py": "\"\"\"\nFortuna Monolith - Single executable frontend + backend\nProduction-grade with enhanced error handling, user-friendly startup, and better logging\n\nIMPORTANT: Uses WinForms instead of CEF for Python 3.10 compatibility\n(CEFPython3 v66.0 doesn't support Python 3.10.11)\n\"\"\"\nimport sys\nimport os\nfrom pathlib import Path\nimport logging\nimport io\nimport threading\nimport time\nimport json\nfrom contextlib import suppress\n\n# ====================================================================\n# CONSTANTS & CONFIGURATION\n# ====================================================================\nAPP_NAME = \"Fortuna Faucet\"\nAPP_VERSION = \"1.0.0\"\nAPI_HOST = \"127.0.0.1\"\nAPI_PORT = 8000\nBACKEND_STARTUP_TIMEOUT = 10\nHEALTH_CHECK_ATTEMPTS = 10\nHEALTH_CHECK_INTERVAL = 1\n\n# ====================================================================\n# LOGGING SETUP (BEFORE ANYTHING ELSE)\n# ====================================================================\ndef _get_log_file() -> Path:\n    \"\"\"Get log file path (works in both dev and frozen modes)\"\"\"\n    if getattr(sys, \"frozen\", False):\n        log_dir = Path(os.environ.get(\"TEMP\", \".\"))\n    else:\n        log_dir = Path(\".\")\n    return log_dir / \"fortuna-monolith.log\"\n\ndef _force_utf8_stream(stream):\n    \"\"\"Ensure stream uses UTF-8 encoding\"\"\"\n    if hasattr(stream, \"reconfigure\"):\n        with suppress(Exception):\n            stream.reconfigure(encoding=\"utf-8\", errors=\"replace\")\n            return stream\n\n    buffer = getattr(stream, \"buffer\", None)\n    if buffer is None:\n        return stream\n\n    with suppress(Exception):\n        return io.TextIOWrapper(buffer, encoding=\"utf-8\", errors=\"replace\")\n\n    return stream\n\ndef setup_logging():\n    \"\"\"Configure logging to both file and console\"\"\"\n    log_file = _get_log_file()\n\n    # Force UTF-8 on stdout/stderr\n    sys.stdout = _force_utf8_stream(sys.stdout)\n    sys.stderr = _force_utf8_stream(sys.stderr)\n\n    # Logging handlers\n    file_handler = logging.FileHandler(log_file, mode=\"w\", encoding=\"utf-8\")\n    console_handler = logging.StreamHandler(sys.stdout)\n\n    # Format with timestamps\n    formatter = logging.Formatter(\n        \"[%(levelname)-8s] %(asctime)s - %(message)s\",\n        datefmt=\"%H:%M:%S\"\n    )\n    file_handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n\n    # Setup root logger\n    logging.basicConfig(\n        level=logging.INFO,\n        handlers=[file_handler, console_handler],\n    )\n\n    logger = logging.getLogger(\"fortuna\")\n    return logger\n\nlogger = setup_logging()\n\n# Banner\nlogger.info(\"=\" * 70)\nlogger.info(f\"{APP_NAME} v{APP_VERSION} - Starting up\")\nlogger.info(\"=\" * 70)\nlogger.info(f\"Mode: {'Frozen EXE' if getattr(sys, 'frozen', False) else 'Development'}\")\nlogger.info(f\"Python: {sys.version.split()[0]}\")\n\n# ====================================================================\n# UI HELPERS (DEFINE BEFORE IMPORTS)\n# ====================================================================\ndef show_error_dialog(title: str, message: str):\n    \"\"\"Show error dialog (fallback if no GUI available)\"\"\"\n    try:\n        import tkinter as tk\n        from tkinter import messagebox\n        root = tk.Tk()\n        root.withdraw()\n        messagebox.showerror(title, message)\n    except:\n        # If tkinter fails, just log it\n        logger.error(f\"{title}: {message}\")\n\n# ====================================================================\n# FORCE PYINSTALLER TO INCLUDE DEPENDENCIES (TOP-LEVEL IMPORTS)\n# ====================================================================\nif False:  # Never executes, but PyInstaller sees the imports\n    import fastapi\n    import uvicorn\n    import webview\n    import pydantic\n    import starlette\n    import requests\n    from fastapi import FastAPI\n    from fastapi.staticfiles import StaticFiles\n    from fastapi.middleware.cors import CORSMiddleware\n    from fastapi.responses import FileResponse, JSONResponse\n\n# ====================================================================\n# IMPORT DEPENDENCIES WITH FRIENDLY ERROR HANDLING\n# ====================================================================\ndef _import_dependencies():\n    \"\"\"Import all required modules with descriptive error messages\"\"\"\n    try:\n        global uvicorn, webview, FastAPI, StaticFiles, CORSMiddleware, FileResponse, JSONResponse, requests\n\n        import requests\n        import uvicorn\n        import webview\n        from fastapi import FastAPI\n        from fastapi.staticfiles import StaticFiles\n        from fastapi.middleware.cors import CORSMiddleware\n        from fastapi.responses import FileResponse, JSONResponse\n\n        logger.info(\"OK - All dependencies loaded successfully\")\n        return True\n    except ImportError as e:\n        logger.critical(f\"FAILED - Missing dependency: {e}\")\n        show_error_dialog(\n            \"Missing Dependencies\",\n            f\"Could not load required library:\\n{str(e)}\\n\\n\"\n            \"Ensure all packages in requirements.txt are installed:\\n\"\n            \"pip install -r web_service/backend/requirements.txt\"\n        )\n        return False\n    except Exception as e:\n        logger.critical(f\"FAILED - Unexpected import error: {e}\", exc_info=True)\n        show_error_dialog(\n            \"Startup Error\",\n            f\"Unexpected error during startup:\\n{str(e)}\\n\\n\"\n            f\"Check the log file for details:\\n{_get_log_file()}\"\n        )\n        return False\n\nif not _import_dependencies():\n    sys.exit(1)\n\n# ====================================================================\n# UTILITY FUNCTIONS\n# ====================================================================\ndef get_resource_path(relative_path: str) -> Path:\n    \"\"\"Get absolute path to bundled resources\"\"\"\n    if getattr(sys, \"frozen\", False):\n        base_path = Path(sys._MEIPASS)\n    else:\n        base_path = Path(__file__).parent.parent.parent\n\n    full_path = base_path / relative_path\n    return full_path\n\n# ====================================================================\n# API CREATION\n# ====================================================================\ndef create_backend_api():\n    \"\"\"Create FastAPI instance with fallback support\"\"\"\n    api = FastAPI(title=\"Fortuna Backend\")\n\n    @api.get(\"/health\")\n    async def health():\n        \"\"\"Health check endpoint\"\"\"\n        return {\n            \"status\": \"ok\",\n            \"service\": \"fortuna-monolith\",\n            \"version\": APP_VERSION\n        }\n\n    try:\n        logger.info(\"Attempting to load full backend API...\")\n        from web_service.backend import api as backend_api\n\n        # Copy routes from full backend\n        for route in backend_api.app.routes:\n            api.routes.append(route)\n\n        logger.info(f\"OK - Full backend API loaded ({len(api.routes)} routes)\")\n        return api\n\n    except (ImportError, AttributeError) as e:\n        logger.warning(f\"Full backend import failed: {e}\")\n        logger.info(\"Running in minimal mode (basic endpoints only)\")\n\n        # Provide stub endpoints\n        @api.get(\"/races\")\n        async def get_races():\n            return {\n                \"status\": \"error\",\n                \"message\": \"Full API not available\",\n                \"sample\": [{\"id\": 1, \"name\": \"Example Race\", \"status\": \"pending\"}]\n            }\n\n        return api\n\n    except Exception as e:\n        logger.error(f\"Unexpected error loading backend: {e}\", exc_info=True)\n        return api\n\n# ====================================================================\n# APP CREATION\n# ====================================================================\ndef create_app():\n    \"\"\"Create main FastAPI application\"\"\"\n    logger.info(\"Creating FastAPI application...\")\n    app = FastAPI(title=\"Fortuna Monolith\")\n\n    # CORS for local development\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n    logger.info(\"OK - CORS middleware configured\")\n\n    # Mount backend API\n    logger.info(\"Mounting backend API at /api...\")\n    backend = create_backend_api()\n    app.mount(\"/api\", backend, name=\"backend\")\n\n    # Setup frontend serving\n    frontend_path = get_resource_path(\"frontend_dist\")\n    index_file = frontend_path / \"index.html\"\n\n    logger.info(f\"Frontend path: {frontend_path}\")\n\n    if not frontend_path.exists():\n        logger.error(\"Frontend directory not found - app will run without UI\")\n\n        @app.get(\"/\")\n        async def fallback():\n            return JSONResponse(\n                {\"message\": \"Frontend not available\", \"api\": \"/api/health\"},\n                status_code=503\n            )\n        return app\n\n    # Mount static files\n    logger.info(\"Configuring static file serving...\")\n\n    # Mount Next.js build output\n    next_dir = frontend_path / \"_next\"\n    if next_dir.exists():\n        app.mount(\"/_next\", StaticFiles(directory=str(next_dir)), name=\"next\")\n        logger.info(\"OK - Static assets mounted\")\n\n    public_dir = frontend_path / \"public\"\n    if public_dir.exists():\n        app.mount(\"/public\", StaticFiles(directory=str(public_dir)), name=\"public\")\n\n    # SPA routing - catch all unmapped routes and serve index.html\n    @app.get(\"/{full_path:path}\")\n    async def serve_spa(full_path: str):\n        # Skip API routes\n        if full_path.startswith(\"api/\"):\n            return JSONResponse({\"error\": \"Not found\"}, status_code=404)\n\n        # Try exact file\n        file_path = frontend_path / full_path\n        try:\n            if file_path.is_file() and file_path.is_relative_to(frontend_path):\n                return FileResponse(file_path)\n        except (ValueError, RuntimeError):\n            pass\n\n        # Try with .html extension\n        html_path = frontend_path / f\"{full_path}.html\"\n        try:\n            if html_path.is_file() and html_path.is_relative_to(frontend_path):\n                return FileResponse(html_path)\n        except (ValueError, RuntimeError):\n            pass\n\n        # SPA fallback to index\n        if index_file.exists():\n            return FileResponse(index_file)\n\n        return JSONResponse({\"error\": \"Not found\"}, status_code=404)\n\n    logger.info(\"OK - SPA routing configured\")\n    return app\n\n# ====================================================================\n# BACKEND SERVER\n# ====================================================================\ndef run_backend():\n    \"\"\"Run Uvicorn server\"\"\"\n    try:\n        logger.info(\"-\" * 70)\n        logger.info(\"STARTING BACKEND SERVER\")\n        logger.info(f\"API: http://{API_HOST}:{API_PORT}\")\n        logger.info(\"-\" * 70)\n\n        app = create_app()\n\n        # Run Uvicorn\n        uvicorn.run(\n            app,\n            host=API_HOST,\n            port=API_PORT,\n            log_level=\"warning\",\n            access_log=False,\n        )\n    except OSError as e:\n        logger.critical(f\"Port {API_PORT} is already in use: {e}\")\n        raise\n    except Exception as e:\n        logger.critical(f\"Backend error: {e}\", exc_info=True)\n        raise\n\n# ====================================================================\n# HEALTH CHECKS\n# ====================================================================\ndef check_backend_health(max_attempts: int = HEALTH_CHECK_ATTEMPTS) -> bool:\n    \"\"\"Check if backend is responding\"\"\"\n    logger.info(\"Testing backend health...\")\n\n    for attempt in range(1, max_attempts + 1):\n        try:\n            response = requests.get(\n                f\"http://{API_HOST}:{API_PORT}/api/health\",\n                timeout=2\n            )\n\n            if response.status_code == 200:\n                data = response.json()\n                logger.info(f\"OK - Backend responding: {data}\")\n                return True\n\n        except requests.ConnectionError:\n            if attempt < max_attempts:\n                logger.debug(f\"Attempt {attempt}/{max_attempts} - waiting...\")\n                time.sleep(HEALTH_CHECK_INTERVAL)\n        except Exception as e:\n            logger.warning(f\"Health check error: {e}\")\n\n    logger.warning(f\"Backend did not respond after {max_attempts} attempts\")\n    return False\n\n# ====================================================================\n# MAIN APPLICATION\n# ====================================================================\ndef main():\n    \"\"\"Main entry point\"\"\"\n    try:\n        logger.info(\"-\" * 70)\n        logger.info(f\"STARTING {APP_NAME}\")\n        logger.info(\"-\" * 70)\n\n        # Start backend in background\n        logger.info(\"Starting backend server...\")\n        backend_thread = threading.Thread(target=run_backend, daemon=True)\n        backend_thread.start()\n        logger.info(\"OK - Backend thread started\")\n\n        # Wait for backend to initialize\n        logger.info(f\"Waiting for backend to be ready (max {BACKEND_STARTUP_TIMEOUT}s)...\")\n        time.sleep(2)\n\n        # Health check\n        backend_ready = check_backend_health()\n\n        if not backend_ready:\n            logger.warning(\"Backend not responding - launching UI anyway\")\n\n        # Launch UI\n        logger.info(\"-\" * 70)\n        logger.info(\"LAUNCHING USER INTERFACE\")\n        logger.info(\"-\" * 70)\n\n        try:\n            # Use WinForms GUI (default on Windows, compatible with Python 3.10)\n            # CEF is not used here to avoid Python version compatibility issues\n            webview.create_window(\n                title=APP_NAME,\n                url=f\"http://{API_HOST}:{API_PORT}\",\n                width=1400,\n                height=900,\n                resizable=True,\n                min_size=(800, 600),\n                background_color=\"#1a1a1a\",\n            )\n\n            logger.info(\"Starting webview event loop...\")\n            # Don't specify gui='cef' - let pywebview auto-detect WinForms\n            webview.start(debug=False)\n\n        except Exception as e:\n            logger.error(f\"Webview error: {e}\", exc_info=True)\n            # Fall back to browser message\n            logger.info(f\"Open http://{API_HOST}:{API_PORT} in your browser\")\n            input(\"Press ENTER to exit...\")\n\n        logger.info(f\"{APP_NAME} closed normally\")\n\n    except KeyboardInterrupt:\n        logger.info(\"Application interrupted by user\")\n    except Exception as e:\n        logger.critical(f\"Fatal error: {e}\", exc_info=True)\n        show_error_dialog(\n            f\"{APP_NAME} Error\",\n            f\"Application failed to start:\\n{str(e)}\\n\\n\"\n            f\"Please check the log file at:\\n{_get_log_file()}\"\n        )\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
    "web_service/backend/notifications.py": "# python_service/notifications.py\n\nimport sys\n\nimport structlog\n\nlog = structlog.get_logger(__name__)\n\n\ndef send_toast(title: str, message: str):\n    \"\"\"\n    Sends a desktop notification. This function is platform-aware and will only\n    attempt to send a toast on Windows. On other operating systems, it will\n    log the notification content.\n    \"\"\"\n    if sys.platform == \"win32\":\n        try:\n            from windows_toasts import Toast\n            from windows_toasts import WindowsToaster\n\n            toaster = WindowsToaster(title)\n            new_toast = Toast()\n            new_toast.text_fields = [message]\n            toaster.show_toast(new_toast)\n            log.info(\"Sent Windows toast notification.\", title=title, message=message)\n        except ImportError:\n            log.warning(\n                \"windows_toasts library not found, skipping notification.\",\n                recommendation=\"Install with: pip install windows-toasts\",\n            )\n        except Exception:\n            log.error(\"Failed to send Windows toast notification.\", exc_info=True)\n    else:\n        log.info(\n            \"Skipping toast notification on non-Windows platform.\",\n            platform=sys.platform,\n            title=title,\n            message=message,\n        )\n",
    "web_service/backend/requirements-x86.txt": "#\n# This file is a modified version of requirements.txt for x86 architecture compatibility.\n# Some packages are pinned to older versions that provide x86 wheels.\n#\naiosqlite==0.17.0\n    # via -r web_service/backend/requirements.in\naltgraph==0.17.4\n    # via pyinstaller\nannotated-types==0.7.0\n    # via pydantic\nanyio==3.7.1\n    # via\n    #   httpx\n    #   starlette\n    #   watchfiles\nasync-timeout==5.0.1\n    # via redis\nbeautifulsoup4==4.12.3\n    # via -r web_service/backend/requirements.in\nblack==24.4.2\n    # via -r web_service/backend/requirements.in\nbuild==1.2.1\n    # via pip-tools\ncertifi==2024.7.4\n    # via\n    #   -r web_service/backend/requirements.in\n    #   httpcore\n    #   httpx\n    #   requests\ncffi==1.16.0\n    # via cryptography\ncharset-normalizer==3.3.2\n    # via requests\nclick==8.1.7\n    # via\n    #   black\n    #   pip-tools\n    #   rich-toolkit\n    #   typer\n    #   uvicorn\ncryptography==42.0.8\n    # via\n    #   -r web_service/backend/requirements.in\n    #   secretstorage\ndeprecated==1.2.14\n    # via limits\ndnspython==2.7.0\n    # via email-validator\nemail-validator==2.3.0\n    # via fastapi\nexceptiongroup==1.3.1\n    # via\n    #   anyio\n    #   pytest\nfastapi==0.111.0\n    # via -r web_service/backend/requirements.in\nfastapi-cli==0.0.20\n    # via fastapi\ngreenlet==1.1.2  # x86 PINNED\n    # via\n    #   -r web_service/backend/requirements.in\n    #   sqlalchemy\nh11==0.14.0\n    # via\n    #   httpcore\n    #   uvicorn\nh2==4.1.0\n    # via httpx\nhpack==4.0.0\n    # via h2\nhttpcore==1.0.5\n    # via httpx\nhttptools==0.7.1\n    # via uvicorn\nhttpx[http2]==0.27.0\n    # via\n    #   -r web_service/backend/requirements.in\n    #   fastapi\nhyperframe==6.0.1\n    # via h2\nidna==3.7\n    # via\n    #   anyio\n    #   email-validator\n    #   httpx\n    #   requests\nimportlib-metadata==8.7.1\n    # via\n    #   build\n    #   keyring\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\niniconfig==2.0.0\n    # via pytest\njaraco-classes==3.4.0\n    # via keyring\njaraco-context==4.3.0\n    # via keyring\njaraco-functools==4.3.0\n    # via keyring\njeepney==0.8.0\n    # via\n    #   keyring\n    #   secretstorage\njinja2==3.1.6\n    # via fastapi\nkeyring==25.2.1\n    # via -r web_service/backend/requirements.in\nlimits==3.14.1\n    # via slowapi\nmarkdown-it-py==3.0.0\n    # via rich\nmarkupsafe==3.0.3\n    # via jinja2\nmdurl==0.1.2\n    # via markdown-it-py\nmore-itertools==10.3.0\n    # via\n    #   jaraco-classes\n    #   jaraco-functools\nmypy-extensions==1.0.0\n    # via black\nnumpy==1.23.5  # x86 PINNED\n    # via\n    #   -r web_service/backend/requirements.in\n    #   pandas\n    #   scipy\norjson==3.11.5\n    # via fastapi\npackaging==24.1\n    # via\n    #   black\n    #   build\n    #   limits\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\n    #   pytest\npandas==1.5.3  # x86 PINNED\n    # via -r web_service/backend/requirements.in\npathspec==0.12.1\n    # via black\npip-tools==7.4.1\n    # via -r web_service/backend/requirements.in\nplatformdirs==4.2.2\n    # via black\npluggy==1.5.0\n    # via pytest\npsutil==5.9.8\n    # via -r web_service/backend/requirements.in\npsycopg2-binary==2.9.9\n    # via -r web_service/backend/requirements.in\npycparser==2.22\n    # via cffi\npydantic==2.8.2\n    # via\n    #   fastapi\n    #   pydantic-settings\npydantic-core==2.20.1\n    # via pydantic\npydantic-settings==2.3.4\n    # via -r web_service/backend/requirements.in\npygments==2.18.0\n    # via rich\npyinstaller==6.5.0\n    # via -r web_service/backend/requirements.in\npyinstaller-hooks-contrib==2024.6\n    # via pyinstaller\npyproject-hooks==1.1.0\n    # via\n    #   build\n    #   pip-tools\npytest==8.2.2\n    # via\n    #   -r web_service/backend/requirements.in\n    #   pytest-asyncio\npytest-asyncio==0.23.7\n    # via -r web_service/backend/requirements.in\npython-dateutil==2.9.0.post0\n    # via pandas\npython-dotenv==1.0.1\n    # via\n    #   pydantic-settings\n    #   uvicorn\npython-multipart==0.0.20\n    # via fastapi\npytz==2024.1\n    # via pandas\npyyaml==6.0.3\n    # via uvicorn\nredis==5.0.6\n    # via -r web_service/backend/requirements.in\nrequests==2.32.5\n    # via -r web_service/backend/requirements.in\nrich==14.2.0\n    # via\n    #   rich-toolkit\n    #   typer\nrich-toolkit==0.17.1\n    # via fastapi-cli\nscipy==1.10.1  # x86 PINNED\n    # via -r web_service/backend/requirements.in\nsecretstorage==3.3.3\n    # via keyring\nselectolax==0.4.0\n    # via -r web_service/backend/requirements.in\nshellingham==1.5.4\n    # via typer\nsix==1.16.0\n    # via python-dateutil\nslowapi==0.1.9\n    # via -r web_service/backend/requirements.in\nsniffio==1.3.1\n    # via\n    #   anyio\n    #   httpx\nsoupsieve==2.5\n    # via beautifulsoup4\nsqlalchemy==1.4.46  # x86 PINNED\n    # via -r web_service/backend/requirements.in\nstarlette==0.37.2\n    # via fastapi\nstructlog==24.2.0\n    # via -r web_service/backend/requirements.in\ntenacity==8.2.3\n    # via -r web_service/backend/requirements.in\ntomli==2.3.0\n    # via\n    #   black\n    #   build\n    #   fastapi-cli\n    #   pip-tools\n    #   pytest\ntyper==0.21.0\n    # via fastapi-cli\ntyping-extensions==4.12.2\n    # via\n    #   aiosqlite\n    #   black\n    #   exceptiongroup\n    #   fastapi\n    #   limits\n    #   pydantic\n    #   pydantic-core\n    #   rich-toolkit\n    #   starlette\n    #   typer\n    #   uvicorn\nujson==5.11.0\n    # via fastapi\nurllib3==2.6.2\n    # via\n    #   -r web_service/backend/requirements.in\n    #   requests\nuvicorn==0.30.1\n    # via\n    #   -r web_service/backend/requirements.in\n    #   fastapi\n    #   fastapi-cli\nhttptools==0.7.1\n    # via uvicorn\nwebsockets==15.0.1\n    # via uvicorn\nwatchfiles==1.1.1\n    # via uvicorn\nwebsockets==15.0.1\n    # via uvicorn\nwheel==0.43.0\n    # via\n    #   -r web_service/backend/requirements.in\n    #   pip-tools\nwrapt==1.16.0\n    # via deprecated\nzipp==3.23.0\n    # via importlib-metadata\n",
    "web_service/backend/tests/test_web_service_manual_override.py": "# python_service/tests/test_manual_override.py\nimport pytest\n\n# Use an absolute import as a workaround for the broken test environment.\n# Pytest is not recognizing this directory as part of a package, so relative imports fail.\nimport sys\nfrom pathlib import Path\n# Add repo root to path to allow absolute imports\nsys.path.insert(0, str(Path(__file__).resolve().parents[3]))\n\nfrom web_service.backend.manual_override_manager import ManualOverrideManager\n\n\n@pytest.fixture\ndef manager():\n    # The manager is now in-memory and doesn't need a path\n    return ManualOverrideManager()\n\n\ndef test_register_and_retrieve(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager):\n    adapter = \"TestAdapter\"\n    url = \"https://example.com/blocked\"\n    content = \"<html>Manual content</html>\"\n    content_type = \"text/html\"\n\n    request_id = manager.register_failure(\n        adapter_name=adapter,\n        url=url,\n    )\n\n    success = manager.submit_manual_data(\n        request_id=request_id,\n        raw_content=content,\n        content_type=content_type,\n    )\n\n    assert success\n\n    # Verify that the data can be retrieved correctly\n    retrieved_data = manager.get_manual_data(adapter_name=adapter, url=url)\n    assert retrieved_data is not None\n    retrieved_content, retrieved_type = retrieved_data\n    assert retrieved_content == content\n    assert retrieved_type == content_type\n\n    # Verify that data is consumed after retrieval\n    assert manager.get_manual_data(adapter_name=adapter, url=url) is None\n",
    "web_service/backend/version.py": "# web_service/backend/version.py\n\n__version__ = \"3.0.1\" # Default version\n\ndef get_version():\n    \"\"\"Returns the application version.\"\"\"\n    return __version__\n",
    "web_service/frontend/app/components/ErrorDisplay.tsx": "// web_platform/frontend/src/components/ErrorDisplay.tsx\n'use client';\n\nimport React from 'react';\n\ninterface ErrorInfo {\n  message: string;\n  suggestion: string;\n  details?: string;\n}\n\ninterface ErrorDisplayProps {\n  error: ErrorInfo;\n}\n\nexport const ErrorDisplay: React.FC<ErrorDisplayProps> = ({ error }) => {\n  return (\n    <div className=\"bg-red-900/20 border border-red-500/30 text-white rounded-lg p-6 max-w-2xl mx-auto my-8\">\n      <div className=\"flex items-center mb-4\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-8 w-8 text-red-400 mr-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n          <path fillRule=\"evenodd\" d=\"M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z\" clipRule=\"evenodd\" />\n        </svg>\n        <h2 className=\"text-2xl font-bold text-red-400\">An Error Occurred</h2>\n      </div>\n      <p className=\"text-lg text-slate-300 mb-2\">{error.message}</p>\n      <p className=\"text-slate-400 mb-6\">{error.suggestion}</p>\n      {error.details && (\n        <details className=\"bg-slate-800/50 rounded-lg p-4\">\n          <summary className=\"cursor-pointer text-sm text-slate-500 hover:text-white\">\n            Technical Details\n          </summary>\n          <pre className=\"text-xs text-slate-400 mt-2 p-2 bg-black/30 rounded overflow-x-auto\">\n            <code>{error.details}</code>\n          </pre>\n        </details>\n      )}\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/RaceCardSkeleton.tsx": "// web_platform/frontend/src/components/RaceCardSkeleton.tsx\nimport React from 'react';\n\nexport const RaceCardSkeleton: React.FC = () => {\n  return (\n    <div className=\"race-card-skeleton border border-gray-700 rounded-lg p-4 bg-gray-800 shadow-lg animate-pulse\">\n      {/* Skeleton Header */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <div className=\"h-7 w-28 bg-gray-700 rounded-md\"></div>\n            <div className=\"h-4 w-40 bg-gray-700 rounded-md mt-2\"></div>\n          </div>\n        </div>\n        <div className=\"h-16 w-16 bg-gray-700 rounded-full\"></div>\n      </div>\n\n      {/* Skeleton Info Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"h-3 w-12 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-8 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-12 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-8 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-10 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-6 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-10 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-6 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n      </div>\n\n      {/* Skeleton Runner Rows */}\n      <div className=\"space-y-2\">\n        {[...Array(3)].map((_, i) => (\n          <div key={i} className=\"runner-row rounded-md p-3\">\n            <div className=\"flex items-center justify-between\">\n              <div className=\"flex items-center gap-4 flex-1\">\n                <div className=\"w-10 h-10 rounded-full bg-gray-700\"></div>\n                <div className=\"flex flex-col space-y-2\">\n                  <div className=\"h-5 w-32 bg-gray-700 rounded-md\"></div>\n                  <div className=\"h-4 w-40 bg-gray-700 rounded-md\"></div>\n                </div>\n              </div>\n              <div className=\"text-right\">\n                <div className=\"h-6 w-16 bg-gray-700 rounded-md\"></div>\n                <div className=\"h-3 w-12 bg-gray-700 rounded-md mt-2\"></div>\n              </div>\n            </div>\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/Tabs.tsx": "// src/components/Tabs.tsx\n'use client';\n\nimport React, { useState } from 'react';\n\ntype Tab = {\n  label: string;\n  content: React.ReactNode;\n};\n\ntype TabsProps = {\n  tabs: Tab[];\n};\n\nexport function Tabs({ tabs }: TabsProps) {\n  const [activeTab, setActiveTab] = useState(0);\n\n  return (\n    <div>\n      <div className=\"border-b border-slate-700\">\n        <nav className=\"-mb-px flex space-x-8\" aria-label=\"Tabs\">\n          {tabs.map((tab, index) => (\n            <button\n              key={tab.label}\n              onClick={() => setActiveTab(index)}\n              className={`${\n                activeTab === index\n                  ? 'border-blue-500 text-blue-400'\n                  : 'border-transparent text-slate-400 hover:text-slate-200 hover:border-slate-500'\n              } whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm transition-colors focus:outline-none`}\n            >\n              {tab.label}\n            </button>\n          ))}\n        </nav>\n      </div>\n      <div className=\"mt-8\">{tabs[activeTab].content}</div>\n    </div>\n  );\n}\n",
    "web_service/frontend/app/layout.tsx": "// web_platform/frontend/app/layout.tsx\nimport './globals.css';\nimport type { Metadata } from 'next';\nimport { Inter } from 'next/font/google';\nimport Providers from './Providers';\n\nconst inter = Inter({ subsets: ['latin'] });\n\nexport const metadata: Metadata = {\n  title: 'Fortuna',\n  description: 'Real-time horse racing analysis.',\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={`${inter.className} bg-white text-gray-900 dark:bg-gray-900 dark:text-gray-100`}>\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}",
    "web_service/frontend/app/utils/exportManager.ts": "// web_platform/frontend/src/utils/exportManager.ts\n// import { saveAs } from 'file-saver';\n// import * as XLSX from 'xlsx';\n\nexport class ExportManager {\n  static exportToExcel(races: any[], filename: string = 'fortuna_races') {\n    //\n    // [JULES] - NOTE FOR JB AND AI EXPERTS:\n    // This feature has been temporarily disabled because the external dependency (xlsx)\n    // is hosted on a CDN (cdn.sheetjs.com) that is consistently failing during\n    // the CI/CD build process with 500 Internal Server Errors.\n    //\n    // To ensure the main application build is not blocked, I have commented out\n    // the implementation of this function. The 'xlsx' package remains in package.json,\n    // but this code will not be active until the dependency issue is resolved.\n    //\n\n    // const workbook = XLSX.utils.book_new();\n\n    // const summaryData = [\n    //   ['Total Qualified Races', races.length],\n    //   ['Generated At', new Date().toLocaleString()]\n    // ];\n    // const summarySheet = XLSX.utils.aoa_to_sheet(summaryData);\n    // XLSX.utils.book_append_sheet(workbook, summarySheet, 'Summary');\n\n    // const raceData = races.map(race => ({\n    //   'Venue': race.venue,\n    //   'Race Number': race.race_number,\n    //   'Post Time': new Date(race.start_time).toLocaleString(),\n    //   'Qualification Score': race.qualification_score || 0,\n    //   'Field Size': race.runners.filter(r => !r.scratched).length,\n    //   'Source': race.source\n    // }));\n    // const raceSheet = XLSX.utils.json_to_sheet(raceData);\n    // XLSX.utils.book_append_sheet(workbook, raceSheet, 'Races');\n\n    // XLSX.writeFile(workbook, `${filename}_${Date.now()}.xlsx`);\n    console.warn(\"Excel export is temporarily disabled due to an external dependency issue.\");\n    alert(\"The Excel export feature is temporarily disabled due to an unreliable external dependency. Please try again later.\");\n  }\n}\n",
    "web_service/frontend/next.config.mjs": "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  output: 'export',  // Critical for static HTML export\n  distDir: 'out',\n  trailingSlash: true,\n  images: {\n    unoptimized: true  // Required for static export\n  },\n  async rewrites() {\n    return [\n      {\n        source: '/api/:path*',\n        destination: 'http://127.0.0.1:8000/api/:path*',\n      },\n    ]\n  },\n};\n\nexport default nextConfig;\n",
    "web_service/frontend/public/sw.js": "if(!self.define){let e,s={};const a=(a,n)=>(a=new URL(a+\".js\",n).href,s[a]||new Promise(s=>{if(\"document\"in self){const e=document.createElement(\"script\");e.src=a,e.onload=s,document.head.appendChild(e)}else e=a,importScripts(a),s()}).then(()=>{let e=s[a];if(!e)throw new Error(`Module ${a} didn\u2019t register its module`);return e}));self.define=(n,t)=>{const i=e||(\"document\"in self?document.currentScript.src:\"\")||location.href;if(s[i])return;let c={};const r=e=>a(e,i),o={module:{uri:i},exports:c,require:r};s[i]=Promise.all(n.map(e=>o[e]||r(e))).then(e=>(t(...e),c))}}define([\"./workbox-4754cb34\"],function(e){\"use strict\";importScripts(),self.skipWaiting(),e.clientsClaim(),e.precacheAndRoute([{url:\"/_next/app-build-manifest.json\",revision:\"b6130f23369e5df052a4061c412f24fa\"},{url:\"/_next/static/YkCCvmjhdkIswKuIgvFNH/_buildManifest.js\",revision:\"c155cce658e53418dec34664328b51ac\"},{url:\"/_next/static/YkCCvmjhdkIswKuIgvFNH/_ssgManifest.js\",revision:\"b6652df95db52feb4daf4eca35380933\"},{url:\"/_next/static/chunks/117-6326cd814d964913.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/816-7254031126ac0a96.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/928.d7f641058b89a54a.js\",revision:\"d7f641058b89a54a\"},{url:\"/_next/static/chunks/app/_not-found/page-e7dc36cd5a340c38.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/app/layout-605479d07717f01e.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/app/page-a2c385e93bfc2dac.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/fd9d1056-af804af0be509bea.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/framework-f66176bb897dc684.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/main-8563e00d234bd632.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/main-app-e0b3e4e952d25145.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/pages/_app-72b849fbd24ac258.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/pages/_error-7ba65e1336b92748.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/chunks/polyfills-42372ed130431b0a.js\",revision:\"846118c33b2c0e922d7b3a7676f81f6f\"},{url:\"/_next/static/chunks/webpack-d92cdde7bb2319ca.js\",revision:\"YkCCvmjhdkIswKuIgvFNH\"},{url:\"/_next/static/css/a55e4893d0564dbf.css\",revision:\"a55e4893d0564dbf\"},{url:\"/_next/static/media/19cfc7226ec3afaa-s.woff2\",revision:\"9dda5cfc9a46f256d0e131bb535e46f8\"},{url:\"/_next/static/media/21350d82a1f187e9-s.woff2\",revision:\"4e2553027f1d60eff32898367dd4d541\"},{url:\"/_next/static/media/8e9860b6e62d6359-s.woff2\",revision:\"01ba6c2a184b8cba08b0d57167664d75\"},{url:\"/_next/static/media/ba9851c3c22cd980-s.woff2\",revision:\"9e494903d6b0ffec1a1e14d34427d44d\"},{url:\"/_next/static/media/c5fe6dc8356a8c31-s.woff2\",revision:\"027a89e9ab733a145db70f09b8a18b42\"},{url:\"/_next/static/media/df0a9ae256c0569c-s.woff2\",revision:\"d54db44de5ccb18886ece2fda72bdfe0\"},{url:\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",revision:\"65850a373e258f1c897a2b3d75eb74de\"},{url:\"/manifest.json\",revision:\"23bffdb04aba9b85948642cffa772eae\"}],{ignoreURLParametersMatching:[]}),e.cleanupOutdatedCaches(),e.registerRoute(\"/\",new e.NetworkFirst({cacheName:\"start-url\",plugins:[{cacheWillUpdate:async({request:e,response:s,event:a,state:n})=>s&&\"opaqueredirect\"===s.type?new Response(s.body,{status:200,statusText:\"OK\",headers:s.headers}):s}]}),\"GET\"),e.registerRoute(/^https:\\/\\/fonts\\.(?:gstatic)\\.com\\/.*/i,new e.CacheFirst({cacheName:\"google-fonts-webfonts\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:31536e3})]}),\"GET\"),e.registerRoute(/^https:\\/\\/fonts\\.(?:googleapis)\\.com\\/.*/i,new e.StaleWhileRevalidate({cacheName:\"google-fonts-stylesheets\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:604800})]}),\"GET\"),e.registerRoute(/\\.(?:eot|otf|ttc|ttf|woff|woff2|font.css)$/i,new e.StaleWhileRevalidate({cacheName:\"static-font-assets\",plugins:[new e.ExpirationPlugin({maxEntries:4,maxAgeSeconds:604800})]}),\"GET\"),e.registerRoute(/\\.(?:jpg|jpeg|gif|png|svg|ico|webp)$/i,new e.StaleWhileRevalidate({cacheName:\"static-image-assets\",plugins:[new e.ExpirationPlugin({maxEntries:64,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\/_next\\/image\\?url=.+$/i,new e.StaleWhileRevalidate({cacheName:\"next-image\",plugins:[new e.ExpirationPlugin({maxEntries:64,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:mp3|wav|ogg)$/i,new e.CacheFirst({cacheName:\"static-audio-assets\",plugins:[new e.RangeRequestsPlugin,new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:mp4)$/i,new e.CacheFirst({cacheName:\"static-video-assets\",plugins:[new e.RangeRequestsPlugin,new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:js)$/i,new e.StaleWhileRevalidate({cacheName:\"static-js-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:css|less)$/i,new e.StaleWhileRevalidate({cacheName:\"static-style-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\/_next\\/data\\/.+\\/.+\\.json$/i,new e.StaleWhileRevalidate({cacheName:\"next-data\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(/\\.(?:json|xml|csv)$/i,new e.NetworkFirst({cacheName:\"static-data-assets\",plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>{if(!(self.origin===e.origin))return!1;const s=e.pathname;return!s.startsWith(\"/api/auth/\")&&!!s.startsWith(\"/api/\")},new e.NetworkFirst({cacheName:\"apis\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:16,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>{if(!(self.origin===e.origin))return!1;return!e.pathname.startsWith(\"/api/\")},new e.NetworkFirst({cacheName:\"others\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:86400})]}),\"GET\"),e.registerRoute(({url:e})=>!(self.origin===e.origin),new e.NetworkFirst({cacheName:\"cross-origin\",networkTimeoutSeconds:10,plugins:[new e.ExpirationPlugin({maxEntries:32,maxAgeSeconds:3600})]}),\"GET\")});\n",
    "web_service/frontend/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"lib\": [\n      \"dom\",\n      \"dom.iterable\",\n      \"esnext\"\n    ],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": false,\n    \"noEmit\": true,\n    \"incremental\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ]\n  },\n  \"include\": [\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\",\n    \"out/types/**/*.ts\"\n  ],\n  \"exclude\": [\n    \"node_modules\"\n  ]\n}\n",
    "wix/product_webservice.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:fire=\"http://schemas.microsoft.com/wix/FirewallExtension\"\n     xmlns:util=\"http://schemas.microsoft.com/wix/UtilExtension\">\n\n  <Product Id=\"*\"\n           Name=\"Fortuna Web Service\"\n           Language=\"1033\"\n           Version=\"$(var.Version)\"\n           Manufacturer=\"Fortuna Development Team\"\n           UpgradeCode=\"A3A4A3B6-2313-4375-9A97-15206C81454A\">\n\n    <Package InstallerVersion=\"200\" Compressed=\"yes\" InstallScope=\"perMachine\" />\n    <MajorUpgrade DowngradeErrorMessage=\"A newer version of [ProductName] is already installed.\" />\n    <MediaTemplate EmbedCab=\"yes\" />\n\n    <Property Id=\"ARPNOREPAIR\" Value=\"no\" />\n    <Property Id=\"ARPNOMODIFY\" Value=\"yes\" />\n\n    <UI>\n      <UIRef Id=\"WixUI_Minimal\" />\n    </UI>\n\n    <WixVariable Id=\"WixUILicenseRtf\" Value=\"electron\\assets\\license.rtf\"/>\n    <WixVariable Id=\"WixUIBannerBmp\"  Value=\"electron\\assets\\banner.bmp\"/>\n    <WixVariable Id=\"WixUIDialogBmp\"  Value=\"electron\\assets\\dialog.bmp\"/>\n\n    <Feature Id=\"ProductFeature\" Title=\"Fortuna Web Service\" Level=\"1\">\n      <ComponentGroupRef Id=\"WebServiceComponents\" />\n      <ComponentRef Id=\"ApplicationShortcut\" />\n    </Feature>\n  </Product>\n\n  <Fragment>\n    <Directory Id=\"TARGETDIR\" Name=\"SourceDir\">\n      <Directory Id=\"ProgramFilesFolder\">\n        <Directory Id=\"INSTALLDIR\" Name=\"FortunaWebService\"/>\n      </Directory>\n      <Directory Id=\"ProgramMenuFolder\">\n        <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Web Service\"/>\n      </Directory>\n      <Directory Id=\"CommonAppDataFolder\">\n        <Directory Id=\"FortunaData\" Name=\"FortunaWebService\"/>\n      </Directory>\n    </Directory>\n  </Fragment>\n\n  <Fragment>\n    <ComponentGroup Id=\"WebServiceComponents\" Directory=\"INSTALLDIR\">\n      <Component Id=\"WebServiceExecutable\" Guid=\"3F2A4A9C-4055-4D62-812E-B715A0123594\">\n        <File Id=\"WebServiceExe\" Source=\"staging/fortuna-webservice.exe\" KeyPath=\"yes\"/>\n        <ServiceInstall Id=\"FortunaWebService\"\n                        Name=\"FortunaWebService\"\n                        DisplayName=\"Fortuna Web Service\"\n                        Description=\"Provides live odds and race data via a web interface.\"\n                        Start=\"auto\"\n                        Type=\"ownProcess\"\n                        ErrorControl=\"normal\"\n                        Account=\"NetworkService\"/>\n        <ServiceControl Id=\"StartFortunaWebService\"\n                        Name=\"FortunaWebService\"\n                        Start=\"install\"\n                        Stop=\"both\"\n                        Remove=\"uninstall\"\n                        Wait=\"yes\"/>\n        <fire:FirewallException Id=\"FortunaFirewall\"\n                                Name=\"FortunaWebService\"\n                                Port=\"8088\"\n                                Protocol=\"tcp\"\n                                Scope=\"any\"/>\n      </Component>\n    </ComponentGroup>\n  </Fragment>\n\n  <Fragment>\n    <DirectoryRef Id=\"ApplicationProgramsFolder\">\n      <Component Id=\"ApplicationShortcut\" Guid=\"5E95E5B9-4F3D-4B9A-819B-9149C5E4700F\">\n        <util:InternetShortcut Id=\"DashboardShortcut\"\n                               Name=\"Fortuna Dashboard\"\n                               Target=\"http://localhost:8088\"/>\n        <Shortcut Id=\"UninstallProduct\"\n                  Name=\"Uninstall Fortuna Web Service\"\n                  Target=\"[SystemFolder]msiexec.exe\"\n                  Arguments=\"/x [ProductCode]\"\n                  Description=\"Uninstalls Fortuna Web Service\"/>\n        <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\"/>\n        <RegistryValue Root=\"HKCU\"\n                       Key=\"Software\\FortunaWebService\"\n                       Name=\"installed\"\n                       Type=\"integer\"\n                       Value=\"1\"\n                       KeyPath=\"yes\"/>\n      </Component>\n    </DirectoryRef>\n  </Fragment>\n</Wix>\n"
}