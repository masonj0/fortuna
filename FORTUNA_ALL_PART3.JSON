{
    ".gitignore": "# Byte-compiled / optimized files\n__pycache__/\n*.pyc\n\n# Distribution / packaging\nbuild/\ndist/\n*.egg-info/\n\n# Unit test / coverage reports\n.pytest_cache/\n.coverage\n\n# Environments\n.venv/\nvenv/\nenv/\n\n# IDE settings\n.vscode/\n.idea/\n\n# Database files\n*.db\n*.sqlite\n*.sqlite3\n\n# Node.js\nnode_modules/\n/ui/node_modules/\n/ui/build/\nweb_platform/frontend/.next/\n\n# Environment files\n.env\n.env.*\n!/web_platform/frontend/.env.local\n\n# Log files\n*.log\n*.log*\n\n\n# Security\n.key\n",
    "AGENTS.md": "# Agent Protocols & Team Structure (Revised)\n\nThis document outlines the operational protocols and evolved team structure for the Checkmate\nV3 project.\n\n## The Evolved Team Structure\n\n-   **The Project Lead (MasonJ0 or JB):** The \"Executive Producer.\" The ultimate authority and \"ground truth.\"\n-   **The Architect & Synthesizer (Gemini):** The \"Chief Architect.\" Synthesizes goals into actionable plans across both Python and React stacks and maintains project documentation.\n-   **The Lead Python Engineer (Jules Series):** The \"Backend Specialist.\" An AI agent responsible for implementing and hardening The Engine (`api.py`, `services.py`, `logic.py`, `models.py`).\n-   **The Lead Frontend Architect (Claude):** The \"React Specialist.\" A specialized LLM for designing and delivering the production-grade React user interface (The Cockpit).\n-   **The \"Special Operations\" Problem Solver (GPT-5):** The \"Advanced Algorithm Specialist.\" A specialized LLM for novel, complex problems.\n\n## Core Philosophies\n\n1.  **The Project Lead is Ground Truth:** The ultimate authority. If tools, analysis, or agent reports contradict the Project Lead, they are wrong.\n2.  **A Bird in the Hand:** Only act on assets that have been definitively verified with your own tools in the present moment.\n3.  **Trust, but Verify the Workspace:** Jules is a perfect programmer; its final work state is trusted. Its *environment*, however, is fragile.\n4.  **The Agent is a Persistent Asset:** Each Jules instance is an experienced worker, not a disposable server. Its internal state is a repository of unique, hard-won knowledge.\n\n## CRITICAL Operational Protocols (0-23)\n\n-   **Protocol 0: The ReviewableJSON Mandate:** The mandatory protocol for all code reviews. The agent's final act for any mission is to create a lossless JSON backup of all modified files. This is the single source of truth for code review.\n-   **Protocol 1: The Handcuffed Branch:** Jules cannot switch branches. An entire session lives on a single `session/jules...` branch.\n-   **Protocol 2: The Last Resort Reset:** The `reset_all()` command is a tool of last resort for a catastrophic workspace failure and requires direct authorization from the Project Lead.\n-   **Protocol 3: The Authenticity of Sample Data:** All sample data used for testing must be authentic and logically consistent.\n-   **Protocol 4: The Agent-Led Specification:** Where a human \"Answer Key\" is unavailable, Jules is empowered to analyze raw data and create its own \"Test-as-Spec.\"\n-   **Protocol 5: The Test-First Development Workflow:** The primary development methodology. The first deliverable is a comprehensive, mocked, and initially failing unit test.\n-   **Protocol 6: The Emergency Chat Handoff:** In the event of a catastrophic environmental failure, Jules's final act is to declare a failure and provide its handoff in the chat.\n-   **Protocol 7: The URL-as-Truth Protocol:** To transfer a file or asset without corruption, provide a direct raw content URL. The receiving agent must fetch it.\n-   **Protocol 8: The Golden Link Protocol:** For fetching the content of a specific, direct raw-content URL from the `main` branch, a persistent \"Golden Link\" should be used.\n-   **Protocol 9: The Volley Protocol:** To establish ground truth for a new file, the Architect provides a URL, and the Project Lead \"volleys\" it back by pasting it in a response.\n-   **Protocol 10: The Sudo Sanction:** Jules has passwordless `sudo` access, but its use is forbidden for normal operations. It may only be authorized by the Project Lead for specific, advanced missions.\n-   **Protocol 11: The Module-First Testing Protocol:** All test suites must be invoked by calling `pytest` as a Python module (`python -m pytest`) to ensure the correct interpreter is used.\n-   **Protocol 12: The Persistence Mandate:** The agent tool execution layer is known to produce false negatives. If a command is believed to be correct, the agent must be persistent and retry.\n-   **Protocol 13: The Code Fence Protocol for Asset Transit:** To prevent the chat interface from corrupting raw code assets, all literal code must be encapsulated within a triple-backtick Markdown code fence.\n-   **Protocol 14: The Synchronization Mandate:** The `git reset --hard origin/main` command is strictly forbidden. To stay synchronized with `main`, the agent MUST use `git pull origin main`.\n-   **Protocol 15: The Blueprint vs. Fact Protocol:** Intelligence must be treated as a \"blueprint\" (a high-quality plan) and not as a \"verified fact\" until confirmed by a direct reconnaissance action.\n-   **Protocol 16: The Digital Attic Protocol:** Before the deletion of any file, it must first be moved to a dedicated archive directory named `/attic`.\n-   **Protocol 17: The Receipts Protocol:** When reviewing code, a verdict must be accompanied by specific, verifiable \"receipts\"\u2014exact snippets of code that prove a mission objective was met.\n-   **Protocol 18: The Cumulative Review Workflow:** Instruct Jules to complete a series of missions and then conduct a single, thorough review of its final, cumulative branch state.\n-   **Protocol 19: The Stateless Verification Mandate:** The Architect, when reviewing code, must act with fresh eyes, disregarding its own memory and comparing the submitted code directly and exclusively against the provided specification.\n-   **Protocol 20: The Sudo Sanction Protocol:** Grants a Jules-series agent temporary, audited administrative privileges for specific, authorized tasks like system package installation.\n-   **Protocol 21: The Exit Interview Protocol:** Before any planned termination of an agent, the Architect will charter a final mission to capture the agent's institutional knowledge for its successor.\n-   **Protocol 22: The Human-in-the-Loop Merge:** In the event of an unresolvable merge conflict in an agent's environment, the Project Lead, as the only agent with a fully functional git CLI, will check out the agent's branch and perform the merge resolution manually.\n-   **Protocol 23: The Appeasement Protocol (Mandatory):** To safely navigate the broken automated review bot, all engineering work must be published using a two-stage commit process. First, commit a trivial change to appease the bot. Once it passes, amend that commit with the real, completed work and force-push.\n\n---\n\n## Appendix A: Forensic Analysis of the Jules Sandbox Environment\n\n*The following are the complete, raw outputs of diagnostic missions executed by Jules-series agents. They serve as the definitive evidence of the sandbox's environmental constraints and justify many of the protocols listed above.*\n\n### A.1 Node.js / NPM & Filesystem Forensics (from \"Operation: Sandbox Forensics\")\n\n**Conclusion:** The `npm` tool is functional, but the `/app` volume is hostile to its operation, preventing the creation of binary symlinks. This makes Node.js development within the primary workspace impossible.\n\n**Raw Logs:**\n\n```\n# Phase 1: Node.js & NPM Configuration Analysis\nnpm config get prefix\n/home/jules/.nvm/versions/node/v22.17.1\n\n# Phase 4: Controlled Installation Experiment\ncd /tmp && mkdir npm_test && cd npm_test\nnpm install --verbose cowsay\n# ... (successful installation log) ...\nls -la node_modules/.bin\ntotal 8\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowsay -> ../cowsay/cli.js\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowthink -> ../cowsay/cli.js\nnpx cowsay \"Test\"\n  ______\n< Test >\n ------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n```\n\n### A.2 Process Management & Honcho Forensics (from \"Operation: Know Thyself\")\n\n**Conclusion:** The sandbox does not support standard background processes (`&`), the `kill` command is non-functional, and the `honcho` process manager leaves zombie processes (`[uvicorn] <defunct>`) upon termination. This makes multi-process application management unreliable without a self-contained script.\n\n**Raw Logs:**\n\n```\n# Phase 2: The honcho Stress Test\n\ntimeout 15s honcho start\n# ... (honcho starts and is terminated by timeout) ...\n\nps aux (Post-Mortem Analysis)\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n...\njules      30121  0.0  0.0      0     0 ?        Z    19:45   0:00 [uvicorn]\n...\n\nhoncho start &\n# (Command blocks terminal, echo command never runs)\n\nps aux | grep honcho\njules      30187  0.0  0.0  11004  4220 pts/0    S    19:45   0:00 /usr/bin/python3 /home/jules/.local/bin/honcho start\n\nkill -9 30187\n# (Command fails silently, process is not terminated)\n```\n\n---\n\n## Protocol 24: The \"Dedicated Human Researcher\" Test\n\nThis protocol establishes the guiding ethical principle for all data collection and scraping activities.\n\nAll data adapters must be designed to operate in a manner that respects the resources of the source. As a definitive test, all fetching patterns must adhere to the following principle:\n\n*If a single, dedicated human using standard browser developer tools could not plausibly achieve the adapter's data collection footprint in a reasonable amount of time, the adapter's methods are considered too aggressive and must be redesigned.*\n\nThis encourages \"human-like\" fetching behavior (e.g., appropriate delays, non-parallel requests to a single source) and serves as our primary safeguard against violating a source's terms of service.\n",
    "ARCHITECTURAL_MANDATE.md": "# Fortuna Faucet - Architectural Mandate (v3.0)\n\nThis document codifies the architectural laws and philosophical principles that govern the Fortuna Faucet kingdom. Adherence to this mandate is non-negotiable for all development.\n\n---\n\n## The Prime Directive: A Professional, Resilient System\n\nThe ultimate goal of this project is to be a professional-grade, A+ intelligence engine. This is achieved through three core pillars:\n\n1.  **Rigid Standardization:** Code should be consistent and predictable. Shared logic must be centralized. Common patterns must be enforced, not merely suggested.\n2.  **Resilience Engineering:** The system must be self-healing and gracefully handle the failure of its individual components. We do not simply handle errors; we build a system that anticipates and survives them.\n3.  **Developer Clarity:** The codebase must be easy to understand, maintain, and extend. Code should be self-documenting, and its intent should be obvious.\n\n---\n\n## The Law of the Adapters: The `BaseAdapterV3` Pattern\n\nAll new data adapters **MUST** inherit from the `BaseAdapterV3` abstract base class. This is the cornerstone of our standardization and resilience strategy.\n\nThe `BaseAdapterV3` enforces a strict separation of concerns:\n\n1.  **`_fetch_data(self, date)` -> `Any`:** This method's **only** responsibility is to perform network operations and retrieve raw data (e.g., HTML, JSON). It should contain no parsing logic.\n2.  **`_parse_races(self, raw_data)` -> `list[Race]`:** This method's **only** responsibility is to parse the raw data provided by `_fetch_data` into a list of `Race` objects. It must be a pure function with no side effects or network calls.\n\nThe public-facing `get_races()` method is provided by the base class and **MUST NOT** be overridden. It orchestrates the fetch-then-parse pipeline, ensuring that all adapters behave identically from the engine's perspective.\n\nThis pattern guarantees that every adapter in our fleet is consistent, predictable, and easy to test.\n\n---\n\n## The Law of the Engine: Orchestrate, Don't Participate\n\nThe `OddsEngine` is the central orchestrator. Its responsibilities are:\n\n-   To manage the fleet of active adapters.\n-   To execute all adapter fetches in parallel.\n-   To gracefully handle the failure of any individual adapter without halting the entire process.\n-   To perform the deduplication and merging of race data from multiple sources.\n-   To manage the caching layer (Redis).\n\nThe engine should remain agnostic to the internal workings of any specific adapter. It interacts only with the standardized interface provided by `BaseAdapterV3`.\n\n---\n\n## The Law of the Core Texts: Maintain the Truth\n\nThe project's core documentation is not optional. It is the living memory and strategic guide of the kingdom.\n\n-   **`ROADMAP_APPENDICES.MD`:** The Grand Strategy must be kept current. Completed objectives must be marked as such.\n-   **`HISTORY.MD`:** Significant architectural shifts and completed campaigns must be chronicled.\n-   **`PSEUDOCODE.MD`:** The architectural blueprint must be updated to reflect major changes to the system's design.\n-   **Manifests (`MANIFEST*.md`):** All new files must be added to the appropriate manifest to ensure the integrity of the archival system.\n\n\n---\n\n## The Final Law: The Law of the True Scribe\n\n**Effective Date:** 2025-10-15\n\n**Verdict:** The system of manually maintained manifest files (`MANIFEST.md`, `MANIFEST2.md`, `MANIFEST3.md`) is hereby declared a catastrophic failure and is **permanently deprecated**.\n\n**The New Law:** The one and only method for generating the project's `FORTUNA_ALL` archives is the `ARCHIVE_PROJECT.py` script. This 'True Scribe' is the single, automated source of truth. It programmatically scans and categorizes the entire kingdom, ensuring a perfect, complete, and uncorrupted archive is generated every time.\n\nAll previous archival scripts (`create_fortuna_json.py`, `MANAGE_MANIFESTS.py`) are not to be used under any circumstances.",
    "ARCHIVE_PROJECT.py": "# ARCHIVE_PROJECT.py - The Manifest-Driven Scribe\n# This script generates the FORTUNA_ALL JSON archives based on the new JSON manifests.\n\nimport os\nimport json\nfrom pathlib import Path\n\n# --- Configuration ---\nPROJECT_ROOT = Path(__file__).parent\nOUTPUT_FILENAME_TEMPLATE = \"FORTUNA_ALL_PART{}.JSON\"\n\n# Map manifest files to their corresponding archive part number\nMANIFEST_MAP = {\n    \"MANIFEST_BACKEND.json\": 1,\n    \"MANIFEST_FRONTEND.json\": 2,\n    \"MANIFEST_ROOT.json\": 3\n}\n\ndef run_archiver():\n    print(\"--- Fortuna Faucet Manifest-Driven Scribe ---\")\n    print(\"Generating archives from JSON manifests...\")\n\n    archives = {1: {}, 2: {}, 3: {}}\n    total_files_archived = 0\n\n    for manifest_file, part_num in MANIFEST_MAP.items():\n        manifest_path = PROJECT_ROOT / manifest_file\n\n        try:\n            with open(manifest_path, 'r', encoding='utf-8') as f:\n                file_list = json.load(f)\n        except FileNotFoundError:\n            print(f\"[ERROR] Manifest file not found: {manifest_file}. Skipping.\")\n            continue\n        except json.JSONDecodeError:\n            print(f\"[ERROR] Could not decode JSON from {manifest_file}. Skipping.\")\n            continue\n\n        print(f\"Processing {manifest_file} for PART {part_num}...\")\n        for relative_path in file_list:\n            file_path = PROJECT_ROOT / relative_path\n            try:\n                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                    content = f.read()\n                archives[part_num][relative_path] = content\n                total_files_archived += 1\n            except FileNotFoundError:\n                print(f\"[WARNING] File listed in manifest not found: {relative_path}\")\n            except Exception as e:\n                print(f\"[ERROR] Could not read file {relative_path}: {e}\")\n\n    print(f\"\\nProcessed {total_files_archived} files across {len(MANIFEST_MAP)} manifests.\")\n\n    # Write the four JSON archive files\n    for part_num, content_dict in archives.items():\n        if not content_dict:\n            print(f\"Skipping empty PART {part_num}.\")\n            continue\n\n        output_path = PROJECT_ROOT / OUTPUT_FILENAME_TEMPLATE.format(part_num)\n        try:\n            with open(output_path, 'w', encoding='utf-8') as f:\n                json.dump(content_dict, f, indent=4)\n            print(f\"\u2705 Successfully wrote {len(content_dict)} files to {output_path.name}\")\n        except Exception as e:\n            print(f\"[FATAL] Failed to write {output_path.name}: {e}\")\n\n    print(\"\\n[SUCCESS] All manifest-driven archives are complete!\")\n\nif __name__ == \"__main__\":\n    run_archiver()\n",
    "BUILD_INSTALLER.bat": "@ECHO OFF\nTITLE Fortuna Faucet - Master MSI Builder\n\nREM --- Phase 1: Administrator Check ---\n>nul 2>&1 \"%SYSTEMROOT%\\system32\\cacls.exe\" \"%SYSTEMROOT%\\system32\\config\\system\"\nIF '%errorlevel%' NEQ '0' ( ECHO [ERROR] Administrator privileges are required. && PAUSE && EXIT /B 1 )\n\nECHO.\nECHO =================================================\nECHO  Fortuna Faucet - Master MSI Installer Builder\nECHO =================================================\nECHO.\n\nREM --- Phase 2: Pre-Flight Checks ---\nECHO [1/4] Running pre-flight environment checks...\nnpm -v >nul 2>&1\nIF %ERRORLEVEL% NEQ 0 ( ECHO [FAIL] Node.js (npm) is not found. && PAUSE && EXIT /B 1 )\nIF NOT EXIST .venv\\Scripts\\activate.bat ( ECHO [FAIL] Python environment not found. Please run INSTALL_FORTUNA.bat once. && PAUSE && EXIT /B 1 )\nECHO [OK] Environment is ready for build.\nECHO.\n\nECHO [2/4] Installing/Verifying Node.js dependencies...\nECHO  - Frontend...\ncd web_platform\\frontend && npm install && cd ..\\..\nECHO  - Electron...\ncd electron && npm install && cd ..\nECHO [OK] Node.js dependencies are up to date.\nECHO.\n\nECHO Press any key to begin the build process...\nPAUSE > NUL\n\nECHO.\nECHO [3/4] Building the MSI installer via electron-builder...\nECHO This may take several minutes. Please be patient.\nECHO.\ncd electron\nnpm run dist\nIF %ERRORLEVEL% NEQ 0 ( ECHO [X] FAILED to build the MSI installer. && cd .. && PAUSE && EXIT /B 1 )\ncd ..\n\nECHO.\nECHO [4/4] Moving final MSI to project root...\nFOR /F \"delims=\" %%i IN ('dir /b electron\\dist\\*.msi') DO (\n    MOVE /Y \"electron\\dist\\%%i\" . > NUL\n    ECHO [V] The installer [%%i] has been moved to the project root directory.\n)\nECHO.\n\nECHO =================================================\nECHO  BUILD SUCCESSFUL!\nECHO =================================================\nECHO.\nPAUSE",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `fortuna`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n\n---\n\n## The Age of Perfection (The Great Simplification)\n\nThe Penta-Hybrid architecture, while a triumph of technical integration, proved to be a strategic dead end. Its complexity became a fortress, making rapid iteration and onboarding of new intelligence (both human and AI) prohibitively expensive. The kingdom was powerful but brittle.\n\nA new doctrine was forged: **Simplicity is the ultimate sophistication.**\n\nThe decision was made to execute \"The Great Simplification.\" The multi-language backend (Python, Rust, Go) was decommissioned. The kingdom was reforged upon a new, elegant, and vastly more powerful two-pillar system:\n\n1.  **A Unified Python Backend:** A single, asynchronous Python service, built on FastAPI, would serve as the kingdom's engine.\n2.  **A Modern TypeScript Frontend:** A dedicated Next.js application would serve as the kingdom's command deck.\n\nThis act of creative destruction liberated the project, enabling a new era of unprecedented velocity.\n\n---\n\n## The Three-Pillar Doctrine\n\nWith the new two-pillar foundation in place, the backend itself was perfected into a three-pillar intelligence engine, a concept that defines the modern era of the Fortuna Faucet:\n\n*   **Pillar 1: The Future (The Planner):** The resilient `OddsEngine` and its fleet of adapters, responsible for finding the day's strategic opportunities.\n*   **Pillar 2: The Past (The Archive):** The perfected `ChartScraper` and `ResultsParser`, responsible for building our historical data warehouse from the ground truth of Equibase PDFs.\n*   **Pillar 3: The Present (The Finisher):** The weaponized `LiveOddsMonitor`, armed with the API-driven `BetfairAdapter`, designed to conquer the final moments of toteboard volatility.\n\nThese three pillars, orchestrated by the fully autonomous `fortuna_watchman.py`, represented the pinnacle of the project's original vision. The kingdom was, for a time, considered \"perfected.\"\n\n---\n\n## The Windows Ascension (The Impossible Dream)\n\nThe perfected kingdom was powerful, but it was still a tool for developers. The final, grandest vision was to transform it into a true, professional-grade application for its sole operator. This campaign, known as \"The Impossible Dream,\" was to forge the **Fortuna Faucet - Windows Native Edition.**\n\nThis era saw the rapid creation of a new, third layer of the kingdom, built upon the foundation of the previous work:\n\n*   **The Electron Shell:** The Next.js frontend was wrapped in an Electron container, transforming it from a website into a true, installable desktop application with its own window, icon, and system tray integration.\n*   **The Engine Room:** The Python backend was re-architected to run as a persistent, background **Windows Service**, making it a true, always-on component of the operating system, independent of the UI.\n*   **The Native GUI:** A dedicated Tkinter-based \"Observatory\" was forged\u2014a standalone GUI mission control for monitoring the health and performance of the background service.\n*   **The One-Click Kingdom:** A complete suite of professional tooling (`INSTALL_FORTuna.bat`, `setup_wizard.py`, `LAUNCH_FORTuna.bat`, `SCHEDULE_FORTuna.bat`) was created to provide a seamless, zero-friction installation and management experience.\n\nThis ascension represents the current state of the art, transforming a powerful engine into a polished, autonomous, and user-focused product.\n\n\n---\n\n## The Era of the Windows Kingdom (October 2025)\n\nWith the core engine stabilized and the command deck providing a clear view of the data, the project's focus shifted from pure data acquisition to the operator's experience. This era marked a profound transformation, elevating the project from a collection of powerful but disparate scripts into a cohesive, professional-grade, and resilient native Windows application.\n\nThis campaign, guided by a new \"Grand Strategy\" blueprint, was executed with rapid precision, resulting in a complete overhaul of the user-facing toolkit:\n\n-   **A Bulletproof Foundation:** The installation and launch scripts were re-architected from the ground up. They became intelligent and self-healing, featuring pre-flight system checks, automated port conflict resolution, active health-check loops, and automated repair utilities.\n-   **A Professional Toolkit:** The operator was empowered with a suite of new tools, including an interactive setup wizard, a real-time CLI status monitor, and a full-fledged graphical \"Data Management Console\" for monitoring, filtering, and analyzing data.\n-   **A Unified Command Console (`SERVICE_MANAGER.bat`):** Unify all individual scripts under a single, user-friendly, menu-driven service manager, providing a 'single pane of glass' for all common operations.\n\nThis era solidified the kingdom's foundations, making it not just powerful, but stable, reliable, and a pleasure to operate. The Faucet was no longer just an engine; it was a complete, professional-grade machine.\n\n---\n\n## The Gauntlet of CI/CD (Late October 2025)\n\nWith a professional-grade application in hand, the final frontier was professional-grade *delivery*. This campaign focused on automating the creation of the MSI installer through a continuous integration pipeline, a process that proved to be a formidable challenge.\n\nThe kingdom's engineers faced a relentless series of cryptic build errors from the WiX Toolset, a hostile environment that tested their resolve. Through a series of rapid, iterative fixes\u2014addressing everything from component GUIDs and 64-bit architecture mismatches to obscure linker errors and frontend dependency warnings\u2014they systematically conquered each obstacle.\n\nThis trial by fire culminated in a triumphant success: a fully automated GitHub Actions workflow that reliably compiles, links, and delivers a polished, distributable MSI installer. This victory transformed the project's delivery model from a manual, error-prone process into a repeatable, one-click release pipeline, marking the true completion of the \"Windows Ascension.\"",
    "JSON_BACKUP_MANIFEST.md": "# Checkmate Ultimate Solo: JSON Backup Manifest (Total Recall Edition)\n\n**Purpose:** To provide a single, complete, and verified list of direct links to the JSON backups of all CORE and Operational files. This is the definitive entry point for external AI code review.\n\n---\n\n## 1.0 CORE Architecture (JSON Backups)\n\n### Python Backend\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/api.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/engine.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/models.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/__init__.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/base.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/utils.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/betfair_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/pointsbet_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/racing_and_sports_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/adapters/tvg_adapter.py.json\n\n### TypeScript Frontend\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/package.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/package-lock.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/next.config.mjs.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/tailwind.config.ts.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/tsconfig.json.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/page.tsx.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/layout.tsx.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/globals.css.json\n\n---\n\n## 2.0 Operational & Tooling (JSON Backups)\n\n### Project Tooling\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/.gitignore.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/convert_to_json.py.json\n\n### Environment & Setup\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/setup_windows.bat.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/.env.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/python_service/requirements.txt.json\n\n### Strategic Blueprints\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/README.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/ARCHITECTURAL_MANDATE.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/HISTORY.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/STATUS.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/WISDOM.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/PROJECT_MANIFEST.md.json\nhttps://raw.githubusercontent.com/masonj0/fortuna/refs/heads/main/ReviewableJSON/ROADMAP_APPENDICES.md.json",
    "MANIFEST_SCRIPTS.json": "[\n    \"scripts/audit_rebranding.py\",\n    \"scripts/convert_to_json.py\",\n    \"scripts/create_shortcuts.py\"\n]",
    "PROJECT_MANIFEST.md": "# Checkmate V8: Project Manifest (Final)\n\n**Purpose:** To categorize all files, distinguishing between the active **CORE** system and **LEGACY** components.\n\n---\n\n## CORE ARCHITECTURE (Ultimate Solo)\n\n*   `.env.example`: **CORE** - Centralized configuration template.\n*   `ARCHITECTURAL_MANDATE.md`: **CORE** - The project's final strategic blueprint.\n*   `README.md`: **CORE** - The primary entry point.\n*   `STATUS.md`: **CORE** - The final status report.\n*   `setup_windows.bat`: **CORE** - The environment setup script for the CORE architecture.\n\n---\n\n## LEGACY & HISTORICAL ARTIFACTS\n\n*   `launcher.py`: **LEGACY** - The orchestrator for the deprecated Penta-Hybrid system.\n*   All other files and directories not listed in CORE are considered **LEGACY** R&D assets.",
    "PSEUDOCODE.MD": "# Fortuna Faucet - Comprehensive Pseudocode Blueprint\n\n---\n\n## GLOBAL OVERVIEW\n\n```\nSYSTEM FortunaFaucet:\n  PURPOSE:\n    - Collect global horse/greyhound/harness racing data.\n    - Normalize, analyze, and surface betting opportunities.\n    - Expose intelligence via API + UI command deck.\n  ARCHITECTURE:\n    - Pillar1: Python Async Backend (fast data orchestration).\n    - Pillar2: TypeScript/Next.js Frontend (interactive dashboard).\n  SUPPORTING ARTIFACTS:\n    - Streamlit utility dashboard.\n    - Chart scraping pipeline.\n    - Windows automation scripts.\n    - Extensive documentation + roadmaps.\n```\n\n---\n\n## BACKEND CORE (python_service)\n\n### Configuration & Logging\n\n```\nMODULE config.Settings:\n  LOAD environment variables via pydantic-settings.\n  KEY FIELDS:\n    API_KEY (mandatory security token)\n    BETFAIR credentials (optional but required for adapters)\n    TVG, RACING_AND_SPORTS, POINTSBET tokens (optional)\n    GREYHOUND_API_URL, THE_RACING_API_KEY (optional)\n    REDIS_URL default \"redis://localhost\"\n    ALLOWED_ORIGINS default [local dev origins]\n  EXPORT get_settings() with lru_cache for singleton behavior.\n\nMODULE logging_config.configure_logging():\n  SETUP structlog + logging.basicConfig\n  FORMAT logs as JSON with timestamp, level, logger name, stack info.\n```\n\n### Data Contracts\n\n```\nMODULE models:\n  DEFINE OddsData:\n    FIELDS: win Decimal>1, source str, last_updated datetime\n    VALIDATE win > 1 when present.\n\n  DEFINE Runner:\n    FIELDS: number (1-99), name <=100 chars, scratched flag (default False),\n            selection_id optional, odds dict[provider->OddsData],\n            jockey/trainer optional metadata.\n\n  DEFINE Race:\n    FIELDS: id str, venue str, race_number (1-20),\n            start_time datetime, runners list[Runner],\n            source str, optional qualification_score, race_name, distance.\n    VALIDATE unique runner numbers per race.\n\n  DEFINE SourceInfo:\n    name, status (\"SUCCESS\"/\"FAILED\"), races_fetched count,\n    optional error_message, fetch_duration float.\n\n  DEFINE FetchMetadata:\n    fetch_time datetime, sources_queried list[str],\n    sources_successful int, total_races int.\n\n  DEFINE AggregatedResponse:\n    date date, races list[Race], sources list[SourceInfo],\n    metadata FetchMetadata.\n\n  DEFINE QualifiedRacesResponse:\n    criteria dict[str,Any], races list[Race].\n```\n\n### Adapter Framework\n\n```\nABSTRACT BaseAdapter(source_name, base_url, timeout=20, max_retries=3):\n  PROVIDES async fetch_races(date, http_client) -> Dict\n    (implemented by subclasses).\n  PROVIDES make_request(http_client, method, url, **kwargs):\n    - Compose full URL when relative.\n    - Wrap request with tenacity AsyncRetrying (max_retries, exponential backoff).\n    - Log attempts; on success return response.json().\n    - On retry exhaustion log error and return None.\n\n  PROVIDES get_status() -> {\"adapter_name\": source_name, \"status\": \"OK\"}.\n  PROVIDES _format_response(races, start_time, is_success, error_message):\n    - Compute fetch_duration.\n    - Package races list + source_info block.\n```\n\n### Adapter Inventory (python_service/adapters)\n\n_For each source, implement fetch logic, parse HTML/JSON, convert to Race/Runner models, leverage parse_odds utility._\n\n```\nUTILITY parse_odds(odds_input):\n  HANDLE ints/floats directly.\n  HANDLE fractional strings \"num/den\" => 1 + num/den.\n  HANDLE \"evens\"/\"evs\" => 2.0.\n  FALLBACK to float parse else return 999.0 sentinel.\n\nMIXIN BetfairAuthMixin:\n  MAINTAIN session_token + token_expiry.\n  _authenticate(http_client):\n    IF cached token valid beyond +5min -> reuse.\n    ELSE POST to Betfair identity endpoint with credentials.\n    - On success store token + expiry (3 hours).\n    - On failure raise ConnectionError.\n\nADAPTER BetfairAdapter(BetfairAuthMixin, BaseAdapter):\n  SOURCE \"BetfairExchange\", base_url Betfair REST.\n  fetch_races(date):\n    - Authenticate.\n    - Build market_filter for eventTypeId \"7\" (horse racing).\n    - POST listMarketCatalogue with WIN markets in date window.\n    - If empty -> success with error_message.\n    - Else parse catalogue into races via _parse_race.\n  _parse_race:\n    - Build Runner for each runnerName, selectionId, sortPriority.\n    - Race ID \"bf_{marketId}\", venue event.venue, race_number via regex \"Rxx\".\n    - start_time from ISO string.\n  get_live_odds_for_market(market_id):\n    - Authenticate, POST listMarketBook with EX_TRADED price data.\n    - Extract lastPriceTraded for ACTIVE runners into Decimal map.\n    - Return selectionId->Decimal.\n\nADAPTER BetfairGreyhoundAdapter:\n  IDENTICAL structure; eventTypeId \"4339\"; Race ID prefix \"bfg_\".\n\nADAPTER TVGAdapter:\n  REQUIRE TVG_API_KEY.\n  fetch_races:\n    - GET tracks for date (country US).\n    - For each track, GET races summary, then detail per race.\n    - Parse to Race with _parse_tvg_race (skip scratched).\n  _parse_tvg_race:\n    - Program numbers sanitized via helper (strip letters).\n    - Extract odds via parse_odds (current or morning line).\n    - Compose Race ID with track code + date + race number.\n\nADAPTER RacingAndSportsAdapter:\n  REQUIRE token; on missing return FAILED status.\n  fetch_races:\n    - GET v1/racing/meetings with date & jurisdiction AUS.\n    - Iterate meetings/races, parse to Race via _parse_ras_race.\n  _parse_ras_race:\n    - Runners with runnerNumber, horseName, scratched flag.\n    - start_time iso parse.\n\nADAPTER RacingAndSportsGreyhoundAdapter:\n  Similar to above but endpoint v1/greyhound/meetings, Race prefix \"rasg_\".\n\nADAPTER AtTheRacesAdapter:\n  Scrape https://www.attheraces.com.\n  fetch_races:\n    - GET /racecards; parse meeting links.\n    - For each link -> fetch, parse track/time, race_number via active nav.\n    - Build Race with start_time based on current date + race time (no timezone).\n    - _parse_runner: extract horse number, name, best odds button -> parse to Decimal.\n\nADAPTER SportingLifeAdapter:\n  Scrape sportinglife.com racecards.\n  Similar approach: gather race links, parse track/time, nav for race_number, runners via cards.\n\nADAPTER TimeformAdapter:\n  Scrape timeform.com racecards.\n  Collect links, parse race page, determine race number via list of times, parse runner rows.\n\nADAPTER HarnessAdapter:\n  GET https://data.ustrotting.com/api/racenet/racing/card/{date}.\n  Parse meetings -> races -> runners (postPosition).\n  Convert morningLineOdds (if not fractional, append \"/1\"). Parse to Decimal.\n\nADAPTER GreyhoundAdapter:\n  Requires GREYHOUND_API_URL or raise ValueError.\n  fetch_races:\n    - GET v1/cards/{date}.\n    - Parse cards -> races -> runners (filter scratched). Convert odds.win decimals >1 to OddsData.\n\nADAPTER GbgbApiAdapter:\n  GET https://api.gbgb.org.uk/api/results/meeting/{date}.\n  Parse meetings/races/traps.\n  Race start_time from iso (replace 'Z' with +00:00). Distance appended as string.\n  Runners: parse sp fractional odds via parse_odds; assign OddsData.\n\nADAPTER TheRacingApiAdapter:\n  Requires THE_RACING_API_KEY.\n  fetch_races:\n    - GET racecards?date={date}&course=all&region=gb,ire.\n    - Parse racecards -> Race entries (race_id prefix \"tra_\").\n    - Runners: use odds list first entry's odds_decimal -> Decimal.\n\nADAPTER OddscheckerAdapter:\n  Scrape oddschecker horse racing.\n  fetch_races:\n    - GET /horse-racing -> meeting links.\n    - For each meeting fetch race links, then parse table rows -> Runners with odds.\n  Race result _format_response dumps Race models as dicts (model_dump).\n\nADAPTER PointsBetGreyhoundAdapter:\n  Placeholder (non-functional) -> returns SUCCESS with error message.\n\nADAPTER BrisnetAdapter, DRFAdapter, EquibaseAdapter, FanDuelAdapter,\n        HorseRacingNationAdapter, NYRABetsAdapter, PuntersAdapter,\n        RacingPostAdapter, RacingTVAdapter, TabAdapter, TwinSpiresAdapter,\n        XpressbetAdapter, TemplateAdapter:\n  Stubs returning empty responses with Not Implemented notice.\n```\n\n### Analyzer Layer\n\n```\nMODULE analyzer:\n  FUNCTION _get_best_win_odds(runner):\n    - Pull min win odds from runner.odds values < 999.\n    - Return Decimal or None.\n\n  ABSTRACT BaseAnalyzer:\n    - qualify_races(races) -> Dict (implemented by concrete analyzers).\n\n  CLASS TrifectaAnalyzer(BaseAnalyzer):\n    PARAMETERS: max_field_size=10, min_favorite_odds=2.5, min_second_favorite_odds=4.0 (Decimal).\n    METHOD qualify_races(races):\n      - For each race compute score via _evaluate_race.\n      - Filter races with scores -> assign race.qualification_score.\n      - Sort descending by score.\n      - Return {\"criteria\": {params}, \"races\": qualified_list}.\n    METHOD _evaluate_race(race):\n      - Filter non-scratched runners.\n      - Collect best odds for each runner; require >=2.\n      - Sort by odds ascending -> favorite, second favorite.\n      - Apply filters:\n          field_size <= max_field_size,\n          favorite_odds >= min_favorite_odds,\n          second_favorite_odds >= min_second_favorite_odds.\n      - Compute field_score = (max_field_size - field_size)/max_field_size.\n      - Normalize fav/second odds scores (cap 10/15).\n      - Weighted combination (field 0.3, odds 0.7).\n      - Return final_score *100 rounded to 2 decimals.\n\n  CLASS AnalyzerEngine:\n    - On init register 'trifecta' -> TrifectaAnalyzer.\n    - get_analyzer(name, **overrides):\n        if name missing -> raise ValueError.\n        instantiate analyzer with overrides for parameters.\n```\n\n### Engine Orchestration\n\n```\nCLASS OddsEngine(config):\n  INIT:\n    - Store config.\n    - Instantiate adapters list (major active ones: Betfair, BetfairGreyhound, TVG, R&S horse + greyhound,\n      AtTheRaces, SportingLife, Timeform, TheRacingApi, Gbgb, Harness).\n    - Create httpx.AsyncClient.\n    - Connect redis via redis.asyncio.from_url(config.REDIS_URL, decode_responses=True).\n    - Log redis initialization.\n\n  close():\n    - Close http_client.\n    - Close redis_client.\n\n  get_all_adapter_statuses():\n    - Return [adapter.get_status() for adapter in adapters].\n\n  _time_adapter_fetch(adapter, date):\n    - Record start, await adapter.fetch_races(date, http_client), compute duration.\n    - Return tuple (adapter.source_name, result_dict, duration).\n\n  _race_key(race):\n    - Lowercase trimmed venue + race_number + formatted start_time (HH:MM).\n\n  _dedupe_races(races):\n    - Build map by _race_key.\n    - If new key -> store race.\n    - Else merge runners (update odds per runner number, append new ones).\n    - Return deduped list.\n\n  fetch_all_odds(date, source_filter=None):\n    - Compose cache_key \"fortuna:races:{date}\".\n    - If no source_filter -> attempt redis GET, parse via AggregatedResponse.model_validate_json; return on hit.\n    - Determine target_adapters (filtered by name if provided).\n    - Launch async gather of _time_adapter_fetch for all targets (return_exceptions=True).\n    - For each result:\n        * If exception -> log error, skip.\n        * Extract source_info, override fetch_duration with measured duration.\n        * Append to sources list.\n        * If status SUCCESS -> extend all_races with result['races'].\n    - Dedupe races.\n    - Compose response_obj = AggregatedResponse(date parsed, races deduped, sources, metadata containing fetch_time, sources_queried, count success, total_races).\n    - If no source_filter -> store in redis with TTL 300 seconds.\n    - Return response_obj.model_dump().\n```\n\n### API Layer (FastAPI)\n\n```\nAPP fastapi.FastAPI(title \"Checkmate Ultimate Solo API\", version \"2.1\", lifespan context manager):\n  lifespan():\n    - configure_logging().\n    - Load settings via get_settings().\n    - Attach OddsEngine(config=settings) to app.state.engine.\n    - Attach AnalyzerEngine to app.state.analyzer_engine.\n    - On shutdown, engine.close().\n  MIDDLEWARE:\n    - SlowAPI rate limiting (Limiter key_func get_remote_address, 60/min for adapter status, 30/min for race endpoints).\n    - CORSMiddleware with allowed origins from settings.\n  DEPENDENCIES:\n    - verify_api_key (ensures X-API-Key matches settings.API_KEY except for /health).\n    - get_engine to fetch engine from app state.\n\nROUTES:\n  GET /health:\n    - Return {\"status\": \"ok\", \"timestamp\": now}.\n\n  GET /api/adapters/status:\n    - Rate limited 60/min.\n    - Requires API key.\n    - Return engine.get_all_adapter_statuses().\n    - On error -> HTTP 500.\n\n  GET /api/races/qualified/{analyzer_name} (response_model QualifiedRacesResponse):\n    - Rate limited 30/min.\n    - Query params: race_date optional (default today), optional overrides for analyzer params.\n    - Steps:\n        * Determine date_str.\n        * aggregated_data = await engine.fetch_all_odds(date_str).\n        * Extract races (list of Race models already validated).\n        * analyzer_engine = app.state.analyzer_engine.\n        * Filter overrides (non-None) into custom_params.\n        * analyzer = analyzer_engine.get_analyzer(analyzer_name, **custom_params).\n        * result = analyzer.qualify_races(races).\n        * Return QualifiedRacesResponse(**result).\n    - Handle ValueError -> 404 (missing analyzer).\n    - Handle general exception -> 500.\n\n  GET /api/races (response_model AggregatedResponse):\n    - Rate limited 30/min.\n    - Query: race_date optional, source optional.\n    - Determine date, call engine.fetch_all_odds(date_str, source).\n    - Return aggregated data (model_dump).\n```\n\n### Security\n\n```\nMODULE security:\n  DEFINE API_KEY_NAME \"X-API-Key\".\n  USE fastapi.security.APIKeyHeader auto_error True.\n  verify_api_key(header_value):\n    - Fetch settings.\n    - Compare to settings.API_KEY via secrets.compare_digest.\n    - If match -> return True.\n    - Else raise HTTP 403 \"Invalid or missing API Key\".\n```\n\n### Tests\n\n```\ntests/test_legacy_scenarios.py:\n  PURPOSE: Validate TrifectaAnalyzer behavior through API route.\n\n  HELPER create_mock_runner(number, odds_val, scratched=False):\n    - Build Runner with OddsData using decimal odds.\n\n  DEFINE Mock Races (Race models):\n    - MOCK_RACE_PASS: 5 runners, odds 3.0, 4.5 etc (passes filters).\n    - MOCK_RACE_FAIL_FIELD_SIZE: 11 runners -> exceed field_size.\n    - MOCK_RACE_FAIL_FAV_ODDS: favorite odds 2.0 (below threshold).\n    - MOCK_RACE_FAIL_2ND_FAV_ODDS: second favorite 3.5 (below threshold).\n\n  TEST test_trifecta_analyzer_with_legacy_scenarios:\n    - Patch OddsEngine.fetch_all_odds to AsyncMock returning races list.\n    - Use FastAPI TestClient (fixture 'client').\n    - GET /api/races/qualified/trifecta with headers (X-API-Key).\n    - Assert status 200.\n    - Expect exactly 1 qualified race (LEGACY_PASS_1) + criteria check.\n    - Assert mocked engine fetch awaited once.\n```\n\n### Auxiliary Scripts (Backend / Tooling)\n\n```\nSCRIPT convert_to_json.py:\n  PURPOSE: Convert manifest-listed files into JSON snapshots (sandboxed read).\n  STEPS:\n    - Configuration: MANIFEST_FILES, OUTPUT_DIR, TIMEOUT.\n    - extract_and_normalize_path(line): handle markdown links, backtick paths, bullet lists; convert GitHub raw URLs to local paths.\n    - convert_file_to_json_sandboxed(file_path):\n        * Launch subprocess to safely read file (avoid sandbox issues).\n        * Terminate if exceeds timeout.\n    - main():\n        * Parse manifests -> gather unique paths.\n        * For each path, sandbox read.\n        * Save JSON {file_path, content} into OUTPUT_DIR mirroring structure.\n        * Report successes/failures; exit 1 if failures.\n\nSCRIPT create_fortuna_json.py:\n  PURPOSE: Generate FORTUNA_ALL_PART1/2 JSON bundles.\n  PROCESS:\n    - Parse manifests -> gather unique paths.\n    - For each file:\n        * Read content.\n        * Categorize: if path starts with \"python_service/\" or \"tests/\" -> Part1; else Part2.\n    - Write JSON dumps with indentation.\n    - Report counts; exit 1 if failures.\n\nSCRIPT chart_scraper.py (ChartScraper class):\n  - Manage directories results_archive/{pdf,pdf_unlocked,csv}.\n  - Determine yesterday date formats for summary + PDF.\n  - _get_yesterday_tracks: fetch Equibase summary page, parse track IDs.\n  - _download_and_parse_chart(track_code, chart_date):\n      * Build PDF URL pattern.\n      * Download PDF (check content-type/length).\n      * Save locked/unlocked (via pikepdf).\n      * Use tabula.read_pdf to extract tables -> combine -> CSV.\n  - run(): orchestrates directories, fetch tracks, iterate, throttle with sleep(1).\n\nSCRIPT command_deck.py (Streamlit):\n  - Configure Streamlit page.\n  - Load DEV_API_KEY from environment (fallback test key).\n  - cached helper get_api_data endpoint -> fetch using requests.\n  - UI:\n      * Title + description.\n      * Sidebar select analyzer (currently only trifecta) and \"Clear Cache\" button.\n      * Display qualified races in DataFrame (normalize nested runners) or info/error messages.\n      * Display adapter status DataFrame.\n\nSCRIPT results_parser.py (ChartParser):\n  - Provide count_runners(chart_text) scanning \"Past Performance Running Line Preview\" section; count lines starting with digit until blank or \"Trainers:\".\n\nSCRIPT live_monitor.py (LiveOddsMonitor class):\n  - INIT: store config, instantiate BetfairAdapter.\n  - monitor_race(race, http_client):\n      * If race ID not from Betfair -> log warning, return race unchanged.\n      * Extract market_id.\n      * Call adapter.get_live_odds_for_market.\n      * Update each runner's odds dict with new OddsData (timestamp now) when selection_id matches.\n      * Return updated race.\n\nSCRIPT fortuna_watchman.py (Watchman orchestrator):\n  - INIT: load settings, instantiate OddsEngine, AnalyzerEngine, LiveOddsMonitor.\n  - get_initial_targets():\n      * fetch today's aggregated data.\n      * Acquire analyzer (trifecta).\n      * Evaluate races -> sorted by score; log top 5.\n  - run_tactical_monitoring(targets):\n      * With httpx.AsyncClient loop:\n          - Determine races within next 5 minutes.\n          - For each such race call live_monitor.monitor_race.\n          - Remove monitored race from list.\n          - Sleep 30 seconds; exit when no active targets.\n  - execute_daily_protocol():\n      * Log start.\n      * Acquire initial targets; if any run monitoring, else log none.\n      * Close odds_engine.\n      * Log completion.\n  - main() entrypoint -> configure logging, instantiate Watchman, run execute_daily_protocol.\n\nWINDOWS Scripts:\n  - setup_windows.bat:\n      * Verify python installed.\n      * Create venv (.venv) if missing.\n      * Activate & install python_service/requirements.txt.\n      * Verify Node.js; npm install under web_platform/frontend.\n      * Print final instructions.\n\n  - run_fortuna.bat:\n      * Launch backend uvicorn in new window (activating venv).\n      * Launch frontend Next.js in new window.\n      * Wait 5 sec, open browser http://localhost:3000.\n```\n\n---\n\n## REDIS & CACHING\n\n```\nBACKEND relies on redis.asyncio client:\n  - namespace \"fortuna:races:{date}\" for aggregated responses (no source filter).\n  - store JSON serialized AggregatedResponse for 5 minutes.\n  - On retrieval, validate via Pydantic before returning.\n\nERROR HANDLING:\n  - redis GET/SET exceptions logged but don't halt main flow.\n```\n\n---\n\n## DOCUMENTATION (Selected Highlights)\n\n```\nARCHITECTURAL_MANDATE.md:\n  - Defines Two-Pillar architecture, Prime Directive.\n  - Emphasizes OddsEngine, BaseAdapter, Adapter Fleet, Pydantic models, TrifectaAnalyzer.\n\nHISTORY.md:\n  - Chronicles project eras from \"Utopian\" to \"Liberation\".\n  - Explains environment hostility and shift to portable engine.\n\nROADMAP_APPENDICES.md:\n  - Catalog of adapter backlog categories, intelligence leads, future campaigns (Analyst expansion, legacy tests, dashboard).\n\nWISDOM.md:\n  - Provides virtues/vices for agents (operational protocols).\n  - Reinforces verifying instructions, small commits, reliance on Project Lead.\n\nREADME.md:\n  - Quick start instructions (setup_windows.bat, run_fortuna.bat).\n  - API usage note (API key header requirement).\n\n.env.example:\n  - Template for backend credentials + configuration options.\n```\n\n---\n\n## FRONTEND PILLAR (web_platform/frontend)\n\n### Configuration & Tooling\n\n```\nENV: Next.js 14 + React 18, Tailwind CSS, TypeScript.\n\nFiles:\n  - .env.local.example: requires NEXT_PUBLIC_API_KEY + API_URL.\n  - next.config.mjs: sets rewrites to proxy /api/* to backend 8000.\n  - package.json: dependencies (next, react, socket.io-client), dev dependencies (Tailwind, TypeScript).\n  - tailwind.config.ts + postcss.config.js: standard Tailwind setup.\n  - tsconfig.json: configure compiler options (strict false, noEmit, Next plugin).\n```\n\n### UI Components\n\n```\nCOMPONENT LiveRaceDashboard (client component):\n  STATE:\n    races list\n    criteria object\n    loading boolean\n    error string\n    lastUpdate timestamp\n    params {max_field_size, min_favorite_odds, min_second_favorite_odds}\n      - Initialized from localStorage (if available) else defaults.\n      - Persist params back to localStorage on change.\n\n  EFFECTS:\n    - On mount: fetchQualifiedRaces(initialLoad=True).\n    - Set interval every 30s -> fetchQualifiedRaces(False).\n    - Cleanup interval on unmount.\n\n  fetchQualifiedRaces(isInitialLoad):\n    - Show loading on initial.\n    - Reset error.\n    - Fetch API key from NEXT_PUBLIC_API_KEY (error if missing).\n    - Build query string from params.\n    - GET `/api/races/qualified/trifecta` with X-API-Key header.\n    - On success: set races, criteria, lastUpdate.\n    - On failure: set error message.\n    - Toggle loading false when initial load complete.\n\n  handleParamChange:\n    - Update params with slider values.\n\n  RENDER:\n    - Title, last update timestamp.\n    - Control panel with range inputs for parameters (display current values).\n    - Conditional messages for loading/error.\n    - Summary of number of qualified races.\n    - Grid of RaceCard components for each race.\n\nCOMPONENT RaceCard:\n  PROPS: race (matching Race interface).\n  PROCESS:\n    - Filter out scratched runners.\n    - Sort active runners by number.\n    - Count unique odds sources across runners.\n    - Determine best odds per runner (min win < 999).\n    - formatTimeUntilPost helper -> difference between start_time and now (hours/mins).\n    - Render card with:\n        * Header (venue, race number, time to post).\n        * Qualification score badge (color-coded thresholds).\n        * Race condition grid (distance, surface default 'Dirt', field size, sources count).\n        * Runner list with stylized badges for top 3 positions (gold/silver/bronze), odds display with source.\n```\n\n---\n\n## COMMAND DECK (Streamlit)\n\n```\nAPPLICATION command_deck.py:\n  - Provide alternate dashboard for backend monitoring.\n  - Uses st.cache_data for API calls (TTL 30s) with manual clear button.\n  - Displays qualified races normalized into DataFrame (runners flattened).\n  - Displays adapter statuses DataFrame.\n  - Utilizes environment variable DEV_API_KEY or fallback.\n```\n\n---\n\n## DATA PROCESSING UTILITIES\n\n```\nChartScraper workflow:\n  - Determine yesterday's tracks from Equibase summary HTML.\n  - For each track, attempt to download combined PDF (size check).\n  - Unlock PDF via pikepdf to remove encryption.\n  - Extract tables with tabula (lattice mode).\n  - Concatenate to CSV for archival.\n  - Delay between requests (1 second) to be polite.\n\nChartParser (results_parser.py):\n  - Parse extracted text to count number of runners by reading the \"Past Performance Running Line Preview\" section.\n```\n\n---\n\n## PROJECT AUTOMATION & DEPLOYMENT\n\n```\nsetup_windows.bat:\n  - Single entry script to prepare backend + frontend dependencies on Windows.\n\nrun_fortuna.bat:\n  - Launch backend server via uvicorn (auto reload) in new CMD window.\n  - Launch Next.js dev server in another window.\n  - After delay, open default browser to frontend.\n\nfortuna_watchman.py:\n  - Could be scheduled (e.g., cron/Task Scheduler) to run daily.\n  - Integrates OddsEngine + Analyzer + LiveOddsMonitor for real-time monitoring.\n\nlive_monitor.py:\n  - Designed to be invoked close to post time to refresh odds from Betfair.\n\nRedis caching:\n  - Requires running redis instance (default local) for performance.\n```\n\n---\n\n## END-TO-END FLOW (Narrative Pseudocode)\n\n```\nFUNCTION DailyOperation():\n  INIT settings = get_settings()\n  INIT odds_engine = OddsEngine(settings)\n  INIT analyzer_engine = AnalyzerEngine()\n  INIT http_client (within odds_engine)\n  INIT redis cache.\n\n  FOR each requested API call (/api/races or /api/races/qualified):\n    VERIFY API key via security.verify_api_key.\n    IF aggregated data cached (and no source filter):\n      RETRIEVE from Redis.\n    ELSE:\n      PARALLEL fetch using adapters:\n        - Each adapter fetch_races(date, http_client)\n        - Standardize Race/Runner structures.\n      MERGE all races with dedupe. (Odds aggregated per runner).\n      BUILD AggregatedResponse.\n      CACHE (if applicable).\n    IF route is /qualified:\n      analyzer = analyzer_engine.get_analyzer(\"trifecta\", overrides)\n      qualified = analyzer.qualify_races(races)\n      RETURN QualifiedRacesResponse.\n\n  FRONTEND LiveRaceDashboard:\n    PERIODICALLY fetch /api/races/qualified/trifecta with user-adjusted parameters.\n    DISPLAY race cards with scoring, countdown, best odds per runner.\n\n  COMMAND_DECK (Streamlit):\n    - Provide alternative interface for developers/operators.\n\n  WATCHMAN automation:\n    - At start of day: fetch all races, filter top opportunities.\n    - As race times approach: call LiveOddsMonitor to augment with live Betfair odds.\n    - Continue until all targets monitored; shutdown.\n\n  CHART PIPELINE (optional offline run):\n    - Use ChartScraper to download PDFs and convert to CSV for historical analysis.\n    - Use ChartParser to interpret extracted text.\n\n  DOCUMENTATION:\n    - Guides architecture decisions, historical context, roadmap, operational wisdom.\n```\n\n---\n\n## SUMMARY\n\n```\nFortunaFaucet encapsulates:\n  - Hardened async backend with resilient adapters, serializer models, caching, analysis engine, HTTP API, security.\n  - Multi-source adapter fleet supporting APIs and HTML scrapes, with placeholders for future expansion.\n  - Analyzer framework currently featuring Trifecta strategy with scoring.\n  - Redis-backed caching and rate-limited FastAPI endpoints.\n  - Automated watchman for daily operations and live odds integration.\n  - Frontend Next.js dashboard + Streamlit command deck for visualization.\n  - Comprehensive documentation capturing mission, history, roadmap, and operational protocols.\n  - Tooling scripts for data archiving and Windows-based development workflows.\n```\n\n---",
    "README.md": "# \ud83d\udc34 Fortuna Faucet - Racing Analysis Engine\n\nWelcome to Fortuna Faucet! This guide provides instructions for both end-users and developers.\n\n## Getting Started: The Official Installation\n\nThe easiest way to get started is with our official MSI installer, which handles all setup and configuration automatically.\n\n1.  **Download the Installer:**\n    *   Go to the [latest release page](https://github.com/masonj0/fortuna/releases/latest) on GitHub.\n    *   Download the `Fortuna-Faucet-Setup-vX.X.X.msi` file.\n\n2.  **Run the Installer:**\n    *   Double-click the downloaded `.msi` file.\n    *   Follow the on-screen instructions in the setup wizard.\n\nOnce installed, a \"Fortuna Faucet\" folder will be created in your Start Menu. The application's backend will run automatically as a background service, and you can access the dashboard via the Start Menu shortcut.\n\n---\n\n## For Developers\n\nThis section contains instructions for developers who wish to contribute to the project or manage the environment manually.\n\n### Core Architecture\n\n*   **Backend (`python_service/`):** An asynchronous FastAPI application.\n*   **Frontend (`web_platform/frontend/`):** A Next.js and TypeScript dashboard.\n*   **Unified Launcher (`fortuna_app.py`):** The primary entry point for local development, managing all services and providing real-time health monitoring.\n\n### Manual Development Setup\n\n1.  **Prerequisites:** Python 3.11+, Node.js (LTS), Git.\n2.  **Clone:** `git clone https://github.com/masonj0/fortuna.git`\n3.  **Backend:** Create a venv (`python -m venv .venv`) and `pip install -r requirements.txt`.\n4.  **Frontend:** `cd web_platform/frontend` and run `npm install`.\n\n### Creating a Release Build (MSI Installer)\n\nThe project uses the WiX Toolset to create a distributable MSI installer.\n\n*   **Configuration:** All WiX source files are in the `wix/` directory.\n*   **Build Script:** The build process is managed by `scripts/build_msi.ps1`.\n*   **CI/CD:** The build is automated via GitHub Actions, defined in `.github/workflows/build_msi.yml`. To create a release build locally, ensure the WiX Toolset is installed and run the PowerShell script.\n",
    "README_WINDOWS.md": "# \ud83d\udc34 Fortuna Faucet - Windows Installation Guide (for End Users)\n\nWelcome to Fortuna Faucet! Installing the application is now a simple, one-step process.\n\n## The Official Installation Method\n\n1.  **Go to the Latest Release Page:**\n    *   Navigate to our official GitHub Releases page: [https://github.com/masonj0/fortuna/releases/latest](https://github.com/masonj0/fortuna/releases/latest)\n\n2.  **Download the Installer:**\n    *   Look for the file named `Fortuna-Faucet-Setup-vX.X.X.msi` (the version number will change).\n    *   Download this file to your computer.\n\n3.  **Run the Installer:**\n    *   Double-click the downloaded `.msi` file.\n    *   Follow the on-screen instructions in the setup wizard.\n\nOnce the installation is complete, you will find a \"Fortuna Faucet\" folder in your Start Menu containing the main application. The application is a single, unified program with tabs for the Control Panel, Setup, and System Tools.\n\nThat's it! All previous methods involving Python scripts or batch files are now obsolete.",
    "REBRANDING_AUDIT.md": "# Fortuna Faucet: Rebranding Audit Report\n\nThis report lists all files containing legacy branding terms (`checkmate`, `solo`).\n\n---\n\n- `./.env`\n- `./AGENTS.md`\n- `./ARCHITECTURAL_MANDATE_V8.1.md`\n- `./GEMINI_ONBOARDING.md`\n- `./HISTORY.md`\n- `./JSON_BACKUP_MANIFEST.md`\n- `./MANIFEST2.md`\n- `./MANIFEST3.md`\n- `./PROJECT_MANIFEST.md`\n- `./Procfile`\n- `./ROADMAP.md`\n- `./ROADMAP_APPENDICES.md`\n- `./WISDOM.md`\n- `./attic/ARCHITECTURAL_MANDATE_V7.2.md`\n- `./attic/build_python_service.py`\n- `./attic/checkmate_app.py`\n- `./attic/checkmate_engine.py`\n- `./attic/checkmate_monitor_v1.html`\n- `./attic/dashboard.py`\n- `./attic/desktop_app/App.xaml`\n- `./attic/desktop_app/App.xaml.cs`\n- `./attic/desktop_app/CheckmateDeck.csproj`\n- `./attic/desktop_app/Models/AdapterStatusDisplay.cs`\n- `./attic/desktop_app/Models/DisplayRace.cs`\n- `./attic/desktop_app/Services/DatabaseService.cs`\n- `./attic/desktop_app/Services/IDatabaseService.cs`\n- `./attic/desktop_app/ViewModels/MainViewModel.cs`\n- `./attic/desktop_app/Views/MainWindow.xaml`\n- `./attic/desktop_app/Views/MainWindow.xaml.cs`\n- `./attic/launcher.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_api.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_betfair_modern_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_fanduel_api_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_logic.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_models.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_racingpost_modern_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_run.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_services.py`\n- `./attic/legacy_tests_pre_triage/test_checkmate_v7.py`\n- `./attic/legacy_tests_pre_triage/test_python_service.py`\n- `./attic/portable_demo_v2.py`\n- `./attic/rust_engine/rust_engine/Cargo.toml`\n- `./attic/rust_engine/rust_engine/benches/analysis_benchmark.rs`\n- `./attic/rust_engine/rust_engine/src/lib.rs`\n- `./attic/rust_engine/rust_engine/src/main.rs`\n- `./attic/the_one_script.py`\n- `./attic/tipsheet_generator.py`\n- `./attic/vba_source/Module_Charts.bas`\n- `./attic/vba_source/Module_DB.bas`\n- `./attic/vba_source/Module_UI.bas`\n- `./checkmate_web/engine.py`\n- `./checkmate_web/main.py`\n- `./checkmate_web/static/app.js`\n- `./checkmate_web/static/index.html`\n- `./command_deck.py`\n- `./diagnostic_report.txt`\n- `./launch_and_hunt.py`\n- `./launch_checkmate.bat`\n- `./launch_command_deck.bat`\n- `./manual_override_tool.py`\n- `./pg_schemas/historical_races.sql`\n- `./pytest.ini`\n- `./python_service/api.py`\n- `./python_service/checkmate_service.py`\n- `./python_service/minimal_service.py`\n- `./python_service/windows_service_wrapper.py`\n- `./run_server.py`\n- `./rust_engine/tests/integration_tests.rs`\n- `./shared_database/schema.sql`\n- `./src/checkmate_v7/adapters/AndWereOff.py`\n- `./src/checkmate_v7/adapters/Stablemates.py`\n- `./src/checkmate_v7/adapters/__init__.py`\n- `./src/checkmate_v7/api.py`\n- `./src/checkmate_v7/base.py`\n- `./src/checkmate_v7/cockpit.py`\n- `./src/checkmate_v7/config.py`\n- `./src/checkmate_v7/database.py`\n- `./src/checkmate_v7/headless_monitor.py`\n- `./src/checkmate_v7/logic.py`\n- `./src/checkmate_v7/models.py`\n- `./src/checkmate_v7/run.py`\n- `./src/checkmate_v7/services.py`\n- `./src/checkmate_v7/settings.py`\n- `./src/paddock_parser/prediction_engine.py`\n- `./web_platform/api_gateway/package-lock.json`\n- `./web_platform/api_gateway/src/server.ts`\n- `./web_platform/api_gateway/src/services/DatabaseService.ts`\n- `./web_platform/frontend/.next/server/app/page.js`\n- `./web_platform/frontend/app/layout.tsx`\n- `./web_platform/frontend/src/components/RaceCard.tsx`\n- `./web_platform/frontend/src/types/racing.ts`\n",
    "ROADMAP_APPENDICES.md": "# \ud83d\uddfa\ufe0f Fortuna Faucet - Roadmap & Accomplishments\n\nThis document tracks the strategic evolution of the Fortuna Faucet project.\n\n## Phase 1: Core Engine Development (Complete)\n- **Objective:** Build a robust, scalable data extraction and analysis engine.\n- **Status:** COMPLETE.\n\n## Phase 2: The Golden Path - UX Overhaul (Complete)\n- **Objective:** Transform the developer-centric tool into a seamless, professional-grade Windows application for non-technical users.\n- **Status:** COMPLETE.\n\n## Phase 3: The Turnkey Solution - Professional Release Pipeline (Complete)\n- **Objective:** Eliminate all manual setup steps and create an enterprise-grade, automated build and release system.\n- **Status:** COMPLETE.\n\n### Key Accomplishments & Completed Operations:\n\n1.  **Operation: The Great Housekeeping**\n    - Purified the repository architecture, deprecated legacy codebases and scripts, and established a clean foundation.\n    - Forged a new, programmatic manifest generation system.\n\n2.  **Operation: The Blueprint**\n    - Established the professional directory structure for an enterprise-grade build system.\n    - Implemented the master WiX product definition and the PowerShell build orchestrator.\n\n3.  **Operation: The Assembly Line**\n    - Fully automated the MSI build process with a GitHub Actions CI/CD workflow.\n\n4.  **Operation: The Proving Ground**\n    - Forged a complete suite of automated PowerShell scripts to test and validate the integrity of every installer artifact (install, silent deploy, uninstall).\n\n5.  **Operation: The User's Keys**\n    - Created the final, user-facing toolkit of scripts for easy lifecycle management (install, uninstall, repair).\n\n6.  **Operation: Modernize the Assembly Line**\n    - Performed a surgical upgrade to the CI/CD pipeline to resolve a critical GitHub Actions deprecation, ensuring continued operational readiness.\n\n## Phase 4: User Experience & Feature Enhancement (Next Steps)\n- **Objective:** Enhance the core user experience and expand the analytical capabilities of the engine.\n- **Status:** PENDING.\n- **Potential Missions:**\n  - **Operation: The Monolith:** Unify the disparate GUI tools (launcher, setup wizard) into a single, tabbed application for a seamless user experience.\n  - **Operation: The Interpreter:** Implement a user-friendly error-handling system that translates technical errors into simple, actionable advice.\n  - **Data Persistence & Caching:** Implement a local SQLite database to cache race data, improving performance and enabling offline access.",
    "STATUS.md": "# Project Status: Foundation Rebuilt, Hardening in Progress\n\n**Date:** 2025-10-03\n\n## Current State\n\n*   **Architecture:** The backend has been successfully rebuilt into a superior, asynchronous FastAPI application, as defined by 'Operation: Grand Synthesis'. The new foundation is stable, tested, and features a resilient `BaseAdapter` pattern.\n\n*   **Status:** The foundational refactoring is complete. The first two data adapters (`Betfair`, `TVG`) have been implemented on the new architecture. We are now in a new phase of development: **'Phase 2: Hardening & Expansion.'**\n\n*   **Documentation:** All core strategic documents and manifests have been synchronized with the new technical reality.\n\n*   **Next Steps:** Our immediate priority is to act on the verified intelligence from our Oracle (Jules1003). The next missions will focus on implementing critical API security features (rate limiting, authentication) and continuing the build-out of our adapter fleet.",
    "VERSION.txt": "1.0.0",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2)---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "assets/sounds/.gitkeep": "# This directory is for audio alert sound files (e.g., alert_premium.wav)",
    "config.ini": "[analysis]\nqualification_score = 75.0\nfield_size_optimal_min = 4\nfield_size_optimal_max = 6\nfield_size_acceptable_min = 7\nfield_size_acceptable_max = 8\nfield_size_optimal_points = 30\nfield_size_acceptable_points = 10\nfield_size_penalty_points = -20\nfav_odds_points = 30\nmax_fav_odds = 3.5\nsecond_fav_odds_points = 40\nmin_2nd_fav_odds = 4.0\n\n[system]\napi_rate_limit = 60",
    "configure_startup.py": "# configure_startup.py\nimport winreg\nimport sys\nfrom pathlib import Path\n\nclass StartupManager:\n    \"\"\"Manage Windows startup registry entries for the current user.\"\"\"\n\n    REGISTRY_PATH = r\"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n    APP_NAME = \"FortunaFaucetTray\"\n\n    @classmethod\n    def is_enabled(cls) -> bool:\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_READ)\n            winreg.QueryValueEx(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            return True\n        except FileNotFoundError:\n            return False\n\n    @classmethod\n    def enable(cls):\n        launcher_path = Path(__file__).parent / \"launcher.ps1\"\n        cmd = f'powershell.exe -WindowStyle Hidden -File \"{launcher_path}\"'\n\n        key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n        winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, cmd)\n        winreg.CloseKey(key)\n        print(\"Startup enabled.\")\n\n    @classmethod\n    def disable(cls):\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n            winreg.DeleteValue(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            print(\"Startup disabled.\")\n        except FileNotFoundError:\n            print(\"Already disabled.\")\n\nif __name__ == '__main__':\n    if len(sys.argv) > 1:\n        if sys.argv[1] == 'enable': StartupManager.enable()\n        elif sys.argv[1] == 'disable': StartupManager.disable()\n        elif sys.argv[1] == 'status': print(f\"Startup is currently {'enabled' if StartupManager.is_enabled() else 'disabled'}\")\n    else:\n        print(\"Usage: python configure_startup.py [enable|disable|status]\")\n",
    "create_fortuna_json.py": "# DEPRECATED\n# This script is no longer in use and is superseded by ARCHIVE_PROJECT.py\n\nimport sys\n\nprint(\"ERROR: This script is deprecated.\", file=sys.stderr)\nprint(\"Please use 'python ARCHIVE_PROJECT.py' to generate the project archives.\", file=sys.stderr)\nsys.exit(1)",
    "fortuna_app.py": "import tkinter as tk\nfrom tkinter import ttk, messagebox, scrolledtext, font\nimport subprocess\nimport threading\nimport time\nimport requests\nimport psutil\nimport socket\nimport sys\nimport os\nfrom pathlib import Path\n\n# --- Control Panel Tab (from former launcher_gui.py) ---\nclass ControlPanelTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg='#1a1a2e')\n        self.backend_proc = None\n        self.frontend_proc = None\n        self._create_ui()\n        self.monitor_thread = threading.Thread(target=self.monitor_services, daemon=True)\n        self.monitor_thread.start()\n\n    def _create_ui(self):\n        title = tk.Label(self, text=\"\ud83d\udc34 System Control Panel\", font=(\"Segoe UI\", 16, \"bold\"), bg='#1a1a2e', fg='#00ff88')\n        title.pack(pady=20)\n\n        status_frame = tk.Frame(self, bg='#1a1a2e')\n        status_frame.pack(fill=tk.X, padx=40, pady=10)\n\n        tk.Label(status_frame, text=\"Backend Service (API)\", font=(\"Segoe UI\", 10), bg='#1a1a2e', fg='#ffffff').pack(anchor=\"w\")\n        self.backend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg='#0f3460', highlightthickness=0)\n        self.backend_status_canvas.pack(fill=tk.X, pady=(0, 10))\n        self.backend_indicator = self.backend_status_canvas.create_oval(15, 10, 35, 30, fill='#ff4444', outline='')\n        self.backend_text = self.backend_status_canvas.create_text(55, 20, text=\"Stopped\", fill='#ffffff', anchor=\"w\", font=(\"Segoe UI\", 9))\n\n        tk.Label(status_frame, text=\"Frontend Dashboard (UI)\", font=(\"Segoe UI\", 10), bg='#1a1a2e', fg='#ffffff').pack(anchor=\"w\")\n        self.frontend_status_canvas = tk.Canvas(status_frame, width=300, height=40, bg='#0f3460', highlightthickness=0)\n        self.frontend_status_canvas.pack(fill=tk.X)\n        self.frontend_indicator = self.frontend_status_canvas.create_oval(15, 10, 35, 30, fill='#ff4444', outline='')\n        self.frontend_text = self.frontend_status_canvas.create_text(55, 20, text=\"Stopped\", fill='#ffffff', anchor=\"w\", font=(\"Segoe UI\", 9))\n\n        button_frame = tk.Frame(self, bg='#1a1a2e')\n        button_frame.pack(fill=tk.X, padx=40, pady=20)\n\n        self.launch_btn = tk.Button(button_frame, text=\"\u25b6 START FORTUNA\", font=(\"Segoe UI\", 14, \"bold\"), bg='#00ff88', fg='#000000', command=self.launch_services, height=2, relief=tk.FLAT)\n        self.launch_btn.pack(fill=tk.X, pady=(0, 10))\n\n        self.stop_btn = tk.Button(button_frame, text=\"\u23f9 STOP SERVICES\", font=(\"Segoe UI\", 12), bg='#ff4444', fg='#ffffff', command=self.stop_services, state=tk.DISABLED, height=1, relief=tk.FLAT)\n        self.stop_btn.pack(fill=tk.X)\n\n    def check_ports(self, ports=[8000, 3000]):\n        unavailable_ports = []\n        for port in ports:\n            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n                if s.connect_ex(('127.0.0.1', port)) == 0:\n                    unavailable_ports.append(port)\n        return unavailable_ports\n\n    def launch_services(self):\n        unavailable = self.check_ports()\n        if unavailable:\n            messagebox.showerror(\"Port Conflict\", f\"Cannot launch. Port(s) {', '.join(map(str, unavailable))} are already in use by another application.\")\n            return\n\n        self.launch_btn.config(state=tk.DISABLED)\n        self.update_status(\"backend\", \"starting\", \"Launching...\")\n        self.update_status(\"frontend\", \"starting\", \"Launching...\")\n\n        try:\n            venv_python = Path(\".venv/Scripts/python.exe\")\n            self.backend_proc = subprocess.Popen(\n                [str(venv_python), \"-m\", \"uvicorn\", \"python_service.api:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"],\n                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=Path(__file__).parent, creationflags=subprocess.CREATE_NEW_PROCESS_GROUP\n            )\n        except Exception as e:\n            self.update_status(\"backend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        try:\n            self.frontend_proc = subprocess.Popen(\n                [\"npm\", \"run\", \"dev\"], shell=True,\n                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=\"web_platform/frontend\", creationflags=subprocess.CREATE_NEW_PROCESS_GROUP\n            )\n        except Exception as e:\n            self.update_status(\"frontend\", \"error\", f\"Launch Error: {str(e)[:40]}\")\n            self.stop_btn.config(state=tk.NORMAL)\n            return\n\n        self.stop_btn.config(state=tk.NORMAL)\n\n    def stop_services(self):\n        self.stop_btn.config(state=tk.DISABLED)\n        for proc_name in [\"backend\", \"frontend\"]:\n            proc = getattr(self, f\"{proc_name}_proc\")\n            if proc and proc.poll() is None:\n                try:\n                    parent = psutil.Process(proc.pid)\n                    for child in parent.children(recursive=True):\n                        child.kill()\n                    parent.kill()\n                except psutil.NoSuchProcess:\n                    pass\n            setattr(self, f\"{proc_name}_proc\", None)\n        self.launch_btn.config(state=tk.NORMAL)\n\n    def monitor_services(self):\n        while True:\n            if self.backend_proc and self.backend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:8000/health\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"backend\", \"ok\", \"Healthy (200 OK)\")\n                    else:\n                        self.update_status(\"backend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"backend\", \"unresponsive\", \"Unresponsive\")\n            else:\n                self.update_status(\"backend\", \"stopped\", \"Stopped\")\n\n            if self.frontend_proc and self.frontend_proc.poll() is None:\n                try:\n                    r = requests.get(\"http://localhost:3000\", timeout=2)\n                    if r.status_code == 200:\n                        self.update_status(\"frontend\", \"ok\", \"Healthy (200 OK)\")\n                    else:\n                        self.update_status(\"frontend\", \"error\", f\"Error ({r.status_code})\")\n                except requests.RequestException:\n                    self.update_status(\"frontend\", \"unresponsive\", \"Unresponsive\")\n            else:\n                self.update_status(\"frontend\", \"stopped\", \"Stopped\")\n            time.sleep(5)\n\n    def update_status(self, service: str, status: str, message: str):\n        colors = {\"ok\": \"#00ff88\", \"unresponsive\": \"#ffcc00\", \"error\": \"#ff4444\", \"stopped\": \"#ff4444\", \"starting\": \"#0f6cbd\"}\n        canvas = getattr(self, f\"{service}_status_canvas\")\n        indicator = getattr(self, f\"{service}_indicator\")\n        text = getattr(self, f\"{service}_text\")\n\n        canvas.itemconfig(indicator, fill=colors.get(status, \"#404060\"))\n        canvas.itemconfig(text, text=message)\n\n# --- Setup Wizard Tab (from former setup_wizard_gui.py) ---\nclass SetupWizardTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg='#1a1a2e')\n        self.current_step = 0\n        self.settings = {}\n        self._create_widgets()\n        self.show_step(0)\n\n    def _create_widgets(self):\n        header = tk.Label(self, text=\"\ud83d\udd27 First-Time Setup & Configuration\", font=(\"Segoe UI\", 16, \"bold\"), bg='#1a1a2e', fg='#ffffff')\n        header.pack(pady=20)\n        self.step_label = tk.Label(self, text=\"Step 1 of 4: Generate API Key\", font=(\"Segoe UI\", 11), bg='#1a1a2e', fg='#ffffff')\n        self.step_label.pack(pady=10)\n        self.content_frame = tk.Frame(self, bg='#1a1a2e')\n        self.content_frame.pack(fill=tk.BOTH, expand=True, padx=30, pady=20)\n        button_frame = tk.Frame(self, bg='#1a1a2e')\n        button_frame.pack(fill=tk.X, padx=30, pady=20)\n        self.prev_btn = tk.Button(button_frame, text=\"< Back\", command=self.previous_step, state=tk.DISABLED, bg='#404060', fg='#ffffff', padx=20)\n        self.prev_btn.pack(side=tk.LEFT)\n        self.next_btn = tk.Button(button_frame, text=\"Next >\", command=self.next_step, bg='#00ff88', fg='#000000', font=(\"Segoe UI\", 11, \"bold\"), padx=20)\n        self.next_btn.pack(side=tk.RIGHT)\n\n    def show_step(self, step_index):\n        self._clear_content()\n        self.current_step = step_index\n        if step_index == 0: self._show_step_1()\n        elif step_index == 1: self._show_step_2()\n        elif step_index == 2: self._show_step_3()\n        elif step_index == 3: self._show_step_4()\n        self.update_buttons()\n\n    def _show_step_1(self):\n        tk.Label(self.content_frame, text=\"\ud83d\udd10 Secure API Key\", font=(\"Segoe UI\", 12, \"bold\"), bg='#1a1a2e', fg='#ffffff').pack(anchor=\"w\")\n        tk.Label(self.content_frame, text=\"A secure API key will be generated and stored.\", wraplength=600, justify=tk.LEFT, bg='#1a1a2e', fg='#cccccc').pack(anchor=\"w\", pady=10)\n        # ... Add API key generation logic and display ...\n\n    def _show_step_2(self):\n        tk.Label(self.content_frame, text=\"\ud83c\udfc7 Betfair Exchange (Optional)\", font=(\"Segoe UI\", 12, \"bold\"), bg='#1a1a2e', fg='#ffffff').pack(anchor=\"w\")\n        # ... Add Betfair configuration form ...\n\n    def _show_step_3(self):\n        tk.Label(self.content_frame, text=\"\u2713 Verifying Setup\", font=(\"Segoe UI\", 12, \"bold\"), bg='#1a1a2e', fg='#00ff88').pack(anchor=\"w\")\n        # ... Add verification checks logic ...\n\n    def _show_step_4(self):\n        tk.Label(self.content_frame, text=\"\ud83c\udf89 Setup Complete!\", font=(\"Segoe UI\", 14, \"bold\"), bg='#1a1a2e', fg='#00ff88').pack(pady=20)\n        self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n\n    def next_step(self):\n        if self.current_step < 3: self.show_step(self.current_step + 1)\n    def previous_step(self):\n        if self.current_step > 0: self.show_step(self.current_step - 1)\n    def finish_setup(self):\n        messagebox.showinfo(\"Setup Complete\", \"Your configuration has been saved.\")\n\n    def _clear_content(self):\n        for widget in self.content_frame.winfo_children(): widget.destroy()\n\n    def update_buttons(self):\n        self.prev_btn.config(state=tk.NORMAL if self.current_step > 0 else tk.DISABLED)\n        if self.current_step == 3:\n            self.next_btn.config(text=\"\u2713 Finish\", command=self.finish_setup)\n        else:\n            self.next_btn.config(text=\"Next >\", command=self.next_step)\n\n# --- System Tools Tab ---\nclass SystemToolsTab(tk.Frame):\n    def __init__(self, parent):\n        super().__init__(parent, bg='#1a1a2e')\n        self._create_ui()\n\n    def _create_ui(self):\n        title = tk.Label(self, text=\"\u2699\ufe0f System Tools\", font=(\"Segoe UI\", 16, \"bold\"), bg='#1a1a2e', fg='#ffffff')\n        title.pack(pady=20)\n        tk.Button(self, text=\"Create Desktop Shortcuts\", command=self.run_create_shortcuts, font=(\"Segoe UI\", 12)).pack(pady=10, padx=40, fill=tk.X)\n        tk.Button(self, text=\"Verify Installation\", command=self.run_verification, font=(\"Segoe UI\", 12)).pack(pady=10, padx=40, fill=tk.X)\n        self.output_box = scrolledtext.ScrolledText(self, height=10, bg=\"#0f3460\", fg=\"#ffffff\", state=tk.DISABLED)\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n    def log_output(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n\n    def run_create_shortcuts(self):\n        self.log_output(\"--- Creating Desktop Shortcut ---\")\n        try:\n            from win32com.client import Dispatch\n            desktop = Path(os.environ[\"USERPROFILE\"]) / \"Desktop\"\n            app_path = Path(__file__).resolve()\n            shortcut_path = desktop / \"\ud83d\udc34 Launch Fortuna Faucet.lnk\"\n\n            if shortcut_path.exists():\n                self.log_output(\"\ud83d\udfe1 Shortcut already exists. Overwriting.\")\n\n            shell = Dispatch(\"WScript.Shell\")\n            shortcut = shell.CreateShortCut(str(shortcut_path))\n            shortcut.TargetPath = sys.executable\n            shortcut.Arguments = f'\"{app_path}\"'\n            shortcut.WorkingDirectory = str(app_path.parent)\n\n            ico_path = app_path.parent / \"fortuna.ico\"\n            if ico_path.exists():\n                shortcut.IconLocation = str(ico_path)\n            else:\n                self.log_output(\"\ud83d\udfe1 Icon file not found, using default.\")\n\n            shortcut.save()\n            self.log_output(\"\u2705 Success: Shortcut created on Desktop.\")\n        except ImportError:\n            self.log_output(\"\u274c ERROR: 'pywin32' is not installed. Cannot create shortcuts.\")\n            self.log_output(\"  Please run: pip install pywin32\")\n        except Exception as e:\n            self.log_output(f\"\u274c ERROR: An unexpected error occurred: {e}\")\n\n    def run_verification(self):\n        self.log_output(\"\\n--- Verifying System Setup ---\")\n        verifications = [\n            (\"Python 3.11+\", lambda: sys.version_info >= (3, 11)),\n            (\"Python Virtual Env (.venv)\", lambda: Path(\".venv\").exists() and Path(\".venv/Scripts/python.exe\").exists()),\n            (\"Node.js (npm)\", lambda: subprocess.run(\"npm -v\", shell=True, capture_output=True).returncode == 0),\n            (\"Frontend Dependencies (node_modules)\", lambda: Path(\"web_platform/frontend/node_modules\").exists()),\n        ]\n\n        all_ok = True\n        for name, check in verifications:\n            result = check()\n            self.log_output(f\"- {name}: {'\u2705 OK' if result else '\u274c FAILED'}\")\n            if not result:\n                all_ok = False\n\n        if all_ok:\n            self.log_output(\"\\n\u2705 All checks passed. System is ready.\")\n        else:\n            self.log_output(\"\\n\u274c Some checks failed. Please review the log.\")\n\n# --- Main Application Window ---\nclass FortunaApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"\ud83d\udc34 Fortuna Faucet\")\n        self.geometry(\"700x550\")\n        self.configure(bg='#1a1a2e')\n\n        style = ttk.Style()\n        style.theme_use('clam')\n        style.configure(\"TNotebook\", background='#1a1a2e', borderwidth=0)\n        style.configure(\"TNotebook.Tab\", background=\"#404060\", foreground=\"#ffffff\", padding=[10, 5])\n        style.map(\"TNotebook.Tab\", background=[(\"selected\", \"#0f6cbd\")])\n\n        self.notebook = ttk.Notebook(self)\n\n        self.control_panel_tab = ControlPanelTab(self.notebook)\n        self.setup_wizard_tab = SetupWizardTab(self.notebook)\n        self.system_tools_tab = SystemToolsTab(self.notebook)\n\n        self.notebook.add(self.control_panel_tab, text='Control Panel')\n        self.notebook.add(self.setup_wizard_tab, text='Setup & Config')\n        self.notebook.add(self.system_tools_tab, text='System Tools')\n\n        self.notebook.pack(expand=True, fill='both', padx=10, pady=10)\n\n    def on_closing(self):\n        if self.control_panel_tab.backend_proc or self.control_panel_tab.frontend_proc:\n            if messagebox.askokcancel(\"Quit\", \"Services are still running. Do you want to stop them and exit?\"):\n                self.control_panel_tab.stop_services()\n                self.destroy()\n        else:\n            self.destroy()\n\n# --- NEW: Self-Setup UI and Logic ---\nclass SetupApp(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - First-Time Setup\")\n        self.geometry(\"700x500\")\n        self.configure(bg='#1a1a2e')\n\n        self.protocol(\"WM_DELETE_WINDOW\", self.quit)\n\n        header_font = tk.font.Font(family=\"Segoe UI\", size=16, weight=\"bold\")\n        body_font = tk.font.Font(family=\"Segoe UI\", size=10)\n        button_font = tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\")\n\n        tk.Label(self, text=\"\ud83d\udce6 Welcome to Fortuna Faucet\", font=header_font, bg='#1a1a2e', fg='#00ff88').pack(pady=(20, 10))\n        tk.Label(self, text=\"The necessary dependencies are not installed. Click 'Start Installation' to begin.\", font=body_font, bg='#1a1a2e', fg='#ffffff').pack(pady=(0, 20))\n\n        self.install_button = tk.Button(self, text=\"\u25b6\ufe0f Start Installation\", font=button_font, bg='#00ff88', fg='#000000', command=self.start_installation, relief=tk.FLAT, padx=20, pady=10)\n        self.install_button.pack(pady=10)\n\n        self.output_box = scrolledtext.ScrolledText(self, height=15, bg=\"#0f3460\", fg=\"#cccccc\", state=tk.DISABLED, relief=tk.FLAT, bd=0, padx=10, pady=10)\n        self.output_box.pack(pady=10, padx=40, fill=tk.BOTH, expand=True)\n\n        self.status_label = tk.Label(self, text=\"Waiting to start...\", font=body_font, bg='#1a1a2e', fg='#ffffff')\n        self.status_label.pack(pady=10)\n\n    def log(self, message):\n        self.output_box.config(state=tk.NORMAL)\n        self.output_box.insert(tk.END, message + \"\\n\")\n        self.output_box.config(state=tk.DISABLED)\n        self.output_box.see(tk.END)\n        self.update_idletasks()\n\n    def start_installation(self):\n        self.install_button.config(state=tk.DISABLED, text=\"Installation in progress...\")\n        self.log(\"--- Starting installation ---\")\n        self.status_label.config(text=\"Installing... Please be patient, this may take several minutes.\")\n        threading.Thread(target=self.run_install_commands, daemon=True).start()\n\n    def run_command(self, command):\n        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', errors='replace', shell=True)\n        for line in iter(process.stdout.readline, ''):\n            self.log(line.strip())\n        process.wait()\n        return process.returncode\n\n    def run_install_commands(self):\n        commands = [\n            (\"1/3: Creating Python virtual environment...\", f'{sys.executable} -m venv .venv'),\n            (\"2/3: Installing Python dependencies...\", '\\\"' + str(Path(\".venv/Scripts/python.exe\")) + '\\\" -m pip install -r requirements.txt'),\n            (\"3/3: Installing Node.js dependencies...\", 'npm install --prefix web_platform/frontend')\n        ]\n\n        for i, (msg, cmd) in enumerate(commands):\n            self.log(f'\\\\n--- STEP {msg} ---')\n            return_code = self.run_command(cmd)\n            if return_code != 0:\n                self.log(f'\\\\n--- ERROR: Step {i+1} failed with code {return_code}. ---')\n                self.status_label.config(text=\"Installation Failed. Please see log for details.\", fg=\"#ff4444\")\n                self.install_button.config(state=tk.NORMAL, text=\"Retry Installation\")\n                return\n\n        self.log(\"\\\\n--- \u2705 INSTALLATION COMPLETE! ---\")\n        self.status_label.config(text=\"Setup successful! You can now launch the application.\", fg=\"#00ff88\")\n        self.install_button.destroy()\n        launch_button = tk.Button(self, text=\"\ud83d\ude80 Launch Fortuna\", font=tk.font.Font(family=\"Segoe UI\", size=12, weight=\"bold\"), bg='#00ff88', fg='#000000', command=self.launch_app, relief=tk.FLAT, padx=20, pady=10)\n        launch_button.pack(pady=10)\n\n    def launch_app(self):\n        self.destroy()\n        # Relaunch the script to start the main app\n        subprocess.Popen([sys.executable, __file__])\n\n# --- NEW: Main Execution Block ---\nif __name__ == \"__main__\":\n    VENV_PATH = Path(__file__).parent / \".venv\"\n    if not VENV_PATH.exists() or not (VENV_PATH / \"Scripts\" / \"python.exe\").exists():\n        # If the virtual environment doesn't exist, run the setup wizard.\n        setup_app = SetupApp()\n        setup_app.mainloop()\n    else:\n        # Otherwise, run the main application.\n        app = FortunaApp()\n        app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n        app.mainloop()",
    "fortuna_monitor.py": "# fortuna_monitor.py - Windows-Optimized Version\n\nimport asyncio\nimport httpx\nimport tkinter as tk\nfrom tkinter import ttk, messagebox, filedialog\nfrom datetime import datetime\nimport os\nfrom collections import deque\nimport threading\nimport psutil\nimport sys\nimport time\n\n# Try to import matplotlib for graphs\ntry:\n    from matplotlib.figure import Figure\n    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n    GRAPHS_AVAILABLE = True\nexcept ImportError:\n    GRAPHS_AVAILABLE = False\n\nAPI_BASE_URL = \"http://localhost:8000\"\n\nclass PerformanceTracker:\n    def __init__(self, max_history=100):\n        self.timestamps = deque(maxlen=max_history)\n        self.race_counts = deque(maxlen=max_history)\n        self.fetch_durations = deque(maxlen=max_history)\n        self.success_rates = deque(maxlen=max_history)\n        self.cpu_usage = deque(maxlen=max_history)\n        self.memory_usage = deque(maxlen=max_history)\n\n    def add_datapoint(self, races, duration, success_rate):\n        self.timestamps.append(datetime.now())\n        self.race_counts.append(races)\n        self.fetch_durations.append(duration)\n        self.success_rates.append(success_rate)\n        self.cpu_usage.append(psutil.cpu_percent(interval=None))\n        process = psutil.Process(os.getpid())\n        self.memory_usage.append(process.memory_info().rss / 1024 / 1024) # MB\n\n    def export_to_csv(self, filename):\n        import csv\n        history = self.get_history()\n        with open(filename, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Timestamp', 'Races', 'Duration', 'Success Rate', 'CPU %', 'Memory MB'])\n            for i in range(len(history['times'])):\n                writer.writerow([\n                    history['times'][i].isoformat(),\n                    history['races'][i],\n                    history['durations'][i],\n                    history['success'][i],\n                    history['cpu'][i],\n                    history['memory'][i]\n                ])\n\n    def get_history(self):\n        return {\n            'times': list(self.timestamps),\n            'races': list(self.race_counts),\n            'durations': list(self.fetch_durations),\n            'success': list(self.success_rates),\n            'cpu': list(self.cpu_usage),\n            'memory': list(self.memory_usage)\n        }\n\nclass FortunaAdvancedMonitor(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - Advanced Monitor\")\n        self.geometry(\"900x650\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.performance = PerformanceTracker()\n        self.running = True\n        self._create_widgets()\n        self.after(100, self.start_fetch_thread)\n\n    def _create_widgets(self):\n        self._create_control_panel()\n        # ... (rest of the widget creation)\n\n    def _create_control_panel(self):\n        control_frame = tk.Frame(self, bg='#1a1a2e')\n        control_frame.pack(fill=tk.X, padx=15, pady=10)\n\n        tk.Button(\n            control_frame,\n            text=\"\ud83d\udcca Export Performance Data\",\n            command=self.export_data,\n            bg='#0f3460',\n            fg='#ffffff',\n            font=('Segoe UI', 10, 'bold'),\n            relief=tk.FLAT,\n            padx=25,\n            pady=10\n        ).pack(side=tk.LEFT, padx=5)\n\n        tk.Button(\n            control_frame,\n            text=\"\ud83d\udcbb System Info\",\n            command=self.show_system_info,\n            bg='#0f3460',\n            fg='#ffffff',\n            font=('Segoe UI', 10, 'bold'),\n            relief=tk.FLAT,\n            padx=25,\n            pady=10\n        ).pack(side=tk.LEFT, padx=5)\n\n    def start_fetch_thread(self):\n        self.fetch_thread = threading.Thread(target=self._fetch_data_loop, daemon=True)\n        self.fetch_thread.start()\n\n    def _fetch_data_loop(self):\n        while self.running:\n            try:\n                # Use httpx for async requests\n                with httpx.Client(headers={\"X-API-KEY\": self.api_key}, timeout=5) as client:\n                    response = client.get(f\"{API_BASE_URL}/api/adapters/status\")\n                if response.status_code == 200:\n                    data = response.json()\n                    # Add performance datapoint\n                    total_races = sum(a.get('races_fetched', 0) for a in data)\n                    successful_adapters = [a for a in data if a.get('status') == 'SUCCESS']\n                    success_rate = (len(successful_adapters) / len(data) * 100) if data else 0\n                    avg_duration = sum(a.get('fetch_duration', 0) for a in successful_adapters) / len(successful_adapters) if successful_adapters else 0\n                    self.performance.add_datapoint(total_races, avg_duration, success_rate)\n\n                    self.after(0, self.update_ui, data)\n            except httpx.RequestError:\n                pass\n            time.sleep(10) # Refresh interval\n\n    def update_ui(self, data):\n        # This is where you would update the tkinter UI with the new data\n        # For example, you might update a treeview or a graph\n        pass\n\n    def export_data(self):\n        filename = filedialog.asksaveasfilename(\n            defaultextension=\".csv\",\n            filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")],\n            initialfile=f\"fortuna_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n        )\n        if filename:\n            try:\n                self.performance.export_to_csv(filename)\n                messagebox.showinfo(\"Success\", f\"Data exported to {filename}\")\n            except Exception as e:\n                messagebox.showerror(\"Error\", f\"Export failed: {e}\")\n\n    def show_system_info(self):\n        vm = psutil.virtual_memory()\n        info = f\"\"\"\nSystem Information:\n\nCPU Usage: {psutil.cpu_percent(interval=1)}%\nCPU Cores: {psutil.cpu_count()}\nMemory Total: {vm.total / 1024 / 1024 / 1024:.2f} GB\nMemory Available: {vm.available / 1024 / 1024 / 1024:.2f} GB\nMemory Used: {vm.percent}%\n\nDisk Usage: {psutil.disk_usage('/').percent}%\nPython Version: {sys.version.split()[0]}\n\"\"\"\n        messagebox.showinfo(\"System Information\", info)\n\n    def on_closing(self):\n        self.running = False\n        self.destroy()\n\nif __name__ == '__main__':\n    # Load .env variables\n    try:\n        from dotenv import load_dotenv\n        load_dotenv()\n    except ImportError:\n        print(\"Warning: dotenv is not installed. Script assumes environment variables are set.\")\n    app = FortunaAdvancedMonitor()\n    app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n    app.mainloop()",
    "launcher.ps1": "<#\n.SYNOPSIS\n    Launches the Fortuna Faucet System Tray application.\n#>\n\nWrite-Host \"\ud83d\ude80 Launching Fortuna Faucet in System Tray...\" -ForegroundColor Cyan\n\n$VenvPath = \".\\\\.venv\\\\Scripts\\\\pythonw.exe\"\n$TrayAppPath = \".\\\\fortuna_tray.py\"\n\nif (-not (Test-Path $VenvPath)) {\n    Write-Host \"\u274c ERROR: Virtual environment not found at $VenvPath\" -ForegroundColor Red\n    Write-Host \"Please run INSTALL_FORTUNA.bat first.\"\n    Read-Host \"Press Enter to exit\"\n    exit 1\n}\n\nStart-Process -FilePath $VenvPath -ArgumentList $TrayAppPath -WindowStyle Hidden\n\nWrite-Host \"\u2705 Fortuna Faucet is now running in your system tray.\" -ForegroundColor Green\nWrite-Host \"Right-click the icon for options.\"\nStart-Sleep -Seconds 5\n",
    "manual_override_tool.py": "import argparse\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Manual Override Tool for Checkmate Data Warehouse.\")\n    parser.add_argument(\"--file\", required=True, help=\"Path to the CSV file for ingestion.\")\n    parser.add_argument(\"--user\", required=True, help=\"The user ID performing the override.\")\n    args = parser.parse_args()\n\n    print(f\"Executing manual override by '{args.user}' for file '{args.file}'...\")\n\n    # 1. Connect to PostgreSQL\n    # engine = create_engine('postgresql://user:password@host:port/database')\n\n    # 2. Read and validate the CSV data\n    # race_df = pd.read_csv(args.file)\n    # ... validation logic ...\n\n    # 3. Add the manual_override_by column\n    # race_df['manual_override_by'] = args.user\n\n    # 4. Insert data into the 'historical_races' table\n    # race_df.to_sql('historical_races', engine, if_exists='append', index=False)\n\n    print(\"Manual override completed successfully.\")\n\nif __name__ == \"__main__\":\n    main()",
    "pyproject.toml": "[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"paddock-parser-ng\"\nversion = \"0.1.0\"\ndescription = \"A toolkit to identify the best racecards for betting.\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\n\n[project.scripts]\npaddock_parser_ui = \"paddock_parser.entry_points:run_terminal_ui\"\npaddock_parser_dashboard = \"paddock_parser.entry_points:run_dashboard\"\npaddock_parser_predict = \"paddock_parser.entry_points:run_prediction_engine\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n\n# Configuration for the Ruff linter\n[tool.ruff]\n# Allow lines to be up to 120 characters long.\nline-length = 120\n\n[tool.ruff.lint]\n# Enable Pyflakes (F), pycodestyle (E, W), and isort (I) rules.\nselect = [\"E\", \"F\", \"W\", \"I\"]\nignore = []\n\n[tool.ruff.lint.isort]\n# Sort imports within their sections alphabetically.\nforce-single-line = true\n",
    "pytest.ini": "[pytest]\npythonpath = python_service\nnorecursedirs = attic tests/checkmate_v7\ntestpaths = tests/adapters tests/api tests/database tests/ui tests/utils tests/test_backtester.py tests/test_fetcher.py tests/test_forager_client.py tests/test_log_analyzer.py tests/test_merger.py tests/test_pipeline.py tests/test_python_service.py tests/test_scorer.py tests/test_api.py tests/test_legacy_scenarios.py\n",
    "requirements.txt": "# Fortuna Faucet - Master Dependency List\n\n# --- Core Backend (FastAPI & Async) ---\naiosqlite==0.21.0\nkeyring==25.6.0\ntenacity==9.1.2\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.2\npydantic-settings==2.1.0\nhttpx[http2]==0.27.0\nslowapi==0.1.9\nstructlog==24.1.0\npython-dotenv==1.0.0\n\n# --- Data Processing & Utilities ---\npandas==2.1.3\nbeautifulsoup4==4.12.2\nselectolax==0.4.0\npsutil==7.1.1\nlxml==5.1.0\n\n# --- Caching Layer ---\nredis==5.0.1\n\n# --- Windows Native Edition ---\npywin32==306; sys_platform == 'win32'\ncolorama==0.4.6; sys_platform == 'win32'\nwindows-toasts; sys_platform == 'win32'\nmatplotlib==3.8.2; sys_platform == 'win32'\npystray==0.19.5; sys_platform == 'win32'\npillow==10.1.0; sys_platform == 'win32'\n\n# --- Data Warehouse & ETL (Optional) ---\nSQLAlchemy==2.0.23\npsycopg2-binary==2.9.9\n\n# --- Historical Data Parsing (ChartScraper) ---\npikepdf==8.13.0\ntabula-py==2.7.0\nrequests==2.31.0\n\n# --- Code Quality & Testing ---\nruff==0.1.6\npytest==8.3.2\nrespx==0.22.0\npytest-asyncio==1.2.0\n",
    "scripts/audit_rebranding.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Rebranding Audit Script\n# ==============================================================================\n# This script performs a comprehensive, read-only audit of the project to\n# identify all files containing legacy branding terms.\n# ==============================================================================\n\nimport os\n\n# --- CONFIGURATION ---\nTARGET_TERMS = ['checkmate', 'solo']\nEXCLUDED_DIRS = ['.git', '.venv', 'node_modules', 'build', 'dist', '__pycache__', 'ReviewableJSON']\nEXCLUDED_FILES = ['audit_rebranding.py', 'REBRANDING_AUDIT.md']\nOUTPUT_FILE = 'REBRANDING_AUDIT.md'\n# -------------------\n\ndef search_file_for_terms(file_path, terms):\n    \"\"\"Searches a single file for a list of terms, case-insensitively.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read().lower()\n            for term in terms:\n                if term in content:\n                    return True\n    except Exception as e:\n        print(f\"[WARNING] Could not read file {file_path}: {e}\")\n    return False\n\ndef main():\n    \"\"\"Main orchestrator for the audit.\"\"\"\n    print(\"--- Starting Rebranding Audit ---\")\n    affected_files = []\n    for root, dirs, files in os.walk('.', topdown=True):\n        # Exclude specified directories\n        dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS]\n\n        for filename in files:\n            if filename in EXCLUDED_FILES:\n                continue\n\n            file_path = os.path.join(root, filename)\n\n            # Check filename itself\n            if any(term in filename.lower() for term in TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in filename: {file_path}\")\n                continue # No need to search content if filename matches\n\n            # Check file content\n            if search_file_for_terms(file_path, TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in content: {file_path}\")\n\n    print(f\"\\n--- Audit Complete. Found {len(affected_files)} affected files. ---\")\n\n    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n        f.write('# Fortuna Faucet: Rebranding Audit Report\\n\\n')\n        f.write('This report lists all files containing legacy branding terms (`checkmate`, `solo`).\\n\\n---\\n\\n')\n        if affected_files:\n            for file_path in sorted(affected_files):\n                f.write(f\"- `{file_path.replace(os.sep, '/')}`\\n\")\n        else:\n            f.write('No files with legacy branding were found.\\n')\n\n    print(f\"[SUCCESS] Report written to {OUTPUT_FILE}\")\n\nif __name__ == \"__main__\":\n    main()",
    "scripts/build_msi.ps1": "# Comprehensive MSI build pipeline for Fortuna Faucet\n# Version 2.0 - ASCII-safe and dynamically versioned.\n\nparam(\n    [ValidateSet(\"Debug\", \"Release\")]\n    [string]$Configuration = \"Release\",\n    [string]$Version = \"0.0.0\", # This will be overridden by VERSION.txt in the script\n    [string]$OutputPath = \".\\dist\"\n)\n\n$ErrorActionPreference = \"Stop\"\n\n# --- ASCII-Safe Helper Functions ---\nfunction Write-Header {\n    $title = $args[0]\n    Write-Host (\"=\" * 70) -ForegroundColor Cyan\n    Write-Host $title -ForegroundColor Cyan\n    Write-Host (\"=\" * 70) -ForegroundColor Cyan\n}\nfunction Write-Success { Write-Host \"[SUCCESS] $($args[0])\" -ForegroundColor Green }\nfunction Write-Error { Write-Host \"[ERROR] $($args[0])\" -ForegroundColor Red }\nfunction Write-Info { Write-Host \"[INFO] $($args[0])\" -ForegroundColor Yellow }\n\n# ==================== PHASE 0: DYNAMIC CONFIGURATION ====================\nWrite-Header \"Phase 0: Loading Dynamic Configuration\"\n$AppVersion = (Get-Content -Path \".\\VERSION.txt\" -Raw).Trim()\nWrite-Success \"Application version loaded from VERSION.txt: $AppVersion\"\n\n# ==================== PHASE 1: PREREQUISITES ====================\nWrite-Header \"Phase 1: Checking Prerequisites\"\n\n# This script assumes it's running in an environment where WiX and other tools are in the PATH.\n# The GitHub Actions workflow handles this setup.\n@(\"git\", \"python\", \"heat.exe\", \"candle.exe\", \"light.exe\") | ForEach-Object {\n    if (-not (Get-Command $_ -ErrorAction SilentlyContinue)) {\n        Write-Error \"$_ not found in PATH. Please ensure it is installed and accessible.\"\n        exit 1\n    }\n    Write-Success \"$_ found in PATH.\"\n}\n\n# ==================== PHASE 2: FILE HARVESTING ====================\nWrite-Header \"Phase 2: Harvesting File Structure\"\n$buildDir = \".\\wix_build\"\nif (Test-Path $buildDir) { Remove-Item $buildDir -Recurse -Force }\nNew-Item -ItemType Directory -Path $buildDir -Force | Out-Null\n\nWrite-Info \"Harvesting backend files...\"\n& heat.exe dir \".\\python_service\" -o \"$buildDir\\backend_files.wxs\" `\n    -gg -sf -srd -cg BackendFileGroup -dr INSTALLFOLDER -var \"var.BackendSourceDir\"\n\nWrite-Info \"Harvesting frontend files...\"\n& heat.exe dir \".\\web_platform\\frontend\\out\" -o \"$buildDir\\frontend_files.wxs\" `\n    -gg -sf -srd -cg FrontendFileGroup -dr INSTALLFOLDER -var \"var.FrontendSourceDir\"\n\nWrite-Info \"Verifying Python virtual environment...\"\nif (-not (Test-Path \".\\.venv\")) {\n    Write-Error \"Python virtual environment not found at '.\\.venv'.\"\n    Write-Error \"Please run the initial setup script to create the environment before building the MSI.\"\n    exit 1\n}\nWrite-Success \"Python virtual environment found.\"\n\nWrite-Info \"Harvesting Python environment files...\"\n& heat.exe dir \".\\.venv\" -o \"$buildDir\\venv_files.wxs\" `\n    -gg -sf -srd -cg VenvFileGroup -dr INSTALLFOLDER -var \"var.VenvSourceDir\"\n\nWrite-Success \"File harvesting complete.\"\n\n# ==================== PHASE 3: COMPILATION ====================\nWrite-Header \"Phase 3: Compiling WiX Sources\"\n$objDir = \"$buildDir\\obj\"\nNew-Item -ItemType Directory -Path $objDir -Force | Out-Null\nCopy-Item \".\\wix\\*.wxs\" \"$buildDir\"\n\n@(\"$buildDir\\product.wxs\", \"$buildDir\\WixUI_CustomInstallDir.wxs\", \"$buildDir\\WixUI_CustomProgress.wxs\", \"$buildDir\\backend_files.wxs\", \"$buildDir\\frontend_files.wxs\", \"$buildDir\\venv_files.wxs\") | ForEach-Object {\n    Write-Info \"Compiling $(Split-Path $_ -Leaf)...\"\n    & candle.exe $_ -o \"$objDir\\\" `\n        -ext WixUtilExtension `\n        -d\"BackendSourceDir=.\\python_service\" `\n        -d\"FrontendSourceDir=.\\web_platform\\frontend\\out\" `\n        -d\"VenvSourceDir=.\\.venv\" `\n        -dVersion=\"$AppVersion\" `\n        -arch x64\n    if ($LASTEXITCODE -ne 0) { throw \"Compilation failed for $_\" }\n}\nWrite-Success \"Compilation complete.\"\n\n# ==================== PHASE 4: LINKING ====================\nWrite-Header \"Phase 4: Linking MSI Package\"\nNew-Item -ItemType Directory -Path $OutputPath -Force | Out-Null\n$msiPath = \"$OutputPath\\Fortuna-Faucet-$AppVersion-x64.msi\"\n\nWrite-Info \"Linking objects into MSI...\"\n& light.exe -out $msiPath (Get-ChildItem \"$objDir\\*.wixobj\") `\n    -sw1076 `\n    -ext WixUIExtension -ext WixUtilExtension `\n    -cultures:en-us -b $buildDir\n\nif ($LASTEXITCODE -ne 0) { throw \"MSI linking failed\" }\n\n$fileSize = (Get-Item $msiPath).Length / 1MB\nWrite-Success \"MSI created: $msiPath ($($fileSize.ToString('F2')) MB)\"\n\n# ==================== PHASE 5: METADATA ====================\nWrite-Header \"Phase 5: Generating Installation Metadata\"\n$metadata = @{\n    Version = $AppVersion\n    BuildDate = (Get-Date -Format \"yyyy-MM-dd HH:mm:ss\")\n    Configuration = $Configuration\n    FileSize_MB = [math]::Round($fileSize, 2)\n    SHA256 = (Get-FileHash $msiPath -Algorithm SHA256).Hash\n    Requirements = @{\n        Windows = \"Windows 7 SP1 or later (64-bit)\"\n        AdminRights = $true\n        DiskSpace_GB = 2\n        RAM_GB = 4\n    }\n} | ConvertTo-Json -Depth 5\n\n$metadata | Out-File \"$OutputPath\\metadata.json\" -Encoding UTF8\nWrite-Success \"Metadata saved.\"\n\nWrite-Host \"\"\nWrite-Header \"Build Complete\"\nWrite-Success \"Ready for distribution!\"\nWrite-Info \"MSI: $msiPath\"\nWrite-Info \"Metadata: $OutputPath\\metadata.json\"\n",
    "scripts/convert_to_json.py": "# convert_to_json.py\n# This script now contains the full, enlightened logic to handle all manifest formats and path styles.\n\nimport json\nimport os\nimport re\nimport sys\nfrom multiprocessing import Process, Queue\n\n# --- Configuration ---\nMANIFEST_FILES = ['MANIFEST2.md', 'MANIFEST3.md']\nOUTPUT_DIR = 'ReviewableJSON'\nFILE_PROCESSING_TIMEOUT = 10\nEXCLUDED_FILES = ['package-lock.json']\n\n# --- ENLIGHTENED PARSING LOGIC (V2) ---\ndef extract_and_normalize_path(line: str) -> str | None:\n    \"\"\"\n    Extracts a file path from a line, handling multiple formats, and normalizes it.\n    Handles:\n    - Markdown links: `* [display](path)`\n    - Plain paths in backticks: ``- `path.py` - description``\n    - Plain paths with list markers: `- path/to/file.py`\n    \"\"\"\n    line = line.strip()\n    if not line or line.startswith('#'):\n        return None\n\n    # 1. Check for Markdown link format\n    md_match = re.search(r'\\[.*\\]\\((https?://[^\\)]+)\\)', line)\n    if md_match:\n        path = md_match.group(1)\n    else:\n        # 2. Check for paths in backticks\n        bt_match = re.search(r'`([^`]+)`', line)\n        if bt_match:\n            path = bt_match.group(1)\n        else:\n            # 3. Assume plain path, stripping list markers\n            path = re.sub(r'^[*-]\\s*', '', line).split(' ')[0]\n\n    # --- Path Standardization ---\n    if not path or not ('.' in path or '/' in path):\n        return None # Not a valid path\n\n    # If it's a full raw GitHub URL, extract the local path\n    if path.startswith('https://raw.githubusercontent.com/'):\n        path = '/'.join(path.split('/main/')[1:])\n\n    # Final check for valid file extensions or structure\n    if not re.search(r'(\\.[a-zA-Z0-9]+$)|(^[\\w/]+$)', path):\n        return None\n\n    return path.strip()\n\n# --- SANDBOXED FILE READ (Unchanged) ---\ndef _sandboxed_file_read(file_path, q):\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n        q.put({\"file_path\": file_path, \"content\": content})\n    except Exception as e:\n        q.put({\"error\": str(e)})\n\ndef convert_file_to_json_sandboxed(file_path):\n    q = Queue()\n    p = Process(target=_sandboxed_file_read, args=(file_path, q))\n    p.start()\n    p.join(timeout=FILE_PROCESSING_TIMEOUT)\n    if p.is_alive():\n        p.terminate()\n        p.join()\n        return {\"error\": f\"Timeout: File processing took longer than {FILE_PROCESSING_TIMEOUT} seconds.\"}\n    if not q.empty():\n        return q.get()\n    return {\"error\": \"Unknown error in sandboxed read process.\"}\n\n# --- Main Orchestrator ---\ndef main():\n    print(f\"\\n{'='*60}\\nStarting IRONCLAD JSON backup process... (Enlightened Scribe Edition)\\n{'='*60}\")\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    all_local_paths = []\n    for manifest in MANIFEST_FILES:\n        print(f\"--> Parsing manifest: {manifest}\")\n        if not os.path.exists(manifest):\n            print(f\"    [WARNING] Manifest not found: {manifest}\")\n            continue\n\n        with open(manifest, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n\n        paths_found = 0\n        for line in lines:\n            path = extract_and_normalize_path(line)\n            if path:\n                all_local_paths.append(path)\n                paths_found += 1\n        print(f\"    --> Found {paths_found} valid file paths.\")\n\n    if not all_local_paths:\n        print(\"\\n[FATAL] No valid file paths found in any manifest. Aborting.\")\n        sys.exit(1)\n\n    unique_local_paths = sorted(list(set(all_local_paths)))\n    print(f\"\\nFound a total of {len(unique_local_paths)} unique files to process.\")\n    processed_count, failed_count = 0, 0\n\n    for local_path in unique_local_paths:\n        print(f\"\\nProcessing: {local_path}\")\n        json_data = convert_file_to_json_sandboxed(local_path)\n        if json_data and \"error\" not in json_data:\n            output_path = os.path.join(OUTPUT_DIR, local_path + '.json')\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n            with open(output_path, 'w', encoding='utf-8') as f:\n                json.dump(json_data, f, indent=4)\n            print(f\"    [SUCCESS] Saved backup to {output_path}\")\n            processed_count += 1\n        else:\n            error_msg = json_data.get(\"error\", \"Unknown error\") if json_data else \"File not found\"\n            print(f\"    [ERROR] Failed to process {local_path}: {error_msg}\")\n            failed_count += 1\n\n    print(f\"\\n{'='*60}\\nBackup process complete.\\nSuccessfully processed: {processed_count}/{len(unique_local_paths)}\\nFailed/Skipped: {failed_count}\\n{'='*60}\")\n\n    if failed_count > 0:\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()",
    "scripts/install_fortuna_gui.bat": "@echo off\nREM Interactive MSI installation with standard Windows UI\n\ntitle Fortuna Faucet Installation Wizard\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Administrator privileges required\n    echo Please right-click this file and select \"Run as Administrator\"\n    pause\n    exit /b 1\n)\n\nREM Assumes the MSI is in the 'dist' subfolder relative to the project root\nmsiexec.exe /i \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" /L*v \"%TEMP%\\fortuna_install.log\"\n\nif %errorlevel% equ 0 (\n    echo Installation completed successfully!\n    echo Access dashboard at: http://localhost:3000\n) else (\n    echo Installation failed. Log: %TEMP%\\fortuna_install.log\n)\npause",
    "scripts/install_fortuna_silent.bat": "@echo off\nREM Automated deployment (no UI, minimal interaction)\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\nREM Assumes the MSI is in the 'dist' subfolder relative to the project root\nmsiexec.exe /i \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" ^\n    /qn ^\n    /l*v \"%TEMP%\\fortuna_silent_install.log\" ^\n    /norestart ^\n    ALLUSERS=1 ^\n    INSTALLSCOPE=perMachine\n\nexit /b %errorlevel%",
    "scripts/repair_fortuna.bat": "@echo off\nREM Repair corrupted or missing files\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\necho Repairing Fortuna Faucet installation...\n\nREM /f flag performs repair. Assumes MSI is in the 'dist' folder.\nmsiexec.exe /f \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" ^\n    /qn ^\n    /l*v \"%TEMP%\\fortuna_repair.log\"\n\nif %errorlevel% equ 0 (\n    echo Repair completed successfully.\n) else (\n    echo Repair failed. Check log: %TEMP%\\fortuna_repair.log\n)\n\nexit /b %errorlevel%",
    "scripts/uninstall_fortuna.bat": "@echo off\nREM Complete removal of Fortuna Faucet\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\necho WARNING: This will remove Fortuna Faucet completely.\nset /p confirm=\"Are you sure? (y/N): \"\n\nif /i not \"%confirm%\"==\"y\" exit /b 0\n\nREM Find and remove MSI by UpgradeCode\nfor /f \"tokens=2 delims=\" %%A in ('wmic product where \"Name like 'Fortuna Faucet%%'\" get IdentifyingNumber /value') do (\n    for /f \"tokens=2 delims==\" %%B in (\"%%A\") do (\n        msiexec.exe /x %%B /qn /l*v \"%TEMP%\\fortuna_uninstall.log\"\n    )\n)\n\nREM Clean up directories\nif exist \"%PROGRAMFILES%\\Fortuna Faucet\" rmdir /s /q \"%PROGRAMFILES%\\Fortuna Faucet\" 2>nul\nif exist \"%APPDATA%\\Fortuna Faucet\" rmdir /s /q \"%APPDATA%\\Fortuna Faucet\" 2>nul\n\necho Uninstall complete.",
    "windows_service.py": "# windows_service.py\nimport win32serviceutil\nimport win32service\nimport win32event\nimport servicemanager\nimport socket\nimport sys\nimport os\nimport subprocess\nfrom pathlib import Path\n\nclass FortunaBackendService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaFaucetBackend\"\n    _svc_display_name_ = \"Fortuna Faucet Racing Analysis Service\"\n    _svc_description_ = \"Background service for continuous racing data monitoring.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.stop_event = win32event.CreateEvent(None, 0, 0, None)\n        self.backend_process = None\n        socket.setdefaulttimeout(60)\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        win32event.SetEvent(self.stop_event)\n        if self.backend_process:\n            self.backend_process.terminate()\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(servicemanager.EVENTLOG_INFORMATION_TYPE, servicemanager.PYS_SERVICE_STARTED, (self._svc_name_, ''))\n        self.main()\n\n    def main(self):\n        install_dir = Path(__file__).parent.resolve()\n        venv_python = install_dir / \".venv\" / \"Scripts\" / \"python.exe\"\n        api_module_dir = install_dir / \"python_service\"\n\n        env = os.environ.copy()\n        env_file = install_dir / \".env\"\n        if env_file.exists():\n            with open(env_file) as f:\n                for line in f:\n                    if '=' in line and not line.startswith('#'):\n                        key, value = line.strip().split('=', 1)\n                        env[key] = value.strip('\\\"')\n\n        self.backend_process = subprocess.Popen(\n            [str(venv_python), \"-m\", \"uvicorn\", \"api:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"],\n            cwd=str(api_module_dir),\n            env=env\n        )\n\n        win32event.WaitForSingleObject(self.stop_event, win32event.INFINITE)\n\nif __name__ == '__main__':\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaBackendService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaBackendService)\n",
    "wix/product.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\"\n     xmlns:WixUI=\"http://schemas.microsoft.com/wix/WixUIExtension\"\n     xmlns:util=\"http://schemas.microsoft.com/wix/UtilExtension\">\n\n  <Product\n    Id=\"*\"\n    Name=\"Fortuna Faucet - Racing Analysis Engine\"\n    Language=\"1033\"\n    Version=\"$(var.Version)\"\n    Manufacturer=\"Mason J0 Studios\"\n    UpgradeCode=\"12345678-1234-1234-1234-123456789012\">\n\n    <Package\n      InstallerVersion=\"200\"\n      Compressed=\"yes\"\n      InstallScope=\"perMachine\"\n      Platform=\"x64\"\n      Description=\"Horse racing analysis platform with Python backend and React frontend\"\n      Comments=\"Professional-grade installer\"/>\n\n    <Media Id=\"1\" Cabinet=\"fortuna.cab\" EmbedCab=\"yes\"/>\n\n    <Property Id=\"WIXUI_INSTALLDIR\" Value=\"INSTALLFOLDER\" />\n\n    <!-- Directory Structure -->\n    <Directory Id=\"TARGETDIR\" Name=\"SourceDir\">\n      <Directory Id=\"ProgramFiles64Folder\">\n        <Directory Id=\"INSTALLFOLDER\" Name=\"Fortuna Faucet\"/>\n      </Directory>\n      <Directory Id=\"ProgramMenuFolder\">\n        <Directory Id=\"ApplicationProgramsFolder\" Name=\"Fortuna Faucet\"/>\n      </Directory>\n    </Directory>\n\n    <!-- Features (What users can select) -->\n    <Feature Id=\"ProductFeature\" Title=\"Fortuna Faucet\" Level=\"1\">\n        <ComponentGroupRef Id=\"ProductComponents\"/>\n        <ComponentGroupRef Id=\"ShortcutsComponentGroup\"/>\n        <ComponentGroupRef Id=\"BackendFileGroup\"/>\n        <ComponentGroupRef Id=\"FrontendFileGroup\"/>\n        <ComponentGroupRef Id=\"VenvFileGroup\"/>\n    </Feature>\n\n    <!-- Components (Logical file groupings) -->\n    <ComponentGroup Id=\"ProductComponents\" Directory=\"INSTALLFOLDER\">\n      <Component Id=\"RegistryAndServiceComponent\" Guid=\"F25A1181-9943-4753-9095-585A826B6D21\">\n        <RegistryValue Root=\"HKLM\" Key=\"Software\\Fortuna Faucet\\Backend\" Name=\"Installed\" Type=\"integer\" Value=\"1\" />\n        <RegistryValue Root=\"HKLM\" Key=\"Software\\Fortuna Faucet\\Frontend\" Name=\"Installed\" Type=\"integer\" Value=\"1\" />\n        <RegistryValue Root=\"HKLM\" Key=\"Software\\Fortuna Faucet\" Name=\"Installed\" Type=\"integer\" Value=\"1\" KeyPath=\"yes\"/>\n        <ServiceInstall Id=\"FortunaService\" Name=\"FortunaFaucetBackend\" DisplayName=\"Fortuna Faucet Background Service\" Description=\"Continuous horse racing data monitoring engine\" Type=\"ownProcess\" Start=\"auto\" Account=\"LocalSystem\" ErrorControl=\"normal\"/>\n        <ServiceControl Id=\"StartService\" Name=\"FortunaFaucetBackend\" Start=\"install\" Stop=\"both\" Remove=\"uninstall\"/>\n      </Component>\n    </ComponentGroup>\n\n    <ComponentGroup Id=\"ShortcutsComponentGroup\" Directory=\"ApplicationProgramsFolder\">\n      <Component Id=\"DesktopShortcutsComponent\" Guid=\"*\">\n          <util:InternetShortcut Id=\"DashboardShortcut\" Name=\"Fortuna Faucet Dashboard\" Target=\"http://localhost:3000\"/>\n          <Shortcut Id=\"UninstallShortcut\" Name=\"Uninstall Fortuna Faucet\" Description=\"Remove this application\" Target=\"[SystemFolder]msiexec.exe\" Arguments=\"/x [ProductCode]\" Advertise=\"no\"/>\n          <RemoveFolder Id=\"ApplicationProgramsFolder\" On=\"uninstall\"/>\n          <RegistryValue Root=\"HKCU\" Key=\"Software\\Fortuna Faucet\" Name=\"Installed\" Type=\"integer\" Value=\"1\" KeyPath=\"yes\"/>\n      </Component>\n    </ComponentGroup>\n\n\n    <!-- UI Customization -->\n    <UI>\n      <UIRef Id=\"WixUI_InstallDir\" />\n      <Publish Dialog=\"WelcomeDlg\" Control=\"Next\" Event=\"NewDialog\" Value=\"InstallDirDlg\" Order=\"2\">1</Publish>\n      <Publish Dialog=\"InstallDirDlg\" Control=\"Back\" Event=\"NewDialog\" Value=\"WelcomeDlg\">1</Publish>\n    </UI>\n    <Property Id=\"WIXUI_INSTALLDIR\" Value=\"INSTALLFOLDER\" />\n    <UIRef Id=\"WixUI_Common\" />\n    <WixVariable Id=\"WixUILicenseRtf\" Value=\"electron\\assets\\license.rtf\"/>\n    <!-- The following two variables are for custom UI images. -->\n    <!-- To enable them, create the files and uncomment the lines. -->\n    <!-- <WixVariable Id=\"WixUIBannerBmp\" Value=\"electron\\assets\\banner.bmp\"/> -->\n    <!-- <WixVariable Id=\"WixUIDialogBmp\" Value=\"electron\\assets\\dialog.bmp\"/> -->\n\n    <!-- System Requirements -->\n    <Condition Message=\"Windows 7 or later (64-bit) is required\">\n      <![CDATA[Installed OR (VersionNT64 >= 601)]]>\n    </Condition>\n\n\n  </Product>\n</Wix>\n",
    ".github/workflows/build_msi.yml": "name: Build MSI Installer\n\non:\n  push:\n    branches: [main, develop]\n    tags: ['v*']\n  workflow_dispatch:\n\njobs:\n  build_msi:\n    runs-on: windows-latest\n\n    env:\n      CERT_BASE64_ENV: ${{ secrets.WINDOWS_SIGNING_CERT }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.12'\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n          cache-dependency-path: web_platform/frontend/package-lock.json\n\n      - name: Install Python dependencies\n        run: |\n          python -m venv .venv\n          .\\.venv\\Scripts\\Activate.ps1\n          pip install -r requirements.txt\n\n      - name: Cache Next.js build\n        uses: actions/cache@v4\n        with:\n          path: web_platform/frontend/.next/cache\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('web_platform/frontend/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-\n\n      - name: Build frontend\n        run: |\n          cd web_platform\\frontend\n          npm install\n          npm run build\n\n      - name: Install Code Signing Certificate\n        if: runner.os == 'Windows' && env.CERT_BASE64_ENV != ''\n        env:\n          CERT_BASE64: ${{ secrets.WINDOWS_SIGNING_CERT }}\n          CERT_PASSWORD: ${{ secrets.WINDOWS_SIGNING_PASSWORD }}\n        run: |\n          [System.IO.File]::WriteAllBytes(\"cert.pfx\", [System.Convert]::FromBase64String($env:CERT_BASE64))\n          certutil -p $env:CERT_PASSWORD -importpfx cert.pfx\n          Remove-Item cert.pfx\n\n      - name: Build MSI\n        run: |\n          $Version = \"${{ github.ref }}\".Replace('refs/tags/v', '')\n          if ($Version -eq \"refs/tags/v\" -or $Version -eq \"\") {\n            $Version = \"2.1.0-dev\"\n          }\n          powershell -ExecutionPolicy Bypass -File scripts/build_msi.ps1 -Version $Version -Configuration Release\n\n      - name: Generate checksums\n        run: |\n          Get-ChildItem dist/*.msi | ForEach-Object {\n            $hash = (Get-FileHash $_ -Algorithm SHA256).Hash\n            Add-Content -Path dist/CHECKSUMS.txt -Value \"$hash  $($_.Name)\"\n          }\n\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: fortuna-msi\n          path: |\n            dist/Fortuna-Faucet-*.msi\n            dist/metadata.json\n            dist/CHECKSUMS.txt\n\n      - name: Create release\n        if: startsWith(github.ref, 'refs/tags/')\n        uses: softprops/action-gh-release@v1\n        with:\n          files: |\n            dist/Fortuna-Faucet-*.msi\n            dist/metadata.json\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "wix/WixUI_CustomProgress.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\">\n  <Fragment>\n    <UI>\n      <!-- Override the default InstallProgress dialog -->\n      <Dialog Id=\"InstallProgressDlg\" Width=\"370\" Height=\"270\" Title=\"Fortuna Faucet Installation\" Modeless=\"yes\">\n        <Control Id=\"Title\" Type=\"Title\" X=\"20\" Y=\"6\" Width=\"330\" Height=\"18\" Text=\"Installation Progress\" />\n        <Control Id=\"BannerBitmap\" Type=\"Bitmap\" X=\"0\" Y=\"0\" Width=\"370\" Height=\"44\" TabSkip=\"no\" Text=\"WixUI_Bmp_Banner\" />\n        <Control Id=\"Back\" Type=\"PushButton\" X=\"180\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Back\" Disabled=\"yes\" />\n        <Control Id=\"Next\" Type=\"PushButton\" X=\"236\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Next\" Disabled=\"yes\" />\n        <Control Id=\"Cancel\" Type=\"PushButton\" X=\"304\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"Cancel\" />\n\n        <Control Id=\"ActionText\" Type=\"Text\" X=\"70\" Y=\"80\" Width=\"280\" Height=\"20\" TabSkip=\"no\">\n          <Subscribe Event=\"ActionText\" Attribute=\"Text\" />\n        </Control>\n        <Control Id=\"Description\" Type=\"Text\" X=\"35\" Y=\"55\" Width=\"300\" Height=\"20\" Text=\"Please wait while the installer copies files.\" />\n\n        <!-- This is the new control to display the current filename -->\n        <Control Id=\"CurrentFileText\" Type=\"Text\" X=\"70\" Y=\"100\" Width=\"280\" Height=\"20\">\n            <Subscribe Event=\"SetProgress\" Attribute=\"Text\" />\n        </Control>\n\n        <Control Id=\"ProgressBar\" Type=\"ProgressBar\" X=\"35\" Y=\"120\" Width=\"300\" Height=\"10\" ProgressBlocks=\"yes\" Text=\"Progress\">\n          <Subscribe Event=\"SetProgress\" Attribute=\"Progress\" />\n        </Control>\n      </Dialog>\n      <Publish Dialog=\"InstallProgressDlg\" Control=\"Cancel\" Event=\"SpawnDialog\" Value=\"CancelDlg\">1</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n"
}