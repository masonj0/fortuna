{
    ".github/dependabot.yml": "# System Timestamp: 2025-11-29 13:19:26.933797\n# To get started with Dependabot version updates, you'll need to specify which\n# package ecosystems to update and where the package manifests are located.\n# Please see the documentation for all configuration options:\n# https://docs.github.com/github/administering-a-repository/configuration-options-for-dependency-updates\n\nversion: 2\nupdates:\n  - package-ecosystem: \"pip\" # See documentation for possible values\n    directory: \"/\" # Location of package manifests\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/web_platform/frontend\"\n    schedule:\n      interval: \"daily\"\n\n  - package-ecosystem: \"npm\"\n    directory: \"/electron\"\n    schedule:\n      interval: \"daily\"\n",
    ".github/workflows/build-bundle.yml": "# System Timestamp: 2025-12-24 18:00:00\nname: \ud83d\ude80 Build Fortuna Faucet Bundle\non:\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  build-electron-msi:\n    uses: ./.github/workflows/build-electron-msi-gpt5.yml\n    secrets: inherit\n\n  build-web-service-msi:\n    uses: ./.github/workflows/build-msi-hattrickfusion-ultimate.yml\n    secrets: inherit\n\n  package-bundle:\n    name: '\ud83c\udf81 Package Final Bundle'\n    runs-on: windows-2022\n    needs: [build-electron-msi, build-web-service-msi]\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: '\ud83d\udce5 Download Electron MSI'\n        uses: actions/download-artifact@v4\n        with:\n          name: fortuna-msi-x64-${{ github.run_id }}\n          path: staging/electron\n\n      - name: '\ud83d\udce5 Download Web Service MSI'\n        uses: actions/download-artifact@v4\n        with:\n          name: msi-x64-${{ github.run_id }}\n          path: staging/service\n\n      - name: '\ud83c\udfd7\ufe0f Build Bundle'\n        shell: pwsh\n        run: |\n          $electronMsi = (Get-ChildItem -Path \"staging/electron\" -Filter \"*.msi\" -Recurse | Select-Object -First 1).FullName\n          $serviceMsi = (Get-ChildItem -Path \"staging/service\" -Filter \"*.msi\" -Recurse | Select-Object -First 1).FullName\n\n          wix build -o dist/FortunaFaucet-Setup.exe build_wix/Bundle.wxs `\n            -d WebServiceMsiPath=\"$serviceMsi\" `\n            -d ElectronAppMsiPath=\"$electronMsi\"\n\n      - name: '\ud83d\udce4 Upload Bundle'\n        uses: actions/upload-artifact@v4\n        with:\n          name: fortuna-bundle\n          path: dist/FortunaFaucet-Setup.exe\n",
    ".github/workflows/build-msi-revived.yml": "# System Timestamp: 2025-12-21 14:04:35\nname: \ud83e\udddf \ud83c\udfdb\ufe0f Fortuna Web Service MSI (The Veteran Reborn) - UNIFIED\n\non:\n  push:\n    branches: [\"main\"]\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.11'\n  DOTNET_VERSION: '8.0.x'\n  WIX_VERSION: '4.0.5'\n  SERVICE_PORT: '8102'\n  API_KEY: mock_key\n  TVG_API_KEY: mock\n  GREYHOUND_API_URL: http://mock\n  FORTUNA_ENV: smoke-test\n  FRONTEND_DIR: 'web_platform/frontend'\n  BACKEND_DIR: 'web_service/backend'\n  WIX_DIR: 'build_wix'\n\njobs:\n  build-frontend:\n    name: '\ud83c\udfa8 Build Frontend'\n    runs-on: windows-2022\n    timeout-minutes: 20\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: '${{ env.FRONTEND_DIR }}/package-lock.json'\n      - name: Install & Build\n        run: |\n          cd ${{ env.FRONTEND_DIR }}\n          npm ci --prefer-offline --no-audit\n          npm run build\n      - uses: actions/upload-artifact@v4\n        with:\n          name: frontend-dist-${{ github.run_id }}\n          path: ${{ env.FRONTEND_DIR }}/out\n\n  build-backend:\n    name: '\ud83d\udc0d Build Backend (${{ matrix.arch }})'\n    runs-on: windows-2022\n    needs: build-frontend\n    strategy:\n      matrix:\n        arch: [x64, x86]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/download-artifact@v4\n        with:\n          name: frontend-dist-${{ github.run_id }}\n          path: staging/ui\n      - name: \ud83d\udc0d Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          architecture: '${{ matrix.arch }}'\n          cache: 'pip'\n      - name: \ud83e\uddfe Create Architecture Constraints\n        id: constraints\n        shell: pwsh\n        run: |\n          $file = \"constraints.txt\"\n          if ('${{ matrix.arch }}' -eq 'x86') {\n            \"numpy==1.23.5`r`npandas==1.5.3`r`n--only-binary=:all:\" | Set-Content $file\n          } else {\n            New-Item $file -ItemType File -Force\n          }\n          \"file=$file\" | Out-File $env:GITHUB_OUTPUT -Append\n      - name: \ud83d\udce6 Install Dependencies & Build\n        shell: pwsh\n        run: |\n          python -m pip install --upgrade pip\n          pip install uv\n          uv pip install --system -r ${{ env.BACKEND_DIR }}/requirements.txt -c ${{ steps.constraints.outputs.file }}\n          uv pip install --system pyinstaller==6.6.0 pywin32\n          pyinstaller --noconfirm --clean --log-level INFO fortuna-unified.spec\n      - uses: actions/upload-artifact@v4\n        with:\n          name: backend-dist-${{ matrix.arch }}-${{ github.run_id }}\n          path: dist/fortuna-webservice/\n\n  preflight-check:\n    name: '\ud83d\udd0d Preflight Check'\n    runs-on: windows-2022\n    outputs:\n      semver: ${{ steps.git_version.outputs.semver }}\n    steps:\n      - uses: actions/checkout@v4\n      - name: '\ud83c\udff7\ufe0f Derive SemVer'\n        id: git_version\n        shell: pwsh\n        run: |\n          $semver = \"0.0.${{ github.run_number }}\"\n          \"semver=$semver\" | Out-File $env:GITHUB_OUTPUT -Encoding utf8 -Append\n\n  package-msi:\n    name: '\ud83d\udcbf Package MSI (${{ matrix.arch }})'\n    runs-on: windows-2022\n    needs: [build-backend, preflight-check]\n    strategy:\n      matrix:\n        arch: [x64, x86]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/download-artifact@v4\n        with:\n          name: backend-dist-${{ matrix.arch }}-${{ github.run_id }}\n          path: staging/backend\n      - uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: ${{ env.DOTNET_VERSION }}\n      - name: Prepare WiX Project\n        shell: pwsh\n        run: |\n          if (-not (Test-Path 'build_wix/license.rtf')) {\n             Set-Content -Path 'build_wix/license.rtf' -Value '{\\rtf1\\ansi Placeholder License}' -Encoding Ascii\n          }\n          Copy-Item \"build_wix/Product_WebService.wxs\" \"build_wix/Product.wxs\" -Force\n          $proj = @(\n            '<Project Sdk=\"WixToolset.Sdk/${{ env.WIX_VERSION }}\">',\n            '  <PropertyGroup>',\n            '    <EnableDefaultCompileItems>false</EnableDefaultCompileItems>',\n            '    <OutputType>Package</OutputType>',\n            '    <Platforms>x64;x86</Platforms>',\n            '    <DefineConstants>Version=$(Version);SourceDir=$(SourceDir);ServicePort=$(ServicePort);Platform=$(Platform)</DefineConstants>',\n            '  </PropertyGroup>',\n            '  <ItemGroup>',\n            '    <PackageReference Include=\"WixToolset.UI.wixext\" Version=\"${{ env.WIX_VERSION }}\" />',\n            '    <PackageReference Include=\"WixToolset.Firewall.wixext\" Version=\"${{ env.WIX_VERSION }}\" />',\n            '    <PackageReference Include=\"WixToolset.Util.wixext\" Version=\"${{ env.WIX_VERSION }}\" />',\n            '  </ItemGroup>',\n            '  <ItemGroup>',\n            '    <Compile Include=\"Product.wxs\" />',\n            '  </ItemGroup>',\n            '</Project>'\n          )\n          Set-Content \"${{ env.WIX_DIR }}/Fortuna.wixproj\" -Value ($proj -join \"`r`n\") -Encoding utf8\n      - name: Build MSI\n        working-directory: ${{ env.WIX_DIR }}\n        run: dotnet build Fortuna.wixproj -c Release -p:Platform=${{ matrix.arch }} -p:Version=\"${{ needs.preflight-check.outputs.semver }}\" -p:SourceDir=\"../staging/backend\" -p:ServicePort=\"${{ env.FORTUNA_PORT }}\"\n      - name: Rename & Hash\n        run: |\n          $releaseDir = \"${{ env.WIX_DIR }}/bin/${{ matrix.arch }}/Release\"\n          $msi = Get-ChildItem -Path $releaseDir -Filter \"*.msi\" | Select -First 1\n          $target = \"Revived-${{ matrix.arch }}-${{ needs.preflight-check.outputs.semver }}.msi\"\n          Move-Item $msi.FullName -Destination \"$releaseDir/$target\" -Force\n          $hash = (Get-FileHash \"$releaseDir/$target\" -Algorithm SHA256).Hash\n          Set-Content -Path \"$releaseDir/$target.sha256\" -Value $hash\n      - uses: actions/upload-artifact@v4\n        with:\n          name: msi-${{ matrix.arch }}-${{ github.run_id }}\n          path: |\n            ${{ env.WIX_DIR }}/bin/${{ matrix.arch }}/Release/*.msi\n            ${{ env.WIX_DIR }}/bin/${{ matrix.arch }}/Release/*.sha256\n\n  smoke-test:\n    name: '\ud83d\udd2c Smoke Test (${{ matrix.arch }})'\n    runs-on: windows-2022\n    needs: [package-msi]\n    strategy:\n      matrix:\n        arch: [x64, x86]\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: msi-${{ matrix.arch }}-${{ github.run_id }}\n          path: installer\n      - name: Install & Verify\n        shell: pwsh\n        run: |\n          $msi = (Get-ChildItem installer/*.msi | Select -First 1).FullName\n          if ($null -ne (Get-Service -Name \"FortunaWebService\" -ErrorAction SilentlyContinue)) { sc.exe delete \"FortunaWebService\" }\n          Start-Process msiexec.exe -ArgumentList \"/i `\"$msi`\" /qn /L*v install.log\" -Wait\n          $progFiles = if ('${{ matrix.arch }}' -eq 'x86') { ${env:ProgramFiles(x86)} } else { ${env:ProgramFiles} }\n          $installRoot = Join-Path $progFiles \"Fortuna Faucet Service\"\n          New-Item -Path \"$installRoot\\data\", \"$installRoot\\json\", \"$installRoot\\logs\" -ItemType Directory -Force | Out-Null\n          Start-Service \"FortunaWebService\"\n          Start-Sleep 15\n          $response = Invoke-WebRequest -Uri \"http://localhost:${{ env.SERVICE_PORT }}/health\" -UseBasicParsing\n          if ($response.StatusCode -ne 200) { throw \"Service health check failed.\" }\n      - name: Cleanup\n        if: always()\n        run: sc.exe delete \"FortunaWebService\" 2>$null\n",
    ".github/workflows/test-quickstart.yml": "name: \ud83e\uddea Backend CI & Quick-Start Test\n\non:\n  workflow_dispatch:\n  push:\n    branches: [\"main\"]\n\njobs:\n  test-bootstrapper:\n    name: '\ud83c\udfc3 Run Quick-Start PS1'\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: \ud83d\udc0d Setup Python\n        id: setup-python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n\n      - name: \ud83d\udfe2 Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n          cache-dependency-path: web_platform/frontend/package-lock.json\n\n      - name: \ud83d\udce6 Install Python Dependencies\n        shell: pwsh\n        run: |\n          pip install --upgrade pip\n          pip install -r web_service/backend/requirements.txt\n          pip install -r web_service/backend/requirements-dev.txt\n\n      - name: \ud83e\uddea Run Backend Unit Tests\n        shell: pwsh\n        run: |\n          $env:PYTHONPATH = \"$env:PYTHONPATH;${env:GITHUB_WORKSPACE}/web_service/backend\"\n          python -m pytest web_service/backend/tests/\n\n      - name: \ud83d\udd0d Syntax Validation\n        shell: pwsh\n        run: |\n          try {\n            $script = Get-Content \"scripts/fortuna-quick-start.ps1\" -Raw\n            [void][System.Management.Automation.PSParser]::Tokenize($script, [ref]$null)\n            Write-Host \"\u2705 PowerShell Syntax is valid.\"\n          } catch {\n            Write-Error \"\u274c Syntax Error: $_\"\n            exit 1\n          }\n\n      - name: \ud83d\ude80 Execute Bootstrapper\n        shell: pwsh\n        run: |\n          # Explicitly add the Python directory to the PATH for the script's environment.\n          # This is necessary because the script may not inherit the PATH set by setup-python.\n          $pythonDir = Split-Path -Parent \"${{ steps.setup-python.outputs.python-path }}\"\n          $pythonScriptsDir = Join-Path $pythonDir \"Scripts\"\n          $env:PATH = \"$pythonDir;$pythonScriptsDir;$($env:PATH)\"\n          Write-Host \"Ensured Python is on PATH for the script.\"\n\n          Write-Host \"Starting script in CI mode...\"\n          # Run with -Clean to test dependency installation\n          # Run with -NoFrontend to focus on Backend health first\n          # *>&1 combines stdout/stderr, Tee-Object saves to file AND shows in console\n          ./scripts/fortuna-quick-start.ps1 -Clean -NoFrontend *>&1 | Tee-Object -FilePath \"bootstrapper_log.txt\"\n\n      - name: \ud83d\udce4 Upload Debug Logs\n        if: always() # CRITICAL: Run this even if the bootstrapper crashes\n        uses: actions/upload-artifact@v4\n        with:\n          name: quickstart-debug-logs\n          path: |\n            bootstrapper_log.txt\n            web_service/backend/*.log\n            web_service/backend/logs/*.log\n\n      - name: \ud83e\ude7a Verify Backend Health\n        shell: pwsh\n        run: |\n          $url = \"http://127.0.0.1:8000/docs\"\n          Write-Host \"\u23f3 Waiting for Backend at $url...\"\n\n          # Give it up to 60 seconds to install deps and start\n          for ($i=0; $i -lt 20; $i++) {\n            try {\n              $resp = Invoke-WebRequest -Uri $url -UseBasicParsing -TimeoutSec 2\n              if ($resp.StatusCode -eq 200) {\n                Write-Host \"\u2705 Backend is UP and responding! The script works.\"\n                return\n              }\n            } catch {\n              Write-Host \"... ping failed, retrying ($i/20)\"\n              Start-Sleep -Seconds 3\n            }\n          }\n          throw \"\u274c Backend failed to start within timeout.\"\n\n      - name: \ud83e\uddf9 Cleanup\n        if: always()\n        shell: pwsh\n        run: |\n          # The script spawns 'pwsh' and 'python' processes. Kill them.\n          Stop-Process -Name \"uvicorn\", \"python\", \"pwsh\" -Force -ErrorAction SilentlyContinue\n          Write-Host \"\u2705 Cleanup complete.\"",
    "PSEUDOCODE.MD": "# \ud83d\udc0e Fortuna Faucet - Complete Pseudocode Blueprint\n\n**Status:** Comprehensive System Specification (Revised & Corrected)\n**Version:** 2.2.0\n**Last Updated:** November 7, 2025\n\n---\n\n## TABLE OF CONTENTS\n\n1.  System Overview\n2.  Architecture Pillars\n3.  Backend Engine (Python) - Detailed\n4.  Frontend Interface (TypeScript/React) - Detailed\n5.  Electron Wrapper & Windows Integration - Detailed\n6.  Data Models & API Specification\n7.  Deployment & Automation (CI/CD)\n8.  End-to-End Workflows\n\n---\n\n## 1. SYSTEM OVERVIEW\n\n```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551         FORTUNA FAUCET - Racing Analysis Platform             \u2551\n\u2551  Unifying global horse/greyhound/harness racing intelligence   \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nMISSION:\n  \u2022 Acquire race data from 20+ global sources (APIs + web scraping).\n  \u2022 Normalize and deduplicate data into a canonical Race format.\n  \u2022 Apply analytical filters to surface high-value betting opportunities.\n  \u2022 Serve results via a secure, local REST API to an interactive dashboard.\n  \u2022 Operate as a professional, standalone, native Windows application.\n\nCORE TENETS:\n  \u2022 UI-First Experience: The user interface is always responsive, even during backend startup or restarts.\n  \u2022 Resilient Process Management: The backend executable's lifecycle is robustly managed, with timeouts and crash detection.\n  \u2022 Asynchronous Initialization: The backend server starts instantly, deferring heavy, blocking I/O to background threads.\n  \u2022 Secure by Design: Communication between the frontend and the privileged main process is secured via a context-aware preload script.\n  \u2022 Automated & Repeatable Builds: The entire application is built, tested, and packaged via a deterministic CI/CD pipeline.\n\nSTAKEHOLDERS:\n  \u2022 End User: Receives a professional MSI installer for a one-click, dependency-free launch.\n  \u2022 Developer: Works with clean, separated Python and TypeScript stacks, governed by this specification.\n```\n\n---\n\n## 2. ARCHITECTURE PILLARS\n\n### Pillar 1: Backend Engine (Python)\n\n```\nPYTHON_BACKEND:\n  \u251c\u2500 main.py\n  \u2502  \u2514\u2500 Entry point for PyInstaller executable; starts the Uvicorn server.\n  \u2502\n  \u251c\u2500 api.py\n  \u2502  \u2514\u2500 FastAPI application definition.\n  \u2502     \u251c\u2500 Lifespan Hook: Manages async startup/shutdown logic.\n  \u2502     \u251c\u2500 API Routes: /health, /api/status, /api/races, etc.\n  \u2502     \u2514\u2500 Dependency Injection: Provides engine and security dependencies.\n  \u2502\n  \u251c\u2500 engine.py\n  \u2502  \u2514\u2500 OddsEngine: Orchestrates all data fetching and processing.\n  \u2502\n  \u251c\u2500 adapters/\n  \u2502  \u251c\u2500 base_v3.py (Abstract Base Class for all data sources)\n  \u2502  \u2514\u2500 [20+ specific adapter implementations]\n  \u2502\n  \u251c\u2500 config.py\n  \u2502  \u2514\u2500 Pydantic settings management from .env file.\n  \u2502\n  \u2514\u2500 requirements.txt\n     \u2514\u2500 Clean, de-duplicated, and conflict-free list of all Python dependencies.\n```\n\n### Pillar 2: Frontend Interface (TypeScript/React)\n\n```\nFRONTEND:\n  \u251c\u2500 next.config.mjs\n  \u2502  \u2514\u2500 Next.js config with `output: 'export'` for 100% static generation.\n  \u2502\n  \u251c\u2500 app/page.tsx\n  \u2502  \u2514\u2500 Main application shell.\n  \u2502\n  \u251c\u2500 src/components/\n  \u2502  \u251c\u2500 LiveRaceDashboard.tsx (Main stateful component)\n  \u2502  \u2502  \u251c\u2500 Manages connection state ('connecting', 'online', 'error').\n  \u2502  \u2502  \u251c\u2500 Polls Electron main process for backend status via secure IPC.\n  \u2502  \u2502  \u2514\u2500 Fetches data from the local Python API when online.\n  \u2502  \u2502\n  \u2502  \u251c\u2500 RaceCard.tsx (Displays a single race)\n  \u2502  \u2514\u2500 StatusIndicator.tsx (Shows backend connection status)\n  \u2502\n  \u2514\u2500 src/types/\n     \u2514\u2500 racing.ts (TypeScript interfaces matching backend Pydantic models)\n```\n\n### Pillar 3: Electron Wrapper & Windows Integration\n\n```\nELECTRON_WRAPPER:\n  \u251c\u2500 main.js (Electron main process)\n  \u2502  \u251c\u2500 Creates the BrowserWindow and loads the static frontend.\n  \u2502  \u251c\u2500 Implements robust lifecycle management for the backend executable.\n  \u2502  \u251c\u2500 Provides secure IPC handlers for status checks and restarts.\n  \u2502  \u2514\u2500 Creates a system tray icon for background operation.\n  \u2502\n  \u251c\u2500 preload.js (Secure IPC Bridge)\n  \u2502  \u2514\u2500 Uses `contextBridge` to safely expose specific functions to the frontend.\n  \u2502\n  \u251c\u2500 package.json\n  \u2502  \u2514\u2500 Defines Node.js dependencies and build scripts.\n  \u2502\n  \u251c\u2500 electron-builder-config.yml\n  \u2502  \u2514\u2500 Defines the configuration for creating the final MSI installer.\n  \u2502\n  \u2514\u2500 .github/workflows/build-msi.yml\n     \u2514\u2500 GitHub Actions pipeline that automates the entire build, test, and package process.\n```\n\n---\n\n## 3. BACKEND ENGINE (PYTHON) - DETAILED\n\n### 3.1 Entry Point & Server Startup (`main.py`)\n\n```pseudocode\n// This is the script executed by fortuna-backend.exe\n\nPROCEDURE Main_Python_Entry_Point\n  // Guard required for PyInstaller and multiprocessing on Windows\n  IF this script is the main entry point:\n    CALL multiprocessing.freeze_support()\n\n    // Programmatically launch the FastAPI application using Uvicorn\n    // This call blocks and runs the server until the process is terminated\n    CALL uvicorn.run(\n      app=\"python_service.api:app\",\n      host=\"0.0.0.0\",\n      port=8000\n    )\nEND PROCEDURE\n```\n\n### 3.2 Asynchronous Application Lifecycle (`api.py`)\n\n```pseudocode\n// --- Lifespan Management (The key to a non-blocking startup) ---\nASYNC FUNCTION lifespan_manager(app: FastAPI):\n  // === ON STARTUP ===\n  LOG \"Uvicorn server is online. Starting lifespan initialization.\"\n\n  // 1. Perform immediate, non-blocking tasks\n  CONNECT to Redis cache\n\n  // 2. Defer slow, blocking tasks to a background thread\n  //    This allows the server to start accepting requests instantly.\n  SCHEDULE function \"initialize_heavy_resources(app)\" to run in a ThreadPoolExecutor\n\n  LOG \"Heavy resource initialization scheduled. Server is now responsive.\"\n\n  // 3. Yield control back to Uvicorn. The server is now live.\n  YIELD\n\n  // === ON SHUTDOWN ===\n  LOG \"Shutdown signal received.\"\n  AWAIT app.state.engine.close() // Gracefully close HTTP client connections\n  DISCONNECT from Redis\n  SHUTDOWN ThreadPoolExecutor\n\n// --- Heavy Initialization (Runs in Background) ---\nFUNCTION initialize_heavy_resources(app: FastAPI):\n  TRY\n    LOG \"Background initialization of OddsEngine has started.\"\n    settings <- get_settings_from_config()\n    engine <- create new OddsEngine(config=settings)\n    // This part is slow: it loads all ~25 adapters\n    app.state.engine <- engine\n    LOG \"Background initialization complete. OddsEngine is now available.\"\n  CATCH Exception as e:\n    LOG_CRITICAL \"Failed to initialize OddsEngine in the background.\", error=e\n    app.state.engine <- null // Ensure the app knows initialization failed\n```\n\n### 3.3 Engine Orchestration (`engine.py`)\n\n```pseudocode\nCLASS OddsEngine:\n  INIT(config):\n    self.config <- config\n    self.adapters <- [List of all adapter instances]\n    self.http_client <- httpx.AsyncClient(...)\n    self.semaphore <- asyncio.Semaphore(config.MAX_CONCURRENT_REQUESTS)\n\n    // Inject the shared, persistent HTTP client into each adapter\n    FOR adapter IN self.adapters:\n      adapter.http_client <- self.http_client\n\n  @cache_async_result(ttl_seconds=300)\n  ASYNC FUNCTION fetch_all_odds(date_str):\n    // Create a list of concurrent fetching tasks, wrapped in the semaphore\n    tasks <- [self._fetch_with_semaphore(adapter, date_str) FOR adapter in self.adapters]\n    results <- AWAIT asyncio.gather(*tasks, return_exceptions=True)\n\n    // Process results, separating successes from failures\n    all_races <- []\n    FOR result IN results:\n      IF result is a success:\n        all_races.extend(result.races)\n\n    // Deduplicate and merge races from different sources\n    deduped_races <- self._dedupe_races(all_races)\n\n    RETURN AggregatedResponse(races=deduped_races, source_statuses=...)\n```\n\n---\n\n## 4. FRONTEND INTERFACE (TYPESCRIPT/REACT) - DETAILED\n\n### 4.1 LiveRaceDashboard Component\n\n```pseudocode\nCOMPONENT LiveRaceDashboard (client-side):\n\n  STATE:\n    races: Race[] <- []\n    backendStatus: 'connecting' | 'online' | 'error' <- 'connecting'\n    lastLogs: string[] <- []\n\n  EFFECT on mount:\n    // Use the secure API exposed by preload.js\n    IF window.electronAPI exists:\n      // Set up a listener for status updates from the main process\n      window.electronAPI.onBackendStatus((update) => {\n        setBackendStatus(update.state)\n        setLastLogs(update.logs)\n      })\n\n    // Immediately request the current status\n    window.electronAPI.getBackendStatus().then((status) => {\n      setBackendStatus(status.state)\n      setLastLogs(status.logs)\n    })\n\n    // Set up a polling interval to keep status fresh\n    interval <- setInterval(() => {\n      window.electronAPI.getBackendStatus().then((status) => {\n        setBackendStatus(status.state)\n        setLastLogs(status.logs)\n      })\n    }, 3000) // Poll every 3 seconds\n\n    CLEANUP: clearInterval(interval)\n\n  EFFECT when backendStatus changes to 'online':\n    // Trigger data fetch only when the backend is confirmed to be running\n    fetchQualifiedRaces()\n\n  ASYNC FUNCTION fetchQualifiedRaces():\n    TRY:\n      // Make a standard HTTP call to the local Python server\n      response <- AWAIT fetch(\"http://127.0.0.1:8000/api/races/qualified/trifecta\")\n      IF NOT response.ok:\n        RAISE new Error(`API returned status ${response.status}`)\n\n      data <- AWAIT response.json()\n      setRaces(data.races)\n\n    CATCH e:\n      // If the API call fails, update the status\n      setBackendStatus('error')\n      setLastLogs([...lastLogs, `API Fetch Error: ${e.message}`])\n\n  FUNCTION RENDER:\n    <div className=\"dashboard\">\n      <StatusIndicator status={backendStatus} />\n      <RaceFilters />\n\n      IF backendStatus === 'error':\n        <ErrorDisplay logs={lastLogs} />\n      ELSE IF backendStatus === 'connecting':\n        <LoadingSkeleton />\n      ELSE IF races.length === 0:\n        <EmptyState message=\"No races matched your filters.\" />\n      ELSE:\n        <RaceGrid races={races} />\n    </div>\n```\n\n---\n\n## 5. ELECTRON WRAPPER & WINDOWS INTEGRATION - DETAILED\n\n### 5.1 Main Process (`main.js`) - With Robust Lifecycle Management\n\n```pseudocode\nCLASS FortunaDesktopApp:\n  INIT():\n    self.mainWindow <- null\n    self.backendState <- 'stopped'\n    self.backendLogs <- []\n    self.backendProcess <- null\n\n  FUNCTION createMainWindow():\n    // ... create BrowserWindow, load static frontend ...\n\n  FUNCTION startBackend():\n    IF self.backendProcess is not null:\n      self.backendProcess.kill()\n\n    self.backendState <- 'starting'\n    self.backendLogs <- ['Attempting to start backend...']\n    self.sendBackendStatusUpdate() // Notify UI\n\n    // Get path to the packaged executable\n    exePath <- path.join(process.resourcesPath, 'fortuna-backend', 'fortuna-backend.exe')\n\n    IF file at exePath does NOT exist:\n      self.backendState <- 'error'\n      self.backendLogs.push(`FATAL: Executable not found at ${exePath}`)\n      self.sendBackendStatusUpdate()\n      dialog.showErrorBox(\"Critical Error\", \"Backend is missing. Please reinstall.\")\n      RETURN\n\n    // Spawn the process\n    self.backendProcess <- spawn(exePath, [], { stdio: ['ignore', 'pipe', 'pipe'] })\n\n    // --- CRITICAL: Resiliency Logic ---\n    startupTimeout <- setTimeout(() => {\n      IF self.backendState === 'starting':\n        self.backendState <- 'error'\n        self.backendLogs.push('Error: Backend startup timed out after 30 seconds.')\n        self.backendProcess.kill()\n        self.sendBackendStatusUpdate()\n    }, 30000) // 30-second timeout\n\n    self.backendProcess.stdout.on('data', (data) => {\n      self.backendLogs.push(data.toString())\n      // A more robust check would be a successful health check poll\n      IF data.toString().includes(\"Uvicorn running\"):\n        self.backendState <- 'online'\n        clearTimeout(startupTimeout)\n        self.sendBackendStatusUpdate()\n    })\n\n    self.backendProcess.stderr.on('data', (data) => {\n      self.backendLogs.push(`[STDERR] ${data.toString()}`)\n    })\n\n    self.backendProcess.on('exit', (code) => {\n      clearTimeout(startupTimeout)\n      IF self.backendState is not 'error': // Avoid duplicate error messages\n        self.backendState <- 'error'\n        self.backendLogs.push(`Backend process exited unexpectedly with code: ${code}`)\n        self.sendBackendStatusUpdate()\n    })\n\n  FUNCTION sendBackendStatusUpdate():\n    // Send the latest status to the frontend renderer process\n    IF self.mainWindow is not null:\n      self.mainWindow.webContents.send('backend-status-update', {\n        state: self.backendState,\n        logs: self.backendLogs.slice(-20) // Send last 20 log lines\n      })\n\n// --- IPC Handlers (Securely Defined) ---\nipcMain.handle('get-backend-status', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN null\n\n  RETURN { state: self.backendState, logs: self.backendLogs.slice(-20) }\n})\n\nipcMain.on('restart-backend', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN\n\n  self.startBackend()\n})\n```\n\n### 5.2 Preload Script (`preload.js`)\n\n```pseudocode\n// Expose a limited, secure API to the frontend renderer process\ncontextBridge.exposeInMainWorld('electronAPI', {\n  getBackendStatus: () => ipcRenderer.invoke('get-backend-status'),\n  restartBackend: () => ipcRenderer.send('restart-backend'),\n  onBackendStatus: (callback) => ipcRenderer.on('backend-status-update', (_event, value) => callback(value))\n})\n```\n\n---\n\n## 6. DATA MODELS & API SPECIFICATION\n\n### 6.1 Core Data Models (Pydantic/TypeScript)\n\n```\nMODEL Race:\n  id: str (unique identifier, e.g., \"Betfair_USA_Aqueduct_2025-11-07_R1\")\n  venue: str\n  race_number: int\n  start_time: datetime\n  runners: List[Runner]\n  source: str\n\nMODEL Runner:\n  name: str\n  odds: Optional[float]\n```\n\n### 6.2 Primary API Endpoints\n\n```\nENDPOINT GET /health\n  Description: Simple health check, requires no authentication.\n  Response (200 OK): {\"status\": \"ok\"}\n\nENDPOINT GET /api/races/qualified/trifecta\n  Description: Fetches all race data, runs the Trifecta analyzer, and returns qualified races.\n  Headers:\n    - X-API-Key: (Required, not used in this local setup but good practice)\n  Query Params:\n    - max_field_size: int\n    - min_odds: float\n  Response (200 OK):\n    {\n      \"qualified_races\": List[Race],\n      \"analysis_metadata\": { ... }\n    }\n```\n\n---\n\n## 7. DEPLOYMENT & AUTOMATION (CI/CD)\n\n```pseudocode\nWORKFLOW Build_MSI_Installer_on_GitHub_Actions:\n  // Phase 1: Setup\n  SETUP Node.js and Python environments\n\n  // Phase 2: Build Frontend\n  RUN \"npm ci\" and \"npm run build\" in /web_platform/frontend\n  COPY static output to /electron/web-ui-build/out\n\n  // Phase 3: Build Backend\n  RUN \"pip install -r python_service/requirements.txt\"\n  // CRITICAL: Use PyInstaller with a spec file or CLI flags that include\n  // necessary hidden imports to prevent runtime crashes.\n  // e.g., --hidden-import=keyring.backends.fail.Keyring\n  EXECUTE PyInstaller to create fortuna-backend.exe\n  PLACE executable in /electron/resources/fortuna-backend\n\n  // Phase 4: Deep Integration Test\n  START fortuna-backend.exe in the background\n  POLL http://127.0.0.1:8000/health until it responds with 200 OK or times out\n  IF timeout or crash THEN FAIL the build\n\n  // Phase 5: Package\n  RUN \"npm ci\" in /electron\n  EXECUTE \"npx electron-builder\" to create the MSI installer\n\n  // Phase 6: Publish\n  UPLOAD MSI as a build artifact\n  IF build was triggered by a git tag THEN CREATE a new GitHub Release\n```\n\n---\n\n## 8. END-TO-END WORKFLOWS\n\n### 8.1 Production Startup Workflow (Resilient)\n\n```\nWORKFLOW user_launches_application:\n  STEP 1: User executes Fortuna Faucet.exe -> Electron main.js starts.\n  STEP 2: UI appears instantly. The main process creates the BrowserWindow and loads the static index.html. The UI shows a 'connecting' state.\n  STEP 3: Backend starts asynchronously. The main process calls the robust `startBackend()` function.\n  STEP 4: `startBackend()` spawns `fortuna-backend.exe` and starts a 30-second timeout.\n  STEP 5: The frontend UI polls for status every 3 seconds via the secure `window.electronAPI.getBackendStatus()`.\n  STEP 6: The backend `.exe` starts, its `lifespan` hook runs, and the Uvicorn server comes online within seconds.\n  STEP 7: The main process detects the \"Uvicorn running\" message (or a successful health poll) and updates its internal state to 'online'. The startup timeout is cleared.\n  STEP 8: On its next poll, the frontend receives the 'online' status.\n  STEP 9: The frontend's state changes, triggering the `fetchQualifiedRaces()` API call to `localhost:8000`.\n  STEP 10: Data is returned from the now fully-initialized backend and rendered in the UI.\n\n  FAILURE SCENARIO (Backend Crash):\n  STEP 6a: The backend `.exe` crashes on startup.\n  STEP 7a: The `on('exit')` handler in `main.js` fires. The state is set to 'error' with the exit code.\n  STEP 8a: On its next poll, the frontend receives the 'error' status and relevant logs.\n  STEP 9a: The UI renders an error message and a \"Restart Backend\" button.\n```\n\n---\n*This concludes the revised and definitive blueprint for the Fortuna Faucet application.*\n\n---\n\n### 9. OPERATION: THE AUDITOR (REAL-TIME VERIFICATION)\n\n**Status:** Implemented (Python)\n**Source:** `python_service/auditor.py`\n\n#### 9.1 System Context\n*Runs as a background thread. Verifies \"Qualifier\" predictions against official results scraped from AtTheRaces.com to calculate real-time profitability.*\n\n#### 9.2 Database Schema (SQLite)\n\n```pseudocode\nTABLE audit_log:\n  race_id: TEXT PRIMARY KEY      // Format: \"VENUE-YYYYMMDD-RR\"\n  track_code: TEXT\n  race_number: INTEGER\n  predicted_horse: TEXT\n  timestamp: DATETIME\n  status: TEXT                   // 'PENDING', 'CASHED', 'BURNED'\n  official_payout: REAL          // Default: 0.00\n  net_profit: REAL               // Default: 0.00\n\n  CONSTRAINT status_check CHECK (status IN ('PENDING', 'CASHED', 'BURNED'))\n  INDEX idx_status_timestamp (status, timestamp)\n```\n\n#### 9.3 Auditor Engine Logic\n\n```pseudocode\nMODULE: Auditor_Engine\nDEPENDENCIES: httpx, beautifulsoup4, sqlite3, structlog\n\nCLASS Auditor_Engine:\n\n    PROPERTIES:\n        db_path: String\n        http_client: AsyncClient\n        TOTE_UNIT: Float (2.00)\n        TRACK_CODE_MAP: Dictionary  // Maps \"DON\" -> \"Doncaster\", etc.\n\n    FUNCTION __init__(db_path):\n        self.db_path = db_path\n        self.Initialize_Database()\n        self.http_client = NEW AsyncClient(timeout=30)\n\n    # --- Phase 1: The Snapshot ---\n    # Called by OddsEngine when a bet is placed/qualified\n    ASYNC FUNCTION Snapshot_Qualifier(venue_code, race_date, race_number, predicted_horse):\n        race_id = GENERATE_ID(venue_code, race_date, race_number)\n\n        TRY:\n            QUERY = \"\"\"\n                INSERT INTO audit_log\n                (race_id, track_code, race_number, predicted_horse, timestamp, status)\n                VALUES (?, ?, ?, ?, ?, 'PENDING')\n            \"\"\"\n            EXECUTE_SQL(self.db_path, QUERY, (race_id, venue_code, race_number, predicted_horse, NOW()))\n            LOG_INFO(\"Snapshot saved: \" + race_id)\n            RETURN TRUE\n        CATCH IntegrityError:\n            LOG_WARN(\"Race already tracked: \" + race_id)\n            RETURN FALSE\n\n    # --- Phase 2: The Fetcher (Background Loop) ---\n    ASYNC FUNCTION Run_Audit_Loop():\n        self.running = TRUE\n        WHILE self.running:\n            TRY:\n                # 1. Get Pending Races (Last 60 mins)\n                cutoff = NOW() - MINUTES(60)\n                pending_races = GET_PENDING_RACES(cutoff)\n\n                IF pending_races IS EMPTY:\n                    SLEEP(120)\n                    CONTINUE\n\n                # 2. Batch by Track\n                unique_tracks = EXTRACT_UNIQUE_TRACKS(pending_races)\n\n                FOR track IN unique_tracks:\n                    track_races = FILTER(pending_races, track)\n\n                    FOR race IN track_races:\n                        # Fetch Official Result from AtTheRaces\n                        result = AWAIT self._Fetch_Official_Result(race.track_code, race.race_number)\n\n                        IF result IS NOT NULL:\n                            self._Determine_Verdict(race, result)\n\n                        SLEEP(2) # Polite delay\n\n            CATCH Exception as e:\n                LOG_ERROR(\"Audit Loop Error: \" + e)\n\n            SLEEP(120)\n\n    # --- Phase 3: The Scraper (AtTheRaces Strategy) ---\n    ASYNC FUNCTION _Fetch_Official_Result(track_code, race_number):\n        # 1. Find the specific Race URL from the daily results page\n        race_url = AWAIT self._Find_Race_URL(track_code, race_number)\n        IF race_url IS NULL: RETURN NULL\n\n        # 2. Fetch the Race Page\n        html = AWAIT self.http_client.GET(race_url)\n\n        # 3. Parse the Table\n        result = self._Parse_AtTheRaces_Results(html, track_code, race_number)\n        RETURN result\n\n    ASYNC FUNCTION _Find_Race_URL(track_code, race_number):\n        base_url = \"https://www.attheraces.com/results\"\n        html = AWAIT self.http_client.GET(base_url)\n\n        track_name = self.TRACK_CODE_MAP[track_code]\n        track_header = FIND_ELEMENT(html, text=track_name)\n\n        IF track_header EXISTS:\n            # Select the Nth link in the track's panel\n            race_links = SELECT_ALL(track_header.parent, 'a[href*=\"/racecard/\"]')\n            IF LENGTH(race_links) >= race_number:\n                RETURN race_links[race_number - 1].href\n\n        RETURN NULL\n\n    FUNCTION _Parse_AtTheRaces_Results(html, track_code, race_number):\n        table = FIND_TABLE(html, header_contains=\"Horse\")\n        IF table IS NULL: RETURN NULL\n\n        finishers = []\n        win_payout = EXTRACT_WIN_PAYOUT(html) # Parse \"Betting returns\" table\n\n        FOR row IN table.rows:\n            position = PARSE_INT(row.cells[0])\n            horse_name = row.cells[2].text\n\n            place_payout = 0.0\n            IF position == 1:\n                place_payout = win_payout\n\n            finishers.APPEND({\n                \"name\": horse_name,\n                \"position\": position,\n                \"place_payout\": place_payout\n            })\n\n        RETURN NEW OfficialResult(finishers)\n\n    # --- Phase 4: The Verdict ---\n    FUNCTION _Determine_Verdict(prediction, official_result):\n        did_place = FALSE\n        payout = 0.00\n\n        # Check if predicted horse won (AtTheRaces basic logic)\n        FOR finisher IN official_result.finishers:\n            IF finisher.name == prediction.predicted_horse AND finisher.place_payout > 0:\n                did_place = TRUE\n                payout = finisher.place_payout\n                BREAK\n\n        IF did_place:\n            status = 'CASHED'\n            net_profit = payout - self.TOTE_UNIT\n        ELSE:\n            status = 'BURNED'\n            net_profit = -self.TOTE_UNIT\n\n        UPDATE_DB(prediction.race_id, status, payout, net_profit)\n\n    # --- Phase 5: Dashboard Metrics ---\n    FUNCTION Get_Rolling_Metrics(minutes=60):\n        cutoff = NOW() - MINUTES(minutes)\n        QUERY = \"\"\"\n            SELECT\n                COUNT(*) as total,\n                SUM(CASE WHEN status='CASHED' THEN 1 ELSE 0 END) as wins,\n                SUM(net_profit) as profit\n            FROM audit_log\n            WHERE timestamp > ? AND status != 'PENDING'\n        \"\"\"\n        stats = EXECUTE_SQL(self.db_path, QUERY, (cutoff,))\n\n        RETURN {\n            \"strike_rate\": (stats.wins / stats.total) * 100,\n            \"net_profit\": stats.profit,\n            \"volume\": stats.total\n        }\n```",
    "electron/main.js": "// electron/main.js - CORRECTED VERSION\nconst { app, BrowserWindow, Tray, Menu, nativeImage, ipcMain, dialog } = require('electron');\nconst { autoUpdater } = require('electron-updater');\nconst { spawn } = require('child_process');\nconst net = require('net');\nconst path = require('path');\nconst fs = require('fs');\nconst SecureSettingsManager = require('./secure-settings-manager');\n\nclass FortunaDesktopApp {\n constructor() {\n this.backendProcess = null;\n this.mainWindow = null;\n this.tray = null;\n this.backendState = 'stopped'; // \"stopped\", \"starting\", \"running\", \"error\"\n this.backendLogs = [];\n this.isBackendStarting = false;\n }\n\n sendBackendStatusUpdate() {\n if (this.mainWindow) {\n this.mainWindow.webContents.send('backend-status-update', {\n state: this.backendState,\n logs: this.backendLogs.slice(-20) // Send last 20 log entries\n });\n }\n }\n\n stopBackend() {\n if (this.backendProcess && !this.backendProcess.killed) {\n console.log('Stopping backend process...');\n this.backendProcess.kill();\n this.backendState = 'stopped';\n this.isBackendStarting = false; // Ensure lock is released on stop\n this.backendLogs.push('Backend process stopped by user.');\n this.sendBackendStatusUpdate();\n }\n }\n\n  checkPortInUse(port) {\n    return new Promise((resolve, reject) => {\n      const server = net.createServer();\n      server.once('error', (err) => {\n        if (err.code === 'EADDRINUSE') {\n          resolve(true); // Port is in use\n        } else {\n          reject(err);\n        }\n      });\n      server.once('listening', () => {\n        server.close(() => {\n          resolve(false); // Port is free\n        });\n      });\n      server.listen(port, '127.0.0.1');\n    });\n  }\n\nasync waitForBackend(maxRetries = 30) {\n    const port = process.env.FORTUNA_PORT || 8000;\n    const url = `http://localhost:${port}/docs`;\n\n    console.log(`[Backend Check] Starting health check at: ${url}`);\n\n    for (let i = 0; i < maxRetries; i++) {\n        try {\n            const response = await fetch(url, { timeout: 3000 });\n            console.log(`[Backend Check] Attempt ${i}: Status ${response.status}`);\n\n            if (response.ok) {\n                console.log('\u2705 Backend is ready!');\n                return true;\n            }\n        } catch (e) {\n            console.log(`[Backend Check] Attempt ${i} failed: ${e.message}`);\n\n            // Log if backend process is still alive\n            if (this.backendProcess && !this.backendProcess.killed) {\n                console.log(`[Backend Check] Process still running (PID: ${this.backendProcess.pid})`);\n            } else {\n                console.error(`[Backend Check] \u26a0\ufe0f Backend process is DEAD!`);\n                console.error(`[Backend Check] Last logs:`, this.backendLogs.slice(-5));\n                throw new Error(`Backend process died. Last logs:\\n${this.backendLogs.slice(-5).join('\\n')}`);\n            }\n\n            await new Promise(r => setTimeout(r, 1000));\n        }\n    }\n\n    throw new Error(`Backend failed to respond at ${url} after 30 seconds`);\n}\n\nasync startBackend() {\n    const isDev = !app.isPackaged;\n    let backendCommand;\n    let backendCwd;\n\n    if (isDev) {\n        console.log('[DEV MODE] Configuring backend...');\n        backendCommand = path.join(__dirname, '..', '.venv', 'Scripts', 'python.exe');\n        backendCwd = path.join(__dirname, '..', 'web_service', 'backend');\n    } else {\n        const backendFolder = path.join(process.resourcesPath, 'fortuna-backend');\n        backendCommand = path.join(backendFolder, 'fortuna-backend.exe');\n        backendCwd = backendFolder;\n\n        // DEBUG: Log the path we're looking for\n        console.log(`[Backend] Looking for executable at: ${backendCommand}`);\n        console.log(`[Backend] Directory exists: ${fs.existsSync(backendFolder)}`);\n        console.log(`[Backend] Executable exists: ${fs.existsSync(backendCommand)}`);\n    }\n\n    if (!fs.existsSync(backendCommand)) {\n        const errorMsg = `Backend executable not found at: ${backendCommand}`;\n        console.error(`[Backend] ${errorMsg}`);\n        this.backendLogs.push(`ERROR: ${errorMsg}`);\n        this.backendState = 'error';\n\n        // Show user a helpful error dialog\n        dialog.showErrorBox(\n            'Backend Launch Failed',\n            `Could not find backend executable.\\n\\nExpected location:\\n${backendCommand}`\n        );\n        return;\n    }\n\n    console.log(`[Backend] Executable found, attempting to spawn...`);\n\n    console.log(`[Electron] Spawning backend: ${backendCommand}`);\n    console.log(`[Electron] Backend CWD: ${backendCwd}`);\n\n    this.backendProcess = spawn(backendCommand, [], {\n        cwd: backendCwd, // CRITICAL: This allows the EXE to find the '_internal' folder\n        windowsHide: true,\n        env: {\n            ...process.env,\n            FORTUNA_MODE: 'electron', // Let the backend know its execution context\n            PYTHONPATH: backendCwd // Force python to look at the root of the extract dir\n        }\n    });\n\n    this.backendProcess.stdout.on('data', (data) => {\n      console.log(`[Backend STDOUT] ${data.toString()}`);\n    });\n\n    this.backendProcess.stderr.on('data', (data) => {\n      console.error(`[Backend STDERR] ${data.toString()}`);\n    });\n\n    this.backendProcess.stdout.on('data', (data) => {\n      const output = data.toString().trim();\n      console.log(`[Backend] ${output}`);\n      this.backendLogs.push(output);\n      if (this.backendState !== 'running' && output.includes('Application startup complete')) {\n        console.log('\u2705 Backend is ready!');\n        this.backendState = 'running';\n        this.isBackendStarting = false;\n      }\n      this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.stderr.on('data', (data) => {\n      const errorOutput = data.toString().trim();\n      console.error(`[Backend ERROR] ${errorOutput}`);\n      this.backendLogs.push(`ERROR: ${errorOutput}`);\n      this.backendState = 'error';\n      this.isBackendStarting = false;\n      this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.on('error', (err) => {\n        const errorMsg = `Failed to spawn backend process: ${err.message}`;\n        console.error(`[Backend] ${errorMsg}`);\n        this.backendLogs.push(`ERROR: ${errorMsg}`);\n        this.backendState = 'error';\n        this.isBackendStarting = false;\n        this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.on('exit', (code) => {\n      if (code !== 0 && this.backendState !== 'stopped') {\n        console.error(`[CRITICAL] Backend process exited with code: ${code}`);\n        console.error(`[CRITICAL] Last 10 logs:`, this.backendLogs.slice(-10));\n\n        // Save logs immediately\n        const fs = require('fs');\n        const path = require('path');\n        const logFile = path.join(require('os').homedir(), '.fortuna', 'backend_crash.log');\n        fs.mkdirSync(path.dirname(logFile), { recursive: true });\n        fs.writeFileSync(logFile, this.backendLogs.join('\\n'));\n        console.error(`[CRITICAL] Full logs saved to: ${logFile}`);\n        this.backendState = 'error';\n        this.isBackendStarting = false;\n        this.sendBackendStatusUpdate();\n      }\n    });\n}\n\ngetFrontendPath() {\n    if (!app.isPackaged) {\n        return 'http://localhost:3000';\n    }\n\n    const indexPath = path.join(app.getAppPath(), 'out', 'index.html');\n    const { pathToFileURL } = require('url');\n    return pathToFileURL(indexPath).toString();\n}\n\n createMainWindow() {\n this.mainWindow = new BrowserWindow({\n width: 1600,\n height: 1000,\n title: 'Fortuna Faucet - Racing Analysis',\n icon: path.join(__dirname, 'assets', 'icon.ico'),\n webPreferences: {\n nodeIntegration: false,\n contextIsolation: true,\n preload: path.join(__dirname, 'preload.js')\n },\n autoHideMenuBar: true,\n backgroundColor: '#1a1a2e'\n });\n\n if (!app.isPackaged) {\n this.mainWindow.webContents.openDevTools();\n }\n\n this.mainWindow.on('close', (event) => {\n if (!app.isQuitting) {\n event.preventDefault();\n this.mainWindow.hide();\n }\n });\n }\n\n createSystemTray() {\n // ... (rest of the file is unchanged)\n }\n\n initialize() {\n  ipcMain.handle('get-api-port', () => {\n    return process.env.FORTUNA_PORT || 8000;\n  });\n this.createMainWindow();\n this.createSystemTray();\n this.startBackend();\n\n  // Wait for backend to be ready before loading frontend\n  this.waitForBackend()\n    .then(() => {\n      const frontendUrl = this.getFrontendPath();\n      this.mainWindow.loadURL(frontendUrl);\n    })\n    .catch((err) => {\n      console.error('Backend startup failed:', err);\n      dialog.showErrorBox('Backend Error', 'Failed to start backend service');\n    });\n\n // Check for updates\n autoUpdater.checkForUpdatesAndNotify();\n\n autoUpdater.on('update-downloaded', (info) => {\n const dialogOpts = {\n type: 'info',\n buttons: ['Restart', 'Later'],\n title: 'Application Update',\n message: process.platform === 'win32' ? info.releaseName : info.releaseName,\n detail: 'A new version has been downloaded. Restart the application to apply the updates.'\n };\n\n dialog.showMessageBox(dialogOpts).then((returnValue) => {\n if (returnValue.response === 0) autoUpdater.quitAndInstall();\n });\n });\n\n ipcMain.on('restart-backend', () => this.startBackend());\n ipcMain.on('stop-backend', () => this.stopBackend());\n ipcMain.handle('get-backend-status', async () => ({\n state: this.backendState,\n logs: this.backendLogs.slice(-20)\n }));\n\n ipcMain.handle('get-api-key', async () => {\n return SecureSettingsManager.getApiKey();\n });\n\n ipcMain.handle('generate-api-key', async () => {\n const crypto = require('node:crypto');\n const newKey = crypto.randomBytes(16).toString('hex');\n SecureSettingsManager.saveApiKey(newKey);\n return newKey;\n });\n\n ipcMain.handle('save-api-key', async (event, apiKey) => {\n return SecureSettingsManager.saveApiKey(apiKey);\n });\n\n ipcMain.handle('save-betfair-credentials', async (event, credentials) => {\n return SecureSettingsManager.saveBetfairCredentials(credentials);\n });\n }\n\n cleanup() {\n if (this.backendProcess && !this.backendProcess.killed) {\n this.backendProcess.kill();\n }\n }\n}\n\nlet fortunaApp;\n\napp.whenReady().then(() => {\n  // Harden the session for security\n  const { session } = require('electron');\n  const ses = session.defaultSession;\n\n  // 1. Content-Security-Policy\n  ses.webRequest.onHeadersReceived((details, callback) => {\n    callback({\n      responseHeaders: {\n        ...details.responseHeaders,\n        'Content-Security-Policy': [\n          \"default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self' data:; connect-src 'self' http://127.0.0.1:*\"\n        ]\n      }\n    });\n  });\n\n  // 2. Permission Request Handler\n  ses.setPermissionRequestHandler((webContents, permission, callback) => {\n    const allowedPermissions = ['clipboard-read', 'clipboard-sanitized-write'];\n    if (allowedPermissions.includes(permission)) {\n      callback(true); // Grant allowed permissions\n    } else {\n      console.warn(`[SECURITY] Denied permission request for: ${permission}`);\n      callback(false); // Deny all others by default\n    }\n  });\n\n  // 3. Certificate Pinning (TODO)\n  // Certificate pinning would be implemented here. It is commented out\n  // because it requires a known certificate hash and would break local dev.\n  // ses.setCertificateVerifyProc((request, callback) => {\n  //   const { hostname, certificate, verificationResult } = request;\n  //   if (hostname === 'api.fortuna.faucet') {\n  //     // TODO: Replace with actual certificate fingerprint\n  //     const expectedFingerprint = '...';\n  //     if (certificate.fingerprint === expectedFingerprint) {\n  //       callback(0); // 0 means success\n  //     } else {\n  //       callback(-2); // -2 means failure\n  //     }\n  //   } else {\n  //     callback(0); // Allow other domains\n  //   }\n  // });\n\n  fortunaApp = new FortunaDesktopApp();\n  fortunaApp.initialize();\n});\n\napp.on('window-all-closed', () => {\n if (process.platform !== 'darwin') {\n // Do nothing, keep app running in tray\n }\n});\n\napp.on('activate', () => {\n if (BrowserWindow.getAllWindows().length === 0) {\n fortunaApp.createMainWindow();\n } else {\n fortunaApp.mainWindow.show();\n }\n});\n\napp.on('before-quit', () => {\n app.isQuitting = true;\n if (fortunaApp) {\n fortunaApp.cleanup();\n }\n});\n",
    "electron/secure-settings-manager.js": "// electron/secure-settings-manager.js\nconst { app } = require('electron');\nconst fs = require('fs');\nconst path = require('path');\n\nconst SETTINGS_FILE = path.join(app.getPath('userData'), 'settings.json');\n\nclass SecureSettingsManager {\n constructor() {\n this.settings = this.loadSettings();\n }\n\n loadSettings() {\n try {\n if (fs.existsSync(SETTINGS_FILE)) {\n const data = fs.readFileSync(SETTINGS_FILE, 'utf-8');\n return JSON.parse(data);\n }\n } catch (error) {\n console.error('Error loading settings:', error);\n }\n return {};\n }\n\n saveSettings() {\n try {\n fs.writeFileSync(SETTINGS_FILE, JSON.stringify(this.settings, null, 2));\n } catch (error) {\n console.error('Error saving settings:', error);\n }\n }\n\n getApiKey() {\n return this.settings.apiKey || null;\n }\n\n saveApiKey(apiKey) {\n this.settings.apiKey = apiKey;\n this.saveSettings();\n return { success: true };\n }\n\n getBetfairCredentials() {\n return this.settings.betfair || null;\n }\n\n saveBetfairCredentials(credentials) {\n this.settings.betfair = credentials;\n this.saveSettings();\n return { success: true };\n }\n}\n\nmodule.exports = new SecureSettingsManager();\n",
    "fortuna-backend-electron.spec": "# -*- mode: python ; coding: utf-8 -*-\nfrom pathlib import Path\nfrom PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\nblock_cipher = None\nproject_root = Path(SPECPATH).parent\n# FIXED: Target the consolidated backend\nbackend_root = project_root / 'web_service' / 'backend'\n\n# Collect data folders\ndatas = []\nfor folder in ['data', 'json', 'adapters']:\n    source_path = backend_root / folder\n    if source_path.exists():\n        datas.append((str(source_path), folder))\n\n# Collect dependencies\nhiddenimports = [\n    'uvicorn', 'fastapi', 'starlette', 'pydantic', 'structlog',\n    'tenacity', 'redis', 'sqlalchemy', 'greenlet', 'win32timezone'\n] + collect_submodules('web_service.backend')\n\na = Analysis(\n    ['web_service/backend/main.py'], # FIXED: Entry point\n    pathex=[str(project_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.zipfiles, a.datas,\n    name='fortuna-backend',\n    debug=False,\n    strip=False,\n    upx=True,\n    console=True, # Keep console for Electron backend debugging\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\n",
    "pytest.ini": "[pytest]\npythonpath = .\ntestpaths = tests\npython_files = test_*.py\naddopts = -v\nasyncio_mode = auto\nasyncio_default_fixture_loop_scope = function\n",
    "python_service/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching horse racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairExchange\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for a given date.\"\"\"\n        await self._authenticate(self.http_client)\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            self.http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"7\"],  # Horse Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\", \"US\", \"FR\", \"ZA\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\"Failed to parse a Betfair market.\", exc_info=True, market=market)\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bf_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 1m Mdn Stks').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "python_service/adapters/equibase_adapter.py": "# python_service/adapters/equibase_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom selectolax.parser import HTMLParser\nfrom selectolax.parser import Node\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass EquibaseAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for scraping Equibase race entries, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Equibase\"\n    BASE_URL = \"https://www.equibase.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        d = datetime.strptime(date, \"%Y-%m-%d\").date()\n        index_url = f\"/entries/Entries.cfm?ELEC_DATE={d.month}/{d.day}/{d.year}&STYLE=EQB\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url, headers=self._get_headers())\n        if not index_response:\n            self.logger.warning(\"Failed to fetch Equibase index page\", url=index_url)\n            return None\n\n        parser = HTMLParser(index_response.text)\n        track_links = [\n            link.attributes[\"href\"]\n            for link in parser.css(\"div.track-information a\")\n            if \"race=\" not in link.attributes.get(\"href\", \"\")\n        ]\n\n        async def get_race_links_from_track(track_url: str):\n            response = await self.make_request(self.http_client, \"GET\", track_url, headers=self._get_headers())\n            if not response:\n                return []\n            parser = HTMLParser(response.text)\n            return [link.attributes[\"href\"] for link in parser.css(\"a.program-race-link\")]\n\n        tasks = [get_race_links_from_track(link) for link in track_links]\n        results = await asyncio.gather(*tasks)\n        race_links = [f\"{self.base_url}{link}\" for sublist in results for link in sublist]\n\n        async def fetch_single_html(race_url: str):\n            response = await self.make_request(self.http_client, \"GET\", race_url, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in race_links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        date = raw_data[\"date\"]\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                venue_node = parser.css_first(\"div.track-information strong\")\n                if not venue_node:\n                    continue\n                venue = clean_text(venue_node.text())\n\n                race_number_node = parser.css_first(\"div.race-information strong\")\n                if not race_number_node:\n                    continue\n                race_number_text = race_number_node.text().replace(\"Race\", \"\").strip()\n                if not race_number_text.isdigit():\n                    continue\n                race_number = int(race_number_text)\n\n                post_time_node = parser.css_first(\"p.post-time span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text().strip()\n                start_time = self._parse_post_time(date, post_time_str)\n\n                runners = []\n                runner_nodes = parser.css(\"table.entries-table tbody tr\")\n                for node in runner_nodes:\n                    if runner := self._parse_runner(node):\n                        runners.append(runner)\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"eqb_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.error(\"Failed to parse Equibase race page.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, node: Node) -> Optional[Runner]:\n        try:\n            number_node = node.css_first(\"td:nth-child(1)\")\n            if not number_node or not number_node.text(strip=True).isdigit():\n                return None\n            number = int(number_node.text(strip=True))\n\n            name_node = node.css_first(\"td:nth-child(3)\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            odds_node = node.css_first(\"td:nth-child(10)\")\n            odds_str = clean_text(odds_node.text()) if odds_node else \"\"\n\n            scratched = \"scratched\" in node.attributes.get(\"class\", \"\").lower()\n\n            odds = {}\n            if not scratched:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds = {\n                        self.source_name: OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n                    }\n            return Runner(number=number, name=name, odds=odds, scratched=scratched)\n        except (ValueError, AttributeError, IndexError):\n            self.logger.warning(\"Could not parse Equibase runner, skipping.\", exc_info=True)\n            return None\n\n    def _parse_post_time(self, date_str: str, time_str: str) -> datetime:\n        \"\"\"Parses a time string like 'Post Time: 12:30 PM ET' into a datetime object.\"\"\"\n        time_part = time_str.split(\" \")[-2] + \" \" + time_str.split(\" \")[-1]\n        dt_str = f\"{date_str} {time_part}\"\n        return datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/horseracingnation_adapter.py": "# python_service/adapters/horseracingnation_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass HorseRacingNationAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for horseracingnation.com.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"HorseRacingNation\"\n    BASE_URL = \"https://www.horseracingnation.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/adapters/racing_and_sports_adapter.py": "# python_service/adapters/racing_and_sports_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSports\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"RACING_AND_SPORTS_TOKEN\") or not config.RACING_AND_SPORTS_TOKEN:\n            raise AdapterConfigError(self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw meetings data from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            self.http_client,\n            \"GET\",\n            \"v1/racing/meetings\",\n            headers=headers,\n            params=params,\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw meetings data into a list of Race objects.\"\"\"\n        all_races = []\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\"No 'meetings' in RacingAndSports response or invalid format.\")\n            return all_races\n\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed_race := self._parse_ras_race(meeting, race_summary):\n                        all_races.append(parsed_race)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse RacingAndSports race, skipping\",\n                        meeting=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return all_races\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        try:\n            start_time = datetime.fromisoformat(start_time_str)\n        except (ValueError, TypeError):\n            self.logger.warning(\n                \"Invalid start time format for RacingAndSports race\",\n                start_time_str=start_time_str,\n                race_id=race_id,\n            )\n            return None\n\n        return Race(\n            id=f\"ras_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/tab_adapter.py": "# python_service/adapters/tab_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TabAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for tab.com.au.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"TAB\"\n    BASE_URL = \"https://www.tab.com.au\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "python_service/adapters/twinspires_adapter.py": "# python_service/adapters/twinspires_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\n\nfrom bs4 import BeautifulSoup\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TwinSpiresAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for twinspires.com.\n    This is a placeholder for a full implementation using the discovered JSON API.\n    \"\"\"\n\n    SOURCE_NAME = \"TwinSpires\"\n    BASE_URL = \"https://www.twinspires.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Reads HTML content from a local fixture file instead of making a live API call.\n        This is a temporary measure to allow development while the live API is blocking requests.\n        \"\"\"\n        # Read the local HTML fixture\n        try:\n            with open(\"tests/fixtures/twinspires_sample.html\", \"r\") as f:\n                html_content = f.read()\n        except FileNotFoundError:\n            self.logger.error(\"TwinSpires test fixture not found.\")\n            return None\n\n        # To maintain the data structure the parser expects, we will create a mock\n        # raw_data object that resembles the original API response, but includes\n        # the HTML content.\n        return {\n            \"html_content\": html_content,\n            \"mock_track_data\": {\"trackId\": \"cd\", \"trackName\": \"Churchill Downs\", \"raceType\": \"Thoroughbred\"},\n            \"mock_race_card\": {\"raceNumber\": 5, \"postTime\": \"2025-10-26T16:30:00Z\"},\n        }\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        [MODIFIED FOR OFFLINE DEVELOPMENT]\n        Parses race and runner data from the mock raw_data object, which now\n        includes the HTML content from the local fixture.\n        \"\"\"\n        if not raw_data or \"html_content\" not in raw_data:\n            return []\n\n        self.logger.info(\"Parsing TwinSpires data from local fixture.\")\n\n        html_content = raw_data[\"html_content\"]\n        track = raw_data[\"mock_track_data\"]\n        race_card = raw_data[\"mock_race_card\"]\n\n        # Parse the runners from the HTML content\n        runners = self._parse_runners_from_html(html_content)\n\n        try:\n            start_time = datetime.fromisoformat(race_card.get(\"postTime\").replace(\"Z\", \"+00:00\"))\n\n            race = Race(\n                id=f\"ts_{track.get('trackId')}_{race_card.get('raceNumber')}\",\n                venue=track.get(\"trackName\"),\n                race_number=race_card.get(\"raceNumber\"),\n                start_time=start_time,\n                discipline=track.get(\"raceType\", \"Unknown\"),\n                runners=runners,\n                source=self.SOURCE_NAME,\n            )\n            return [race]\n        except Exception as e:\n            self.logger.warning(\n                \"Failed to parse race card from mock data.\",\n                error=e,\n                exc_info=True,\n            )\n            return []\n\n    def _parse_runners_from_html(self, html_content: str) -> List[Runner]:\n        \"\"\"Parses runner data from a race card's HTML content.\"\"\"\n        runners = []\n        soup = BeautifulSoup(html_content, \"html.parser\")\n        runner_elements = soup.select(\"li.runner\")\n\n        for element in runner_elements:\n            try:\n                scratched = \"scratched\" in element.get(\"class\", [])\n\n                number_tag = element.select_one(\"span.runner-number\")\n                name_tag = element.select_one(\"span.runner-name\")\n                odds_tag = element.select_one(\"span.runner-odds\")\n\n                if not all([number_tag, name_tag, odds_tag]):\n                    continue\n\n                number = int(number_tag.text.strip())\n                name = name_tag.text.strip()\n                odds_str = odds_tag.text.strip()\n\n                odds = {}\n                if not scratched and odds_str not in [\"SCR\", \"\"]:\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    if win_odds:\n                        odds[self.SOURCE_NAME] = OddsData(\n                            win=win_odds,\n                            source=self.SOURCE_NAME,\n                            last_updated=datetime.now(),\n                        )\n\n                runners.append(\n                    Runner(\n                        number=number,\n                        name=name,\n                        scratched=scratched,\n                        odds=odds,\n                    )\n                )\n            except (ValueError, TypeError) as e:\n                self.logger.warning(\"Failed to parse a runner, skipping.\", error=e, exc_info=True)\n                continue\n\n        return runners\n\n    async def _get_races_async(self, date: str) -> List[Race]:\n        raw_data = await self._fetch_data(date)\n        return self._parse_races(raw_data)\n\n    def get_races(self, date: str) -> List[Race]:\n        \"\"\"\n        Orchestrates the fetching and parsing of race data for a given date.\n        This method will be called by the FortunaEngine.\n        \"\"\"\n        self.logger.info(f\"Getting races for {date} from {self.SOURCE_NAME}\")\n        # This is a synchronous wrapper for the async orchestrator\n        # It's a temporary measure to allow me to see the API response.\n        import asyncio\n\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        races = loop.run_until_complete(self._get_races_async(date))\n        return races\n",
    "python_service/api.py": "# python_service/api.py\n\nimport asyncio\nimport os\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom contextlib import asynccontextmanager\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import List\nfrom typing import Optional\n\nimport aiosqlite\nimport structlog\nfrom fastapi import Depends\nfrom fastapi import FastAPI\nfrom fastapi import HTTPException\nfrom fastapi import Query\nfrom fastapi import Request\nfrom fastapi import WebSocket\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom slowapi import Limiter\nfrom slowapi import _rate_limit_exceeded_handler\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi.middleware import SlowAPIMiddleware\nfrom slowapi.util import get_remote_address\nfrom fastapi import WebSocketDisconnect\n\n# --- PyInstaller Explicit Imports ---\nfrom .analyzer import AnalyzerEngine\nfrom .cache_manager import cache_manager\nfrom .config import get_settings\nfrom .core.exceptions import AdapterConfigError\nfrom .core.exceptions import AdapterHttpError\nfrom .engine import OddsEngine\nfrom .health import router as health_router\nfrom .logging_config import configure_logging\nfrom .manual_override_manager import ManualOverrideManager\nfrom .middleware.error_handler import UserFriendlyException\nfrom .middleware.error_handler import user_friendly_exception_handler\nfrom .middleware.error_handler import validation_exception_handler\nfrom .models import AggregatedResponse\nfrom .models import ManualParseRequest\nfrom .models import QualifiedRacesResponse\nfrom .models import Race\nfrom .models import TipsheetRace\nfrom .security import verify_api_key\n\n# ------------------------------------\n\nlog = structlog.get_logger()\n\n# Create a fixed thread pool for blocking calls at the module level\nexecutor = ThreadPoolExecutor(max_workers=1)\n\n\ndef _initialize_heavy_resources_sync(app: FastAPI):\n    \"\"\"\n    This synchronous function contains the blocking I/O and CPU-intensive\n    initialization of the OddsEngine and its ~25 adapters. By isolating it,\n    we can run it in a background thread without stalling the main Uvicorn event loop.\n    \"\"\"\n    log.info(\"Background initialization of heavy resources started.\")\n    try:\n        settings = get_settings()\n\n        # Initialize WebSocket connection manager\n        connection_manager = ConnectionManager()\n\n        # Initialize manual override manager\n        manual_override_manager = ManualOverrideManager()\n\n        # Initialize engine with manual override and WebSocket support\n        engine = OddsEngine(\n            config=settings,\n            manual_override_manager=manual_override_manager,\n            connection_manager=connection_manager,\n        )\n\n        # Store the initialized components on the app state\n        app.state.engine = engine\n        app.state.analyzer_engine = AnalyzerEngine()\n        app.state.manual_override_manager = manual_override_manager\n        app.state.connection_manager = connection_manager\n        log.info(\"Background initialization of heavy resources completed successfully.\")\n    except Exception:\n        log.critical(\"CRITICAL: Background initialization failed.\", exc_info=True)\n        # In a real-world scenario, you might want a more robust way\n        # to signal this failure to the main application.\n        app.state.engine = None\n\n\nclass ConnectionManager:\n    \"\"\"Manages active WebSocket connections.\"\"\"\n\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        log.info(\"WebSocket ConnectionManager initialized.\")\n\n    async def connect(self, websocket: WebSocket):\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        log.info(\"New WebSocket connection established.\")\n\n    def disconnect(self, websocket: WebSocket):\n        self.active_connections.remove(websocket)\n        log.info(\"WebSocket connection closed.\")\n\n    async def broadcast(self, message: dict):\n        \"\"\"Broadcasts a message to all connected clients.\"\"\"\n        if not self.active_connections:\n            return\n\n        log.info(\n            \"Broadcasting message to connected clients\",\n            client_count=len(self.active_connections),\n        )\n        for connection in self.active_connections:\n            try:\n                await connection.send_json(message)\n            except Exception:\n                log.error(\"Error sending message to a WebSocket client.\", exc_info=True)\n\n\n# Lifespan context manager\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    configure_logging()\n    log.info(\"Uvicorn is online, starting lifespan hook.\")\n\n    # 1. Perform lightweight, non-blocking startup tasks\n    settings = get_settings()\n    await cache_manager.connect(settings.REDIS_URL)\n    log.info(\"Fast, non-blocking startup tasks complete (Redis connected).\")\n\n    # 2. Schedule the heavy, synchronous initialization to run in a background thread\n    loop = asyncio.get_event_loop()\n    loop.run_in_executor(executor, _initialize_heavy_resources_sync, app)\n    log.info(\"Heavy resource initialization has been scheduled in a background thread.\")\n\n    # 3. Wait for the engine to be initialized before yielding control.\n    start_time = time.time()\n    while not hasattr(app.state, \"engine\") or app.state.engine is None:\n        if time.time() - start_time > 30:  # 30-second timeout\n            raise RuntimeError(\"Engine initialization timed out.\")\n        await asyncio.sleep(0.1)\n\n    log.info(\"Engine is initialized. Server is ready to accept requests.\")\n    yield\n\n    # --- Shutdown Sequence ---\n    log.info(\"Server shutdown sequence initiated.\")\n    if hasattr(app.state, \"engine\") and app.state.engine:\n        log.info(\"Closing HTTP client resources.\")\n        await app.state.engine.close()\n\n    await cache_manager.disconnect()\n\n    # Do not shut down the executor in a test environment, as it is shared\n    # across multiple test functions and app instances. Pytest will handle\n    # the process cleanup.\n    settings = get_settings()\n    if not settings.testing:\n        executor.shutdown(wait=False)\n\n    log.info(\"Server shutdown sequence complete.\")\n\n\nlimiter = Limiter(key_func=get_remote_address)\napp = FastAPI(\n    title=\"Fortuna Faucet API\",\n    version=\"2.1\",\n    lifespan=lifespan,\n    docs_url=\"/api/docs\",\n    redoc_url=\"/api/redoc\",\n    openapi_url=\"/api/openapi.json\",\n)\n\napp.add_middleware(SlowAPIMiddleware)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\napp.add_exception_handler(RequestValidationError, validation_exception_handler)\napp.add_exception_handler(UserFriendlyException, user_friendly_exception_handler)\napp.include_router(health_router)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\", \"http://localhost:3001\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\"],\n    allow_headers=[\"*\"],\n)\n\n# --- Robust Pathing for Frozen Executables ---\ndef resource_path(relative_path: str) -> str:\n    \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\n    if getattr(sys, 'frozen', False):\n        # PyInstaller creates a temp folder and stores path in _MEIPASS\n        base_path = sys._MEIPASS\n    else:\n        # In development, the base path is the project root.\n        # This assumes the script is run from the project root.\n        base_path = os.path.abspath(\".\")\n    return os.path.join(base_path, relative_path)\n\n# --- Conditional UI Serving for Web Service Mode ---\nif os.environ.get(\"FORTUNA_MODE\") == \"webservice\":\n    import sys\n    from fastapi.staticfiles import StaticFiles\n    from starlette.responses import FileResponse\n    from starlette.middleware.base import BaseHTTPMiddleware\n\n    log.info(\"Application running in 'webservice' mode, configuring static file serving.\")\n\n    # Use the robust resource_path function to find the 'ui' directory.\n    # The spec file bundles 'staging/ui' into the 'ui' folder in the executable's root.\n    static_dir_key = \"ui\" if getattr(sys, 'frozen', False) else \"staging/ui\"\n    static_files_dir = resource_path(static_dir_key)\n    log.info(\"Resolved static files directory\", path=static_files_dir)\n\n    if not os.path.exists(static_files_dir):\n        log.error(\"Static files directory not found! UI will not be served.\", path=static_files_dir)\n    else:\n        class SpaMiddleware(BaseHTTPMiddleware):\n            async def dispatch(self, request, call_next):\n                response = await call_next(request)\n                if response.status_code == 404 and not request.url.path.startswith('/api'):\n                    index_path = os.path.join(static_files_dir, \"index.html\")\n                    if os.path.exists(index_path):\n                        return FileResponse(index_path)\n                return response\n\n        app.add_middleware(SpaMiddleware)\n\n        app.mount(\"/\", StaticFiles(directory=static_files_dir), name=\"static\")\n\ndef get_engine(request: Request) -> OddsEngine:\n    return request.app.state.engine\n\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"ok\", \"timestamp\": datetime.now().isoformat()}\n\n\n@app.get(\"/api/adapters/status\")\n@limiter.limit(\"60/minute\")\nasync def get_all_adapter_statuses(\n    request: Request,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        return engine.get_all_adapter_statuses()\n    except Exception:\n        log.error(\"Error in /api/adapters/status\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@app.get(\"/api/races/qualified/{analyzer_name}\", response_model=QualifiedRacesResponse)\n@limiter.limit(\"120/minute\")\nasync def get_qualified_races(\n    analyzer_name: str,\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n    max_field_size: int = Query(10, ge=3, le=20),\n    min_favorite_odds: float = Query(2.5, ge=1.0, le=100.0),\n    min_second_favorite_odds: float = Query(4.0, ge=1.0, le=100.0),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        aggregated_data = await engine.fetch_all_odds(date_str)\n        races = [Race(**r) for r in aggregated_data.get(\"races\", [])]\n        analyzer_engine = request.app.state.analyzer_engine\n        custom_params = {\n            \"max_field_size\": max_field_size,\n            \"min_favorite_odds\": min_favorite_odds,\n            \"min_second_favorite_odds\": min_second_favorite_odds,\n        }\n        analyzer = analyzer_engine.get_analyzer(analyzer_name, **custom_params)\n        result = analyzer.qualify_races(races)\n        return QualifiedRacesResponse(**result)\n    except ValueError as e:\n        log.warning(\"Requested analyzer not found\", analyzer_name=analyzer_name)\n        raise HTTPException(status_code=404, detail=str(e))\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(\"Error in /api/races/qualified\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\n@app.get(\"/api/races/filter-suggestions\")\nasync def get_filter_suggestions(engine: OddsEngine = Depends(get_engine)):\n    try:\n        date_str = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n        aggregated = await engine.fetch_all_odds(date_str)\n        if not aggregated or not aggregated.get(\"races\"):\n            return {\"suggestions\": {}}\n        field_sizes = [len(r[\"runners\"]) for r in aggregated[\"races\"]]\n        favorite_odds, second_favorite_odds = [], []\n        for race_data in aggregated[\"races\"]:\n            race = Race(**race_data)\n            runners = race.runners\n            if len(runners) >= 2:\n                odds_list = []\n                for runner in runners:\n                    if not runner.scratched and runner.odds:\n                        best_odd = min(\n                            (o.win for o in runner.odds.values() if o.win is not None),\n                            default=None,\n                        )\n                        if best_odd is not None:\n                            odds_list.append(float(best_odd))\n                if len(odds_list) >= 2:\n                    odds_list.sort()\n                    favorite_odds.append(odds_list[0])\n                    second_favorite_odds.append(odds_list[1])\n        return {\n            \"suggestions\": {\n                \"max_field_size\": {\"recommended\": (int(sum(field_sizes) / len(field_sizes)) if field_sizes else 10)},\n                \"min_favorite_odds\": {\"recommended\": 2.5},\n                \"min_second_favorite_odds\": {\"recommended\": 4.0},\n            }\n        }\n    except Exception:\n        log.error(\"Error generating filter suggestions\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Failed to generate suggestions\")\n\n\n@app.get(\"/api/races/source/{source_name}\", response_model=AggregatedResponse)\n@limiter.limit(\"60/minute\")\nasync def get_races_by_source(\n    source_name: str,\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        return await engine.fetch_all_odds(date_str, source=source_name)\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(f\"Error in /api/races/source/{source_name}\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\n@app.get(\"/api/races\", response_model=AggregatedResponse)\n@limiter.limit(\"30/minute\")\nasync def get_races(\n    request: Request,\n    race_date: Optional[date] = Query(\n        default=None,\n        description=\"Date of the races in YYYY-MM-DD format. Defaults to today.\",\n    ),\n    source: Optional[str] = None,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    try:\n        date_obj = race_date or datetime.now().date()\n        date_str = date_obj.strftime(\"%Y-%m-%d\")\n        return await engine.fetch_all_odds(date_str, source)\n    except (AdapterHttpError, AdapterConfigError) as e:\n        raise UserFriendlyException(error_key=e.__class__.__name__, details=str(e))\n    except Exception:\n        log.error(\"Error in /api/races\", exc_info=True)\n        raise UserFriendlyException(error_key=\"default\")\n\n\nDB_PATH = \"fortuna.db\"\n\n\ndef get_current_date() -> date:\n    return datetime.now().date()\n\n\n@app.get(\"/api/tipsheet\", response_model=List[TipsheetRace])\n@limiter.limit(\"30/minute\")\nasync def get_tipsheet_endpoint(request: Request, date: date = Depends(get_current_date)):\n    results = []\n    try:\n        async with aiosqlite.connect(DB_PATH) as db:\n            db.row_factory = aiosqlite.Row\n            query = \"SELECT * FROM tipsheet WHERE date(post_time) = ? ORDER BY post_time ASC\"\n            async with db.execute(query, (date.isoformat(),)) as cursor:\n                async for row in cursor:\n                    results.append(dict(row))\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return results\n\n\n# API Models\nclass ManualDataSubmission(BaseModel):\n    request_id: str\n    content: str\n    content_type: str = \"html\"\n\n\n# New endpoints\n@app.get(\"/api/manual-overrides/pending\")\n@limiter.limit(\"60/minute\")\nasync def get_pending_overrides(\n    request: Request,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Get all pending manual override requests\"\"\"\n    pending = manager.get_pending_requests()\n    return {\"pending_requests\": [req.model_dump() for req in pending]}\n\n\n@app.post(\"/api/manual-overrides/submit\")\n@limiter.limit(\"30/minute\")\nasync def submit_manual_data(\n    request: Request,\n    submission: ManualDataSubmission,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Submit manually-provided data for a failed fetch\"\"\"\n    success = manager.submit_manual_data(\n        request_id=submission.request_id,\n        raw_content=submission.content,\n        content_type=submission.content_type,\n    )\n\n    if success:\n        return {\"status\": \"success\", \"message\": \"Manual data submitted\"}\n    else:\n        raise HTTPException(status_code=404, detail=\"Request not found\")\n\n\n@app.post(\"/api/manual-overrides/skip/{request_id}\")\n@limiter.limit(\"60/minute\")\nasync def skip_manual_override(\n    request: Request,\n    request_id: str,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Skip a manual override request\"\"\"\n    success = manager.skip_request(request_id)\n\n    if success:\n        return {\"status\": \"success\", \"message\": \"Request skipped\"}\n    else:\n        raise HTTPException(status_code=404, detail=\"Request not found\")\n\n\n@app.post(\"/api/manual-overrides/cleanup\")\n@limiter.limit(\"60/minute\")\nasync def cleanup_old_overrides(\n    request: Request,\n    max_age_hours: int = 24,\n    api_key: str = Depends(verify_api_key),\n    manager: ManualOverrideManager = Depends(lambda: app.state.manual_override_manager),\n):\n    \"\"\"Clean up old manual override requests\"\"\"\n    manager.clear_old_requests(max_age_hours)\n    return {\"status\": \"success\", \"message\": \"Old requests cleaned\"}\n\n\n@app.websocket(\"/ws/live-updates\")\nasync def websocket_endpoint(websocket: WebSocket, api_key: str = Query(...)):\n    \"\"\"WebSocket endpoint for live race updates.\"\"\"\n    try:\n        # Use the existing API key verification logic\n        # This is a synchronous call, which is fine for auth at the start.\n        # In a real-world scenario with high connection rates, you might\n        # want to make this check asynchronous if it involved I/O.\n        verify_api_key(api_key)\n    except HTTPException as e:\n        log.warning(\"WebSocket connection rejected due to invalid API key.\")\n        await websocket.close(code=4001, reason=f\"Authentication failed: {e.detail}\")\n        return\n\n    manager = websocket.app.state.connection_manager\n    await manager.connect(websocket)\n    try:\n        # Keep the connection alive, listening for messages (if any)\n        while True:\n            # You could implement logic here to handle incoming messages if needed\n            # For now, it's just a broadcast-only connection\n            await websocket.receive_text()\n    except WebSocketDisconnect:\n        manager.disconnect(websocket)\n        log.info(\"Client disconnected from WebSocket.\")\n\n\n@app.post(\"/api/races/parse-manual\", response_model=List[Race])\n@limiter.limit(\"30/minute\")\nasync def parse_manual_html(\n    request: Request,\n    parse_request: ManualParseRequest,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n):\n    \"\"\"\n    Manually parses a block of HTML using a specified adapter.\n    \"\"\"\n    try:\n        adapter = engine.get_adapter(parse_request.adapter_name)\n        if not adapter:\n            raise HTTPException(\n                status_code=404,\n                detail=f\"Adapter '{parse_request.adapter_name}' not found.\",\n            )\n\n        # The _parse_races method is synchronous, so we run it in a thread\n        # to avoid blocking the asyncio event loop.\n        loop = asyncio.get_event_loop()\n        parsed_races_data = await loop.run_in_executor(executor, adapter._parse_races, parse_request.html_content)\n\n        # Validate the parsed data with the Race model\n        validated_races = [Race(**race_data) for race_data in parsed_races_data]\n        return validated_races\n\n    except Exception as e:\n        log.error(\"Error during manual parsing\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n",
    "python_service/cache_manager.py": "# python_service/cache_manager.py\nimport asyncio\nimport hashlib\nimport json\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom functools import wraps\nfrom typing import Any\nfrom typing import Callable\n\nimport structlog\n\ntry:\n    import redis\n\n    REDIS_AVAILABLE = True\nexcept ImportError:\n    REDIS_AVAILABLE = False\n\nlog = structlog.get_logger(__name__)\n\n\nclass CacheManager:\n    def __init__(self):\n        self.redis_client = None\n        self.memory_cache = {}\n        self.is_configured = False\n        log.info(\"CacheManager initialized (not connected).\")\n\n    async def connect(self, redis_url: str):\n        if self.is_configured or not REDIS_AVAILABLE or not redis_url:\n            return\n\n        try:\n            log.info(\"Attempting to connect to Redis...\", url=redis_url)\n            # Use the async version of the client\n            self.redis_client = redis.asyncio.from_url(redis_url, decode_responses=True)\n            await self.redis_client.ping()  # Verify connection asynchronously\n            self.is_configured = True\n            log.info(\"Redis cache connected successfully.\")\n        except (redis.exceptions.ConnectionError, asyncio.TimeoutError) as e:\n            log.warning(\n                \"Failed to connect to Redis. Falling back to in-memory cache.\",\n                error=str(e),\n            )\n            self.redis_client = None\n            self.is_configured = False\n\n    async def disconnect(self):\n        if self.redis_client:\n            await self.redis_client.close()\n            log.info(\"Redis connection closed.\")\n\n    def _generate_key(self, prefix: str, *args, **kwargs) -> str:\n        key_data = f\"{prefix}:{args}:{sorted(kwargs.items())}\"\n        return hashlib.md5(key_data.encode()).hexdigest()\n\n    async def get(self, key: str) -> Any | None:\n        if self.redis_client:\n            try:\n                value = await self.redis_client.get(key)\n                return json.loads(value) if value else None\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis GET failed, falling back to memory cache.\", error=e)\n\n        entry = self.memory_cache.get(key)\n        if entry and entry.get(\"expires_at\", datetime.min) > datetime.now():\n            return entry.get(\"value\")\n        return None\n\n    async def set(self, key: str, value: Any, ttl_seconds: int = 300):\n        try:\n            serialized = json.dumps(value, default=str)\n        except (TypeError, ValueError) as e:\n            log.error(\"Failed to serialize value for caching.\", value=value, error=str(e))\n            return\n\n        if self.redis_client:\n            try:\n                await self.redis_client.setex(key, ttl_seconds, serialized)\n                return\n            except redis.exceptions.RedisError as e:\n                log.warning(\"Redis SET failed, falling back to memory cache.\", error=e)\n\n        self.memory_cache[key] = {\n            \"value\": value,\n            \"expires_at\": datetime.now() + timedelta(seconds=ttl_seconds),\n        }\n\n\n# --- Singleton Instance & Decorator ---\ncache_manager = CacheManager()\n\n\ndef cache_async_result(ttl_seconds: int = 300, key_prefix: str = \"cache\"):\n    def decorator(func: Callable):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            instance_args = args[1:] if args and hasattr(args[0], func.__name__) else args\n            cache_key = cache_manager._generate_key(f\"{key_prefix}:{func.__name__}\", *instance_args, **kwargs)\n\n            cached_result = await cache_manager.get(cache_key)\n            if cached_result is not None:\n                log.debug(\"Cache hit\", function=func.__name__)\n                return cached_result\n\n            log.debug(\"Cache miss\", function=func.__name__)\n            result = await func(*args, **kwargs)\n\n            try:\n                await cache_manager.set(cache_key, result, ttl_seconds)\n            except Exception as e:\n                log.error(\"Failed to store result in cache.\", error=str(e), key=cache_key)\n\n            return result\n\n        return wrapper\n\n    return decorator\n",
    "python_service/credentials_manager.py": "# python_service/credentials_manager.py\ntry:\n    import keyring\n\n    # This check is crucial for cross-platform compatibility\n    import keyring.backends.windows\n\n    IS_WINDOWS = True\nexcept ImportError:\n    keyring = None\n    IS_WINDOWS = False\n\n\nclass SecureCredentialsManager:\n    \"\"\"Manages secrets in the system's native credential store.\"\"\"\n\n    SERVICE_NAME = \"Fortuna\"\n\n    @staticmethod\n    def save_credential(account: str, secret: str) -> bool:\n        \"\"\"Saves a secret for a given account (e.g., 'api_key', 'betfair_username').\"\"\"\n        if not IS_WINDOWS:\n            print(\"Credential storage is only supported on Windows.\")\n            return False\n        try:\n            keyring.set_password(SecureCredentialsManager.SERVICE_NAME, account, secret)\n            return True\n        except Exception as e:\n            print(f\"\u274c Failed to save credential for {account}: {e}\")\n            return False\n\n    @staticmethod\n    def get_credential(account: str) -> str:\n        \"\"\"Retrieves a secret for a given account.\"\"\"\n        if not IS_WINDOWS:\n            return None\n        try:\n            return keyring.get_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception as e:\n            print(f\"\u274c Failed to retrieve credential for {account}: {e}\")\n            return None\n\n    @staticmethod\n    def get_betfair_credentials() -> tuple[str, str]:\n        \"\"\"Convenience method to retrieve both Betfair username and password.\"\"\"\n        username = SecureCredentialsManager.get_credential(\"betfair_username\")\n        password = SecureCredentialsManager.get_credential(\"betfair_password\")\n        return username, password\n\n    @staticmethod\n    def delete_credential(account: str):\n        \"\"\"Deletes a specific credential.\"\"\"\n        if not IS_WINDOWS:\n            return\n        try:\n            keyring.delete_password(SecureCredentialsManager.SERVICE_NAME, account)\n        except Exception:\n            pass\n",
    "python_service/fortuna_windows_service.py": "# fortuna_windows_service.py\n\nimport logging\nimport os\nimport sys\n\nimport servicemanager\nimport win32event\nimport win32service\nimport win32serviceutil\n\n# Ensure the script's directory is at the front of the path\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.insert(0, script_dir)\n\ntry:\n    from fortuna_service import FortunaBackgroundService\nexcept ImportError as e:\n    # Log a detailed error to the Windows Event Log if the import fails\n    servicemanager.LogErrorMsg(f\"FATAL: Could not import FortunaBackgroundService. Error: {e}\")\n    sys.exit(1)  # Exit with an error code\n\n\nclass FortunaWindowsService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaV8Service\"\n    _svc_display_name_ = \"Fortuna V8 Racing Analysis Service\"\n    _svc_description_ = \"Continuously fetches and analyzes horse racing data.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)\n        self.fortuna_service = FortunaBackgroundService()\n        # Configure logging to use the Windows Event Log\n        logging.basicConfig(\n            level=logging.INFO,\n            format=\"%(name)s - %(levelname)s - %(message)s\",\n            handlers=[servicemanager.LogHandler()],\n        )\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        self.fortuna_service.stop()\n        win32event.SetEvent(self.hWaitStop)\n        self.ReportServiceStatus(win32service.SERVICE_STOPPED)\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(\n            servicemanager.EVENTLOG_INFORMATION_TYPE,\n            servicemanager.PYS_SERVICE_STARTED,\n            (self._svc_name_, \"\"),\n        )\n        self.main()\n\n    def main(self):\n        self.fortuna_service.start()\n        win32event.WaitForSingleObject(self.hWaitStop, win32event.INFINITE)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaWindowsService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaWindowsService)\n",
    "python_service/main.py": "import uvicorn\nimport sys\nimport os\nimport asyncio\nfrom multiprocessing import freeze_support\n\n# Force UTF-8 encoding for stdout and stderr, crucial for PyInstaller on Windows\nos.environ[\"PYTHONUTF8\"] = \"1\"\n\n# Import the 'app' object at the top level to make it accessible for import by other modules,\n# such as diagnostic scripts in CI/CD.\nfrom python_service.api import app, HTTPException\n\n# This is the definitive entry point for the Fortuna Faucet backend service.\n# It is designed to be compiled with PyInstaller.\n\n\ndef _configure_sys_path():\n    \"\"\"\n    Dynamically adds project paths to sys.path.\n    This is the robust solution to ensure that string-based imports like\n    \"web_service.backend.api:app\" work correctly when the application is\n    run from a PyInstaller executable. The `_MEIPASS` attribute is a temporary\n    directory created by PyInstaller at runtime.\n    \"\"\"\n    if getattr(sys, \"frozen\", False) and hasattr(sys, \"_MEIPASS\"):\n        # Running in a PyInstaller bundle. The project root is the _MEIPASS directory.\n        project_root = os.path.abspath(sys._MEIPASS)\n\n        # Aggressively add paths to resolve potential module lookup issues in frozen mode.\n        paths_to_add = [\n            project_root,\n            os.path.join(project_root, \"python_service\"),\n        ]\n\n        # Insert paths at the beginning of sys.path in reverse order\n        # to maintain the desired precedence.\n        for path in reversed(paths_to_add):\n            if path not in sys.path:\n                sys.path.insert(0, path)\n                print(f\"INFO: Added path to sys.path: {path}\")\n\n    else:\n        # Running as a normal script. The project root is one level up.\n        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n        if project_root not in sys.path:\n            sys.path.insert(0, project_root)\n            print(f\"INFO: Added project root to sys.path: {project_root}\")\n\n\ndef main():\n    \"\"\"\n    Primary entry point for the Fortuna Faucet backend application.\n    This function configures and runs the Uvicorn server.\n    It's crucial to launch the app this way to ensure PyInstaller's bootloader\n    can correctly resolve the package context.\n    \"\"\"\n    # CRITICAL: This must be called before any other application imports.\n    _configure_sys_path()\n\n    # When packaged, we need to ensure multiprocessing works correctly.\n    if getattr(sys, \"frozen\", False):\n        # CRITICAL for multiprocessing support in frozen mode on Windows.\n        freeze_support()\n\n        # \u2705 CRITICAL FIX: Set event loop policy BEFORE any imports that use asyncio\n        if sys.platform == \"win32\":\n            import asyncio\n            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n            print(\"[BOOT] \u2705 Applied WindowsSelectorEventLoopPolicy for PyInstaller\", file=sys.stderr)\n\n    from python_service.config import get_settings\n    from fastapi.staticfiles import StaticFiles\n    from fastapi.responses import FileResponse\n    from python_service.port_check import check_port_and_exit_if_in_use\n\n    settings = get_settings()\n\n    # --- Port Sanity Check ---\n    # Before doing anything else, ensure the target port is not already in use.\n    # This prevents a common and confusing crash scenario on startup.\n    check_port_and_exit_if_in_use(settings.FORTUNA_PORT, settings.UVICORN_HOST)\n\n    # --- Conditional UI Serving for Web Service Mode ---\n    # Only serve the UI if the FORTUNA_MODE environment variable is set to 'webservice'.\n    # This prevents the Electron-packaged backend from trying to serve files it doesn't have.\n    if os.environ.get(\"FORTUNA_MODE\") == \"webservice\":\n        # Define the path to the static UI files, accommodating PyInstaller's bundle.\n        if getattr(sys, \"frozen\", False):\n            # In a bundled app, the UI files are in the '_MEIPASS/ui' directory.\n            STATIC_DIR = os.path.join(sys._MEIPASS, \"ui\")\n        else:\n            # In development, they are in the frontend's output directory.\n            STATIC_DIR = os.path.abspath(\n                os.path.join(os.path.dirname(__file__), \"..\", \"web_platform\", \"frontend\", \"out\")\n            )\n\n        # Mount the static assets directory for CSS, JS, etc.\n        if os.path.exists(os.path.join(STATIC_DIR, \"_next\")):\n            app.mount(\"/_next\", StaticFiles(directory=os.path.join(STATIC_DIR, \"_next\")), name=\"next\")\n\n        # Serve the main index.html for any non-API path.\n        @app.get(\"/{full_path:path}\", include_in_schema=False)\n        async def serve_frontend(full_path: str):\n            if full_path.startswith(\"api/\") or full_path.startswith(\"docs\") or full_path == \"health\":\n                # This is an API route, let FastAPI handle it.\n                # A 404 will be raised naturally if no route matches.\n                return\n\n            index_path = os.path.join(STATIC_DIR, \"index.html\")\n            if os.path.exists(index_path):\n                return FileResponse(index_path)\n            else:\n                # This will only be hit if the frontend files are missing entirely.\n                raise HTTPException(\n                    status_code=404,\n                    detail=\"Frontend not found. Please build the frontend and ensure it's in the correct location.\",\n                )\n\n    uvicorn.run(app, host=settings.UVICORN_HOST, port=settings.FORTUNA_PORT, log_level=\"info\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "python_service/models_v3.py": "# python_service/models_v3.py\n# Defines the data structures for the V3 adapter architecture.\n\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import List\n\n\n@dataclass\nclass NormalizedRunner:\n    runner_id: str\n    name: str\n    saddle_cloth: str\n    odds_decimal: float\n\n\n@dataclass\nclass NormalizedRace:\n    race_key: str\n    track_key: str\n    start_time_iso: str\n    race_name: str\n    runners: List[NormalizedRunner] = field(default_factory=list)\n    source_ids: List[str] = field(default_factory=list)\n",
    "python_service/requirements-x86.txt": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile --output-file=python_service/requirements.txt python_service/requirements.in\n#\n--only-binary=:all:\naiosqlite==0.21.0\n    # via -r python_service/requirements.in\naltgraph==0.17.4\n    # via pyinstaller\nannotated-doc==0.0.4\n    # via fastapi\nannotated-types==0.7.0\n    # via pydantic\nanyio==4.11.0\n    # via\n    #   httpx\n    #   starlette\nbeautifulsoup4==4.14.2\n    # via -r python_service/requirements.in\nblack==25.11.0\n    # via -r python_service/requirements.in\nbuild==1.3.0\n    # via pip-tools\ncertifi==2025.10.5\n    # via\n    #   -r python_service/requirements.in\n    #   httpcore\n    #   httpx\n    #   requests\ncffi==2.0.0\n    # via cryptography\ncharset-normalizer==3.4.4\n    # via requests\nclick==8.3.0\n    # via\n    #   black\n    #   pip-tools\n    #   uvicorn\ncryptography==46.0.3\n    # via\n    #   -r python_service/requirements.in\n    #   secretstorage\ndeprecated==1.3.1\n    # via limits\nfastapi==0.121.1\n    # via -r python_service/requirements.in\ngreenlet\n    # via sqlalchemy\n    # Version pin removed to allow pip to resolve a compatible version for x86 builds.\nh11==0.16.0\n    # via\n    #   httpcore\n    #   uvicorn\nh2==4.3.0\n    # via httpx\nhpack==4.1.0\n    # via h2\nhttpcore==1.0.9\n    # via httpx\nhttpx[http2]==0.28.1\n    # via -r python_service/requirements.in\nhyperframe==6.1.0\n    # via h2\nidna==3.11\n    # via\n    #   anyio\n    #   httpx\n    #   requests\niniconfig==2.3.0\n    # via pytest\njaraco-classes==3.4.0\n    # via keyring\njaraco-context==6.0.1\n    # via keyring\njaraco-functools==4.3.0\n    # via keyring\njeepney==0.9.0\n    # via\n    #   keyring\n    #   secretstorage\nkeyring==25.6.0\n    # via -r python_service/requirements.in\nlimits==5.6.0\n    # via slowapi\nmore-itertools==10.8.0\n    # via\n    #   jaraco-classes\n    #   jaraco-functools\nmypy-extensions==1.1.0\n    # via black\nnumpy==2.3.4\n    # via\n    #   -r python_service/requirements.in\n    #   pandas\n    #   scipy\npackaging==25.0\n    # via\n    #   black\n    #   build\n    #   limits\n    #   pyinstaller\n    #   pyinstaller-hooks-contrib\n    #   pytest\npandas==2.3.3\n    # via -r python_service/requirements.in\npathspec==0.12.1\n    # via black\npip-tools==7.5.1\n    # via -r python_service/requirements.in\nplatformdirs==4.5.0\n    # via black\npluggy==1.6.0\n    # via pytest\npsutil==7.1.3\n    # via -r python_service/requirements.in\npsycopg2-binary==2.9.11\n    # via -r python_service/requirements.in\npycparser==2.23\n    # via cffi\npydantic==2.12.4\n    # via\n    #   fastapi\n    #   pydantic-settings\npydantic-core==2.41.5\n    # via pydantic\npydantic-settings==2.12.0\n    # via -r python_service/requirements.in\npygments==2.19.2\n    # via pytest\npyinstaller==6.6.0\n    # via -r python_service/requirements.in\npyinstaller-hooks-contrib==2025.9\n    # via pyinstaller\npyproject-hooks==1.2.0\n    # via\n    #   build\n    #   pip-tools\npytest==9.0.0\n    # via\n    #   -r python_service/requirements.in\n    #   pytest-asyncio\npytest-asyncio==1.3.0\n    # via -r python_service/requirements.in\npython-dateutil==2.9.0.post0\n    # via pandas\npython-dotenv==1.2.1\n    # via pydantic-settings\npytokens==0.3.0\n    # via black\npytz==2025.2\n    # via pandas\nredis==7.0.1\n    # via -r python_service/requirements.in\nrequests==2.32.5\n    # via -r python_service/requirements.in\nscipy==1.16.3\n    # via -r python_service/requirements.in\nsecretstorage==3.4.1\n    # via keyring\nselectolax==0.4.0\n    # via -r python_service/requirements.in\nsix==1.17.0\n    # via python-dateutil\nslowapi==0.1.9\n    # via -r python_service/requirements.in\nsniffio==1.3.1\n    # via anyio\nsoupsieve==2.8\n    # via beautifulsoup4\nsqlalchemy==2.0.44\n    # via -r python_service/requirements.in\nstarlette==0.49.3\n    # via fastapi\nstructlog==25.5.0\n    # via -r python_service/requirements.in\ntenacity==8.5.0\n    # via -r python_service/requirements.in\ntyping-extensions==4.15.0\n    # via\n    #   aiosqlite\n    #   anyio\n    #   beautifulsoup4\n    #   fastapi\n    #   limits\n    #   pydantic\n    #   pydantic-core\n    #   pytest-asyncio\n    #   sqlalchemy\n    #   starlette\n    #   typing-inspection\ntyping-inspection==0.4.2\n    # via\n    #   pydantic\n    #   pydantic-settings\ntzdata==2025.2\n    # via pandas\nurllib3>=2.6.0\n    # via\n    #   -r python_service/requirements.in\n    #   requests\nuvicorn==0.30.1\n    # via -r python_service/requirements.in\nwheel==0.45.1\n    # via\n    #   -r python_service/requirements.in\n    #   pip-tools\nwrapt==2.0.1\n    # via deprecated\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools\n",
    "python_service/requirements.in": "#\n# Fortuna Faucet - High-Level Backend Dependencies\n# This is the source of truth. Run 'pip-compile' to generate requirements.txt.\n#\n\n# --- Core Application Framework (Hard Pins) ---\nfastapi\nuvicorn==0.30.1\ncryptography\n\n# --- Core Application Dependencies (Flexible) ---\ntenacity\npydantic-settings\nhttpx[http2]\nselectolax==0.4.0\nbeautifulsoup4\nslowapi\nredis\npandas\nnumpy\nscipy\naiosqlite\nSQLAlchemy\npsycopg2-binary\nstructlog\ncertifi\n\n# --- Desktop & OS Integration (Flexible) ---\npsutil\npywin32 ; sys_platform == 'win32'\nwindows-toasts ; sys_platform == 'win32'\nkeyring\npynput ; sys_platform == 'win32'\n\n# --- Development & Testing Dependencies ---\npytest\npytest-asyncio\nblack\n\n# --- Build Dependencies (Hard Pins) ---\n# THE FIX: Upgraded to 6.6.0 for official Python 3.12 support.\npyinstaller==6.6.0\nwheel\nsetuptools>=78.1.1,<81\npip-tools\nrequests>=2.32.4\nurllib3>=2.5.0\n",
    "python_service/security.py": "# python_service/security.py\n\nimport secrets\n\nfrom fastapi import Depends\nfrom fastapi import HTTPException\nfrom fastapi import Security\nfrom fastapi import status\nfrom fastapi.security import APIKeyHeader\n\nfrom .config import Settings\nfrom .config import get_settings\n\nAPI_KEY_NAME = \"X-API-Key\"\napi_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)\n\n\nasync def verify_api_key(key: str = Security(api_key_header), settings: Settings = Depends(get_settings)):\n    \"\"\"\n    Verifies the provided API key against the one in settings using a\n    timing-attack resistant comparison.\n    \"\"\"\n    if secrets.compare_digest(key, settings.API_KEY):\n        return True\n    else:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Invalid or missing API Key\")\n",
    "python_service/utils/text.py": "# python_service/utils/text.py\n# Centralized text and name normalization utilities\nimport re\nfrom typing import Optional\n\n\ndef clean_text(text: Optional[str]) -> Optional[str]:\n    \"\"\"Strips leading/trailing whitespace and collapses internal whitespace.\"\"\"\n    if not text:\n        return None\n    return \" \".join(text.strip().split())\n\n\ndef normalize_venue_name(name: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Normalizes a UK or Irish racecourse name to a standard format.\n    Handles common abbreviations and variations.\n    \"\"\"\n    if not name:\n        return None\n\n    # Use a temporary variable for matching, but return the properly cased name\n    cleaned_name_upper = clean_text(name).upper()\n\n    VENUE_MAP = {\n        \"ASCOT\": \"Ascot\",\n        \"AYR\": \"Ayr\",\n        \"BANGOR-ON-DEE\": \"Bangor-on-Dee\",\n        \"CATTERICK BRIDGE\": \"Catterick\",\n        \"CHELMSFORD CITY\": \"Chelmsford\",\n        \"EPSOM DOWNS\": \"Epsom\",\n        \"FONTWELL\": \"Fontwell Park\",\n        \"HAYDOCK\": \"Haydock Park\",\n        \"KEMPTON\": \"Kempton Park\",\n        \"LINGFIELD\": \"Lingfield Park\",\n        \"NEWMARKET (ROWLEY)\": \"Newmarket\",\n        \"NEWMARKET (JULY)\": \"Newmarket\",\n        \"SANDOWN\": \"Sandown Park\",\n        \"STRATFORD\": \"Stratford-on-Avon\",\n        \"YARMOUTH\": \"Great Yarmouth\",\n        \"CURRAGH\": \"Curragh\",\n        \"DOWN ROYAL\": \"Down Royal\",\n    }\n\n    # Check primary map first\n    if cleaned_name_upper in VENUE_MAP:\n        return VENUE_MAP[cleaned_name_upper]\n\n    # Handle cases where the key is the desired output but needs to be mapped from a variation\n    # e.g. CHELMSFORD maps to Chelmsford\n    # Title case the cleaned name for a sensible default\n    title_cased_name = clean_text(name).title()\n    if title_cased_name in VENUE_MAP.values():\n        return title_cased_name\n\n    # Return the title-cased cleaned name as a fallback\n    return title_cased_name\n\n\ndef normalize_course_name(name: str) -> str:\n    if not name:\n        return \"\"\n    name = name.lower().strip()\n    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s-]+\", \"_\", name)\n    return name\n",
    "scripts/get_api_key.py": "# scripts/get_api_key.py\nimport os\nimport sys\n\n# This is a workaround to ensure the script can find the python_service module,\n# especially when run from the packaged Electron app.\n# It assumes this script is in `resources/app/scripts` and the service is in `resources/app/python_service`.\ntry:\n    # Get the directory of the current script.\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    # Go up one level to the `app` directory and add `python_service` to the path.\n    project_root = os.path.dirname(script_dir)\n    sys.path.append(project_root)\n    from python_service.credentials_manager import SecureCredentialsManager\nexcept ImportError as e:\n    # If the import fails, write the error to stderr and exit.\n    # This helps in debugging path issues in the production environment.\n    print(\n        f\"Error: Failed to import SecureCredentialsManager. Details: {e}\",\n        file=sys.stderr,\n    )\n    sys.exit(1)\n\n\ndef retrieve_and_print_key():\n    \"\"\"\n    Retrieves the API key using the SecureCredentialsManager and prints it to stdout.\n    If the key is not found, it prints an empty string.\n    If an error occurs, it prints the error to stderr.\n    \"\"\"\n    try:\n        api_key = SecureCredentialsManager.get_api_key()\n        if api_key:\n            print(api_key, end=\"\")  # Print the key directly to stdout\n        else:\n            print(\"\", end=\"\")  # Print empty string if no key is found\n    except Exception as e:\n        print(f\"An error occurred while retrieving the API key: {e}\", file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    retrieve_and_print_key()\n",
    "scripts/uninstall_fortuna.bat": "@echo off\nREM Complete removal of Fortuna Faucet\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\necho WARNING: This will remove Fortuna Faucet completely.\nset /p confirm=\"Are you sure? (y/N): \"\n\nif /i not \"%confirm%\"==\"y\" exit /b 0\n\nREM Find and remove MSI by UpgradeCode\nfor /f \"tokens=2 delims=\" %%A in ('wmic product where \"Name like 'Fortuna Faucet%%'\" get IdentifyingNumber /value') do (\n    for /f \"tokens=2 delims==\" %%B in (\"%%A\") do (\n        msiexec.exe /x %%B /qn /l*v \"%TEMP%\\fortuna_uninstall.log\"\n    )\n)\n\nREM Clean up directories\nif exist \"%PROGRAMFILES%\\Fortuna Faucet\" rmdir /s /q \"%PROGRAMFILES%\\Fortuna Faucet\" 2>nul\nif exist \"%APPDATA%\\Fortuna Faucet\" rmdir /s /q \"%APPDATA%\\Fortuna Faucet\" 2>nul\n\necho Uninstall complete.",
    "web_platform/frontend/app/layout.tsx": "// web_platform/frontend/app/layout.tsx\nimport './globals.css';\nimport type { Metadata } from 'next';\nimport { Inter } from 'next/font/google';\nimport Providers from './Providers';\n\nconst inter = Inter({ subsets: ['latin'] });\n\nexport const metadata: Metadata = {\n  title: 'Fortuna',\n  description: 'Real-time horse racing analysis.',\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={`${inter.className} bg-white text-gray-900 dark:bg-gray-900 dark:text-gray-100`}>\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}",
    "web_platform/frontend/package.json": "{\n  \"name\": \"frontend\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n  \"scripts\": {\n    \"dev\": \"next dev\",\n    \"build\": \"next build\",\n    \"start\": \"next start\"\n  },\n  \"dependencies\": {\n    \"@tanstack/react-query\": \"^5.28.9\",\n    \"file-saver\": \"^2.0.5\",\n    \"lucide-react\": \"^0.548.0\",\n    \"next\": \"^14.2.33\",\n    \"react\": \"^18\",\n    \"react-dom\": \"^18\",\n    \"socket.io-client\": \"^4.7.4\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20\",\n    \"@types/react\": \"^18\",\n    \"@types/react-dom\": \"^18\",\n    \"autoprefixer\": \"^10.0.1\",\n    \"file-saver\": \"^2.0.5\",\n    \"next-pwa\": \"^5.6.0\",\n    \"postcss\": \"^8\",\n    \"tailwindcss\": \"^3.3.0\",\n    \"typescript\": \"^5\"\n  }\n}\n",
    "web_platform/frontend/src/components/AdapterStatusPanel.tsx": "// web_platform/frontend/src/components/AdapterStatusPanel.tsx\n'use client';\n\nimport React from 'react';\nimport { SourceInfo } from '../types/racing';\n\ninterface AdapterStatusPanelProps {\n  adapter: SourceInfo;\n  onFetchRaces: (sourceName: string) => void;\n}\n\nexport const AdapterStatusPanel: React.FC<AdapterStatusPanelProps> = ({ adapter, onFetchRaces }) => {\n  const isConfigured = adapter.status !== 'CONFIG_ERROR';\n\n  return (\n    <div className={`p-4 rounded-lg border ${isConfigured ? 'bg-slate-800 border-slate-700' : 'bg-yellow-900/20 border-yellow-700/50'}`}>\n      <div className=\"flex justify-between items-center\">\n        <h3 className=\"font-bold text-lg text-white\">{adapter.name}</h3>\n        <span className={`px-2 py-0.5 rounded-full text-xs font-medium ${isConfigured ? 'bg-green-500/20 text-green-300' : 'bg-yellow-500/20 text-yellow-300'}`}>\n          {isConfigured ? 'Ready' : 'Not Configured'}\n        </span>\n      </div>\n      <div className=\"mt-4 flex gap-2\">\n        <button\n          onClick={() => onFetchRaces(adapter.name)}\n          disabled={!isConfigured}\n          className=\"flex-1 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 disabled:bg-slate-700 disabled:text-slate-400 disabled:cursor-not-allowed\"\n        >\n          Automatic Load\n        </button>\n        <button\n          disabled\n          className=\"flex-1 px-4 py-2 bg-slate-700 text-slate-400 rounded cursor-not-allowed\"\n        >\n          Manual Entry (Coming Soon)\n        </button>\n      </div>\n    </div>\n  );\n};\n",
    "web_platform/frontend/src/components/ManualOverridePanel.tsx": "// web_platform/frontend/src/components/ManualOverridePanel.tsx\nimport React, { useState } from 'react';\nimport { Race } from '../types/racing';\n\ninterface ManualOverridePanelProps {\n  adapterName: string;\n  attemptedUrl: string;\n  apiKey: string | null;\n  onParseSuccess: (adapterName: string, parsedRaces: Race[]) => void;\n}\n\nconst ManualOverridePanel: React.FC<ManualOverridePanelProps> = ({\n  adapterName,\n  attemptedUrl,\n  apiKey,\n  onParseSuccess,\n}) => {\n  const [showPanel, setShowPanel] = useState(true);\n  const [htmlContent, setHtmlContent] = useState('');\n  const [isSubmitting, setIsSubmitting] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  const handleSubmit = async () => {\n    if (!htmlContent.trim()) {\n      setError('HTML content cannot be empty.');\n      return;\n    }\n    if (!apiKey) {\n      setError('API key is not available. Cannot submit.');\n      return;\n    }\n\n    setIsSubmitting(true);\n    setError(null);\n\n    try {\n      const response = await fetch('/api/races/parse-manual', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'X-API-Key': apiKey,\n        },\n        body: JSON.stringify({\n          adapter_name: adapterName,\n          html_content: htmlContent,\n        }),\n      });\n\n      if (!response.ok) {\n        const errorData = await response.json();\n        throw new Error(errorData.detail || 'Failed to parse HTML.');\n      }\n\n      const parsedRaces: Race[] = await response.json();\n      onParseSuccess(adapterName, parsedRaces);\n      setShowPanel(false); // Hide panel on success\n\n    } catch (err) {\n      const errorMessage = err instanceof Error ? err.message : 'An unknown error occurred.';\n      setError(errorMessage);\n      console.error('Manual parse submission failed:', err);\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n\n  if (!showPanel) {\n    return null;\n  }\n\n  return (\n    <div className=\"bg-red-900 bg-opacity-50 border border-red-700 p-4 rounded-lg shadow-lg mb-4\">\n      <div className=\"flex justify-between items-center\">\n        <div>\n          <h3 className=\"font-bold text-red-300\">Data Fetch Failed: {adapterName}</h3>\n          <p className=\"text-sm text-red-400\">\n            The application failed to automatically retrieve data from:{' '}\n            <a href={attemptedUrl} target=\"_blank\" rel=\"noopener noreferrer\" className=\"underline hover:text-red-200\">\n              {attemptedUrl}\n            </a>\n          </p>\n        </div>\n        <button onClick={() => setShowPanel(false)} className=\"text-red-400 hover:text-red-200 text-2xl\">&times;</button>\n      </div>\n      <div className=\"mt-4\">\n        <p className=\"text-sm text-red-300 mb-2\">\n          <strong>To resolve this:</strong>\n          <ol className=\"list-decimal list-inside pl-4\">\n            <li>Click the link above to open the page in a new tab.</li>\n            <li>Right-click on the page and select \"View Page Source\".</li>\n            <li>Copy the entire HTML source code.</li>\n            <li>Paste the code into the text area below and click \"Submit Manual Data\".</li>\n          </ol>\n        </p>\n        <textarea\n          className=\"w-full h-24 p-2 bg-gray-900 border border-gray-700 rounded text-gray-300 font-mono text-xs\"\n          placeholder={`Paste HTML source for ${adapterName} here...`}\n          value={htmlContent}\n          onChange={(e) => setHtmlContent(e.target.value)}\n          disabled={isSubmitting}\n        />\n        {error && <p className=\"text-red-400 text-sm mt-2\">{error}</p>}\n        <div className=\"mt-2 flex gap-2\">\n          <button\n            onClick={handleSubmit}\n            className=\"px-3 py-1.5 bg-blue-600 text-white rounded hover:bg-blue-700 text-sm disabled:bg-blue-800 disabled:cursor-not-allowed\"\n            disabled={isSubmitting}\n          >\n            {isSubmitting ? 'Submitting...' : 'Submit Manual Data'}\n          </button>\n          <button\n            onClick={() => setShowPanel(false)}\n            className=\"px-3 py-1.5 bg-gray-700 text-white rounded hover:bg-gray-600 text-sm\"\n          >\n            Skip for Now\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default ManualOverridePanel;\n",
    "web_platform/frontend/src/components/SettingsPage.tsx": "// src/components/SettingsPage.tsx\n'use client';\n\nimport React, { useState, useEffect } from 'react';\n\nexport function SettingsPage() {\n  const [apiKey, setApiKey] = useState('');\n  const [betfairAppKey, setBetfairAppKey] = useState('');\n  const [betfairUsername, setBetfairUsername] = useState('');\n  const [betfairPassword, setBetfairPassword] = useState('');\n\n  useEffect(() => {\n    // Fetch the current API key when the component mounts\n    const fetchApiKey = async () => {\n      if (window.electronAPI?.getApiKey) {\n        const key = await window.electronAPI.getApiKey();\n        if (key) {\n          setApiKey(key);\n        }\n      }\n    };\n    fetchApiKey();\n  }, []);\n\n  const handleGenerateApiKey = async () => {\n    if (window.electronAPI?.generateApiKey) {\n      const newKey = await window.electronAPI.generateApiKey();\n      setApiKey(newKey);\n    }\n  };\n\n  const handleSaveSettings = async () => {\n    if (window.electronAPI?.saveApiKey && window.electronAPI?.saveBetfairCredentials) {\n      await window.electronAPI.saveApiKey(apiKey);\n      await window.electronAPI.saveBetfairCredentials({\n        appKey: betfairAppKey,\n        username: betfairUsername,\n        password: betfairPassword,\n      });\n      alert('Settings saved successfully!');\n    }\n  };\n\n  return (\n    <div className=\"bg-slate-800 p-8 rounded-lg border border-slate-700 text-white max-w-2xl mx-auto\">\n      <h2 className=\"text-3xl font-bold text-white mb-6\">Application Settings</h2>\n\n      <div className=\"space-y-8\">\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">API Key</h3>\n          <p className=\"text-sm text-slate-400 mb-3\">This key is required for the dashboard to communicate with the backend service.</p>\n          <div className=\"flex items-center space-x-2\">\n            <input\n              type=\"text\"\n              readOnly\n              value={apiKey}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 font-mono text-sm\"\n            />\n            <button\n              onClick={handleGenerateApiKey}\n              className=\"px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded transition-colors font-semibold\"\n            >\n              Generate New Key\n            </button>\n          </div>\n        </div>\n\n        <div>\n          <h3 className=\"text-xl font-semibold text-slate-300 mb-2\">Betfair Credentials (Optional)</h3>\n           <p className=\"text-sm text-slate-400 mb-3\">Required for adapters that use the Betfair Exchange API.</p>\n          <div className=\"space-y-3\">\n            <input\n              type=\"password\"\n              placeholder=\"App Key\"\n              value={betfairAppKey}\n              onChange={(e) => setBetfairAppKey(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"text\"\n              placeholder=\"Username\"\n              value={betfairUsername}\n              onChange={(e) => setBetfairUsername(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n            <input\n              type=\"password\"\n              placeholder=\"Password\"\n              value={betfairPassword}\n              onChange={(e) => setBetfairPassword(e.target.value)}\n              className=\"w-full p-2 bg-slate-700 rounded border border-slate-600 placeholder-slate-500\"\n            />\n          </div>\n        </div>\n\n        <div className=\"flex justify-end pt-6 border-t border-slate-700\">\n          <button\n            onClick={handleSaveSettings}\n            className=\"px-8 py-3 bg-green-600 hover:bg-green-700 rounded font-bold text-lg transition-colors\"\n          >\n            Save All Settings\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
    "web_platform/frontend/src/hooks/useWebSocket.ts": "// web_platform/frontend/src/hooks/useWebSocket.ts\n'use client';\n\nimport { useState, useEffect, useRef } from 'react';\n\ninterface WebSocketOptions {\n  apiKey: string | null;\n  port: number | null;\n}\n\nexport const useWebSocket = <T>(path: string, options: WebSocketOptions) => {\n  const [data, setData] = useState<T | null>(null);\n  const [isConnected, setIsConnected] = useState(false);\n  const webSocketRef = useRef<WebSocket | null>(null);\n\n  useEffect(() => {\n    console.log(\n      `[useWebSocket] useEffect triggered. Path: ${path}, API Key: ${options.apiKey}, Port: ${options.port}`,\n    );\n    if (!path || !options.apiKey || !options.port) {\n      console.log(\n        '[useWebSocket] Missing path, API key, or port. Aborting connection.',\n      );\n      if (webSocketRef.current) {\n        webSocketRef.current.close();\n      }\n      return;\n    }\n\n    const wsUrl = `ws://localhost:${options.port}${path}?api_key=${options.apiKey}`;\n    console.log(`[useWebSocket] Attempting to connect to: ${wsUrl}`);\n\n    const ws = new WebSocket(wsUrl);\n    webSocketRef.current = ws;\n\n    ws.onopen = () => {\n      console.log('WebSocket connection established.');\n      setIsConnected(true);\n    };\n\n    ws.onmessage = (event) => {\n      try {\n        const messageData = JSON.parse(event.data);\n        setData(messageData);\n      } catch (error) {\n        console.error('Error parsing WebSocket message:', error);\n      }\n    };\n\n    ws.onerror = (error) => {\n      console.error('WebSocket error:', error);\n    };\n\n    ws.onclose = (event) => {\n      console.log(`WebSocket connection closed: ${event.code} ${event.reason}`);\n      setIsConnected(false);\n      webSocketRef.current = null;\n    };\n\n    return () => {\n      if (ws.readyState === WebSocket.OPEN) {\n        ws.close();\n      }\n    };\n  }, [path, options.apiKey, options.port]);\n\n  return { data, isConnected };\n};\n",
    "web_platform/frontend/tailwind.config.ts": "import type { Config } from 'tailwindcss'\n\nconst config: Config = {\n  darkMode: 'media',\n  content: [\n    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/components/**/*.{js,ts,jsx,tsx,mdx}',\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\nexport default config",
    "web_service/backend/adapters/base_adapter_v3.py": "# python_service/adapters/base_v3.py\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom typing import Any\nfrom typing import AsyncGenerator\nfrom typing import List\n\nimport httpx\nimport structlog\nfrom tenacity import RetryError\nfrom tenacity import retry\nfrom tenacity import stop_after_attempt\nfrom tenacity import wait_exponential\n\nfrom ..core.exceptions import AdapterHttpError\nfrom ..manual_override_manager import ManualOverrideManager\nfrom ..models import Race\n\n\nclass BaseAdapterV3(ABC):\n    \"\"\"\n    Abstract base class for all V3 data adapters.\n    Enforces a standardized fetch/parse pattern and includes robust request handling.\n    \"\"\"\n\n    def __init__(self, source_name: str, base_url: str, config=None, timeout: int = 20):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.config = config\n        self.timeout = timeout\n        self.logger = structlog.get_logger(adapter_name=self.source_name)\n        self.http_client: httpx.AsyncClient = None  # Injected by the engine\n        self.manual_override_manager: ManualOverrideManager = None\n        self.supports_manual_override = True  # Can be overridden by subclasses\n\n    def enable_manual_override(self, manager: ManualOverrideManager):\n        \"\"\"Injects the manual override manager into the adapter.\"\"\"\n        self.manual_override_manager = manager\n\n    @abstractmethod\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw data (e.g., HTML, JSON) for the given date.\n        This is the only method that should perform network operations.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        Parses the raw data retrieved by _fetch_data into a list of Race objects.\n        This method should be a pure function with no side effects.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        Orchestrates the fetch-then-parse pipeline for the adapter.\n        This public method should not be overridden by subclasses.\n        \"\"\"\n        raw_data = None\n\n        if self.manual_override_manager:\n            # This is not a full URL, but a representative key for the fetch operation\n            # Subclasses might need to override get_races to provide a more specific URL if needed\n            lookup_key = f\"{self.base_url}/racecards/{date}\"\n            manual_data = self.manual_override_manager.get_manual_data(self.source_name, lookup_key)\n            if manual_data:\n                self.logger.info(\"Using manually submitted data for request\", url=lookup_key)\n                # Reconstruct a dictionary similar to what _fetch_data would return\n                # This may need adjustment based on adapter specifics\n                raw_data = {\"pages\": [manual_data[0]], \"date\": date}\n\n        if raw_data is None:\n            try:\n                raw_data = await self._fetch_data(date)\n            except AdapterHttpError as e:\n                if self.manual_override_manager and self.supports_manual_override:\n                    self.manual_override_manager.register_failure(self.source_name, e.url)\n                raise  # Reraise the exception to be handled by the OddsEngine\n\n        if raw_data is not None:\n            parsed_races = self._parse_races(raw_data)\n            for race in parsed_races:\n                yield race\n\n    @retry(\n        wait=wait_exponential(multiplier=1, min=2, max=10),\n        stop=stop_after_attempt(3),\n        reraise=True,  # Reraise the final exception to be caught by get_races\n    )\n    async def make_request(self, http_client: httpx.AsyncClient, method: str, url: str, **kwargs) -> httpx.Response:\n        \"\"\"\n        Makes a resilient HTTP request with built-in retry logic using tenacity.\n        \"\"\"\n        # Ensure the URL is correctly formed, whether it's relative or absolute\n        full_url = url if url.startswith(\"http\") else f\"{self.base_url.rstrip('/')}/{url.lstrip('/')}\"\n\n        try:\n            self.logger.info(\"Making request\", method=method.upper(), url=full_url)\n            response = await http_client.request(method, full_url, timeout=self.timeout, **kwargs)\n            response.raise_for_status()  # Raise an exception for 4xx/5xx responses\n            return response\n        except httpx.HTTPStatusError as e:\n            self.logger.error(\n                \"HTTP Status Error during request\",\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            )\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=e.response.status_code,\n                url=str(e.request.url),\n            ) from e\n        except (httpx.RequestError, RetryError) as e:\n            self.logger.error(\"Request Error or Retry Error\", error=str(e))\n            raise AdapterHttpError(\n                adapter_name=self.source_name,\n                status_code=503,  # Service Unavailable\n                url=full_url,\n            ) from e\n\n    def get_status(self) -> dict:\n        \"\"\"\n        Returns a dictionary representing the adapter's current status.\n        Subclasses can extend this to include more specific health checks.\n        \"\"\"\n        return {\n            \"adapter_name\": self.source_name,\n            \"status\": \"OK\",  # Basic status; can be enhanced in subclasses\n        }\n",
    "web_service/backend/adapters/brisnet_adapter.py": "# python_service/adapters/brisnet_adapter.py\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom dateutil.parser import parse\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import normalize_venue_name\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass BrisnetAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for brisnet.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"Brisnet\"\n    BASE_URL = \"https://www.brisnet.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"Fetches the raw HTML from the Brisnet race page.\"\"\"\n        # Note: Brisnet URL structure seems to require a track code, e.g., 'CD' for Churchill Downs.\n        # This implementation will need to be improved to dynamically handle different tracks.\n        # For now, it is hardcoded to Churchill Downs as a placeholder.\n        url = f\"/race/{date}/CD\"\n        response = await self.make_request(self.http_client, \"GET\", url)\n        return {\"html\": response.text, \"date\": date} if response and response.text else None\n\n    def _parse_races(self, raw_data: Optional[dict]) -> List[Race]:\n        \"\"\"Parses the raw HTML into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"html\"):\n            return []\n\n        html = raw_data[\"html\"]\n        race_date = raw_data[\"date\"]\n        soup = BeautifulSoup(html, \"html.parser\")\n\n        venue_text_node = soup.select_one(\"header h1\")\n        if not venue_text_node:\n            self.logger.warning(\"Could not find venue name on Brisnet page.\")\n            return []\n\n        venue_text = venue_text_node.text\n        venue = normalize_venue_name(venue_text.split(\" - \")[0])\n\n        races = []\n        for race_section in soup.select(\"section.race\"):\n            try:\n                race_number_str = race_section.get(\"data-racenumber\")\n                if not race_number_str or not race_number_str.isdigit():\n                    continue\n                race_number = int(race_number_str)\n\n                post_time_node = race_section.select_one(\".race-title span\")\n                if not post_time_node:\n                    continue\n                post_time_str = post_time_node.text.replace(\"Post Time: \", \"\").strip()\n                start_time = parse(f\"{race_date} {post_time_str}\")\n\n                runners = []\n                for row in race_section.select(\"tbody tr\"):\n                    if \"scratched\" in row.get(\"class\", []):\n                        continue\n\n                    cells = row.find_all(\"td\")\n                    if len(cells) < 3:\n                        continue\n\n                    number_text = cells[0].text.strip()\n                    if not number_text.isdigit():\n                        continue\n                    number = int(number_text)\n\n                    name = cells[1].text.strip()\n                    odds_str = cells[2].text.strip()\n\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    odds = {}\n                    if win_odds:\n                        odds[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now(),\n                        )\n\n                    runners.append(Runner(number=number, name=name, odds=odds))\n\n                if not runners:\n                    continue\n\n                race = Race(\n                    id=f\"brisnet_{venue.replace(' ', '').lower()}_{race_date}_{race_number}\",\n                    venue=venue,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=runners,\n                    source=self.source_name,\n                    field_size=len(runners),\n                )\n                races.append(race)\n            except (ValueError, IndexError, TypeError):\n                self.logger.warning(\"Failed to parse a race on Brisnet, skipping.\", exc_info=True)\n                continue\n\n        return races\n",
    "web_service/backend/adapters/harness_adapter.py": "# python_service/adapters/harness_adapter.py\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass HarnessAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US harness racing data with manual override support.\"\"\"\n\n    SOURCE_NAME = \"USTrotting\"\n    BASE_URL = \"https://data.ustrotting.com/api/racenet/racing/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches all harness races for a given date.\"\"\"\n        response = await self.make_request(self.http_client, \"GET\", f\"card/{date}\")\n\n        if not response:\n            return None\n\n        card_data = response.json()\n        return {\"data\": card_data, \"date\": date}\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw card data into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"data\") or not raw_data.get(\"data\", {}).get(\"meetings\"):\n            self.logger.warning(\"No meetings found in harness data response.\")\n            return []\n\n        all_races = []\n        date = raw_data.get(\"date\")\n        for meeting in raw_data.get(\"data\", {}).get(\"meetings\", []):\n            track_name = meeting.get(\"track\", {}).get(\"name\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name, date):\n                        all_races.append(race)\n                except Exception:\n                    self.logger.warning(\n                        \"Failed to parse harness race, skipping.\",\n                        race_data=race_data,\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: dict, track_name: str, date: str) -> Optional[Race]:\n        \"\"\"Parses a single race from the USTA API into a Race object.\"\"\"\n        race_number = race_data.get(\"raceNumber\")\n        post_time_str = race_data.get(\"postTime\")\n        if not all([race_number, post_time_str]):\n            return None\n\n        start_time = self._parse_post_time(date, post_time_str)\n\n        runners = []\n        for runner_data in race_data.get(\"runners\", []):\n            if runner_data.get(\"scratched\", False):\n                continue\n\n            odds_str = runner_data.get(\"morningLineOdds\", \"\")\n            if \"/\" not in odds_str and odds_str.isdigit():\n                odds_str = f\"{odds_str}/1\"\n\n            odds = {}\n            win_odds = parse_odds_to_decimal(odds_str)\n            if win_odds and win_odds < 999:\n                odds = {\n                    self.SOURCE_NAME: OddsData(\n                        win=win_odds,\n                        source=self.SOURCE_NAME,\n                        last_updated=datetime.now(),\n                    )\n                }\n\n            runners.append(\n                Runner(\n                    number=runner_data.get(\"postPosition\", 0),\n                    name=runner_data.get(\"horse\", {}).get(\"name\", \"Unknown Horse\"),\n                    odds=odds,\n                    scratched=False,\n                )\n            )\n\n        if not runners:\n            return None\n\n        return Race(\n            id=f\"ust_{track_name.lower().replace(' ', '')}_{date}_{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME,\n        )\n\n    def _parse_post_time(self, date: str, post_time: str) -> datetime:\n        \"\"\"Parses a time string like '07:00 PM' into a timezone-aware datetime object.\"\"\"\n        dt_str = f\"{date} {post_time}\"\n        naive_dt = datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n        # Assume Eastern Time for USTA data, a common standard for US racing.\n        eastern = ZoneInfo(\"America/New_York\")\n        return naive_dt.replace(tzinfo=eastern)\n",
    "web_service/backend/adapters/punters_adapter.py": "# python_service/adapters/punters_adapter.py\nfrom typing import Any\nfrom typing import List\n\nfrom ..models import Race\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass PuntersAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for punters.com.au.\n    This adapter is a non-functional stub and has not been implemented.\n    \"\"\"\n\n    SOURCE_NAME = \"Punters\"\n    BASE_URL = \"https://www.punters.com.au\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"This is a stub and does not fetch any data.\"\"\"\n        self.logger.warning(\n            f\"{self.source_name} is a non-functional stub and has not been implemented. It will not fetch any data.\"\n        )\n        return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"This is a stub and does not parse any data.\"\"\"\n        return []\n",
    "web_service/backend/adapters/sporting_life_adapter.py": "# python_service/adapters/sporting_life_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass SportingLifeAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for sportinglife.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"SportingLife\"\n    BASE_URL = \"https://www.sportinglife.com\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        Returns a dictionary containing the HTML content and the date.\n        \"\"\"\n        index_url = f\"/horse-racing/racecards/{date}\"\n        index_response = await self.make_request(self.http_client, \"GET\", index_url)\n        if not index_response:\n            self.logger.warning(\"Failed to fetch SportingLife index page\", url=index_url)\n            return None\n\n        index_soup = BeautifulSoup(index_response.text, \"html.parser\")\n        links = {a[\"href\"] for a in index_soup.select(\"a.hr-race-card-meeting__race-link[href]\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(self.http_client, \"GET\", url_path)\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to SportingLifeAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                soup = BeautifulSoup(html, \"html.parser\")\n\n                track_name_node = soup.select_one(\"a.hr-race-header-course-name__link\")\n                if not track_name_node:\n                    continue\n                track_name = clean_text(track_name_node.get_text())\n\n                race_time_node = soup.select_one(\"span.hr-race-header-time__time\")\n                if not race_time_node:\n                    continue\n                race_time_str = clean_text(race_time_node.get_text())\n\n                start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n\n                active_link = soup.select_one(\"a.hr-race-header-navigation-link--active\")\n                race_number = 1\n                if active_link:\n                    all_links = soup.select(\"a.hr-race-header-navigation-link\")\n                    try:\n                        race_number = all_links.index(active_link) + 1\n                    except ValueError:\n                        pass  # Keep default race number if active link not in all links\n\n                runners = [self._parse_runner(row) for row in soup.select(\"div.hr-racing-runner-card\")]\n\n                race = Race(\n                    id=f\"sl_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError):\n                self.logger.warning(\n                    \"Error parsing a race from SportingLife, skipping race.\",\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name_node = row.select_one(\"a.hr-racing-runner-horse-name\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.get_text())\n\n            num_node = row.select_one(\"span.hr-racing-runner-saddle-cloth-no\")\n            if not num_node:\n                return None\n            num_str = clean_text(num_node.get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n\n            odds_node = row.select_one(\"span.hr-racing-runner-odds\")\n            odds_str = clean_text(odds_node.get_text()) if odds_node else \"\"\n\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {\n                    self.source_name: OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n                }\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError):\n            self.logger.warning(\"Failed to parse a runner on SportingLife, skipping runner.\")\n            return None\n",
    "web_service/backend/adapters/tvg_adapter.py": "# python_service/adapters/tvg_adapter.py\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..core.exceptions import AdapterParsingError\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass TVGAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US racing data from the TVG API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"TVG\"\n    BASE_URL = \"https://api.tvg.com/v2/races/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not hasattr(config, \"TVG_API_KEY\") or not config.TVG_API_KEY:\n            raise AdapterConfigError(self.source_name, \"TVG_API_KEY is not configured.\")\n        self.tvg_api_key = config.TVG_API_KEY\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches all race details for a given date by first getting tracks.\"\"\"\n        headers = {\"X-Api-Key\": self.tvg_api_key}\n        summary_url = f\"summary?date={date}&country=USA\"\n\n        tracks_response = await self.make_request(self.http_client, \"GET\", summary_url, headers=headers)\n        if not tracks_response:\n            return None\n        tracks_data = tracks_response.json()\n\n        race_detail_tasks = []\n        for track in tracks_data.get(\"tracks\", []):\n            track_id = track.get(\"id\")\n            for race in track.get(\"races\", []):\n                race_id = race.get(\"id\")\n                if track_id and race_id:\n                    details_url = f\"{track_id}/{race_id}\"\n                    race_detail_tasks.append(self.make_request(self.http_client, \"GET\", details_url, headers=headers))\n\n        race_detail_responses = await asyncio.gather(*race_detail_tasks, return_exceptions=True)\n\n        # Filter out exceptions and return only successful responses\n        return [resp.json() for resp in race_detail_responses if resp and not isinstance(resp, Exception)]\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of detailed race JSON objects into Race models.\"\"\"\n        races = []\n        if not isinstance(raw_data, list):\n            self.logger.warning(\"raw_data is not a list, cannot parse TVG races.\")\n            return races\n\n        for race_detail in raw_data:\n            try:\n                if race := self._parse_race(race_detail):\n                    races.append(race)\n            except AdapterParsingError:\n                self.logger.warning(\n                    \"Failed to parse TVG race detail, skipping.\",\n                    race_detail=race_detail,\n                    exc_info=True,\n                )\n        return races\n\n    def _parse_race(self, race_detail: dict) -> Optional[Race]:\n        \"\"\"Parses a single detailed race JSON object into a Race model.\"\"\"\n        track = race_detail.get(\"track\")\n        race_info = race_detail.get(\"race\")\n\n        if not track or not race_info:\n            raise AdapterParsingError(self.source_name, \"Missing track or race info in race detail.\")\n\n        runners = []\n        for runner_data in race_detail.get(\"runners\", []):\n            if runner_data.get(\"scratched\"):\n                continue\n\n            odds = runner_data.get(\"odds\", {})\n            current_odds = odds.get(\"currentPrice\", {})\n            odds_str = current_odds.get(\"fractional\") or odds.get(\"morningLinePrice\", {}).get(\"fractional\")\n\n            try:\n                number = int(runner_data.get(\"programNumber\", \"0\").replace(\"A\", \"\"))\n            except (ValueError, TypeError):\n                self.logger.warning(f\"Could not parse program number: {runner_data.get('programNumber')}\")\n                continue\n\n            odds_data = {}\n            if odds_str:\n                win_odds = parse_odds_to_decimal(odds_str)\n                if win_odds and win_odds < 999:\n                    odds_data[self.source_name] = OddsData(\n                        win=win_odds,\n                        source=self.source_name,\n                        last_updated=datetime.now(),\n                    )\n\n            runners.append(\n                Runner(\n                    number=number,\n                    name=clean_text(runner_data.get(\"name\")),\n                    odds=odds_data,\n                    scratched=False,\n                )\n            )\n\n        if not runners:\n            raise AdapterParsingError(self.source_name, \"No non-scratched runners found.\")\n\n        post_time = race_info.get(\"postTime\")\n        if not post_time:\n            raise AdapterParsingError(self.source_name, \"Missing post time.\")\n\n        try:\n            start_time = datetime.fromisoformat(post_time.replace(\"Z\", \"+00:00\"))\n        except (ValueError, TypeError, AttributeError) as e:\n            raise AdapterParsingError(\n                self.source_name,\n                f\"Could not parse post time: {post_time}\",\n            ) from e\n\n        return Race(\n            id=f\"tvg_{track.get('code', 'UNK')}_{race_info.get('date', 'NODATE')}_{race_info.get('number', 0)}\",\n            venue=track.get(\"name\"),\n            race_number=race_info.get(\"number\"),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/analyzer.py": "from abc import ABC\nfrom abc import abstractmethod\nfrom decimal import Decimal\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\n\nimport structlog\n\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\ntry:\n    # winsound is a built-in Windows library\n    import winsound\nexcept ImportError:\n    winsound = None\ntry:\n    from win10toast_py3 import ToastNotifier\nexcept (ImportError, RuntimeError):\n    # Fails gracefully on non-Windows systems\n    ToastNotifier = None\n\nlog = structlog.get_logger(__name__)\n\n\ndef _get_best_win_odds(runner: Runner) -> Optional[Decimal]:\n    \"\"\"Gets the best win odds for a runner, filtering out invalid or placeholder values.\"\"\"\n    if not runner.odds:\n        return None\n\n    # Filter out invalid or placeholder odds (e.g., > 999)\n    valid_odds = [o.win for o in runner.odds.values() if o.win is not None and o.win > 0 and o.win < 999]\n\n    if not valid_odds:\n        return None\n\n    return min(valid_odds)\n\n\nclass BaseAnalyzer(ABC):\n    \"\"\"The abstract interface for all future analyzer plugins.\"\"\"\n\n    def __init__(self, **kwargs):\n        pass\n\n    @abstractmethod\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"The core method every analyzer must implement.\"\"\"\n        pass\n\n\nclass TrifectaAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzes races and assigns a qualification score based on the 'Trifecta of Factors'.\"\"\"\n\n    @property\n    def name(self) -> str:\n        return \"trifecta_analyzer\"\n\n    def __init__(\n        self,\n        max_field_size: int = 10,\n        min_favorite_odds: float = 2.5,\n        min_second_favorite_odds: float = 4.0,\n    ):\n        self.max_field_size = max_field_size\n        self.min_favorite_odds = Decimal(str(min_favorite_odds))\n        self.min_second_favorite_odds = Decimal(str(min_second_favorite_odds))\n        self.notifier = RaceNotifier()\n\n    def is_race_qualified(self, race: Race) -> bool:\n        \"\"\"A race is qualified for a trifecta if it has at least 3 non-scratched runners.\"\"\"\n        if not race or not race.runners:\n            return False\n\n        active_runners = sum(1 for r in race.runners if not r.scratched)\n        return active_runners >= 3\n\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"Scores all races and returns a dictionary with criteria and a sorted list.\"\"\"\n        qualified_races = []\n        for race in races:\n            score = self._evaluate_race(race)\n            if score > 0:\n                race.qualification_score = score\n                qualified_races.append(race)\n\n        qualified_races.sort(key=lambda r: r.qualification_score, reverse=True)\n\n        criteria = {\n            \"max_field_size\": self.max_field_size,\n            \"min_favorite_odds\": float(self.min_favorite_odds),\n            \"min_second_favorite_odds\": float(self.min_second_favorite_odds),\n        }\n\n        log.info(\n            \"Universal scoring complete\",\n            total_races_scored=len(qualified_races),\n            criteria=criteria,\n        )\n\n        for race in qualified_races:\n            if race.qualification_score and race.qualification_score >= 85:\n                self.notifier.notify_qualified_race(race)\n\n        return {\"criteria\": criteria, \"races\": qualified_races}\n\n    def _evaluate_race(self, race: Race) -> float:\n        \"\"\"Evaluates a single race and returns a qualification score.\"\"\"\n        # --- Constants for Scoring Logic ---\n        FAV_ODDS_NORMALIZATION = 10.0\n        SEC_FAV_ODDS_NORMALIZATION = 15.0\n        FAV_ODDS_WEIGHT = 0.6\n        SEC_FAV_ODDS_WEIGHT = 0.4\n        FIELD_SIZE_SCORE_WEIGHT = 0.3\n        ODDS_SCORE_WEIGHT = 0.7\n\n        active_runners = [r for r in race.runners if not r.scratched]\n\n        runners_with_odds = []\n        for runner in active_runners:\n            best_odds = _get_best_win_odds(runner)\n            if best_odds is not None:\n                runners_with_odds.append((runner, best_odds))\n\n        if len(runners_with_odds) < 2:\n            return 0.0\n\n        runners_with_odds.sort(key=lambda x: x[1])\n        favorite_odds = runners_with_odds[0][1]\n        second_favorite_odds = runners_with_odds[1][1]\n\n        # --- Calculate Qualification Score (as inspired by the TypeScript Genesis) ---\n        field_score = (self.max_field_size - len(active_runners)) / self.max_field_size\n\n        # Normalize odds scores - cap influence of extremely high odds\n        fav_odds_score = min(float(favorite_odds) / FAV_ODDS_NORMALIZATION, 1.0)\n        sec_fav_odds_score = min(float(second_favorite_odds) / SEC_FAV_ODDS_NORMALIZATION, 1.0)\n\n        # Weighted average\n        odds_score = (fav_odds_score * FAV_ODDS_WEIGHT) + (sec_fav_odds_score * SEC_FAV_ODDS_WEIGHT)\n        final_score = (field_score * FIELD_SIZE_SCORE_WEIGHT) + (odds_score * ODDS_SCORE_WEIGHT)\n\n        # --- Apply a penalty if hard filters are not met, instead of returning None ---\n        if (\n            len(active_runners) > self.max_field_size\n            or favorite_odds < self.min_favorite_odds\n            or second_favorite_odds < self.min_second_favorite_odds\n        ):\n            # Assign a score of 0 to races that would have been filtered out\n            return 0.0\n\n        score = round(final_score * 100, 2)\n        race.qualification_score = score\n        return score\n\n\nclass AnalyzerEngine:\n    \"\"\"Discovers and manages all available analyzer plugins.\"\"\"\n\n    def __init__(self):\n        self.analyzers: Dict[str, Type[BaseAnalyzer]] = {}\n        self._discover_analyzers()\n\n    def _discover_analyzers(self):\n        # In a real plugin system, this would inspect a folder.\n        # For now, we register them manually.\n        self.register_analyzer(\"trifecta\", TrifectaAnalyzer)\n        log.info(\n            \"AnalyzerEngine discovered plugins\",\n            available_analyzers=list(self.analyzers.keys()),\n        )\n\n    def register_analyzer(self, name: str, analyzer_class: Type[BaseAnalyzer]):\n        self.analyzers[name] = analyzer_class\n\n    def get_analyzer(self, name: str, **kwargs) -> BaseAnalyzer:\n        analyzer_class = self.analyzers.get(name)\n        if not analyzer_class:\n            log.error(\"Requested analyzer not found\", requested_analyzer=name)\n            raise ValueError(f\"Analyzer '{name}' not found.\")\n        return analyzer_class(**kwargs)\n\n\nclass AudioAlertSystem:\n    \"\"\"Plays sound alerts for important events.\"\"\"\n\n    def __init__(self):\n        self.sounds = {\n            \"high_value\": Path(__file__).parent.parent.parent / \"assets\" / \"sounds\" / \"alert_premium.wav\",\n        }\n        self.enabled = winsound is not None\n\n    def play(self, sound_type: str):\n        if not self.enabled:\n            return\n\n        sound_file = self.sounds.get(sound_type)\n        if sound_file and sound_file.exists():\n            try:\n                winsound.PlaySound(str(sound_file), winsound.SND_FILENAME | winsound.SND_ASYNC)\n            except Exception as e:\n                log.warning(\"Could not play sound\", file=sound_file, error=e)\n\n\nclass RaceNotifier:\n    \"\"\"Handles sending native Windows notifications and audio alerts for high-value races.\"\"\"\n\n    def __init__(self):\n        self.toaster = ToastNotifier(\"Fortuna\") if ToastNotifier else None\n        self.audio_system = AudioAlertSystem()\n        self.notified_races = set()\n\n    def notify_qualified_race(self, race):\n        if not self.toaster or race.id in self.notified_races:\n            return\n\n        title = \"\ud83c\udfc7 High-Value Opportunity!\"\n        message = f\"\"\"{race.venue} - Race {race.race_number}\nScore: {race.qualification_score:.0f}%\nPost Time: {race.start_time.strftime(\"%I:%M %p\")}\"\"\"\n\n        try:\n            # The `threaded=True` argument is crucial to prevent blocking the main application thread.\n            self.toaster.show_toast(title, message, duration=10, threaded=True)\n            self.notified_races.add(race.id)\n            self.audio_system.play(\"high_value\")\n            log.info(\"Notification and audio alert sent for high-value race\", race_id=race.id)\n        except Exception as e:\n            # Catch potential exceptions from the notification library itself\n            log.error(\"Failed to send notification\", error=str(e), exc_info=True)\n",
    "web_service/backend/core/errors.py": "# python_service/core/errors.py\nfrom enum import Enum\n\n\nclass ErrorCategory(Enum):\n    CONFIGURATION_ERROR = \"Configuration missing or invalid\"\n    NETWORK_ERROR = \"HTTP/Network request failed\"\n    PARSING_ERROR = \"Data parsing or validation unsuccessful\"\n    UNEXPECTED_ERROR = \"An unhandled exception occurred\"\n",
    "web_service/backend/fortuna_service.py": "# fortuna_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport json\nimport logging\nimport os\nimport sqlite3\nimport subprocess\nimport threading\nfrom datetime import datetime\nfrom typing import List\nfrom typing import Optional\n\nfrom .analyzer import TrifectaAnalyzer\nfrom .engine import Race\nfrom .engine import Settings\nfrom .engine import SuperchargedOrchestrator\n\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Correctly resolve paths from the service's location\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n            schema_path = os.path.join(base_dir, \"shared_database\", \"schema.sql\")\n            web_schema_path = os.path.join(base_dir, \"shared_database\", \"web_schema.sql\")\n\n            # Read both schema files\n            with open(schema_path, \"r\") as f:\n                schema = f.read()\n            with open(web_schema_path, \"r\") as f:\n                web_schema = f.read()\n\n            # Apply both schemas in a single transaction\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(\"CRITICAL SUCCESS: All database schemas (base + web) applied successfully.\")\n        except Exception as e:\n            self.logger.critical(\n                f\"FATAL: Database setup failed. Other platforms will fail. Error: {e}\",\n                exc_info=True,\n            )\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO live_races (\n                        race_id, track_name, race_number, post_time, raw_data_json,\n                        fortuna_score, qualified, trifecta_factors_json, updated_at\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        race.race_id,\n                        race.track_name,\n                        race.race_number,\n                        race.post_time,\n                        race.model_dump_json(),\n                        race.fortuna_score,\n                        race.is_qualified,\n                        race.trifecta_factors_json,\n                        datetime.now(),\n                    ),\n                )\n            for status in statuses:\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO adapter_status (\n                        adapter_name, status, last_run, races_found, error_message,\n                        execution_time_ms\n                    )\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        status.get(\"adapter_id\"),\n                        status.get(\"status\"),\n                        status.get(\"timestamp\"),\n                        status.get(\"races_found\"),\n                        status.get(\"error_message\"),\n                        int(status.get(\"response_time\", 0) * 1000),\n                    ),\n                )\n\n            if races or statuses:\n                cursor.execute(\n                    \"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                    (\"RACES_UPDATED\", json.dumps({\"race_count\": len(races)})),\n                )\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\n\nclass FortunaBackgroundService:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        from dotenv import load_dotenv\n\n        dotenv_path = os.path.join(os.path.dirname(__file__), \"..\", \".env\")\n        load_dotenv(dotenv_path=dotenv_path)\n\n        db_path = os.getenv(\"FORTUNA_DB_PATH\")\n        if not db_path:\n            self.logger.critical(\"FATAL: FORTUNA_DB_PATH environment variable not set. Service cannot start.\")\n            raise ValueError(\"FORTUNA_DB_PATH is not configured.\")\n\n        self.logger.info(f\"Database path loaded from environment: {db_path}\")\n\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(db_path)\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.python_analyzer = TrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.rust_engine_path = os.path.join(\n            os.path.dirname(__file__),\n            \"..\",\n            \"rust_engine\",\n            \"target\",\n            \"release\",\n            \"fortuna_engine.exe\",\n        )\n\n    def _analyze_with_rust(self, races: List[Race]) -> Optional[List[Race]]:\n        self.logger.info(\"Attempting analysis with external Rust engine.\")\n        try:\n            race_data_json = json.dumps([r.model_dump() for r in races])\n            result = subprocess.run(\n                [self.rust_engine_path],\n                input=race_data_json,\n                capture_output=True,\n                text=True,\n                check=True,\n                timeout=30,\n            )\n            results_data = json.loads(result.stdout)\n            results_map = {res[\"race_id\"]: res for res in results_data}\n\n            for race in races:\n                if race.race_id in results_map:\n                    res = results_map[race.race_id]\n                    race.fortuna_score = res.get(\"fortuna_score\")\n                    race.is_qualified = res.get(\"qualified\")\n                    race.trifecta_factors_json = json.dumps(res.get(\"trifecta_factors\"))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (\n            subprocess.CalledProcessError,\n            json.JSONDecodeError,\n            subprocess.TimeoutExpired,\n        ) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race_advanced(race) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races_parallel()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None:  # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races:  # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"FortunaBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, \"thread\") and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"FortunaBackgroundService stopped.\")\n",
    "web_service/backend/initialize_db.py": "# python_service/initialize_db.py\nfrom db.init import initialize_database\n\n\ndef main():\n    \"\"\"\n    This script exists solely to initialize the database.\n    It should be called before the main server process is started.\n    \"\"\"\n    print(\"Initializing database...\", flush=True)\n    initialize_database()\n    print(\"Database initialization complete.\", flush=True)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "web_service/backend/middleware/error_handler.py": "# python_service/middleware/error_handler.py\n\nfrom fastapi import Request\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\n\nfrom ..user_friendly_errors import ERROR_MAP\n\n\nclass UserFriendlyException(Exception):\n    def __init__(self, error_key: str, status_code: int = 500, details: str = None):\n        self.error_key = error_key\n        self.status_code = status_code\n        self.details = details\n        error_info = ERROR_MAP.get(error_key, ERROR_MAP[\"default\"])\n        self.message = error_info[\"message\"]\n        self.suggestion = error_info[\"suggestion\"]\n        super().__init__(self.message)\n\n\nasync def user_friendly_exception_handler(request: Request, exc: UserFriendlyException):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"error\": {\n                \"message\": exc.message,\n                \"suggestion\": exc.suggestion,\n                \"details\": exc.details,\n            }\n        },\n    )\n\n\nasync def validation_exception_handler(request: Request, exc: RequestValidationError):\n    \"\"\"Convert Pydantic validation errors to user-friendly messages.\"\"\"\n    return JSONResponse(\n        status_code=422,\n        content={\n            \"detail\": \"Invalid request parameters\",\n            \"errors\": [\n                {\n                    \"field\": error[\"loc\"][-1] if error[\"loc\"] else \"unknown\",\n                    \"message\": error[\"msg\"],\n                    \"type\": error[\"type\"],\n                }\n                for error in exc.errors()\n            ],\n        },\n    )\n",
    "web_service/backend/port_check.py": "import socket\nimport sys\n\n\ndef is_port_in_use(port: int, host: str = \"127.0.0.1\") -> bool:\n    \"\"\"\n    Checks if a local port is already in use.\n\n    Args:\n        port: The port number to check.\n        host: The host to check (defaults to localhost).\n\n    Returns:\n        True if the port is in use, False otherwise.\n    \"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        try:\n            s.bind((host, port))\n            return False\n        except OSError:\n            return True\n\n\ndef check_port_and_exit_if_in_use(port: int, host: str = \"127.0.0.1\"):\n    \"\"\"\n    Checks the specified port and exits the application with a user-friendly\n    message if it's already in use.\n    \"\"\"\n    # Note: A simple s.connect_ex((host, port)) == 0 is not reliable, as it can\n    # intermittently fail depending on socket states. A full bind attempt is\n    # the most robust way to check for port availability.\n    if is_port_in_use(port, host):\n        print(f\"--- FATAL ERROR ---\")\n        print(f\"Port {port} on host {host} is already in use by another application.\")\n        print(f\"Please close the other application or configure Fortuna Faucet to use a different port.\")\n        print(f\"-------------------\")\n        # Use sys.exit to ensure a clean exit, especially important for PyInstaller executables.\n        sys.exit(1)\n",
    "web_service/backend/requirements-dev.txt": "#\n# Development & Build-Time Dependencies\n# This file should be used for setting up a development or CI/CD environment.\n#\n\n-r requirements.txt\n\n# --- Build Tools ---\npyinstaller==6.6.0\npip-tools\n\n# --- Testing Tools ---\npytest\npytest-asyncio\nfakeredis\nrespx\n\n# --- Linting & Auditing ---\nblack\nruff\npip-audit\nsetuptools<81\n",
    "web_service/backend/user_friendly_errors.py": "# python_service/user_friendly_errors.py\n\n\"\"\"\nCentralized dictionary for mapping technical exceptions to user-friendly messages.\n\"\"\"\n\nERROR_MAP = {\n    \"AdapterHttpError\": {\n        \"message\": \"A data source is currently unavailable.\",\n        \"suggestion\": (\n            \"This is usually temporary. Please try again in a few minutes. \"\n            \"If the problem persists, the website may be down for maintenance.\"\n        ),\n    },\n    \"AdapterConfigError\": {\n        \"message\": \"A data adapter is misconfigured.\",\n        \"suggestion\": \"Please check that all required API keys and settings are present in your .env file.\",\n    },\n    \"default\": {\n        \"message\": \"An unexpected error occurred.\",\n        \"suggestion\": \"Please check the application logs for more details or contact support.\",\n    },\n}\n",
    "web_service/backend/windows_compat.py": "\"\"\"\nWindows Compatibility Utilities\n\nCRITICAL: This module MUST be imported and called at the top of EVERY entry point\nthat uses asyncio or uvicorn in a PyInstaller bundle on Windows.\n\nWithout this fix, the asyncio event loop will fail to bind network ports, causing\nsilent failures where uvicorn reports \"Application startup complete\" but the\nservice is actually inaccessible.\n\"\"\"\n\nimport sys\n\n\ndef setup_windows_event_loop():\n    \"\"\"\n    Configure Windows event loop policy for PyInstaller bundles.\n\n    This MUST be called BEFORE any asyncio or uvicorn initialization.\n\n    Context:\n    - PyInstaller bundles on Windows have a broken default event loop policy\n    - The default policy (ProactorEventLoop) silently fails to bind ports\n    - WindowsSelectorEventLoopPolicy is the only policy that works reliably\n\n    This function is idempotent and safe to call multiple times.\n    \"\"\"\n    if sys.platform == 'win32' and getattr(sys, 'frozen', False):\n        import asyncio\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n        print('[BOOT] \u2713 Applied WindowsSelectorEventLoopPolicy for PyInstaller',\n              file=sys.stderr)\n    else:\n        # Not Windows or not frozen - no action needed\n        pass\n",
    "web_service/frontend/app/components/LiveModeToggle.tsx": "// web_platform/frontend/src/components/LiveModeToggle.tsx\n'use client';\n\nimport React from 'react';\n\ninterface LiveModeToggleProps {\n  isLive: boolean;\n  onToggle: (isLive: boolean) => void;\n  isDisabled: boolean;\n}\n\nexport const LiveModeToggle: React.FC<LiveModeToggleProps> = ({ isLive, onToggle, isDisabled }) => {\n  const handleToggle = () => {\n    if (!isDisabled) {\n      onToggle(!isLive);\n    }\n  };\n\n  return (\n    <button\n      onClick={handleToggle}\n      disabled={isDisabled}\n      className={`relative inline-flex items-center h-8 rounded-full w-32 transition-colors duration-300 ease-in-out focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-slate-800 focus:ring-blue-500 ${\n        isDisabled ? 'cursor-not-allowed bg-slate-700' : 'cursor-pointer'\n      } ${isLive ? 'bg-green-600' : 'bg-slate-600'}`}\n    >\n      <span className=\"sr-only\">Toggle Live Mode</span>\n      <span\n        className={`absolute left-1 top-1 inline-block w-6 h-6 rounded-full bg-white transform transition-transform duration-300 ease-in-out ${\n          isLive ? 'translate-x-[104px]' : 'translate-x-0'\n        }`}\n      />\n      <span\n        className={`absolute left-8 transition-opacity duration-200 ease-in-out ${\n          !isLive && !isDisabled ? 'opacity-100' : 'opacity-50'\n        }`}\n      >\n        Poll\n      </span>\n      <span\n        className={`absolute right-4 transition-opacity duration-200 ease-in-out ${\n          isLive && !isDisabled ? 'opacity-100' : 'opacity-50'\n        }`}\n      >\n        \u26a1 Live\n      </span>\n    </button>\n  );\n};\n",
    "web_service/frontend/app/components/RaceFilters.tsx": "// web_platform/frontend/src/components/RaceFilters.tsx\n'use client';\n\nimport { useState, useCallback } from 'react';\nimport { Settings, RotateCcw } from 'lucide-react';\n\ninterface FilterParams {\n  maxFieldSize: number;\n  minFavoriteOdds: number;\n  minSecondFavoriteOdds: number;\n}\n\nexport interface RaceFiltersProps {\n  onParamsChange: (params: FilterParams) => void;\n  isLoading: boolean;\n  refetch: () => void;\n}\n\nconst DEFAULT_PARAMS: FilterParams = {\n  maxFieldSize: 10,\n  minFavoriteOdds: 2.5,\n  minSecondFavoriteOdds: 4.0,\n};\n\nexport function RaceFilters({ onParamsChange, isLoading, refetch }: RaceFiltersProps) {\n  const [params, setParams] = useState<FilterParams>(DEFAULT_PARAMS);\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // Handle individual parameter changes\n  const handleChange = useCallback((key: keyof FilterParams, value: number) => {\n    setParams(prev => {\n      const updated = { ...prev, [key]: value };\n      onParamsChange(updated);\n      return updated;\n    });\n    // Debounce the refetch call\n    const timer = setTimeout(() => {\n      refetch();\n    }, 500);\n    return () => clearTimeout(timer);\n  }, [onParamsChange, refetch]);\n\n  // Reset to defaults\n  const handleReset = useCallback(() => {\n    setParams(DEFAULT_PARAMS);\n    onParamsChange(DEFAULT_PARAMS);\n    refetch();\n  }, [onParamsChange, refetch]);\n\n  return (\n    <div className=\"bg-gradient-to-r from-slate-800 to-slate-900 rounded-lg p-4 mb-6 border border-slate-700\">\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-2\">\n          <Settings className=\"w-5 h-5 text-amber-500\" />\n          <h3 className=\"text-lg font-semibold text-white\">Race Filters</h3>\n        </div>\n        <button\n          onClick={() => setIsExpanded(!isExpanded)}\n          className=\"text-sm text-slate-400 hover:text-slate-200 transition\"\n        >\n          {isExpanded ? 'Hide' : 'Show'}\n        </button>\n      </div>\n\n      {isExpanded && (\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 pt-4 border-t border-slate-700\">\n          {/* Max Field Size */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Max Field Size\n              <span className=\"text-amber-500 ml-2\">{params.maxFieldSize}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2\"\n              max=\"20\"\n              value={params.maxFieldSize}\n              onChange={(e) => handleChange('maxFieldSize', parseInt(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Filters races with larger fields</p>\n          </div>\n\n          {/* Min Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"1.5\"\n              max=\"5\"\n              step=\"0.1\"\n              value={params.minFavoriteOdds}\n              onChange={(e) => handleChange('minFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = pickier favorites</p>\n          </div>\n\n          {/* Min Second Favorite Odds */}\n          <div className=\"space-y-2\">\n            <label className=\"block text-sm font-medium text-slate-300\">\n              Min 2nd Favorite Odds\n              <span className=\"text-amber-500 ml-2\">{params.minSecondFavoriteOdds.toFixed(2)}</span>\n            </label>\n            <input\n              type=\"range\"\n              min=\"2.0\"\n              max=\"8\"\n              step=\"0.1\"\n              value={params.minSecondFavoriteOdds}\n              onChange={(e) => handleChange('minSecondFavoriteOdds', parseFloat(e.target.value))}\n              disabled={isLoading}\n              className=\"w-full accent-amber-500 cursor-pointer disabled:opacity-50\"\n            />\n            <p className=\"text-xs text-slate-500\">Higher = better odds separation</p>\n          </div>\n\n          {/* Reset Button */}\n          <div className=\"md:col-span-3 flex justify-end pt-4 border-t border-slate-700\">\n            <button\n              onClick={handleReset}\n              disabled={isLoading}\n              className=\"inline-flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-600 text-slate-200 rounded text-sm font-medium transition disabled:opacity-50\"\n            >\n              <RotateCcw className=\"w-4 h-4\" />\n              Reset to Defaults\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n",
    "web_service/frontend/app/components/TrifectaFactors.tsx": "// TrifectaFactors.tsx - FINAL, DYNAMIC VERSION\n'use client';\nimport React from 'react';\n\ninterface TrifectaFactorsProps {\n  factorsJson: string | null;\n}\n\nexport function TrifectaFactors({ factorsJson }: TrifectaFactorsProps) {\n  if (!factorsJson) {\n    return <div className=\"text-sm text-gray-500\">No analysis factors available.</div>;\n  }\n\n  try {\n    const factors = JSON.parse(factorsJson);\n    const positiveFactors = Object.entries(factors).filter(([key, value]: [string, any]) => value.ok);\n\n    if (positiveFactors.length === 0) {\n      return <div className=\"text-sm text-gray-500\">No positive factors identified.</div>;\n    }\n\n    return (\n      <div className=\"mt-2 text-xs\">\n        <h4 className=\"font-semibold mb-1\">Key Factors:</h4>\n        <ul className=\"list-disc list-inside space-y-1\">\n          {positiveFactors.map(([key, value]: [string, any]) => (\n            <li key={key} className=\"text-gray-700\">\n              <span className=\"font-medium text-green-600\">\u2713</span> {value.reason} ({value.points > 0 ? `+${value.points}` : value.points} pts)\n            </li>\n          ))}\n        </ul>\n      </div>\n    );\n  } catch (error) {\n    console.error(\"Failed to parse trifecta factors:\", error);\n    return <div className=\"text-sm text-red-500\">Error displaying analysis factors.</div>;\n  }\n}",
    "web_service/frontend/app/lib/queryClient.ts": "// web_platform/frontend/src/lib/queryClient.ts\nimport { QueryClient } from '@tanstack/react-query';\n\nexport const queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      retry: 3,\n      staleTime: 1000 * 60 * 5, // 5 minutes\n    },\n  },\n});\n",
    "web_service/frontend/next-env.d.ts": "/// <reference types=\"next\" />\n/// <reference types=\"next/image-types/global\" />\n\n// NOTE: This file should not be edited\n// see https://nextjs.org/docs/app/building-your-application/configuring/typescript for more information.\n",
    "web_service/frontend/next.config.mjs": "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  output: 'export',  // Critical for static HTML export\n  distDir: 'out',\n  trailingSlash: true,\n  images: {\n    unoptimized: true  // Required for static export\n  },\n  async rewrites() {\n    return [\n      {\n        source: '/api/:path*',\n        destination: 'http://127.0.0.1:8000/api/:path*',\n      },\n    ]\n  },\n};\n\nexport default nextConfig;\n",
    "web_service/frontend/public/manifest.json": "{\n  \"name\": \"Fortuna Faucet Command Deck\",\n  \"short_name\": \"Fortuna\",\n  \"description\": \"Real-time racing analysis.\",\n  \"start_url\": \"/\",\n  \"display\": \"standalone\",\n  \"background_color\": \"#1a202c\",\n  \"theme_color\": \"#1a202c\",\n  \"icons\": [\n    {\n      \"src\": \"/icons/icon-192x192.png\",\n      \"sizes\": \"192x192\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/icon-512x512.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\"\n    }\n  ]\n}\n",
    "wix/WixUI_CustomProgress.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\">\n  <Fragment>\n    <UI>\n      <!-- Override the default InstallProgress dialog -->\n      <Dialog Id=\"InstallProgressDlg\" Width=\"370\" Height=\"270\" Title=\"Fortuna Faucet Installation\" Modeless=\"yes\">\n        <Control Id=\"Title\" Type=\"Title\" X=\"20\" Y=\"6\" Width=\"330\" Height=\"18\" Text=\"Installation Progress\" />\n        <Control Id=\"BannerBitmap\" Type=\"Bitmap\" X=\"0\" Y=\"0\" Width=\"370\" Height=\"44\" TabSkip=\"no\" Text=\"WixUI_Bmp_Banner\" />\n        <Control Id=\"Back\" Type=\"PushButton\" X=\"180\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Back\" Disabled=\"yes\" />\n        <Control Id=\"Next\" Type=\"PushButton\" X=\"236\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Next\" Disabled=\"yes\" />\n        <Control Id=\"Cancel\" Type=\"PushButton\" X=\"304\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"Cancel\" />\n\n        <Control Id=\"ActionText\" Type=\"Text\" X=\"70\" Y=\"80\" Width=\"280\" Height=\"20\" TabSkip=\"no\">\n          <Subscribe Event=\"ActionText\" Attribute=\"Text\" />\n        </Control>\n        <Control Id=\"Description\" Type=\"Text\" X=\"35\" Y=\"55\" Width=\"300\" Height=\"20\" Text=\"Please wait while the installer copies files.\" />\n\n        <!-- This is the new control to display the current filename -->\n        <Control Id=\"CurrentFileText\" Type=\"Text\" X=\"70\" Y=\"100\" Width=\"280\" Height=\"20\">\n            <Subscribe Event=\"SetProgress\" Attribute=\"Text\" />\n        </Control>\n\n        <Control Id=\"ProgressBar\" Type=\"ProgressBar\" X=\"35\" Y=\"120\" Width=\"300\" Height=\"10\" ProgressBlocks=\"yes\" Text=\"Progress\">\n          <Subscribe Event=\"SetProgress\" Attribute=\"Progress\" />\n        </Control>\n      </Dialog>\n\n      <!-- The Publish element must be a child of UI, not Dialog -->\n      <Publish Dialog=\"InstallProgressDlg\" Control=\"Cancel\" Event=\"SpawnDialog\" Value=\"CancelDlg\">1</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n"
}