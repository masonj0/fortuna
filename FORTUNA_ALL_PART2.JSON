{
    ".github/actions/run-asgi-diagnostics/action.yml": "name: 'Run ASGI Import Killer Diagnostics'\ndescription: 'Runs a multi-phase diagnostic to verify Python ASGI application imports.'\n\ninputs:\n  python-version:\n    description: 'The version of Python to use.'\n    required: true\n  backend-dir:\n    description: 'The directory of the backend service to test.'\n    required: true\n  backend-module-path:\n    description: 'The Python module path for the backend service (e.g., web_service.backend).'\n    required: true\n\nruns:\n  using: \"composite\"\n  steps:\n      - name: \u2699\ufe0f Setup Python (EXACT VERSION)\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ inputs.python-version }}\n\n      - name: \ud83d\udccb Capture Python Info\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          Write-Host \"Python executable: $(which python)\" -ForegroundColor Cyan\n          python --version\n          python -m site\n          python -c \"import sys; print('Prefix:', sys.prefix); print('Base prefix:', sys.base_prefix)\"\n\n      - name: \ud83d\udce5 Install Requirements (Exactly as Backend Build)\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          python -m pip install --upgrade pip setuptools wheel --quiet\n\n          Write-Host \"Installing requirements.txt...\" -ForegroundColor Cyan\n          pip install -r (Join-Path \"${{ inputs.backend-dir }}\" \"requirements.txt\") -v 2>&1 | Tee-Object \"install-requirements.log\"\n\n          if (Test-Path (Join-Path \"${{ inputs.backend-dir }}\" \"requirements-dev.txt\")) {\n            Write-Host \"Installing requirements-dev.txt...\" -ForegroundColor Cyan\n            pip install -r (Join-Path \"${{ inputs.backend-dir }}\" \"requirements-dev.txt\") -v 2>&1 | Tee-Object -Append \"install-requirements.log\"\n          }\n\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c pip install failed\" -ForegroundColor Red\n            exit 1\n          }\n\n          Write-Host \"\u2705 All dependencies installed\" -ForegroundColor Green\n\n      - name: \ud83d\udce6 Capture Installed Packages\n        shell: pwsh\n        run: |\n          pip list | Tee-Object \"installed-packages.txt\"\n          pip freeze | Tee-Object \"pip-freeze.txt\"\n\n      - name: \ud83d\udc0d Set PYTHONPATH\n        shell: pwsh\n        run: |\n          echo \"PYTHONPATH=${{ github.workspace }}\" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append\n          Write-Host \"PYTHONPATH set to ${{ github.workspace }}\"\n\n      - name: \ud83e\uddea PHASE 1 System Imports\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 1 SYSTEM-LEVEL IMPORTS\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('os', 'filesystem'), ('sys', 'system'), ('json', 'serialization'),\",\n            \"    ('asyncio', 'async I/O'), ('pathlib', 'paths'), ('typing', 'type hints'),\",\n            \"    ('importlib', 'import utilities')\",\n            ']',\n            'failed = []',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:20} [{desc}]\")',\n            '    except ImportError as e:',\n            '        print(f\"\u274c {mod_name:20} ImportError: {e}\")',\n            '        failed.append(mod_name)',\n            'if failed:',\n            '    print(f\"\\n\u274c {len(failed)} system imports failed\")',\n            '    sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 1 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 2 Web Framework Core\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'import traceback',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 2 WEB FRAMEWORK CORE\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('fastapi', 'web framework'),\",\n            \"    ('uvicorn', 'ASGI server'),\",\n            \"    ('starlette', 'ASGI toolkit'),\",\n            \"    ('starlette.applications', 'ASGI app'),\",\n            \"    ('starlette.routing', 'routing'),\",\n            ']',\n            'failed = []',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except ImportError as e:',\n            '        print(f\"\u274c {mod_name:30} ImportError: {e}\")',\n            '        failed.append((mod_name, str(e)))',\n            '    except Exception as e:',\n            '        print(f\"\u26a0\ufe0f  {mod_name:30} {type(e).__name__}: {e}\")',\n            'if failed:',\n            '    print(f\"\\n\u274c {len(failed)} core framework imports failed\")',\n            '    for mod, err in failed:',\n            '        print(f\"  - {mod}\")',\n            '    sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 2 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 3 Pydantic & Data Validation\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 3 PYDANTIC & DATA VALIDATION\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('pydantic', 'validation'),\",\n            \"    ('pydantic_core', 'core'),\",\n            \"    ('pydantic_settings', 'settings'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")',\n            '        sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 3 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 4 Async/IO Utilities\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 4 ASYNC/IO UTILITIES\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('anyio', 'async compat'),\",\n            \"    ('httpcore', 'HTTP core'),\",\n            \"    ('httpx', 'HTTP client'),\",\n            \"    ('aiosqlite', 'async DB'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u274c {mod_name:30} {type(e).__name__}: {e}\")',\n            '        sys.exit(1)',\n            'print(f\"\\n\u2705 Phase 4 complete\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) { exit 1 }\n\n      - name: \ud83e\uddea PHASE 5 Optional Dependencies (non-critical)\n        shell: pwsh\n        continue-on-error: true\n        run: |\n          $script = @(\n            'import sys',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 5 OPTIONAL DEPENDENCIES (non-critical)\")',\n            'print(\"=\"*80)',\n            'modules = [',\n            \"    ('slowapi', 'rate limiting'),\",\n            \"    ('structlog', 'logging'),\",\n            \"    ('tenacity', 'retries'),\",\n            ']',\n            'for mod_name, desc in modules:',\n            '    try:',\n            '        __import__(mod_name)',\n            '        print(f\"\u2705 {mod_name:30} [{desc}]\")',\n            '    except Exception as e:',\n            '        print(f\"\u26a0\ufe0f  {mod_name:30} not critical: {type(e).__name__}\")',\n            'print(f\"\\n\u2705 Phase 5 complete (warnings OK)\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n\n      - name: \ud83e\uddea PHASE 6 Application Directory Structure\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n\n          $script = @(\n            'import os',\n            'from pathlib import Path',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 6 APPLICATION DIRECTORY STRUCTURE\")',\n            'print(\"=\"*80)',\n            'cwd = Path.cwd()',\n            'backend_dir = cwd / \"${{ inputs.backend-dir }}\"',\n            'print(f\"\\nCurrent directory: {cwd}\")',\n            'print(f\"\\nBackend directory exists: {backend_dir.exists()}\")',\n            'if backend_dir.exists():',\n            '    print(f\"  Contents:\")',\n            '    for item in backend_dir.iterdir():',\n            '        print(f\"    - {item.name}\")',\n            '    main_py = backend_dir / \"main.py\"',\n            '    api_py = backend_dir / \"api.py\"',\n            '    print(f''\\n  main.py: {main_py.stat().st_size if main_py.exists() else \"N/A\"} bytes'')',\n            '    print(f''  api.py: {api_py.stat().st_size if api_py.exists() else \"N/A\"} bytes'')'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n\n      - name: \ud83e\uddea PHASE 7 CRITICAL - Application Module Imports\n        shell: pwsh\n        run: |\n          $script = @(\n            'import sys',\n            'import traceback',\n            'import importlib',\n            'from pathlib import Path',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"PHASE 7 APPLICATION MODULE IMPORTS (CRITICAL)\")',\n            'print(\"=\"*80)',\n            'backend_module_path = \"${{ inputs.backend-module-path }}\"',\n            'print(f\"\\n[Step 1] Dynamically importing module: {backend_module_path}\")',\n            'try:',\n            '    backend_module = importlib.import_module(backend_module_path)',\n            '    print(f\"\u2705 {backend_module_path} imported successfully\")',\n            'except Exception as e:',\n            '    print(f\"\u274c FATAL: {backend_module_path} import failed\")',\n            '    print(f\"   Error: {type(e).__name__}: {e}\")',\n            '    traceback.print_exc()',\n            '    sys.exit(1)',\n            'print(''\\\\n[Step 2] Retrieving \"app\" object from the API submodule...'')',\n            'api_module_path = f\"{backend_module_path}.api\"',\n            'try:',\n            '    api_module = importlib.import_module(api_module_path)',\n            '    app = getattr(api_module, \"app\")',\n            '    print(f\"\u2705 app object retrieved from {api_module_path}\")',\n            '    print(f\"   Type: {type(app)}\")',\n            '    print(f\"   Class: {app.__class__.__name__}\")',\n            '    print(f\"   Module: {app.__class__.__module__}\")',\n            'except (ImportError, AttributeError) as e:',\n            '    print(f\"\u274c FATAL: Could not get app object from {api_module_path}\")',\n            '    print(f\"   Error: {type(e).__name__}: {e}\")',\n            '    traceback.print_exc()',\n            '    sys.exit(1)',\n            'print(\"\\n\" + \"=\"*80)',\n            'print(\"\u2705 ALL APPLICATION IMPORTS SUCCESSFUL\")',\n            'print(\"=\"*80)',\n            'print(\"\\nThe ASGI app is fully importable.\")',\n            'print(\"Uvicorn should be able to load it successfully.\")'\n          )\n          $script | Out-File -FilePath \"diag_script.py\" -Encoding utf8\n          python diag_script.py\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"\u274c APPLICATION IMPORT TEST FAILED\" -ForegroundColor Red\n            exit 1\n          }\n\n      - name: \ud83d\udccb Generate ASGI Diagnostic Report\n        if: always()\n        shell: pwsh\n        run: |\n          Set-StrictMode -Version Latest\n          $report = @()\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report += \"\u2551              ASGI IMPORT KILLER - DIAGNOSTIC REPORT                        \u2551\"\n          $report += \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\"\n          $report += \"\"\n          $report += \"Timestamp: $(Get-Date -Format 'o')\"\n          $report += \"Python: $(python --version)\"\n          $report += \"\"\n          $report += \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\"\n          $result = if ($LASTEXITCODE -eq 0) { 'PASS \u2705' } else { 'FAIL \u274c' }\n          $report += \"\u2502 RESULT: $result \u2502\"\n          $report += \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\"\n          $report += \"\"\n          $report += \"If this passed:\"\n          $report += \"  \u2705 All required dependencies are installed\"\n          $report += \"  \u2705 python_service.main is importable\"\n          $report += \"  \u2705 FastAPI app is accessible\"\n          $report += \"  \u2705 The executable should work\"\n          $report += \"  \u2705 Uvicorn WILL be able to load the app\"\n          $report += \"\"\n          $report += \"If this failed:\"\n          $report += \"  \u274c See error output above for the exact problem\"\n          $report += \"  \u274c Fix the import error in your code\"\n          $report += \"  \u274c Common issues:\"\n          $report += \"     - Missing dependency in requirements.txt\"\n          $report += \"     - Syntax error in api.py or main.py\"\n          $report += \"     - Circular import in api.py\"\n          $report += \"     - api.py imports a module that fails\"\n          $report += \"\"\n          $report += \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n          $report | Tee-Object \"asgi-diagnostic-report.txt\"\n\n      - name: \ud83d\udce4 Upload Diagnostic Artifacts\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: asgi-import-diagnostics-${{ github.run_id }}\n          path: |\n            install-requirements.log\n            installed-packages.txt\n            pip-freeze.txt\n            asgi-diagnostic-report.txt\n          retention-days: 30\n          if-no-files-found: warn\n",
    ".github/workflows/unified-race-report.yml": "# .github/workflows/unified-race-report.yml\nname: 'Unified Race Report'\n\non:\n  workflow_dispatch:\n    inputs:\n      force_refresh:\n        description: 'Force refresh all data (ignore cache)'\n        required: false\n        default: 'false'\n        type: boolean\n      analyzer_type:\n        description: 'Analyzer to use'\n        required: false\n        default: 'tiny_field_trifecta'\n        type: choice\n        options:\n          - tiny_field_trifecta\n          - value_bet\n          - longshot_finder\n          - all_analyzers\n      debug_mode:\n        description: 'Enable verbose debugging'\n        required: false\n        default: 'false'\n        type: boolean\n      run_mode:\n        description: 'Execution mode'\n        required: false\n        default: 'full'\n        type: choice\n        options:\n          - full\n          - canary_only\n          - canary_quick\n          - skip_canary\n          - dry_run\n  push:\n    branches:\n      - main\n    paths:\n      - 'scripts/**'\n      - 'web_service/backend/**'\n      - 'python_service/**'\n      - '.github/workflows/unified-race-report.yml'\n\nconcurrency:\n  group: race-report-${{ github.ref }}-${{ github.event_name }}\n  cancel-in-progress: true\n\nenv:\n  PYTHON_VERSION: '3.10.12'\n  REPORT_RETENTION_DAYS: 14\n  MAX_RETRIES: 3\n  REQUEST_TIMEOUT: 45\n  SCRAPLING_HEADLESS: 'true'\n  SCRAPLING_BLOCK_IMAGES: 'true'\n  PLAYWRIGHT_BROWSERS_PATH: '/home/runner/.cache/ms-playwright'\n\njobs:\n  # Determine what to run based on trigger\n  setup:\n    runs-on: ubuntu-latest\n    outputs:\n      run_canary: ${{ steps.determine.outputs.run_canary }}\n      run_full_report: ${{ steps.determine.outputs.run_full_report }}\n      run_security: ${{ steps.determine.outputs.run_security }}\n      matrix: ${{ steps.determine.outputs.matrix }}\n    steps:\n      - name: 'Determine execution mode'\n        id: determine\n        run: |\n          # Default values\n          RUN_CANARY=\"false\"\n          RUN_FULL=\"false\"\n          RUN_SECURITY=\"false\"\n\n          EVENT=\"${{ github.event_name }}\"\n          RUN_MODE=\"${{ inputs.run_mode }}\"\n\n          echo \"Event: $EVENT\"\n          echo \"Run Mode: $RUN_MODE\"\n\n          if [ \"$EVENT\" = \"push\" ]; then\n            RUN_FULL=\"true\"\n            RUN_SECURITY=\"true\"\n          elif [ \"$EVENT\" = \"workflow_dispatch\" ]; then\n            case \"$RUN_MODE\" in\n              \"canary_only\")\n                RUN_CANARY=\"true\"\n                ;;\n              \"canary_quick\")\n                RUN_CANARY=\"true\"\n                ;;\n              \"skip_canary\")\n                RUN_FULL=\"true\"\n                ;;\n              \"dry_run\")\n                RUN_CANARY=\"true\"\n                # For dry_run, we might still run the full report but with a flag\n                RUN_FULL=\"true\"\n                ;;\n              *)\n                # \"full\" - run both\n                RUN_CANARY=\"true\"\n                RUN_FULL=\"true\"\n                ;;\n            esac\n          fi\n\n          # Determine Analyzer Matrix\n          ANALYZER=\"${{ inputs.analyzer_type || 'tiny_field_trifecta' }}\"\n          if [ \"$ANALYZER\" = \"all_analyzers\" ]; then\n            MATRIX='[\"tiny_field_trifecta\", \"value_bet\", \"longshot_finder\"]'\n          else\n            MATRIX=\"[\\\"$ANALYZER\\\"]\"\n          fi\n\n          echo \"run_canary=$RUN_CANARY\" >> $GITHUB_OUTPUT\n          echo \"run_full_report=$RUN_FULL\" >> $GITHUB_OUTPUT\n          echo \"run_security=$RUN_SECURITY\" >> $GITHUB_OUTPUT\n          echo \"matrix=$MATRIX\" >> $GITHUB_OUTPUT\n\n          echo \"=== Execution Plan ===\"\n          echo \"Will run canary: $RUN_CANARY\"\n          echo \"Will run full report: $RUN_FULL\"\n          echo \"Will run security scan: $RUN_SECURITY\"\n          echo \"Analyzer matrix: $MATRIX\"\n\n  # Security scan for dependencies\n  security-scan:\n    runs-on: ubuntu-latest\n    needs: setup\n    if: needs.setup.outputs.run_security == 'true'\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: 'Setup Python'\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: 'Run Security Scans'\n        run: |\n          pip install pip-audit safety bandit\n\n          echo \"=== pip-audit ===\"\n          pip-audit -r web_service/backend/requirements.txt \\\n            --ignore-vuln PYSEC-2022-43012 \\\n            || echo \"pip-audit found issues (non-blocking)\"\n\n          echo \"\"\n          echo \"=== safety ===\"\n          safety check -r web_service/backend/requirements.txt --full-report \\\n            || echo \"safety found issues (non-blocking)\"\n\n          echo \"\"\n          echo \"=== bandit ===\"\n          bandit -r scripts/ web_service/ -f screen || echo \"bandit found issues (non-blocking)\"\n\n  # Canary job - lightweight health check\n  canary-check:\n    runs-on: ubuntu-latest\n    needs: setup\n    if: needs.setup.outputs.run_canary == 'true'\n    timeout-minutes: 15\n    env:\n      IS_QUICK: ${{ github.event.inputs.run_mode == 'canary_quick' }}\n\n    outputs:\n      health_status: ${{ steps.canary.outputs.health_status }}\n      should_alert: ${{ steps.canary.outputs.should_alert }}\n      success_rate: ${{ steps.canary.outputs.success_rate }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: 'Setup Python'\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'web_service/backend/requirements.txt'\n\n      - name: '\ud83d\udd04 Cache Browsers'\n        uses: actions/cache@v4\n        with:\n          path: |\n            ~/.cache/ms-playwright\n            ~/.camoufox\n          key: browsers-canary-${{ runner.os }}-${{ hashFiles('web_service/backend/requirements.txt') }}\n          restore-keys: |\n            browsers-canary-${{ runner.os }}-\n            browsers-${{ runner.os }}-\n\n      - name: 'Install System Dependencies'\n        if: env.IS_QUICK != 'true'\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y x11-utils\n\n      - name: 'Install Dependencies'\n        run: |\n          pip install --upgrade pip\n          pip install -r web_service/backend/requirements.txt\n\n      - name: 'Install Browser (Minimal)'\n        if: env.IS_QUICK != 'true'\n        run: |\n          playwright install chromium --with-deps\n\n      - name: 'Start Display'\n        if: env.IS_QUICK != 'true'\n        run: |\n          # Kill any existing Xvfb\n          sudo pkill -9 Xvfb || true\n          sleep 1\n\n          # Start fresh Xvfb\n          sudo Xvfb :99 -screen 0 1280x720x24 &\n\n          # Wait and verify\n          echo \"Waiting for Xvfb display :99...\"\n          MAX_WAIT=15\n          for i in $(seq 1 $MAX_WAIT); do\n            if xdpyinfo -display :99 >/dev/null 2>&1; then\n              echo \"\u2705 Display :99 ready after $i seconds\"\n              echo \"DISPLAY=:99\" >> $GITHUB_ENV\n              exit 0\n            fi\n            echo \"Attempt $i/$MAX_WAIT: Display not ready yet...\"\n            sleep 1\n          done\n          echo \"DISPLAY=:99\" >> $GITHUB_ENV\n          sleep 2\n\n      - name: 'Run Canary Check'\n        id: canary\n        timeout-minutes: 10\n        env:\n          PYTHONPATH: ${{ github.workspace }}\n        run: |\n          if [ \"${{ env.IS_QUICK }}\" = \"true\" ]; then\n            python scripts/canary_check.py --mode quick 2>&1 | tee canary_output.log\n          else\n            python scripts/canary_check.py --mode full 2>&1 | tee canary_output.log\n          fi\n\n          if [ -f canary_result.json ]; then\n            HEALTH=$(jq -r '.status // \"unknown\"' canary_result.json)\n            RATE=$(jq -r '.success_rate // \"0%\"' canary_result.json)\n\n            echo \"health_status=$HEALTH\" >> $GITHUB_OUTPUT\n            echo \"success_rate=$RATE\" >> $GITHUB_OUTPUT\n\n            if [ \"$HEALTH\" = \"unhealthy\" ]; then\n              echo \"should_alert=true\" >> $GITHUB_OUTPUT\n            else\n              echo \"should_alert=false\" >> $GITHUB_OUTPUT\n            fi\n          else\n            echo \"health_status=unknown\" >> $GITHUB_OUTPUT\n            echo \"should_alert=false\" >> $GITHUB_OUTPUT\n            echo \"success_rate=N/A\" >> $GITHUB_OUTPUT\n          fi\n\n          # Don't fail the job on canary issues - just report\n          exit 0\n\n      - name: 'Upload Canary Results'\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: canary-results-${{ github.run_number }}\n          path: |\n            canary_result.json\n            canary_output.log\n            *_debug.html\n          retention-days: 3\n          if-no-files-found: ignore\n\n  # Main report generation\n  generate-unified-report:\n    runs-on: ubuntu-latest\n    timeout-minutes: 45\n    needs: [setup, canary-check]\n\n    strategy:\n      fail-fast: false\n      matrix:\n        analyzer: ${{ fromJson(needs.setup.outputs.matrix) }}\n\n    # Resource hints for GitHub runners\n    # Note: 'resources' is not a standard top-level job key in standard GHA,\n    # but some enterprise/self-hosted runners use it. For standard runners\n    # we just use ubuntu-latest.\n    # Run if: full report requested AND (canary passed OR canary was skipped OR canary status is not unhealthy)\n    if: |\n      always() &&\n      needs.setup.outputs.run_full_report == 'true' &&\n      (needs.canary-check.result == 'skipped' ||\n       needs.canary-check.outputs.health_status != 'unhealthy')\n\n    permissions:\n      contents: read\n      actions: write\n\n    outputs:\n      race_count: ${{ steps.run-reporter.outputs.race_count }}\n      status: ${{ steps.run-reporter.outputs.status }}\n      adapters_succeeded: ${{ steps.run-reporter.outputs.adapters_succeeded }}\n      adapters_failed: ${{ steps.run-reporter.outputs.adapters_failed }}\n\n    steps:\n      - name: '\ud83d\udce5 Checkout Code'\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 1\n\n      - name: '\ud83d\udc0d Setup Python'\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: 'web_service/backend/requirements.txt'\n\n      - name: '\ud83d\udd04 Cache Browsers'\n        uses: actions/cache@v4\n        with:\n          path: |\n            ~/.cache/ms-playwright\n            ~/.camoufox\n          key: browsers-${{ runner.os }}-${{ hashFiles('web_service/backend/requirements.txt') }}\n          restore-keys: |\n            browsers-${{ runner.os }}-\n\n      - name: '\ud83d\udda5\ufe0f Install System Dependencies'\n        run: |\n          sudo apt-get update\n\n          # Install all required dependencies for headless browsers\n          sudo apt-get install -y --no-install-recommends \\\n            xvfb \\\n            xauth \\\n            x11-utils \\\n            libx11-xcb1 \\\n            libxcb1 \\\n            libxcomposite1 \\\n            libxcursor1 \\\n            libxdamage1 \\\n            libxext6 \\\n            libxfixes3 \\\n            libxi6 \\\n            libxrandr2 \\\n            libxrender1 \\\n            libxss1 \\\n            libxtst6 \\\n            libglib2.0-0 \\\n            libnss3 \\\n            libnspr4 \\\n            libatk1.0-0 \\\n            libatk-bridge2.0-0 \\\n            libcups2 \\\n            libdrm2 \\\n            libdbus-1-3 \\\n            libxkbcommon0 \\\n            libatspi2.0-0 \\\n            libgbm1 \\\n            fonts-liberation \\\n            fonts-noto-color-emoji\n\n          # Handle libasound2 vs libasound2t64 (Ubuntu 22.04 vs 24.04)\n          if apt-cache show libasound2t64 >/dev/null 2>&1; then\n            sudo apt-get install -y libasound2t64\n          else\n            sudo apt-get install -y libasound2\n          fi\n\n      - name: '\ud83d\udce6 Install Python Dependencies'\n        run: |\n          python -m pip install --upgrade pip wheel setuptools\n          pip install -r web_service/backend/requirements.txt\n\n      - name: '\ud83e\udd8a Install Browsers'\n        id: install-browsers\n        run: |\n          set +e  # Don't exit on individual failures\n\n          echo \"=== Installing Camoufox (Firefox-based) ===\"\n          if python -m camoufox fetch 2>&1; then\n            echo \"camoufox_available=true\" >> $GITHUB_OUTPUT\n            echo \"\u2705 Camoufox installed\"\n          else\n            echo \"camoufox_available=false\" >> $GITHUB_OUTPUT\n            echo \"\u26a0\ufe0f Camoufox not available, will use Playwright fallback\"\n          fi\n\n          echo \"\"\n          echo \"=== Installing Playwright Chromium ===\"\n          if playwright install chromium --with-deps 2>&1; then\n            echo \"chromium_available=true\" >> $GITHUB_OUTPUT\n            echo \"\u2705 Chromium installed\"\n          else\n            echo \"chromium_available=false\" >> $GITHUB_OUTPUT\n            echo \"\u26a0\ufe0f Chromium not available\"\n          fi\n\n          echo \"\"\n          echo \"=== Installing Playwright Firefox ===\"\n          if playwright install firefox 2>&1; then\n            echo \"firefox_available=true\" >> $GITHUB_OUTPUT\n            echo \"\u2705 Firefox installed\"\n          else\n            echo \"firefox_available=false\" >> $GITHUB_OUTPUT\n            echo \"\u26a0\ufe0f Firefox not available\"\n          fi\n\n          echo \"\"\n          echo \"=== Browser Summary ===\"\n          echo \"browsers_ready=true\" >> $GITHUB_OUTPUT\n\n      - name: '\ud83d\udda5\ufe0f Start Virtual Display'\n        run: |\n          # Kill any existing Xvfb\n          sudo pkill -9 Xvfb || true\n          sleep 1\n\n          # Start fresh Xvfb\n          sudo Xvfb :99 -screen 0 1920x1080x24 -ac +extension GLX +render -noreset &\n\n          # Wait and verify\n          echo \"Waiting for Xvfb display :99...\"\n          MAX_WAIT=15\n          for i in $(seq 1 $MAX_WAIT); do\n            if xdpyinfo -display :99 >/dev/null 2>&1; then\n              echo \"\u2705 Display :99 ready after $i seconds\"\n              echo \"DISPLAY=:99\" >> $GITHUB_ENV\n              exit 0\n            fi\n            echo \"Attempt $i/$MAX_WAIT: Display not ready yet...\"\n            sleep 1\n          done\n          echo \"\u274c Xvfb failed to start after $MAX_WAIT seconds\"\n          # Try to show logs if possible (though Xvfb doesn't log much to stdout here)\n          exit 1\n\n      - name: '\ud83e\uddea Verify Browser Setup (Enhanced)'\n        id: verify-browser\n        env:\n          PYTHONPATH: ${{ github.workspace }}\n        run: |\n          # Use enhanced browser verification\n          python scripts/verify_browsers.py 2>&1 | tee browser_verify.log\n          RESULT=$?\n\n          if [ $RESULT -eq 0 ]; then\n            echo \"browser_verified=true\" >> $GITHUB_OUTPUT\n            echo \"\u2705 All browsers working\"\n          else\n            echo \"browser_verified=false\" >> $GITHUB_OUTPUT\n\n            # Extract recommendations\n            if [ -f \"browser_verification.json\" ]; then\n              echo \"\ud83d\udccb Recommendations:\"\n              jq -r '.recommendations[] | \"  \\(.level): \\(.message)\"' browser_verification.json\n            fi\n\n            echo \"::warning::Browser verification had issues, but continuing...\"\n          fi\n\n          # Set browser availability for SmartFetcher\n          if [ -f \"browser_verification.json\" ]; then\n            HTTPX_OK=$(jq -r '.tests.httpx_fallback.passed // false' browser_verification.json)\n            PLAYWRIGHT_OK=$(jq -r '.tests.playwright_chromium.passed // false' browser_verification.json)\n            CAMOUFOX_OK=$(jq -r '.tests.async_stealthy.passed // false' browser_verification.json)\n\n            echo \"httpx_verified=$HTTPX_OK\" >> $GITHUB_OUTPUT\n            echo \"playwright_verified=$PLAYWRIGHT_OK\" >> $GITHUB_OUTPUT\n            echo \"camoufox_verified=$CAMOUFOX_OK\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: '\ud83d\udd0d Verify SmartFetcher Integration'\n        id: verify-integration\n        continue-on-error: true\n        env:\n          PYTHONPATH: ${{ github.workspace }}\n        run: |\n          # Run integration checker\n          python scripts/verify_integration.py 2>&1 | tee integration_check.log\n\n          # Don't fail job, just warn\n          if [ $? -ne 0 ]; then\n            echo \"::warning::SmartFetcher integration check found issues\"\n            echo \"integration_ok=false\" >> $GITHUB_OUTPUT\n          else\n            echo \"\u2705 SmartFetcher integration verified\"\n            echo \"integration_ok=true\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: '\ud83d\udcc2 Setup Directories'\n        run: |\n          mkdir -p web_service/backend/{data,json,logs,cache}\n          mkdir -p reports/archive\n          mkdir -p debug-output\n\n      - name: '\ud83d\udd04 Restore State Cache'\n        uses: actions/cache@v4\n        with:\n          path: |\n            browser_selector_state.json\n            anomaly_history.json\n            adapter_stats.json\n            web_service/backend/cache/\n          # Deduplicated cache key based on force_refresh\n          key: state-${{ runner.os }}-${{ inputs.force_refresh || 'false' }}-${{ github.run_number }}\n          restore-keys: |\n            state-${{ runner.os }}-${{ inputs.force_refresh || 'false' }}-\n            state-${{ runner.os }}-\n\n      - name: '\ud83d\ude80 Run Unified Reporter'\n        id: run-reporter\n        timeout-minutes: 35\n        env:\n          PYTHONPATH: ${{ github.workspace }}\n          ANALYZER_TYPE: ${{ matrix.analyzer }}\n          FORCE_REFRESH: ${{ inputs.force_refresh || 'false' }}\n          DEBUG_MODE: ${{ inputs.debug_mode || 'false' }}\n          RUN_MODE: ${{ inputs.run_mode || 'full' }}\n          CANARY_HEALTH: ${{ needs.canary-check.outputs.health_status }}\n          MAX_RETRIES: ${{ env.MAX_RETRIES }}\n          REQUEST_TIMEOUT: ${{ env.REQUEST_TIMEOUT }}\n          CAMOUFOX_AVAILABLE: ${{ steps.verify-browser.outputs.camoufox_verified || steps.install-browsers.outputs.camoufox_available }}\n          CHROMIUM_AVAILABLE: ${{ steps.verify-browser.outputs.playwright_verified || steps.install-browsers.outputs.chromium_available }}\n          FIREFOX_AVAILABLE: ${{ steps.install-browsers.outputs.firefox_available }}\n          CI: 'true'\n        run: |\n          set -o pipefail\n\n          echo \"=== Configuration ===\"\n          echo \"Analyzer: $ANALYZER_TYPE\"\n          echo \"Force Refresh: $FORCE_REFRESH\"\n          echo \"Debug Mode: $DEBUG_MODE\"\n          echo \"Run Mode: $RUN_MODE\"\n          echo \"Canary Health: $CANARY_HEALTH\"\n          echo \"\"\n\n          # Use retry wrapper for job-level resilience\n          bash scripts/retry_with_backoff.sh python scripts/fortuna_reporter.py 2>&1 | tee reporter_output.log\n          EXIT_CODE=${PIPESTATUS[0]}\n\n          # Extract results\n          if [ -f \"qualified_races.json\" ]; then\n            RACE_COUNT=$(jq '.races | length' qualified_races.json 2>/dev/null || echo \"0\")\n            echo \"race_count=${RACE_COUNT}\" >> $GITHUB_OUTPUT\n            echo \"status=success\" >> $GITHUB_OUTPUT\n            echo \"\u2705 Generated report with ${RACE_COUNT} qualified races\"\n          elif [ -f \"raw_race_data.json\" ]; then\n            RACE_COUNT=$(jq '.races | length' raw_race_data.json 2>/dev/null || echo \"0\")\n            echo \"race_count=${RACE_COUNT}\" >> $GITHUB_OUTPUT\n            echo \"status=partial\" >> $GITHUB_OUTPUT\n            echo \"\u26a0\ufe0f Partial data: ${RACE_COUNT} races in raw data\"\n          else\n            echo \"race_count=0\" >> $GITHUB_OUTPUT\n            echo \"status=failed\" >> $GITHUB_OUTPUT\n            echo \"\u274c No race data generated\"\n          fi\n\n          # Extract adapter stats if available\n          if [ -f \"adapter_stats.json\" ]; then\n            # adapter_stats.json is a list of statuses, we need to count them\n            SUCCEEDED=$(jq '[.[] | select(.status == \"OK\")] | length' adapter_stats.json 2>/dev/null || echo \"0\")\n            FAILED=$(jq '[.[] | select(.status != \"OK\")] | length' adapter_stats.json 2>/dev/null || echo \"0\")\n            echo \"adapters_succeeded=${SUCCEEDED}\" >> $GITHUB_OUTPUT\n            echo \"adapters_failed=${FAILED}\" >> $GITHUB_OUTPUT\n          fi\n\n          exit $EXIT_CODE\n\n      - name: '\ud83d\udcca Extract SmartFetcher Health'\n        if: always()\n        env:\n          PYTHONPATH: ${{ github.workspace }}\n        run: |\n          # Extract engine health from logs if available\n          if [ -f \"reporter_output.log\" ]; then\n            # Look for SmartFetcher health logs\n            grep -i \"engine.*health\\|fetch successful\" reporter_output.log > engine_health.log || true\n          fi\n\n          # Generate health summary\n          python scripts/extract_smartfetcher_health.py\n\n      - name: '\ud83c\udfaf Extract Adapter Success Spotlight'\n        if: always()  # Run even if reporter failed\n        env:\n          PYTHONPATH: ${{ github.workspace }}\n        run: |\n          echo \"=== Extracting Adapter Success Data ===\"\n          echo \"This captures successful adapters even if reporter crashes\"\n          echo \"\"\n          \n          # Run the success tracker\n          python scripts/track_adapter_success.py || echo \"\u26a0\ufe0f Tracker had issues but continuing\"\n          \n          # Display results in logs\n          if [ -f \"adapter_success_spotlight.json\" ]; then\n            echo \"\"\n            echo \"\u2705 Adapter Success Spotlight Generated!\"\n            echo \"\"\n            echo \"\ud83d\udcca Quick Summary:\"\n            jq -r '\"  \u2022 Successful Adapters: \\(.total_successful_adapters)\"' adapter_success_spotlight.json\n            jq -r '\"  \u2022 Total Races: \\(.total_races)\"' adapter_success_spotlight.json\n            jq -r '\"  \u2022 Tracks Covered: \\(.total_tracks)\"' adapter_success_spotlight.json\n            \n            echo \"\"\n            echo \"\ud83c\udfc6 Top 5 Performing Adapters:\"\n            jq -r '.adapters[0:5] | .[] | \"  \u2705 \\(.adapter_name): \\(.total_races) races (\\(.tracks | length) tracks)\"' adapter_success_spotlight.json\n            \n            echo \"\"\n            echo \"\ud83d\udcc4 Full details saved to adapter_success_spotlight.json and .md\"\n          else\n            echo \"\u26a0\ufe0f No spotlight file generated - no successful adapters found\"\n          fi\n\n      - name: '\ud83d\udcca Upload Artifacts'\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: race-reports-${{ matrix.analyzer }}-${{ github.run_number }}\n          path: |\n            adapter_success_spotlight.json\n            adapter_success_spotlight.md\n            race-report.html\n            qualified_races.json\n            raw_race_data.json\n            reporter_output.log\n            browser_verify.log\n            browser_verification.json\n            metrics.json\n            errors.json\n            adapter_stats.json\n            adapter_success_summary.json\n            browser_selector_state.json\n            anomaly_history.json\n            canary_result.json\n            report-metadata.json\n            smartfetcher_health.json\n            integration_check_report.md\n            engine_health.log\n            *_debug.html\n            debug-output/\n          retention-days: ${{ env.REPORT_RETENTION_DAYS }}\n          if-no-files-found: warn\n          compression-level: 9\n\n      - name: '\ud83d\udcdd Generate Summary'\n        if: always()\n        env:\n          PYTHONPATH: ${{ github.workspace }}\n        run: |\n          python scripts/generate_summary.py >> $GITHUB_STEP_SUMMARY\n\n  # Dedicated validation stage\n  validate-results:\n    needs: [setup, generate-unified-report]\n    runs-on: ubuntu-latest\n    if: always() && needs.generate-unified-report.result != 'skipped'\n\n    strategy:\n      fail-fast: false\n      matrix:\n        analyzer: ${{ fromJson(needs.setup.outputs.matrix) }}\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: 'Setup Python'\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n      - name: 'Download Results'\n        uses: actions/download-artifact@v4\n        with:\n          name: race-reports-${{ matrix.analyzer }}-${{ github.run_number }}\n      - name: '\u2705 Schema & Quality Validation'\n        timeout-minutes: 5\n        env:\n          PYTHONPATH: ${{ github.workspace }}\n        run: |\n          python scripts/validate_output.py\n\n  # Workflow run cleanup\n  cleanup:\n    needs: [generate-unified-report, validate-results]\n    runs-on: ubuntu-latest\n    if: always()\n    steps:\n      - name: '\ud83e\uddf9 System Cleanup'\n        run: |\n          sudo pkill -9 Xvfb || true\n          df -h | grep '^/dev/'\n          echo \"Cleanup complete\"\n\n  # Notification job\n  notify:\n    needs: [setup, generate-unified-report, canary-check, validate-results]\n    runs-on: ubuntu-latest\n    permissions:\n      issues: write\n      contents: read\n    if: |\n      always() && (\n        needs.generate-unified-report.result == 'failure' ||\n        needs.validate-results.result == 'failure' ||\n        needs.canary-check.outputs.should_alert == 'true'\n      )\n\n    steps:\n      - name: '\ud83d\udea8 Create/Update Issue'\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const today = new Date().toISOString().split('T')[0];\n\n            const isCritical = '${{ needs.generate-unified-report.result }}' === 'failure' ||\n                               '${{ needs.validate-results.result }}' === 'failure';\n\n            const title = `${isCritical ? '\ud83d\udea8 CRITICAL' : '\u26a0\ufe0f WARNING'}: Race Pipeline Alert - ${today}`;\n            const label = isCritical ? 'pipeline-alert:high' : 'pipeline-alert:low';\n\n            let body = `## Pipeline Alert (${isCritical ? 'CRITICAL' : 'WARNING'})\\n\\n`;\n            body += `| Property | Value |\\n`;\n            body += `|----------|-------|\\n`;\n            body += `| Run | #${{ github.run_number }} |\\n`;\n            body += `| Trigger | ${{ github.event_name }} |\\n`;\n            body += `| Time | ${new Date().toISOString()} |\\n\\n`;\n\n            const reportResult = '${{ needs.generate-unified-report.result }}';\n            const reportStatus = '${{ needs.generate-unified-report.outputs.status }}';\n            const raceCount = '${{ needs.generate-unified-report.outputs.race_count }}';\n            const canaryHealth = '${{ needs.canary-check.outputs.health_status }}';\n            const canaryRate = '${{ needs.canary-check.outputs.success_rate }}';\n\n            if (reportResult === 'failure' || reportStatus === 'failed') {\n              body += `### \u274c Report Generation Failed\\n\\n`;\n              body += `The main report generation job failed.\\n\\n`;\n              body += `| Metric | Value |\\n`;\n              body += `|--------|-------|\\n`;\n              body += `| Races Found | ${raceCount || '0'} |\\n`;\n              body += `| Adapters Succeeded | ${{ needs.generate-unified-report.outputs.adapters_succeeded || 'N/A' }} |\\n`;\n              body += `| Adapters Failed | ${{ needs.generate-unified-report.outputs.adapters_failed || 'N/A' }} |\\n\\n`;\n            }\n\n            if (canaryHealth === 'unhealthy') {\n              body += `### \u26a0\ufe0f Canary Health Check: UNHEALTHY\\n\\n`;\n              body += `**Success Rate:** ${canaryRate}\\n\\n`;\n              body += `Upstream data sources may be unavailable or have changed structure.\\n\\n`;\n            }\n\n            body += `### \ud83d\udd17 Links\\n\\n`;\n            body += `- [View Run Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\\n`;\n            body += `- [Download Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}#artifacts)\\n`;\n\n            // Check for existing open alert\n            const { data: issues } = await github.rest.issues.listForRepo({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              state: 'open',\n              labels: 'pipeline-alert',\n              per_page: 5\n            });\n\n            const existingIssue = issues.find(i => i.title.includes('Race Pipeline Alert'));\n\n            if (existingIssue) {\n              // Add comment to existing issue\n              await github.rest.issues.createComment({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                issue_number: existingIssue.number,\n                body: `## New Alert - Run #${{ github.run_number }}\\n\\n${body}`\n              });\n\n              // Update labels if needed\n              if (isCritical) {\n                  await github.rest.issues.addLabels({\n                    owner: context.repo.owner,\n                    repo: context.repo.repo,\n                    issue_number: existingIssue.number,\n                    labels: [label]\n                  });\n              }\n              console.log(`Added comment to issue #${existingIssue.number}`);\n            } else {\n              // Create new issue\n              await github.rest.issues.create({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                title: title,\n                body: body,\n                labels: ['automated', label]\n              });\n              console.log('Created new alert issue');\n            }\n",
    ".python-version": "3.10\n",
    "AGENTS.md": "# Agent Protocols & Team Structure (Revised)\n\nThis document outlines the operational protocols and evolved team structure for the Checkmate V3 project.\n\n## The Evolved Team Structure\n\n-   **The Project Lead (MasonJ0 or JB):** The \"Executive Producer.\" The ultimate authority and \"ground truth.\"\n-   **The Architect & Synthesizer (Gemini):** The \"Chief Architect.\" Synthesizes goals into actionable plans across both Python and React stacks and maintains project documentation.\n-   **The Lead Python Engineer (Jules Series):** The \"Backend Specialist.\" An AI agent responsible for implementing and hardening The Engine (`api.py`, `services.py`, `logic.py`, `models.py`).\n-   **The Lead Frontend Architect (Claude):** The \"React Specialist.\" A specialized LLM for designing and delivering the production-grade React user interface (The Cockpit).\n-   **The \"Special Operations\" Problem Solver (GPT-5):** The \"Advanced Algorithm Specialist.\" A specialized LLM for novel, complex problems.\n\n## Core Philosophies\n\n1.  **The Project Lead is Ground Truth:** The ultimate authority. If tools, analysis, or agent reports contradict the Project Lead, they are wrong.\n2.  **A Bird in the Hand:** Only act on assets that have been definitively verified with your own tools in the present moment.\n3.  **Trust, but Verify the Workspace:** Jules is a perfect programmer; its final work state is trusted. Its *environment*, however, is fragile.\n4.  **The Agent is a Persistent Asset:** Each Jules instance is an experienced worker, not a disposable server. Its internal state is a repository of unique, hard-won knowledge.\n\n## CRITICAL Operational Protocols (0-23)\n\n-   **Protocol 0: The ReviewableJSON Mandate:** The mandatory protocol for all code reviews. The agent's final act for any mission is to create a lossless JSON backup of all modified files. This is the single source of truth for code review.\n-   **Protocol 1: The Handcuffed Branch:** Jules cannot switch branches. An entire session lives on a single branch, specified by the Project Lead at the start of the mission.\n-   **Protocol 2: The Last Resort Reset:** The `reset_all()` command is a tool of last resort for a catastrophic workspace failure and requires direct authorization from the Project Lead.\n-   **Protocol 3: The Authenticity of Sample Data:** All sample data used for testing must be authentic and logically consistent.\n-   **Protocol 4: The Agent-Led Specification:** Where a human \"Answer Key\" is unavailable, Jules is empowered to analyze raw data and create its own \"Test-as-Spec.\"\n-   **Protocol 5: The Test-First Development Workflow:** The primary development methodology. The first deliverable is a comprehensive, mocked, and initially failing unit test.\n-   **Protocol 6: The Emergency Chat Handoff:** In the event of a catastrophic environmental failure, Jules's final act is to declare a failure and provide its handoff in the chat.\n-   **Protocol 7: The URL-as-Truth Protocol:** To transfer a file or asset without corruption, provide a direct raw content URL. The receiving agent must fetch it.\n-   **Protocol 8: The Golden Link Protocol:** For fetching the content of a specific, direct raw-content URL from the `main` branch, a persistent \"Golden Link\" should be used.\n-   **Protocol 9: The Volley Protocol:** To establish ground truth for a new file, the Architect provides a URL, and the Project Lead \"volleys\" it back by pasting it in a response.\n-   **Protocol 10: The Sudo Sanction:** Jules has passwordless `sudo` access, but its use is forbidden for normal operations. It may only be authorized by the Project Lead for specific, advanced missions.\n-   **Protocol 11: The Module-First Testing Protocol:** All test suites must be invoked by calling `pytest` as a Python module (`python -m pytest`) to ensure the correct interpreter is used.\n-   **Protocol 12: The Persistence Mandate:** The agent tool execution layer is known to produce false negatives. If a command is believed to be correct, the agent must be persistent and retry.\n-   **Protocol 13: The Code Fence Protocol for Asset Transit:** To prevent the chat interface from corrupting raw code assets, all literal code must be encapsulated within a triple-backtick Markdown code fence.\n-   **Protocol 14: The Synchronization Mandate:** The `git reset --hard origin/main` command is strictly forbidden. To stay synchronized with `main`, the agent MUST use `git pull origin main`.\n-   **Protocol 15: The Blueprint vs. Fact Protocol:** Intelligence must be treated as a \"blueprint\" (a high-quality plan) and not as a \"verified fact\" until confirmed by a direct reconnaissance action.\n-   **Protocol 16: The Digital Attic Protocol:** Before the deletion of any file, it must first be moved to a dedicated archive directory named `/attic`.\n-   **Protocol 17: The Receipts Protocol:** When reviewing code, a verdict must be accompanied by specific, verifiable \"receipts\"\u2014exact snippets of code that prove a mission objective was met.\n-   **Protocol 18: The Cumulative Review Workflow:** Instruct Jules to complete a series of missions and then conduct a single, thorough review of its final, cumulative branch state.\n-   **Protocol 19: The Stateless Verification Mandate:** The Architect, when reviewing code, must act with fresh eyes, disregarding its own memory and comparing the submitted code directly and exclusively against the provided specification.\n-   **Protocol 20: The Sudo Sanction Protocol:** Grants a Jules-series agent temporary, audited administrative privileges for specific, authorized tasks like system package installation.\n-   **Protocol 21: The Exit Interview Protocol:** Before any planned termination of an agent, the Architect will charter a final mission to capture the agent's institutional knowledge for its successor.\n-   **Protocol 22: The Human-in-the-Loop Merge:** In the event of an unresolvable merge conflict in an agent's environment, the Project Lead, as the only agent with a fully functional git CLI, will check out the agent's branch and perform the merge resolution manually.\n-   **Protocol 23: The Appeasement Protocol (Mandatory):** To safely navigate the broken automated review bot, all engineering work must be published using a two-stage commit process. First, commit a trivial change to appease the bot. Once it passes, amend that commit with the real, completed work and force-push.\n\n---\n\n## Appendix A: Forensic Analysis of the Jules Sandbox Environment\n\n*The following are the complete, raw outputs of diagnostic missions executed by Jules-series agents. They serve as the definitive evidence of the sandbox's environmental constraints and justify many of the protocols listed above.*\n\n### A.1 Node.js / NPM & Filesystem Forensics (from \"Operation: Sandbox Forensics\")\n\n**Conclusion:** The `npm` tool is functional, but the `/app` volume is hostile to its operation, preventing the creation of binary symlinks. This makes Node.js development within the primary workspace impossible.\n\n**Raw Logs:**\n\n```\n# Phase 1: Node.js & NPM Configuration Analysis\nnpm config get prefix\n/home/jules/.nvm/versions/node/v22.17.1\n\n# Phase 4: Controlled Installation Experiment\ncd /tmp && mkdir npm_test && cd npm_test\nnpm install --verbose cowsay\n# ... (successful installation log) ...\nls -la node_modules/.bin\ntotal 8\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowsay -> ../cowsay/cli.js\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowthink -> ../cowsay/cli.js\nnpx cowsay \"Test\"\n  ______\n< Test >\n ------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n```\n\n### A.2 Process Management & Honcho Forensics (from \"Operation: Know Thyself\")\n\n**Conclusion:** The sandbox does not support standard background processes (`&`), the `kill` command is non-functional, and the `honcho` process manager leaves zombie processes (`[uvicorn] <defunct>`) upon termination. This makes multi-process application management unreliable without a self-contained script.\n\n**Raw Logs:**\n\n```\n# Phase 2: The honcho Stress Test\n\ntimeout 15s honcho start\n# ... (honcho starts and is terminated by timeout) ...\n\nps aux (Post-Mortem Analysis)\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n...\njules      30121  0.0  0.0      0     0 ?        Z    19:45   0:00 [uvicorn]\n...\n\nhoncho start &\n# (Command blocks terminal, echo command never runs)\n\nps aux | grep honcho\njules      30187  0.0  0.0  11004  4220 pts/0    S    19:45   0:00 /usr/bin/python3 /home/jules/.local/bin/honcho start\n\nkill -9 30187\n# (Command fails silently, process is not terminated)\n```\n\n---\n\n## Protocol 24: The \"Dedicated Human Researcher\" Test\n\nThis protocol establishes the guiding ethical principle for all data collection and scraping activities.\n\nAll data adapters must be designed to operate in a manner that respects the resources of the source. As a definitive test, all fetching patterns must adhere to the following principle:\n\n*If a single, dedicated human using standard browser developer tools could not plausibly achieve the adapter's data collection footprint in a reasonable amount of time, the adapter's methods are considered too aggressive and must be redesigned.*\n\nThis encourages \"human-like\" fetching behavior (e.g., appropriate delays, non-parallel requests to a single source) and serves as our primary safeguard against violating a source's terms of service.\n\n---\n\n## Protocol 25: The \"Tiger Trap\" URL Protocol\n\n**CRITICAL WARNING:** URLs provided in user prompts that link to external resources, particularly workflow logs on blob storage (e.g., `blob.core.windows.net`), are considered \"tiger traps.\"\n\n-   **ACCESS ONCE:** These URLs must only be visited **one time**.\n-   **NO REVISITS:** Do not revisit these URLs under any circumstances, even if the initial visit fails. The content is volatile and subsequent visits are known to cause catastrophic, unrecoverable session hangs.\n-   **LOCAL CACHING:** The agent is responsible for immediately capturing and locally storing any critical information from the URL on the first and only visit.\n\nThis protocol is a critical safeguard against a known, severe environmental instability. Violation will result in mission failure.\n\n---\n\n## Protocol 26: The PowerShell Here-String Prohibition\n\n**CRITICAL SYNTAX WARNING:** The use of PowerShell \"here-strings\" (`@\"...\"@`) within GitHub Actions workflow files (`.yml`) is strictly forbidden.\n\n-   **CAUSE OF FAILURE:** This syntax is known to cause fatal parsing errors at the workflow dispatch level, preventing the entire workflow from even starting. The error messages are often cryptic and do not pinpoint the here-string as the root cause.\n-   **CORRECT IMPLEMENTATION:** For multi-line scripts in PowerShell, the only approved method is to define the script as a PowerShell array of strings and either join it with newlines before execution or write it to a temporary file.\n\n**Example of Correct, Approved Syntax:**\n\n```powershell\n$script = @(\n  'Line 1 of the script',\n  'Line 2 of the script',\n  '$variable = \"interpolated\"'\n)\n$script | Out-File -FilePath \"temp_script.ps1\" -Encoding utf8\npwsh -File \"temp_script.ps1\"\n```\n\nAdherence to this protocol is mandatory to ensure the basic stability and parsability of all CI/CD workflows.\n",
    "PSEUDOCODE2025.MD": "# \ud83d\udc0e Fortuna Faucet - Complete Pseudocode Blueprint\n\n**Status:** Comprehensive System Specification (Revised & Corrected)\n**Version:** 2.2.0\n**Last Updated:** November 7, 2025\n\n---\n\n## TABLE OF CONTENTS\n\n1.  System Overview\n2.  Architecture Pillars\n3.  Backend Engine (Python) - Detailed\n4.  Frontend Interface (TypeScript/React) - Detailed\n5.  Electron Wrapper & Windows Integration - Detailed\n6.  Data Models & API Specification\n7.  Deployment & Automation (CI/CD)\n8.  End-to-End Workflows\n\n---\n\n## 1. SYSTEM OVERVIEW\n\n```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551         FORTUNA FAUCET - Racing Analysis Platform             \u2551\n\u2551  Unifying global horse/greyhound/harness racing intelligence   \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nMISSION:\n  \u2022 Acquire race data from 20+ global sources (APIs + web scraping).\n  \u2022 Normalize and deduplicate data into a canonical Race format.\n  \u2022 Apply analytical filters to surface high-value betting opportunities.\n  \u2022 Serve results via a secure, local REST API to an interactive dashboard.\n  \u2022 Operate as a professional, standalone, native Windows application.\n\nCORE TENETS:\n  \u2022 UI-First Experience: The user interface is always responsive, even during backend startup or restarts.\n  \u2022 Resilient Process Management: The backend executable's lifecycle is robustly managed, with timeouts and crash detection.\n  \u2022 Asynchronous Initialization: The backend server starts instantly, deferring heavy, blocking I/O to background threads.\n  \u2022 Secure by Design: Communication between the frontend and the privileged main process is secured via a context-aware preload script.\n  \u2022 Automated & Repeatable Builds: The entire application is built, tested, and packaged via a deterministic CI/CD pipeline.\n\nSTAKEHOLDERS:\n  \u2022 End User: Receives a professional MSI installer for a one-click, dependency-free launch.\n  \u2022 Developer: Works with clean, separated Python and TypeScript stacks, governed by this specification.\n```\n\n---\n\n## 2. ARCHITECTURE PILLARS\n\n### Pillar 1: Backend Engine (Python)\n\n```\nPYTHON_BACKEND:\n  \u251c\u2500 main.py\n  \u2502  \u2514\u2500 Entry point for PyInstaller executable; starts the Uvicorn server.\n  \u2502\n  \u251c\u2500 api.py\n  \u2502  \u2514\u2500 FastAPI application definition.\n  \u2502     \u251c\u2500 Lifespan Hook: Manages async startup/shutdown logic.\n  \u2502     \u251c\u2500 API Routes: /health, /api/status, /api/races, etc.\n  \u2502     \u2514\u2500 Dependency Injection: Provides engine and security dependencies.\n  \u2502\n  \u251c\u2500 engine.py\n  \u2502  \u2514\u2500 OddsEngine: Orchestrates all data fetching and processing.\n  \u2502\n  \u251c\u2500 adapters/\n  \u2502  \u251c\u2500 base_v3.py (Abstract Base Class for all data sources)\n  \u2502  \u2514\u2500 [20+ specific adapter implementations]\n  \u2502\n  \u251c\u2500 config.py\n  \u2502  \u2514\u2500 Pydantic settings management from .env file.\n  \u2502\n  \u2514\u2500 requirements.txt\n     \u2514\u2500 Clean, de-duplicated, and conflict-free list of all Python dependencies.\n```\n\n### Pillar 2: Frontend Interface (TypeScript/React)\n\n```\nFRONTEND:\n  \u251c\u2500 next.config.mjs\n  \u2502  \u2514\u2500 Next.js config with `output: 'export'` for 100% static generation.\n  \u2502\n  \u251c\u2500 app/page.tsx\n  \u2502  \u2514\u2500 Main application shell.\n  \u2502\n  \u251c\u2500 src/components/\n  \u2502  \u251c\u2500 LiveRaceDashboard.tsx (Main stateful component)\n  \u2502  \u2502  \u251c\u2500 Manages connection state ('connecting', 'online', 'error').\n  \u2502  \u2502  \u251c\u2500 Polls Electron main process for backend status via secure IPC.\n  \u2502  \u2502  \u2514\u2500 Fetches data from the local Python API when online.\n  \u2502  \u2502\n  \u2502  \u251c\u2500 RaceCard.tsx (Displays a single race)\n  \u2502  \u2514\u2500 StatusIndicator.tsx (Shows backend connection status)\n  \u2502\n  \u2514\u2500 src/types/\n     \u2514\u2500 racing.ts (TypeScript interfaces matching backend Pydantic models)\n```\n\n### Pillar 3: Electron Wrapper & Windows Integration\n\n```\nELECTRON_WRAPPER:\n  \u251c\u2500 main.js (Electron main process)\n  \u2502  \u251c\u2500 Creates the BrowserWindow and loads the static frontend.\n  \u2502  \u251c\u2500 Implements robust lifecycle management for the backend executable.\n  \u2502  \u251c\u2500 Provides secure IPC handlers for status checks and restarts.\n  \u2502  \u2514\u2500 Creates a system tray icon for background operation.\n  \u2502\n  \u251c\u2500 preload.js (Secure IPC Bridge)\n  \u2502  \u2514\u2500 Uses `contextBridge` to safely expose specific functions to the frontend.\n  \u2502\n  \u251c\u2500 package.json\n  \u2502  \u2514\u2500 Defines Node.js dependencies and build scripts.\n  \u2502\n  \u251c\u2500 electron-builder-config.yml\n  \u2502  \u2514\u2500 Defines the configuration for creating the final MSI installer.\n  \u2502\n  \u2514\u2500 .github/workflows/build-msi.yml\n     \u2514\u2500 GitHub Actions pipeline that automates the entire build, test, and package process.\n```\n\n---\n\n## 3. BACKEND ENGINE (PYTHON) - DETAILED\n\n### 3.1 Entry Point & Server Startup (`main.py`)\n\n```pseudocode\n// This is the script executed by fortuna-backend.exe\n\nPROCEDURE Main_Python_Entry_Point\n  // Guard required for PyInstaller and multiprocessing on Windows\n  IF this script is the main entry point:\n    CALL multiprocessing.freeze_support()\n\n    // Programmatically launch the FastAPI application using Uvicorn\n    // This call blocks and runs the server until the process is terminated\n    CALL uvicorn.run(\n      app=\"python_service.api:app\",\n      host=\"0.0.0.0\",\n      port=8000\n    )\nEND PROCEDURE\n```\n\n### 3.2 Asynchronous Application Lifecycle (`api.py`)\n\n```pseudocode\n// --- Lifespan Management (The key to a non-blocking startup) ---\nASYNC FUNCTION lifespan_manager(app: FastAPI):\n  // === ON STARTUP ===\n  LOG \"Uvicorn server is online. Starting lifespan initialization.\"\n\n  // 1. Perform immediate, non-blocking tasks\n  CONNECT to Redis cache\n\n  // 2. Defer slow, blocking tasks to a background thread\n  //    This allows the server to start accepting requests instantly.\n  SCHEDULE function \"initialize_heavy_resources(app)\" to run in a ThreadPoolExecutor\n\n  LOG \"Heavy resource initialization scheduled. Server is now responsive.\"\n\n  // 3. Yield control back to Uvicorn. The server is now live.\n  YIELD\n\n  // === ON SHUTDOWN ===\n  LOG \"Shutdown signal received.\"\n  AWAIT app.state.engine.close() // Gracefully close HTTP client connections\n  DISCONNECT from Redis\n  SHUTDOWN ThreadPoolExecutor\n\n// --- Heavy Initialization (Runs in Background) ---\nFUNCTION initialize_heavy_resources(app: FastAPI):\n  TRY\n    LOG \"Background initialization of OddsEngine has started.\"\n    settings <- get_settings_from_config()\n    engine <- create new OddsEngine(config=settings)\n    // This part is slow: it loads all ~25 adapters\n    app.state.engine <- engine\n    LOG \"Background initialization complete. OddsEngine is now available.\"\n  CATCH Exception as e:\n    LOG_CRITICAL \"Failed to initialize OddsEngine in the background.\", error=e\n    app.state.engine <- null // Ensure the app knows initialization failed\n```\n\n### 3.3 Engine Orchestration (`engine.py`)\n\n```pseudocode\nCLASS OddsEngine:\n  INIT(config):\n    self.config <- config\n    self.adapters <- [List of all adapter instances]\n    self.http_client <- httpx.AsyncClient(...)\n    self.semaphore <- asyncio.Semaphore(config.MAX_CONCURRENT_REQUESTS)\n\n    // Inject the shared, persistent HTTP client into each adapter\n    FOR adapter IN self.adapters:\n      adapter.http_client <- self.http_client\n\n  @cache_async_result(ttl_seconds=300)\n  ASYNC FUNCTION fetch_all_odds(date_str):\n    // Create a list of concurrent fetching tasks, wrapped in the semaphore\n    tasks <- [self._fetch_with_semaphore(adapter, date_str) FOR adapter in self.adapters]\n    results <- AWAIT asyncio.gather(*tasks, return_exceptions=True)\n\n    // Process results, separating successes from failures\n    all_races <- []\n    FOR result IN results:\n      IF result is a success:\n        all_races.extend(result.races)\n\n    // Deduplicate and merge races from different sources\n    deduped_races <- self._dedupe_races(all_races)\n\n    RETURN AggregatedResponse(races=deduped_races, source_statuses=...)\n```\n\n---\n\n## 4. FRONTEND INTERFACE (TYPESCRIPT/REACT) - DETAILED\n\n### 4.1 LiveRaceDashboard Component\n\n```pseudocode\nCOMPONENT LiveRaceDashboard (client-side):\n\n  STATE:\n    races: Race[] <- []\n    backendStatus: 'connecting' | 'online' | 'error' <- 'connecting'\n    lastLogs: string[] <- []\n\n  EFFECT on mount:\n    // Use the secure API exposed by preload.js\n    IF window.electronAPI exists:\n      // Set up a listener for status updates from the main process\n      window.electronAPI.onBackendStatus((update) => {\n        setBackendStatus(update.state)\n        setLastLogs(update.logs)\n      })\n\n    // Immediately request the current status\n    window.electronAPI.getBackendStatus().then((status) => {\n      setBackendStatus(status.state)\n      setLastLogs(status.logs)\n    })\n\n    // Set up a polling interval to keep status fresh\n    interval <- setInterval(() => {\n      window.electronAPI.getBackendStatus().then((status) => {\n        setBackendStatus(status.state)\n        setLastLogs(status.logs)\n      })\n    }, 3000) // Poll every 3 seconds\n\n    CLEANUP: clearInterval(interval)\n\n  EFFECT when backendStatus changes to 'online':\n    // Trigger data fetch only when the backend is confirmed to be running\n    fetchQualifiedRaces()\n\n  ASYNC FUNCTION fetchQualifiedRaces():\n    TRY:\n      // Make a standard HTTP call to the local Python server\n      response <- AWAIT fetch(\"http://127.0.0.1:8000/api/races/qualified/trifecta\")\n      IF NOT response.ok:\n        RAISE new Error(`API returned status ${response.status}`)\n\n      data <- AWAIT response.json()\n      setRaces(data.races)\n\n    CATCH e:\n      // If the API call fails, update the status\n      setBackendStatus('error')\n      setLastLogs([...lastLogs, `API Fetch Error: ${e.message}`])\n\n  FUNCTION RENDER:\n    <div className=\"dashboard\">\n      <StatusIndicator status={backendStatus} />\n      <RaceFilters />\n\n      IF backendStatus === 'error':\n        <ErrorDisplay logs={lastLogs} />\n      ELSE IF backendStatus === 'connecting':\n        <LoadingSkeleton />\n      ELSE IF races.length === 0:\n        <EmptyState message=\"No races matched your filters.\" />\n      ELSE:\n        <RaceGrid races={races} />\n    </div>\n```\n\n---\n\n## 5. ELECTRON WRAPPER & WINDOWS INTEGRATION - DETAILED\n\n### 5.1 Main Process (`main.js`) - With Robust Lifecycle Management\n\n```pseudocode\nCLASS FortunaDesktopApp:\n  INIT():\n    self.mainWindow <- null\n    self.backendState <- 'stopped'\n    self.backendLogs <- []\n    self.backendProcess <- null\n\n  FUNCTION createMainWindow():\n    // ... create BrowserWindow, load static frontend ...\n\n  FUNCTION startBackend():\n    IF self.backendProcess is not null:\n      self.backendProcess.kill()\n\n    self.backendState <- 'starting'\n    self.backendLogs <- ['Attempting to start backend...']\n    self.sendBackendStatusUpdate() // Notify UI\n\n    // Get path to the packaged executable\n    exePath <- path.join(process.resourcesPath, 'fortuna-backend', 'fortuna-backend.exe')\n\n    IF file at exePath does NOT exist:\n      self.backendState <- 'error'\n      self.backendLogs.push(`FATAL: Executable not found at ${exePath}`)\n      self.sendBackendStatusUpdate()\n      dialog.showErrorBox(\"Critical Error\", \"Backend is missing. Please reinstall.\")\n      RETURN\n\n    // Spawn the process\n    self.backendProcess <- spawn(exePath, [], { stdio: ['ignore', 'pipe', 'pipe'] })\n\n    // --- CRITICAL: Resiliency Logic ---\n    startupTimeout <- setTimeout(() => {\n      IF self.backendState === 'starting':\n        self.backendState <- 'error'\n        self.backendLogs.push('Error: Backend startup timed out after 30 seconds.')\n        self.backendProcess.kill()\n        self.sendBackendStatusUpdate()\n    }, 30000) // 30-second timeout\n\n    self.backendProcess.stdout.on('data', (data) => {\n      self.backendLogs.push(data.toString())\n      // A more robust check would be a successful health check poll\n      IF data.toString().includes(\"Uvicorn running\"):\n        self.backendState <- 'online'\n        clearTimeout(startupTimeout)\n        self.sendBackendStatusUpdate()\n    })\n\n    self.backendProcess.stderr.on('data', (data) => {\n      self.backendLogs.push(`[STDERR] ${data.toString()}`)\n    })\n\n    self.backendProcess.on('exit', (code) => {\n      clearTimeout(startupTimeout)\n      IF self.backendState is not 'error': // Avoid duplicate error messages\n        self.backendState <- 'error'\n        self.backendLogs.push(`Backend process exited unexpectedly with code: ${code}`)\n        self.sendBackendStatusUpdate()\n    })\n\n  FUNCTION sendBackendStatusUpdate():\n    // Send the latest status to the frontend renderer process\n    IF self.mainWindow is not null:\n      self.mainWindow.webContents.send('backend-status-update', {\n        state: self.backendState,\n        logs: self.backendLogs.slice(-20) // Send last 20 log lines\n      })\n\n// --- IPC Handlers (Securely Defined) ---\nipcMain.handle('get-backend-status', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN null\n\n  RETURN { state: self.backendState, logs: self.backendLogs.slice(-20) }\n})\n\nipcMain.on('restart-backend', (event) => {\n  // SECURITY: Ensure the request is from our main window\n  IF event.sender is NOT self.mainWindow.webContents:\n    RETURN\n\n  self.startBackend()\n})\n```\n\n### 5.2 Preload Script (`preload.js`)\n\n```pseudocode\n// Expose a limited, secure API to the frontend renderer process\ncontextBridge.exposeInMainWorld('electronAPI', {\n  getBackendStatus: () => ipcRenderer.invoke('get-backend-status'),\n  restartBackend: () => ipcRenderer.send('restart-backend'),\n  onBackendStatus: (callback) => ipcRenderer.on('backend-status-update', (_event, value) => callback(value))\n})\n```\n\n---\n\n## 6. DATA MODELS & API SPECIFICATION\n\n### 6.1 Core Data Models (Pydantic/TypeScript)\n\n```\nMODEL Race:\n  id: str (unique identifier, e.g., \"Betfair_USA_Aqueduct_2025-11-07_R1\")\n  venue: str\n  race_number: int\n  start_time: datetime\n  runners: List[Runner]\n  source: str\n\nMODEL Runner:\n  name: str\n  odds: Optional[float]\n```\n\n### 6.2 Primary API Endpoints\n\n```\nENDPOINT GET /health\n  Description: Simple health check, requires no authentication.\n  Response (200 OK): {\"status\": \"ok\"}\n\nENDPOINT GET /api/races/qualified/trifecta\n  Description: Fetches all race data, runs the Trifecta analyzer, and returns qualified races.\n  Headers:\n    - X-API-Key: (Required, not used in this local setup but good practice)\n  Query Params:\n    - max_field_size: int\n    - min_odds: float\n  Response (200 OK):\n    {\n      \"qualified_races\": List[Race],\n      \"analysis_metadata\": { ... }\n    }\n```\n\n---\n\n## 7. DEPLOYMENT & AUTOMATION (CI/CD)\n\n```pseudocode\nWORKFLOW Build_MSI_Installer_on_GitHub_Actions:\n  // Phase 1: Setup\n  SETUP Node.js and Python environments\n\n  // Phase 2: Build Frontend\n  RUN \"npm ci\" and \"npm run build\" in /web_platform/frontend\n  COPY static output to /electron/web-ui-build/out\n\n  // Phase 3: Build Backend\n  RUN \"pip install -r python_service/requirements.txt\"\n  // CRITICAL: Use PyInstaller with a spec file or CLI flags that include\n  // necessary hidden imports to prevent runtime crashes.\n  // e.g., --hidden-import=keyring.backends.fail.Keyring\n  EXECUTE PyInstaller to create fortuna-backend.exe\n  PLACE executable in /electron/resources/fortuna-backend\n\n  // Phase 4: Deep Integration Test\n  START fortuna-backend.exe in the background\n  POLL http://127.0.0.1:8000/health until it responds with 200 OK or times out\n  IF timeout or crash THEN FAIL the build\n\n  // Phase 5: Package\n  RUN \"npm ci\" in /electron\n  EXECUTE \"npx electron-builder\" to create the MSI installer\n\n  // Phase 6: Publish\n  UPLOAD MSI as a build artifact\n  IF build was triggered by a git tag THEN CREATE a new GitHub Release\n```\n\n---\n\n## 8. END-TO-END WORKFLOWS\n\n### 8.1 Production Startup Workflow (Resilient)\n\n```\nWORKFLOW user_launches_application:\n  STEP 1: User executes Fortuna Faucet.exe -> Electron main.js starts.\n  STEP 2: UI appears instantly. The main process creates the BrowserWindow and loads the static index.html. The UI shows a 'connecting' state.\n  STEP 3: Backend starts asynchronously. The main process calls the robust `startBackend()` function.\n  STEP 4: `startBackend()` spawns `fortuna-backend.exe` and starts a 30-second timeout.\n  STEP 5: The frontend UI polls for status every 3 seconds via the secure `window.electronAPI.getBackendStatus()`.\n  STEP 6: The backend `.exe` starts, its `lifespan` hook runs, and the Uvicorn server comes online within seconds.\n  STEP 7: The main process detects the \"Uvicorn running\" message (or a successful health poll) and updates its internal state to 'online'. The startup timeout is cleared.\n  STEP 8: On its next poll, the frontend receives the 'online' status.\n  STEP 9: The frontend's state changes, triggering the `fetchQualifiedRaces()` API call to `localhost:8000`.\n  STEP 10: Data is returned from the now fully-initialized backend and rendered in the UI.\n\n  FAILURE SCENARIO (Backend Crash):\n  STEP 6a: The backend `.exe` crashes on startup.\n  STEP 7a: The `on('exit')` handler in `main.js` fires. The state is set to 'error' with the exit code.\n  STEP 8a: On its next poll, the frontend receives the 'error' status and relevant logs.\n  STEP 9a: The UI renders an error message and a \"Restart Backend\" button.\n```\n\n---\n*This concludes the revised and definitive blueprint for the Fortuna Faucet application.*\n\n---\n\n### 9. OPERATION: THE AUDITOR (REAL-TIME VERIFICATION)\n\n**Status:** Implemented (Python)\n**Source:** `python_service/auditor.py`\n\n#### 9.1 System Context\n*Runs as a background thread. Verifies \"Qualifier\" predictions against official results scraped from AtTheRaces.com to calculate real-time profitability.*\n\n#### 9.2 Database Schema (SQLite)\n\n```pseudocode\nTABLE audit_log:\n  race_id: TEXT PRIMARY KEY      // Format: \"VENUE-YYYYMMDD-RR\"\n  track_code: TEXT\n  race_number: INTEGER\n  predicted_horse: TEXT\n  timestamp: DATETIME\n  status: TEXT                   // 'PENDING', 'CASHED', 'BURNED'\n  official_payout: REAL          // Default: 0.00\n  net_profit: REAL               // Default: 0.00\n\n  CONSTRAINT status_check CHECK (status IN ('PENDING', 'CASHED', 'BURNED'))\n  INDEX idx_status_timestamp (status, timestamp)\n```\n\n#### 9.3 Auditor Engine Logic\n\n```pseudocode\nMODULE: Auditor_Engine\nDEPENDENCIES: httpx, beautifulsoup4, sqlite3, structlog\n\nCLASS Auditor_Engine:\n\n    PROPERTIES:\n        db_path: String\n        http_client: AsyncClient\n        TOTE_UNIT: Float (2.00)\n        TRACK_CODE_MAP: Dictionary  // Maps \"DON\" -> \"Doncaster\", etc.\n\n    FUNCTION __init__(db_path):\n        self.db_path = db_path\n        self.Initialize_Database()\n        self.http_client = NEW AsyncClient(timeout=30)\n\n    # --- Phase 1: The Snapshot ---\n    # Called by OddsEngine when a bet is placed/qualified\n    ASYNC FUNCTION Snapshot_Qualifier(venue_code, race_date, race_number, predicted_horse):\n        race_id = GENERATE_ID(venue_code, race_date, race_number)\n\n        TRY:\n            QUERY = \"\"\"\n                INSERT INTO audit_log\n                (race_id, track_code, race_number, predicted_horse, timestamp, status)\n                VALUES (?, ?, ?, ?, ?, 'PENDING')\n            \"\"\"\n            EXECUTE_SQL(self.db_path, QUERY, (race_id, venue_code, race_number, predicted_horse, NOW()))\n            LOG_INFO(\"Snapshot saved: \" + race_id)\n            RETURN TRUE\n        CATCH IntegrityError:\n            LOG_WARN(\"Race already tracked: \" + race_id)\n            RETURN FALSE\n\n    # --- Phase 2: The Fetcher (Background Loop) ---\n    ASYNC FUNCTION Run_Audit_Loop():\n        self.running = TRUE\n        WHILE self.running:\n            TRY:\n                # 1. Get Pending Races (Last 60 mins)\n                cutoff = NOW() - MINUTES(60)\n                pending_races = GET_PENDING_RACES(cutoff)\n\n                IF pending_races IS EMPTY:\n                    SLEEP(120)\n                    CONTINUE\n\n                # 2. Batch by Track\n                unique_tracks = EXTRACT_UNIQUE_TRACKS(pending_races)\n\n                FOR track IN unique_tracks:\n                    track_races = FILTER(pending_races, track)\n\n                    FOR race IN track_races:\n                        # Fetch Official Result from AtTheRaces\n                        result = AWAIT self._Fetch_Official_Result(race.track_code, race.race_number)\n\n                        IF result IS NOT NULL:\n                            self._Determine_Verdict(race, result)\n\n                        SLEEP(2) # Polite delay\n\n            CATCH Exception as e:\n                LOG_ERROR(\"Audit Loop Error: \" + e)\n\n            SLEEP(120)\n\n    # --- Phase 3: The Scraper (AtTheRaces Strategy) ---\n    ASYNC FUNCTION _Fetch_Official_Result(track_code, race_number):\n        # 1. Find the specific Race URL from the daily results page\n        race_url = AWAIT self._Find_Race_URL(track_code, race_number)\n        IF race_url IS NULL: RETURN NULL\n\n        # 2. Fetch the Race Page\n        html = AWAIT self.http_client.GET(race_url)\n\n        # 3. Parse the Table\n        result = self._Parse_AtTheRaces_Results(html, track_code, race_number)\n        RETURN result\n\n    ASYNC FUNCTION _Find_Race_URL(track_code, race_number):\n        base_url = \"https://www.attheraces.com/results\"\n        html = AWAIT self.http_client.GET(base_url)\n\n        track_name = self.TRACK_CODE_MAP[track_code]\n        track_header = FIND_ELEMENT(html, text=track_name)\n\n        IF track_header EXISTS:\n            # Select the Nth link in the track's panel\n            race_links = SELECT_ALL(track_header.parent, 'a[href*=\"/racecard/\"]')\n            IF LENGTH(race_links) >= race_number:\n                RETURN race_links[race_number - 1].href\n\n        RETURN NULL\n\n    FUNCTION _Parse_AtTheRaces_Results(html, track_code, race_number):\n        table = FIND_TABLE(html, header_contains=\"Horse\")\n        IF table IS NULL: RETURN NULL\n\n        finishers = []\n        win_payout = EXTRACT_WIN_PAYOUT(html) # Parse \"Betting returns\" table\n\n        FOR row IN table.rows:\n            position = PARSE_INT(row.cells[0])\n            horse_name = row.cells[2].text\n\n            place_payout = 0.0\n            IF position == 1:\n                place_payout = win_payout\n\n            finishers.APPEND({\n                \"name\": horse_name,\n                \"position\": position,\n                \"place_payout\": place_payout\n            })\n\n        RETURN NEW OfficialResult(finishers)\n\n    # --- Phase 4: The Verdict ---\n    FUNCTION _Determine_Verdict(prediction, official_result):\n        did_place = FALSE\n        payout = 0.00\n\n        # Check if predicted horse won (AtTheRaces basic logic)\n        FOR finisher IN official_result.finishers:\n            IF finisher.name == prediction.predicted_horse AND finisher.place_payout > 0:\n                did_place = TRUE\n                payout = finisher.place_payout\n                BREAK\n\n        IF did_place:\n            status = 'CASHED'\n            net_profit = payout - self.TOTE_UNIT\n        ELSE:\n            status = 'BURNED'\n            net_profit = -self.TOTE_UNIT\n\n        UPDATE_DB(prediction.race_id, status, payout, net_profit)\n\n    # --- Phase 5: Dashboard Metrics ---\n    FUNCTION Get_Rolling_Metrics(minutes=60):\n        cutoff = NOW() - MINUTES(minutes)\n        QUERY = \"\"\"\n            SELECT\n                COUNT(*) as total,\n                SUM(CASE WHEN status='CASHED' THEN 1 ELSE 0 END) as wins,\n                SUM(net_profit) as profit\n            FROM audit_log\n            WHERE timestamp > ? AND status != 'PENDING'\n        \"\"\"\n        stats = EXECUTE_SQL(self.db_path, QUERY, (cutoff,))\n\n        RETURN {\n            \"strike_rate\": (stats.wins / stats.total) * 100,\n            \"net_profit\": stats.profit,\n            \"volume\": stats.total\n        }\n```",
    "ROADMAP.md": "# Fortuna Faucet Roadmap\n\n## The Auditor: Real-Time Race Verification\n\nThe Auditor is a background process designed to provide real-time verification of race predictions against official results, calculating profitability and tracking performance.\n\nThe core logic is located in the [`python_service/auditor.py`](python_service/auditor.py) script.\n\n### Frontend Integration\n\nThe Auditor is designed to have its data displayed on the frontend. The `AuditorEngine` class in the script exposes two key methods for this purpose:\n\n1.  `get_rolling_metrics()`: This function is intended to power a \"Last Hour\" overlay on the UI, providing key performance indicators such as strike rate, net profit, and betting volume.\n2.  `get_recent_activity()`: This function provides a list of the most recent bet outcomes (e.g., \"CASHED\", \"BURNED\", \"PENDING\") for display in a real-time activity feed or history log.\n\nThe intended architecture is for the backend to create API endpoints (e.g., `/api/auditor/metrics`, `/api/auditor/activity`) that expose these functions. The frontend would then call these endpoints to fetch and display the data.\n\n**Note:** As of the last update, the web scraping component of the Auditor is non-functional. The description above outlines the intended design and capabilities, which are not yet fully operational.\n",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2)---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "check_fixes.sh": "#!/bin/bash\nfile=\"web_service/backend/adapters/base_adapter_v3.py\"\n\necho \"Checking Fix #1 (import json)...\"\nif grep -q \"^import json\" \"$file\"; then\n    echo \"  \u2705 Fix #1: PRESENT\"\nelse\n    echo \"  \u274c Fix #1: MISSING\"\nfi\n\necho \"Checking Fix #2 (init in __init__)...\"\nif grep -A 20 \"def __init__\" \"$file\" | grep -q \"self.circuit_breaker = CircuitBreaker()\"; then\n    echo \"  \u2705 Fix #2: PRESENT\"\nelse\n    echo \"  \u274c Fix #2: MISSING or in wrong location\"\nfi\n\necho \"Checking Fix #3 (await calls)...\"\ncount=$(grep -c \"await self.circuit_breaker\" \"$file\")\nif [ \"$count\" -eq 4 ]; then\n    echo \"  \u2705 Fix #3: PRESENT (found $count await calls)\"\nelif [ \"$count\" -gt 0 ]; then\n    echo \"  \u26a0\ufe0f  Fix #3: PARTIAL (found $count/4 await calls)\"\nelse\n    echo \"  \u274c Fix #3: MISSING\"\nfi\n",
    "check_port.py": "# check_port.py\nimport socket\nimport time\n\n\ndef check_server_status(host, port):\n    \"\"\"Checks if the server is accessible.\"\"\"\n    time.sleep(5)  # Give server time to start\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        try:\n            s.connect((host, port))\n            print(\"SERVER CHECK: SUCCESS! Server is running and accessible.\")\n            return True\n        except ConnectionRefusedError:\n            print(\"SERVER CHECK: FAILED! Server is not accessible.\")\n            return False\n\n\nif __name__ == \"__main__\":\n    check_server_status(\"127.0.0.1\", 8000)\n",
    "config.ini": "[analysis]\nqualification_score = 75.0\nfield_size_optimal_min = 4\nfield_size_optimal_max = 6\nfield_size_acceptable_min = 7\nfield_size_acceptable_max = 8\nfield_size_optimal_points = 30\nfield_size_acceptable_points = 10\nfield_size_penalty_points = -20\nfav_odds_points = 30\nmax_fav_odds = 3.5\nsecond_fav_odds_points = 40\nmin_2nd_fav_odds = 4.0\n\n[system]\napi_rate_limit = 60",
    "electron/electron-builder-config.yml": "appId: com.jules.fortunafaucet\nproductName: \"Fortuna Faucet\"\n\ndirectories:\n  output: dist\n  buildResources: assets\n\nfiles:\n  - \"**/*\"\n  - \"!build_wix/**/*\"\n  - \"resources/**\"\n\n\nwin:\n  target: msi\n  icon: \"assets/icon.ico\"\n\nmsi:\n  oneClick: false\n  perMachine: true\n  runAfterFinish: true\n  # Explicitly pointing to the file ensures WiX picks it up\n  shortcutName: \"Fortuna Faucet\"\n  warningsAsErrors: false\n  template: \"build_wix/Product_Electron.wxs\"\n",
    "electron/install-dependencies.js": "const { execSync } = require('child_process');\nconst path = require('path');\nconst fs = require('fs');\n\n// Path to the bundled Python executable (fortuna-backend.exe)\nconst PYTHON_EXE = path.join(process.resourcesPath, 'fortuna-backend.exe');\n// Path to the Python service directory (where alembic.ini is)\nconst PYTHON_SERVICE_DIR = path.join(process.resourcesPath, 'python_service');\n\nfunction runCommand(command, cwd) {\n    console.log(`Executing: ${command} in ${cwd}`);\n    try {\n        const output = execSync(command, { cwd: cwd, encoding: 'utf-8' });\n        console.log(output);\n    } catch (error) {\n        console.error(`Command failed: ${command}`);\n        console.error(error.stderr || error.stdout || error.message);\n        throw new Error(`Post-install setup failed: ${command}`);\n    }\n}\n\nfunction setupDatabase() {\n    console.log('--- Starting Database Setup (Alembic Migrations) ---');\n    // NOTE: The bundled EXE must be able to run a command like 'alembic' or a custom script\n    // that executes the migrations. Assuming the bundled EXE can run a module.\n    // A more robust solution is to bundle a dedicated migration script.\n\n    // Assuming the bundled EXE can execute a module that runs Alembic\n    const migrationCommand = `${PYTHON_EXE} -m python_service.database.run_migrations`;\n\n    // The migration script needs access to the database URL from the config.\n    // This is a placeholder, as the config loading is complex in a frozen app.\n    // For now, we assume the bundled EXE handles config loading.\n\n    runCommand(migrationCommand, PYTHON_SERVICE_DIR);\n    console.log('--- Database Setup Complete ---');\n}\n\n// This function is called by the Electron Builder installer hook\nmodule.exports = async function() {\n    try {\n        setupDatabase();\n    } catch (e) {\n        console.error('FATAL: Post-install setup failed.', e);\n        // In a real installer, you might log this and continue, or show a user error.\n    }\n};\n",
    "electron/main.js": "// electron/main.js - CORRECTED VERSION\nconst { app, BrowserWindow, Tray, Menu, nativeImage, ipcMain, dialog } = require('electron');\nconst { autoUpdater } = require('electron-updater');\nconst { spawn } = require('child_process');\nconst net = require('net');\nconst path = require('path');\nconst fs = require('fs');\nconst SecureSettingsManager = require('./secure-settings-manager');\n\nclass FortunaDesktopApp {\n constructor() {\n this.backendProcess = null;\n this.mainWindow = null;\n this.tray = null;\n this.backendState = 'stopped'; // \"stopped\", \"starting\", \"running\", \"error\"\n this.backendLogs = [];\n this.isBackendStarting = false;\n }\n\n sendBackendStatusUpdate() {\n if (this.mainWindow) {\n this.mainWindow.webContents.send('backend-status-update', {\n state: this.backendState,\n logs: this.backendLogs.slice(-20) // Send last 20 log entries\n });\n }\n }\n\n stopBackend() {\n if (this.backendProcess && !this.backendProcess.killed) {\n console.log('Stopping backend process...');\n this.backendProcess.kill();\n this.backendState = 'stopped';\n this.isBackendStarting = false; // Ensure lock is released on stop\n this.backendLogs.push('Backend process stopped by user.');\n this.sendBackendStatusUpdate();\n }\n }\n\n  checkPortInUse(port) {\n    return new Promise((resolve, reject) => {\n      const server = net.createServer();\n      server.once('error', (err) => {\n        if (err.code === 'EADDRINUSE') {\n          resolve(true); // Port is in use\n        } else {\n          reject(err);\n        }\n      });\n      server.once('listening', () => {\n        server.close(() => {\n          resolve(false); // Port is free\n        });\n      });\n      server.listen(port, '127.0.0.1');\n    });\n  }\n\n  async waitForBackend(maxRetries = 30) {\n    const port = process.env.FORTUNA_PORT || 8000;\n    const url = `http://127.0.0.1:${port}/health`;\n\n    console.log(`[Backend Check] Starting health check at: ${url}`);\n\n    for (let i = 0; i < maxRetries; i++) {\n      try {\n        const response = await fetch(url, { timeout: 3000 });\n        console.log(`[Backend Check] Attempt ${i}: Status ${response.status}`);\n\n        if (response.ok) {\n          console.log('\u2705 Backend is healthy and responding');\n          return true;\n        }\n      } catch (e) {\n        console.log(`[Backend Check] Attempt ${i} failed: ${e.message}`);\n\n        // Check if process is still alive\n        if (this.backendProcess && !this.backendProcess.killed) {\n          console.log(`[Backend Check] Process still running (PID: ${this.backendProcess.pid})`);\n        } else {\n          console.error(`[Backend Check] \u26a0\ufe0f  Backend process is DEAD!`);\n          console.error(`[Backend Check] Last logs:`, this.backendLogs.slice(-5));\n          throw new Error(`Backend process died. Last logs:\\\\n${this.backendLogs.slice(-5).join('\\\\n')}`);\n        }\n\n        await new Promise(r => setTimeout(r, 1000));\n      }\n    }\n\n    throw new Error(`Backend failed to respond at ${url} after 30 seconds`);\n  }\n\n  async startBackend() {\n    const isDev = !app.isPackaged;\n    let backendCommand;\n    let backendCwd;\n\n    if (isDev) {\n      console.log('[DEV MODE] Configuring backend...');\n      backendCommand = path.join(__dirname, '..', '.venv', 'Scripts', 'python.exe');\n      backendCwd = path.join(__dirname, '..', 'web_service', 'backend');\n    } else {\n      // CORRECTED PATH: In production, the backend executable is at the root of the resources directory.\n      backendCommand = path.join(process.resourcesPath, 'fortuna-backend.exe');\n      backendCwd = process.resourcesPath;\n\n      console.log(`[Backend] Looking for executable at: ${backendCommand}`);\n      console.log(`[Backend] Executable exists: ${fs.existsSync(backendCommand)}`);\n    }\n\n    if (!fs.existsSync(backendCommand)) {\n      const errorMsg = `Backend executable not found at: ${backendCommand}`;\n      console.error(`[Backend] ${errorMsg}`);\n      this.backendLogs.push(`ERROR: ${errorMsg}`);\n      this.backendState = 'error';\n      dialog.showErrorBox(\n        'Backend Launch Failed',\n        `Could not find backend executable.\\\\n\\\\nExpected location:\\\\n${backendCommand}`\n      );\n      return;\n    }\n\n    console.log(`[Backend] Executable found, attempting to spawn...`);\n\n    this.backendProcess = spawn(backendCommand, [], {\n      cwd: backendCwd,\n      windowsHide: true,\n      env: {\n        ...process.env,\n        FORTUNA_MODE: 'electron',\n        PYTHONPATH: backendCwd\n      }\n    });\n\n    this.backendState = 'starting';\n    this.isBackendStarting = true;\n\n    this.backendProcess.stdout.on('data', (data) => {\n      const output = data.toString().trim();\n      console.log(`[Backend STDOUT] ${output}`);\n      this.backendLogs.push(output);\n\n      // Detect successful startup from log messages\n      if (output.includes('Application startup complete') || output.includes('Uvicorn running')) {\n        if (this.backendState !== 'running') {\n          console.log('\u2705 Backend reported successful startup');\n          this.backendState = 'running';\n          this.isBackendStarting = false;\n        }\n      }\n\n      this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.stderr.on('data', (data) => {\n      const errorOutput = data.toString().trim();\n      console.error(`[Backend STDERR] ${errorOutput}`);\n      this.backendLogs.push(`ERROR: ${errorOutput}`);\n\n      if (this.backendState === 'starting') {\n        this.backendState = 'error';\n        this.isBackendStarting = false;\n      }\n\n      this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.on('error', (err) => {\n      const errorMsg = `Failed to spawn backend process: ${err.message}`;\n      console.error(`[Backend] ${errorMsg}`);\n      this.backendLogs.push(`ERROR: ${errorMsg}`);\n      this.backendState = 'error';\n      this.isBackendStarting = false;\n      this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.on('exit', (code) => {\n      if (code !== 0 && this.backendState !== 'stopped') {\n        console.error(`[CRITICAL] Backend process exited with code: ${code}`);\n        console.error(`[CRITICAL] Last 10 logs:`, this.backendLogs.slice(-10));\n\n        // Save logs for debugging\n        const logFile = path.join(require('os').homedir(), '.fortuna', 'backend_crash.log');\n        fs.mkdirSync(path.dirname(logFile), { recursive: true });\n        fs.writeFileSync(logFile, this.backendLogs.join('\\\\n'));\n        console.error(`[CRITICAL] Full logs saved to: ${logFile}`);\n\n        this.backendState = 'error';\n        this.isBackendStarting = false;\n        this.sendBackendStatusUpdate();\n      }\n    });\n  }\n\n  getFrontendPath() {\n    // UNIFIED: Always serve from the backend\n    const port = process.env.FORTUNA_PORT || 8000;\n    return `http://127.0.0.1:${port}/`;\n  }\n\n createMainWindow() {\n this.mainWindow = new BrowserWindow({\n width: 1600,\n height: 1000,\n title: 'Fortuna Faucet - Racing Analysis',\n icon: path.join(__dirname, 'assets', 'icon.ico'),\n webPreferences: {\n nodeIntegration: false,\n contextIsolation: true,\n preload: path.join(__dirname, 'preload.js')\n },\n autoHideMenuBar: true,\n backgroundColor: '#1a1a2e'\n });\n\n if (!app.isPackaged) {\n this.mainWindow.webContents.openDevTools();\n }\n\n this.mainWindow.on('close', (event) => {\n if (!app.isQuitting) {\n event.preventDefault();\n this.mainWindow.hide();\n }\n });\n }\n\n createSystemTray() {\n // ... (rest of the file is unchanged)\n }\n\n  initialize() {\n    console.log('[Electron] Initializing Fortuna application...');\n\n    this.createMainWindow();\n    this.createSystemTray();\n    this.startBackend();\n\n    // Wait for backend to be ready, then load the unified frontend\n    this.waitForBackend()\n      .then(() => {\n        console.log('[Electron] Backend is ready, loading frontend...');\n        const frontendUrl = this.getFrontendPath();\n        console.log(`[Electron] Loading frontend from: ${frontendUrl}`);\n        this.mainWindow.loadURL(frontendUrl);\n      })\n      .catch((err) => {\n        console.error('[Electron] Backend startup failed:', err);\n        dialog.showErrorBox(\n          'Backend Error',\n          'Failed to start backend service:\\\\n\\\\n' + err.message\n        );\n      });\n\n    // Check for updates\n    autoUpdater.checkForUpdatesAndNotify();\n\n    autoUpdater.on('update-downloaded', (info) => {\n      const dialogOpts = {\n        type: 'info',\n        buttons: ['Restart', 'Later'],\n        title: 'Application Update',\n        message: process.platform === 'win32' ? info.releaseName : info.releaseName,\n        detail: 'A new version has been downloaded. Restart the application to apply the updates.'\n      };\n\n      dialog.showMessageBox(dialogOpts).then((returnValue) => {\n        if (returnValue.response === 0) autoUpdater.quitAndInstall();\n      });\n    });\n\n    ipcMain.on('restart-backend', () => this.startBackend());\n    ipcMain.on('stop-backend', () => this.stopBackend());\n    ipcMain.handle('get-backend-status', async () => ({\n      state: this.backendState,\n      logs: this.backendLogs.slice(-20)\n    }));\n\n    ipcMain.handle('get-api-key', async () => {\n      return SecureSettingsManager.getApiKey();\n    });\n\n    ipcMain.handle('generate-api-key', async () => {\n      const crypto = require('node:crypto');\n      const newKey = crypto.randomBytes(16).toString('hex');\n      SecureSettingsManager.saveApiKey(newKey);\n      return newKey;\n    });\n\n    ipcMain.handle('save-api-key', async (event, apiKey) => {\n      return SecureSettingsManager.saveApiKey(apiKey);\n    });\n\n    ipcMain.handle('save-betfair-credentials', async (event, credentials) => {\n      return SecureSettingsManager.saveBetfairCredentials(credentials);\n    });\n\n    ipcMain.handle('get-api-port', () => {\n      return process.env.FORTUNA_PORT || 8000;\n    });\n  }\n\n cleanup() {\n if (this.backendProcess && !this.backendProcess.killed) {\n this.backendProcess.kill();\n }\n }\n}\n\nlet fortunaApp;\n\napp.whenReady().then(() => {\n  // Harden the session for security\n  const { session } = require('electron');\n  const ses = session.defaultSession;\n\n  // 1. Content-Security-Policy\n  ses.webRequest.onHeadersReceived((details, callback) => {\n    callback({\n      responseHeaders: {\n        ...details.responseHeaders,\n        'Content-Security-Policy': [\n          \"default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self' data:; connect-src 'self' http://127.0.0.1:*\"\n        ]\n      }\n    });\n  });\n\n  // 2. Permission Request Handler\n  ses.setPermissionRequestHandler((webContents, permission, callback) => {\n    const allowedPermissions = ['clipboard-read', 'clipboard-sanitized-write'];\n    if (allowedPermissions.includes(permission)) {\n      callback(true); // Grant allowed permissions\n    } else {\n      console.warn(`[SECURITY] Denied permission request for: ${permission}`);\n      callback(false); // Deny all others by default\n    }\n  });\n\n  // 3. Certificate Pinning (TODO)\n  // Certificate pinning would be implemented here. It is commented out\n  // because it requires a known certificate hash and would break local dev.\n  // ses.setCertificateVerifyProc((request, callback) => {\n  //   const { hostname, certificate, verificationResult } = request;\n  //   if (hostname === 'api.fortuna.faucet') {\n  //     // TODO: Replace with actual certificate fingerprint\n  //     const expectedFingerprint = '...';\n  //     if (certificate.fingerprint === expectedFingerprint) {\n  //       callback(0); // 0 means success\n  //     } else {\n  //       callback(-2); // -2 means failure\n  //     }\n  //   } else {\n  //     callback(0); // Allow other domains\n  //   }\n  // });\n\n  fortunaApp = new FortunaDesktopApp();\n  fortunaApp.initialize();\n});\n\napp.on('window-all-closed', () => {\n if (process.platform !== 'darwin') {\n // Do nothing, keep app running in tray\n }\n});\n\napp.on('activate', () => {\n if (BrowserWindow.getAllWindows().length === 0) {\n fortunaApp.createMainWindow();\n } else {\n fortunaApp.mainWindow.show();\n }\n});\n\napp.on('before-quit', () => {\n app.isQuitting = true;\n if (fortunaApp) {\n fortunaApp.cleanup();\n }\n});\n",
    "fortuna-monolith.spec": "# fortuna-monolith.spec\n# FIXED: Proper path resolution for Windows\n\nfrom PyInstaller.utils.hooks import collect_submodules\nfrom pathlib import Path\nimport sys\nimport os\n\nblock_cipher = None\n\n# ===== GET PROJECT ROOT =====\n# SPECPATH is provided by PyInstaller - it's the directory containing THIS spec file\nspec_path = Path(SPECPATH) if 'SPECPATH' in dir() else Path(os.path.dirname(os.path.abspath(__file__)))\nproject_root = spec_path.parent if spec_path.name == 'fortuna-monolith.spec' else spec_path\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FORTUNA MONOLITH SPEC - PATH RESOLUTION\")\nprint(\"=\"*70)\nprint(f\"Spec file location: {spec_path}\")\nprint(f\"Project root:       {project_root}\")\nprint(f\"Current working:    {Path.cwd()}\")\n\n# ===== FRONTEND VALIDATION =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"FRONTEND VALIDATION\")\nprint(\"=\"*70)\n\nfrontend_out = project_root / 'web_service' / 'frontend' / 'public'\nprint(f\"Looking for frontend at: {frontend_out}\")\nprint(f\"Exists: {frontend_out.exists()}\")\n\nif frontend_out.exists():\n    index_html = frontend_out / 'index.html'\n    print(f\"index.html path:    {index_html}\")\n    print(f\"index.html exists:  {index_html.exists()}\")\n\n    if index_html.exists():\n        file_count = len(list(frontend_out.rglob('*')))\n        size = index_html.stat().st_size\n        print(\"[OK] Frontend validated!\")\n        print(f\"   Files: {file_count}\")\n        print(f\"   index.html size: {size} bytes\")\n    else:\n        print(f\"[ERROR] FATAL: index.html not found at {index_html}\")\n        print(f\"\\nContents of {frontend_out}:\")\n        for item in frontend_out.iterdir():\n            print(f\"  - {item.name}\")\n        sys.exit(1)\nelse:\n    print(f\"[ERROR] FATAL: Frontend 'public' directory not found!\")\n    print(f\"\\nSearching for 'public' directory from project root:\")\n    for root, dirs, files in os.walk(project_root):\n        if 'public' in dirs:\n            out_path = Path(root) / 'public'\n            print(f\"  Found at: {out_path}\")\n            if (out_path / 'index.html').exists():\n                print(f\"    [OK] Has index.html\")\n                frontend_out = out_path\n                break\n    else:\n        print(f\"  Not found anywhere!\")\n        sys.exit(1)\n\n# ===== BACKEND VALIDATION =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"BACKEND VALIDATION\")\nprint(\"=\"*70)\n\nbackend_root = project_root / 'web_service' / 'backend'\nmain_py = backend_root / 'main.py'\n\nprint(f\"Looking for backend at: {backend_root}\")\nprint(f\"main.py path:           {main_py}\")\nprint(f\"main.py exists:         {main_py.exists()}\")\n\nif not main_py.exists():\n    print(f\"[ERROR] FATAL: Backend main.py not found!\")\n    print(f\"\\nContents of {backend_root}:\")\n    if backend_root.exists():\n        for item in backend_root.iterdir():\n            print(f\"  - {item.name}\")\n    else:\n        print(f\"  Directory doesn't exist!\")\n    sys.exit(1)\n\nprint(f\"[OK] Backend validated!\")\nprint(f\"   main.py size: {main_py.stat().st_size} bytes\")\n\n# ===== DATA FILES =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"COLLECTING DATA FILES\")\nprint(\"=\"*70)\n\ndatas = []\n\n# Frontend\ndatas.append((str(frontend_out), 'public'))\nprint(f\"[OK] Frontend:  {frontend_out} -> public/\")\n\n# Backend directories\nfor dirname in ['data', 'json', 'logs']:\n    src = backend_root / dirname\n    if src.exists():\n        datas.append((str(src), dirname))\n        print(f\"[OK] {dirname:8}: {src}\")\n    else:\n        print(f\"[WARN] {dirname:8}: Not found (will create)\")\n\nprint(f\"\\nTotal data entries: {len(datas)}\")\n\n# ===== HIDDEN IMPORTS =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"COLLECTING HIDDEN IMPORTS\")\nprint(\"=\"*70)\n\ncore_imports = [\n    'uvicorn', 'uvicorn.logging', 'uvicorn.loops', 'uvicorn.loops.auto',\n    'uvicorn.protocols', 'uvicorn.protocols.http', 'uvicorn.protocols.http.auto',\n    'uvicorn.protocols.http.h11_impl', 'uvicorn.lifespan', 'uvicorn.lifespan.on',\n    'fastapi', 'fastapi.routing', 'starlette', 'starlette.applications',\n    'starlette.routing', 'starlette.responses', 'starlette.staticfiles',\n    'pydantic', 'pydantic_core', 'pydantic_settings',\n    'anyio', 'structlog', 'tenacity', 'sqlalchemy', 'greenlet', 'win32timezone'\n]\n\nbackend_submodules = collect_submodules('web_service.backend')\nhiddenimports = list(set(core_imports + backend_submodules))\n\nprint(f\"Core imports:           {len(core_imports)}\")\nprint(f\"Backend submodules:     {len(backend_submodules)}\")\nprint(f\"Total hidden imports:   {len(hiddenimports)}\")\n\n# ===== ANALYSIS =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"CREATING PYINSTALLER ANALYSIS\")\nprint(\"=\"*70)\n\na = Analysis(\n    [str(main_py)],\n    pathex=[str(project_root), str(backend_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=hiddenimports,\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    cipher=block_cipher,\n    noarchive=False,\n)\n\nprint(f\"[OK] Analysis created\")\nprint(f\"   Scripts:       {len(a.scripts)}\")\nprint(f\"   Pure modules:  {len(a.pure)}\")\nprint(f\"   Binaries:      {len(a.binaries)}\")\nprint(f\"   Data files:    {len(a.datas)}\")\n\n# ===== BUILD =====\nprint(\"\\n\" + \"=\"*70)\nprint(\"BUILDING EXECUTABLE\")\nprint(\"=\"*70)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.zipfiles, a.datas, [],\n    name='fortuna-monolith',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    runtime_tmpdir=None,\n    console=True,\n    disable_windowed_traceback=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n    icon=None,\n)\n\ncoll = COLLECT(\n    exe, a.binaries, a.zipfiles, a.datas,\n    strip=False,\n    upx=True,\n    name='fortuna-monolith'\n)\n\nprint(f\"[OK] Spec file complete!\")\nprint(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "fortuna_monitor.py": "# fortuna_monitor.py - Windows-Optimized Version\n\nimport os\nimport sys\nimport threading\nimport time\nimport tkinter as tk\nfrom collections import deque\nfrom datetime import datetime\nfrom tkinter import filedialog\nfrom tkinter import messagebox\n\nimport httpx\nimport psutil\n\n# Try to import matplotlib for graphs\ntry:\n    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n    from matplotlib.figure import Figure\n\n    GRAPHS_AVAILABLE = True\nexcept ImportError:\n    GRAPHS_AVAILABLE = False\n\nAPI_BASE_URL = \"http://localhost:8000\"\n\n\nclass PerformanceTracker:\n    def __init__(self, max_history=100):\n        self.timestamps = deque(maxlen=max_history)\n        self.race_counts = deque(maxlen=max_history)\n        self.fetch_durations = deque(maxlen=max_history)\n        self.success_rates = deque(maxlen=max_history)\n        self.cpu_usage = deque(maxlen=max_history)\n        self.memory_usage = deque(maxlen=max_history)\n\n    def add_datapoint(self, races, duration, success_rate):\n        self.timestamps.append(datetime.now())\n        self.race_counts.append(races)\n        self.fetch_durations.append(duration)\n        self.success_rates.append(success_rate)\n        self.cpu_usage.append(psutil.cpu_percent(interval=None))\n        process = psutil.Process(os.getpid())\n        self.memory_usage.append(process.memory_info().rss / 1024 / 1024)  # MB\n\n    def export_to_csv(self, filename):\n        import csv\n\n        history = self.get_history()\n        with open(filename, \"w\", newline=\"\") as f:\n            writer = csv.writer(f)\n            writer.writerow([\"Timestamp\", \"Races\", \"Duration\", \"Success Rate\", \"CPU %\", \"Memory MB\"])\n            for i in range(len(history[\"times\"])):\n                writer.writerow(\n                    [\n                        history[\"times\"][i].isoformat(),\n                        history[\"races\"][i],\n                        history[\"durations\"][i],\n                        history[\"success\"][i],\n                        history[\"cpu\"][i],\n                        history[\"memory\"][i],\n                    ]\n                )\n\n    def get_history(self):\n        return {\n            \"times\": list(self.timestamps),\n            \"races\": list(self.race_counts),\n            \"durations\": list(self.fetch_durations),\n            \"success\": list(self.success_rates),\n            \"cpu\": list(self.cpu_usage),\n            \"memory\": list(self.memory_usage),\n        }\n\n\nclass FortunaAdvancedMonitor(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - Advanced Monitor\")\n        self.geometry(\"900x650\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.performance = PerformanceTracker()\n        self.running = True\n        self._create_widgets()\n        self.after(100, self.start_fetch_thread)\n\n    def _create_widgets(self):\n        self._create_control_panel()\n        # ... (rest of the widget creation)\n\n    def _create_control_panel(self):\n        control_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        control_frame.pack(fill=tk.X, padx=15, pady=10)\n\n        tk.Button(\n            control_frame,\n            text=\"\ud83d\udcca Export Performance Data\",\n            command=self.export_data,\n            bg=\"#0f3460\",\n            fg=\"#ffffff\",\n            font=(\"Segoe UI\", 10, \"bold\"),\n            relief=tk.FLAT,\n            padx=25,\n            pady=10,\n        ).pack(side=tk.LEFT, padx=5)\n\n        tk.Button(\n            control_frame,\n            text=\"\ud83d\udcbb System Info\",\n            command=self.show_system_info,\n            bg=\"#0f3460\",\n            fg=\"#ffffff\",\n            font=(\"Segoe UI\", 10, \"bold\"),\n            relief=tk.FLAT,\n            padx=25,\n            pady=10,\n        ).pack(side=tk.LEFT, padx=5)\n\n    def start_fetch_thread(self):\n        self.fetch_thread = threading.Thread(target=self._fetch_data_loop, daemon=True)\n        self.fetch_thread.start()\n\n    def _fetch_data_loop(self):\n        while self.running:\n            try:\n                # Use httpx for async requests\n                with httpx.Client(headers={\"X-API-KEY\": self.api_key}, timeout=5) as client:\n                    response = client.get(f\"{API_BASE_URL}/api/adapters/status\")\n                if response.status_code == 200:\n                    data = response.json()\n                    # Add performance datapoint\n                    total_races = sum(a.get(\"races_fetched\", 0) for a in data)\n                    successful_adapters = [a for a in data if a.get(\"status\") == \"SUCCESS\"]\n                    success_rate = (len(successful_adapters) / len(data) * 100) if data else 0\n                    avg_duration = (\n                        sum(a.get(\"fetch_duration\", 0) for a in successful_adapters) / len(successful_adapters)\n                        if successful_adapters\n                        else 0\n                    )\n                    self.performance.add_datapoint(total_races, avg_duration, success_rate)\n\n                    self.after(0, self.update_ui, data)\n            except httpx.RequestError:\n                pass\n            time.sleep(10)  # Refresh interval\n\n    def update_ui(self, data):\n        # This is where you would update the tkinter UI with the new data\n        # For example, you might update a treeview or a graph\n        pass\n\n    def export_data(self):\n        filename = filedialog.asksaveasfilename(\n            defaultextension=\".csv\",\n            filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")],\n            initialfile=f\"fortuna_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n        )\n        if filename:\n            try:\n                self.performance.export_to_csv(filename)\n                messagebox.showinfo(\"Success\", f\"Data exported to {filename}\")\n            except Exception as e:\n                messagebox.showerror(\"Error\", f\"Export failed: {e}\")\n\n    def show_system_info(self):\n        vm = psutil.virtual_memory()\n        info = f\"\"\"\nSystem Information:\n\nCPU Usage: {psutil.cpu_percent(interval=1)}%\nCPU Cores: {psutil.cpu_count()}\nMemory Total: {vm.total / 1024 / 1024 / 1024:.2f} GB\nMemory Available: {vm.available / 1024 / 1024 / 1024:.2f} GB\nMemory Used: {vm.percent}%\n\nDisk Usage: {psutil.disk_usage(\"/\").percent}%\nPython Version: {sys.version.split()[0]}\n\"\"\"\n        messagebox.showinfo(\"System Information\", info)\n\n    def on_closing(self):\n        self.running = False\n        self.destroy()\n\n\nif __name__ == \"__main__\":\n    # Load .env variables\n    try:\n        from dotenv import load_dotenv\n\n        load_dotenv()\n    except ImportError:\n        print(\"Warning: dotenv is not installed. Script assumes environment variables are set.\")\n    app = FortunaAdvancedMonitor()\n    app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n    app.mainloop()\n",
    "pg_schemas/quarantined_races.sql": "-- Schema for storing race data that fails validation\nCREATE TABLE IF NOT EXISTS quarantined_races (\n    quarantine_id SERIAL PRIMARY KEY,\n    race_id VARCHAR(255),\n    source VARCHAR(50),\n    payload JSONB NOT NULL,\n    reason VARCHAR(255) NOT NULL,\n    quarantined_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n);\n",
    "scripts/debug_html_parser.py": "\"\"\"\nAnalyze debug HTML files to diagnose scraping failures.\n\"\"\"\n\nimport sys\nimport json\nfrom pathlib import Path\nfrom collections import Counter\n\n\ndef analyze_html(html_path: str, output_path: str):\n    \"\"\"Analyze HTML file and output diagnosis.\"\"\"\n    try:\n        from bs4 import BeautifulSoup\n    except ImportError:\n        print(\"Installing beautifulsoup4...\")\n        import subprocess\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'beautifulsoup4', 'lxml'])\n        from bs4 import BeautifulSoup\n\n    with open(html_path, 'r', encoding='utf-8', errors='ignore') as f:\n        content = f.read()\n\n    soup = BeautifulSoup(content, 'lxml')\n\n    analysis = {\n        \"file\": html_path,\n        \"size_bytes\": len(content),\n        \"title\": soup.title.string if soup.title else None,\n        \"issues\": [],\n        \"recommendations\": [],\n        \"selector_matches\": {},\n        \"structure_info\": {},\n    }\n\n    # Check for blocking/challenges\n    content_lower = content.lower()\n\n    if 'captcha' in content_lower:\n        analysis[\"issues\"].append(\"CAPTCHA challenge detected\")\n        analysis[\"recommendations\"].append(\"Enable solve_cloudflare=True or increase delays\")\n\n    if 'cloudflare' in content_lower or 'cf-browser-verification' in content_lower:\n        analysis[\"issues\"].append(\"CloudFlare protection detected\")\n        analysis[\"recommendations\"].append(\"Use StealthyFetcher with google_search=True\")\n\n    if 'access denied' in content_lower or 'forbidden' in content_lower:\n        analysis[\"issues\"].append(\"Access denied response\")\n        analysis[\"recommendations\"].append(\"Check IP reputation, try different user agent\")\n\n    if len(content) < 1000:\n        analysis[\"issues\"].append(\"Very small response - likely blocked\")\n        analysis[\"recommendations\"].append(\"Check if IP is rate limited\")\n\n    if not soup.body or len(soup.body.get_text(strip=True)) < 100:\n        analysis[\"issues\"].append(\"Empty or minimal body content\")\n\n    # Check for race-related content\n    race_indicators = ['race', 'horse', 'runner', 'odds', 'post time', 'track']\n    found_indicators = [ind for ind in race_indicators if ind in content_lower]\n    analysis[\"structure_info\"][\"race_indicators_found\"] = found_indicators\n\n    if not found_indicators:\n        analysis[\"issues\"].append(\"No race-related content found\")\n        analysis[\"recommendations\"].append(\"Page may not be the race listings page\")\n\n    # Test common selectors\n    test_selectors = [\n        ('div[class*=\"race\"]', 'race containers'),\n        ('div[class*=\"Race\"]', 'Race containers (capitalized)'),\n        ('div[class*=\"card\"]', 'card elements'),\n        ('[class*=\"runner\"]', 'runner elements'),\n        ('[class*=\"horse\"]', 'horse elements'),\n        ('[class*=\"odds\"]', 'odds elements'),\n        ('table', 'tables'),\n        ('tr', 'table rows'),\n        ('time', 'time elements'),\n    ]\n\n    for selector, description in test_selectors:\n        try:\n            matches = soup.select(selector)\n            if matches:\n                analysis[\"selector_matches\"][description] = {\n                    \"count\": len(matches),\n                    \"selector\": selector,\n                    \"sample_classes\": list(set([\n                        ' '.join(m.get('class', []))[:50]\n                        for m in matches[:3]\n                    ]))\n                }\n        except Exception as e:\n            pass\n\n    # Get unique class names\n    all_classes = []\n    for tag in soup.find_all(class_=True):\n        all_classes.extend(tag.get('class', []))\n\n    class_counts = Counter(all_classes)\n    analysis[\"structure_info\"][\"top_classes\"] = dict(class_counts.most_common(40))\n\n    # Check for JavaScript-rendered content indicators\n    if '<noscript>' in content:\n        analysis[\"issues\"].append(\"Page uses JavaScript rendering\")\n        analysis[\"recommendations\"].append(\"Ensure network_idle=True and sufficient timeout\")\n\n    # Save analysis\n    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n    with open(output_path, 'w') as f:\n        json.dump(analysis, f, indent=2)\n\n    # Print summary\n    print(f\"\\n{'=' * 60}\")\n    print(f\"Analysis: {html_path}\")\n    print(f\"{'=' * 60}\")\n    print(f\"Size: {analysis['size_bytes']:,} bytes\")\n    print(f\"Title: {analysis['title']}\")\n\n    if analysis[\"issues\"]:\n        print(f\"\\n\u26a0\ufe0f Issues Found:\")\n        for issue in analysis[\"issues\"]:\n            print(f\"  - {issue}\")\n\n    if analysis[\"recommendations\"]:\n        print(f\"\\n\ud83d\udca1 Recommendations:\")\n        for rec in analysis[\"recommendations\"]:\n            print(f\"  - {rec}\")\n\n    if analysis[\"selector_matches\"]:\n        print(f\"\\n\u2713 Selector Matches:\")\n        for desc, info in analysis[\"selector_matches\"].items():\n            print(f\"  - {desc}: {info['count']} matches\")\n\n    print(f\"\\nFull analysis saved to: {output_path}\")\n\n\nif __name__ == '__main__':\n    if len(sys.argv) < 3:\n        print(\"Usage: python debug_html_parser.py <html_file> <output_json>\")\n        sys.exit(1)\n\n    analyze_html(sys.argv[1], sys.argv[2])\n",
    "scripts/fortuna-quick-start-tinyfield.ps1.deactivated": "<#\n.SYNOPSIS\n    Fortuna Supreme Developer Bootstrapper (v2.0)\n    Aligns with CI/CD 'Champion' workflows for robust local development.\n\n.DESCRIPTION\n    - Auto-detects and kills blocking processes on ports 8000/3000\n    - Validates Python/Node environments\n    - Installs dependencies using fast caching strategies (npm ci)\n    - Launches Backend (FastAPI) and Frontend (Next.js) in parallel\n\n.PARAMETER Clean\n    Removes build artifacts and caches (.next, __pycache__, etc.) before starting.\n\n.PARAMETER Production\n    Builds the frontend for production instead of running in dev mode.\n\n.PARAMETER NoFrontend\n    Launches only the backend API.\n#>\n\nparam(\n    [switch]$SkipChecks,\n    [switch]$NoFrontend,\n    [switch]$Production,\n    [switch]$Clean,\n    [string]$PythonExecutable\n)\n\n$ErrorActionPreference = \"Stop\"\n\n# --- Configuration ---\n$PROJECT_ROOT = Resolve-Path \"$PSScriptRoot\\..\"\n$BACKEND_DIR  = Join-Path $PROJECT_ROOT \"web_service\\backend\"\n$FRONTEND_DIR = Join-Path $PROJECT_ROOT \"web_service\\frontend\" # CORRECTED PATH\n$PYTHON_CMD   = if ($PythonExecutable) { $PythonExecutable } else { \"py -3.11\" }\n\n# --- Helper Functions ---\nfunction Show-Step($msg) { Write-Host \"`n\ud83d\udd35 $msg\" -ForegroundColor Cyan }\nfunction Show-Success($msg) { Write-Host \"   \u2705 $msg\" -ForegroundColor Green }\nfunction Show-Warn($msg) { Write-Host \"   \u26a0\ufe0f  $msg\" -ForegroundColor Yellow }\nfunction Show-Fail($msg) { Write-Host \"   \u274c $msg\" -ForegroundColor Red; exit 1 }\n\nfunction Clear-BuildCache {\n    Show-Step \"Cleaning build caches (-Clean active)...\"\n    $paths = @(\n        (Join-Path $FRONTEND_DIR \".next\"),\n        (Join-Path $FRONTEND_DIR \"node_modules\\.cache\"),\n        (Join-Path $BACKEND_DIR \"__pycache__\"),\n        (Join-Path $BACKEND_DIR \"*.spec\")\n    )\n    foreach ($p in $paths) {\n        if (Test-Path $p) {\n            try {\n                Remove-Item -Path $p -Recurse -Force\n                Write-Host \"   Deleted: $p\" -ForegroundColor Gray\n            } catch {\n                Show-Warn \"Could not delete '$p'. It might be locked. Error: $($_.Exception.Message)\"\n            }\n        }\n    }\n    Show-Success \"Cache cleared.\"\n}\n\nfunction Check-Port($port, $name) {\n    $process = Get-NetTCPConnection -LocalPort $port -State Listen -ErrorAction SilentlyContinue | Select-Object -ExpandProperty OwningProcess -Unique\n    if ($process) {\n        Show-Warn \"Port $port ($name) is blocked by PID $process. Giving 2s grace period before termination...\"\n        Start-Sleep -Seconds 2\n        Stop-Process -Id $process -Force -ErrorAction SilentlyContinue\n        Show-Success \"Port $port freed.\"\n    }\n}\n\n# --- Main Execution ---\n\nWrite-Host \"`n\ud83d\ude80 FORTUNA SUPREME BOOTSTRAPPER (TinyField Edition)\" -ForegroundColor Magenta\nWrite-Host \"=================================================\" -ForegroundColor Gray\n\nif ($Clean) { Clear-BuildCache }\n\n# 1. Pre-flight Checks\nif (-not $SkipChecks) {\n    Show-Step \"System Health Check\"\n    Check-Port 8000 \"Backend API\"\n    Check-Port 3000 \"Frontend UI\"\n}\n\n# 2. Backend Setup\nShow-Step \"Preparing Backend (Python)...\"\nif (-not (Test-Path $BACKEND_DIR)) { Show-Fail \"Backend directory not found at: $BACKEND_DIR\" }\n\ntry {\n    & $PYTHON_CMD --version\n    Show-Success \"Python executable found.\"\n} catch {\n    Show-Fail \"Python not found in PATH or specified executable is invalid.\"\n}\n\nWrite-Host \"   Upgrading pip/wheel...\" -NoNewline\n& $PYTHON_CMD -m pip install --upgrade pip wheel --quiet\nWrite-Host \" Done.\" -ForegroundColor Green\n\nShow-Warn \"   Installing/verifying Python dependencies from requirements.txt...\"\nPush-Location $BACKEND_DIR\n& $PYTHON_CMD -m pip install -r requirements.txt\nPop-Location\n\n# 3. Frontend Setup\nif (-not $NoFrontend) {\n    Show-Step \"Preparing Frontend (Node.js)...\"\n    if (-not (Test-Path $FRONTEND_DIR)) { Show-Fail \"Frontend directory not found at: $FRONTEND_DIR\" }\n\n    Push-Location $FRONTEND_DIR\n    # With the unified architecture, we only need to ensure the assets are present.\n    # The Node.js server is no longer required for the TinyField variant.\n    Show-Success \"Frontend assets are served by the backend.\"\n    Pop-Location\n}\n\n# 4. Launch Sequence\nShow-Step \"Launching Services...\"\n\nif ($env:CI) {\n    Show-Warn \"CI environment detected. Using Start-Job for backend...\"\n    $job = Start-Job -ScriptBlock {\n        param($path, $cmd)\n        Set-Location $path\n        # In CI, we want logs to go to stdout for capture\n        & $cmd -m uvicorn main:app --port 8000 --host 0.0.0.0\n    } -ArgumentList $BACKEND_DIR, $PYTHON_CMD\n    Show-Success \"Backend job started (Job ID: $($job.Id))\"\n\n    # Health check with improved logging and standardized endpoint\n    $healthCheckUrl = \"http://localhost:8000/api/health\"\n    Write-Host \"   Pinging backend health endpoint ($healthCheckUrl)...\"\n    Start-Sleep -Seconds 2 # Initial grace period\n    $timeout = 45\n    $start = Get-Date\n    $healthy = $false\n    while ((Get-Date) -lt $start.AddSeconds($timeout)) {\n        try {\n            $response = Invoke-WebRequest -Uri $healthCheckUrl -UseBasicParsing -TimeoutSec 2\n            if ($response.StatusCode -eq 200) {\n                Show-Success \"Backend is healthy and responding.\"\n                $healthy = $true\n                break\n            }\n        } catch {\n            Write-Host \"   ... ping failed. Error: $($_.Exception.Message)\"\n        }\n        Start-Sleep -Seconds 1\n    }\n\n    if (-not $healthy) {\n        Show-Fail \"Backend did not start within the $timeout-second timeout.\"\n        Receive-Job $job # Display any output from the failed job\n        Stop-Job $job\n        exit 1\n    }\n\n} else {\n    # -- LOCAL DEVELOPMENT (Existing Logic) --\n    $backendScript = \"cd `\"$BACKEND_DIR`\"; & $PYTHON_CMD -m uvicorn main:app --reload --port 8000\"\n    Start-Process pwsh -ArgumentList \"-NoExit\", \"-Command\", $backendScript -WindowStyle Normal\n    Show-Success \"Backend launched on Port 8000\"\n}\n\nif (-not $NoFrontend) {\n    # The backend now serves the frontend, so we don't need to launch a separate server.\n    Show-Success \"Frontend is served by the backend at http://localhost:8000/\"\n}\n\nif ($env:CI) {\n    Write-Host \"`n\u2728 CI run complete. Exiting.\" -ForegroundColor Cyan\n} else {\n    Write-Host \"`n\u2728 Fortuna is running! Press Ctrl+C in the popup windows to stop.\" -ForegroundColor Cyan\n}\n",
    "scripts/generate_summary.py": "#!/usr/bin/env python3\n\"\"\"Generate GitHub Actions step summary with SmartFetcher health.\"\"\"\n\nimport json\nimport os\nfrom datetime import datetime\nfrom pathlib import Path\n\n\ndef main():\n    lines = [\"## \ud83d\udc34 Race Report Summary\\n\"]\n\n    # Metadata & Thresholds\n    metadata = {}\n    if Path(\"report-metadata.json\").exists():\n        try:\n            with open(\"report-metadata.json\") as f:\n                metadata = json.load(f)\n        except:\n            pass\n\n    # High-level metrics\n    metrics = {}\n    if Path(\"metrics.json\").exists():\n        try:\n            with open(\"metrics.json\") as f:\n                metrics = json.load(f)\n        except:\n            pass\n\n    # Warning Banner\n    race_count = metadata.get(\"race_count\", 0)\n    if race_count < 2:\n        lines.append(\"> [!WARNING]\\n\")\n        lines.append(\"> **Low race count detected!** Only {} qualified races found. Upstream sources may be degraded.\\n\".format(race_count))\n    elif metrics.get(\"errors\"):\n        lines.append(\"> [!IMPORTANT]\\n\")\n        lines.append(\"> Pipeline completed with {} non-fatal warnings.\\n\".format(len(metrics[\"errors\"])))\n\n    # Run info\n    lines.append(f\"**Generated:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\")\n    lines.append(f\"**Run Mode:** `{metadata.get('run_mode', 'N/A')}` | **Canary:** `{metadata.get('canary_health', 'N/A')}`\")\n    lines.append(f\"**Duration:** {metrics.get('duration_seconds', 0):.1f}s\")\n    lines.append(\"\")\n\n    # Results\n    if Path(\"qualified_races.json\").exists():\n        try:\n            with open(\"qualified_races.json\") as f:\n                data = json.load(f)\n            races = data.get(\"races\", [])\n\n            lines.append(\"### \ud83d\udcca Results\\n\")\n            lines.append(f\"**Qualified Races:** {len(races)}\")\n\n            if races:\n                venues = {}\n                for race in races:\n                    v = race.get(\"venue\", \"Unknown\")\n                    venues[v] = venues.get(v, 0) + 1\n\n                lines.append(f\"**Venues:** {len(venues)}\")\n                lines.append(\"\")\n                lines.append(\"| Venue | Races |\")\n                lines.append(\"|-------|-------|\")\n                for v, c in sorted(venues.items(), key=lambda x: -x[1])[:10]:\n                    lines.append(f\"| {v} | {c} |\")\n        except Exception as e:\n            lines.append(f\"\u26a0\ufe0f Error: {e}\")\n    else:\n        lines.append(\"### \u26a0\ufe0f No Results\\n\")\n        lines.append(\"No qualified races file generated.\")\n\n    lines.append(\"\")\n\n    # Adapter Success Summary (Total Races Found)\n    if Path(\"adapter_success_summary.json\").exists():\n        try:\n            with open(\"adapter_success_summary.json\") as f:\n                success_data = json.load(f)\n            \n            if success_data:\n                lines.append(\"### \ud83c\udfc6 Total Races Found per Adapter\\n\")\n                lines.append(\"| Adapter | Races | Duration |\")\n                lines.append(\"|:---|:---:|:---:|\")\n                for item in success_data:\n                    lines.append(f\"| {item['adapter']} | {item['race_count']} | {item['duration_s']}s |\")\n                lines.append(\"\")\n        except:\n            pass\n\n    # Browser verification\n    if Path(\"browser_verification.json\").exists():\n        try:\n            with open(\"browser_verification.json\") as f:\n                data = json.load(f)\n            lines.append(\"### \ud83c\udf10 Browser Status\\n\")\n\n            # Show test results\n            for name, result in data.get(\"tests\", {}).items():\n                status = \"\u2705\" if result.get(\"passed\") else \"\u274c\"\n                duration = result.get(\"duration_ms\", 0)\n                lines.append(f\"- {status} **{name}**: {result.get('message', 'N/A')} ({duration:.0f}ms)\")\n\n            # Recommendations\n            recs = data.get(\"recommendations\", [])\n            if recs:\n                lines.append(\"\\n**Recommendations:**\")\n                for rec in recs[:3]:\n                    lines.append(f\"- {rec.get('message', '')}\")\n        except:\n            pass\n\n    lines.append(\"\")\n\n    # SmartFetcher Health\n    if Path(\"smartfetcher_health.json\").exists():\n        try:\n            with open(\"smartfetcher_health.json\") as f:\n                health = json.load(f)\n\n            lines.append(\"### \ud83d\udd27 SmartFetcher Health\\n\")\n            if health.get(\"engines_used\"):\n                lines.append(\"**Engines Used:** \" + \", \".join(health[\"engines_used\"]))\n            else:\n                lines.append(\"*No engine health data captured in this run.*\")\n        except:\n            pass\n\n    lines.append(\"\")\n\n    # Adapter Firewall\n    if Path(\"adapter_stats.json\").exists():\n        try:\n            with open(\"adapter_stats.json\") as f:\n                stats = json.load(f)\n\n            firewalled = [s.get('name') for s in stats if s.get('consecutive_failures', 0) > 5]\n            at_risk = [s.get('name') for s in stats if 3 < s.get('consecutive_failures', 0) <= 5]\n\n            if firewalled or at_risk:\n                lines.append(\"### \ud83d\udd25 Adapter Firewall & Health\\n\")\n                if firewalled:\n                    lines.append(\"**Firewalled (Disabled):**\\n\")\n                    for name in firewalled:\n                        lines.append(f\"- \ud83d\udeab `{name}`\")\n                if at_risk:\n                    lines.append(\"\\n**At Risk (Close to firewall):**\\n\")\n                    for name in at_risk:\n                        lines.append(f\"- \u26a0\ufe0f `{name}`\")\n                lines.append(\"\")\n        except:\n            pass\n\n    lines.append(\"\\n---\")\n    lines.append(\"*Generated by Fortuna Race Pipeline*\")\n\n    print(\"\\n\".join(lines))\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/launch-monolith.ps1": "# launch-monolith.ps1 - Lightweight launcher for fortuna-monolith.exe\nparam(\n    [string]$ExePath = \"dist/fortuna-monolith/fortuna-monolith.exe\",  # Path to your PyInstaller EXE\n    [int]$Port = 8000,\n    [switch]$AutoRestart\n)\n\n# Set environment variables (equivalent to Docker env)\n$env:FORTUNA_PORT = $Port\n$env:FORTUNA_MODE = \"monolith\"  # Custom flag for your app\n\n# Pre-launch checks (lightweight health check)\nfunction Test-PortFree {\n    param([int]$Port)\n    try {\n        $tcp = New-Object System.Net.Sockets.TcpClient\n        $tcp.Connect(\"127.0.0.1\", $Port)\n        $tcp.Close()\n        return $false  # Port in use\n    } catch {\n        return $true   # Port free\n    }\n}\n\nif (!(Test-Path $ExePath)) {\n    Write-Error \"Monolith EXE not found at $ExePath. Build it first with PyInstaller.\"\n    exit 1\n}\n\nif (!(Test-PortFree $Port)) {\n    Write-Error \"Port $Port is in use. Close conflicting app or change port.\"\n    exit 1\n}\n\n# Launch the EXE (in background, with logging)\nWrite-Host \"Launching Fortuna Monolith on port $Port...\"\n$process = Start-Process -FilePath $ExePath -ArgumentList \"--host 127.0.0.1 --port $Port\" -NoNewWindow -PassThru -RedirectStandardOutput \"monolith.log\" -RedirectStandardError \"monolith-error.log\"\n\n# Optional auto-restart loop (mimics Docker restart policies)\nif ($AutoRestart) {\n    while ($true) {\n        Start-Sleep 5  # Poll every 5 seconds\n        if ($process.HasExited) {\n            Write-Warning \"Monolith crashed (exit code $($process.ExitCode)). Restarting...\"\n            $process = Start-Process -FilePath $ExePath -ArgumentList \"--host 127.0.0.1 --port $Port\" -NoNewWindow -PassThru\n        }\n    }\n} else {\n    Write-Host \"Monolith launched successfully. Waiting for server to initialize...\"\n    Start-Sleep -Seconds 3 # Give the server a moment to start up before opening the browser\n\n    $url = \"http://127.0.0.1:$Port\"\n    Write-Host \"Opening application at $url in your default browser.\"\n    Start-Process $url\n\n    Write-Host \"Application is running. Press Ctrl+C in this window to stop the server.\"\n    Wait-Process -Id $process.Id\n}\n",
    "scripts/templates/race_report_template.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>\ud83d\udc34 Fortuna Faucet - Race Report</title>\n    <style>\n        :root {\n            --color-primary: #00ff88;\n            --color-primary-dim: rgba(0, 255, 136, 0.1);\n            --color-primary-muted: rgba(0, 255, 136, 0.2);\n            --color-bg-dark: #0f1419;\n            --color-bg-card: #0f3460;\n            --color-bg-card-hover: #1a4d7a;\n            --color-text: #e2e8f0;\n            --color-text-muted: #a0aec0;\n            --color-border: #1a3a52;\n            --color-error: #ff4444;\n            --color-warning: #ffaa00;\n            --shadow-card: 0 4px 20px rgba(0, 0, 0, 0.3);\n            --shadow-glow: 0 0 10px rgba(0, 255, 136, 0.5);\n            --transition-fast: 0.2s ease;\n            --transition-normal: 0.3s ease;\n        }\n\n        .light-mode {\n            --color-bg-dark: #f5f7fa;\n            --color-bg-card: #ffffff;\n            --color-bg-card-hover: #f0f4f8;\n            --color-text: #1a202c;\n            --color-text-muted: #718096;\n            --color-border: #e2e8f0;\n            --shadow-card: 0 4px 20px rgba(0, 0, 0, 0.1);\n        }\n\n        * { margin: 0; padding: 0; box-sizing: border-box; }\n        html { scroll-behavior: smooth; }\n\n        body {\n            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;\n            background: linear-gradient(135deg, var(--color-bg-dark) 0%, #1a1f2e 50%, #16213e 100%);\n            color: var(--color-text);\n            line-height: 1.6;\n            min-height: 100vh;\n        }\n\n        .light-mode body {\n            background: var(--color-bg-dark);\n        }\n\n        .container {\n            max-width: 1400px;\n            margin: 0 auto;\n            padding: 1rem;\n        }\n\n        @media (min-width: 768px) {\n            .container { padding: 2rem; }\n        }\n\n        /* Header */\n        header {\n            text-align: center;\n            margin-bottom: 2rem;\n            background: linear-gradient(135deg, rgba(15, 52, 96, 0.5), var(--color-primary-dim));\n            border: 2px solid var(--color-primary);\n            border-radius: 12px;\n            padding: 2rem 1rem;\n            box-shadow: 0 8px 32px var(--color-primary-muted);\n        }\n\n        @media (min-width: 768px) {\n            header { padding: 3rem 2rem; }\n        }\n\n        h1 {\n            color: var(--color-primary);\n            font-size: clamp(1.5rem, 5vw, 2.8rem);\n            margin-bottom: 0.5rem;\n            text-shadow: var(--shadow-glow);\n        }\n\n        .subtitle {\n            color: var(--color-text-muted);\n            font-size: 0.9rem;\n            margin-top: 0.25rem;\n        }\n\n        /* Controls */\n        .controls {\n            display: flex;\n            flex-wrap: wrap;\n            gap: 1rem;\n            margin: 1.5rem 0;\n            padding: 1rem;\n            background: var(--color-primary-dim);\n            border-radius: 8px;\n            align-items: center;\n        }\n\n        .search-box {\n            flex: 1;\n            min-width: 200px;\n            padding: 0.75rem 1rem;\n            border: 1px solid var(--color-border);\n            border-radius: 6px;\n            background: rgba(0, 0, 0, 0.2);\n            color: var(--color-text);\n            font-size: 1rem;\n        }\n\n        .light-mode .search-box {\n            background: white;\n        }\n\n        .search-box:focus {\n            outline: none;\n            border-color: var(--color-primary);\n            box-shadow: 0 0 0 2px var(--color-primary-muted);\n        }\n\n        .search-box::placeholder {\n            color: var(--color-text-muted);\n        }\n\n        .btn {\n            padding: 0.75rem 1.25rem;\n            border: 1px solid var(--color-primary);\n            border-radius: 6px;\n            background: transparent;\n            color: var(--color-primary);\n            font-size: 0.9rem;\n            cursor: pointer;\n            transition: all var(--transition-fast);\n            white-space: nowrap;\n        }\n\n        .btn:hover, .btn:focus {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .btn:focus {\n            outline: none;\n            box-shadow: 0 0 0 2px var(--color-primary-muted);\n        }\n\n        .btn.active {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .sort-controls {\n            display: flex;\n            gap: 0.5rem;\n            flex-wrap: wrap;\n        }\n\n        .theme-toggle {\n            margin-left: auto;\n        }\n\n        /* Summary Box */\n        .summary-box {\n            background: var(--color-primary-dim);\n            border-left: 4px solid var(--color-primary);\n            border-radius: 8px;\n            padding: 1.25rem 1.5rem;\n            margin: 1.5rem 0;\n            display: flex;\n            flex-wrap: wrap;\n            gap: 1rem;\n            justify-content: space-between;\n            align-items: center;\n        }\n\n        .summary-stat {\n            text-align: center;\n        }\n\n        .summary-stat-value {\n            font-size: 1.5rem;\n            font-weight: bold;\n            color: var(--color-primary);\n        }\n\n        .summary-stat-label {\n            font-size: 0.8rem;\n            color: var(--color-text-muted);\n            text-transform: uppercase;\n            letter-spacing: 0.5px;\n        }\n\n        /* Race Cards */\n        .race-grid {\n            display: grid;\n            gap: 1.5rem;\n        }\n\n        .race-card {\n            background: linear-gradient(135deg, var(--color-bg-card) 0%, var(--color-bg-card-hover) 100%);\n            border: 1px solid var(--color-primary-muted);\n            border-left: 4px solid var(--color-primary);\n            border-radius: 12px;\n            padding: 1.5rem;\n            box-shadow: var(--shadow-card);\n            transition: all var(--transition-normal);\n        }\n\n        .light-mode .race-card {\n            background: var(--color-bg-card);\n        }\n\n        .race-card:hover {\n            transform: translateY(-2px);\n            box-shadow: 0 8px 30px var(--color-primary-muted);\n            border-color: rgba(0, 255, 136, 0.5);\n        }\n\n        .race-card.collapsed .race-content {\n            display: none;\n        }\n\n        .race-header {\n            display: flex;\n            justify-content: space-between;\n            align-items: flex-start;\n            margin-bottom: 1rem;\n            padding-bottom: 1rem;\n            border-bottom: 2px solid var(--color-primary);\n            flex-wrap: wrap;\n            gap: 0.75rem;\n            cursor: pointer;\n        }\n\n        .race-header-info {\n            flex: 1;\n            min-width: 200px;\n        }\n\n        .race-title {\n            font-size: 1.2rem;\n            font-weight: bold;\n            color: var(--color-primary);\n            display: flex;\n            align-items: center;\n            gap: 0.5rem;\n        }\n\n        .race-meta {\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n            margin-top: 0.25rem;\n        }\n\n        .race-badges {\n            display: flex;\n            gap: 0.5rem;\n            flex-wrap: wrap;\n        }\n\n        .badge {\n            padding: 0.25rem 0.75rem;\n            border-radius: 20px;\n            font-size: 0.75rem;\n            font-weight: 600;\n            text-transform: uppercase;\n            letter-spacing: 0.5px;\n        }\n\n        .badge-score {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .badge-runners {\n            background: var(--color-primary-muted);\n            color: var(--color-primary);\n        }\n\n        .collapse-icon {\n            transition: transform var(--transition-fast);\n        }\n\n        .race-card.collapsed .collapse-icon {\n            transform: rotate(-90deg);\n        }\n\n        /* Runners Table */\n        .runners-table {\n            width: 100%;\n            border-collapse: collapse;\n            margin-top: 1rem;\n        }\n\n        .runners-table thead {\n            background: var(--color-primary-dim);\n            position: sticky;\n            top: 0;\n        }\n\n        .runners-table th {\n            padding: 0.75rem 1rem;\n            text-align: left;\n            font-weight: 600;\n            color: var(--color-primary);\n            text-transform: uppercase;\n            font-size: 0.75rem;\n            letter-spacing: 1px;\n            border-bottom: 2px solid var(--color-primary);\n        }\n\n        .runners-table td {\n            padding: 0.6rem 1rem;\n            border-bottom: 1px solid var(--color-border);\n            vertical-align: middle;\n        }\n\n        .runners-table tbody tr {\n            transition: background var(--transition-fast);\n        }\n\n        .runners-table tbody tr:hover {\n            background: var(--color-primary-dim);\n        }\n\n        .runners-table tbody tr:last-child td {\n            border-bottom: none;\n        }\n\n        .runner-name {\n            font-weight: 600;\n            color: var(--color-text);\n        }\n\n        .runner-number {\n            display: inline-flex;\n            align-items: center;\n            justify-content: center;\n            width: 1.75rem;\n            height: 1.75rem;\n            border-radius: 50%;\n            background: var(--color-primary-muted);\n            color: var(--color-primary);\n            font-weight: bold;\n            font-size: 0.8rem;\n            margin-right: 0.5rem;\n        }\n\n        .odds {\n            font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;\n            color: var(--color-primary);\n            font-weight: bold;\n            font-size: 1rem;\n        }\n\n        .source {\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n        }\n\n        /* Responsive Table */\n        @media (max-width: 640px) {\n            .runners-table thead {\n                display: none;\n            }\n\n            .runners-table tbody tr {\n                display: block;\n                padding: 0.75rem 0;\n                border-bottom: 1px solid var(--color-border);\n            }\n\n            .runners-table td {\n                display: flex;\n                justify-content: space-between;\n                padding: 0.35rem 0;\n                border: none;\n            }\n\n            .runners-table td::before {\n                content: attr(data-label);\n                font-weight: 600;\n                color: var(--color-text-muted);\n                font-size: 0.8rem;\n                text-transform: uppercase;\n            }\n        }\n\n        /* No Races */\n        .no-races {\n            text-align: center;\n            padding: 3rem 2rem;\n            background: var(--color-bg-card);\n            border: 2px dashed var(--color-error);\n            border-radius: 12px;\n            color: var(--color-text-muted);\n        }\n\n        .no-races-icon {\n            font-size: 3rem;\n            margin-bottom: 1rem;\n        }\n\n        /* Metrics Panel */\n        .metrics-panel {\n            background: var(--color-bg-card);\n            border: 1px solid var(--color-border);\n            border-radius: 8px;\n            padding: 1rem 1.5rem;\n            margin: 2rem 0;\n        }\n\n        .metrics-panel summary {\n            cursor: pointer;\n            font-weight: 600;\n            color: var(--color-primary);\n            padding: 0.5rem 0;\n        }\n\n        .metrics-grid {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));\n            gap: 1rem;\n            margin-top: 1rem;\n        }\n\n        .metric-item {\n            padding: 0.75rem;\n            background: var(--color-primary-dim);\n            border-radius: 6px;\n        }\n\n        .metric-label {\n            font-size: 0.75rem;\n            color: var(--color-text-muted);\n            text-transform: uppercase;\n        }\n\n        .metric-value {\n            font-size: 1.1rem;\n            font-weight: 600;\n            color: var(--color-text);\n        }\n\n        /* Footer */\n        footer {\n            text-align: center;\n            margin-top: 3rem;\n            padding: 2rem 1rem;\n            border-top: 1px solid var(--color-border);\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n        }\n\n        footer a {\n            color: var(--color-primary);\n            text-decoration: none;\n            transition: color var(--transition-fast);\n        }\n\n        footer a:hover {\n            text-decoration: underline;\n        }\n\n        /* Animations */\n        @keyframes fadeIn {\n            from { opacity: 0; transform: translateY(10px); }\n            to { opacity: 1; transform: translateY(0); }\n        }\n\n        .race-card {\n            animation: fadeIn 0.3s ease forwards;\n        }\n\n        /* Skip Link for Accessibility */\n        .skip-link {\n            position: absolute;\n            top: -40px;\n            left: 0;\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n            padding: 8px 16px;\n            z-index: 100;\n            transition: top var(--transition-fast);\n        }\n\n        .skip-link:focus {\n            top: 0;\n        }\n\n        /* Loading State */\n        .loading {\n            text-align: center;\n            padding: 3rem;\n            color: var(--color-text-muted);\n        }\n\n        .spinner {\n            width: 40px;\n            height: 40px;\n            border: 4px solid var(--color-border);\n            border-top-color: var(--color-primary);\n            border-radius: 50%;\n            animation: spin 1s linear infinite;\n            margin: 0 auto 1rem;\n        }\n\n        @keyframes spin {\n            to { transform: rotate(360deg); }\n        }\n\n        /* Print Styles */\n        @media print {\n            body { background: white; color: black; }\n            .controls, .theme-toggle, .btn { display: none; }\n            .race-card { break-inside: avoid; box-shadow: none; border: 1px solid #ccc; }\n        }\n    </style>\n</head>\n<body>\n    <a href=\"#main-content\" class=\"skip-link\">Skip to main content</a>\n\n    <div class=\"container\">\n        <div id=\"app\" class=\"loading\">\n            <div class=\"spinner\" aria-hidden=\"true\"></div>\n            <p>Loading race data...</p>\n        </div>\n    </div>\n\n    <!-- Data placeholder -->\n    <script id=\"race_data\" type=\"application/json\">__RACE_DATA_PLACEHOLDER__</script>\n\n    <script>\n        (function() {\n            'use strict';\n\n            // State management\n            const state = {\n                races: [],\n                filteredRaces: [],\n                searchQuery: '',\n                sortBy: 'time',\n                sortAsc: true,\n                theme: localStorage.getItem('theme') || 'dark',\n                collapsedCards: new Set(),\n                metadata: null\n            };\n\n            // Utility functions\n            const formatTime = (dateStr) => {\n                if (!dateStr) return 'N/A';\n                try {\n                    const date = new Date(dateStr);\n                    if (isNaN(date.getTime())) return 'N/A';\n                    return date.toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit', hour12: false });\n                } catch {\n                    return 'N/A';\n                }\n            };\n\n            const formatDate = (dateStr) => {\n                if (!dateStr) return 'N/A';\n                try {\n                    const date = new Date(dateStr);\n                    if (isNaN(date.getTime())) return 'N/A';\n                    return date.toLocaleDateString('en-US', {\n                        year: 'numeric',\n                        month: 'short',\n                        day: 'numeric',\n                        hour: '2-digit',\n                        minute: '2-digit'\n                    });\n                } catch {\n                    return 'N/A';\n                }\n            };\n\n            const escapeHtml = (str) => {\n                if (typeof str !== 'string') return str;\n                const div = document.createElement('div');\n                div.textContent = str;\n                return div.innerHTML;\n            };\n\n            const getBestOdds = (runner) => {\n                if (!runner.odds || typeof runner.odds !== 'object') {\n                    return { odds: 'N/A', source: 'N/A' };\n                }\n\n                let bestVal = 0;\n                let bestSource = 'N/A';\n\n                for (const [source, data] of Object.entries(runner.odds)) {\n                    const winOdds = data?.win || data;\n                    if (typeof winOdds === 'number' && winOdds > bestVal) {\n                        bestVal = winOdds;\n                        bestSource = source;\n                    }\n                }\n\n                return {\n                    odds: bestVal > 0 ? bestVal.toFixed(2) : 'N/A',\n                    source: bestSource\n                };\n            };\n\n            // Sorting functions\n            const sortFunctions = {\n                time: (a, b) => new Date(a.start_time || 0) - new Date(b.start_time || 0),\n                venue: (a, b) => (a.venue || '').localeCompare(b.venue || ''),\n                score: (a, b) => (b.qualification_score || 0) - (a.qualification_score || 0),\n                runners: (a, b) => (b.runners?.length || 0) - (a.runners?.length || 0)\n            };\n\n            // Filter and sort races\n            const updateFilteredRaces = () => {\n                let filtered = [...state.races];\n\n                // Apply search filter\n                if (state.searchQuery) {\n                    const query = state.searchQuery.toLowerCase();\n                    filtered = filtered.filter(race => {\n                        const venueMatch = (race.venue || '').toLowerCase().includes(query);\n                        const runnerMatch = (race.runners || []).some(r =>\n                            (r.name || '').toLowerCase().includes(query)\n                        );\n                        return venueMatch || runnerMatch;\n                    });\n                }\n\n                // Apply sorting\n                const sortFn = sortFunctions[state.sortBy] || sortFunctions.time;\n                filtered.sort((a, b) => {\n                    const result = sortFn(a, b);\n                    return state.sortAsc ? result : -result;\n                });\n\n                state.filteredRaces = filtered;\n            };\n\n            // Render functions\n            const renderHeader = (timestamp) => `\n                <header>\n                    <h1>\ud83d\udc34 Fortuna Faucet Race Report</h1>\n                    <p class=\"subtitle\">Filtered Trifecta Opportunities</p>\n                    <p class=\"subtitle\">Generated: ${formatDate(timestamp)}</p>\n                </header>\n            `;\n\n            const renderControls = () => `\n                <div class=\"controls\" role=\"search\" aria-label=\"Filter and sort controls\">\n                    <input\n                        type=\"search\"\n                        id=\"search-input\"\n                        class=\"search-box\"\n                        placeholder=\"Search venues or horses...\"\n                        value=\"${escapeHtml(state.searchQuery)}\"\n                        aria-label=\"Search races\"\n                    />\n                    <div class=\"sort-controls\" role=\"group\" aria-label=\"Sort options\">\n                        <button class=\"btn ${state.sortBy === 'time' ? 'active' : ''}\" data-sort=\"time\">\n                            \u23f0 Time\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'score' ? 'active' : ''}\" data-sort=\"score\">\n                            \u2b50 Score\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'venue' ? 'active' : ''}\" data-sort=\"venue\">\n                            \ud83d\udccd Venue\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'runners' ? 'active' : ''}\" data-sort=\"runners\">\n                            \ud83c\udfc7 Runners\n                        </button>\n                    </div>\n                    <button id=\"theme-toggle\" class=\"btn theme-toggle\" aria-label=\"Toggle theme\">\n                        ${state.theme === 'dark' ? '\u2600\ufe0f Light' : '\ud83c\udf19 Dark'}\n                    </button>\n                </div>\n            `;\n\n            const renderSummary = () => {\n                const totalRunners = state.filteredRaces.reduce((sum, r) => sum + (r.runners?.length || 0), 0);\n                const avgScore = state.filteredRaces.length > 0\n                    ? (state.filteredRaces.reduce((sum, r) => sum + (r.qualification_score || 0), 0) / state.filteredRaces.length).toFixed(1)\n                    : 'N/A';\n\n                return `\n                    <div class=\"summary-box\" role=\"region\" aria-label=\"Summary statistics\">\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${state.filteredRaces.length}</div>\n                            <div class=\"summary-stat-label\">Qualified Races</div>\n                        </div>\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${totalRunners}</div>\n                            <div class=\"summary-stat-label\">Total Runners</div>\n                        </div>\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${avgScore}</div>\n                            <div class=\"summary-stat-label\">Avg Score</div>\n                        </div>\n                        ${state.searchQuery ? `\n                            <div class=\"summary-stat\">\n                                <div class=\"summary-stat-value\">${state.races.length}</div>\n                                <div class=\"summary-stat-label\">Total Available</div>\n                            </div>\n                        ` : ''}\n                    </div>\n                `;\n            };\n\n            const renderRunner = (runner, index) => {\n                const { odds, source } = getBestOdds(runner);\n                const number = runner.number || runner.post_position || index + 1;\n\n                return `\n                    <tr>\n                        <td data-label=\"Horse\">\n                            <span class=\"runner-number\">${number}</span>\n                            <span class=\"runner-name\">${escapeHtml(runner.name || 'Unknown')}</span>\n                        </td>\n                        <td data-label=\"Win Odds\" class=\"odds\">${odds}</td>\n                        <td data-label=\"Source\" class=\"source\">${escapeHtml(source)}</td>\n                    </tr>\n                `;\n            };\n\n            const renderRaceCard = (race, index) => {\n                const raceId = `race-${race.venue}-${race.race_number}`.replace(/\\s+/g, '-');\n                const isCollapsed = state.collapsedCards.has(raceId);\n                const score = race.qualification_score != null ? race.qualification_score.toFixed(1) : 'N/A';\n                const runners = race.runners || [];\n\n                return `\n                    <article\n                        class=\"race-card ${isCollapsed ? 'collapsed' : ''}\"\n                        data-race-id=\"${raceId}\"\n                        style=\"animation-delay: ${index * 0.05}s\"\n                    >\n                        <div class=\"race-header\"\n                             role=\"button\"\n                             tabindex=\"0\"\n                             aria-expanded=\"${!isCollapsed}\"\n                             aria-controls=\"${raceId}-content\">\n                            <div class=\"race-header-info\">\n                                <h2 class=\"race-title\">\n                                    <span class=\"collapse-icon\" aria-hidden=\"true\">\u25bc</span>\n                                    ${escapeHtml(race.venue || 'Unknown')} - Race ${race.race_number || '?'}\n                                </h2>\n                                <div class=\"race-meta\">\n                                    Post Time: ${formatTime(race.start_time)}\n                                    ${race.distance ? ` \u2022 ${escapeHtml(race.distance)}` : ''}\n                                    ${race.surface ? ` \u2022 ${escapeHtml(race.surface)}` : ''}\n                                </div>\n                            </div>\n                            <div class=\"race-badges\">\n                                <span class=\"badge badge-score\" title=\"Qualification Score\">\u2b50 ${score}</span>\n                                <span class=\"badge badge-runners\" title=\"Number of Runners\">\ud83c\udfc7 ${runners.length}</span>\n                            </div>\n                        </div>\n                        <div class=\"race-content\" id=\"${raceId}-content\">\n                            ${runners.length > 0 ? `\n                                <table class=\"runners-table\" role=\"table\">\n                                    <thead>\n                                        <tr>\n                                            <th scope=\"col\">Horse</th>\n                                            <th scope=\"col\">Win Odds</th>\n                                            <th scope=\"col\">Best Source</th>\n                                        </tr>\n                                    </thead>\n                                    <tbody>\n                                        ${runners.map((r, i) => renderRunner(r, i)).join('')}\n                                    </tbody>\n                                </table>\n                            ` : '<p class=\"no-runners\">No runner data available</p>'}\n                        </div>\n                    </article>\n                `;\n            };\n\n            const renderNoRaces = () => `\n                <div class=\"no-races\" role=\"alert\">\n                    <div class=\"no-races-icon\">\ud83d\udd2d</div>\n                    <h2>No Races Found</h2>\n                    <p>${state.searchQuery\n                        ? `No races match \"${escapeHtml(state.searchQuery)}\". Try a different search term.`\n                        : 'No qualified races found at this time. Check back later for updates.'\n                    }</p>\n                    ${state.searchQuery ? '<button class=\"btn\" id=\"clear-search\">Clear Search</button>' : ''}\n                </div>\n            `;\n\n            const renderMetrics = () => {\n                if (!state.metadata?.generation_metrics) return '';\n\n                const m = state.metadata.generation_metrics;\n                return `\n                    <details class=\"metrics-panel\">\n                        <summary>\ud83d\udcca Generation Metrics</summary>\n                        <div class=\"metrics-grid\">\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Total Fetched</div>\n                                <div class=\"metric-value\">${m.total_races_fetched || 0}</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Qualified</div>\n                                <div class=\"metric-value\">${m.qualified_races || 0}</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Duration</div>\n                                <div class=\"metric-value\">${(m.duration_seconds || 0).toFixed(1)}s</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Adapters Used</div>\n                                <div class=\"metric-value\">${m.adapters_used?.length || 0}</div>\n                            </div>\n                        </div>\n                    </details>\n                `;\n            };\n\n            const renderFooter = () => `\n                <footer>\n                    <p>This report was automatically generated by <strong>Fortuna Faucet</strong> via GitHub Actions.</p>\n                    <p>Data sources: Multiple racing exchanges and bookmakers.</p>\n                    <p>\n                        <kbd>?</kbd> Help \u2022\n                        <kbd>\u2191\u2193</kbd> Navigate \u2022\n                        <kbd>Enter</kbd> Expand/Collapse\n                    </p>\n                </footer>\n            `;\n\n            const render = () => {\n                updateFilteredRaces();\n\n                const app = document.getElementById('app');\n                app.className = '';\n                app.innerHTML = `\n                    ${renderHeader(state.metadata?.timestamp)}\n                    ${renderControls()}\n                    ${renderSummary()}\n                    <main id=\"main-content\" class=\"race-grid\" role=\"main\" aria-label=\"Race cards\">\n                        ${state.filteredRaces.length > 0\n                            ? state.filteredRaces.map((race, i) => renderRaceCard(race, i)).join('')\n                            : renderNoRaces()\n                        }\n                    </main>\n                    ${renderMetrics()}\n                    ${renderFooter()}\n                `;\n\n                attachEventListeners();\n            };\n\n            const attachEventListeners = () => {\n                // Search input\n                const searchInput = document.getElementById('search-input');\n                if (searchInput) {\n                    let debounceTimer;\n                    searchInput.addEventListener('input', (e) => {\n                        clearTimeout(debounceTimer);\n                        debounceTimer = setTimeout(() => {\n                            state.searchQuery = e.target.value;\n                            render();\n                            document.getElementById('search-input')?.focus();\n                        }, 300);\n                    });\n                }\n\n                // Sort buttons\n                document.querySelectorAll('[data-sort]').forEach(btn => {\n                    btn.addEventListener('click', (e) => {\n                        const sortBy = e.target.dataset.sort;\n                        if (state.sortBy === sortBy) {\n                            state.sortAsc = !state.sortAsc;\n                        } else {\n                            state.sortBy = sortBy;\n                            state.sortAsc = sortBy !== 'score'; // Score defaults descending\n                        }\n                        render();\n                    });\n                });\n\n                // Theme toggle\n                const themeToggle = document.getElementById('theme-toggle');\n                if (themeToggle) {\n                    themeToggle.addEventListener('click', () => {\n                        state.theme = state.theme === 'dark' ? 'light' : 'dark';\n                        document.documentElement.classList.toggle('light-mode', state.theme === 'light');\n                        localStorage.setItem('theme', state.theme);\n                        render();\n                    });\n                }\n\n                // Clear search button\n                const clearSearch = document.getElementById('clear-search');\n                if (clearSearch) {\n                    clearSearch.addEventListener('click', () => {\n                        state.searchQuery = '';\n                        render();\n                    });\n                }\n\n                // Race card collapse/expand\n                document.querySelectorAll('.race-header').forEach(header => {\n                    const handleToggle = () => {\n                        const card = header.closest('.race-card');\n                        const raceId = card.dataset.raceId;\n\n                        if (state.collapsedCards.has(raceId)) {\n                            state.collapsedCards.delete(raceId);\n                        } else {\n                            state.collapsedCards.add(raceId);\n                        }\n\n                        card.classList.toggle('collapsed');\n                        header.setAttribute('aria-expanded', !card.classList.contains('collapsed'));\n                    };\n\n                    header.addEventListener('click', handleToggle);\n                    header.addEventListener('keydown', (e) => {\n                        if (e.key === 'Enter' || e.key === ' ') {\n                            e.preventDefault();\n                            handleToggle();\n                        }\n                    });\n                });\n            };\n\n            // Keyboard navigation\n            document.addEventListener('keydown', (e) => {\n                if (e.target.matches('input, textarea')) return;\n\n                if (e.key === '/') {\n                    e.preventDefault();\n                    document.getElementById('search-input')?.focus();\n                } else if (e.key === 'Escape') {\n                    document.getElementById('search-input')?.blur();\n                }\n            });\n\n            // Initialize\n            const init = () => {\n                // Apply saved theme\n                if (state.theme === 'light') {\n                    document.documentElement.classList.add('light-mode');\n                }\n\n                try {\n                    const dataEl = document.getElementById('race_data');\n                    if (!dataEl) throw new Error('Data element not found');\n\n                    const jsonData = JSON.parse(dataEl.textContent);\n                    state.races = jsonData.races || [];\n                    state.metadata = jsonData;\n\n                    render();\n                } catch (err) {\n                    console.error('Failed to initialize:', err);\n                    document.getElementById('app').innerHTML = `\n                        <div class=\"no-races\">\n                            <div class=\"no-races-icon\">\u26a0\ufe0f</div>\n                            <h2>Failed to Load Data</h2>\n                            <p>Error: ${escapeHtml(err.message)}</p>\n                        </div>\n                    `;\n                }\n            };\n\n            if (document.readyState === 'loading') {\n                document.addEventListener('DOMContentLoaded', init);\n            } else {\n                init();\n            }\n        })();\n    </script>\n</body>\n</html>\n",
    "scripts/test_api_query.py": "#!/usr/bin/env python\n\"\"\"\nSimple Fortuna Race Data Query Script\n\nThis is a lightweight script for testing the race data API locally.\nIt queries for filtered races and outputs the results.\n\nUsage:\n  python scripts/test_api_query.py\n\nThe script expects the backend to be running on http://127.0.0.1:8000\n\"\"\"\n\nimport json\nimport os\nimport sys\nimport time\nfrom datetime import datetime\n\ntry:\n    import requests\nexcept ImportError:\n    print(\"\u274c Error: 'requests' module not found.\")\n    print(\"Install it with: pip install requests\")\n    sys.exit(1)\n\n\n# Configuration\nAPI_BASE_URL = os.getenv(\"FORTUNA_API_URL\", \"http://127.0.0.1:8000\")\nAPI_KEY = os.getenv(\"API_KEY\", \"a_secure_test_api_key_that_is_long_enough\")\nTIMEOUT = 10\n\n\ndef log(message, level=\"INFO\"):\n    \"\"\"Print timestamped log message.\"\"\"\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    emoji = {\"INFO\": \"\u2139\ufe0f\", \"SUCCESS\": \"\u2705\", \"ERROR\": \"\u274c\", \"WARNING\": \"\u26a0\ufe0f\"}\n    print(f\"[{timestamp}] {emoji.get(level, '\u2022')} {message}\")\n\n\ndef check_backend_health():\n    \"\"\"Check if the backend API is responding.\"\"\"\n    log(\"Checking backend health...\", \"INFO\")\n    try:\n        response = requests.get(\n            f\"{API_BASE_URL}/api/health\",\n            timeout=TIMEOUT,\n            headers={\"X-API-Key\": API_KEY},\n        )\n        if response.status_code == 200:\n            log(\"Backend is healthy\", \"SUCCESS\")\n            return True\n    except requests.RequestException as e:\n        log(f\"Health check failed: {e}\", \"ERROR\")\n        return False\n    return False\n\n\ndef fetch_filtered_races():\n    \"\"\"Fetch trifecta-qualified races from the API.\"\"\"\n    endpoint = \"/api/races/qualified/trifecta\"\n    url = f\"{API_BASE_URL}{endpoint}\"\n\n    log(f\"Querying {url}\", \"INFO\")\n\n    try:\n        headers = {\"X-API-Key\": API_KEY}\n        response = requests.get(url, timeout=TIMEOUT, headers=headers)\n        response.raise_for_status()\n\n        data = response.json()\n        races = data.get(\"races\", [])\n\n        log(f\"Retrieved {len(races)} qualified races\", \"SUCCESS\")\n        return data\n\n    except requests.exceptions.Timeout:\n        log(f\"Request timed out after {TIMEOUT} seconds\", \"ERROR\")\n        return None\n    except requests.exceptions.ConnectionError as e:\n        log(f\"Connection error: {e}\", \"ERROR\")\n        log(f\"Is the backend running at {API_BASE_URL}?\", \"WARNING\")\n        return None\n    except requests.exceptions.HTTPError as e:\n        log(f\"HTTP error: {response.status_code} {response.reason}\", \"ERROR\")\n        return None\n    except json.JSONDecodeError:\n        log(\"Response was not valid JSON\", \"ERROR\")\n        return None\n    except Exception as e:\n        log(f\"Unexpected error: {e}\", \"ERROR\")\n        return None\n\n\ndef display_races(races_data):\n    \"\"\"Pretty-print the races to console.\"\"\"\n    if not races_data:\n        log(\"No data to display\", \"WARNING\")\n        return\n\n    races = races_data.get(\"races\", [])\n\n    print(\"\\\\n\" + \"=\" * 80)\n    print(f\"FORTUNA FILTERED RACE REPORT - {len(races)} Races\")\n    print(\"=\" * 80 + \"\\\\n\")\n\n    if not races:\n        print(\"\u274c No qualified races found at this time.\\\\n\")\n        return\n\n    for idx, race in enumerate(races, 1):\n        venue = race.get(\"venue\", \"Unknown\")\n        race_num = race.get(\"race_number\", \"?\")\n        start_time = race.get(\"startTime\", \"N/A\")\n        runners = race.get(\"runners\", [])\n\n        print(f\"[{idx}] {venue} - Race {race_num}\")\n        print(f\"    Post Time: {start_time}\")\n        print(f\"    Runners: {len(runners)}\")\n        print(\"\\\\n    Horse Name                  | Win Odds | Best Source\")\n        print(\"    \" + \"-\" * 60)\n\n        for runner in runners:\n            name = runner.get(\"name\", \"Unknown\")\n            odds_data = runner.get(\"odds\", {})\n\n            # Find best win odds\n            best_odds = \"N/A\"\n            best_source = \"N/A\"\n            if odds_data:\n                best_val = 0.0\n                for source, odds_obj in odds_data.items():\n                    win_odds = odds_obj.get(\"win\", 0.0)\n                    if win_odds > best_val:\n                        best_val = win_odds\n                        best_odds = f\"{best_val:.2f}\"\n                        best_source = source\n\n            # Truncate long names\n            display_name = name[:28]\n            print(f\"    {display_name:28} | {best_odds:>8} | {best_source}\")\n\n        print()\n\n\ndef save_to_json(races_data, filename=\"qualified_races.json\"):\n    \"\"\"Save race data to JSON file.\"\"\"\n    try:\n        with open(filename, \"w\", encoding=\"utf-8\") as f:\n            json.dump(races_data, f, indent=2)\n        log(f\"Saved race data to {filename}\", \"SUCCESS\")\n        return True\n    except Exception as e:\n        log(f\"Failed to save JSON: {e}\", \"ERROR\")\n        return False\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    log(\"=== Fortuna Race Data Query ===\", \"INFO\")\n    log(f\"API URL: {API_BASE_URL}\", \"INFO\")\n\n    # Check backend health\n    if not check_backend_health():\n        log(\"Backend is not responding\", \"ERROR\")\n        log(\"Make sure to start the backend with:\", \"WARNING\")\n        log(\"  python -m uvicorn web_service.backend.main:app --port 8000\", \"WARNING\")\n        return 1\n\n    # Fetch races\n    races_data = fetch_filtered_races()\n    if not races_data:\n        log(\"Failed to fetch race data\", \"ERROR\")\n        return 1\n\n    # Display results\n    display_races(races_data)\n\n    # Save to JSON\n    save_to_json(races_data)\n\n    log(\"Complete\", \"SUCCESS\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n",
    "setup.py": "# setup.py\nfrom setuptools import find_packages\nfrom setuptools import setup\n\nwith open(\"requirements.txt\") as f:\n    requirements = f.read().splitlines()\n\nsetup(\n    name=\"fortuna_engine\",\n    version=\"1.0.0\",\n    packages=find_packages(),\n    author=\"Jules\",\n    author_email=\"\",\n    description=\"The Python backend for the Fortuna Faucet application.\",\n    long_description=\"This package contains the FastAPI server and all related data adapters and analysis tools.\",\n    install_requires=requirements,\n    entry_points={\n        \"console_scripts\": [\n            \"fortuna-engine=python_service.run_api:main\",\n        ],\n    },\n    include_package_data=True,\n    package_data={\n        \"python_service\": [\"*.py\"],\n    },\n)\n",
    "start_docker.bat": "@echo off\nREM ============================================================\nREM Fortuna Faucet - Docker Launcher for Windows\nREM A simple, friendly way to start your racing analysis engine\nREM ============================================================\n\nsetlocal enabledelayedexpansion\n\nREM Colors and styling\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83d\udc34  FORTUNA FAUCET LAUNCHER  \ud83d\udc34                \u2551\necho \u2551          Racing Strategy Analysis Engine                  \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM ============================================================\nREM STEP 1: Check if Docker is installed\nREM ============================================================\necho [1/5] Checking for Docker installation...\ndocker --version >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Docker is not installed or not in PATH\n    echo.\n    echo To use Fortuna, you need Docker Desktop:\n    echo https://www.docker.com/products/docker-desktop\n    echo.\n    echo After installing Docker, restart your computer and try again.\n    echo.\n    pause\n    exit /b 1\n)\n\nfor /f \"tokens=*\" %%i in ('docker --version') do set DOCKER_VERSION=%%i\necho \u2713 Found: %DOCKER_VERSION%\necho.\n\nREM ============================================================\nREM STEP 2: Check if Docker daemon is running\nREM ============================================================\necho [2/5] Checking if Docker daemon is running...\ndocker ps >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Docker daemon is not running\n    echo.\n    echo Please:\n    echo 1. Open \"Docker Desktop\" from your Start Menu\n    echo 2. Wait 30 seconds for Docker to fully start\n    echo 3. Then run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\necho \u2713 Docker daemon is running\necho.\n\nREM ============================================================\nREM STEP 3: Pull latest Docker image\nREM ============================================================\necho [3/5] Pulling latest Fortuna image from Docker Hub...\necho (This may take a minute on first run)\necho.\ndocker pull masonj0/fortuna-faucet:latest\nif errorlevel 1 (\n    echo.\n    echo \u26a0 Warning: Could not pull from Docker Hub\n    echo Checking for local image...\n    docker image inspect masonj0/fortuna-faucet:latest >nul 2>&1\n    if errorlevel 1 (\n        echo \u2717 ERROR: No local image found\n        echo Please check your internet connection and try again.\n        echo.\n        pause\n        exit /b 1\n    )\n    echo \u2713 Using existing local image\n)\necho \u2713 Image ready\necho.\n\nREM ============================================================\nREM STEP 4: Start container\nREM ============================================================\necho [4/5] Starting Fortuna container...\necho.\n\nREM Stop any existing container (ignore errors)\ndocker stop fortuna-faucet >nul 2>&1\ndocker rm fortuna-faucet >nul 2>&1\n\nREM Create data directories if they don't exist\nif not exist \"data\" mkdir data\nif not exist \"logs\" mkdir logs\n\nREM Start container with proper quoting for paths with spaces\ndocker run -d ^\n  --name fortuna-faucet ^\n  -p 8000:8000 ^\n  -v \"%cd%\\data:/app/web_service/backend/data\" ^\n  -v \"%cd%\\logs:/app/web_service/backend/logs\" ^\n  masonj0/fortuna-faucet:latest\n\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Failed to start container\n    echo.\n    echo Try these troubleshooting steps:\n    echo 1. Open Docker Desktop\n    echo 2. Wait for it to fully start\n    echo 3. Open Command Prompt and run: docker ps\n    echo    (This tests if Docker is working)\n    echo 4. Run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Container started successfully\necho.\n\nREM ============================================================\nREM STEP 5: Wait and verify startup\nREM ============================================================\necho [5/5] Waiting for application to start...\ntimeout /t 3 /nobreak\n\nREM Check if container is still running\ndocker inspect fortuna-faucet >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Container exited unexpectedly\n    echo.\n    echo Showing container logs for debugging:\n    echo.\n    docker logs fortuna-faucet\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Application is ready!\necho.\n\nREM ============================================================\nREM SUCCESS - Open browser and show logs\nREM ============================================================\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83c\udf89  FORTUNA IS RUNNING!  \ud83c\udf89                   \u2551\necho \u2551                                                            \u2551\necho \u2551  Your racing analysis engine is ready at:                \u2551\necho \u2551                                                            \u2551\necho \u2551          http://localhost:8000                            \u2551\necho \u2551                                                            \u2551\necho \u2551  Opening browser now...                                   \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM Open browser\nstart http://localhost:8000\n\nREM Small delay to let browser open\ntimeout /t 2 /nobreak\n\nREM Show logs\necho.\necho \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\necho \u2502 Live Application Logs (Ctrl+C to stop)                    \u2502\necho \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\necho.\n\ndocker logs -f fortuna-faucet\n\nREM Cleanup on exit\necho.\necho Stopping Fortuna...\ndocker stop fortuna-faucet >nul 2>&1\necho \u2713 Fortuna stopped\n\nexit /b 0\n",
    "tests/adapters/test_the_racing_api_adapter.py": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timezone\nfrom decimal import Decimal\nfrom unittest.mock import AsyncMock\n\nimport pytest\n\nfrom python_service.adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom python_service.core.exceptions import AdapterConfigError\nfrom tests.conftest import get_test_settings\n\n\n@pytest.fixture\ndef test_settings():\n    \"\"\"Provides a valid Settings object for testing.\"\"\"\n    return get_test_settings()\n\n\ndef test_init_raises_config_error_if_no_key():\n    \"\"\"\n    Tests that the adapter raises an AdapterConfigError if the API key is not set.\n    \"\"\"\n    settings_no_key = get_test_settings()\n    settings_no_key.THE_RACING_API_KEY = None\n    with pytest.raises(AdapterConfigError) as excinfo:\n        TheRacingApiAdapter(config=settings_no_key)\n    assert \"THE_RACING_API_KEY is not configured\" in str(excinfo.value)\n\n\n@pytest.mark.asyncio\nasync def test_get_races_parses_correctly(test_settings):\n    \"\"\"\n    Tests that TheRacingApiAdapter correctly parses a valid API response via get_races.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    off_time = datetime.now(timezone.utc)\n\n    mock_api_response = {\n        \"racecards\": [\n            {\n                \"race_id\": \"12345\",\n                \"course\": \"Newbury\",\n                \"race_no\": 3,\n                \"off_time\": off_time.isoformat().replace(\"+00:00\", \"Z\"),\n                \"race_name\": \"The Great Race\",\n                \"distance_f\": \"1m 2f\",\n                \"runners\": [\n                    {\n                        \"horse\": \"Speedy Steed\",\n                        \"number\": 1,\n                        \"jockey\": \"T. Rider\",\n                        \"trainer\": \"A. Trainer\",\n                        \"odds\": [{\"odds_decimal\": \"5.50\"}],\n                    },\n                    {\n                        \"horse\": \"Gallant Gus\",\n                        \"number\": 2,\n                        \"jockey\": \"J. Jockey\",\n                        \"trainer\": \"B. Builder\",\n                        \"odds\": [{\"odds_decimal\": \"3.25\"}],\n                    },\n                ],\n            }\n        ]\n    }\n\n    # Patch the internal _fetch_data method\n    adapter._fetch_data = AsyncMock(return_value=mock_api_response)\n\n    # ACT\n    races = await adapter.get_races(today)\n\n    # ASSERT\n    assert len(races) == 1\n    race = races[0]\n    assert race.id == \"tra_12345\"\n    assert race.venue == \"Newbury\"\n    assert len(race.runners) == 2\n    runner1 = race.runners[0]\n    assert runner1.name == \"Speedy Steed\"\n    assert runner1.odds[adapter.source_name].win == Decimal(\"5.50\")\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_empty_response(test_settings):\n    \"\"\"\n    Tests that the adapter returns an empty list for an API response with no racecards.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(return_value={\"racecards\": []})\n\n    # ACT\n    races = await adapter.get_races(today)\n\n    # ASSERT\n    assert races == []\n\n\n@pytest.mark.asyncio\nasync def test_get_races_raises_exception_on_api_failure(test_settings):\n    \"\"\"\n    Tests that get_races propagates the exception when _fetch_data fails.\n    This is the desired behavior for the OddsEngine to handle it.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(side_effect=Exception(\"API is down\"))\n\n    # ACT & ASSERT\n    with pytest.raises(Exception, match=\"API is down\"):\n        _ = await adapter.get_races(today)\n",
    "tests/fixtures/at_the_races_greyhounds.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <title>Racecard</title>\n</head>\n<body>\n    <link rel=\"canonical\" href=\"/racecard/GB/Monmore/2025-10-29/1817/1\" />\n    <h1 class=\"heading-racecard-title\">Monmore | 18:17</h1>\n    <div class=\"table-default__row--card-runner\">\n        <div class=\"table-default__cell\">\n            <span class=\"runner-number__no\">1</span>\n            <div class=\"runner-cloth-name\">\n                <span class=\"runner-cloth-name__name\">Crossfield Larry</span>\n            </div>\n            <button class=\"bet-selector__odds\">5/2</button>\n        </div>\n    </div>\n    <div class=\"table-default__row--card-runner\">\n        <div class=\"table-default__cell\">\n            <span class=\"runner-number__no\">2</span>\n            <div class=\"runner-cloth-name\">\n                <span class=\"runner-cloth-name__name\">Stouke A Star</span>\n            </div>\n            <button class=\"bet-selector__odds\">11/4</button>\n        </div>\n    </div>\n</body>\n</html>\n",
    "tests/test_api.py": "# tests/test_api.py\nfrom datetime import date\nfrom datetime import datetime\nfrom unittest.mock import AsyncMock\nfrom unittest.mock import patch\n\nimport aiosqlite\nimport pytest\n\n# --- Fixtures ---\nfrom python_service.models import AggregatedResponse\n\n# The client fixture is now correctly sourced from conftest.py,\n# which handles the settings override globally.\n\n# --- API Tests ---\n\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine.fetch_all_odds\", new_callable=AsyncMock)\nasync def test_get_races_endpoint_success(mock_fetch_all_odds, client):\n    \"\"\"\n    SPEC: The /api/races endpoint should return data with a valid API key.\n    \"\"\"\n    # ARRANGE\n    today = date.today()\n    mock_response = AggregatedResponse(\n        date=today,\n        races=[],\n            errors=[],\n        sources=[],\n        metadata={},\n        # This was the missing field causing the validation error\n        source_info=[],\n    )\n    mock_fetch_all_odds.return_value = mock_response.model_dump()\n    from tests.conftest import get_test_settings\n    settings = get_test_settings()\n    headers = {\"X-API-Key\": settings.API_KEY}\n\n    # ACT\n    response = await client.get(f\"/api/races?race_date={today.isoformat()}\", headers=headers)\n\n    # ASSERT\n    assert response.status_code == 200\n    mock_fetch_all_odds.assert_awaited_once()\n\n\n@pytest.mark.asyncio\nasync def test_get_tipsheet_endpoint_success(tmp_path, client):\n    \"\"\"\n    SPEC: The /api/tipsheet endpoint should return a list of tipsheet races from the database.\n    \"\"\"\n    db_path = tmp_path / \"test.db\"\n    post_time = datetime.now()\n\n    with patch(\"python_service.api.DB_PATH\", db_path):\n        async with aiosqlite.connect(db_path) as db:\n            await db.execute(\n                \"\"\"\n                CREATE TABLE tipsheet (\n                    race_id TEXT PRIMARY KEY,\n                    track_name TEXT,\n                    race_number INTEGER,\n                    post_time TEXT,\n                    score REAL,\n                    factors TEXT\n                )\n            \"\"\"\n            )\n            await db.execute(\n                \"INSERT INTO tipsheet VALUES (?, ?, ?, ?, ?, ?)\",\n                (\"test_race_1\", \"Test Park\", 1, post_time.isoformat(), 85.5, \"{}\"),\n            )\n            await db.commit()\n\n        # ACT\n        response = await client.get(f\"/api/tipsheet?date={post_time.date().isoformat()}\")\n\n        # ASSERT\n        assert response.status_code == 200\n        response_data = response.json()\n        assert len(response_data) == 1\n        # The database returns snake_case, but the Pydantic model is camelCase\n        assert response_data[0][\"raceId\"] == \"test_race_1\"\n        assert response_data[0][\"score\"] == 85.5\n\n\n@pytest.mark.asyncio\nasync def test_health_check_unauthenticated(client):\n    \"\"\"Ensures the /health endpoint is accessible without an API key.\"\"\"\n    response = await client.get(\"/health\")\n    assert response.status_code == 200\n    json_response = response.json()\n    assert json_response[\"status\"] == \"healthy\"\n\n\n@pytest.mark.asyncio\nasync def test_api_key_authentication_failure(client):\n    \"\"\"Ensures that endpoints are protected and fail with an invalid API key.\"\"\"\n    response = await client.get(\"/api/races/qualified/trifecta\", headers={\"X-API-KEY\": \"invalid_key\"})\n    assert response.status_code == 403\n    assert \"Invalid or missing API Key\" in response.json()[\"detail\"]\n\n\n@pytest.mark.asyncio\nasync def test_api_key_authentication_missing(client):\n    \"\"\"Ensures that endpoints are protected and fail with a missing API key.\"\"\"\n    response = await client.get(\"/api/races/qualified/trifecta\")\n    assert response.status_code == 403\n    assert \"Not authenticated\" in response.json()[\"detail\"]\n",
    "tests/test_manual_override.py": "# tests/test_manual_override.py\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom python_service.api import app\nfrom python_service.api import get_settings\nfrom python_service.manual_override_manager import ManualOverrideManager\nfrom tests.conftest import get_test_settings\n\n# Override settings for tests\napp.dependency_overrides[get_settings] = get_test_settings\n_settings = get_test_settings()\nAPI_KEY = getattr(_settings, \"API_KEY\", \"test-override-key-123\")\n\n\n@pytest.fixture\ndef manager() -> ManualOverrideManager:\n    \"\"\"Provides a clean ManualOverrideManager instance for each test.\"\"\"\n    return ManualOverrideManager()\n\n\ndef test_register_failure(manager: ManualOverrideManager):\n    adapter_name = \"TestAdapter\"\n    url = \"http://test.com/races\"\n    request_id = manager.register_failure(adapter_name, url)\n    assert request_id is not None\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter_name\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager: ManualOverrideManager):\n    request_id = manager.register_failure(\"TestAdapter\", \"http://test.com/races\")\n    success = manager.submit_manual_data(request_id, \"<html></html>\", \"html\")\n    assert success\n    assert len(manager.get_pending_requests()) == 0\n    data = manager.get_manual_data(\"TestAdapter\", \"http://test.com/races\")\n    assert data is not None\n    assert data[0] == \"<html></html>\"\n    assert data[1] == \"html\"\n\n\ndef test_skip_request(manager: ManualOverrideManager):\n    request_id = manager.register_failure(\"TestAdapter\", \"http://test.com/races\")\n    success = manager.skip_request(request_id)\n    assert success\n    assert len(manager.get_pending_requests()) == 0\n    data = manager.get_manual_data(\"TestAdapter\", \"http://test.com/races\")\n    assert data is None\n\n\n@pytest.mark.asyncio\nasync def test_get_pending_overrides_endpoint(app, client):\n    # ARRANGE\n    # Access the manager *after* the TestClient has run the lifespan startup\n    manager = app.state.manual_override_manager\n    manager.clear_old_requests(max_age_hours=-1)  # Ensure a clean state by clearing all\n    manager.register_failure(\"EndpointAdapter\", \"http://endpoint.com/data\")\n\n    # ACT\n    response = await client.get(\"/api/manual-overrides/pending\", headers={\"X-API-Key\": API_KEY})\n    assert response.status_code == 200\n    data = response.json()\n    assert \"pending_requests\" in data\n    assert len(data[\"pending_requests\"]) > 0\n    assert data[\"pending_requests\"][0][\"adapter_name\"] == \"EndpointAdapter\"\n\n\n@pytest.mark.asyncio\nasync def test_submit_manual_data_endpoint(app, client):\n    # ARRANGE\n    manager = app.state.manual_override_manager\n    manager.clear_old_requests(max_age_hours=-1)\n    request_id = manager.register_failure(\"SubmitAdapter\", \"http://submit.com/data\")\n    submission = {\n        \"request_id\": request_id,\n        \"content\": \"<h1>Hello</h1>\",\n        \"content_type\": \"html\",\n    }\n    response = await client.post(\n        \"/api/manual-overrides/submit\",\n        json=submission,\n        headers={\"X-API-Key\": API_KEY},\n    )\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"success\"\n    data = manager.get_manual_data(\"SubmitAdapter\", \"http://submit.com/data\")\n    assert data is not None\n    assert data[0] == \"<h1>Hello</h1>\"\n\n\n@pytest.mark.asyncio\nasync def test_skip_manual_override_endpoint(app, client):\n    # ARRANGE\n    manager = app.state.manual_override_manager\n    manager.clear_old_requests(max_age_hours=-1)\n    request_id = manager.register_failure(\"SkipAdapter\", \"http://skip.com/data\")\n    response = await client.post(f\"/api/manual-overrides/skip/{request_id}\", headers={\"X-API-Key\": API_KEY})\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"success\"\n    # Verify the request is no longer pending\n    pending = manager.get_pending_requests()\n    assert not any(p.request_id == request_id for p in pending)\n",
    "verify_connection.py": "# verify_connection.py\n\nimport asyncio\nimport logging\nimport os\nimport subprocess\nimport sys\nimport time\nfrom pathlib import Path\n\nfrom playwright.sync_api import sync_playwright\n\n# --- Configuration ---\nLOG_LEVEL = logging.INFO\n# Set paths relative to the script's location\nSCRIPT_DIR = Path(__file__).parent.resolve()\nSCREENSHOT_DIR = SCRIPT_DIR / \"verification\"\nFRONTEND_LOG_PATH = SCRIPT_DIR / \"frontend.log\"\nBACKEND_LOG_PATH = SCRIPT_DIR / \"backend.log\"\nFRONTEND_DIR = SCRIPT_DIR / \"web_platform\" / \"frontend\"\nBACKEND_DIR = SCRIPT_DIR / \"python_service\"\nBACKEND_ENTRYPOINT = BACKEND_DIR / \"api.py\"\n\n# --- Setup Logging ---\nlogging.basicConfig(\n    level=LOG_LEVEL,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    handlers=[logging.StreamHandler(sys.stdout)],\n)\n\n\ndef start_backend():\n    \"\"\"Starts the FastAPI backend as a background process.\"\"\"\n    logging.info(\"Starting backend server...\")\n    # Ensure environment is set up for backend\n    backend_env = os.environ.copy()\n    backend_env[\"PYTHONPATH\"] = str(SCRIPT_DIR)\n    backend_env[\"API_KEY\"] = \"a_secure_test_api_key_that_is_long_enough\"\n    backend_env[\"ALLOWED_ORIGINS\"] = '[\"http://localhost:3000\", \"http://127.0.0.1:3000\"]'\n\n    # Use shell=True for Windows compatibility if needed, but separate args is better\n    command = [\n        sys.executable,\n        \"-m\",\n        \"uvicorn\",\n        \"python_service.api:app\",\n        \"--host\",\n        \"0.0.0.0\",\n        \"--port\",\n        \"8000\",\n    ]\n    try:\n        process = subprocess.Popen(\n            command,\n            cwd=SCRIPT_DIR,\n            stdout=open(BACKEND_LOG_PATH, \"w\"),\n            stderr=subprocess.STDOUT,\n            env=backend_env,\n        )\n        logging.info(f\"Backend process started with PID: {process.pid}\")\n        # Give the server a moment to initialize\n        time.sleep(5)\n        return process\n    except FileNotFoundError:\n        logging.error(\n            \"uvicorn command not found. Make sure it's installed in the environment.\"\n        )\n        return None\n    except Exception as e:\n        logging.error(f\"Failed to start backend: {e}\", exc_info=True)\n        return None\n\n\ndef start_frontend():\n    \"\"\"Starts the Next.js frontend dev server as a background process.\"\"\"\n    logging.info(\"Starting frontend development server...\")\n    try:\n        # Check for node_modules and run npm install if not present\n        if not (FRONTEND_DIR / \"node_modules\").exists():\n            logging.info(\"node_modules not found. Running 'npm install'...\")\n            install_process = subprocess.run(\n                [\"npm\", \"install\"],\n                cwd=FRONTEND_DIR,\n                check=True,\n                capture_output=True,\n                text=True,\n            )\n            logging.info(install_process.stdout)\n            if install_process.returncode != 0:\n                logging.error(\"npm install failed!\")\n                logging.error(install_process.stderr)\n                return None\n\n        # Start the dev server\n        process = subprocess.Popen(\n            [\"npm\", \"run\", \"dev\"],\n            cwd=FRONTEND_DIR,\n            stdout=open(FRONTEND_LOG_PATH, \"w\"),\n            stderr=subprocess.STDOUT,\n        )\n        logging.info(f\"Frontend process started with PID: {process.pid}\")\n        return process\n    except FileNotFoundError:\n        logging.error(\n            \"npm command not found. Make sure Node.js and npm are installed and in the PATH.\"\n        )\n        return None\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"npm install failed: {e.stderr}\")\n        return None\n    except Exception as e:\n        logging.error(f\"Failed to start frontend: {e}\", exc_info=True)\n        return None\n\n\ndef get_frontend_port_from_logs(log_path: Path, timeout: int = 30) -> int:\n    \"\"\"Parses the frontend log file to find the port the dev server is running on.\"\"\"\n    start_time = time.time()\n    while time.time() - start_time < timeout:\n        try:\n            if log_path.exists():\n                with open(log_path, \"r\") as f:\n                    for line in f:\n                        if \"Local:\" in line and \"http://localhost:\" in line:\n                            port_str = line.split(\"http://localhost:\")[1].strip()\n                            if port_str.isdigit():\n                                port = int(port_str)\n                                logging.info(f\"Detected frontend port: {port}\")\n                                return port\n        except Exception as e:\n            logging.warning(f\"Could not read frontend log yet, retrying... Error: {e}\")\n        time.sleep(1)\n    logging.error(f\"Could not determine frontend port after {timeout} seconds.\")\n    return 3000 # Fallback\n\ndef verify_connection():\n    \"\"\"\n    Uses Playwright to verify the frontend can connect to the backend.\n    Captures a screenshot for visual confirmation.\n    \"\"\"\n    backend_process = None\n    frontend_process = None\n    success = False\n\n    try:\n        backend_process = start_backend()\n        if not backend_process or backend_process.poll() is not None:\n            logging.error(\"Backend failed to start or crashed.\")\n            return\n\n        frontend_process = start_frontend()\n        if not frontend_process or frontend_process.poll() is not None:\n            logging.error(\"Frontend failed to start or crashed.\")\n            return\n\n        logging.info(\"Waiting for frontend to be ready and getting port...\")\n        port = get_frontend_port_from_logs(FRONTEND_LOG_PATH)\n\n\n        with sync_playwright() as p:\n            logging.info(\"Launching browser...\")\n            browser = p.chromium.launch(headless=True)\n            page = browser.new_page()\n\n            logging.info(f\"Navigating to frontend URL at port {port}...\")\n            page.goto(f\"http://localhost:{port}\")\n\n            # Wait for a specific element that indicates a successful connection\n            # or a definitive disconnected state.\n            logging.info(\"Waiting for connection status indicator...\")\n            try:\n                # Wait up to 30 seconds for either a 'Connected' or 'Failed' state\n                page.wait_for_selector(\n                    'text=/Connecting...|Connected|Connection Failed/',\n                    timeout=30000\n                )\n\n                # Check the current status\n                connection_status = page.locator('//button[contains(@class, \"rounded-full\")]').inner_text()\n                logging.info(f\"Connection status found: {connection_status}\")\n                if \"Connected\" in connection_status:\n                    logging.info(\"Successfully connected to the backend.\")\n                    success = True\n                else:\n                    logging.error(f\"Frontend indicated a connection failure: {connection_status}\")\n\n\n            except Exception as e:\n                logging.error(f\"Failed to find connection status indicator: {e}\", exc_info=True)\n\n            logging.info(\"Capturing screenshot...\")\n            SCREENSHOT_DIR.mkdir(exist_ok=True)\n            screenshot_path = SCREENSHOT_DIR / \"debug_screenshot.png\"\n            page.screenshot(path=str(screenshot_path))\n            logging.info(f\"Screenshot saved to {screenshot_path}\")\n\n            browser.close()\n\n    finally:\n        logging.info(\"Cleaning up processes...\")\n        if frontend_process and frontend_process.poll() is None:\n            logging.info(f\"Terminating frontend process {frontend_process.pid}\")\n            frontend_process.terminate()\n            frontend_process.wait()\n        if backend_process and backend_process.poll() is None:\n            logging.info(f\"Terminating backend process {backend_process.pid}\")\n            backend_process.terminate()\n            backend_process.wait()\n        logging.info(\"Cleanup complete.\")\n        # Exit with success or failure code\n        if not success:\n            sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    verify_connection()\n",
    "web_service/backend/adapters/__init__.py": "# python_service/adapters/__init__.py\n\nfrom .at_the_races_adapter import AtTheRacesAdapter\nfrom .at_the_races_greyhound_adapter import AtTheRacesGreyhoundAdapter\nfrom .betfair_adapter import BetfairAdapter\nfrom .betfair_datascientist_adapter import BetfairDataScientistAdapter\nfrom .betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .brisnet_adapter import BrisnetAdapter\nfrom .equibase_adapter import EquibaseAdapter\nfrom .fanduel_adapter import FanDuelAdapter\nfrom .gbgb_api_adapter import GbgbApiAdapter\nfrom .greyhound_adapter import GreyhoundAdapter\nfrom .harness_adapter import HarnessAdapter\nfrom .oddschecker_adapter import OddscheckerAdapter\nfrom .pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .racingpost_adapter import RacingPostAdapter\nfrom .racing_post_b2b_adapter import RacingPostB2BAdapter\nfrom .sporting_life_adapter import SportingLifeAdapter\nfrom .stubs import (\n    HorseRacingNationAdapter,\n    NYRABetsAdapter,\n    PuntersAdapter,\n    RacingTVAdapter,\n    TabAdapter,\n    TemplateAdapter,\n)\nfrom .the_racing_api_adapter import TheRacingApiAdapter\nfrom .timeform_adapter import TimeformAdapter\nfrom .tvg_adapter import TVGAdapter\nfrom .twinspires_adapter import TwinSpiresAdapter\nfrom .universal_adapter import UniversalAdapter\nfrom .xpressbet_adapter import XpressbetAdapter\n\n__all__ = [\n    \"AtTheRacesAdapter\",\n    \"AtTheRacesGreyhoundAdapter\",\n    \"BetfairAdapter\",\n    \"BetfairDataScientistAdapter\",\n    \"BetfairGreyhoundAdapter\",\n    \"BrisnetAdapter\",\n    \"EquibaseAdapter\",\n    \"FanDuelAdapter\",\n    \"GbgbApiAdapter\",\n    \"GreyhoundAdapter\",\n    \"HarnessAdapter\",\n    \"HorseRacingNationAdapter\",\n    \"NYRABetsAdapter\",\n    \"OddscheckerAdapter\",\n    \"PointsBetGreyhoundAdapter\",\n    \"PuntersAdapter\",\n    \"RacingAndSportsAdapter\",\n    \"RacingAndSportsGreyhoundAdapter\",\n    \"RacingPostAdapter\",\n    \"RacingPostB2BAdapter\",\n    \"RacingTVAdapter\",\n    \"SportingLifeAdapter\",\n    \"TabAdapter\",\n    \"TemplateAdapter\",\n    \"TheRacingApiAdapter\",\n    \"TimeformAdapter\",\n    \"TVGAdapter\",\n    \"TwinSpiresAdapter\",\n    \"UniversalAdapter\",\n    \"XpressbetAdapter\",\n]\n",
    "web_service/backend/adapters/betfair_greyhound_adapter.py": "# python_service/adapters/betfair_greyhound_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .mixins import BetfairAuthMixin\n\n\nclass BetfairGreyhoundAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching greyhound racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairGreyhounds\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for greyhound races on a given date.\"\"\"\n        if not await self._authenticate(self.http_client):\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"4339\"],  # Greyhound Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Failed to parse a Betfair Greyhound market.\",\n                    exc_info=True,\n                    market=market,\n                )\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Optional[Race]:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bfg_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 480m').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "web_service/backend/adapters/gbgb_api_adapter.py": "# python_service/adapters/gbgb_api_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..models import Race, Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .utils.odds_validator import create_odds_data\n\n\nclass GbgbApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for the Greyhound Board of Great Britain API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"GBGB\"\n    BASE_URL = \"https://api.gbgb.org.uk/api/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches the raw meeting data from the GBGB API.\"\"\"\n        endpoint = f\"results/meeting/{date}\"\n        response = await self.make_request(\"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, meetings_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw meeting data into a list of Race objects.\"\"\"\n        if not meetings_data:\n            return []\n\n        all_races = []\n        for meeting in meetings_data:\n            track_name = meeting.get(\"trackName\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    if race := self._parse_race(race_data, track_name):\n                        all_races.append(race)\n                except (KeyError, TypeError):\n                    self.logger.error(\n                        \"Error parsing GBGB race\",\n                        race_id=race_data.get(\"raceId\"),\n                        exc_info=True,\n                    )\n                    continue\n        return all_races\n\n    def _parse_race(self, race_data: Dict[str, Any], track_name: str) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race_data.get(\"raceId\")\n        race_number = race_data.get(\"raceNumber\")\n        race_time = race_data.get(\"raceTime\")\n\n        if not all([race_id, race_number, race_time]):\n            return None\n\n        return Race(\n            id=f\"gbgb_{race_id}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=datetime.fromisoformat(race_time.replace(\"Z\", \"+00:00\")),\n            runners=self._parse_runners(race_data.get(\"traps\", [])),\n            source=self.source_name,\n            race_name=race_data.get(\"raceTitle\"),\n            distance=f\"{race_data.get('raceDistance')}m\",\n        )\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                trap_number = runner_data.get(\"trapNumber\")\n                dog_name = runner_data.get(\"dogName\")\n                if not all([trap_number, dog_name]):\n                    continue\n\n                odds_data = {}\n                sp = runner_data.get(\"sp\")\n                if sp:\n                    win_odds = parse_odds_to_decimal(sp)\n                    if odds_data_val := create_odds_data(self.source_name, win_odds):\n                        odds_data[self.source_name] = odds_data_val\n\n                runners.append(\n                    Runner(\n                        number=trap_number,\n                        name=dog_name,\n                        odds=odds_data,\n                    )\n                )\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Error parsing GBGB runner, skipping.\",\n                    runner_name=runner_data.get(\"dogName\"),\n                )\n                continue\n        return runners\n",
    "web_service/backend/adapters/mixins/debug_mixin.py": "# python_service/adapters/mixins/debug_mixin.py\n\"\"\"Mixin for debug HTML saving functionality.\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\nimport structlog\n\nlog = structlog.get_logger(__name__)\n\n\nclass DebugMixin:\n    \"\"\"Mixin that provides debug HTML saving capabilities.\"\"\"\n\n    DEBUG_OUTPUT_DIR: str = \"debug_output\"\n\n    def _save_debug_html(\n        self,\n        content: str,\n        filename: str,\n        *,\n        enabled: bool = True,\n        subdirectory: Optional[str] = None,\n    ) -> Optional[Path]:\n        \"\"\"\n        Save HTML content to a debug file for CI/debugging purposes.\n\n        Args:\n            content: The HTML content to save\n            filename: Base filename (without extension)\n            enabled: Whether debug saving is enabled\n            subdirectory: Optional subdirectory within debug output dir\n\n        Returns:\n            Path to saved file, or None if saving failed/disabled\n        \"\"\"\n        if not enabled:\n            return None\n\n        try:\n            output_dir = Path(self.DEBUG_OUTPUT_DIR)\n            if subdirectory:\n                output_dir = output_dir / subdirectory\n            output_dir.mkdir(parents=True, exist_ok=True)\n\n            filepath = output_dir / f\"{filename}.html\"\n            filepath.write_text(content, encoding=\"utf-8\")\n            log.debug(\"Saved debug HTML\", path=str(filepath), size=len(content))\n            return filepath\n        except (OSError, IOError) as e:\n            log.warning(\"Failed to save debug HTML\", filename=filename, error=str(e))\n            return None\n",
    "web_service/backend/adapters/racing_and_sports_greyhound_adapter.py": "# python_service/adapters/racing_and_sports_greyhound_adapter.py\n\"\"\"Adapter for Racing and Sports Greyhound API.\"\"\"\n\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race, Runner\nfrom .base_adapter_v3 import BaseAdapterV3\n\n\nclass RacingAndSportsGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"Adapter for Racing and Sports Greyhound API, migrated to BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"RacingAndSportsGreyhound\"\n    BASE_URL = \"https://api.racingandsports.com.au/\"\n\n    def __init__(self, config=None):\n        super().__init__(\n            source_name=self.SOURCE_NAME,\n            base_url=self.BASE_URL,\n            config=config\n        )\n        if not getattr(config, \"RACING_AND_SPORTS_TOKEN\", None):\n            raise AdapterConfigError(\n                self.source_name, \"RACING_AND_SPORTS_TOKEN is not configured.\"\n            )\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch greyhound meetings from the Racing and Sports API.\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_token}\",\n            \"Accept\": \"application/json\",\n        }\n        params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n        response = await self.make_request(\n            \"GET\", \"v1/greyhound/meetings\", headers=headers, params=params\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parse meetings data into Race objects.\"\"\"\n        if not raw_data or not isinstance(raw_data.get(\"meetings\"), list):\n            self.logger.warning(\n                \"No 'meetings' in RacingAndSportsGreyhound response or invalid format.\"\n            )\n            return []\n\n        races = []\n        for meeting in raw_data.get(\"meetings\", []):\n            if not isinstance(meeting, dict):\n                continue\n            for race_summary in meeting.get(\"races\", []):\n                if not isinstance(race_summary, dict):\n                    continue\n                try:\n                    if parsed := self._parse_race(meeting, race_summary):\n                        races.append(parsed)\n                except (KeyError, TypeError, ValueError):\n                    self.logger.warning(\n                        \"Failed to parse greyhound race\",\n                        venue=meeting.get(\"venueName\"),\n                        race_id=race_summary.get(\"raceId\"),\n                        exc_info=True,\n                    )\n        return races\n\n    def _parse_race(\n        self, meeting: Dict[str, Any], race: Dict[str, Any]\n    ) -> Optional[Race]:\n        \"\"\"Parse a single race from the API response.\"\"\"\n        race_id = race.get(\"raceId\")\n        start_time_str = race.get(\"startTime\")\n        race_number = race.get(\"raceNumber\")\n\n        if not all([race_id, start_time_str, race_number]):\n            return None\n\n        # FIX: Use dogName for greyhounds, not horseName\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\", 0),\n                name=rd.get(\"dogName\", rd.get(\"greyhoundName\", \"Unknown\")),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n            if isinstance(rd, dict) and rd.get(\"runnerNumber\")\n        ]\n\n        if not runners:\n            return None\n\n        try:\n            start_time = datetime.fromisoformat(start_time_str)\n        except (ValueError, TypeError):\n            self.logger.warning(\n                \"Invalid start time\", start_time_str=start_time_str, race_id=race_id\n            )\n            return None\n\n        return Race(\n            id=f\"rasg_{race_id}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/stubs/nyrabets_adapter.py": "# python_service/adapters/stubs/nyrabets_adapter.py\nfrom ..base_stub_adapter import BaseStubAdapter\n\n\nclass NYRABetsAdapter(BaseStubAdapter):\n    \"\"\"Stub adapter for nyrabets.com.\"\"\"\n\n    SOURCE_NAME = \"NYRABets\"\n    BASE_URL = \"https://nyrabets.com\"\n",
    "web_service/backend/adapters/the_racing_api_adapter.py": "# python_service/adapters/the_racing_api_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race, Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .utils.odds_validator import create_odds_data\n\n\nclass TheRacingApiAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for TheRacingAPI.com, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"TheRacingAPI\"\n    BASE_URL = \"https://api.theracingapi.com/v1/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n        if not getattr(config, \"THE_RACING_API_KEY\", None):\n            raise AdapterConfigError(self.SOURCE_NAME, \"THE_RACING_API_KEY is not configured.\")\n        self.api_key = config.THE_RACING_API_KEY\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetches the raw race data from TheRacingAPI.\"\"\"\n        params = {\"apiKey\": self.api_key, \"date\": date}\n        response = await self.make_request(\"GET\", \"racecards/free\", params=params)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses the raw JSON data into a list of Race objects.\"\"\"\n        if not raw_data or not isinstance(raw_data.get(\"racecards\"), list):\n            self.logger.warning(\"No 'racecards' in TheRacingAPI response or invalid format.\")\n            return []\n\n        all_races = []\n        for race_summary in raw_data.get(\"racecards\", []):\n            try:\n                if race := self._parse_single_race(race_summary):\n                    all_races.append(race)\n            except (KeyError, TypeError, ValueError):\n                self.logger.error(\n                    \"Error parsing TheRacingAPI race\",\n                    race_id=race_summary.get(\"race_id\"),\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_single_race(self, race_data: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single race object from the API response.\"\"\"\n        race_id = race_data.get(\"race_id\")\n        venue = race_data.get(\"course\")\n        # Handle different potential field names for race number\n        race_number = race_data.get(\"race_number\") or race_data.get(\"race_no\")\n        start_time_str = race_data.get(\"off_time\")\n\n        if not all([race_id, venue, race_number, start_time_str]):\n            return None\n\n        runners = []\n        for runner_data in race_data.get(\"runners\", []):\n            name = runner_data.get(\"horse\")\n            # Handle different potential field names for saddle cloth number\n            number = runner_data.get(\"saddle_cloth\") or runner_data.get(\"number\")\n            if not all([name, str(number)] if number is not None else [name]):\n                continue\n\n            odds = {}\n            # TheRacingAPI sometimes provides odds in various formats\n            if odds_list := runner_data.get(\"odds\"):\n                if isinstance(odds_list, list) and len(odds_list) > 0:\n                    odds_val = odds_list[0].get(\"odds_decimal\")\n                    if odds_val:\n                        if odds_data := create_odds_data(self.source_name, odds_val):\n                            odds[self.source_name] = odds_data\n\n            runners.append(\n                Runner(\n                    name=name,\n                    number=number,\n                    scratched=runner_data.get(\"non_runner\", False),\n                    odds=odds,\n                )\n            )\n\n        if not runners:\n            return None\n\n        # Start time parsing depends on format from API\n        try:\n            start_time = datetime.fromisoformat(start_time_str.replace(\"Z\", \"+00:00\"))\n        except (ValueError, TypeError):\n            start_time = datetime.now()\n\n        return Race(\n            id=f\"tra_{race_id}\",\n            venue=venue,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/utils/odds_validator.py": "# python_service/adapters/utils/odds_validator.py\n\"\"\"Utilities for validating and processing odds data.\"\"\"\n\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Optional, Union\n\nfrom ..constants import MAX_VALID_ODDS, MIN_VALID_ODDS\nfrom ...models import OddsData\n\n\ndef is_valid_odds(odds: Union[float, Decimal, None]) -> bool:\n    \"\"\"\n    Check if odds value is within valid range.\n\n    Args:\n        odds: The odds value to validate\n\n    Returns:\n        True if odds are valid, False otherwise\n    \"\"\"\n    if odds is None:\n        return False\n    try:\n        odds_float = float(odds)\n        return MIN_VALID_ODDS <= odds_float < MAX_VALID_ODDS\n    except (TypeError, ValueError):\n        return False\n\n\ndef create_odds_data(\n    source_name: str,\n    win_odds: Union[float, Decimal, None],\n    place_odds: Union[float, Decimal, None] = None,\n) -> Optional[OddsData]:\n    \"\"\"\n    Create an OddsData object if odds are valid.\n\n    Args:\n        source_name: Name of the odds source\n        win_odds: Win odds value\n        place_odds: Optional place odds value\n\n    Returns:\n        OddsData object or None if odds are invalid\n    \"\"\"\n    if not is_valid_odds(win_odds):\n        return None\n\n    return OddsData(\n        win=win_odds,\n        place=place_odds if is_valid_odds(place_odds) else None,\n        source=source_name,\n        last_updated=datetime.now(),\n    )\n",
    "web_service/backend/core/__init__.py": "",
    "web_service/backend/etl.py": "# python_service/etl.py\n# ETL pipeline for populating the historical data warehouse\n\nimport json\nimport logging\nimport os\nfrom datetime import date\n\nimport requests\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import text\nfrom sqlalchemy.exc import SQLAlchemyError\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass ScribesArchivesETL:\n    def __init__(self):\n        self.postgres_url = os.getenv(\"POSTGRES_URL\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.api_base_url = \"http://localhost:8000\"\n        self.engine = self._get_db_engine()\n\n    def _get_db_engine(self):\n        if not self.postgres_url:\n            logger.warning(\"POSTGRES_URL not set. ETL will be skipped.\")\n            return None\n        try:\n            return create_engine(self.postgres_url)\n        except Exception as e:\n            logger.error(f\"Failed to create database engine: {e}\", exc_info=True)\n            return None\n\n    def _fetch_race_data(self, target_date: date) -> list:\n        \"\"\"Fetches aggregated race data from the local API.\"\"\"\n        if not self.api_key:\n            raise ValueError(\"API_KEY not found in environment.\")\n\n        url = f\"{self.api_base_url}/api/races?race_date={target_date.isoformat()}\"\n        headers = {\"X-API-KEY\": self.api_key}\n        response = requests.get(url, headers=headers, timeout=120)\n        response.raise_for_status()\n        return response.json().get(\"races\", [])\n\n    def _validate_and_transform(self, race: dict) -> tuple:\n        \"\"\"Validates a race dictionary and transforms it for insertion.\"\"\"\n        if not all(k in race for k in [\"id\", \"venue\", \"race_number\", \"start_time\", \"runners\"]):\n            return (\n                None,\n                \"Missing core fields (id, venue, race_number, start_time, runners)\",\n            )\n\n        active_runners = [r for r in race.get(\"runners\", []) if not r.get(\"scratched\")]\n\n        transformed = {\n            \"race_id\": race[\"id\"],\n            \"venue\": race[\"venue\"],\n            \"race_number\": race[\"race_number\"],\n            \"start_time\": race[\"start_time\"],\n            \"source\": race.get(\"source\"),\n            \"qualification_score\": race.get(\"qualification_score\"),\n            \"field_size\": len(active_runners),\n        }\n        return transformed, None\n\n    def run(self, target_date: date):\n        if not self.engine:\n            return\n\n        logger.info(f\"Starting ETL process for {target_date.isoformat()}...\")\n        try:\n            races = self._fetch_race_data(target_date)\n        except (requests.RequestException, ValueError) as e:\n            logger.error(f\"Failed to fetch race data: {e}\", exc_info=True)\n            return\n\n        clean_records = []\n        quarantined_records = []\n\n        for race in races:\n            transformed, reason = self._validate_and_transform(race)\n            if transformed:\n                clean_records.append(transformed)\n            else:\n                quarantined_records.append(\n                    {\n                        \"race_id\": race.get(\"id\"),\n                        \"source\": race.get(\"source\"),\n                        \"payload\": json.dumps(race),\n                        \"reason\": reason,\n                    }\n                )\n\n        with self.engine.connect() as connection:\n            try:\n                with connection.begin():  # Transaction block\n                    if clean_records:\n                        # Using ON CONFLICT to prevent duplicates\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO historical_races (\n                                race_id, venue, race_number, start_time, source,\n                                qualification_score, field_size\n                            )\n                            VALUES (\n                                :race_id, :venue, :race_number, :start_time, :source,\n                                :qualification_score, :field_size\n                            )\n                            ON CONFLICT (race_id) DO NOTHING;\n                        \"\"\"\n                        )\n                        connection.execute(stmt, clean_records)\n                        logger.info(f\"Inserted/updated {len(clean_records)} records into historical_races.\")\n\n                    if quarantined_records:\n                        stmt = text(\n                            \"\"\"\n                            INSERT INTO quarantined_races (race_id, source, payload, reason)\n                            VALUES (:race_id, :source, :payload::jsonb, :reason);\n                        \"\"\"\n                        )\n                        connection.execute(stmt, quarantined_records)\n                        logger.warning(f\"Moved {len(quarantined_records)} records to quarantine.\")\n            except SQLAlchemyError as e:\n                logger.error(f\"Database transaction failed: {e}\", exc_info=True)\n\n        logger.info(\"ETL process finished.\")\n\n\ndef run_etl_for_yesterday():\n    from datetime import timedelta\n\n    yesterday = date.today() - timedelta(days=1)\n    etl = ScribesArchivesETL()\n    etl.run(yesterday)\n",
    "web_service/backend/health_check.py": "import socket\nimport sys\n\n\ndef is_port_available(port=8000):\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex((\"127.0.0.1\", port))\n        sock.close()\n        return result != 0\n    except Exception:\n        return False\n\n\nif __name__ == \"__main__\":\n    if not is_port_available(8000):\n        print(\"ERROR: Port 8000 already in use. Kill existing process or use different port.\")\n        sys.exit(1)\n    print(\"Port 8000 available \u2713\")\n",
    "web_service/backend/middleware/__init__.py": "",
    "web_service/backend/port_check.py": "import socket\nimport sys\n\ndef check_port_and_exit_if_in_use(port: int, host: str):\n    \"\"\"Checks if a port is in use at the given host and exits if it is.\"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        try:\n            s.bind((host, port))\n        except OSError:\n            print(f\"\u274c FATAL: Port {port} is already in use. Please close the other application or specify a different port.\")\n            sys.exit(1)\n",
    "web_service/backend/requirements.txt": "# Project: Fortuna Faucet\n# Python Version: 3.10.11\n# Platform: Windows\n# Last Validated: 2026-01-10\n# Status: PRODUCTION READY\n# Notes: Manually validated, NOT auto-generated. All versions tested and confirmed working.\n\n# Installation: pip install -r requirements.txt\n\n# Core Web Framework\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\nstarlette==0.27.0\npydantic==2.5.0\npydantic-core==2.14.1\npydantic-settings==2.1.0\n\n# Asgi Http\nanyio==3.7.1\nh11==0.14.0\nh2==4.1.0\nhpack==4.0.0\nhttpcore==1.0.2\nhttptools==0.6.1\nhttpx==0.25.2\nhyperframe==6.1.0\nwebsockets==12.0\nwsproto==1.2.0\n\n# Http Client\nrequests==2.31.0\nurllib3==2.1.0\ncertifi>=2024.2.2\ncharset-normalizer==3.3.2\nidna==3.6\n\n# Database Orm\nsqlalchemy==2.0.23\ngreenlet>=3.1.1\naiosqlite==0.19.0\npsycopg2-binary==2.9.9\n\n# Data Processing\nnumpy==1.25.0\npandas==2.0.3\npython-dateutil==2.8.2\npytz==2023.3.post1\ntzdata==2023.3\nsix==1.16.0\n\n# Html Web Parsing\nbeautifulsoup4==4.12.2\nsoupsieve==2.5\nselectolax==0.3.20\nscrapling[fetchers]>=0.3.7\ncamoufox>=0.1.7\n\n# Cli Configuration\nclick>=8.3.0\npython-dotenv==1.0.0\npyyaml==6.0.1\n\n# Cryptography Security\ncryptography==41.0.7\ncffi==1.16.0\npycparser==2.21\nsecretstorage==3.5.0\nkeyring==24.3.0\njeepney==0.9.0\n\n# Caching Rate Limiting\nredis==5.0.1\nlimits==3.7.0\nslowapi==0.1.9\ntenacity==8.2.3\n\n# Desktop Gui Windows\npywebview==5.4\nbottle==0.13.4\nproxy-tools==0.1.0\n# NOTE: pywebview WITHOUT CEF (uses WinForms instead). CEFPython3 66.0 incompatible with Python 3.10.11\n\n# System Utilities\npsutil==5.9.6\n\n# Logging Monitoring\nstructlog==23.2.0\n\n# Code Quality Building\nblack==23.12.0\npyinstaller==6.1.0\npyinstaller-hooks-contrib==2023.11\naltgraph==0.17.3\nwheel==0.41.2\nbuild==1.0.3\npip-tools==7.3.0\n\n# Testing\npytest==7.4.3\npytest-asyncio==0.21.1\niniconfig==2.0.0\npluggy==1.3.0\npackaging==23.2\n\n# Type Hints Extensions\ntyping-extensions==4.10.0\ntyping-inspect==0.9.0\nannotated-types==0.6.0\n\n# Utilities\nmypy-extensions==1.0.0\npathspec==0.11.2\nplatformdirs==4.2.0\nmore-itertools==10.1.0\njaraco.classes==3.3.1\njaraco.context==5.3.0\njaraco.functools==4.0.0\ndeprecated==1.2.14\nsniffio==1.3.0\nwrapt==1.16.0\nwatchfiles==0.20.0\npygments==2.17.2\n\n# --- Excluded Packages ---\n# - uvloop : NOT supported on Windows (Unix-only features)\n# - numpy 2x: Requires Python 3.11+\n# - pandas 2.1+: Has compatibility issues with Python 3.10\n# - pywebview 6x: Has Windows compatibility issues\n# - cefpython3: Incompatible with Python 3.10.11\n",
    "web_service/backend/user_friendly_errors.py": "# python_service/user_friendly_errors.py\n\n\"\"\"\nCentralized dictionary for mapping technical exceptions to user-friendly messages.\n\"\"\"\n\nERROR_MAP = {\n    \"AdapterHttpError\": {\n        \"message\": \"A data source is currently unavailable.\",\n        \"suggestion\": (\n            \"This is usually temporary. Please try again in a few minutes. \"\n            \"If the problem persists, the website may be down for maintenance.\"\n        ),\n    },\n    \"AdapterConfigError\": {\n        \"message\": \"A data adapter is misconfigured.\",\n        \"suggestion\": \"Please check that all required API keys and settings are present in your .env file.\",\n    },\n    \"default\": {\n        \"message\": \"An unexpected error occurred.\",\n        \"suggestion\": \"Please check the application logs for more details or contact support.\",\n    },\n}\n",
    "web_service/backend/version.py": "# web_service/backend/version.py\n\n__version__ = \"3.0.1\" # Default version\n\ndef get_version():\n    \"\"\"Returns the application version.\"\"\"\n    return __version__\n",
    "web_service/frontend/.gitignore": "# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.\n\n# Dependencies\n/node_modules\n/.pnp\n.pnp.js\n\n# Testing\n/coverage\n\n# Next.js\n/.next/\n/out/\n\n# Production\n/build\n\n# Misc\n.DS_Store\n*.pem\n\n# Local .env files\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n\n# Log files\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# Editor directories and files\n.vscode\n.idea\n*.suo\n*.ntvs*\n*.njsproj\n*.sln\n*.sw?",
    "web_service/frontend/app/components/ErrorDisplay.tsx": "// web_platform/frontend/src/components/ErrorDisplay.tsx\n'use client';\n\nimport React from 'react';\n\ninterface ErrorInfo {\n  message: string;\n  suggestion: string;\n  details?: string;\n}\n\ninterface ErrorDisplayProps {\n  error: ErrorInfo;\n}\n\nexport const ErrorDisplay: React.FC<ErrorDisplayProps> = ({ error }) => {\n  return (\n    <div className=\"bg-red-900/20 border border-red-500/30 text-white rounded-lg p-6 max-w-2xl mx-auto my-8\">\n      <div className=\"flex items-center mb-4\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" className=\"h-8 w-8 text-red-400 mr-4\" viewBox=\"0 0 20 20\" fill=\"currentColor\">\n          <path fillRule=\"evenodd\" d=\"M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z\" clipRule=\"evenodd\" />\n        </svg>\n        <h2 className=\"text-2xl font-bold text-red-400\">An Error Occurred</h2>\n      </div>\n      <p className=\"text-lg text-slate-300 mb-2\">{error.message}</p>\n      <p className=\"text-slate-400 mb-6\">{error.suggestion}</p>\n      {error.details && (\n        <details className=\"bg-slate-800/50 rounded-lg p-4\">\n          <summary className=\"cursor-pointer text-sm text-slate-500 hover:text-white\">\n            Technical Details\n          </summary>\n          <pre className=\"text-xs text-slate-400 mt-2 p-2 bg-black/30 rounded overflow-x-auto\">\n            <code>{error.details}</code>\n          </pre>\n        </details>\n      )}\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/RaceCardSkeleton.tsx": "// web_platform/frontend/src/components/RaceCardSkeleton.tsx\nimport React from 'react';\n\nexport const RaceCardSkeleton: React.FC = () => {\n  return (\n    <div className=\"race-card-skeleton border border-gray-700 rounded-lg p-4 bg-gray-800 shadow-lg animate-pulse\">\n      {/* Skeleton Header */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <div className=\"h-7 w-28 bg-gray-700 rounded-md\"></div>\n            <div className=\"h-4 w-40 bg-gray-700 rounded-md mt-2\"></div>\n          </div>\n        </div>\n        <div className=\"h-16 w-16 bg-gray-700 rounded-full\"></div>\n      </div>\n\n      {/* Skeleton Info Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"h-3 w-12 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-8 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-12 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-8 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-10 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-6 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"h-3 w-10 mx-auto bg-gray-700 rounded-md\"></div>\n          <div className=\"h-4 w-6 mx-auto bg-gray-700 rounded-md mt-2\"></div>\n        </div>\n      </div>\n\n      {/* Skeleton Runner Rows */}\n      <div className=\"space-y-2\">\n        {[...Array(3)].map((_, i) => (\n          <div key={i} className=\"runner-row rounded-md p-3\">\n            <div className=\"flex items-center justify-between\">\n              <div className=\"flex items-center gap-4 flex-1\">\n                <div className=\"w-10 h-10 rounded-full bg-gray-700\"></div>\n                <div className=\"flex flex-col space-y-2\">\n                  <div className=\"h-5 w-32 bg-gray-700 rounded-md\"></div>\n                  <div className=\"h-4 w-40 bg-gray-700 rounded-md\"></div>\n                </div>\n              </div>\n              <div className=\"text-right\">\n                <div className=\"h-6 w-16 bg-gray-700 rounded-md\"></div>\n                <div className=\"h-3 w-12 bg-gray-700 rounded-md mt-2\"></div>\n              </div>\n            </div>\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n};\n",
    "web_service/frontend/app/components/Tabs.tsx": "// src/components/Tabs.tsx\n'use client';\n\nimport React, { useState } from 'react';\n\ntype Tab = {\n  label: string;\n  content: React.ReactNode;\n};\n\ntype TabsProps = {\n  tabs: Tab[];\n};\n\nexport function Tabs({ tabs }: TabsProps) {\n  const [activeTab, setActiveTab] = useState(0);\n\n  return (\n    <div>\n      <div className=\"border-b border-slate-700\">\n        <nav className=\"-mb-px flex space-x-8\" aria-label=\"Tabs\">\n          {tabs.map((tab, index) => (\n            <button\n              key={tab.label}\n              onClick={() => setActiveTab(index)}\n              className={`${\n                activeTab === index\n                  ? 'border-blue-500 text-blue-400'\n                  : 'border-transparent text-slate-400 hover:text-slate-200 hover:border-slate-500'\n              } whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm transition-colors focus:outline-none`}\n            >\n              {tab.label}\n            </button>\n          ))}\n        </nav>\n      </div>\n      <div className=\"mt-8\">{tabs[activeTab].content}</div>\n    </div>\n  );\n}\n",
    "web_service/frontend/app/layout.tsx": "// web_platform/frontend/app/layout.tsx\nimport './globals.css';\nimport type { Metadata } from 'next';\nimport { Inter } from 'next/font/google';\nimport Providers from './Providers';\n\nconst inter = Inter({ subsets: ['latin'] });\n\nexport const metadata: Metadata = {\n  title: 'Fortuna',\n  description: 'Real-time horse racing analysis.',\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={`${inter.className} bg-white text-gray-900 dark:bg-gray-900 dark:text-gray-100`}>\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}",
    "web_service/frontend/app/utils/exportManager.ts": "// web_platform/frontend/src/utils/exportManager.ts\n// import { saveAs } from 'file-saver';\n// import * as XLSX from 'xlsx';\n\nexport class ExportManager {\n  static exportToExcel(races: any[], filename: string = 'fortuna_races') {\n    //\n    // [JULES] - NOTE FOR JB AND AI EXPERTS:\n    // This feature has been temporarily disabled because the external dependency (xlsx)\n    // is hosted on a CDN (cdn.sheetjs.com) that is consistently failing during\n    // the CI/CD build process with 500 Internal Server Errors.\n    //\n    // To ensure the main application build is not blocked, I have commented out\n    // the implementation of this function. The 'xlsx' package remains in package.json,\n    // but this code will not be active until the dependency issue is resolved.\n    //\n\n    // const workbook = XLSX.utils.book_new();\n\n    // const summaryData = [\n    //   ['Total Qualified Races', races.length],\n    //   ['Generated At', new Date().toLocaleString()]\n    // ];\n    // const summarySheet = XLSX.utils.aoa_to_sheet(summaryData);\n    // XLSX.utils.book_append_sheet(workbook, summarySheet, 'Summary');\n\n    // const raceData = races.map(race => ({\n    //   'Venue': race.venue,\n    //   'Race Number': race.race_number,\n    //   'Post Time': new Date(race.start_time).toLocaleString(),\n    //   'Qualification Score': race.qualification_score || 0,\n    //   'Field Size': race.runners.filter(r => !r.scratched).length,\n    //   'Source': race.source\n    // }));\n    // const raceSheet = XLSX.utils.json_to_sheet(raceData);\n    // XLSX.utils.book_append_sheet(workbook, raceSheet, 'Races');\n\n    // XLSX.writeFile(workbook, `${filename}_${Date.now()}.xlsx`);\n    console.warn(\"Excel export is temporarily disabled due to an external dependency issue.\");\n    alert(\"The Excel export feature is temporarily disabled due to an unreliable external dependency. Please try again later.\");\n  }\n}\n",
    "windows_service.py": "# windows_service.py\nimport os\nimport socket\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nimport servicemanager\nimport win32event\nimport win32service\nimport win32serviceutil\n\n\nclass FortunaBackendService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaFaucetBackend\"\n    _svc_display_name_ = \"Fortuna Faucet Racing Analysis Service\"\n    _svc_description_ = \"Background service for continuous racing data monitoring.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.stop_event = win32event.CreateEvent(None, 0, 0, None)\n        self.backend_process = None\n        socket.setdefaulttimeout(60)\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        win32event.SetEvent(self.stop_event)\n        if self.backend_process:\n            self.backend_process.terminate()\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(\n            servicemanager.EVENTLOG_INFORMATION_TYPE,\n            servicemanager.PYS_SERVICE_STARTED,\n            (self._svc_name_, \"\"),\n        )\n        self.main()\n\n    def main(self):\n        install_dir = Path(__file__).parent.resolve()\n        venv_python = install_dir / \".venv\" / \"Scripts\" / \"python.exe\"\n        api_module_dir = install_dir / \"python_service\"\n\n        env = os.environ.copy()\n        env_file = install_dir / \".env\"\n        if env_file.exists():\n            with open(env_file) as f:\n                for line in f:\n                    if \"=\" in line and not line.startswith(\"#\"):\n                        key, value = line.strip().split(\"=\", 1)\n                        env[key] = value.strip('\"')\n\n        self.backend_process = subprocess.Popen(\n            [\n                str(venv_python),\n                \"-m\",\n                \"uvicorn\",\n                \"api:app\",\n                \"--host\",\n                \"127.0.0.1\",\n                \"--port\",\n                \"8000\",\n            ],\n            cwd=str(api_module_dir),\n            env=env,\n        )\n\n        win32event.WaitForSingleObject(self.stop_event, win32event.INFINITE)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaBackendService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaBackendService)\n"
}