{
    ".dockerignore": ".git\n.gitignore\n.github\n__pycache__\n*.pyc\n.pytest_cache\n.venv\nvenv\n# Keep node_modules out of the build context\nnode_modules/\n\n# Keep build caches out of the build context\nweb_service/frontend/.next/\n\n# Allow frontend build artifacts\n# dist/\n# build/\n*.egg-info\n.DS_Store\n.env\n*.log\n.coverage\n.vscode\n.idea\n",
    ".github/workflows/build-monolith-final.yml": "name: Build Monolith (Final)\n\non:\n  push:\n    branches: [ main ]\n  workflow_dispatch:\n\njobs:\n  build:\n    name: 'Build Fortuna Monolith'\n    runs-on: windows-latest\n\n    steps:\n      - name: \ud83d\udce5 Checkout\n        uses: actions/checkout@v4\n\n      # ========== FRONTEND ==========\n      - name: \ud83c\udfa8 Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n\n      - name: \ud83e\uddf9 Clean Previous Builds\n        working-directory: ./web_service/frontend\n        shell: pwsh\n        run: |\n          Remove-Item -Path \"public\" -Recurse -Force -ErrorAction SilentlyContinue\n          Remove-Item -Path \".next\" -Recurse -Force -ErrorAction SilentlyContinue\n          Write-Host \"\u2705 Cleaned\"\n\n      - name: \ud83d\udccb Check Next.js Config\n        working-directory: ./web_service/frontend\n        shell: pwsh\n        run: |\n          Write-Host \"Checking package.json...\"\n          if (Test-Path \"package.json\") {\n            $pkg = Get-Content package.json | ConvertFrom-Json\n            Write-Host \"  name: $($pkg.name)\"\n            Write-Host \"  build: $($pkg.scripts.build)\"\n          } else {\n            Write-Error \"package.json not found!\"\n            exit 1\n          }\n\n      - name: \ud83c\udfd7\ufe0f Build Frontend\n        working-directory: ./web_service/frontend\n        shell: pwsh\n        run: |\n          Write-Host \"=== BUILDING FRONTEND ===\" -ForegroundColor Cyan\n\n          # Create/verify next.config.js\n          $configLines = @(\n            \"/** @type {import('next').NextConfig} */\",\n            \"const nextConfig = {\",\n            \"  output: 'export',\",\n            \"  distDir: 'build',\",\n            \"  images: { unoptimized: true },\",\n            \"  trailingSlash: true,\",\n            \"}\",\n            \"module.exports = nextConfig\"\n          )\n          $configContent = $configLines -join [System.Environment]::NewLine\n          Set-Content -Path \"next.config.js\" -Value $configContent -Encoding UTF8\n          Write-Host \"\u2705 next.config.js set for 'build' directory output\"\n\n          Write-Host \"Installing dependencies...\"\n          npm install --legacy-peer-deps\n          if ($LASTEXITCODE -ne 0) {\n            Write-Error \"npm install failed\"\n            exit 1\n          }\n\n          Write-Host \"Building...\"\n          npm run build\n          if ($LASTEXITCODE -ne 0) {\n            Write-Error \"npm run build failed\"\n            exit 1\n          }\n\n          Write-Host \"Moving build artifacts to 'public'...\"\n          New-Item -ItemType Directory -Force -Path \"public\" | Out-Null\n          Move-Item -Path \"build/*\" -Destination \"public\" -Force\n          if ($LASTEXITCODE -ne 0) {\n            Write-Error \"Failed to move build artifacts\"\n            exit 1\n          }\n          Write-Host \"\u2705 Artifacts moved.\"\n\n          # Verify output\n          Write-Host \"`nVerifying output...\"\n          if (-not (Test-Path \"public\")) {\n            Write-Host \"\u274c 'public' directory not found!\" -ForegroundColor Red\n            Write-Host \"Contents of current dir:\"\n            Get-ChildItem | Format-Table Name\n            exit 1\n          }\n\n          if (-not (Test-Path \"public/index.html\")) {\n            Write-Host \"\u274c public/index.html not found!\" -ForegroundColor Red\n            Write-Host \"Contents of 'public':\"\n            Get-ChildItem -Path \"public\" -Recurse | Format-Table Name\n            exit 1\n          }\n\n          $count = (Get-ChildItem -Path \"public\" -Recurse -File).Count\n          Write-Host \"\u2705 Frontend built: $count files\" -ForegroundColor Green\n\n      # ========== BACKEND ==========\n      - name: \ud83d\udc0d Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n          cache-dependency-path: 'web_service/backend/requirements.txt'\n\n      - name: \ud83d\udce6 Install Python Dependencies\n        shell: pwsh\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install pyinstaller==6.6.0\n          pip install pywin32 # CRITICAL: Provides the 'win32timezone' hidden import\n          pip install -r web_service/backend/requirements.txt\n\n      - name: \ud83d\udcc2 Create Data Directories\n        shell: pwsh\n        run: |\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/data\" | Out-Null\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/json\" | Out-Null\n          New-Item -ItemType Directory -Force -Path \"web_service/backend/logs\" | Out-Null\n\n      # ========== BUILD ==========\n      - name: \ud83d\udd28 Build with PyInstaller\n        shell: pwsh\n        run: |\n          Write-Host \"=== BUILDING MONOLITH ===\" -ForegroundColor Cyan\n\n          # Final verification\n          if (-not (Test-Path \"web_service/frontend/public/index.html\")) {\n            Write-Error \"\u274c Frontend not ready!\"\n            Write-Host \"Frontend path check:\"\n            Test-Path \"web_service/frontend/public\"\n            Test-Path \"web_service/frontend/public/index.html\"\n            exit 1\n          }\n\n          Write-Host \"\u2705 Frontend verified\"\n          Write-Host \"Running PyInstaller...\"\n\n          pyinstaller --noconfirm --clean fortuna-desktop.spec 2>&1 | Tee-Object -FilePath \"build.log\"\n\n          if ($LASTEXITCODE -ne 0) {\n            Write-Host \"Last 100 lines of build.log:\" -ForegroundColor Red\n            Get-Content \"build.log\" -Tail 100\n            exit 1\n          }\n\n          $exe = \"dist/Fortuna-Desktop/Fortuna-Desktop.exe\"\n          if (Test-Path $exe) {\n            $mb = (Get-Item $exe).Length / 1MB\n            Write-Host \"\u2705 BUILD SUCCESS: $([math]::Round($mb, 2)) MB\" -ForegroundColor Green\n          } else {\n            Write-Error \"EXE not created!\"\n            exit 1\n          }\n\n      # ========== PACKAGE & UPLOAD ==========\n      - name: \ud83d\udce6 Package Artifact for Distribution\n        shell: pwsh\n        run: |\n          $distDir = \"dist/Fortuna-Desktop\"\n          Write-Host \"=== PACKAGING ARTIFACT ===\" -ForegroundColor Cyan\n\n          # Create README.txt\n          $readmeLines = @(\n            'Fortuna Desktop - User Guide',\n            '',\n            '**HOW TO RUN**',\n            '1. Double-click \"Fortuna-Desktop.exe\".',\n            '2. The application window will open and the dashboard will load.',\n            '',\n            '**WHAT TO EXPECT**',\n            '- To stop the application, simply close the window.'\n          )\n          $readmeLines | Out-File -FilePath \"$distDir/README.txt\" -Encoding utf8\n          Write-Host \"\u2705 Created README.txt\"\n\n          # Create ZIP archive\n          $zipFileName = \"Fortuna-Desktop-Windows-${{ github.run_number }}.zip\"\n          Compress-Archive -Path \"$distDir/*\" -DestinationPath $zipFileName -Force\n          Write-Host \"\u2705 Created $zipFileName\" -ForegroundColor Green\n\n      - name: \ud83d\udce4 Upload Packaged Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: Fortuna-Desktop-Windows-${{ github.run_number }}\n          path: Fortuna-Desktop-Windows-${{ github.run_number }}.zip\n          if-no-files-found: error\n\n      # ========== TEST ==========\n      - name: Install VC++ Redistributable\n        shell: pwsh\n        run: |\n          # Download and install VC++ Runtime\n          $url = \"https://aka.ms/vs/17/release/vc_redist.x64.exe\"\n          Invoke-WebRequest -Uri $url -OutFile vc_redist.x64.exe\n          .\\vc_redist.x64.exe /install /quiet /norestart\n          Start-Sleep -Seconds 5\n          Get-Command vc_redist.x64.exe -ErrorAction SilentlyContinue\n\n      - name: \ud83e\uddea Smoke Test\n        shell: pwsh\n        timeout-minutes: 5\n        run: |\n          Write-Host \"=== SMOKE TEST ===\" -ForegroundColor Cyan\n          $exe = \"dist/Fortuna-Desktop/Fortuna-Desktop.exe\"\n\n          # 1. Launch App\n          Write-Host \"\ud83d\ude80 Launching $exe...\"\n          $process = Start-Process -FilePath $exe -PassThru\n          $processId = $process.Id\n          Write-Host \"   PID: $processId\"\n\n          # 2. Wait & Check Health\n          $url = \"http://127.0.0.1:8000/api/health\"\n          $maxRetries = 20\n          $success = $false\n\n          for ($i=1; $i -le $maxRetries; $i++) {\n            if ($process.HasExited) {\n              Write-Error \"\u274c Process crashed immediately! Exit Code: $($process.ExitCode)\"\n              break\n            }\n            try {\n              $resp = Invoke-WebRequest -Uri $url -UseBasicParsing -TimeoutSec 2\n              if ($resp.StatusCode -eq 200) {\n                Write-Host \"\u2705 Backend is HEALTHY!\" -ForegroundColor Green\n\n                # Take screenshot on success\n                try {\n                  Add-Type -AssemblyName System.Windows.Forms\n                  Add-Type -AssemblyName System.Drawing\n                  $bounds = [System.Windows.Forms.Screen]::PrimaryScreen.Bounds\n                  $bmp = New-Object System.Drawing.Bitmap $bounds.Width, $bounds.Height\n                  $graphics = [System.Drawing.Graphics]::FromImage($bmp)\n                  $graphics.CopyFromScreen($bounds.Location, [System.Drawing.Point]::Empty, $bounds.Size)\n                  $bmp.Save(\"smoke-test-screenshot.png\", [System.Drawing.Imaging.ImageFormat]::Png)\n                  $graphics.Dispose()\n                  $bmp.Dispose()\n                  Write-Host \"\ud83d\udcf8 Screenshot saved to smoke-test-screenshot.png\"\n                } catch {\n                  Write-Warning \"Failed to capture screenshot: $_\"\n                }\n\n                $success = $true\n                break\n              }\n            } catch {\n              Write-Host \"   Ping failed ($i/$maxRetries)...\"\n              Start-Sleep -Seconds 2\n            }\n          }\n\n          # 3. Wait for Frontend Rendering & Take Screenshot\n          if ($success) {\n            Write-Host \"\u23f3 Waiting for frontend to render dashboard...\"\n            $logPath = \"$env:TEMP\\fortuna-desktop.log\"\n            $timeout = 60\n            $logUpdated = $false\n            for ($j=0; $j -lt $timeout; $j++) {\n              if (Test-Path $logPath) {\n                $logContent = Get-Content $logPath -Raw\n                if ($logContent -match \"Extracted \\d+ races\") {\n                  Write-Host \"\u2705 Frontend has rendered races.\"\n                  $logUpdated = $true\n                  break\n                }\n              }\n              Start-Sleep -Seconds 1\n            }\n\n            if (-not $logUpdated) {\n              Write-Warning \"Timed out waiting for frontend to render. Proceeding with screenshot anyway.\"\n            }\n\n            try {\n              Add-Type -AssemblyName System.Windows.Forms\n              Add-Type -AssemblyName System.Drawing\n              $bounds = [System.Windows.Forms.Screen]::PrimaryScreen.Bounds\n              $bmp = New-Object System.Drawing.Bitmap $bounds.Width, $bounds.Height\n              $graphics = [System.Drawing.Graphics]::FromImage($bmp)\n              $graphics.CopyFromScreen($bounds.Location, [System.Drawing.Point]::Empty, $bounds.Size)\n              $bmp.Save(\"smoke-test-screenshot.png\", [System.Drawing.Imaging.ImageFormat]::Png)\n              $graphics.Dispose()\n              $bmp.Dispose()\n              Write-Host \"\ud83d\udcf8 Screenshot saved to smoke-test-screenshot.png\"\n            } catch {\n              Write-Warning \"Failed to capture screenshot: $_\"\n            }\n          }\n\n          # 4. Cleanup\n          if (-not $process.HasExited) {\n            Stop-Process -Id $processId -Force\n          }\n\n          # 5. Diagnostics (If Failed)\n          if (-not $success) {\n            Write-Host \"\u274c SMOKE TEST FAILED\" -ForegroundColor Red\n\n            # Check for the log file created by run_desktop_app.py\n            $logPath = \"$env:TEMP\\fortuna-desktop.log\"\n            if (Test-Path $logPath) {\n              Write-Host \"--- APPLICATION LOG ($logPath) ---\" -ForegroundColor Yellow\n              Get-Content $logPath\n              Write-Host \"----------------------------------\"\n            } else {\n              Write-Host \"\u26a0\ufe0f No application log found at $logPath\"\n            }\n            exit 1\n          }\n          Write-Host \"\u2705 Test Complete.\"\n\n      - name: \ud83d\uddbc\ufe0f Upload Smoke Test Screenshot\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: smoke-test-screenshot-${{ github.run_number }}\n          path: smoke-test-screenshot.png\n          if-no-files-found: ignore\n\n      - name: \ud83d\udccb Upload Build Log\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: build-log-${{ github.run_number }}\n          path: build.log\n          if-no-files-found: ignore\n",
    ".gitignore": "\n# Node.js\nnode_modules\nnpm-debug.log\nyarn-error.log\n\n# Python\n__pycache__/\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\npip-selfcheck.json\n.eggs/\ndist/\nbuild/\n*.egg-info/\n\n# IDEs and Editors\n.idea/\n.vscode/\n*.swp\n*.swo\n\n# OS-specific\n.DS_Store\nThumbs.db\n\n# Project-specific\n/web_service/frontend/public\n/web_service/frontend/build\n/web_service/frontend/.next\n\n# Jules's temporary log files\nnew_logs*.txt\n",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `fortuna`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n\n---\n\n## The Age of Perfection (The Great Simplification)\n\nThe Penta-Hybrid architecture, while a triumph of technical integration, proved to be a strategic dead end. Its complexity became a fortress, making rapid iteration and onboarding of new intelligence (both human and AI) prohibitively expensive. The kingdom was powerful but brittle.\n\nA new doctrine was forged: **Simplicity is the ultimate sophistication.**\n\nThe decision was made to execute \"The Great Simplification.\" The multi-language backend (Python, Rust, Go) was decommissioned. The kingdom was reforged upon a new, elegant, and vastly more powerful two-pillar system:\n\n1.  **A Unified Python Backend:** A single, asynchronous Python service, built on FastAPI, would serve as the kingdom's engine.\n2.  **A Modern TypeScript Frontend:** A dedicated Next.js application would serve as the kingdom's command deck.\n\nThis act of creative destruction liberated the project, enabling a new era of unprecedented velocity.\n\n---\n\n## The Three-Pillar Doctrine\n\nWith the new two-pillar foundation in place, the backend itself was perfected into a three-pillar intelligence engine, a concept that defines the modern era of the Fortuna Faucet:\n\n*   **Pillar 1: The Future (The Planner):** The resilient `OddsEngine` and its fleet of adapters, responsible for finding the day's strategic opportunities.\n*   **Pillar 2: The Past (The Archive):** The perfected `ChartScraper` and `ResultsParser`, responsible for building our historical data warehouse from the ground truth of Equibase PDFs.\n*   **Pillar 3: The Present (The Finisher):** The weaponized `LiveOddsMonitor`, armed with the API-driven `BetfairAdapter`, designed to conquer the final moments of toteboard volatility.\n\nThese three pillars, orchestrated by the fully autonomous `fortuna_watchman.py`, represented the pinnacle of the project's original vision. The kingdom was, for a time, considered \"perfected.\"\n\n---\n\n## The Windows Ascension (The Impossible Dream)\n\nThe perfected kingdom was powerful, but it was still a tool for developers. The final, grandest vision was to transform it into a true, professional-grade application for its sole operator. This campaign, known as \"The Impossible Dream,\" was to forge the **Fortuna Faucet - Windows Native Edition.**\n\nThis era saw the rapid creation of a new, third layer of the kingdom, built upon the foundation of the previous work:\n\n*   **The Electron Shell:** The Next.js frontend was wrapped in an Electron container, transforming it from a website into a true, installable desktop application with its own window, icon, and system tray integration.\n*   **The Engine Room:** The Python backend was re-architected to run as a persistent, background **Windows Service**, making it a true, always-on component of the operating system, independent of the UI.\n*   **The Native GUI:** A dedicated Tkinter-based \"Observatory\" was forged\u2014a standalone GUI mission control for monitoring the health and performance of the background service.\n*   **The One-Click Kingdom:** A complete suite of professional tooling (including installation scripts, a setup wizard, and launchers) was created to provide a seamless, zero-friction installation and management experience.\n\nThis ascension represents the current state of the art, transforming a powerful engine into a polished, autonomous, and user-focused product.\n\n\n---\n\n## The Era of the Windows Kingdom (October 2025)\n\nWith the core engine stabilized and the command deck providing a clear view of the data, the project's focus shifted from pure data acquisition to the operator's experience. This era marked a profound transformation, elevating the project from a collection of powerful but disparate scripts into a cohesive, professional-grade, and resilient native Windows application.\n\nThis campaign, guided by a new \"Grand Strategy\" blueprint, was executed with rapid precision, resulting in a complete overhaul of the user-facing toolkit:\n\n-   **A Bulletproof Foundation:** The installation and launch scripts were re-architected from the ground up. They became intelligent and self-healing, featuring pre-flight system checks, automated port conflict resolution, active health-check loops, and automated repair utilities.\n-   **A Professional Toolkit:** The operator was empowered with a suite of new tools, including an interactive setup wizard, a real-time CLI status monitor, and a full-fledged graphical \"Data Management Console\" for monitoring, filtering, and analyzing data.\n-   **A Unified Command Console (`SERVICE_MANAGER.bat`):** Unify all individual scripts under a single, user-friendly, menu-driven service manager, providing a 'single pane of glass' for all common operations.\n\nThis era solidified the kingdom's foundations, making it not just powerful, but stable, reliable, and a pleasure to operate. The Faucet was no longer just an engine; it was a complete, professional-grade machine.\n\n---\n\n## The Gauntlet of CI/CD (Late October 2025)\n\nWith a professional-grade application in hand, the final frontier was professional-grade *delivery*. This campaign focused on automating the creation of the MSI installer through a continuous integration pipeline, a process that proved to be a formidable challenge.\n\nThe kingdom's engineers faced a relentless series of cryptic build errors from the WiX Toolset, a hostile environment that tested their resolve. Through a series of rapid, iterative fixes\u2014addressing everything from component GUIDs and 64-bit architecture mismatches to obscure linker errors and frontend dependency warnings\u2014they systematically conquered each obstacle.\n\nThis trial by fire culminated in a triumphant success: a fully automated GitHub Actions workflow that reliably compiles, links, and delivers a polished, distributable MSI installer. This victory transformed the project's delivery model from a manual, error-prone process into a repeatable, one-click release pipeline, marking the true completion of the \"Windows Ascension.\"\n\n---\n\n## The Great Unbundling (Late October 2025)\n\nThe CI/CD pipeline was technically successful, but it revealed a deeper, philosophical flaw in the architecture. The installer, while automated, was a fragile monolith. It attempted to bundle raw source code (Python, JavaScript) and orchestrate their setup on the user's machine using post-install scripts. This approach was fraught with peril, vulnerable to failures from network issues, corporate firewalls, and unpredictable machine states.\n\nA final, decisive architectural mandate was issued, informed by the wisdom of external AI consultants: **The application must be delivered, not assembled.**\n\nThis mandate triggered \"The Great Unbundling,\" a swift and transformative refactoring of the entire delivery pipeline:\n\n*   **The Backend Forged:** The Python backend was no longer treated as source code to be installed, but as a product to be delivered. **PyInstaller** was used to forge the entire FastAPI service\u2014interpreter and all dependencies\u2014into a single, standalone `.exe`.\n*   **The Frontend Solidified:** The Next.js frontend was no longer a service to be run, but a static asset to be displayed. The `npm run build` process was configured to produce a clean, static HTML/CSS/JS export.\n*   **The Installer Perfected:** With the application components now self-contained, the MSI installer's role was radically simplified. All complex post-install scripting was eliminated. The WiX toolset was now used for its core competency: reliably copying pre-compiled, robust artifacts to the user's machine.\n\nThis final act of architectural purification created the \"Three-Executable Architecture\" (the backend executable, the Electron wrapper, and the MSI installer itself), achieving true portability and eliminating an entire class of deployment failures. The Windows Ascension was not just complete; it was perfected.",
    "README.md": "# \ud83d\udc34 Fortuna Faucet - Developer's Guide\n\nThis guide provides technical instructions for developers. For end-user installation, please refer to the MSI installers generated by the project's GitHub Actions workflows.\n\n---\n\n## \ud83c\udfdb\ufe0f Core Architecture\n\nThis repository contains the source code for the Fortuna Faucet application, which has two primary deployment targets:\n\n1.  **Standalone Web Service (MSI Installer):**\n    *   A Python backend powered by FastAPI, compiled into a self-contained executable using PyInstaller.\n    *   A static Next.js frontend, which is bundled with the backend.\n    *   The entire application is packaged into an MSI installer using the WiX Toolset, which installs the backend as a background Windows Service.\n\n2.  **Electron Desktop Application (MSI Installer):**\n    *   The same Python backend, compiled as an executable.\n    *   An Electron application that acts as a wrapper, launching the backend executable and displaying the frontend.\n\nThe `python_service` and `web_service/backend` directories contain functionally equivalent but historically separate versions of the backend code. The modern workflows primarily use `web_service/backend`.\n\n---\n\n## \ud83c\udfd7\ufe0f Building the Application (The Right Way)\n\n**This project is built and packaged entirely through GitHub Actions.** The CI/CD pipelines are the single source of truth for creating production-ready installers. Manual builds are not recommended or supported due to the complexity of the environment.\n\nThe primary, production-ready build workflows are:\n\n*   **`build-msi-hattrickfusion-ultimate.yml`**: Builds the standalone Web Service MSI. This is the most feature-rich and stable build pipeline.\n*   **`build-electron-msi-gpt5.yml`**: Builds the Electron-based desktop application MSI.\n\nThese workflows handle all necessary steps, including:\n*   Installing the correct versions of Python, Node.js, and the WiX Toolset.\n*   Managing architecture-specific dependencies (e.g., `pandas` for x86 builds).\n*   Compiling the Python backend with PyInstaller.\n*   Building the static Next.js frontend.\n*   Packaging the final MSI installer.\n*   Running automated smoke tests to verify the installation.\n\nTo get a build, simply push a commit to the `main` branch and retrieve the MSI artifact from the completed workflow run on the [Actions tab](https://github.com/masonj0/fortuna/actions) of the repository.\n\n---\n\n## \ud83d\udd2c Local Development Environment\n\n### Python Version Requirement\n\n**Crucial:** The monolith build of this project requires **Python 3.10.11**. It is not compatible with Python 3.11 or newer due to a dependency on `cefpython3`, which does not support Python 3.11.\n\nBefore running the application locally or attempting to build it, ensure you are using the correct Python version.\n\n- **Using `pyenv` (Recommended):**\n  ```bash\n  pyenv install 3.10.11\n  pyenv local 3.10.11\n  ```\n\n- **Using `conda`:**\n  ```bash\n  conda create -n fortuna python=3.10.11\n  conda activate fortuna\n  ```\n\nWhile production builds are handled by CI/CD, the easiest way to run the application locally for development is to use the new quick-start script.\n\n```powershell\n# From the project root\n./scripts/fortuna-quick-start.ps1\n```\n\nThis interactive script will:\n*   Check for all required dependencies (Python, Node.js, etc.).\n*   Install any missing Python or Node packages automatically.\n*   Clear the required network ports (8000 and 3000).\n*   Launch the backend and frontend services in separate, managed terminal windows.\n*   Provide a clean shutdown process.\n\nFor detailed options and first-time setup guidance, run the script with the `-Help` flag:\n```powershell\n./scripts/fortuna-quick-start.ps1 -Help\n```\n\n---\n## \ud83d\udce6 Key Tooling & Scripts\n\n*   **`ARCHIVE_PROJECT.py`**: A utility script that scans the repository and generates the `FORTUNA_ALL_PART*.JSON` archive files. These archives are used as a ground truth for AI-driven code reviews and analysis.\n*   **`AGENTS.md`**: Contains critical operational protocols for the AI agents working on this repository.\n\n---\n\n## \ud83d\udc0d Python Version Requirement\n\n**The Fortuna Monolith application must be built and run with Python 3.10.12.**\n\nThis is due to a dependency (`cefpython3`) that does not support Python 3.11 or newer. The CI/CD workflows are pinned to this version. If you are building the application locally, please ensure you are using a Python 3.10.x environment.\n",
    "STATUS.md": "# Project Status: Foundation Rebuilt, Hardening in Progress\n\n**Date:** 2025-10-03\n\n## Current State\n\n*   **Architecture:** The backend has been successfully rebuilt into a superior, asynchronous FastAPI application, as defined by 'Operation: Grand Synthesis'. The new foundation is stable, tested, and features a resilient `BaseAdapter` pattern.\n\n*   **Status:** The foundational refactoring is complete. The first two data adapters (`Betfair`, `TVG`) have been implemented on the new architecture. We are now in a new phase of development: **'Phase 2: Hardening & Expansion.'**\n\n*   **Documentation:** All core strategic documents and manifests have been synchronized with the new technical reality.\n\n*   **Next Steps:** Our immediate priority is to act on the verified intelligence from our Oracle (Jules1003). The next missions will focus on implementing critical API security features (rate limiting, authentication) and continuing the build-out of our adapter fleet.",
    "assets/sounds/.gitkeep": "# This directory is for audio alert sound files (e.g., alert_premium.wav)",
    "check_port.py": "# check_port.py\nimport socket\nimport time\n\n\ndef check_server_status(host, port):\n    \"\"\"Checks if the server is accessible.\"\"\"\n    time.sleep(5)  # Give server time to start\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        try:\n            s.connect((host, port))\n            print(\"SERVER CHECK: SUCCESS! Server is running and accessible.\")\n            return True\n        except ConnectionRefusedError:\n            print(\"SERVER CHECK: FAILED! Server is not accessible.\")\n            return False\n\n\nif __name__ == \"__main__\":\n    check_server_status(\"127.0.0.1\", 8000)\n",
    "electron/assets/license.rtf": "{\\rtf1\\ansi\\deff0\n{\\fonttbl{\\f0 Courier New;}}\n\\f0\\fs20\nFortuna Faucet License Agreement\\line\n\\line\nThis is a hobby project. It was cobbled together with a lot of caffeine and hope.\\line\n\\line\nThere are no warranties, guarantees, or promises that this will work.\\line\nFeel free to use it, break it, or share it. No copyrights are claimed.\\line\n\\line\nGood luck! You might need it.\n}",
    "electron/install-dependencies.js": "const { execSync } = require('child_process');\nconst path = require('path');\nconst fs = require('fs');\n\n// Path to the bundled Python executable (fortuna-backend.exe)\nconst PYTHON_EXE = path.join(process.resourcesPath, 'fortuna-backend.exe');\n// Path to the Python service directory (where alembic.ini is)\nconst PYTHON_SERVICE_DIR = path.join(process.resourcesPath, 'python_service');\n\nfunction runCommand(command, cwd) {\n    console.log(`Executing: ${command} in ${cwd}`);\n    try {\n        const output = execSync(command, { cwd: cwd, encoding: 'utf-8' });\n        console.log(output);\n    } catch (error) {\n        console.error(`Command failed: ${command}`);\n        console.error(error.stderr || error.stdout || error.message);\n        throw new Error(`Post-install setup failed: ${command}`);\n    }\n}\n\nfunction setupDatabase() {\n    console.log('--- Starting Database Setup (Alembic Migrations) ---');\n    // NOTE: The bundled EXE must be able to run a command like 'alembic' or a custom script\n    // that executes the migrations. Assuming the bundled EXE can run a module.\n    // A more robust solution is to bundle a dedicated migration script.\n\n    // Assuming the bundled EXE can execute a module that runs Alembic\n    const migrationCommand = `${PYTHON_EXE} -m python_service.database.run_migrations`;\n\n    // The migration script needs access to the database URL from the config.\n    // This is a placeholder, as the config loading is complex in a frozen app.\n    // For now, we assume the bundled EXE handles config loading.\n\n    runCommand(migrationCommand, PYTHON_SERVICE_DIR);\n    console.log('--- Database Setup Complete ---');\n}\n\n// This function is called by the Electron Builder installer hook\nmodule.exports = async function() {\n    try {\n        setupDatabase();\n    } catch (e) {\n        console.error('FATAL: Post-install setup failed.', e);\n        // In a real installer, you might log this and continue, or show a user error.\n    }\n};\n",
    "electron/main.js": "// electron/main.js - CORRECTED VERSION\nconst { app, BrowserWindow, Tray, Menu, nativeImage, ipcMain, dialog } = require('electron');\nconst { autoUpdater } = require('electron-updater');\nconst { spawn } = require('child_process');\nconst net = require('net');\nconst path = require('path');\nconst fs = require('fs');\nconst SecureSettingsManager = require('./secure-settings-manager');\n\nclass FortunaDesktopApp {\n constructor() {\n this.backendProcess = null;\n this.mainWindow = null;\n this.tray = null;\n this.backendState = 'stopped'; // \"stopped\", \"starting\", \"running\", \"error\"\n this.backendLogs = [];\n this.isBackendStarting = false;\n }\n\n sendBackendStatusUpdate() {\n if (this.mainWindow) {\n this.mainWindow.webContents.send('backend-status-update', {\n state: this.backendState,\n logs: this.backendLogs.slice(-20) // Send last 20 log entries\n });\n }\n }\n\n stopBackend() {\n if (this.backendProcess && !this.backendProcess.killed) {\n console.log('Stopping backend process...');\n this.backendProcess.kill();\n this.backendState = 'stopped';\n this.isBackendStarting = false; // Ensure lock is released on stop\n this.backendLogs.push('Backend process stopped by user.');\n this.sendBackendStatusUpdate();\n }\n }\n\n  checkPortInUse(port) {\n    return new Promise((resolve, reject) => {\n      const server = net.createServer();\n      server.once('error', (err) => {\n        if (err.code === 'EADDRINUSE') {\n          resolve(true); // Port is in use\n        } else {\n          reject(err);\n        }\n      });\n      server.once('listening', () => {\n        server.close(() => {\n          resolve(false); // Port is free\n        });\n      });\n      server.listen(port, '127.0.0.1');\n    });\n  }\n\n  async waitForBackend(maxRetries = 30) {\n    const port = process.env.FORTUNA_PORT || 8000;\n    const url = `http://127.0.0.1:${port}/health`;\n\n    console.log(`[Backend Check] Starting health check at: ${url}`);\n\n    for (let i = 0; i < maxRetries; i++) {\n      try {\n        const response = await fetch(url, { timeout: 3000 });\n        console.log(`[Backend Check] Attempt ${i}: Status ${response.status}`);\n\n        if (response.ok) {\n          console.log('\u2705 Backend is healthy and responding');\n          return true;\n        }\n      } catch (e) {\n        console.log(`[Backend Check] Attempt ${i} failed: ${e.message}`);\n\n        // Check if process is still alive\n        if (this.backendProcess && !this.backendProcess.killed) {\n          console.log(`[Backend Check] Process still running (PID: ${this.backendProcess.pid})`);\n        } else {\n          console.error(`[Backend Check] \u26a0\ufe0f  Backend process is DEAD!`);\n          console.error(`[Backend Check] Last logs:`, this.backendLogs.slice(-5));\n          throw new Error(`Backend process died. Last logs:\\\\n${this.backendLogs.slice(-5).join('\\\\n')}`);\n        }\n\n        await new Promise(r => setTimeout(r, 1000));\n      }\n    }\n\n    throw new Error(`Backend failed to respond at ${url} after 30 seconds`);\n  }\n\n  async startBackend() {\n    const isDev = !app.isPackaged;\n    let backendCommand;\n    let backendCwd;\n\n    if (isDev) {\n      console.log('[DEV MODE] Configuring backend...');\n      backendCommand = path.join(__dirname, '..', '.venv', 'Scripts', 'python.exe');\n      backendCwd = path.join(__dirname, '..', 'web_service', 'backend');\n    } else {\n      // CORRECTED PATH: In production, the backend executable is at the root of the resources directory.\n      backendCommand = path.join(process.resourcesPath, 'fortuna-backend.exe');\n      backendCwd = process.resourcesPath;\n\n      console.log(`[Backend] Looking for executable at: ${backendCommand}`);\n      console.log(`[Backend] Executable exists: ${fs.existsSync(backendCommand)}`);\n    }\n\n    if (!fs.existsSync(backendCommand)) {\n      const errorMsg = `Backend executable not found at: ${backendCommand}`;\n      console.error(`[Backend] ${errorMsg}`);\n      this.backendLogs.push(`ERROR: ${errorMsg}`);\n      this.backendState = 'error';\n      dialog.showErrorBox(\n        'Backend Launch Failed',\n        `Could not find backend executable.\\\\n\\\\nExpected location:\\\\n${backendCommand}`\n      );\n      return;\n    }\n\n    console.log(`[Backend] Executable found, attempting to spawn...`);\n\n    this.backendProcess = spawn(backendCommand, [], {\n      cwd: backendCwd,\n      windowsHide: true,\n      env: {\n        ...process.env,\n        FORTUNA_MODE: 'electron',\n        PYTHONPATH: backendCwd\n      }\n    });\n\n    this.backendState = 'starting';\n    this.isBackendStarting = true;\n\n    this.backendProcess.stdout.on('data', (data) => {\n      const output = data.toString().trim();\n      console.log(`[Backend STDOUT] ${output}`);\n      this.backendLogs.push(output);\n\n      // Detect successful startup from log messages\n      if (output.includes('Application startup complete') || output.includes('Uvicorn running')) {\n        if (this.backendState !== 'running') {\n          console.log('\u2705 Backend reported successful startup');\n          this.backendState = 'running';\n          this.isBackendStarting = false;\n        }\n      }\n\n      this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.stderr.on('data', (data) => {\n      const errorOutput = data.toString().trim();\n      console.error(`[Backend STDERR] ${errorOutput}`);\n      this.backendLogs.push(`ERROR: ${errorOutput}`);\n\n      if (this.backendState === 'starting') {\n        this.backendState = 'error';\n        this.isBackendStarting = false;\n      }\n\n      this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.on('error', (err) => {\n      const errorMsg = `Failed to spawn backend process: ${err.message}`;\n      console.error(`[Backend] ${errorMsg}`);\n      this.backendLogs.push(`ERROR: ${errorMsg}`);\n      this.backendState = 'error';\n      this.isBackendStarting = false;\n      this.sendBackendStatusUpdate();\n    });\n\n    this.backendProcess.on('exit', (code) => {\n      if (code !== 0 && this.backendState !== 'stopped') {\n        console.error(`[CRITICAL] Backend process exited with code: ${code}`);\n        console.error(`[CRITICAL] Last 10 logs:`, this.backendLogs.slice(-10));\n\n        // Save logs for debugging\n        const logFile = path.join(require('os').homedir(), '.fortuna', 'backend_crash.log');\n        fs.mkdirSync(path.dirname(logFile), { recursive: true });\n        fs.writeFileSync(logFile, this.backendLogs.join('\\\\n'));\n        console.error(`[CRITICAL] Full logs saved to: ${logFile}`);\n\n        this.backendState = 'error';\n        this.isBackendStarting = false;\n        this.sendBackendStatusUpdate();\n      }\n    });\n  }\n\n  getFrontendPath() {\n    // UNIFIED: Always serve from the backend\n    const port = process.env.FORTUNA_PORT || 8000;\n    return `http://127.0.0.1:${port}/`;\n  }\n\n createMainWindow() {\n this.mainWindow = new BrowserWindow({\n width: 1600,\n height: 1000,\n title: 'Fortuna Faucet - Racing Analysis',\n icon: path.join(__dirname, 'assets', 'icon.ico'),\n webPreferences: {\n nodeIntegration: false,\n contextIsolation: true,\n preload: path.join(__dirname, 'preload.js')\n },\n autoHideMenuBar: true,\n backgroundColor: '#1a1a2e'\n });\n\n if (!app.isPackaged) {\n this.mainWindow.webContents.openDevTools();\n }\n\n this.mainWindow.on('close', (event) => {\n if (!app.isQuitting) {\n event.preventDefault();\n this.mainWindow.hide();\n }\n });\n }\n\n createSystemTray() {\n // ... (rest of the file is unchanged)\n }\n\n  initialize() {\n    console.log('[Electron] Initializing Fortuna application...');\n\n    this.createMainWindow();\n    this.createSystemTray();\n    this.startBackend();\n\n    // Wait for backend to be ready, then load the unified frontend\n    this.waitForBackend()\n      .then(() => {\n        console.log('[Electron] Backend is ready, loading frontend...');\n        const frontendUrl = this.getFrontendPath();\n        console.log(`[Electron] Loading frontend from: ${frontendUrl}`);\n        this.mainWindow.loadURL(frontendUrl);\n      })\n      .catch((err) => {\n        console.error('[Electron] Backend startup failed:', err);\n        dialog.showErrorBox(\n          'Backend Error',\n          'Failed to start backend service:\\\\n\\\\n' + err.message\n        );\n      });\n\n    // Check for updates\n    autoUpdater.checkForUpdatesAndNotify();\n\n    autoUpdater.on('update-downloaded', (info) => {\n      const dialogOpts = {\n        type: 'info',\n        buttons: ['Restart', 'Later'],\n        title: 'Application Update',\n        message: process.platform === 'win32' ? info.releaseName : info.releaseName,\n        detail: 'A new version has been downloaded. Restart the application to apply the updates.'\n      };\n\n      dialog.showMessageBox(dialogOpts).then((returnValue) => {\n        if (returnValue.response === 0) autoUpdater.quitAndInstall();\n      });\n    });\n\n    ipcMain.on('restart-backend', () => this.startBackend());\n    ipcMain.on('stop-backend', () => this.stopBackend());\n    ipcMain.handle('get-backend-status', async () => ({\n      state: this.backendState,\n      logs: this.backendLogs.slice(-20)\n    }));\n\n    ipcMain.handle('get-api-key', async () => {\n      return SecureSettingsManager.getApiKey();\n    });\n\n    ipcMain.handle('generate-api-key', async () => {\n      const crypto = require('node:crypto');\n      const newKey = crypto.randomBytes(16).toString('hex');\n      SecureSettingsManager.saveApiKey(newKey);\n      return newKey;\n    });\n\n    ipcMain.handle('save-api-key', async (event, apiKey) => {\n      return SecureSettingsManager.saveApiKey(apiKey);\n    });\n\n    ipcMain.handle('save-betfair-credentials', async (event, credentials) => {\n      return SecureSettingsManager.saveBetfairCredentials(credentials);\n    });\n\n    ipcMain.handle('get-api-port', () => {\n      return process.env.FORTUNA_PORT || 8000;\n    });\n  }\n\n cleanup() {\n if (this.backendProcess && !this.backendProcess.killed) {\n this.backendProcess.kill();\n }\n }\n}\n\nlet fortunaApp;\n\napp.whenReady().then(() => {\n  // Harden the session for security\n  const { session } = require('electron');\n  const ses = session.defaultSession;\n\n  // 1. Content-Security-Policy\n  ses.webRequest.onHeadersReceived((details, callback) => {\n    callback({\n      responseHeaders: {\n        ...details.responseHeaders,\n        'Content-Security-Policy': [\n          \"default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self' data:; connect-src 'self' http://127.0.0.1:*\"\n        ]\n      }\n    });\n  });\n\n  // 2. Permission Request Handler\n  ses.setPermissionRequestHandler((webContents, permission, callback) => {\n    const allowedPermissions = ['clipboard-read', 'clipboard-sanitized-write'];\n    if (allowedPermissions.includes(permission)) {\n      callback(true); // Grant allowed permissions\n    } else {\n      console.warn(`[SECURITY] Denied permission request for: ${permission}`);\n      callback(false); // Deny all others by default\n    }\n  });\n\n  // 3. Certificate Pinning (TODO)\n  // Certificate pinning would be implemented here. It is commented out\n  // because it requires a known certificate hash and would break local dev.\n  // ses.setCertificateVerifyProc((request, callback) => {\n  //   const { hostname, certificate, verificationResult } = request;\n  //   if (hostname === 'api.fortuna.faucet') {\n  //     // TODO: Replace with actual certificate fingerprint\n  //     const expectedFingerprint = '...';\n  //     if (certificate.fingerprint === expectedFingerprint) {\n  //       callback(0); // 0 means success\n  //     } else {\n  //       callback(-2); // -2 means failure\n  //     }\n  //   } else {\n  //     callback(0); // Allow other domains\n  //   }\n  // });\n\n  fortunaApp = new FortunaDesktopApp();\n  fortunaApp.initialize();\n});\n\napp.on('window-all-closed', () => {\n if (process.platform !== 'darwin') {\n // Do nothing, keep app running in tray\n }\n});\n\napp.on('activate', () => {\n if (BrowserWindow.getAllWindows().length === 0) {\n fortunaApp.createMainWindow();\n } else {\n fortunaApp.mainWindow.show();\n }\n});\n\napp.on('before-quit', () => {\n app.isQuitting = true;\n if (fortunaApp) {\n fortunaApp.cleanup();\n }\n});\n",
    "fortuna-backend-webservice.spec": "# -*- mode: python ; coding: utf-8 -*-\nfrom pathlib import Path\nfrom PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\n# This spec has been standardized to build the web_service from its own directory,\n# removing the dependency on the obsolete 'python_service'.\n\nblock_cipher = None\nproject_root = Path(SPECPATH).parent\nbackend_root = project_root / 'web_service' / 'backend'\n\n# --- Data Files ---\n# Collect all necessary data files from their respective packages.\ndatas = []\ndatas += collect_data_files('uvicorn')\ndatas += collect_data_files('fastapi')\ndatas += collect_data_files('starlette')\n\n# --- Hidden Imports ---\n# Ensure all necessary submodules and dynamically loaded modules are included.\nhiddenimports = set()\nhiddenimports.update(collect_submodules('web_service.backend'))\nhiddenimports.update(collect_submodules('uvicorn'))\nhiddenimports.update(collect_submodules('fastapi'))\nhiddenimports.update(collect_submodules('starlette'))\nhiddenimports.update(collect_submodules('anyio'))\nhiddenimports.add('win32timezone') # Critical for Windows service operation\nhiddenimports.update(['pydantic_settings.sources']) # For settings management\n\na = Analysis(\n    [str(backend_root / 'service_entry.py')], # Entry point is the service wrapper\n    pathex=[str(project_root)],\n    binaries=[],\n    datas=datas,\n    hiddenimports=sorted(hiddenimports),\n    hookspath=[str(project_root / 'fortuna-backend-hooks')],\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False\n)\n\n# --- PYZ Archive ---\n# Force __init__.py files into the PYZ archive to ensure robust module loading.\na.pure += [\n    ('web_service', str(project_root / 'web_service/__init__.py'), 'PYMODULE'),\n    ('web_service.backend', str(backend_root / '__init__.py'), 'PYMODULE'),\n]\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\n# --- Final Executable ---\n# This creates a single-file executable. The COLLECT object has been removed\n# as it is not needed for this build target.\nexe = EXE(\n    pyz,\n    a.scripts,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    name='fortuna-webservice',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    runtime_tmpdir=None,\n    console=True # Console is useful for debugging service startup\n)\n",
    "fortuna-webservice.spec": "# -*- mode: python ; coding: utf-8 -*-\n\nimport os\nfrom pathlib import Path\nfrom PyInstaller.utils.hooks import collect_data_files, collect_submodules\n\nblock_cipher = None\nproject_root = Path(SPECPATH).resolve()\n\ndef include_tree(rel_path, target, store):\n    absolute = project_root / rel_path\n    if absolute.exists():\n        store.append((str(absolute), target))\n        print(f\"[spec] Including {absolute} -> {target}\")\n    else:\n        # This spec is used by the legacy build-msi.yml, which checks for these dirs.\n        # If they are missing here, it's a critical error.\n        raise FileNotFoundError(f\"[spec] Required directory not found: {absolute}\")\n\ndatas = []\n# Paths must match the legacy structure used by build-msi.yml\ninclude_tree('python_service/adapters', 'adapters', datas)\ninclude_tree('python_service/data', 'data', datas)\ninclude_tree('python_service/json', 'json', datas)\n\n# Collect library assets\ntry:\n    datas += collect_data_files('uvicorn', includes=['*.html', '*.json'])\n    datas += collect_data_files('structlog', includes=['*.json'])\nexcept Exception as e:\n    print(f\"[spec] Warning: Could not collect library data files: {e}\")\n\n# Collect Hidden Imports for python_service\nhidden_imports = set()\nhidden_imports.update(collect_submodules('python_service'))\nhidden_imports.update([\n    'fastapi', 'uvicorn', 'uvicorn.logging', 'uvicorn.loops.auto', 'uvicorn.lifespan.on',\n    'uvicorn.protocols.http.h11_impl', 'uvicorn.protocols.http.httptools_impl',\n    'uvicorn.protocols.websockets.wsproto_impl', 'uvicorn.protocols.websockets.websockets_impl',\n    'anyio', 'httpcore', 'httpx', 'python_multipart', 'pydantic', 'pydantic_core',\n    'aiosqlite', 'structlog', 'tenacity', 'slowapi'\n])\n\na = Analysis(\n    # FIX: Target service_entry.py instead of main.py\n    ['web_service/backend/service_entry.py'],\n    pathex=[],\n    binaries=[],\n    datas=[('web_service/backend', 'backend')],\n    # FIX: Ensure critical service modules are hidden-imported\n    hiddenimports=['win32timezone', 'win32serviceutil', 'win32service', 'win32event'],\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    noarchive=False,\n)\n\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz,\n    a.scripts,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    [],\n    name='fortuna-webservice', # Name matches the workflow expectation\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=False,\n    runtime_tmpdir=None,\n    console=False,\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\n",
    "fortuna_monitor.py": "# fortuna_monitor.py - Windows-Optimized Version\n\nimport os\nimport sys\nimport threading\nimport time\nimport tkinter as tk\nfrom collections import deque\nfrom datetime import datetime\nfrom tkinter import filedialog\nfrom tkinter import messagebox\n\nimport httpx\nimport psutil\n\n# Try to import matplotlib for graphs\ntry:\n    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n    from matplotlib.figure import Figure\n\n    GRAPHS_AVAILABLE = True\nexcept ImportError:\n    GRAPHS_AVAILABLE = False\n\nAPI_BASE_URL = \"http://localhost:8000\"\n\n\nclass PerformanceTracker:\n    def __init__(self, max_history=100):\n        self.timestamps = deque(maxlen=max_history)\n        self.race_counts = deque(maxlen=max_history)\n        self.fetch_durations = deque(maxlen=max_history)\n        self.success_rates = deque(maxlen=max_history)\n        self.cpu_usage = deque(maxlen=max_history)\n        self.memory_usage = deque(maxlen=max_history)\n\n    def add_datapoint(self, races, duration, success_rate):\n        self.timestamps.append(datetime.now())\n        self.race_counts.append(races)\n        self.fetch_durations.append(duration)\n        self.success_rates.append(success_rate)\n        self.cpu_usage.append(psutil.cpu_percent(interval=None))\n        process = psutil.Process(os.getpid())\n        self.memory_usage.append(process.memory_info().rss / 1024 / 1024)  # MB\n\n    def export_to_csv(self, filename):\n        import csv\n\n        history = self.get_history()\n        with open(filename, \"w\", newline=\"\") as f:\n            writer = csv.writer(f)\n            writer.writerow([\"Timestamp\", \"Races\", \"Duration\", \"Success Rate\", \"CPU %\", \"Memory MB\"])\n            for i in range(len(history[\"times\"])):\n                writer.writerow(\n                    [\n                        history[\"times\"][i].isoformat(),\n                        history[\"races\"][i],\n                        history[\"durations\"][i],\n                        history[\"success\"][i],\n                        history[\"cpu\"][i],\n                        history[\"memory\"][i],\n                    ]\n                )\n\n    def get_history(self):\n        return {\n            \"times\": list(self.timestamps),\n            \"races\": list(self.race_counts),\n            \"durations\": list(self.fetch_durations),\n            \"success\": list(self.success_rates),\n            \"cpu\": list(self.cpu_usage),\n            \"memory\": list(self.memory_usage),\n        }\n\n\nclass FortunaAdvancedMonitor(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - Advanced Monitor\")\n        self.geometry(\"900x650\")\n        self.api_key = os.getenv(\"API_KEY\")\n        self.performance = PerformanceTracker()\n        self.running = True\n        self._create_widgets()\n        self.after(100, self.start_fetch_thread)\n\n    def _create_widgets(self):\n        self._create_control_panel()\n        # ... (rest of the widget creation)\n\n    def _create_control_panel(self):\n        control_frame = tk.Frame(self, bg=\"#1a1a2e\")\n        control_frame.pack(fill=tk.X, padx=15, pady=10)\n\n        tk.Button(\n            control_frame,\n            text=\"\ud83d\udcca Export Performance Data\",\n            command=self.export_data,\n            bg=\"#0f3460\",\n            fg=\"#ffffff\",\n            font=(\"Segoe UI\", 10, \"bold\"),\n            relief=tk.FLAT,\n            padx=25,\n            pady=10,\n        ).pack(side=tk.LEFT, padx=5)\n\n        tk.Button(\n            control_frame,\n            text=\"\ud83d\udcbb System Info\",\n            command=self.show_system_info,\n            bg=\"#0f3460\",\n            fg=\"#ffffff\",\n            font=(\"Segoe UI\", 10, \"bold\"),\n            relief=tk.FLAT,\n            padx=25,\n            pady=10,\n        ).pack(side=tk.LEFT, padx=5)\n\n    def start_fetch_thread(self):\n        self.fetch_thread = threading.Thread(target=self._fetch_data_loop, daemon=True)\n        self.fetch_thread.start()\n\n    def _fetch_data_loop(self):\n        while self.running:\n            try:\n                # Use httpx for async requests\n                with httpx.Client(headers={\"X-API-KEY\": self.api_key}, timeout=5) as client:\n                    response = client.get(f\"{API_BASE_URL}/api/adapters/status\")\n                if response.status_code == 200:\n                    data = response.json()\n                    # Add performance datapoint\n                    total_races = sum(a.get(\"races_fetched\", 0) for a in data)\n                    successful_adapters = [a for a in data if a.get(\"status\") == \"SUCCESS\"]\n                    success_rate = (len(successful_adapters) / len(data) * 100) if data else 0\n                    avg_duration = (\n                        sum(a.get(\"fetch_duration\", 0) for a in successful_adapters) / len(successful_adapters)\n                        if successful_adapters\n                        else 0\n                    )\n                    self.performance.add_datapoint(total_races, avg_duration, success_rate)\n\n                    self.after(0, self.update_ui, data)\n            except httpx.RequestError:\n                pass\n            time.sleep(10)  # Refresh interval\n\n    def update_ui(self, data):\n        # This is where you would update the tkinter UI with the new data\n        # For example, you might update a treeview or a graph\n        pass\n\n    def export_data(self):\n        filename = filedialog.asksaveasfilename(\n            defaultextension=\".csv\",\n            filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")],\n            initialfile=f\"fortuna_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n        )\n        if filename:\n            try:\n                self.performance.export_to_csv(filename)\n                messagebox.showinfo(\"Success\", f\"Data exported to {filename}\")\n            except Exception as e:\n                messagebox.showerror(\"Error\", f\"Export failed: {e}\")\n\n    def show_system_info(self):\n        vm = psutil.virtual_memory()\n        info = f\"\"\"\nSystem Information:\n\nCPU Usage: {psutil.cpu_percent(interval=1)}%\nCPU Cores: {psutil.cpu_count()}\nMemory Total: {vm.total / 1024 / 1024 / 1024:.2f} GB\nMemory Available: {vm.available / 1024 / 1024 / 1024:.2f} GB\nMemory Used: {vm.percent}%\n\nDisk Usage: {psutil.disk_usage(\"/\").percent}%\nPython Version: {sys.version.split()[0]}\n\"\"\"\n        messagebox.showinfo(\"System Information\", info)\n\n    def on_closing(self):\n        self.running = False\n        self.destroy()\n\n\nif __name__ == \"__main__\":\n    # Load .env variables\n    try:\n        from dotenv import load_dotenv\n\n        load_dotenv()\n    except ImportError:\n        print(\"Warning: dotenv is not installed. Script assumes environment variables are set.\")\n    app = FortunaAdvancedMonitor()\n    app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n    app.mainloop()\n",
    "pg_schemas/quarantine_races.sql": "CREATE TABLE IF NOT EXISTS quarantine_races (\n    quarantine_id SERIAL PRIMARY KEY,\n    race_id VARCHAR(100),\n    track_name VARCHAR(100),\n    race_number INT,\n    post_time TIMESTAMP WITH TIME ZONE,\n    source VARCHAR(50),\n    raw_data_json JSONB, -- Store the original raw data for inspection\n    quarantine_reason TEXT, -- Reason for failing validation\n    collection_timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);",
    "requirements-dev.in": "#\n# Fortuna Faucet - High-Level Development & Testing Dependencies\n# This file is the source of truth for development dependencies.\n# Run 'pip-compile' to generate requirements-dev.txt.\n#\n\n# --- Core Testing Frameworks ---\npytest\npytest-asyncio\nfakeredis[lua]\nrespx\nplaywright\n\n# --- Code Quality & Linting ---\nblack\n# ruff is often used with black\n\n# --- Analysis & Notebooks ---\n# pandas is already in the main requirements.in\naltair\npydeck\nstreamlit\ntabula-py\n\n# --- Git & Versioning ---\nGitPython\n\n# --- Security & Auditing ---\npip-audit\npytest-mock\nanyio<4.0.0\npackaging<24\n",
    "scripts/audit_rebranding.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Rebranding Audit Script\n# ==============================================================================\n# This script performs a comprehensive, read-only audit of the project to\n# identify all files containing legacy branding terms.\n# ==============================================================================\n\nimport os\n\n# --- CONFIGURATION ---\nTARGET_TERMS = [\"checkmate\", \"solo\"]\nEXCLUDED_DIRS = [\n    \".git\",\n    \".venv\",\n    \"node_modules\",\n    \"build\",\n    \"dist\",\n    \"__pycache__\",\n    \"ReviewableJSON\",\n]\nEXCLUDED_FILES = [\"audit_rebranding.py\", \"REBRANDING_AUDIT.md\"]\nOUTPUT_FILE = \"REBRANDING_AUDIT.md\"\n# -------------------\n\n\ndef search_file_for_terms(file_path, terms):\n    \"\"\"Searches a single file for a list of terms, case-insensitively.\"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            content = f.read().lower()\n            for term in terms:\n                if term in content:\n                    return True\n    except Exception as e:\n        print(f\"[WARNING] Could not read file {file_path}: {e}\")\n    return False\n\n\ndef main():\n    \"\"\"Main orchestrator for the audit.\"\"\"\n    print(\"--- Starting Rebranding Audit ---\")\n    affected_files = []\n    for root, dirs, files in os.walk(\".\", topdown=True):\n        # Exclude specified directories\n        dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS]\n\n        for filename in files:\n            if filename in EXCLUDED_FILES:\n                continue\n\n            file_path = os.path.join(root, filename)\n\n            # Check filename itself\n            if any(term in filename.lower() for term in TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in filename: {file_path}\")\n                continue  # No need to search content if filename matches\n\n            # Check file content\n            if search_file_for_terms(file_path, TARGET_TERMS):\n                affected_files.append(file_path)\n                print(f\"[FOUND] Legacy term in content: {file_path}\")\n\n    print(f\"\\n--- Audit Complete. Found {len(affected_files)} affected files. ---\")\n\n    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"# Fortuna Faucet: Rebranding Audit Report\\n\\n\")\n        f.write(\"This report lists all files containing legacy branding terms (`checkmate`, `solo`).\\n\\n---\\n\\n\")\n        if affected_files:\n            for file_path in sorted(affected_files):\n                f.write(f\"- `{file_path.replace(os.sep, '/')}`\\n\")\n        else:\n            f.write(\"No files with legacy branding were found.\\n\")\n\n    print(f\"[SUCCESS] Report written to {OUTPUT_FILE}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/generate_manifests.py": "# scripts/generate_manifests.py\nimport json\nimport os\nfrom pathlib import Path\n\n# --- Configuration ---\nROOT_DIR = Path(\".\")\nOUTPUT_DIR = Path(\".\")\nNUM_MANIFESTS = 5 # We will create 5 balanced manifests\n\n# --- Inclusion/Exclusion Rules ---\n# This script is now comprehensive. Instead of a narrow include list,\n# it scans everything and uses a more precise exclusion list.\nINCLUDE_ONLY_DIRS = None # Deactivated: We now scan all directories by default\n\nEXCLUDE_DIRS = {\n    # Standard git/ide/v-env exclusions\n    \".git\", \".idea\", \".vscode\", \"node_modules\", \".next\", \".venv\",\n    # Build artifacts and caches\n    \"dist\", \"build\", \"__pycache__\", \".pytest_cache\", \"out\", \"build_wix\",\n    # Agent-specific/Volatile directories\n    \"attic\", \"installer\", \"ReviewableJSON\", \"jules-scratch\",\n    # Legacy code not relevant to the current monolith\n    \"PREV_src\", \"python_service\",\n}\n\nEXCLUDE_FILES_BY_EXTENSION = {\n    # Archives and logs\n    \".zip\", \".json\", \".log\", \".db\", \".sqlite3\",\n    # Binary/Image formats not useful for LLM context\n    \".png\", \".ico\", \".bmp\", \".exe\", \".dll\", \".pyd\", \".pdf\",\n    # Deactivated workflows (keep them for history, but not for active context)\n    \".ymlx\"\n}\n\n\ndef get_all_project_files():\n    \"\"\"\n    Walks the entire project directory to find all relevant files for archiving,\n    respecting a detailed set of exclusion rules.\n    \"\"\"\n    all_files_with_size = []\n    print(\"\\n--- Starting Comprehensive File Audit ---\")\n    scanned_count = 0\n    included_count = 0\n\n    for root, dirs, files in os.walk(ROOT_DIR, topdown=True):\n        current_path = Path(root)\n\n        # 1. Directory Exclusion: Prune entire directory subtrees\n        dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS and not d.endswith('.egg-info')]\n\n        for name in files:\n            scanned_count += 1\n            file_path = current_path / name\n\n            # 2. Filename/Extension Exclusion\n            if name.startswith(('MANIFEST_PART', 'FORTUNA_ALL_PART', '.env')):\n                continue\n            if file_path.suffix in EXCLUDE_FILES_BY_EXTENSION:\n                continue\n\n            # Special case: allow '.spec' files which are critical configs\n            if file_path.suffix == '.spec' and name not in ['api.spec']:\n                 pass # keep it\n            elif file_path.suffix in ['.spec']:\n                 continue # exclude other .spec files\n\n            try:\n                posix_path = str(file_path.as_posix())\n                size = os.path.getsize(file_path)\n                all_files_with_size.append((posix_path, size))\n                included_count += 1\n            except FileNotFoundError:\n                print(f\"[WARNING] File not found during scan: {file_path}\")\n                continue\n\n    print(f\"Scanned {scanned_count} files, included {included_count} for manifest.\")\n    print(\"--- File Audit Complete ---\\n\")\n    return all_files_with_size\n\n\ndef balance_files_by_size(files_with_size, num_bins):\n    \"\"\"\n    Distributes files into a specified number of bins, balancing by size and count.\n    Uses a hybrid greedy and round-robin approach for better distribution.\n    \"\"\"\n    # Define categories for more granular balancing\n    categories = {\n        'large': [], 'medium': [], 'small': [], 'config': [], 'docs': [],\n        'workflows': [], 'scripts': [], 'source': []\n    }\n\n    # Categorize files based on extension and size\n    for path, size in files_with_size:\n        ext = Path(path).suffix.lower()\n        if 'github/workflows' in path:\n            categories['workflows'].append((path, size))\n        elif ext in ['.md', '.txt']:\n            categories['docs'].append((path, size))\n        elif ext in ['.json', '.toml', '.ini', '.spec', '.lock']:\n            categories['config'].append((path, size))\n        elif ext == '.py' and 'scripts' in path:\n            categories['scripts'].append((path, size))\n        elif ext in ['.py', '.js', '.ts', '.tsx', '.css', '.html', '.wxs']:\n            if size > 50 * 1024:  # Over 50KB\n                categories['large'].append((path, size))\n            elif size > 10 * 1024: # Over 10KB\n                categories['medium'].append((path, size))\n            else:\n                categories['small'].append((path, size))\n        else:\n            categories['source'].append((path, size))\n\n    bins = [[] for _ in range(num_bins)]\n    bin_sizes = [0] * num_bins\n\n    # Distribute large files first using greedy approach\n    for category in ['large', 'medium']:\n        # Sort descending to place largest files first\n        categories[category].sort(key=lambda x: x[1], reverse=True)\n        for path, size in categories[category]:\n            min_bin_index = bin_sizes.index(min(bin_sizes))\n            bins[min_bin_index].append(path)\n            bin_sizes[min_bin_index] += size\n\n    # Distribute remaining files using round-robin to balance file count\n    current_bin = 0\n    for category in ['small', 'config', 'docs', 'workflows', 'scripts', 'source']:\n        # Sort alphabetically for consistent distribution\n        categories[category].sort(key=lambda x: x[0])\n        for path, size in categories[category]:\n            bins[current_bin].append(path)\n            bin_sizes[current_bin] += size\n            current_bin = (current_bin + 1) % num_bins\n\n    # Print the balancing results for verification\n    print(\"--- Manifest Balancing Results (Enhanced) ---\")\n    for i, (file_list, total_size) in enumerate(zip(bins, bin_sizes)):\n        print(\n            f\" Manifest {i+1}: {len(file_list):>4} files, \"\n            f\"Total size: {total_size / 1024 / 1024:>6.2f} MB\"\n        )\n    print(\"------------------------------------------\")\n\n    return bins\n\n\ndef main():\n    \"\"\"Generate balanced manifest files based on file size.\"\"\"\n    print(\"--- Starting Manifest Generation (Size-Balanced) ---\")\n    all_files = get_all_project_files()\n    print(f\"Found {len(all_files)} total project files to consider.\")\n\n    balanced_manifests = balance_files_by_size(all_files, NUM_MANIFESTS)\n\n    # Write the updated manifest files\n    for i, file_list in enumerate(balanced_manifests):\n        manifest_name = f\"MANIFEST_PART{i+1}.json\"\n        output_path = OUTPUT_DIR / manifest_name\n        sorted_files = sorted(file_list) # Sort alphabetically for consistency\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(sorted_files, f, indent=4)\n        print(f\"\u2705 Wrote {len(sorted_files)} entries to {output_path}\")\n\n    print(\"\\n[SUCCESS] All manifest files have been generated and balanced.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "scripts/import_test.py": "\nimport sys\nsys.path.insert(0, '.')\ntry:\n    from web_service.backend.api import app\n    print(f'\u2705 app object loaded: {type(app).__name__}')\nexcept Exception as e:\n    print(f'\u274c CRITICAL IMPORT ERROR: {e}')\n    import traceback\n    traceback.print_exc()\n    sys.exit(1)\n",
    "scripts/install_fortuna_silent.bat": "@echo off\nREM Automated deployment (no UI, minimal interaction)\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo ERROR: Admin rights required\n    exit /b 1\n)\n\nREM Assumes the MSI is in the 'dist' subfolder relative to the project root\nmsiexec.exe /i \"..\\dist\\Fortuna-Faucet-2.1.0-x64.msi\" ^\n    /qn ^\n    /l*v \"%TEMP%\\fortuna_silent_install.log\" ^\n    /norestart ^\n    ALLUSERS=1 ^\n    INSTALLSCOPE=perMachine\n\nexit /b %errorlevel%",
    "scripts/templates/race_report_template.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>\ud83d\udc34 Fortuna Faucet - Race Report</title>\n    <style>\n        :root {\n            --color-primary: #00ff88;\n            --color-primary-dim: rgba(0, 255, 136, 0.1);\n            --color-primary-muted: rgba(0, 255, 136, 0.2);\n            --color-bg-dark: #0f1419;\n            --color-bg-card: #0f3460;\n            --color-bg-card-hover: #1a4d7a;\n            --color-text: #e2e8f0;\n            --color-text-muted: #a0aec0;\n            --color-border: #1a3a52;\n            --color-error: #ff4444;\n            --color-warning: #ffaa00;\n            --shadow-card: 0 4px 20px rgba(0, 0, 0, 0.3);\n            --shadow-glow: 0 0 10px rgba(0, 255, 136, 0.5);\n            --transition-fast: 0.2s ease;\n            --transition-normal: 0.3s ease;\n        }\n\n        .light-mode {\n            --color-bg-dark: #f5f7fa;\n            --color-bg-card: #ffffff;\n            --color-bg-card-hover: #f0f4f8;\n            --color-text: #1a202c;\n            --color-text-muted: #718096;\n            --color-border: #e2e8f0;\n            --shadow-card: 0 4px 20px rgba(0, 0, 0, 0.1);\n        }\n\n        * { margin: 0; padding: 0; box-sizing: border-box; }\n        html { scroll-behavior: smooth; }\n\n        body {\n            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;\n            background: linear-gradient(135deg, var(--color-bg-dark) 0%, #1a1f2e 50%, #16213e 100%);\n            color: var(--color-text);\n            line-height: 1.6;\n            min-height: 100vh;\n        }\n\n        .light-mode body {\n            background: var(--color-bg-dark);\n        }\n\n        .container {\n            max-width: 1400px;\n            margin: 0 auto;\n            padding: 1rem;\n        }\n\n        @media (min-width: 768px) {\n            .container { padding: 2rem; }\n        }\n\n        /* Header */\n        header {\n            text-align: center;\n            margin-bottom: 2rem;\n            background: linear-gradient(135deg, rgba(15, 52, 96, 0.5), var(--color-primary-dim));\n            border: 2px solid var(--color-primary);\n            border-radius: 12px;\n            padding: 2rem 1rem;\n            box-shadow: 0 8px 32px var(--color-primary-muted);\n        }\n\n        @media (min-width: 768px) {\n            header { padding: 3rem 2rem; }\n        }\n\n        h1 {\n            color: var(--color-primary);\n            font-size: clamp(1.5rem, 5vw, 2.8rem);\n            margin-bottom: 0.5rem;\n            text-shadow: var(--shadow-glow);\n        }\n\n        .subtitle {\n            color: var(--color-text-muted);\n            font-size: 0.9rem;\n            margin-top: 0.25rem;\n        }\n\n        /* Controls */\n        .controls {\n            display: flex;\n            flex-wrap: wrap;\n            gap: 1rem;\n            margin: 1.5rem 0;\n            padding: 1rem;\n            background: var(--color-primary-dim);\n            border-radius: 8px;\n            align-items: center;\n        }\n\n        .search-box {\n            flex: 1;\n            min-width: 200px;\n            padding: 0.75rem 1rem;\n            border: 1px solid var(--color-border);\n            border-radius: 6px;\n            background: rgba(0, 0, 0, 0.2);\n            color: var(--color-text);\n            font-size: 1rem;\n        }\n\n        .light-mode .search-box {\n            background: white;\n        }\n\n        .search-box:focus {\n            outline: none;\n            border-color: var(--color-primary);\n            box-shadow: 0 0 0 2px var(--color-primary-muted);\n        }\n\n        .search-box::placeholder {\n            color: var(--color-text-muted);\n        }\n\n        .btn {\n            padding: 0.75rem 1.25rem;\n            border: 1px solid var(--color-primary);\n            border-radius: 6px;\n            background: transparent;\n            color: var(--color-primary);\n            font-size: 0.9rem;\n            cursor: pointer;\n            transition: all var(--transition-fast);\n            white-space: nowrap;\n        }\n\n        .btn:hover, .btn:focus {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .btn:focus {\n            outline: none;\n            box-shadow: 0 0 0 2px var(--color-primary-muted);\n        }\n\n        .btn.active {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .sort-controls {\n            display: flex;\n            gap: 0.5rem;\n            flex-wrap: wrap;\n        }\n\n        .theme-toggle {\n            margin-left: auto;\n        }\n\n        /* Summary Box */\n        .summary-box {\n            background: var(--color-primary-dim);\n            border-left: 4px solid var(--color-primary);\n            border-radius: 8px;\n            padding: 1.25rem 1.5rem;\n            margin: 1.5rem 0;\n            display: flex;\n            flex-wrap: wrap;\n            gap: 1rem;\n            justify-content: space-between;\n            align-items: center;\n        }\n\n        .summary-stat {\n            text-align: center;\n        }\n\n        .summary-stat-value {\n            font-size: 1.5rem;\n            font-weight: bold;\n            color: var(--color-primary);\n        }\n\n        .summary-stat-label {\n            font-size: 0.8rem;\n            color: var(--color-text-muted);\n            text-transform: uppercase;\n            letter-spacing: 0.5px;\n        }\n\n        /* Race Cards */\n        .race-grid {\n            display: grid;\n            gap: 1.5rem;\n        }\n\n        .race-card {\n            background: linear-gradient(135deg, var(--color-bg-card) 0%, var(--color-bg-card-hover) 100%);\n            border: 1px solid var(--color-primary-muted);\n            border-left: 4px solid var(--color-primary);\n            border-radius: 12px;\n            padding: 1.5rem;\n            box-shadow: var(--shadow-card);\n            transition: all var(--transition-normal);\n        }\n\n        .light-mode .race-card {\n            background: var(--color-bg-card);\n        }\n\n        .race-card:hover {\n            transform: translateY(-2px);\n            box-shadow: 0 8px 30px var(--color-primary-muted);\n            border-color: rgba(0, 255, 136, 0.5);\n        }\n\n        .race-card.collapsed .race-content {\n            display: none;\n        }\n\n        .race-header {\n            display: flex;\n            justify-content: space-between;\n            align-items: flex-start;\n            margin-bottom: 1rem;\n            padding-bottom: 1rem;\n            border-bottom: 2px solid var(--color-primary);\n            flex-wrap: wrap;\n            gap: 0.75rem;\n            cursor: pointer;\n        }\n\n        .race-header-info {\n            flex: 1;\n            min-width: 200px;\n        }\n\n        .race-title {\n            font-size: 1.2rem;\n            font-weight: bold;\n            color: var(--color-primary);\n            display: flex;\n            align-items: center;\n            gap: 0.5rem;\n        }\n\n        .race-meta {\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n            margin-top: 0.25rem;\n        }\n\n        .race-badges {\n            display: flex;\n            gap: 0.5rem;\n            flex-wrap: wrap;\n        }\n\n        .badge {\n            padding: 0.25rem 0.75rem;\n            border-radius: 20px;\n            font-size: 0.75rem;\n            font-weight: 600;\n            text-transform: uppercase;\n            letter-spacing: 0.5px;\n        }\n\n        .badge-score {\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n        }\n\n        .badge-runners {\n            background: var(--color-primary-muted);\n            color: var(--color-primary);\n        }\n\n        .collapse-icon {\n            transition: transform var(--transition-fast);\n        }\n\n        .race-card.collapsed .collapse-icon {\n            transform: rotate(-90deg);\n        }\n\n        /* Runners Table */\n        .runners-table {\n            width: 100%;\n            border-collapse: collapse;\n            margin-top: 1rem;\n        }\n\n        .runners-table thead {\n            background: var(--color-primary-dim);\n            position: sticky;\n            top: 0;\n        }\n\n        .runners-table th {\n            padding: 0.75rem 1rem;\n            text-align: left;\n            font-weight: 600;\n            color: var(--color-primary);\n            text-transform: uppercase;\n            font-size: 0.75rem;\n            letter-spacing: 1px;\n            border-bottom: 2px solid var(--color-primary);\n        }\n\n        .runners-table td {\n            padding: 0.6rem 1rem;\n            border-bottom: 1px solid var(--color-border);\n            vertical-align: middle;\n        }\n\n        .runners-table tbody tr {\n            transition: background var(--transition-fast);\n        }\n\n        .runners-table tbody tr:hover {\n            background: var(--color-primary-dim);\n        }\n\n        .runners-table tbody tr:last-child td {\n            border-bottom: none;\n        }\n\n        .runner-name {\n            font-weight: 600;\n            color: var(--color-text);\n        }\n\n        .runner-number {\n            display: inline-flex;\n            align-items: center;\n            justify-content: center;\n            width: 1.75rem;\n            height: 1.75rem;\n            border-radius: 50%;\n            background: var(--color-primary-muted);\n            color: var(--color-primary);\n            font-weight: bold;\n            font-size: 0.8rem;\n            margin-right: 0.5rem;\n        }\n\n        .odds {\n            font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;\n            color: var(--color-primary);\n            font-weight: bold;\n            font-size: 1rem;\n        }\n\n        .source {\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n        }\n\n        /* Responsive Table */\n        @media (max-width: 640px) {\n            .runners-table thead {\n                display: none;\n            }\n\n            .runners-table tbody tr {\n                display: block;\n                padding: 0.75rem 0;\n                border-bottom: 1px solid var(--color-border);\n            }\n\n            .runners-table td {\n                display: flex;\n                justify-content: space-between;\n                padding: 0.35rem 0;\n                border: none;\n            }\n\n            .runners-table td::before {\n                content: attr(data-label);\n                font-weight: 600;\n                color: var(--color-text-muted);\n                font-size: 0.8rem;\n                text-transform: uppercase;\n            }\n        }\n\n        /* No Races */\n        .no-races {\n            text-align: center;\n            padding: 3rem 2rem;\n            background: var(--color-bg-card);\n            border: 2px dashed var(--color-error);\n            border-radius: 12px;\n            color: var(--color-text-muted);\n        }\n\n        .no-races-icon {\n            font-size: 3rem;\n            margin-bottom: 1rem;\n        }\n\n        /* Metrics Panel */\n        .metrics-panel {\n            background: var(--color-bg-card);\n            border: 1px solid var(--color-border);\n            border-radius: 8px;\n            padding: 1rem 1.5rem;\n            margin: 2rem 0;\n        }\n\n        .metrics-panel summary {\n            cursor: pointer;\n            font-weight: 600;\n            color: var(--color-primary);\n            padding: 0.5rem 0;\n        }\n\n        .metrics-grid {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));\n            gap: 1rem;\n            margin-top: 1rem;\n        }\n\n        .metric-item {\n            padding: 0.75rem;\n            background: var(--color-primary-dim);\n            border-radius: 6px;\n        }\n\n        .metric-label {\n            font-size: 0.75rem;\n            color: var(--color-text-muted);\n            text-transform: uppercase;\n        }\n\n        .metric-value {\n            font-size: 1.1rem;\n            font-weight: 600;\n            color: var(--color-text);\n        }\n\n        /* Footer */\n        footer {\n            text-align: center;\n            margin-top: 3rem;\n            padding: 2rem 1rem;\n            border-top: 1px solid var(--color-border);\n            color: var(--color-text-muted);\n            font-size: 0.85rem;\n        }\n\n        footer a {\n            color: var(--color-primary);\n            text-decoration: none;\n            transition: color var(--transition-fast);\n        }\n\n        footer a:hover {\n            text-decoration: underline;\n        }\n\n        /* Animations */\n        @keyframes fadeIn {\n            from { opacity: 0; transform: translateY(10px); }\n            to { opacity: 1; transform: translateY(0); }\n        }\n\n        .race-card {\n            animation: fadeIn 0.3s ease forwards;\n        }\n\n        /* Skip Link for Accessibility */\n        .skip-link {\n            position: absolute;\n            top: -40px;\n            left: 0;\n            background: var(--color-primary);\n            color: var(--color-bg-dark);\n            padding: 8px 16px;\n            z-index: 100;\n            transition: top var(--transition-fast);\n        }\n\n        .skip-link:focus {\n            top: 0;\n        }\n\n        /* Loading State */\n        .loading {\n            text-align: center;\n            padding: 3rem;\n            color: var(--color-text-muted);\n        }\n\n        .spinner {\n            width: 40px;\n            height: 40px;\n            border: 4px solid var(--color-border);\n            border-top-color: var(--color-primary);\n            border-radius: 50%;\n            animation: spin 1s linear infinite;\n            margin: 0 auto 1rem;\n        }\n\n        @keyframes spin {\n            to { transform: rotate(360deg); }\n        }\n\n        /* Print Styles */\n        @media print {\n            body { background: white; color: black; }\n            .controls, .theme-toggle, .btn { display: none; }\n            .race-card { break-inside: avoid; box-shadow: none; border: 1px solid #ccc; }\n        }\n    </style>\n</head>\n<body>\n    <a href=\"#main-content\" class=\"skip-link\">Skip to main content</a>\n\n    <div class=\"container\">\n        <div id=\"app\" class=\"loading\">\n            <div class=\"spinner\" aria-hidden=\"true\"></div>\n            <p>Loading race data...</p>\n        </div>\n    </div>\n\n    <!-- Data placeholder -->\n    <script id=\"race_data\" type=\"application/json\">__RACE_DATA_PLACEHOLDER__</script>\n\n    <script>\n        (function() {\n            'use strict';\n\n            // State management\n            const state = {\n                races: [],\n                filteredRaces: [],\n                searchQuery: '',\n                sortBy: 'time',\n                sortAsc: true,\n                theme: localStorage.getItem('theme') || 'dark',\n                collapsedCards: new Set(),\n                metadata: null\n            };\n\n            // Utility functions\n            const formatTime = (dateStr) => {\n                if (!dateStr) return 'N/A';\n                try {\n                    const date = new Date(dateStr);\n                    if (isNaN(date.getTime())) return 'N/A';\n                    return date.toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit', hour12: false });\n                } catch {\n                    return 'N/A';\n                }\n            };\n\n            const formatDate = (dateStr) => {\n                if (!dateStr) return 'N/A';\n                try {\n                    const date = new Date(dateStr);\n                    if (isNaN(date.getTime())) return 'N/A';\n                    return date.toLocaleDateString('en-US', {\n                        year: 'numeric',\n                        month: 'short',\n                        day: 'numeric',\n                        hour: '2-digit',\n                        minute: '2-digit'\n                    });\n                } catch {\n                    return 'N/A';\n                }\n            };\n\n            const escapeHtml = (str) => {\n                if (typeof str !== 'string') return str;\n                const div = document.createElement('div');\n                div.textContent = str;\n                return div.innerHTML;\n            };\n\n            const getBestOdds = (runner) => {\n                if (!runner.odds || typeof runner.odds !== 'object') {\n                    return { odds: 'N/A', source: 'N/A' };\n                }\n\n                let bestVal = 0;\n                let bestSource = 'N/A';\n\n                for (const [source, data] of Object.entries(runner.odds)) {\n                    const winOdds = data?.win || data;\n                    if (typeof winOdds === 'number' && winOdds > bestVal) {\n                        bestVal = winOdds;\n                        bestSource = source;\n                    }\n                }\n\n                return {\n                    odds: bestVal > 0 ? bestVal.toFixed(2) : 'N/A',\n                    source: bestSource\n                };\n            };\n\n            // Sorting functions\n            const sortFunctions = {\n                time: (a, b) => new Date(a.start_time || 0) - new Date(b.start_time || 0),\n                venue: (a, b) => (a.venue || '').localeCompare(b.venue || ''),\n                score: (a, b) => (b.qualification_score || 0) - (a.qualification_score || 0),\n                runners: (a, b) => (b.runners?.length || 0) - (a.runners?.length || 0)\n            };\n\n            // Filter and sort races\n            const updateFilteredRaces = () => {\n                let filtered = [...state.races];\n\n                // Apply search filter\n                if (state.searchQuery) {\n                    const query = state.searchQuery.toLowerCase();\n                    filtered = filtered.filter(race => {\n                        const venueMatch = (race.venue || '').toLowerCase().includes(query);\n                        const runnerMatch = (race.runners || []).some(r =>\n                            (r.name || '').toLowerCase().includes(query)\n                        );\n                        return venueMatch || runnerMatch;\n                    });\n                }\n\n                // Apply sorting\n                const sortFn = sortFunctions[state.sortBy] || sortFunctions.time;\n                filtered.sort((a, b) => {\n                    const result = sortFn(a, b);\n                    return state.sortAsc ? result : -result;\n                });\n\n                state.filteredRaces = filtered;\n            };\n\n            // Render functions\n            const renderHeader = (timestamp) => `\n                <header>\n                    <h1>\ud83d\udc34 Fortuna Faucet Race Report</h1>\n                    <p class=\"subtitle\">Filtered Trifecta Opportunities</p>\n                    <p class=\"subtitle\">Generated: ${formatDate(timestamp)}</p>\n                </header>\n            `;\n\n            const renderControls = () => `\n                <div class=\"controls\" role=\"search\" aria-label=\"Filter and sort controls\">\n                    <input\n                        type=\"search\"\n                        id=\"search-input\"\n                        class=\"search-box\"\n                        placeholder=\"Search venues or horses...\"\n                        value=\"${escapeHtml(state.searchQuery)}\"\n                        aria-label=\"Search races\"\n                    />\n                    <div class=\"sort-controls\" role=\"group\" aria-label=\"Sort options\">\n                        <button class=\"btn ${state.sortBy === 'time' ? 'active' : ''}\" data-sort=\"time\">\n                            \u23f0 Time\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'score' ? 'active' : ''}\" data-sort=\"score\">\n                            \u2b50 Score\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'venue' ? 'active' : ''}\" data-sort=\"venue\">\n                            \ud83d\udccd Venue\n                        </button>\n                        <button class=\"btn ${state.sortBy === 'runners' ? 'active' : ''}\" data-sort=\"runners\">\n                            \ud83c\udfc7 Runners\n                        </button>\n                    </div>\n                    <button id=\"theme-toggle\" class=\"btn theme-toggle\" aria-label=\"Toggle theme\">\n                        ${state.theme === 'dark' ? '\u2600\ufe0f Light' : '\ud83c\udf19 Dark'}\n                    </button>\n                </div>\n            `;\n\n            const renderSummary = () => {\n                const totalRunners = state.filteredRaces.reduce((sum, r) => sum + (r.runners?.length || 0), 0);\n                const avgScore = state.filteredRaces.length > 0\n                    ? (state.filteredRaces.reduce((sum, r) => sum + (r.qualification_score || 0), 0) / state.filteredRaces.length).toFixed(1)\n                    : 'N/A';\n\n                return `\n                    <div class=\"summary-box\" role=\"region\" aria-label=\"Summary statistics\">\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${state.filteredRaces.length}</div>\n                            <div class=\"summary-stat-label\">Qualified Races</div>\n                        </div>\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${totalRunners}</div>\n                            <div class=\"summary-stat-label\">Total Runners</div>\n                        </div>\n                        <div class=\"summary-stat\">\n                            <div class=\"summary-stat-value\">${avgScore}</div>\n                            <div class=\"summary-stat-label\">Avg Score</div>\n                        </div>\n                        ${state.searchQuery ? `\n                            <div class=\"summary-stat\">\n                                <div class=\"summary-stat-value\">${state.races.length}</div>\n                                <div class=\"summary-stat-label\">Total Available</div>\n                            </div>\n                        ` : ''}\n                    </div>\n                `;\n            };\n\n            const renderRunner = (runner, index) => {\n                const { odds, source } = getBestOdds(runner);\n                const number = runner.number || runner.post_position || index + 1;\n\n                return `\n                    <tr>\n                        <td data-label=\"Horse\">\n                            <span class=\"runner-number\">${number}</span>\n                            <span class=\"runner-name\">${escapeHtml(runner.name || 'Unknown')}</span>\n                        </td>\n                        <td data-label=\"Win Odds\" class=\"odds\">${odds}</td>\n                        <td data-label=\"Source\" class=\"source\">${escapeHtml(source)}</td>\n                    </tr>\n                `;\n            };\n\n            const renderRaceCard = (race, index) => {\n                const raceId = `race-${race.venue}-${race.race_number}`.replace(/\\s+/g, '-');\n                const isCollapsed = state.collapsedCards.has(raceId);\n                const score = race.qualification_score != null ? race.qualification_score.toFixed(1) : 'N/A';\n                const runners = race.runners || [];\n\n                return `\n                    <article\n                        class=\"race-card ${isCollapsed ? 'collapsed' : ''}\"\n                        data-race-id=\"${raceId}\"\n                        style=\"animation-delay: ${index * 0.05}s\"\n                    >\n                        <div class=\"race-header\"\n                             role=\"button\"\n                             tabindex=\"0\"\n                             aria-expanded=\"${!isCollapsed}\"\n                             aria-controls=\"${raceId}-content\">\n                            <div class=\"race-header-info\">\n                                <h2 class=\"race-title\">\n                                    <span class=\"collapse-icon\" aria-hidden=\"true\">\u25bc</span>\n                                    ${escapeHtml(race.venue || 'Unknown')} - Race ${race.race_number || '?'}\n                                </h2>\n                                <div class=\"race-meta\">\n                                    Post Time: ${formatTime(race.start_time)}\n                                    ${race.distance ? ` \u2022 ${escapeHtml(race.distance)}` : ''}\n                                    ${race.surface ? ` \u2022 ${escapeHtml(race.surface)}` : ''}\n                                </div>\n                            </div>\n                            <div class=\"race-badges\">\n                                <span class=\"badge badge-score\" title=\"Qualification Score\">\u2b50 ${score}</span>\n                                <span class=\"badge badge-runners\" title=\"Number of Runners\">\ud83c\udfc7 ${runners.length}</span>\n                            </div>\n                        </div>\n                        <div class=\"race-content\" id=\"${raceId}-content\">\n                            ${runners.length > 0 ? `\n                                <table class=\"runners-table\" role=\"table\">\n                                    <thead>\n                                        <tr>\n                                            <th scope=\"col\">Horse</th>\n                                            <th scope=\"col\">Win Odds</th>\n                                            <th scope=\"col\">Best Source</th>\n                                        </tr>\n                                    </thead>\n                                    <tbody>\n                                        ${runners.map((r, i) => renderRunner(r, i)).join('')}\n                                    </tbody>\n                                </table>\n                            ` : '<p class=\"no-runners\">No runner data available</p>'}\n                        </div>\n                    </article>\n                `;\n            };\n\n            const renderNoRaces = () => `\n                <div class=\"no-races\" role=\"alert\">\n                    <div class=\"no-races-icon\">\ud83d\udd2d</div>\n                    <h2>No Races Found</h2>\n                    <p>${state.searchQuery\n                        ? `No races match \"${escapeHtml(state.searchQuery)}\". Try a different search term.`\n                        : 'No qualified races found at this time. Check back later for updates.'\n                    }</p>\n                    ${state.searchQuery ? '<button class=\"btn\" id=\"clear-search\">Clear Search</button>' : ''}\n                </div>\n            `;\n\n            const renderMetrics = () => {\n                if (!state.metadata?.generation_metrics) return '';\n\n                const m = state.metadata.generation_metrics;\n                return `\n                    <details class=\"metrics-panel\">\n                        <summary>\ud83d\udcca Generation Metrics</summary>\n                        <div class=\"metrics-grid\">\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Total Fetched</div>\n                                <div class=\"metric-value\">${m.total_races_fetched || 0}</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Qualified</div>\n                                <div class=\"metric-value\">${m.qualified_races || 0}</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Duration</div>\n                                <div class=\"metric-value\">${(m.duration_seconds || 0).toFixed(1)}s</div>\n                            </div>\n                            <div class=\"metric-item\">\n                                <div class=\"metric-label\">Adapters Used</div>\n                                <div class=\"metric-value\">${m.adapters_used?.length || 0}</div>\n                            </div>\n                        </div>\n                    </details>\n                `;\n            };\n\n            const renderFooter = () => `\n                <footer>\n                    <p>This report was automatically generated by <strong>Fortuna Faucet</strong> via GitHub Actions.</p>\n                    <p>Data sources: Multiple racing exchanges and bookmakers.</p>\n                    <p>\n                        <kbd>?</kbd> Help \u2022\n                        <kbd>\u2191\u2193</kbd> Navigate \u2022\n                        <kbd>Enter</kbd> Expand/Collapse\n                    </p>\n                </footer>\n            `;\n\n            const render = () => {\n                updateFilteredRaces();\n\n                const app = document.getElementById('app');\n                app.className = '';\n                app.innerHTML = `\n                    ${renderHeader(state.metadata?.timestamp)}\n                    ${renderControls()}\n                    ${renderSummary()}\n                    <main id=\"main-content\" class=\"race-grid\" role=\"main\" aria-label=\"Race cards\">\n                        ${state.filteredRaces.length > 0\n                            ? state.filteredRaces.map((race, i) => renderRaceCard(race, i)).join('')\n                            : renderNoRaces()\n                        }\n                    </main>\n                    ${renderMetrics()}\n                    ${renderFooter()}\n                `;\n\n                attachEventListeners();\n            };\n\n            const attachEventListeners = () => {\n                // Search input\n                const searchInput = document.getElementById('search-input');\n                if (searchInput) {\n                    let debounceTimer;\n                    searchInput.addEventListener('input', (e) => {\n                        clearTimeout(debounceTimer);\n                        debounceTimer = setTimeout(() => {\n                            state.searchQuery = e.target.value;\n                            render();\n                            document.getElementById('search-input')?.focus();\n                        }, 300);\n                    });\n                }\n\n                // Sort buttons\n                document.querySelectorAll('[data-sort]').forEach(btn => {\n                    btn.addEventListener('click', (e) => {\n                        const sortBy = e.target.dataset.sort;\n                        if (state.sortBy === sortBy) {\n                            state.sortAsc = !state.sortAsc;\n                        } else {\n                            state.sortBy = sortBy;\n                            state.sortAsc = sortBy !== 'score'; // Score defaults descending\n                        }\n                        render();\n                    });\n                });\n\n                // Theme toggle\n                const themeToggle = document.getElementById('theme-toggle');\n                if (themeToggle) {\n                    themeToggle.addEventListener('click', () => {\n                        state.theme = state.theme === 'dark' ? 'light' : 'dark';\n                        document.documentElement.classList.toggle('light-mode', state.theme === 'light');\n                        localStorage.setItem('theme', state.theme);\n                        render();\n                    });\n                }\n\n                // Clear search button\n                const clearSearch = document.getElementById('clear-search');\n                if (clearSearch) {\n                    clearSearch.addEventListener('click', () => {\n                        state.searchQuery = '';\n                        render();\n                    });\n                }\n\n                // Race card collapse/expand\n                document.querySelectorAll('.race-header').forEach(header => {\n                    const handleToggle = () => {\n                        const card = header.closest('.race-card');\n                        const raceId = card.dataset.raceId;\n\n                        if (state.collapsedCards.has(raceId)) {\n                            state.collapsedCards.delete(raceId);\n                        } else {\n                            state.collapsedCards.add(raceId);\n                        }\n\n                        card.classList.toggle('collapsed');\n                        header.setAttribute('aria-expanded', !card.classList.contains('collapsed'));\n                    };\n\n                    header.addEventListener('click', handleToggle);\n                    header.addEventListener('keydown', (e) => {\n                        if (e.key === 'Enter' || e.key === ' ') {\n                            e.preventDefault();\n                            handleToggle();\n                        }\n                    });\n                });\n            };\n\n            // Keyboard navigation\n            document.addEventListener('keydown', (e) => {\n                if (e.target.matches('input, textarea')) return;\n\n                if (e.key === '/') {\n                    e.preventDefault();\n                    document.getElementById('search-input')?.focus();\n                } else if (e.key === 'Escape') {\n                    document.getElementById('search-input')?.blur();\n                }\n            });\n\n            // Initialize\n            const init = () => {\n                // Apply saved theme\n                if (state.theme === 'light') {\n                    document.documentElement.classList.add('light-mode');\n                }\n\n                try {\n                    const dataEl = document.getElementById('race_data');\n                    if (!dataEl) throw new Error('Data element not found');\n\n                    const jsonData = JSON.parse(dataEl.textContent);\n                    state.races = jsonData.races || [];\n                    state.metadata = jsonData;\n\n                    render();\n                } catch (err) {\n                    console.error('Failed to initialize:', err);\n                    document.getElementById('app').innerHTML = `\n                        <div class=\"no-races\">\n                            <div class=\"no-races-icon\">\u26a0\ufe0f</div>\n                            <h2>Failed to Load Data</h2>\n                            <p>Error: ${escapeHtml(err.message)}</p>\n                        </div>\n                    `;\n                }\n            };\n\n            if (document.readyState === 'loading') {\n                document.addEventListener('DOMContentLoaded', init);\n            } else {\n                init();\n            }\n        })();\n    </script>\n</body>\n</html>\n",
    "setup.py": "# setup.py\nfrom setuptools import find_packages\nfrom setuptools import setup\n\nwith open(\"requirements.txt\") as f:\n    requirements = f.read().splitlines()\n\nsetup(\n    name=\"fortuna_engine\",\n    version=\"1.0.0\",\n    packages=find_packages(),\n    author=\"Jules\",\n    author_email=\"\",\n    description=\"The Python backend for the Fortuna Faucet application.\",\n    long_description=\"This package contains the FastAPI server and all related data adapters and analysis tools.\",\n    install_requires=requirements,\n    entry_points={\n        \"console_scripts\": [\n            \"fortuna-engine=python_service.run_api:main\",\n        ],\n    },\n    include_package_data=True,\n    package_data={\n        \"python_service\": [\"*.py\"],\n    },\n)\n",
    "start_docker.bat": "@echo off\nREM ============================================================\nREM Fortuna Faucet - Docker Launcher for Windows\nREM A simple, friendly way to start your racing analysis engine\nREM ============================================================\n\nsetlocal enabledelayedexpansion\n\nREM Colors and styling\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83d\udc34  FORTUNA FAUCET LAUNCHER  \ud83d\udc34                \u2551\necho \u2551          Racing Strategy Analysis Engine                  \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM ============================================================\nREM STEP 1: Check if Docker is installed\nREM ============================================================\necho [1/5] Checking for Docker installation...\ndocker --version >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Docker is not installed or not in PATH\n    echo.\n    echo To use Fortuna, you need Docker Desktop:\n    echo https://www.docker.com/products/docker-desktop\n    echo.\n    echo After installing Docker, restart your computer and try again.\n    echo.\n    pause\n    exit /b 1\n)\n\nfor /f \"tokens=*\" %%i in ('docker --version') do set DOCKER_VERSION=%%i\necho \u2713 Found: %DOCKER_VERSION%\necho.\n\nREM ============================================================\nREM STEP 2: Check if Docker daemon is running\nREM ============================================================\necho [2/5] Checking if Docker daemon is running...\ndocker ps >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Docker daemon is not running\n    echo.\n    echo Please:\n    echo 1. Open \"Docker Desktop\" from your Start Menu\n    echo 2. Wait 30 seconds for Docker to fully start\n    echo 3. Then run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\necho \u2713 Docker daemon is running\necho.\n\nREM ============================================================\nREM STEP 3: Pull latest Docker image\nREM ============================================================\necho [3/5] Pulling latest Fortuna image from Docker Hub...\necho (This may take a minute on first run)\necho.\ndocker pull masonj0/fortuna-faucet:latest\nif errorlevel 1 (\n    echo.\n    echo \u26a0 Warning: Could not pull from Docker Hub\n    echo Checking for local image...\n    docker image inspect masonj0/fortuna-faucet:latest >nul 2>&1\n    if errorlevel 1 (\n        echo \u2717 ERROR: No local image found\n        echo Please check your internet connection and try again.\n        echo.\n        pause\n        exit /b 1\n    )\n    echo \u2713 Using existing local image\n)\necho \u2713 Image ready\necho.\n\nREM ============================================================\nREM STEP 4: Start container\nREM ============================================================\necho [4/5] Starting Fortuna container...\necho.\n\nREM Stop any existing container (ignore errors)\ndocker stop fortuna-faucet >nul 2>&1\ndocker rm fortuna-faucet >nul 2>&1\n\nREM Create data directories if they don't exist\nif not exist \"data\" mkdir data\nif not exist \"logs\" mkdir logs\n\nREM Start container with proper quoting for paths with spaces\ndocker run -d ^\n  --name fortuna-faucet ^\n  -p 8000:8000 ^\n  -v \"%cd%\\data:/app/web_service/backend/data\" ^\n  -v \"%cd%\\logs:/app/web_service/backend/logs\" ^\n  masonj0/fortuna-faucet:latest\n\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Failed to start container\n    echo.\n    echo Try these troubleshooting steps:\n    echo 1. Open Docker Desktop\n    echo 2. Wait for it to fully start\n    echo 3. Open Command Prompt and run: docker ps\n    echo    (This tests if Docker is working)\n    echo 4. Run this launcher again\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Container started successfully\necho.\n\nREM ============================================================\nREM STEP 5: Wait and verify startup\nREM ============================================================\necho [5/5] Waiting for application to start...\ntimeout /t 3 /nobreak\n\nREM Check if container is still running\ndocker inspect fortuna-faucet >nul 2>&1\nif errorlevel 1 (\n    echo.\n    echo \u2717 ERROR: Container exited unexpectedly\n    echo.\n    echo Showing container logs for debugging:\n    echo.\n    docker logs fortuna-faucet\n    echo.\n    pause\n    exit /b 1\n)\n\necho \u2713 Application is ready!\necho.\n\nREM ============================================================\nREM SUCCESS - Open browser and show logs\nREM ============================================================\ncls\necho.\necho \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\necho \u2551                                                            \u2551\necho \u2551            \ud83c\udf89  FORTUNA IS RUNNING!  \ud83c\udf89                   \u2551\necho \u2551                                                            \u2551\necho \u2551  Your racing analysis engine is ready at:                \u2551\necho \u2551                                                            \u2551\necho \u2551          http://localhost:8000                            \u2551\necho \u2551                                                            \u2551\necho \u2551  Opening browser now...                                   \u2551\necho \u2551                                                            \u2551\necho \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\necho.\n\nREM Open browser\nstart http://localhost:8000\n\nREM Small delay to let browser open\ntimeout /t 2 /nobreak\n\nREM Show logs\necho.\necho \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\necho \u2502 Live Application Logs (Ctrl+C to stop)                    \u2502\necho \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\necho.\n\ndocker logs -f fortuna-faucet\n\nREM Cleanup on exit\necho.\necho Stopping Fortuna...\ndocker stop fortuna-faucet >nul 2>&1\necho \u2713 Fortuna stopped\n\nexit /b 0\n",
    "tests/adapters/test_the_racing_api_adapter.py": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timezone\nfrom decimal import Decimal\nfrom unittest.mock import AsyncMock\n\nimport pytest\n\nfrom python_service.adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom python_service.core.exceptions import AdapterConfigError\nfrom tests.conftest import get_test_settings\n\n\n@pytest.fixture\ndef test_settings():\n    \"\"\"Provides a valid Settings object for testing.\"\"\"\n    return get_test_settings()\n\n\ndef test_init_raises_config_error_if_no_key():\n    \"\"\"\n    Tests that the adapter raises an AdapterConfigError if the API key is not set.\n    \"\"\"\n    settings_no_key = get_test_settings()\n    settings_no_key.THE_RACING_API_KEY = None\n    with pytest.raises(AdapterConfigError) as excinfo:\n        TheRacingApiAdapter(config=settings_no_key)\n    assert \"THE_RACING_API_KEY is not configured\" in str(excinfo.value)\n\n\n@pytest.mark.asyncio\nasync def test_get_races_parses_correctly(test_settings):\n    \"\"\"\n    Tests that TheRacingApiAdapter correctly parses a valid API response via get_races.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    off_time = datetime.now(timezone.utc)\n\n    mock_api_response = {\n        \"racecards\": [\n            {\n                \"race_id\": \"12345\",\n                \"course\": \"Newbury\",\n                \"race_no\": 3,\n                \"off_time\": off_time.isoformat().replace(\"+00:00\", \"Z\"),\n                \"race_name\": \"The Great Race\",\n                \"distance_f\": \"1m 2f\",\n                \"runners\": [\n                    {\n                        \"horse\": \"Speedy Steed\",\n                        \"number\": 1,\n                        \"jockey\": \"T. Rider\",\n                        \"trainer\": \"A. Trainer\",\n                        \"odds\": [{\"odds_decimal\": \"5.50\"}],\n                    },\n                    {\n                        \"horse\": \"Gallant Gus\",\n                        \"number\": 2,\n                        \"jockey\": \"J. Jockey\",\n                        \"trainer\": \"B. Builder\",\n                        \"odds\": [{\"odds_decimal\": \"3.25\"}],\n                    },\n                ],\n            }\n        ]\n    }\n\n    # Patch the internal _fetch_data method\n    adapter._fetch_data = AsyncMock(return_value=mock_api_response)\n\n    # ACT\n    races = await adapter.get_races(today)\n\n    # ASSERT\n    assert len(races) == 1\n    race = races[0]\n    assert race.id == \"tra_12345\"\n    assert race.venue == \"Newbury\"\n    assert len(race.runners) == 2\n    runner1 = race.runners[0]\n    assert runner1.name == \"Speedy Steed\"\n    assert runner1.odds[adapter.source_name].win == Decimal(\"5.50\")\n\n\n@pytest.mark.asyncio\nasync def test_get_races_handles_empty_response(test_settings):\n    \"\"\"\n    Tests that the adapter returns an empty list for an API response with no racecards.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(return_value={\"racecards\": []})\n\n    # ACT\n    races = await adapter.get_races(today)\n\n    # ASSERT\n    assert races == []\n\n\n@pytest.mark.asyncio\nasync def test_get_races_raises_exception_on_api_failure(test_settings):\n    \"\"\"\n    Tests that get_races propagates the exception when _fetch_data fails.\n    This is the desired behavior for the OddsEngine to handle it.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=test_settings)\n    today = date.today().strftime(\"%Y-%m-%d\")\n    adapter._fetch_data = AsyncMock(side_effect=Exception(\"API is down\"))\n\n    # ACT & ASSERT\n    with pytest.raises(Exception, match=\"API is down\"):\n        _ = await adapter.get_races(today)\n",
    "tests/fixtures/at_the_races_greyhounds.html": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <title>Racecard</title>\n</head>\n<body>\n    <link rel=\"canonical\" href=\"/racecard/GB/Monmore/2025-10-29/1817/1\" />\n    <h1 class=\"heading-racecard-title\">Monmore | 18:17</h1>\n    <div class=\"table-default__row--card-runner\">\n        <div class=\"table-default__cell\">\n            <span class=\"runner-number__no\">1</span>\n            <div class=\"runner-cloth-name\">\n                <span class=\"runner-cloth-name__name\">Crossfield Larry</span>\n            </div>\n            <button class=\"bet-selector__odds\">5/2</button>\n        </div>\n    </div>\n    <div class=\"table-default__row--card-runner\">\n        <div class=\"table-default__cell\">\n            <span class=\"runner-number__no\">2</span>\n            <div class=\"runner-cloth-name\">\n                <span class=\"runner-cloth-name__name\">Stouke A Star</span>\n            </div>\n            <button class=\"bet-selector__odds\">11/4</button>\n        </div>\n    </div>\n</body>\n</html>\n",
    "tests/test_api.py": "# tests/test_api.py\nfrom datetime import date\nfrom datetime import datetime\nfrom unittest.mock import AsyncMock\nfrom unittest.mock import patch\n\nimport aiosqlite\nimport pytest\n\n# --- Fixtures ---\nfrom python_service.models import AggregatedResponse\n\n# The client fixture is now correctly sourced from conftest.py,\n# which handles the settings override globally.\n\n# --- API Tests ---\n\n\n@pytest.mark.asyncio\n@patch(\"python_service.engine.OddsEngine.fetch_all_odds\", new_callable=AsyncMock)\nasync def test_get_races_endpoint_success(mock_fetch_all_odds, client):\n    \"\"\"\n    SPEC: The /api/races endpoint should return data with a valid API key.\n    \"\"\"\n    # ARRANGE\n    today = date.today()\n    mock_response = AggregatedResponse(\n        date=today,\n        races=[],\n            errors=[],\n        sources=[],\n        metadata={},\n        # This was the missing field causing the validation error\n        source_info=[],\n    )\n    mock_fetch_all_odds.return_value = mock_response.model_dump()\n    from tests.conftest import get_test_settings\n    settings = get_test_settings()\n    headers = {\"X-API-Key\": settings.API_KEY}\n\n    # ACT\n    response = await client.get(f\"/api/races?race_date={today.isoformat()}\", headers=headers)\n\n    # ASSERT\n    assert response.status_code == 200\n    mock_fetch_all_odds.assert_awaited_once()\n\n\n@pytest.mark.asyncio\nasync def test_get_tipsheet_endpoint_success(tmp_path, client):\n    \"\"\"\n    SPEC: The /api/tipsheet endpoint should return a list of tipsheet races from the database.\n    \"\"\"\n    db_path = tmp_path / \"test.db\"\n    post_time = datetime.now()\n\n    with patch(\"python_service.api.DB_PATH\", db_path):\n        async with aiosqlite.connect(db_path) as db:\n            await db.execute(\n                \"\"\"\n                CREATE TABLE tipsheet (\n                    race_id TEXT PRIMARY KEY,\n                    track_name TEXT,\n                    race_number INTEGER,\n                    post_time TEXT,\n                    score REAL,\n                    factors TEXT\n                )\n            \"\"\"\n            )\n            await db.execute(\n                \"INSERT INTO tipsheet VALUES (?, ?, ?, ?, ?, ?)\",\n                (\"test_race_1\", \"Test Park\", 1, post_time.isoformat(), 85.5, \"{}\"),\n            )\n            await db.commit()\n\n        # ACT\n        response = await client.get(f\"/api/tipsheet?date={post_time.date().isoformat()}\")\n\n        # ASSERT\n        assert response.status_code == 200\n        response_data = response.json()\n        assert len(response_data) == 1\n        # The database returns snake_case, but the Pydantic model is camelCase\n        assert response_data[0][\"raceId\"] == \"test_race_1\"\n        assert response_data[0][\"score\"] == 85.5\n\n\n@pytest.mark.asyncio\nasync def test_health_check_unauthenticated(client):\n    \"\"\"Ensures the /health endpoint is accessible without an API key.\"\"\"\n    response = await client.get(\"/health\")\n    assert response.status_code == 200\n    json_response = response.json()\n    assert json_response[\"status\"] == \"healthy\"\n\n\n@pytest.mark.asyncio\nasync def test_api_key_authentication_failure(client):\n    \"\"\"Ensures that endpoints are protected and fail with an invalid API key.\"\"\"\n    response = await client.get(\"/api/races/qualified/trifecta\", headers={\"X-API-KEY\": \"invalid_key\"})\n    assert response.status_code == 403\n    assert \"Invalid or missing API Key\" in response.json()[\"detail\"]\n\n\n@pytest.mark.asyncio\nasync def test_api_key_authentication_missing(client):\n    \"\"\"Ensures that endpoints are protected and fail with a missing API key.\"\"\"\n    response = await client.get(\"/api/races/qualified/trifecta\")\n    assert response.status_code == 403\n    assert \"Not authenticated\" in response.json()[\"detail\"]\n",
    "tests/test_manual_override.py": "# tests/test_manual_override.py\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom python_service.api import app\nfrom python_service.api import get_settings\nfrom python_service.manual_override_manager import ManualOverrideManager\nfrom tests.conftest import get_test_settings\n\n# Override settings for tests\napp.dependency_overrides[get_settings] = get_test_settings\n_settings = get_test_settings()\nAPI_KEY = getattr(_settings, \"API_KEY\", \"test-override-key-123\")\n\n\n@pytest.fixture\ndef manager() -> ManualOverrideManager:\n    \"\"\"Provides a clean ManualOverrideManager instance for each test.\"\"\"\n    return ManualOverrideManager()\n\n\ndef test_register_failure(manager: ManualOverrideManager):\n    adapter_name = \"TestAdapter\"\n    url = \"http://test.com/races\"\n    request_id = manager.register_failure(adapter_name, url)\n    assert request_id is not None\n    pending = manager.get_pending_requests()\n    assert len(pending) == 1\n    assert pending[0].request_id == request_id\n    assert pending[0].adapter_name == adapter_name\n    assert pending[0].url == url\n\n\ndef test_submit_manual_data(manager: ManualOverrideManager):\n    request_id = manager.register_failure(\"TestAdapter\", \"http://test.com/races\")\n    success = manager.submit_manual_data(request_id, \"<html></html>\", \"html\")\n    assert success\n    assert len(manager.get_pending_requests()) == 0\n    data = manager.get_manual_data(\"TestAdapter\", \"http://test.com/races\")\n    assert data is not None\n    assert data[0] == \"<html></html>\"\n    assert data[1] == \"html\"\n\n\ndef test_skip_request(manager: ManualOverrideManager):\n    request_id = manager.register_failure(\"TestAdapter\", \"http://test.com/races\")\n    success = manager.skip_request(request_id)\n    assert success\n    assert len(manager.get_pending_requests()) == 0\n    data = manager.get_manual_data(\"TestAdapter\", \"http://test.com/races\")\n    assert data is None\n\n\n@pytest.mark.asyncio\nasync def test_get_pending_overrides_endpoint(app, client):\n    # ARRANGE\n    # Access the manager *after* the TestClient has run the lifespan startup\n    manager = app.state.manual_override_manager\n    manager.clear_old_requests(max_age_hours=-1)  # Ensure a clean state by clearing all\n    manager.register_failure(\"EndpointAdapter\", \"http://endpoint.com/data\")\n\n    # ACT\n    response = await client.get(\"/api/manual-overrides/pending\", headers={\"X-API-Key\": API_KEY})\n    assert response.status_code == 200\n    data = response.json()\n    assert \"pending_requests\" in data\n    assert len(data[\"pending_requests\"]) > 0\n    assert data[\"pending_requests\"][0][\"adapter_name\"] == \"EndpointAdapter\"\n\n\n@pytest.mark.asyncio\nasync def test_submit_manual_data_endpoint(app, client):\n    # ARRANGE\n    manager = app.state.manual_override_manager\n    manager.clear_old_requests(max_age_hours=-1)\n    request_id = manager.register_failure(\"SubmitAdapter\", \"http://submit.com/data\")\n    submission = {\n        \"request_id\": request_id,\n        \"content\": \"<h1>Hello</h1>\",\n        \"content_type\": \"html\",\n    }\n    response = await client.post(\n        \"/api/manual-overrides/submit\",\n        json=submission,\n        headers={\"X-API-Key\": API_KEY},\n    )\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"success\"\n    data = manager.get_manual_data(\"SubmitAdapter\", \"http://submit.com/data\")\n    assert data is not None\n    assert data[0] == \"<h1>Hello</h1>\"\n\n\n@pytest.mark.asyncio\nasync def test_skip_manual_override_endpoint(app, client):\n    # ARRANGE\n    manager = app.state.manual_override_manager\n    manager.clear_old_requests(max_age_hours=-1)\n    request_id = manager.register_failure(\"SkipAdapter\", \"http://skip.com/data\")\n    response = await client.post(f\"/api/manual-overrides/skip/{request_id}\", headers={\"X-API-Key\": API_KEY})\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"success\"\n    # Verify the request is no longer pending\n    pending = manager.get_pending_requests()\n    assert not any(p.request_id == request_id for p in pending)\n",
    "verify_connection.py": "# verify_connection.py\n\nimport asyncio\nimport logging\nimport os\nimport subprocess\nimport sys\nimport time\nfrom pathlib import Path\n\nfrom playwright.sync_api import sync_playwright\n\n# --- Configuration ---\nLOG_LEVEL = logging.INFO\n# Set paths relative to the script's location\nSCRIPT_DIR = Path(__file__).parent.resolve()\nSCREENSHOT_DIR = SCRIPT_DIR / \"verification\"\nFRONTEND_LOG_PATH = SCRIPT_DIR / \"frontend.log\"\nBACKEND_LOG_PATH = SCRIPT_DIR / \"backend.log\"\nFRONTEND_DIR = SCRIPT_DIR / \"web_platform\" / \"frontend\"\nBACKEND_DIR = SCRIPT_DIR / \"python_service\"\nBACKEND_ENTRYPOINT = BACKEND_DIR / \"api.py\"\n\n# --- Setup Logging ---\nlogging.basicConfig(\n    level=LOG_LEVEL,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    handlers=[logging.StreamHandler(sys.stdout)],\n)\n\n\ndef start_backend():\n    \"\"\"Starts the FastAPI backend as a background process.\"\"\"\n    logging.info(\"Starting backend server...\")\n    # Ensure environment is set up for backend\n    backend_env = os.environ.copy()\n    backend_env[\"PYTHONPATH\"] = str(SCRIPT_DIR)\n    backend_env[\"API_KEY\"] = \"a_secure_test_api_key_that_is_long_enough\"\n    backend_env[\"ALLOWED_ORIGINS\"] = '[\"http://localhost:3000\", \"http://127.0.0.1:3000\"]'\n\n    # Use shell=True for Windows compatibility if needed, but separate args is better\n    command = [\n        sys.executable,\n        \"-m\",\n        \"uvicorn\",\n        \"python_service.api:app\",\n        \"--host\",\n        \"0.0.0.0\",\n        \"--port\",\n        \"8000\",\n    ]\n    try:\n        process = subprocess.Popen(\n            command,\n            cwd=SCRIPT_DIR,\n            stdout=open(BACKEND_LOG_PATH, \"w\"),\n            stderr=subprocess.STDOUT,\n            env=backend_env,\n        )\n        logging.info(f\"Backend process started with PID: {process.pid}\")\n        # Give the server a moment to initialize\n        time.sleep(5)\n        return process\n    except FileNotFoundError:\n        logging.error(\n            \"uvicorn command not found. Make sure it's installed in the environment.\"\n        )\n        return None\n    except Exception as e:\n        logging.error(f\"Failed to start backend: {e}\", exc_info=True)\n        return None\n\n\ndef start_frontend():\n    \"\"\"Starts the Next.js frontend dev server as a background process.\"\"\"\n    logging.info(\"Starting frontend development server...\")\n    try:\n        # Check for node_modules and run npm install if not present\n        if not (FRONTEND_DIR / \"node_modules\").exists():\n            logging.info(\"node_modules not found. Running 'npm install'...\")\n            install_process = subprocess.run(\n                [\"npm\", \"install\"],\n                cwd=FRONTEND_DIR,\n                check=True,\n                capture_output=True,\n                text=True,\n            )\n            logging.info(install_process.stdout)\n            if install_process.returncode != 0:\n                logging.error(\"npm install failed!\")\n                logging.error(install_process.stderr)\n                return None\n\n        # Start the dev server\n        process = subprocess.Popen(\n            [\"npm\", \"run\", \"dev\"],\n            cwd=FRONTEND_DIR,\n            stdout=open(FRONTEND_LOG_PATH, \"w\"),\n            stderr=subprocess.STDOUT,\n        )\n        logging.info(f\"Frontend process started with PID: {process.pid}\")\n        return process\n    except FileNotFoundError:\n        logging.error(\n            \"npm command not found. Make sure Node.js and npm are installed and in the PATH.\"\n        )\n        return None\n    except subprocess.CalledProcessError as e:\n        logging.error(f\"npm install failed: {e.stderr}\")\n        return None\n    except Exception as e:\n        logging.error(f\"Failed to start frontend: {e}\", exc_info=True)\n        return None\n\n\ndef get_frontend_port_from_logs(log_path: Path, timeout: int = 30) -> int:\n    \"\"\"Parses the frontend log file to find the port the dev server is running on.\"\"\"\n    start_time = time.time()\n    while time.time() - start_time < timeout:\n        try:\n            if log_path.exists():\n                with open(log_path, \"r\") as f:\n                    for line in f:\n                        if \"Local:\" in line and \"http://localhost:\" in line:\n                            port_str = line.split(\"http://localhost:\")[1].strip()\n                            if port_str.isdigit():\n                                port = int(port_str)\n                                logging.info(f\"Detected frontend port: {port}\")\n                                return port\n        except Exception as e:\n            logging.warning(f\"Could not read frontend log yet, retrying... Error: {e}\")\n        time.sleep(1)\n    logging.error(f\"Could not determine frontend port after {timeout} seconds.\")\n    return 3000 # Fallback\n\ndef verify_connection():\n    \"\"\"\n    Uses Playwright to verify the frontend can connect to the backend.\n    Captures a screenshot for visual confirmation.\n    \"\"\"\n    backend_process = None\n    frontend_process = None\n    success = False\n\n    try:\n        backend_process = start_backend()\n        if not backend_process or backend_process.poll() is not None:\n            logging.error(\"Backend failed to start or crashed.\")\n            return\n\n        frontend_process = start_frontend()\n        if not frontend_process or frontend_process.poll() is not None:\n            logging.error(\"Frontend failed to start or crashed.\")\n            return\n\n        logging.info(\"Waiting for frontend to be ready and getting port...\")\n        port = get_frontend_port_from_logs(FRONTEND_LOG_PATH)\n\n\n        with sync_playwright() as p:\n            logging.info(\"Launching browser...\")\n            browser = p.chromium.launch(headless=True)\n            page = browser.new_page()\n\n            logging.info(f\"Navigating to frontend URL at port {port}...\")\n            page.goto(f\"http://localhost:{port}\")\n\n            # Wait for a specific element that indicates a successful connection\n            # or a definitive disconnected state.\n            logging.info(\"Waiting for connection status indicator...\")\n            try:\n                # Wait up to 30 seconds for either a 'Connected' or 'Failed' state\n                page.wait_for_selector(\n                    'text=/Connecting...|Connected|Connection Failed/',\n                    timeout=30000\n                )\n\n                # Check the current status\n                connection_status = page.locator('//button[contains(@class, \"rounded-full\")]').inner_text()\n                logging.info(f\"Connection status found: {connection_status}\")\n                if \"Connected\" in connection_status:\n                    logging.info(\"Successfully connected to the backend.\")\n                    success = True\n                else:\n                    logging.error(f\"Frontend indicated a connection failure: {connection_status}\")\n\n\n            except Exception as e:\n                logging.error(f\"Failed to find connection status indicator: {e}\", exc_info=True)\n\n            logging.info(\"Capturing screenshot...\")\n            SCREENSHOT_DIR.mkdir(exist_ok=True)\n            screenshot_path = SCREENSHOT_DIR / \"debug_screenshot.png\"\n            page.screenshot(path=str(screenshot_path))\n            logging.info(f\"Screenshot saved to {screenshot_path}\")\n\n            browser.close()\n\n    finally:\n        logging.info(\"Cleaning up processes...\")\n        if frontend_process and frontend_process.poll() is None:\n            logging.info(f\"Terminating frontend process {frontend_process.pid}\")\n            frontend_process.terminate()\n            frontend_process.wait()\n        if backend_process and backend_process.poll() is None:\n            logging.info(f\"Terminating backend process {backend_process.pid}\")\n            backend_process.terminate()\n            backend_process.wait()\n        logging.info(\"Cleanup complete.\")\n        # Exit with success or failure code\n        if not success:\n            sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    verify_connection()\n",
    "web_service/backend/adapters/__init__.py": "# python_service/adapters/__init__.py\n\nfrom .at_the_races_adapter import AtTheRacesAdapter\nfrom .betfair_adapter import BetfairAdapter\nfrom .betfair_datascientist_adapter import BetfairDataScientistAdapter\nfrom .betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .brisnet_adapter import BrisnetAdapter\nfrom .equibase_adapter import EquibaseAdapter\nfrom .fanduel_adapter import FanDuelAdapter\nfrom .gbgb_api_adapter import GbgbApiAdapter\nfrom .greyhound_adapter import GreyhoundAdapter\nfrom .harness_adapter import HarnessAdapter\nfrom .oddschecker_adapter import OddscheckerAdapter\nfrom .pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .racingpost_adapter import RacingPostAdapter\nfrom .sporting_life_adapter import SportingLifeAdapter\nfrom .stubs import (\n    HorseRacingNationAdapter,\n    NYRABetsAdapter,\n    PuntersAdapter,\n    RacingTVAdapter,\n    TabAdapter,\n    TemplateAdapter,\n)\nfrom .the_racing_api_adapter import TheRacingApiAdapter\nfrom .timeform_adapter import TimeformAdapter\nfrom .tvg_adapter import TVGAdapter\nfrom .twinspires_adapter import TwinSpiresAdapter\nfrom .universal_adapter import UniversalAdapter\nfrom .xpressbet_adapter import XpressbetAdapter\n\n__all__ = [\n    \"AtTheRacesAdapter\",\n    \"BetfairAdapter\",\n    \"BetfairDataScientistAdapter\",\n    \"BetfairGreyhoundAdapter\",\n    \"BrisnetAdapter\",\n    \"EquibaseAdapter\",\n    \"FanDuelAdapter\",\n    \"GbgbApiAdapter\",\n    \"GreyhoundAdapter\",\n    \"HarnessAdapter\",\n    \"HorseRacingNationAdapter\",\n    \"NYRABetsAdapter\",\n    \"OddscheckerAdapter\",\n    \"PointsBetGreyhoundAdapter\",\n    \"PuntersAdapter\",\n    \"RacingAndSportsAdapter\",\n    \"RacingAndSportsGreyhoundAdapter\",\n    \"RacingPostAdapter\",\n    \"RacingTVAdapter\",\n    \"SportingLifeAdapter\",\n    \"TabAdapter\",\n    \"TemplateAdapter\",\n    \"TheRacingApiAdapter\",\n    \"TimeformAdapter\",\n    \"TVGAdapter\",\n    \"TwinSpiresAdapter\",\n    \"UniversalAdapter\",\n    \"XpressbetAdapter\",\n]\n",
    "web_service/backend/adapters/betfair_greyhound_adapter.py": "# python_service/adapters/betfair_greyhound_adapter.py\nimport re\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Any\nfrom typing import List\nfrom typing import Optional\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .mixins import BetfairAuthMixin\n\n\nclass BetfairGreyhoundAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching greyhound racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairGreyhounds\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for greyhound races on a given date.\"\"\"\n        if not await self._authenticate(self.http_client):\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        response = await self.make_request(\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"4339\"],  # Greyhound Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\n                        \"from\": start_time.isoformat(),\n                        \"to\": end_time.isoformat(),\n                    },\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                if race := self._parse_race(market):\n                    races.append(race)\n            except (KeyError, TypeError):\n                self.logger.warning(\n                    \"Failed to parse a Betfair Greyhound market.\",\n                    exc_info=True,\n                    market=market,\n                )\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Optional[Race]:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market.get(\"marketId\")\n        event = market.get(\"event\", {})\n        market_start_time = market.get(\"marketStartTime\")\n\n        if not all([market_id, market_start_time]):\n            return None\n\n        start_time = datetime.fromisoformat(market_start_time.replace(\"Z\", \"+00:00\"))\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner.get(\"runnerName\"),\n                scratched=runner.get(\"status\") != \"ACTIVE\",\n                selection_id=runner.get(\"selectionId\"),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n            if runner.get(\"runnerName\")\n        ]\n\n        return Race(\n            id=f\"bfg_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: str) -> int:\n        \"\"\"Extracts the race number from a market name (e.g., 'R1 480m').\"\"\"\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 0\n\n    def _get_datetime_range(self, date_str: str):\n        # Helper to create a datetime range for the Betfair API\n        start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_time = start_time + timedelta(days=1)\n        return start_time, end_time\n",
    "web_service/backend/adapters/greyhound_adapter.py": "# python_service/adapters/greyhound_adapter.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any, Dict, List\n\nfrom pydantic import ValidationError\n\nfrom ..core.exceptions import AdapterConfigError\nfrom ..models import Race, Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .utils.odds_validator import create_odds_data\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\n\n\nclass GreyhoundAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for fetching Greyhound racing data, migrated to BaseAdapterV3.\n    Activated by setting GREYHOUND_API_URL in .env.\n    \"\"\"\n\n    SOURCE_NAME = \"Greyhound Racing\"\n\n    def __init__(self, config=None):\n        if not getattr(config, \"GREYHOUND_API_URL\", None):\n            raise AdapterConfigError(self.SOURCE_NAME, \"GREYHOUND_API_URL is not configured.\")\n        super().__init__(\n            source_name=self.SOURCE_NAME,\n            base_url=config.GREYHOUND_API_URL,\n            config=config,\n        )\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw card data from the greyhound API.\"\"\"\n        endpoint = f\"v1/cards/{date}\"\n        response = await self.make_request(\"GET\", endpoint)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw card data into a list of Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"cards\"):\n            self.logger.warning(\"No 'cards' in greyhound response or empty list.\")\n            return []\n\n        all_races = []\n        for card in raw_data.get(\"cards\", []):\n            venue = card.get(\"track_name\", \"Unknown Venue\")\n            for race_data in card.get(\"races\", []):\n                try:\n                    if not race_data.get(\"runners\"):\n                        continue\n\n                    race_id = race_data.get(\"race_id\")\n                    race_number = race_data.get(\"race_number\")\n                    start_timestamp = race_data.get(\"start_time\")\n                    if not all([race_id, race_number, start_timestamp]):\n                        continue\n\n                    race = Race(\n                        id=f\"greyhound_{race_id}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=datetime.fromtimestamp(start_timestamp),\n                        runners=self._parse_runners(race_data.get(\"runners\", [])),\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n                except (ValidationError, KeyError) as e:\n                    self.logger.error(\n                        \"Error parsing greyhound race\",\n                        race_id=race_data.get(\"race_id\", \"N/A\"),\n                        error=str(e),\n                    )\n                    continue\n        return all_races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                if runner_data.get(\"scratched\", False):\n                    continue\n\n                trap_number = runner_data.get(\"trap_number\")\n                dog_name = runner_data.get(\"dog_name\")\n                if not all([trap_number, dog_name]):\n                    continue\n\n                odds_data = {}\n                win_odds_val = runner_data.get(\"odds\", {}).get(\"win\")\n                if win_odds_val is not None:\n                    win_odds = Decimal(str(win_odds_val))\n                    if odds_data_val := create_odds_data(self.source_name, win_odds):\n                        odds_data[self.source_name] = odds_data_val\n\n                runners.append(\n                    Runner(\n                        number=trap_number,\n                        name=dog_name,\n                        scratched=runner_data.get(\"scratched\", False),\n                        odds=odds_data,\n                    )\n                )\n            except (KeyError, ValidationError):\n                self.logger.warning(\"Error parsing greyhound runner, skipping.\", runner_data=runner_data)\n                continue\n        return runners\n",
    "web_service/backend/adapters/pointsbet_greyhound_adapter.py": "# python_service/adapters/pointsbet_greyhound_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\nfrom ..models import Race, Runner\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .utils.odds_validator import create_odds_data\n\n\nclass PointsBetGreyhoundAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for PointsBet Greyhound API, migrated to BaseAdapterV3.\n    \"\"\"\n\n    SOURCE_NAME = \"PointsBetGreyhound\"\n    BASE_URL = \"https://api.pointsbet.com/api/v2/sports/greyhound-racing/events/by-date/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    async def _fetch_data(self, date: str) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Fetches the raw events data from the PointsBet API.\"\"\"\n        response = await self.make_request(\"GET\", date)\n        return response.json() if response else None\n\n    def _parse_races(self, raw_data: Optional[List[Dict[str, Any]]]) -> List[Race]:\n        \"\"\"Parses the raw events data into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        all_races = []\n        for event in raw_data:\n            try:\n                if race := self._parse_race(event):\n                    all_races.append(race)\n            except (KeyError, TypeError, ValueError):\n                self.logger.error(\n                    \"Error parsing PointsBet greyhound event\",\n                    event_id=event.get(\"eventId\"),\n                    exc_info=True,\n                )\n                continue\n        return all_races\n\n    def _parse_race(self, event: Dict[str, Any]) -> Optional[Race]:\n        \"\"\"Parses a single event object from the API response.\"\"\"\n        event_id = event.get(\"eventId\")\n        venue = event.get(\"venueName\")\n        race_number = event.get(\"raceNumber\")\n        start_time_str = event.get(\"startsAt\")\n\n        if not all([event_id, venue, race_number, start_time_str]):\n            return None\n\n        runners = []\n        for runner_data in event.get(\"runners\", []):\n            name = runner_data.get(\"name\")\n            number = runner_data.get(\"saddleNumber\")\n            if not all([name, number]):\n                continue\n\n            runners.append(\n                Runner(\n                    name=name,\n                    number=number,\n                    scratched=runner_data.get(\"isScratched\", False),\n                    odds={},\n                )\n            )\n\n        if not runners:\n            return None\n\n        try:\n            start_time = datetime.fromisoformat(start_time_str.replace(\"Z\", \"+00:00\"))\n        except (ValueError, TypeError):\n            start_time = datetime.now()\n\n        return Race(\n            id=f\"pbg_{event_id}\",\n            venue=venue,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "web_service/backend/adapters/timeform_adapter.py": "# python_service/adapters/timeform_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any, List, Optional\n\nfrom selectolax.parser import HTMLParser, Node\n\nfrom ..models import Race, Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base_adapter_v3 import BaseAdapterV3\nfrom .mixins import BrowserHeadersMixin, DebugMixin\nfrom .utils.odds_validator import create_odds_data\nfrom python_service.core.smart_fetcher import BrowserEngine, FetchStrategy\n\n\nclass TimeformAdapter(BrowserHeadersMixin, DebugMixin, BaseAdapterV3):\n    \"\"\"\n    Adapter for timeform.com, migrated to BaseAdapterV3 and standardized on selectolax.\n    \"\"\"\n\n    SOURCE_NAME = \"Timeform\"\n    BASE_URL = \"https://www.timeform.com/horse-racing\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL, config=config)\n\n    def _configure_fetch_strategy(self) -> FetchStrategy:\n        return FetchStrategy(primary_engine=BrowserEngine.HTTPX)\n\n    def _get_headers(self) -> dict:\n        return self._get_browser_headers(host=\"www.timeform.com\")\n\n    async def _fetch_data(self, date: str) -> Optional[dict]:\n        \"\"\"\n        Fetches the raw HTML for all race pages for a given date.\n        \"\"\"\n        index_url = f\"/racecards/{date}\"\n        index_response = await self.make_request(\"GET\", index_url, headers=self._get_headers())\n        if not index_response or not index_response.text:\n            self.logger.warning(\"Failed to fetch Timeform index page\", url=index_url)\n            return None\n\n        self._save_debug_html(index_response.text, f\"timeform_index_{date}\")\n\n        parser = HTMLParser(index_response.text)\n        links = {a.attributes[\"href\"] for a in parser.css(\"a.rp-racecard-off-link[href]\") if a.attributes.get(\"href\")}\n\n        async def fetch_single_html(url_path: str):\n            response = await self.make_request(\"GET\", url_path, headers=self._get_headers())\n            return response.text if response else \"\"\n\n        tasks = [fetch_single_html(link) for link in links]\n        html_pages = await asyncio.gather(*tasks)\n        return {\"pages\": html_pages, \"date\": date}\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses a list of raw HTML strings into Race objects.\"\"\"\n        if not raw_data or not raw_data.get(\"pages\"):\n            return []\n\n        try:\n            race_date = datetime.strptime(raw_data[\"date\"], \"%Y-%m-%d\").date()\n        except ValueError:\n            self.logger.error(\n                \"Invalid date format provided to TimeformAdapter\",\n                date=raw_data.get(\"date\"),\n            )\n            return []\n\n        all_races = []\n        for html in raw_data[\"pages\"]:\n            if not html:\n                continue\n            try:\n                parser = HTMLParser(html)\n\n                track_name_node = parser.css_first(\"h1.rp-raceTimeCourseName_name\")\n                if not track_name_node:\n                    continue\n                track_name = clean_text(track_name_node.text())\n\n                race_time_node = parser.css_first(\"span.rp-raceTimeCourseName_time\")\n                if not race_time_node:\n                    continue\n                race_time_str = clean_text(race_time_node.text())\n\n                start_time = datetime.combine(race_date, datetime.strptime(race_time_str, \"%H:%M\").time())\n\n                all_times = [clean_text(a.text()) for a in parser.css(\"a.rp-racecard-off-link\")]\n                race_number = all_times.index(race_time_str) + 1 if race_time_str in all_times else 1\n\n                runner_rows = parser.css(\"div.rp-horseTable_mainRow\")\n                if not runner_rows:\n                    continue\n\n                runners = [self._parse_runner(row) for row in runner_rows]\n                race = Race(\n                    id=f\"tf_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                    venue=track_name,\n                    race_number=race_number,\n                    start_time=start_time,\n                    runners=[r for r in runners if r],  # Filter out None values\n                    source=self.source_name,\n                )\n                all_races.append(race)\n            except (AttributeError, ValueError, TypeError):\n                self.logger.warning(\"Error parsing a race from Timeform, skipping race.\", exc_info=True)\n                continue\n        return all_races\n\n    def _parse_runner(self, row: Node) -> Optional[Runner]:\n        try:\n            name_node = row.css_first(\"a.rp-horseTable_horse-name\")\n            if not name_node:\n                return None\n            name = clean_text(name_node.text())\n\n            num_node = row.css_first(\"span.rp-horseTable_horse-number\")\n            if not num_node:\n                return None\n            num_str = clean_text(num_node.text())\n            number_part = \"\".join(filter(str.isdigit, num_str.strip(\"()\")))\n            number = int(number_part)\n\n            odds_data = {}\n            odds_tag = row.css_first(\"button.rp-bet-placer-btn__odds\")\n            if odds_tag:\n                odds_str = clean_text(odds_tag.text())\n                if win_odds := parse_odds_to_decimal(odds_str):\n                    if odds_data_val := create_odds_data(self.source_name, win_odds):\n                        odds_data[self.source_name] = odds_data_val\n\n            return Runner(number=number, name=name, odds=odds_data)\n        except (AttributeError, ValueError, TypeError):\n            self.logger.warning(\"Failed to parse a runner from Timeform, skipping runner.\")\n            return None\n",
    "web_service/backend/analyzer.py": "from abc import ABC\nfrom abc import abstractmethod\nfrom decimal import Decimal\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\n\nimport structlog\n\nfrom python_service.models import Race\nfrom python_service.models import Runner\n\ntry:\n    # winsound is a built-in Windows library\n    import winsound\nexcept ImportError:\n    winsound = None\ntry:\n    from win10toast_py3 import ToastNotifier\nexcept (ImportError, RuntimeError):\n    # Fails gracefully on non-Windows systems\n    ToastNotifier = None\n\nlog = structlog.get_logger(__name__)\n\n\ndef _get_best_win_odds(runner: Runner) -> Optional[Decimal]:\n    \"\"\"Gets the best win odds for a runner, filtering out invalid or placeholder values.\"\"\"\n    if not runner.odds:\n        return None\n\n    valid_odds = []\n    for source_data in runner.odds.values():\n        # Handle both dict and primitive formats\n        if isinstance(source_data, dict):\n            win = source_data.get('win')\n        elif hasattr(source_data, 'win'):\n            win = source_data.win\n        else:\n            win = source_data\n\n        if win is not None and 0 < win < 999:\n            valid_odds.append(win)\n\n    return min(valid_odds) if valid_odds else None\n\n\nclass BaseAnalyzer(ABC):\n    \"\"\"The abstract interface for all future analyzer plugins.\"\"\"\n\n    def __init__(self, **kwargs):\n        pass\n\n    @abstractmethod\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"The core method every analyzer must implement.\"\"\"\n        pass\n\n\nclass TrifectaAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzes races and assigns a qualification score based on the 'Trifecta of Factors'.\"\"\"\n\n    @property\n    def name(self) -> str:\n        return \"trifecta_analyzer\"\n\n    def __init__(\n        self,\n        max_field_size: int = 10,\n        min_favorite_odds: float = 2.5,\n        min_second_favorite_odds: float = 4.0,\n    ):\n        self.max_field_size = max_field_size\n        self.min_favorite_odds = Decimal(str(min_favorite_odds))\n        self.min_second_favorite_odds = Decimal(str(min_second_favorite_odds))\n        self.notifier = RaceNotifier()\n\n    def is_race_qualified(self, race: Race) -> bool:\n        \"\"\"A race is qualified for a trifecta if it has at least 3 non-scratched runners.\"\"\"\n        if not race or not race.runners:\n            return False\n\n        active_runners = sum(1 for r in race.runners if not r.scratched)\n        return active_runners >= 3\n\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"Scores all races and returns a dictionary with criteria and a sorted list.\"\"\"\n        qualified_races = []\n        for race in races:\n            if not self.is_race_qualified(race):\n                continue\n            score = self._evaluate_race(race)\n            if score > 0:\n                race.qualification_score = score\n                qualified_races.append(race)\n\n        qualified_races.sort(key=lambda r: r.qualification_score, reverse=True)\n\n        criteria = {\n            \"max_field_size\": self.max_field_size,\n            \"min_favorite_odds\": float(self.min_favorite_odds),\n            \"min_second_favorite_odds\": float(self.min_second_favorite_odds),\n        }\n\n        log.info(\n            \"Universal scoring complete\",\n            total_races_scored=len(qualified_races),\n            criteria=criteria,\n        )\n\n        for race in qualified_races:\n            if race.qualification_score and race.qualification_score >= 85:\n                self.notifier.notify_qualified_race(race)\n\n        return {\"criteria\": criteria, \"races\": qualified_races}\n\n    def _evaluate_race(self, race: Race) -> float:\n        \"\"\"Evaluates a single race and returns a qualification score.\"\"\"\n        # --- Constants for Scoring Logic ---\n        FAV_ODDS_NORMALIZATION = 10.0\n        SEC_FAV_ODDS_NORMALIZATION = 15.0\n        FAV_ODDS_WEIGHT = 0.6\n        SEC_FAV_ODDS_WEIGHT = 0.4\n        FIELD_SIZE_SCORE_WEIGHT = 0.3\n        ODDS_SCORE_WEIGHT = 0.7\n\n        active_runners = [r for r in race.runners if not r.scratched]\n\n        runners_with_odds = []\n        for runner in active_runners:\n            best_odds = _get_best_win_odds(runner)\n            if best_odds is not None:\n                runners_with_odds.append((runner, best_odds))\n\n        if len(runners_with_odds) < 2:\n            return 0.0\n\n        runners_with_odds.sort(key=lambda x: x[1])\n        favorite_odds = runners_with_odds[0][1]\n        second_favorite_odds = runners_with_odds[1][1]\n\n        # --- Calculate Qualification Score (as inspired by the TypeScript Genesis) ---\n        field_score = (self.max_field_size - len(active_runners)) / self.max_field_size\n\n        # Normalize odds scores - cap influence of extremely high odds\n        fav_odds_score = min(float(favorite_odds) / FAV_ODDS_NORMALIZATION, 1.0)\n        sec_fav_odds_score = min(float(second_favorite_odds) / SEC_FAV_ODDS_NORMALIZATION, 1.0)\n\n        # Weighted average\n        odds_score = (fav_odds_score * FAV_ODDS_WEIGHT) + (sec_fav_odds_score * SEC_FAV_ODDS_WEIGHT)\n        final_score = (field_score * FIELD_SIZE_SCORE_WEIGHT) + (odds_score * ODDS_SCORE_WEIGHT)\n\n        # --- Apply hard filters before scoring ---\n        if (\n            len(active_runners) > self.max_field_size\n            or favorite_odds < self.min_favorite_odds\n            or second_favorite_odds < self.min_second_favorite_odds\n        ):\n            return 0.0\n\n        score = round(final_score * 100, 2)\n        race.qualification_score = score\n        return score\n\n\nclass TinyFieldTrifectaAnalyzer(TrifectaAnalyzer):\n    \"\"\"A specialized TrifectaAnalyzer that only considers races with 6 or fewer runners.\"\"\"\n\n    def __init__(self, **kwargs):\n        # Override the max_field_size to 6 for \"tiny field\" analysis\n        super().__init__(max_field_size=6, min_favorite_odds=0.75, min_second_favorite_odds=2.0, **kwargs)\n\n    @property\n    def name(self) -> str:\n        return \"tiny_field_trifecta_analyzer\"\n\n\nclass AnalyzerEngine:\n    \"\"\"Discovers and manages all available analyzer plugins.\"\"\"\n\n    def __init__(self):\n        self.analyzers: Dict[str, Type[BaseAnalyzer]] = {}\n        self._discover_analyzers()\n\n    def _discover_analyzers(self):\n        # In a real plugin system, this would inspect a folder.\n        # For now, we register them manually.\n        self.register_analyzer(\"trifecta\", TrifectaAnalyzer)\n        self.register_analyzer(\"tiny_field_trifecta\", TinyFieldTrifectaAnalyzer)\n        log.info(\n            \"AnalyzerEngine discovered plugins\",\n            available_analyzers=list(self.analyzers.keys()),\n        )\n\n    def register_analyzer(self, name: str, analyzer_class: Type[BaseAnalyzer]):\n        self.analyzers[name] = analyzer_class\n\n    def get_analyzer(self, name: str, **kwargs) -> BaseAnalyzer:\n        analyzer_class = self.analyzers.get(name)\n        if not analyzer_class:\n            log.error(\"Requested analyzer not found\", requested_analyzer=name)\n            raise ValueError(f\"Analyzer '{name}' not found.\")\n        return analyzer_class(**kwargs)\n\n\nclass AudioAlertSystem:\n    \"\"\"Plays sound alerts for important events.\"\"\"\n\n    def __init__(self):\n        self.sounds = {\n            \"high_value\": Path(__file__).parent.parent.parent / \"assets\" / \"sounds\" / \"alert_premium.wav\",\n        }\n        self.enabled = winsound is not None\n\n    def play(self, sound_type: str):\n        if not self.enabled:\n            return\n\n        sound_file = self.sounds.get(sound_type)\n        if sound_file and sound_file.exists():\n            try:\n                winsound.PlaySound(str(sound_file), winsound.SND_FILENAME | winsound.SND_ASYNC)\n            except Exception as e:\n                log.warning(\"Could not play sound\", file=sound_file, error=e)\n\n\nclass RaceNotifier:\n    \"\"\"Handles sending native Windows notifications and audio alerts for high-value races.\"\"\"\n\n    def __init__(self):\n        self.toaster = ToastNotifier(\"Fortuna\") if ToastNotifier else None\n        self.audio_system = AudioAlertSystem()\n        self.notified_races = set()\n\n    def notify_qualified_race(self, race):\n        if not self.toaster or race.id in self.notified_races:\n            return\n\n        title = \"\ud83c\udfc7 High-Value Opportunity!\"\n        message = f\"\"\"{race.venue} - Race {race.race_number}\nScore: {race.qualification_score:.0f}%\nPost Time: {race.start_time.strftime(\"%I:%M %p\")}\"\"\"\n\n        try:\n            # The `threaded=True` argument is crucial to prevent blocking the main application thread.\n            self.toaster.show_toast(title, message, duration=10, threaded=True)\n            self.notified_races.add(race.id)\n            self.audio_system.play(\"high_value\")\n            log.info(\"Notification and audio alert sent for high-value race\", race_id=race.id)\n        except Exception as e:\n            # Catch potential exceptions from the notification library itself\n            log.error(\"Failed to send notification\", error=str(e), exc_info=True)\n",
    "web_service/backend/core/exceptions.py": "# python_service/core/exceptions.py\n\"\"\"\nCustom, application-specific exceptions for the Fortuna Faucet service.\n\nThis module defines a hierarchy of exception classes to provide standardized\nerror handling, particularly for the data adapter layer. Using these specific\nexceptions instead of generic ones allows for more precise error handling and\nclearer logging throughout the application.\n\"\"\"\n\n\nclass FortunaException(Exception):\n    \"\"\"Base class for all custom exceptions in this application.\"\"\"\n\n    pass\n\n\nclass AdapterError(FortunaException):\n    \"\"\"Base class for all adapter-related errors.\"\"\"\n\n    def __init__(self, adapter_name: str, message: str):\n        self.adapter_name = adapter_name\n        super().__init__(f\"[{adapter_name}] {message}\")\n\n\nclass AdapterRequestError(AdapterError):\n    \"\"\"Raised for general network or request-related issues.\"\"\"\n\n    pass\n\n\nclass AdapterHttpError(AdapterRequestError):\n    \"\"\"Raised for unsuccessful HTTP responses (e.g., 4xx or 5xx status codes).\"\"\"\n\n    def __init__(self, adapter_name: str, status_code: int, url: str):\n        self.status_code = status_code\n        self.url = url\n        message = f\"Received HTTP {status_code} from {url}\"\n        super().__init__(adapter_name, message)\n\n\nclass AdapterAuthError(AdapterHttpError):\n    \"\"\"Raised specifically for HTTP 401/403 errors, indicating an auth failure.\"\"\"\n\n    pass\n\n\nclass AdapterRateLimitError(AdapterHttpError):\n    \"\"\"Raised specifically for HTTP 429 errors, indicating a rate limit has been hit.\"\"\"\n\n    pass\n\n\nclass AdapterTimeoutError(AdapterRequestError):\n    \"\"\"Raised when a request to an external API times out.\"\"\"\n\n    pass\n\n\nclass AdapterConnectionError(AdapterRequestError):\n    \"\"\"Raised for DNS lookup failures or refused connections.\"\"\"\n\n    pass\n\n\nclass AdapterConfigError(AdapterError):\n    \"\"\"Raised when an adapter is missing necessary configuration (e.g., an API key).\"\"\"\n\n    pass\n\n\nclass AuthenticationError(FortunaException):\n    \"\"\"Raised when authentication fails.\"\"\"\n\n    def __init__(self, source: str, message: str):\n        self.source = source\n        super().__init__(f\"[{source}] Authentication failed: {message}\")\n\n\nclass AdapterParsingError(AdapterError):\n    \"\"\"Raised when an adapter fails to parse the response from an API.\"\"\"\n\n    pass\n",
    "web_service/backend/fortuna_watchman.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: The Watchman (v2 - Score-Aware)\n# ==============================================================================\n# This is the master orchestrator for the Fortuna Faucet project.\n# It executes the full, end-to-end handicapping strategy autonomously.\n# ==============================================================================\n\nimport asyncio\nfrom datetime import datetime\nfrom datetime import timezone\nfrom typing import List\n\nimport structlog\n\nfrom .analyzer import AnalyzerEngine\nfrom .config import get_settings\nfrom .engine import OddsEngine\nfrom .etl import run_etl_for_yesterday\nfrom .models import Race\n\nlog = structlog.get_logger(__name__)\n\n\nclass Watchman:\n    \"\"\"Orchestrates the daily operation of the Fortuna Faucet.\"\"\"\n\n    def __init__(self):\n        self.settings = get_settings()\n        self.odds_engine = OddsEngine(config=self.settings)\n        self.analyzer_engine = AnalyzerEngine()\n\n    async def get_initial_targets(self) -> List[Race]:\n        \"\"\"Uses the OddsEngine and AnalyzerEngine to get the day's ranked targets.\"\"\"\n        log.info(\"Watchman: Acquiring and ranking initial targets for the day...\")\n        today_str = datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")\n        try:\n            background_tasks = set()  # Create a dummy set for background tasks\n            aggregated_data = await self.odds_engine.fetch_all_odds(today_str, background_tasks)\n            all_races = aggregated_data.get(\"races\", [])\n            if not all_races:\n                log.warning(\"Watchman: No races returned from OddsEngine.\")\n                return []\n\n            analyzer = self.analyzer_engine.get_analyzer(\"trifecta\")\n            qualified_races_result = analyzer.qualify_races(all_races)\n            qualified_races_list = qualified_races_result.get(\"races\", [])\n            log.info(\n                \"Watchman: Initial target acquisition and ranking complete\",\n                target_count=len(qualified_races_list),\n            )\n\n            # Log the top targets for better observability\n            for race in qualified_races_list[:5]:\n                log.info(\n                    \"Top Target Found\",\n                    score=race.qualification_score,\n                    venue=race.venue,\n                    race_number=race.race_number,\n                    post_time=race.start_time.isoformat(),\n                )\n            return qualified_races_list\n        except Exception as e:\n            log.error(\"Watchman: Failed to get initial targets\", error=str(e), exc_info=True)\n            return []\n\n    async def run_tactical_monitoring(self, targets: List[Race]):\n        \"\"\"Uses the LiveOddsMonitor on each target as it approaches post time.\"\"\"\n        log.info(\"Watchman: Entering tactical monitoring loop.\")\n        # active_targets = list(targets)\n\n        # from python_service.adapters.betfair_adapter import BetfairAdapter\n        # async with LiveOddsMonitor(betfair_adapter=BetfairAdapter(config=self.settings)) as live_monitor:\n        #     async with httpx.AsyncClient() as client:\n        #         while active_targets:\n        #             now = datetime.now(timezone.utc)\n\n        #             # Find races that are within the 5-minute monitoring window\n        #             races_to_monitor = [\n        #                 r\n        #                 for r in active_targets\n        #                 if r.start_time.replace(tzinfo=timezone.utc) > now\n        #                 and r.start_time.replace(tzinfo=timezone.utc)\n        #                 < now + timedelta(minutes=5)\n        #             ]\n\n        #             if races_to_monitor:\n        #                 for race in races_to_monitor:\n        #                     log.info(\"Watchman: Deploying Live Monitor for approaching target\",\n        #                         race_id=race.id,\n        #                         venue=race.venue,\n        #                         score=race.qualification_score\n        #                     )\n        #                     updated_race = await live_monitor.monitor_race(race, client)\n        #                     log.info(\"Watchman: Live monitoring complete for race\", race_id=updated_race.id)\n        #                     # Remove from target list to prevent re-monitoring\n        #                     active_targets = [t for t in active_targets if t.id != race.id]\n\n        #             if not active_targets:\n        #                 break # Exit loop if all targets are processed\n\n        #             await asyncio.sleep(30) # Check for upcoming races every 30 seconds\n\n        log.info(\"Watchman: All targets for the day have been monitored. Mission complete.\")\n\n    async def execute_daily_protocol(self):\n        \"\"\"The main, end-to-end orchestration method.\"\"\"\n        log.info(\"--- Fortuna Watchman Daily Protocol: ACTIVE ---\")\n        try:\n            initial_targets = await self.get_initial_targets()\n            if initial_targets:\n                await self.run_tactical_monitoring(initial_targets)\n            else:\n                log.info(\"Watchman: No initial targets found. Shutting down for the day.\")\n        finally:\n            await self.odds_engine.close()\n\n        # Run ETL for yesterday's data after all other operations are complete\n        try:\n            log.info(\"Starting daily ETL process for Scribe's Archives...\")\n            run_etl_for_yesterday()\n            log.info(\"Daily ETL process completed successfully.\")\n        except Exception:\n            log.error(\"Daily ETL process failed.\", exc_info=True)\n        log.info(\"--- Fortuna Watchman Daily Protocol: COMPLETE ---\")\n\n\nasync def main():\n    from .logging_config import configure_logging\n\n    configure_logging()\n    watchman = Watchman()\n    await watchman.execute_daily_protocol()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
    "web_service/backend/logging_config.py": "# python_service/logging_config.py\nimport logging\nimport sys\n\nimport structlog\n\n\ndef configure_logging(log_level: str = \"INFO\"):\n    \"\"\"Configures structlog for structured, JSON-formatted logging.\"\"\"\n    logging.basicConfig(\n        level=log_level,\n        format=\"%(message)s\",\n        stream=sys.stdout,\n    )\n\n    # Keep the processor chain simple for maximum reliability in bundled executables.\n    # More complex processors like StackInfoRenderer can cause issues in\n    # constrained environments.\n    structlog.configure(\n        processors=[\n            structlog.stdlib.filter_by_level,\n            structlog.stdlib.add_log_level,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n        cache_logger_on_first_use=True,\n    )\n",
    "web_service/backend/models.py": "# python_service/models.py\n\nfrom datetime import datetime, date\nfrom decimal import Decimal\nfrom typing import Annotated, Any, Callable, Dict, List, Optional\n\nfrom pydantic import BaseModel, ConfigDict, Field, WrapSerializer\n\n\ndef decimal_serializer(value: Decimal, handler: Callable[[Decimal], Any]) -> Any:\n    \"\"\"Custom serializer for Decimal to float conversion.\"\"\"\n    return float(value)\n\n\nJsonDecimal = Annotated[Decimal, WrapSerializer(decimal_serializer, when_used=\"json\")]\n\n\n# --- Configuration for Aliases (BUG #4 Fix) ---\nclass FortunaBaseModel(BaseModel):\n    model_config = ConfigDict(\n        populate_by_name=True,\n        arbitrary_types_allowed=True,\n    )\n\n\n# --- Core Data Models ---\nclass OddsData(FortunaBaseModel):\n    win: Optional[JsonDecimal] = None\n    place: Optional[JsonDecimal] = None\n    show: Optional[JsonDecimal] = None\n    source: str\n    last_updated: datetime\n\n\nclass Runner(FortunaBaseModel):\n    id: Optional[str] = None\n    name: str\n    number: Optional[int] = Field(None, alias=\"saddleClothNumber\")\n    scratched: bool = False\n    odds: Dict[str, OddsData] = {}\n    jockey: Optional[str] = None\n    trainer: Optional[str] = None\n\n\nclass Race(FortunaBaseModel):\n    id: str\n    venue: str\n    race_number: int = Field(..., alias=\"raceNumber\")\n    start_time: datetime = Field(..., alias=\"startTime\")\n    runners: List[Runner]\n    source: str\n    field_size: Optional[int] = None\n    qualification_score: Optional[float] = Field(None, alias=\"qualificationScore\")\n    favorite: Optional[Runner] = None\n    race_name: Optional[str] = None\n    distance: Optional[str] = None\n    is_error_placeholder: bool = Field(False, alias=\"isErrorPlaceholder\")\n    error_message: Optional[str] = Field(None, alias=\"errorMessage\")\n\n\nclass SourceInfo(FortunaBaseModel):\n    name: str\n    status: str\n    races_fetched: int = Field(..., alias=\"racesFetched\")\n    fetch_duration: float = Field(..., alias=\"fetchDuration\")\n    error_message: Optional[str] = Field(None, alias=\"errorMessage\")\n    attempted_url: Optional[str] = Field(None, alias=\"attemptedUrl\")\n\n\nclass AdapterError(FortunaBaseModel):\n    adapter_name: str = Field(..., alias=\"adapterName\")\n    error_message: str = Field(..., alias=\"errorMessage\")\n    attempted_url: Optional[str] = Field(None, alias=\"attemptedUrl\")\n\n\nclass AggregatedResponse(FortunaBaseModel):\n    race_date: Optional[date] = Field(None, alias=\"date\")\n    races: List[Race]\n    errors: List[AdapterError]\n    source_info: List[SourceInfo] = Field(..., alias=\"sourceInfo\")\n    metadata: Dict[str, Any] = {}\n\n\nclass QualifiedRacesResponse(FortunaBaseModel):\n    criteria: Dict[str, Any]\n    races: List[Race]\n\n\nclass TipsheetRace(FortunaBaseModel):\n    race_id: str = Field(..., alias=\"raceId\")\n    track_name: str = Field(..., alias=\"trackName\")\n    race_number: int = Field(..., alias=\"raceNumber\")\n    post_time: str = Field(..., alias=\"postTime\")\n    score: float\n    factors: Any  # JSON string stored as Any\n\n\nclass ManualParseRequest(FortunaBaseModel):\n    adapter_name: str\n    html_content: str = Field(..., max_length=5_000_000)  # ~5MB limit\n",
    "web_service/backend/requirements-dev.txt": "#\n# Development & Build-Time Dependencies\n# This file should be used for setting up a development or CI/CD environment.\n#\n\n-r requirements.txt\n\n# --- Build Tools ---\npip-tools\n\n# --- Testing Tools ---\npytest\npytest-asyncio\nfakeredis\nrespx\n\n# --- Linting & Auditing ---\nblack\nruff\npip-audit\nsetuptools<81\n",
    "web_service/backend/service_entry.py": "import win32serviceutil\nimport win32service\nimport win32event\nimport servicemanager\nimport socket\nimport sys\nimport os\nimport uvicorn\nimport multiprocessing\nimport threading\nfrom pathlib import Path\n\n# --- Resilient Import Block ---\n# This block is designed to robustly locate the `main` module and its `app` object,\n# whether running from source, as a PyInstaller bundle, or as a Windows Service.\n\nimport asyncio\n\ndef _bootstrap_path():\n    \"\"\"\n    Ensures the application's root directories are on the Python path.\n    This is critical for PyInstaller's frozen executables to find modules.\n    \"\"\"\n    if getattr(sys, 'frozen', False) and hasattr(sys, '_MEIPASS'):\n        # We are running in a PyInstaller bundle.\n        # The `_MEIPASS` directory is the root of our bundled files.\n        # In our `--onedir` build, this is where `main.py`'s content is.\n        sys.path.insert(0, sys._MEIPASS)\n    else:\n        # We are running from source.\n        # The entry point is in `web_service/backend`, so we need to add the project root.\n        project_root = str(Path(__file__).parent.parent.parent)\n        sys.path.insert(0, project_root)\n\n_bootstrap_path()\n\ntry:\n    # This is the most direct import path and should work when the CWD\n    # is correctly set to the directory containing the executable.\n    print(f\"[service_entry] Attempting direct import of 'main:app'...\")\n    from main import app\n    print(f\"[service_entry] Direct import successful.\")\nexcept (ImportError, ModuleNotFoundError) as e:\n    print(f\"[service_entry] Direct import failed: {e}. Attempting namespace import...\")\n    try:\n        # This is a fallback for environments where the `web_service` namespace is preserved.\n        from web_service.backend.main import app\n        print(f\"[service_entry] Namespace import successful.\")\n    except (ImportError, ModuleNotFoundError) as e2:\n        print(f\"[service_entry] All import attempts failed: {e2}. Cannot start service.\")\n        sys.exit(1) # Exit if the app cannot be imported, to prevent service start failure.\n\nclass FortunaSvc(win32serviceutil.ServiceFramework):\n    _svc_name_ = 'FortunaWebService'\n    _svc_display_name_ = 'Fortuna Faucet Backend Service'\n    _svc_description_ = 'Data aggregation and analysis engine.'\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)\n        self.server = None\n        self.server_thread = None\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        win32event.SetEvent(self.hWaitStop)\n        if self.server:\n            self.server.should_exit = True\n\n    def SvcDoRun(self):\n        # When running as a Windows Service, the default working directory is System32,\n        # which can cause issues with relative paths. This fix changes the working\n        # directory to the location of the executable.\n        if getattr(sys, 'frozen', False):\n            os.chdir(os.path.dirname(sys.executable))\n            # \u2622\ufe0f CRITICAL FIX for Windows Services running asyncio \u2622\ufe0f\n            # This policy prevents the notorious \"NotImplementedError\" when uvicorn\n            # tries to create a subprocess in a non-interactive service environment.\n            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n\n        servicemanager.LogMsg(servicemanager.EVENTLOG_INFORMATION_TYPE,\n                              servicemanager.PYS_SERVICE_STARTED,\n                              (self._svc_name_, ''))\n\n        config = uvicorn.Config(app, host='127.0.0.1', port=8102, log_config=None, reload=False)\n        self.server = uvicorn.Server(config)\n\n        # Run the server in a separate thread\n        self.server_thread = threading.Thread(target=self.server.run)\n        self.server_thread.start()\n\n        # Wait for the stop event\n        win32event.WaitForSingleObject(self.hWaitStop, win32event.INFINITE)\n\n        # Wait for the server thread to finish\n        self.server_thread.join()\n\nif __name__ == '__main__':\n    multiprocessing.freeze_support()\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaSvc)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaSvc)\n",
    "web_service/backend/utils/odds.py": "\"\"\"Odds parsing utilities with comprehensive format support.\"\"\"\n\nimport re\nfrom typing import Optional\nfrom decimal import Decimal, InvalidOperation\n\n\ndef parse_odds_to_decimal(odds_str: str) -> Optional[float]:\n    \"\"\"\n    Parse various odds formats to decimal odds.\n\n    Supports:\n    - Fractional: \"5/2\", \"9-2\", \"5-1\"\n    - Decimal: \"3.50\", \"3,50\" (European)\n    - American: \"+250\", \"-150\"\n    - Even/Evens: \"EVN\", \"EVEN\", \"evs\"\n    - Morning line: \"5-2 ML\"\n\n    Returns:\n        Decimal odds as float, or None if unparseable\n    \"\"\"\n    if not odds_str:\n        return None\n\n    # Clean input\n    odds_str = odds_str.strip().upper()\n\n    # Remove common suffixes\n    odds_str = re.sub(r'\\s*(ML|MTP|AM|PM)$', '', odds_str)\n\n    # Handle even money\n    if odds_str in ('EVN', 'EVEN', 'EVS', 'EVENS'):\n        return 2.0\n\n    # Handle scratched/invalid\n    if odds_str in ('SCR', 'SCRATCHED', '--', 'N/A', ''):\n        return None\n\n    try:\n        # Try fractional odds (5/2 or 5-2)\n        frac_match = re.match(r'^(\\d+)[/\\-](\\d+)$', odds_str)\n        if frac_match:\n            num = int(frac_match.group(1))\n            den = int(frac_match.group(2))\n            if den > 0:\n                return round((num / den) + 1.0, 2)\n\n        # Try American odds (+250 or -150)\n        american_match = re.match(r'^([+-])(\\d+)$', odds_str)\n        if american_match:\n            sign = american_match.group(1)\n            value = int(american_match.group(2))\n            if sign == '+':\n                return round((value / 100) + 1.0, 2)\n            else:\n                return round((100 / value) + 1.0, 2)\n\n        # Try decimal odds (already in correct format)\n        decimal_str = odds_str.replace(',', '.')\n        decimal_match = re.match(r'^(\\d+\\.?\\d*)$', decimal_str)\n        if decimal_match:\n            value = float(decimal_match.group(1))\n            if value >= 1.0:\n                return round(value, 2)\n\n    except (ValueError, ZeroDivisionError, InvalidOperation):\n        pass\n\n    return None\n\n\ndef format_odds_display(decimal_odds: float, style: str = 'fractional') -> str:\n    \"\"\"\n    Format decimal odds for display.\n\n    Args:\n        decimal_odds: Odds in decimal format\n        style: 'fractional', 'american', or 'decimal'\n\n    Returns:\n        Formatted odds string\n    \"\"\"\n    if not decimal_odds or decimal_odds < 1.01:\n        return \"N/A\"\n\n    if style == 'decimal':\n        return f\"{decimal_odds:.2f}\"\n\n    elif style == 'american':\n        if decimal_odds >= 2.0:\n            american = int((decimal_odds - 1) * 100)\n            return f\"+{american}\"\n        else:\n            american = int(-100 / (decimal_odds - 1))\n            return str(american)\n\n    else:  # fractional\n        # Common fractional odds lookup\n        profit = decimal_odds - 1\n\n        # Check common fractions\n        common_fractions = [\n            (0.5, \"1/2\"), (1.0, \"1/1\"), (1.5, \"3/2\"), (2.0, \"2/1\"),\n            (2.5, \"5/2\"), (3.0, \"3/1\"), (4.0, \"4/1\"), (5.0, \"5/1\"),\n            (6.0, \"6/1\"), (8.0, \"8/1\"), (10.0, \"10/1\"), (12.0, \"12/1\"),\n            (14.0, \"14/1\"), (16.0, \"16/1\"), (20.0, \"20/1\"), (25.0, \"25/1\"),\n            (33.0, \"33/1\"), (50.0, \"50/1\"), (100.0, \"100/1\"),\n        ]\n\n        for value, display in common_fractions:\n            if abs(profit - value) < 0.05:\n                return display\n\n        # Approximate to nearest reasonable fraction\n        if profit < 1:\n            return f\"{int(profit * 2)}/2\"\n        else:\n            return f\"{int(profit)}/1\"\n",
    "web_service/frontend/.gitignore": "# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.\n\n# Dependencies\n/node_modules\n/.pnp\n.pnp.js\n\n# Testing\n/coverage\n\n# Next.js\n/.next/\n/out/\n\n# Production\n/build\n\n# Misc\n.DS_Store\n*.pem\n\n# Local .env files\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n\n# Log files\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# Editor directories and files\n.vscode\n.idea\n*.suo\n*.ntvs*\n*.njsproj\n*.sln\n*.sw?",
    "web_service/frontend/app/Providers.tsx": "// web_platform/frontend/app/Providers.tsx\n'use client';\n\nimport { QueryClientProvider } from '@tanstack/react-query';\nimport { queryClient } from './lib/queryClient';\nimport React from 'react';\n\nexport default function Providers({ children }: { children: React.ReactNode }) {\n  return (\n    <QueryClientProvider client={queryClient}>{children}</QueryClientProvider>\n  );\n}\n",
    "web_service/frontend/app/components/LiveRaceDashboardNoSSR.tsx": "// web_platform/frontend/src/components/LiveRaceDashboardNoSSR.tsx\nimport dynamic from 'next/dynamic';\n\nconst LiveRaceDashboardNoSSR = dynamic(\n  () => import('./LiveRaceDashboard').then((mod) => mod.LiveRaceDashboard),\n  { ssr: false }\n);\n\nexport default LiveRaceDashboardNoSSR;\n",
    "web_service/frontend/app/components/ScoreBadge.tsx": "'use client';\nimport React from 'react';\n\nconst getScoreStyling = (score: number) => {\n  if (score >= 90) return { bg: 'bg-yellow-400/10', text: 'text-yellow-300', border: 'border-yellow-400' };\n  if (score >= 80) return { bg: 'bg-orange-500/10', text: 'text-orange-400', border: 'border-orange-500' };\n  return { bg: 'bg-sky-500/10', text: 'text-sky-400', border: 'border-sky-500' };\n};\n\nexport const ScoreBadge: React.FC<{ score: number }> = ({ score }) => {\n  const { bg, text } = getScoreStyling(score);\n  return (\n    <div className={`text-right ${text}`}>\n      <p className=\"text-3xl font-bold\">{score.toFixed(1)}</p>\n      <p className=\"text-xs font-medium tracking-wider uppercase\\\">Score</p>\n    </div>\n  );\n};",
    "web_service/frontend/app/globals.css": "@tailwind base;\n@tailwind components;\n@tailwind utilities;",
    "web_service/frontend/app/page.tsx": "'use client';\nimport dynamic from 'next/dynamic';\nimport React from 'react';\nimport { Tabs } from './components/Tabs';\nimport { SettingsPage } from './components/SettingsPage';\n\nconst LiveRaceDashboard = dynamic(\n  () => import('./components/LiveRaceDashboard').then((mod) => mod.LiveRaceDashboard),\n  {\n    ssr: false,\n    loading: () => <p className=\"text-center text-xl mt-8\">Loading Dashboard...</p>\n  }\n);\n\nexport default function Home() {\n  const tabs = [\n    {\n      label: 'Dashboard',\n      content: <LiveRaceDashboard />,\n    },\n    {\n      label: 'Settings',\n      content: <SettingsPage />,\n    },\n  ];\n\n  return (\n    <main className=\"min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 p-8\">\n      <div className=\"max-w-7xl mx-auto space-y-8\">\n        <h1 className=\"text-4xl font-bold text-white\" data-testid=\"main-heading\">Fortuna Faucet</h1>\n        <Tabs tabs={tabs} />\n      </div>\n    </main>\n  );\n}\n",
    "web_service/frontend/next.config.js": "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  output: 'export',\n  distDir: 'build',\n  images: { unoptimized: true },\n  trailingSlash: true,\n}\nmodule.exports = nextConfig\n",
    "wix/WixUI_CustomProgress.wxs": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Wix xmlns=\"http://schemas.microsoft.com/wix/2006/wi\">\n  <Fragment>\n    <UI>\n      <!-- Override the default InstallProgress dialog -->\n      <Dialog Id=\"InstallProgressDlg\" Width=\"370\" Height=\"270\" Title=\"Fortuna Faucet Installation\" Modeless=\"yes\">\n        <Control Id=\"Title\" Type=\"Title\" X=\"20\" Y=\"6\" Width=\"330\" Height=\"18\" Text=\"Installation Progress\" />\n        <Control Id=\"BannerBitmap\" Type=\"Bitmap\" X=\"0\" Y=\"0\" Width=\"370\" Height=\"44\" TabSkip=\"no\" Text=\"WixUI_Bmp_Banner\" />\n        <Control Id=\"Back\" Type=\"PushButton\" X=\"180\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Back\" Disabled=\"yes\" />\n        <Control Id=\"Next\" Type=\"PushButton\" X=\"236\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"&amp;Next\" Disabled=\"yes\" />\n        <Control Id=\"Cancel\" Type=\"PushButton\" X=\"304\" Y=\"243\" Width=\"56\" Height=\"17\" Text=\"Cancel\" />\n\n        <Control Id=\"ActionText\" Type=\"Text\" X=\"70\" Y=\"80\" Width=\"280\" Height=\"20\" TabSkip=\"no\">\n          <Subscribe Event=\"ActionText\" Attribute=\"Text\" />\n        </Control>\n        <Control Id=\"Description\" Type=\"Text\" X=\"35\" Y=\"55\" Width=\"300\" Height=\"20\" Text=\"Please wait while the installer copies files.\" />\n\n        <!-- This is the new control to display the current filename -->\n        <Control Id=\"CurrentFileText\" Type=\"Text\" X=\"70\" Y=\"100\" Width=\"280\" Height=\"20\">\n            <Subscribe Event=\"SetProgress\" Attribute=\"Text\" />\n        </Control>\n\n        <Control Id=\"ProgressBar\" Type=\"ProgressBar\" X=\"35\" Y=\"120\" Width=\"300\" Height=\"10\" ProgressBlocks=\"yes\" Text=\"Progress\">\n          <Subscribe Event=\"SetProgress\" Attribute=\"Progress\" />\n        </Control>\n      </Dialog>\n\n      <!-- The Publish element must be a child of UI, not Dialog -->\n      <Publish Dialog=\"InstallProgressDlg\" Control=\"Cancel\" Event=\"SpawnDialog\" Value=\"CancelDlg\">1</Publish>\n    </UI>\n  </Fragment>\n</Wix>\n"
}